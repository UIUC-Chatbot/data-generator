{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversational Data \n",
    "\n",
    "To do :\n",
    "-Alter prompts to add more questions per conversation \n",
    "-Format questions as per Q0,A0 - Q1,A1, etc.\n",
    "-Generate different types of conversations - interactive/talkative, formal/academic, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import transformers\n",
    "from transformers import GPT2Tokenizer\n",
    "import backoff\n",
    "from openai.error import RateLimitError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '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'\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API response for any prompt - change settings : temperature to be low, best_of=5, n=3 -> captures completions response\n",
    "@backoff.on_exception(backoff.expo, RateLimitError)\n",
    "def response_API(prompt, myKwargs = {}):\n",
    "    \n",
    "    kwargs = {\"model\" :\"text-davinci-002\",\n",
    "            \"temperature\" :0.7,\n",
    "            \"max_tokens\": 600,\n",
    "            \"frequency_penalty\":1,\n",
    "            \"presence_penalty\":0}\n",
    "    #assign changed values and keep everything else the same\n",
    "    for kwarg in myKwargs:\n",
    "        kwargs[kwarg] = myKwargs[kwarg]\n",
    "        \n",
    "    try:\n",
    "        response = openai.Completion.create(prompt=prompt, **kwargs)\n",
    "    except openai.error.APIConnectionError:\n",
    "        print(\"Failed\")\n",
    "    \n",
    "    return response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check number of tokens - to add, function takes too long. - not being used currently \n",
    "def calculate_tokens(context):\n",
    "    features = tokenizer(\"%s\", context)['input_ids']\n",
    "\n",
    "    return len(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = open(\"/Users/nehasheth/Desktop/Research - AI Chatbot TA/github/data-generator/gpt-3/GPT-3_section_level.json\")\n",
    "sections_data = json.load(s)\n",
    "\n",
    "sections_list = []\n",
    "for p, item in enumerate(sections_data):\n",
    "    subtext = item['positive_ctxs']['text']\n",
    "    sections_list.append(subtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sections_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: Hi, I'm a little confused about the design process for FSMs. Could you walk me through it?\n",
      "\n",
      "Teacher: Sure. The design process for a digital FSM typically begins with the development of an abstract model. This model captures the essential behaviors of the FSM, without getting bogged down in concrete details. Once the abstract model is developed, it can be used to generate functions for the next-state variables and output signals. These functions are then implemented using flip-flops and logic gates.\n",
      "\n",
      "Student: I see. So how do you determine which states are next to each other?\n",
      "\n",
      "Teacher: That's a good question. In most cases, you'll want to start by identifying all of the possible input combinations that can occur, and then map each combination to a corresponding state transition diagram. This will give you a good overview of how the FSM will behave under different circumstances. From there, it's just a matter of translating the state transition diagram into an implementation using logic gates and flip-flops.\n",
      "\n",
      "Student: That makes sense. But what if the number of states isn't a power of two?\n",
      "\n",
      "Teacher: In that case, you'll need to initialize the FSM in order to ensure that it starts in a known state. This can be done using a multiplexer, which is a type of selection logic that allows you to select one of several inputs based on some external control signal. By carefully choosing the input signals and setting up the multiplexer properly, you can ensure that your FSM starts in the correct state regardless of its initial conditions.\n"
     ]
    }
   ],
   "source": [
    "#0\n",
    "conversations = []\n",
    "for section in sections_list[0:1]:\n",
    "    prompt = '''Generate a long conversation between a teaching assistant and a student where the student approaches the teaching assistant with some questions based on the given context, and the teaching assistant answers the questions using thorough, academic and formal responses which are in continuation with the previous topic the student refers to. The teaching assistant has to ask follow up questions or suggestions to spur curiosity and also maintain a professional and compassionate tone while answering. \\n\n",
    "    The format of the conversation is : Student : \\n Teacher: \\n Student : \\n Teacher : \\n Student : \\n Teacher: \\n Student : \\n Teacher : \\n Student : \\n Teacher : \\n Student : \\n Teacher : \\n\n",
    "    Make sure that the conversation has atleast 7 follow up questions by the student which the teaching assistant answers.\n",
    "    The conversation is based on this below context :\\n  : %s''' % section\n",
    "    \n",
    "    response = response_API(prompt)\n",
    "    print(response)\n",
    "    conversations.append(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "for section in sections_list[0:1]:\n",
    "    prompt = '''Generate a debate and discussion based interactive conversation between a teaching assistant and a student. The student who is curious asks interesting questions to the teaching assistant, and the teaching assistant develops firm, competitive arguments to discuss the topic with the student. \n",
    "    The student has to ask at least 7 follow up questions to argue in a professional, calm tone. \n",
    "    The format of the conversation is : Student : \\n Teacher: \\n Student : \\n Teacher : \\n Student : \\n Teacher: \\n Student : \\n Teacher : \\n  Student : \\n Teacher : \\n  Student : \\n \n",
    "\n",
    "The conversation is based on this below context :\\n %s''' % section\n",
    "    \n",
    "    response = response_API(prompt)\n",
    "    print(response)\n",
    "    conversations.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Student: Hi, can I ask you a few questions about the notes on finite state machines?\n",
      "Teacher: Of course. What would you like to know?\n",
      "Student: Well, I'm having trouble understanding the design process. Could you walk me through an example?\n",
      "Teacher: Sure. Let's take a look at the counter example. First, we need to develop an abstract model of the FSM. \n",
      "Student: What does that involve?\n",
      "Teacher: We need to identify the states, inputs, and outputs of the FSM. For this example, there are four states- S0, S1, S2, and S3. The inputs are X and Y, and the output is Z. \n",
      "Student : Okay, that makes sense. So how do we turn that into an implementation?\n",
      "Teacher : For each state, we need to create a next-state function and an output function . The next-state function defines what state the FSM will be in based on its current state and input values. The output function defines what value will be outputted based on the current state . \n",
      "Student : Can you show me how that works for one of the states? \n",
      "Teacher : Sure. Let's take a look at State 2 for example . The next-state function for State 2 is defined as follows: If X=0 and Y=0 , then stay in State 2 . If X=0 and Y=1 , then go to State 3 . If X=1 , then go to State 1 . So based on the input values , the FSM will either stay in State 2 or transition to either State 1 or State 3 . \n",
      "The output function for State 2 is defined as follows: If X=0 , then output 0 . Otherwise , output 1 . So regardless of whether Y is 0 or 1 , if X is 0 , then Z will be 0 . Otherwise , if X is 1 , then Z will be 1 .\"\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "for section in sections_list[0:1]:\n",
    "    prompt = '''Generate a scientific, academic and formal conversation between a student and a teaching assistant. \n",
    "    The curious student initiates the conversation using a direct-approach, outlines the overall agenda of the conversation. \n",
    "    Thereafter, the teaching assistant expands on the topic with proper feedback and mutual understanding. \n",
    "    The student asks at least 4 innovative follow up questions, and after accepting the feedback, transitions to the conclusion of the conversation. \n",
    "    The format of the conversation is : Student : \\n Teacher: \\n Student : \\n Teacher : \\n Student : \\n Teacher: \\n Student : \\n Teacher : \\n  Student : \\n Teacher : \\n  Student : \\n \n",
    "\n",
    "The conversation is based on this below context :\\n  %s''' % section\n",
    "    \n",
    "    response = response_API(prompt)\n",
    "    print(response)\n",
    "    conversations.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Student : Hi, I'm a little confused about how to design a finite state machine when the number of states isn't a power of two. Can you help me understand that concept?\n",
      "Teacher : Sure! So when you're designing an FSM, you always want to start with your state transition diagram. That will show you all the possible states your machine can be in, and all the inputs and outputs for each state.\n",
      "Student : Okay, that makes sense.\n",
      "Teacher : Once you have your state transition diagram, you can start figuring out your next-state logic functions. For each state, you need to determine what the next state will be based on the current inputs. \n",
      "Student : That sounds like a lot of work...\n",
      "Teacher : It can be, but it's worth it to get a clear understanding of your design. After you have your next-state logic functions figured out, you can start implementing them with flip-flops and logic gates. \n",
      "Student : Okay, I think I understand. Thanks for explaining it!\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "for section in sections_list[0:1]:\n",
    "    prompt = '''Generate an informal, free-flowing, cool conversation between a student and a teaching assistant. \n",
    "    The student is unsure about a specific sub topic and approaches the teaching assistant with in-depth analytical questions. \n",
    "    The teaching assistant uses a procedural talking style and highlights the key ideas behind each concept. \n",
    "    Using relevant terms and an energetic tone, the teaching assistant reaches the conclusion in a way that the student doubts are clarified. \n",
    "    The student asks follow up questions if their doubts are still not clear. \n",
    "    The format of the conversation is : Student : \\n Teacher: \\n Student : \\n Teacher : \\n Student : \\n Teacher: \\n Student : \\n Teacher : \\n  Student : \\n Teacher : \\n  Student : \\n \n",
    "\n",
    "The conversation is based on this below context :\\n   %s''' % section\n",
    "    \n",
    "    response = response_API(prompt)\n",
    "    print(response)\n",
    "    conversations.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting data \n",
    "all_data = []\n",
    "for i, passage in enumerate(sections_list):\n",
    "    data = {}\n",
    "    data['textbook-paragraph'] = passage\n",
    "    data['GPT-3_conversations'] = conversations[i]\n",
    "    #data['GPT-3_conversations']['conversations'] = conversations[i]\n",
    "    all_data.append(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GPT-3_conversations.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_data, f, ensure_ascii=False, indent=4) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75437bf4ff09ccf37c1a7b89ec6af0194e10f783ac143972fe56d1183a93e4f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
