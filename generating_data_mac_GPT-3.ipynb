{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9ad31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60e57d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5913d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "41b8d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "directory = 'notes'\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if not os.path.isfile(f):\n",
    "        for fn in os.listdir(f):\n",
    "            notes.append(f+'/'+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b575462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['notes/part3/ece120-set-3-2-fsm-examples-part-i.tex',\n",
       " 'notes/part3/ece120-set-3-6-memory.tex',\n",
       " 'notes/part3/ece120-set-3-3-lab.tex',\n",
       " 'notes/part3/ece120-set-3-5-fsm-examples-part-ii.tex',\n",
       " 'notes/part3/ece120-set-3-7-fsm-to-computer.tex',\n",
       " 'notes/part3/ece120-set-3-4-keyless-extension.tex',\n",
       " 'notes/part3/ece120-set-3-1-serialize.tex',\n",
       " 'notes/part3/ece120-set-3-8-summary.tex',\n",
       " 'notes/part4/ece120-set-4-3-isa-design.tex',\n",
       " 'notes/part4/ece120-set-4-1-control-unit.tex',\n",
       " 'notes/part4/ece120-set-4-2-coding.tex',\n",
       " 'notes/part4/ece120-set-4-4-summary.tex',\n",
       " 'notes/part2/ece120-set-2-3-adder.tex',\n",
       " 'notes/part2/ece120-set-2-8-summary.tex',\n",
       " 'notes/part2/ece120-set-2-7-registers.tex',\n",
       " 'notes/part2/ece120-set-2-2-dontcare.tex',\n",
       " 'notes/part2/ece120-set-2-1-goodforms.tex',\n",
       " 'notes/part2/ece120-set-2-6-sequential.tex',\n",
       " 'notes/part2/ece120-set-2-5-abstraction.tex',\n",
       " 'notes/part2/ece120-set-2-4-comparator.tex',\n",
       " 'notes/part1/ece120-set-1-4-logic.tex',\n",
       " 'notes/part1/ece120-set-1-2-twos-complement.tex',\n",
       " 'notes/part1/ece120-set-1-1-halting-problem.tex',\n",
       " 'notes/part1/ece120-set-1-5-programming.tex',\n",
       " 'notes/part1/ece120-set-1-6-summary.tex',\n",
       " 'notes/part1/ece120-set-1-3-overflow.tex']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "711b3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean \n",
    "def clean(file):\n",
    "    with open(file) as input_file:\n",
    "        text = \"\"\n",
    "        for line in input_file:\n",
    "            text += line\n",
    "    texts = text.split('subsection')\n",
    "    cleaned = []\n",
    "    for text in texts[1:]:\n",
    "        text = re.sub(r\"\\\\[a-z]*\", '', text)\n",
    "        text = re.sub(r\"{+[a-zA-Z0-9=\\/\\.\\,:]+}+\", '', text)\n",
    "        text = re.sub(r\"\\$\", '', text)\n",
    "        text = re.sub(r\"~\", ' ', text)\n",
    "        text = re.sub(r\"%\", '', text)\n",
    "        cleaned.append(text)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2f5d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(cleaned_list):\n",
    "    questions = []\n",
    "    for text in cleaned_list:\n",
    "        prompt = \"Context: %s\\nGenerate 3 questions about this text:\\n\" % text\n",
    "        response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        q = response['choices'][0]['text']\n",
    "        questions.append(q)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "598eedbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(cleaned_list, questions):\n",
    "    answers = []\n",
    "    for i, text in enumerate(cleaned_list):\n",
    "        prompt = \"Context: %s\\nGenerate 3 answers to these questions about this text:\\n%s\" % (text, questions[i])\n",
    "        response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        answers.append(response['choices'][0]['text'])\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "19baec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section(file):\n",
    "    with open(file) as input_file:\n",
    "        text = \"\"\n",
    "        for line in input_file:\n",
    "            text += line\n",
    "    texts = text.split('subsection')\n",
    "    sections = []\n",
    "    for text in texts[1:]:\n",
    "        section = re.match(r\"{.*}\", text)\n",
    "        sections.append(section[0].replace('{', '').replace('}', ''))\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3fb5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(file):\n",
    "    cleaned = clean(file)\n",
    "    sections = get_section(file)\n",
    "    questions = get_questions(cleaned)\n",
    "    answers = get_answers(cleaned, questions)\n",
    "    return questions, answers, sections, cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e5502a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = []\n",
    "# for note in notes:\n",
    "      \n",
    "#     sections = get_section(note)\n",
    "#     cleaned = clean(note)\n",
    "\n",
    "#     # Generating Questions\n",
    "#     questions = []\n",
    "#     for text in cleaned:\n",
    "#         prompt = \"[%s]\\nGenerate a question about this text:\\n\" % text\n",
    "#         response = openai.Completion.create(\n",
    "#         model=\"text-davinci-002\",\n",
    "#         prompt=prompt,\n",
    "#         temperature=0.7,\n",
    "#         max_tokens=256,\n",
    "#         top_p=1,\n",
    "#         frequency_penalty=0,\n",
    "#         presence_penalty=0\n",
    "#         )\n",
    "#         questions.append(response['choices'][0]['text'])\n",
    "    \n",
    "#     # Formatting questions\n",
    "#     clean_questions = []\n",
    "#     for question in questions:\n",
    "#         split = question.split('\\n')\n",
    "#         string = ''\n",
    "#         for qs in split[1:]:\n",
    "#             sent = '\\nQ. ' + qs\n",
    "#             string += sent\n",
    "#         clean_questions.append(string)\n",
    "    \n",
    "#     # Generating Answers\n",
    "#     answers = []\n",
    "#     for i, text in enumerate(cleaned):\n",
    "#         prompt = \"[%s]\\nPlease answer the question according to the above context:\\n%s\" % (text, clean_questions[i])\n",
    "#         response = openai.Completion.create(\n",
    "#         model=\"text-davinci-002\",\n",
    "#         prompt=prompt,\n",
    "#         temperature=0.7,\n",
    "#         max_tokens=256,\n",
    "#         top_p=1,\n",
    "#         frequency_penalty=0,\n",
    "#         presence_penalty=0\n",
    "#         )\n",
    "#         answers.append(response['choices'][0]['text'])\n",
    "\n",
    "#     n = len(sections)\n",
    "#     for i in range(n):  \n",
    "#         data = {}\n",
    "#         data['positive_ctxs'] = {}\n",
    "#         data['questions'] = clean_questions[i]\n",
    "#         data['answers'] = answers[i]\n",
    "#         data['positive_ctxs']['title'] = sections[i]\n",
    "#         data['positive_ctxs']['text'] = cleaned[i]\n",
    "#         all_data.append(data)\n",
    "#     time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e00e15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('GPT-3.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(all_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "911f0d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('GPT-3.json')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f07895e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "for row in data:\n",
    "    if row['answers'] == '':\n",
    "        counter+=1\n",
    "questions = len(data)\n",
    "answers = questions - counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8213a131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 144 questions, there were 137 answers\n"
     ]
    }
   ],
   "source": [
    "print(\"Out of\", questions, 'questions, there were', answers, 'answers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ceb9bed3d30ec29b846b63fb1c460e88a52d9e7a358740ef37444bae539c2a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
