{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ad31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60e57d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5913d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b8d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "directory = 'notes'\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if not os.path.isfile(f):\n",
    "        for fn in os.listdir(f):\n",
    "            notes.append(f+'/'+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b575462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['notes/part3/ece120-set-3-2-fsm-examples-part-i.tex',\n",
       " 'notes/part3/ece120-set-3-6-memory.tex',\n",
       " 'notes/part3/ece120-set-3-3-lab.tex',\n",
       " 'notes/part3/ece120-set-3-5-fsm-examples-part-ii.tex',\n",
       " 'notes/part3/ece120-set-3-7-fsm-to-computer.tex',\n",
       " 'notes/part3/ece120-set-3-4-keyless-extension.tex',\n",
       " 'notes/part3/ece120-set-3-1-serialize.tex',\n",
       " 'notes/part3/ece120-set-3-8-summary.tex',\n",
       " 'notes/part4/ece120-set-4-3-isa-design.tex',\n",
       " 'notes/part4/ece120-set-4-1-control-unit.tex',\n",
       " 'notes/part4/ece120-set-4-2-coding.tex',\n",
       " 'notes/part4/ece120-set-4-4-summary.tex',\n",
       " 'notes/part2/ece120-set-2-3-adder.tex',\n",
       " 'notes/part2/ece120-set-2-8-summary.tex',\n",
       " 'notes/part2/ece120-set-2-7-registers.tex',\n",
       " 'notes/part2/ece120-set-2-2-dontcare.tex',\n",
       " 'notes/part2/ece120-set-2-1-goodforms.tex',\n",
       " 'notes/part2/ece120-set-2-6-sequential.tex',\n",
       " 'notes/part2/ece120-set-2-5-abstraction.tex',\n",
       " 'notes/part2/ece120-set-2-4-comparator.tex',\n",
       " 'notes/part1/ece120-set-1-4-logic.tex',\n",
       " 'notes/part1/ece120-set-1-2-twos-complement.tex',\n",
       " 'notes/part1/ece120-set-1-1-halting-problem.tex',\n",
       " 'notes/part1/ece120-set-1-5-programming.tex',\n",
       " 'notes/part1/ece120-set-1-6-summary.tex',\n",
       " 'notes/part1/ece120-set-1-3-overflow.tex']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711b3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean \n",
    "def clean(file):\n",
    "    with open(file) as input_file:\n",
    "        text = \"\"\n",
    "        for line in input_file:\n",
    "            text += line\n",
    "    texts = text.split('subsection')\n",
    "    cleaned = []\n",
    "    for text in texts[1:]:\n",
    "        text = re.sub(r\"\\\\[a-z]*\", '', text)\n",
    "        text = re.sub(r\"{+[a-zA-Z0-9=\\/\\.\\,:]+}+\", '', text)\n",
    "        text = re.sub(r\"\\$\", '', text)\n",
    "        text = re.sub(r\"~\", ' ', text)\n",
    "        text = re.sub(r\"%\", '', text)\n",
    "        cleaned.append(text)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2f5d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(cleaned_list):\n",
    "    questions = []\n",
    "    for text in cleaned_list:\n",
    "        prompt = \"Context: %s\\nGenerate 3 questions about this text:\\n\" % text\n",
    "        response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        q = response['choices'][0]['text']\n",
    "        questions.append(q)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598eedbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(cleaned_list, questions):\n",
    "    answers = []\n",
    "    for i, text in enumerate(cleaned_list):\n",
    "        prompt = \"Context: %s\\nGenerate 3 answers to these questions about this text:\\n%s\" % (text, questions[i])\n",
    "        response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        answers.append(response['choices'][0]['text'])\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19baec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section(file):\n",
    "    with open(file) as input_file:\n",
    "        text = \"\"\n",
    "        for line in input_file:\n",
    "            text += line\n",
    "    texts = text.split('subsection')\n",
    "    sections = []\n",
    "    for text in texts[1:]:\n",
    "        section = re.match(r\"{.*}\", text)\n",
    "        sections.append(section[0].replace('{', '').replace('}', ''))\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fb5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(file):\n",
    "    cleaned = clean(file)\n",
    "    sections = get_section(file)\n",
    "    questions = get_questions(cleaned)\n",
    "    answers = get_answers(cleaned, questions)\n",
    "    return questions, answers, sections, cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4949e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, a, s, c = retrieve_data(notes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd7b60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12 12 12\n"
     ]
    }
   ],
   "source": [
    "print(len(q), len(a), len(s), len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a41c8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# all_data = []\n",
    "# for note in notes:\n",
    "    # questions, answers, sections, cleaned = retrieve_data(note)\n",
    "#     n = len(sections)\n",
    "#     data = {}\n",
    "#     data['positive_ctxs'] = {}\n",
    "#     for i in range(n):  \n",
    "#         data['questions'] = questions[i]\n",
    "#         data['answers'] = answers[i]\n",
    "#         data['positive_ctxs']['title'] = sections[i]\n",
    "#         data['positive_ctxs']['text'] = cleaned[i]\n",
    "#         all_data.append(data)\n",
    "#         time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7509092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data2 = []\n",
    "# for note in notes:\n",
    "      \n",
    "#     sections = get_section(note)\n",
    "#     cleaned = clean(note)\n",
    "\n",
    "#     # Generating Questions\n",
    "#     questions = []\n",
    "#     for text in cleaned:\n",
    "#         prompt = \"Context: %s\\nGenerate 3 questions about this text:\\n\" % text\n",
    "#         response = openai.Completion.create(\n",
    "#         model=\"text-davinci-002\",\n",
    "#         prompt=prompt,\n",
    "#         temperature=0.7,\n",
    "#         max_tokens=256,\n",
    "#         top_p=1,\n",
    "#         frequency_penalty=0,\n",
    "#         presence_penalty=0\n",
    "#         )\n",
    "#         questions.append(response['choices'][0]['text'])\n",
    "\n",
    "#     # Generating Answers\n",
    "#     answers = []\n",
    "#     for i, text in enumerate(cleaned):\n",
    "#         prompt = \"Context: %s\\nGenerate 3 answers to these questions about this text:\\n%s\" % (text, questions[i])\n",
    "#         response = openai.Completion.create(\n",
    "#         model=\"text-davinci-002\",\n",
    "#         prompt=prompt,\n",
    "#         temperature=0.7,\n",
    "#         max_tokens=256,\n",
    "#         top_p=1,\n",
    "#         frequency_penalty=0,\n",
    "#         presence_penalty=0\n",
    "#         )\n",
    "#         answers.append(response['choices'][0]['text'])\n",
    "\n",
    "#     n = len(sections)\n",
    "#     data = {}\n",
    "#     data['positive_ctxs'] = {}\n",
    "#     for i in range(n):  \n",
    "#         data['questions'] = questions[i]\n",
    "#         data['answers'] = answers[i]\n",
    "#         data['positive_ctxs']['title'] = sections[i]\n",
    "#         data['positive_ctxs']['text'] = cleaned[i]\n",
    "#         all_data.append(data)\n",
    "#     time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d033a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('GPT-3.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(all_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2117dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('GPT-3second.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(all_data2, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db3fc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('GPT-3.json')\n",
    "first_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "755c28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('GPT-3second.json')\n",
    "second_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d009cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "for row in first_data:\n",
    "    if row['answers'] == '':\n",
    "        counter+=1\n",
    "questions = len(second_data)\n",
    "answers = questions - counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16abc367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 144 questions, there were 40 answers\n"
     ]
    }
   ],
   "source": [
    "# Most answers were not printed for the first one\n",
    "print(\"Out of\", questions, 'questions, there were', answers, 'answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac83dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "for row in second_data:\n",
    "    if row['answers'] == '':\n",
    "        counter+=1\n",
    "questions = len(second_data)\n",
    "answers = questions - counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24a35695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 144 questions, there were 34 answers\n"
     ]
    }
   ],
   "source": [
    "# Most answers were not printed for the second one\n",
    "print(\"Out of\", questions, 'questions, there were', answers, 'answers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "28596858067060ee176f7bab50a17c769bfd8a96306468e7ae0695529617abaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
