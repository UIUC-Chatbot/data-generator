{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the notes from the files\n",
    "notes = []\n",
    "directory = 'notes'\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if not os.path.isfile(f):\n",
    "        for fn in os.listdir(f):\n",
    "            notes.append(f+'\\\\'+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean \n",
    "def clean(file):\n",
    "    with open(file) as input_file:\n",
    "        text = \"\"\n",
    "        for line in input_file:\n",
    "            text += line\n",
    "    texts = text.split('subsection')\n",
    "    cleaned = []\n",
    "    for text in texts[1:]:\n",
    "        text = re.sub(r\"\\\\[a-z]*\", '', text)\n",
    "        text = re.sub(r\"{+[a-zA-Z0-9=\\/\\.\\,:]+}+\", '', text)\n",
    "        text = re.sub(r\"\\$\", '', text)\n",
    "        text = re.sub(r\"~\", ' ', text)\n",
    "        text = re.sub(r\"%\", '', text)\n",
    "        cleaned.append(text)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(cleaned_list):\n",
    "    questions = []\n",
    "    for text in cleaned_list:\n",
    "        prompt = \"Context: %s\\nGenerate 3 questions about this text:\\n\" % text\n",
    "        response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        q = response['choices'][0]['text']\n",
    "        questions.append(q)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(cleaned_list, questions):\n",
    "    answers = []\n",
    "    for i, text in enumerate(cleaned_list):\n",
    "        prompt = \"Context: %s\\nGenerate 3 answers to these questions about this text:\\n%s\" % (text, questions[i])\n",
    "        response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        answers.append(response['choices'][0]['text'])\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section(file):\n",
    "    with open(file) as input_file:\n",
    "        text = \"\"\n",
    "        for line in input_file:\n",
    "            text += line\n",
    "\n",
    "    texts = text.split('subsection')\n",
    "    subsections = []\n",
    "\n",
    "    for section in texts[1:]:\n",
    "        subsection = re.match(r'{.*}', section)\n",
    "        if subsection == None:\n",
    "            subsections.append(None)\n",
    "        else:\n",
    "            subsections.append(subsection[0].replace('{', '').replace('}', ''))\n",
    "    return subsections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(file):\n",
    "    cleaned = clean(file)\n",
    "    questions = get_questions(cleaned)\n",
    "    answers= get_answers(cleaned, questions)\n",
    "    section = get_section(cleaned)\n",
    "    return questions, answers, section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (['\\n1. What is the halting problem?\\n2. What is a universal computational device?\\n3. What is an undecidable problem?',\n",
    "  '\\n1. What is a Turing machine?\\n2. What is the Church-Turing conjecture?\\n3. What would it mean to disprove the Church-Turing conjecture?',\n",
    "  \"\\n1. What is the halting problem?\\n2. What is the Liar's paradox?\\n3. What does it mean if a Turing machine is 'deterministic'?\"],\n",
    " ['',\n",
    "  '\\n\\n1. A Turing machine is a machine that can be used to solve any problem that can be solved by any other machine.\\n2. The Church-Turing conjecture is the conjecture that a problem that cannot be solved by a Turing machine cannot be solved in any systematic manner, with any machine, or by any person.\\n3. To disprove the Church-Turing conjecture, one would need to demonstrate a systematic technique (or a machine) capable of solving a problem that cannot be solved by a Turing machine.',\n",
    "  '\\n\\n1. The halting problem is whether a Turing machine will finish in a finite number of steps.\\n2. The Liar\\'s paradox is the sentence \"This sentence is not true.\"\\n3. A Turing machine is deterministic if it always produces the same result for a given input.'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
