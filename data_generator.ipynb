{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import openai\n",
    "import os\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the notes from the files\n",
    "notes = []\n",
    "directory = 'notes'\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if not os.path.isfile(f):\n",
    "        for fn in os.listdir(f):\n",
    "            notes.append(f+'\\\\'+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean \n",
    "def clean(file):\n",
    "    with open(file) as input_file:\n",
    "        text = \"\"\n",
    "        for line in input_file:\n",
    "            text += line\n",
    "    texts = text.split('subsection')\n",
    "    cleaned = []\n",
    "    for text in texts[1:]:\n",
    "        text = re.sub(r\"\\\\[a-z]*\", '', text)\n",
    "        text = re.sub(r\"{+[a-zA-Z0-9=\\/\\.\\,:]+}+\", '', text)\n",
    "        text = re.sub(r\"\\$\", '', text)\n",
    "        text = re.sub(r\"~\", ' ', text)\n",
    "        text = re.sub(r\"%\", '', text)\n",
    "        text = re.sub(r\"{+file[\\{a-zA-Z\\|\\=\\/\\.\\,\\-\\0-9\\&\\_]*}+\", '', text)\n",
    "        cleaned.append(text)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(cleaned_list):\n",
    "    questions = []\n",
    "    for text in cleaned_list:\n",
    "        prompt = \"Context: %s\\nGenerate 3 questions about this text:\\n\" % text\n",
    "        response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        q = response['choices'][0]['text']\n",
    "        questions.append(q)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(cleaned_list, questions):\n",
    "    answers = []\n",
    "    for i, text in enumerate(cleaned_list):\n",
    "        prompt = \"Context: %s\\nGenerate 3 answers to these questions about this text:\\n%s\" % (text, questions[i])\n",
    "        response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        answers.append(response['choices'][0]['text'])\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section(file):\n",
    "    with open(file) as input_file:\n",
    "        text = \"\"\n",
    "        for line in input_file:\n",
    "            text += line\n",
    "\n",
    "    texts = text.split('subsection')\n",
    "    subsections = []\n",
    "\n",
    "    for section in texts[1:]:\n",
    "        subsection = re.match(r'{.*}', section)\n",
    "        if subsection == None:\n",
    "            subsections.append(None)\n",
    "        else:\n",
    "            subsections.append(subsection[0].replace('{', '').replace('}', ''))\n",
    "    return subsections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(file):\n",
    "    cleaned = clean(file)\n",
    "    questions = get_questions(cleaned)\n",
    "    answers= get_answers(cleaned, questions)\n",
    "    section = get_section(cleaned)\n",
    "    return questions, answers, section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_paragraphs(cleaned_file):\n",
    "    paragraphs = []\n",
    "\n",
    "    for file in cleaned_file:\n",
    "        split_files = file.split('\\n\\n')\n",
    "        section = []\n",
    "        for split in split_files[1:]:\n",
    "            length = len(split.split())\n",
    "            if split == '' or length < 5:\n",
    "                pass\n",
    "            else:\n",
    "                section.append(split)\n",
    "        paragraphs.append(section)\n",
    "            \n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in notes:\n",
    "      \n",
    "    sections = get_section(note)\n",
    "    cleaned = clean(note)\n",
    "    paragraphs = split_paragraphs(cleaned)\n",
    "    sentences = []\n",
    "    # Extra Cleaning\n",
    "    for sent in paragraphs:\n",
    "        for s in sent:\n",
    "            s = re.sub(r\"{[\\{\\}a-z\\|]+}\", '', s)\n",
    "            if s.startswith('{eqnarray*}') or s.endswith('{eqnarray*}') :\n",
    "                pass\n",
    "            elif s.startswith('{cc'):\n",
    "                pass\n",
    "            else: \n",
    "                sentences.append(s)\n",
    "    # Generating Questions\n",
    "    questions = []\n",
    "    for text in sentences:\n",
    "        prompt = \"[%s]\\nGenerate a question about this text:\\n\" % text\n",
    "        response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        questions.append(response['choices'][0]['text'])\n",
    "        time.sleep(3)\n",
    "    \n",
    "    # Formatting questions\n",
    "    clean_questions = []\n",
    "    for question in questions:\n",
    "        split = question.split('\\n')\n",
    "        string = ''\n",
    "        for qs in split[1:]:\n",
    "            sent = '\\nQ. ' + qs\n",
    "            string += sent\n",
    "        clean_questions.append(string)\n",
    "    \n",
    "    # Generating Answers\n",
    "    answers = []\n",
    "    for i, text in enumerate(sentences):\n",
    "        prompt = \"[%s]\\nPlease answer the question according to the above context:\\n%s\" % (text, clean_questions[i])\n",
    "        response = openai.Completion.create(\n",
    "        model=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        answers.append(response['choices'][0]['text'])\n",
    "        time.sleep(3)\n",
    "\n",
    "    n = len(sections)\n",
    "    for j in range(n):  \n",
    "        for i, par in enumerate(paragraphs[j]):\n",
    "            data = {}\n",
    "            data['positive_ctxs'] = {}\n",
    "            data['questions'] = clean_questions[i]\n",
    "            data['answers'] = answers[i]\n",
    "            data['positive_ctxs']['title'] = sections[j] + \" P\" + str(i)\n",
    "            data['positive_ctxs']['text'] = par\n",
    "            all_data.append(data)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1822 questions, there were 1336 answers\n"
     ]
    }
   ],
   "source": [
    "counter = 0 \n",
    "for row in all_data:\n",
    "    if row['answers'] == '':\n",
    "        counter+=1\n",
    "qs = len(all_data)\n",
    "anws = qs - counter\n",
    "print(\"Out of\", qs, 'questions, there were', anws, 'answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GPT-3_paragraphs.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_data, f, ensure_ascii=False, indent=4) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
