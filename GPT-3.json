[
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Impact of the State Representation",
            "text": "{Impact of the State Representation}\n\nWhat happens if we choose a bad representation?  For the same FSM---the\ntwo-bit Gray code counter with start and stop inputs---the \ntable below shows a poorly chosen mapping from states to internal \nstate representation.\n\nBelow the table is a diagram of an implementation using that\nrepresentation.\n\nVerifying that the implementation's behavior\nis correct is left as an exercise for the determined reader.\n\n{\n{|c|c|c|c|c|}{1-2}{4-5}\nstate& S_2S_1S_0& & state& S_2S_1S_0  {1-2}{4-5}\n{ COUNT A}& 000& & { HALT A}& 111 \n{ COUNT B}& 101& & { HALT B}& 110 \n{ COUNT C}& 011& & { HALT C}& 100 \n{ COUNT D}& 010& & { HALT D}& 001  {1-2}{4-5}\n\n}\n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the impact of choosing a bad state representation?\n2. What is an example of a bad state representation?\n3. How can you verify that an implementation using a bad state representation is correct?",
        "answers": "\n\n1. The impact of choosing a bad state representation is that the implementation may not work correctly.\n2. An example of a bad state representation is one that does not match the states of the FSM.\n3. One way to verify that an implementation using a bad state representation is correct is to test it against all possible inputs."
    },
    {
        "positive_ctxs": {
            "title": "Dynamic Random Access Memory*",
            "text": "{Dynamic Random Access Memory*}\n\nDynamic random access memory, or DRAM, is used for main memory in\ncomputers and for other applications in which size is more important\nthan speed.  While slower than SRAM, DRAM is denser (has\nmore bits per chip area).  A substantial part of DRAM density is\ndue to transistor count: typical SRAM cells use six transistors\n(two for each inverter, and two more to connect the inverters to the \nbit lines), while DRAM cells use only a single transistor.\nHowever, memory designers have also made significant advances in\nfurther miniaturizing DRAM cells to improve density beyond the \nbenefit available from simple transistor count.\n\n\nA diagram of a DRAM cell appears to the right.  \nDRAM storage is capacitive: a bit is stored by charging or not charging \na capacitor.  The capacitor is attached to a BIT line \nthrough a transistor controlled by a SELECT line.  \n\nWhen SELECT is low, the capacitor is isolated and \nholds its charge.  However, the transistor's resistance is\nfinite, and some charge leaks out onto the bit line.  Charge also\nleaks into the substrate on which the transistor is constructed.  After\nsome amount of time, all of the charge dissipates, and the bit is\nlost.  To avoid such loss, the cell must be { refreshed}\nperiodically by reading the contents and writing them back with active\nlogic.\n\n\n{file=part3/figs/lec18-8.eps,width=1.1in}\n\n\nWhen the SELECT line is high during a write operation, logic driving\nthe bit line forces charge onto the capacitor or removes all charge\nfrom it.  For a read operation, the bit line is first brought to an\nintermediate voltage level (a voltage level between 0 and 1), then\nSELECT is raised, allowing the capacitor to either pull a small\namount of charge from the bit line or to push a small amount of charge\nonto the bit line.  The resulting change in voltage is then detected\nby a { sense amplifier} at the end of the bit line.  A sense amp \nis analogous to a marble on a mountaintop: a small push causes the\nmarble to roll rapidly downhill in the direction of the push.\nSimilarly, a small change in voltage causes a sense amp's output to\nmove rapidly to a logical 0 or 1, depending on the direction of the\nsmall change.  As mentioned earlier, sense amplifiers also appear in \nSRAM implementations.\nWhile not technically necessary, as they are with DRAM, the use of a\nsense amp to react to small changes in voltage makes reads faster.\n\nEach read operation on a DRAM cell brings the voltage on its capacitor\ncloser to the intermediate voltage level, in effect destroying the\ndata in the cell.  DRAM is thus said to have { destructive reads}.\nTo preserve data during a read, the bits must be written back\ninto the cells after a read.  For example, the output of the sense \namplifiers can\nbe used to drive the bit lines, rewriting the cells with the\nappropriate data.\n\nAt the chip level, typical DRAM inputs and outputs differ from those\nof SRAM.  \n\nDue to the large size and high density of DRAM,\naddresses are split into row and column components and provided\nthrough a common set of pins.  The DRAM stores the components in\nregisters to support this approach.  Additional inputs, known as the\n{ row} and { column address} {{ strobes}---RAS} and\nCAS, {respectively---are} used to indicate when address\ncomponents are available.  As\nyou might guess from the structure of coincident selection, DRAM\nrefresh occurs on a row-by-row basis (across bit slices---on columns\nrather than rows in the figures earlier in these notes, but the terminology\nof DRAM is a row).  Raising the SELECT line for a\nrow destructively reads the contents of all cells on that row, forcing\nthe cells to be rewritten and effecting a refresh.  The row is thus a\nnatural basis for the refresh cycle.  The DRAM data pins provide\nbidirectional signals for reading and writing elements of the DRAM.\nAn { output enable} input, OE, controls tri-state buffers with\nthe DRAM to determine whether or not the DRAM drives the data pins.\nThe WE input, which controls the type of operation, is\nalso present.\n\n\nTiming diagrams for writes and reads on a historical DRAM implementation\nappear to the right.  In both cases, the row component of the address is \nfirst applied to the address pins, then RAS is raised.  In the\nnext cycle of the controlling logic, the column component is applied\nto the address pins, and CAS is raised.  \n\nFor a write, as shown on the left, the WE signal and the\ndata can\n\n\n{file=part3/figs/lec18-9.eps,width=4in}\n\n\nalso be applied in the second cycle.  The DRAM has internal\ntiming and control logic that prevent races from overwriting an\nincorrect element (remember that the row and column addresses have to\nbe stored in registers).  The DRAM again specifies a write cycle,\nafter which the operation is guaranteed to be complete.  In order, the\nWE, CAS, and RAS signals are then lowered.  \n\nFor a read operation, the output enable signal, OE, is raised after\nCAS is raised.  The DATA pins, which should be floating (in other\nwords, not driven by any logic), are then driven by the DRAM.  After the \nread cycle, valid data appear on the DATA pins, and OE, CAS, and\nRAS are lowered in order after the data are read.\n\nModern DRAM chips are substantially more sophisticated than those\ndiscussed here, and many of the functions that used to be provided\nby external logic are now integrated onto the chips themselves.\n\nAs an example of modern DRAMs, one can obtain\nthe data sheet for Micron Semiconductor's 8Gb ({2^b},\nfor example) DDR4 SDRAM, which is 366 pages long as of 11 May 2016.\n\nThe ability to synchronize to an external clock has become prevalent in \nthe industry, leading to the somewhat confusing term SDRAM, which stands \nfor { synchronous DRAM}.  The memory structures themselves\nare still unclocked, but logic is provided on the chip to synchronize \naccesses to the external clock without the need for additional \nlogic.\n\nThe clock provided to the Micron chip just mentioned\ncan be as fast as 1.6 GHz, and data can be\ntransferred on both the rising and falling edges of the clock\n(hence the name DDR, or { double data rate}).  \n\nIn addition to row and\ncolumn components of the address, these chips further separate cells into\n{ banks} and groups of banks.  These allow a user to exploit parallelism\nby starting reads or writes to separate banks at the same time, thus\nimproving the speed at which data can move in and out of the memory.\n\nFor the {2^b} version of the Micron chip,\nthe cells are structured into 4 groups of 4 banks (16 banks total),\neach with 131,072 rows and 1,024 columns.  \n\nDRAM implementations provide interfaces for specifying\nrefresh operations in addition to reads and writes.\nManaging refresh timing and execution is\ngenerally left to an external DRAM controller.\n\nFor the Micron chip, refresh commands must be issued every \n7.8 microseconds at normal temperatures.  Each\ncommand refreshes about 2^ cells, so 8,192 commands refresh\nthe whole chip in less than 64 milliseconds.\n\nAlternatively, the chip can handle refresh on-chip in\norder to maintain memory contents when the rest of the system is \npowered down.\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of DRAM over SRAM?\n2. What is the main disadvantage of DRAM?\n3. What is the difference between SDRAM and DDR SDRAM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Dynamic Random Access Memory*",
            "text": "{Dynamic Random Access Memory*}\n\nDynamic random access memory, or DRAM, is used for main memory in\ncomputers and for other applications in which size is more important\nthan speed.  While slower than SRAM, DRAM is denser (has\nmore bits per chip area).  A substantial part of DRAM density is\ndue to transistor count: typical SRAM cells use six transistors\n(two for each inverter, and two more to connect the inverters to the \nbit lines), while DRAM cells use only a single transistor.\nHowever, memory designers have also made significant advances in\nfurther miniaturizing DRAM cells to improve density beyond the \nbenefit available from simple transistor count.\n\n\nA diagram of a DRAM cell appears to the right.  \nDRAM storage is capacitive: a bit is stored by charging or not charging \na capacitor.  The capacitor is attached to a BIT line \nthrough a transistor controlled by a SELECT line.  \n\nWhen SELECT is low, the capacitor is isolated and \nholds its charge.  However, the transistor's resistance is\nfinite, and some charge leaks out onto the bit line.  Charge also\nleaks into the substrate on which the transistor is constructed.  After\nsome amount of time, all of the charge dissipates, and the bit is\nlost.  To avoid such loss, the cell must be { refreshed}\nperiodically by reading the contents and writing them back with active\nlogic.\n\n\n{file=part3/figs/lec18-8.eps,width=1.1in}\n\n\nWhen the SELECT line is high during a write operation, logic driving\nthe bit line forces charge onto the capacitor or removes all charge\nfrom it.  For a read operation, the bit line is first brought to an\nintermediate voltage level (a voltage level between 0 and 1), then\nSELECT is raised, allowing the capacitor to either pull a small\namount of charge from the bit line or to push a small amount of charge\nonto the bit line.  The resulting change in voltage is then detected\nby a { sense amplifier} at the end of the bit line.  A sense amp \nis analogous to a marble on a mountaintop: a small push causes the\nmarble to roll rapidly downhill in the direction of the push.\nSimilarly, a small change in voltage causes a sense amp's output to\nmove rapidly to a logical 0 or 1, depending on the direction of the\nsmall change.  As mentioned earlier, sense amplifiers also appear in \nSRAM implementations.\nWhile not technically necessary, as they are with DRAM, the use of a\nsense amp to react to small changes in voltage makes reads faster.\n\nEach read operation on a DRAM cell brings the voltage on its capacitor\ncloser to the intermediate voltage level, in effect destroying the\ndata in the cell.  DRAM is thus said to have { destructive reads}.\nTo preserve data during a read, the bits must be written back\ninto the cells after a read.  For example, the output of the sense \namplifiers can\nbe used to drive the bit lines, rewriting the cells with the\nappropriate data.\n\nAt the chip level, typical DRAM inputs and outputs differ from those\nof SRAM.  \n\nDue to the large size and high density of DRAM,\naddresses are split into row and column components and provided\nthrough a common set of pins.  The DRAM stores the components in\nregisters to support this approach.  Additional inputs, known as the\n{ row} and { column address} {{ strobes}---RAS} and\nCAS, {respectively---are} used to indicate when address\ncomponents are available.  As\nyou might guess from the structure of coincident selection, DRAM\nrefresh occurs on a row-by-row basis (across bit slices---on columns\nrather than rows in the figures earlier in these notes, but the terminology\nof DRAM is a row).  Raising the SELECT line for a\nrow destructively reads the contents of all cells on that row, forcing\nthe cells to be rewritten and effecting a refresh.  The row is thus a\nnatural basis for the refresh cycle.  The DRAM data pins provide\nbidirectional signals for reading and writing elements of the DRAM.\nAn { output enable} input, OE, controls tri-state buffers with\nthe DRAM to determine whether or not the DRAM drives the data pins.\nThe WE input, which controls the type of operation, is\nalso present.\n\n\nTiming diagrams for writes and reads on a historical DRAM implementation\nappear to the right.  In both cases, the row component of the address is \nfirst applied to the address pins, then RAS is raised.  In the\nnext cycle of the controlling logic, the column component is applied\nto the address pins, and CAS is raised.  \n\nFor a write, as shown on the left, the WE signal and the\ndata can\n\n\n{file=part3/figs/lec18-9.eps,width=4in}\n\n\nalso be applied in the second cycle.  The DRAM has internal\ntiming and control logic that prevent races from overwriting an\nincorrect element (remember that the row and column addresses have to\nbe stored in registers).  The DRAM again specifies a write cycle,\nafter which the operation is guaranteed to be complete.  In order, the\nWE, CAS, and RAS signals are then lowered.  \n\nFor a read operation, the output enable signal, OE, is raised after\nCAS is raised.  The DATA pins, which should be floating (in other\nwords, not driven by any logic), are then driven by the DRAM.  After the \nread cycle, valid data appear on the DATA pins, and OE, CAS, and\nRAS are lowered in order after the data are read.\n\nModern DRAM chips are substantially more sophisticated than those\ndiscussed here, and many of the functions that used to be provided\nby external logic are now integrated onto the chips themselves.\n\nAs an example of modern DRAMs, one can obtain\nthe data sheet for Micron Semiconductor's 8Gb ({2^b},\nfor example) DDR4 SDRAM, which is 366 pages long as of 11 May 2016.\n\nThe ability to synchronize to an external clock has become prevalent in \nthe industry, leading to the somewhat confusing term SDRAM, which stands \nfor { synchronous DRAM}.  The memory structures themselves\nare still unclocked, but logic is provided on the chip to synchronize \naccesses to the external clock without the need for additional \nlogic.\n\nThe clock provided to the Micron chip just mentioned\ncan be as fast as 1.6 GHz, and data can be\ntransferred on both the rising and falling edges of the clock\n(hence the name DDR, or { double data rate}).  \n\nIn addition to row and\ncolumn components of the address, these chips further separate cells into\n{ banks} and groups of banks.  These allow a user to exploit parallelism\nby starting reads or writes to separate banks at the same time, thus\nimproving the speed at which data can move in and out of the memory.\n\nFor the {2^b} version of the Micron chip,\nthe cells are structured into 4 groups of 4 banks (16 banks total),\neach with 131,072 rows and 1,024 columns.  \n\nDRAM implementations provide interfaces for specifying\nrefresh operations in addition to reads and writes.\nManaging refresh timing and execution is\ngenerally left to an external DRAM controller.\n\nFor the Micron chip, refresh commands must be issued every \n7.8 microseconds at normal temperatures.  Each\ncommand refreshes about 2^ cells, so 8,192 commands refresh\nthe whole chip in less than 64 milliseconds.\n\nAlternatively, the chip can handle refresh on-chip in\norder to maintain memory contents when the rest of the system is \npowered down.\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of DRAM over SRAM?\n2. What is the main disadvantage of DRAM?\n3. What is the difference between SDRAM and DDR SDRAM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Dynamic Random Access Memory*",
            "text": "{Dynamic Random Access Memory*}\n\nDynamic random access memory, or DRAM, is used for main memory in\ncomputers and for other applications in which size is more important\nthan speed.  While slower than SRAM, DRAM is denser (has\nmore bits per chip area).  A substantial part of DRAM density is\ndue to transistor count: typical SRAM cells use six transistors\n(two for each inverter, and two more to connect the inverters to the \nbit lines), while DRAM cells use only a single transistor.\nHowever, memory designers have also made significant advances in\nfurther miniaturizing DRAM cells to improve density beyond the \nbenefit available from simple transistor count.\n\n\nA diagram of a DRAM cell appears to the right.  \nDRAM storage is capacitive: a bit is stored by charging or not charging \na capacitor.  The capacitor is attached to a BIT line \nthrough a transistor controlled by a SELECT line.  \n\nWhen SELECT is low, the capacitor is isolated and \nholds its charge.  However, the transistor's resistance is\nfinite, and some charge leaks out onto the bit line.  Charge also\nleaks into the substrate on which the transistor is constructed.  After\nsome amount of time, all of the charge dissipates, and the bit is\nlost.  To avoid such loss, the cell must be { refreshed}\nperiodically by reading the contents and writing them back with active\nlogic.\n\n\n{file=part3/figs/lec18-8.eps,width=1.1in}\n\n\nWhen the SELECT line is high during a write operation, logic driving\nthe bit line forces charge onto the capacitor or removes all charge\nfrom it.  For a read operation, the bit line is first brought to an\nintermediate voltage level (a voltage level between 0 and 1), then\nSELECT is raised, allowing the capacitor to either pull a small\namount of charge from the bit line or to push a small amount of charge\nonto the bit line.  The resulting change in voltage is then detected\nby a { sense amplifier} at the end of the bit line.  A sense amp \nis analogous to a marble on a mountaintop: a small push causes the\nmarble to roll rapidly downhill in the direction of the push.\nSimilarly, a small change in voltage causes a sense amp's output to\nmove rapidly to a logical 0 or 1, depending on the direction of the\nsmall change.  As mentioned earlier, sense amplifiers also appear in \nSRAM implementations.\nWhile not technically necessary, as they are with DRAM, the use of a\nsense amp to react to small changes in voltage makes reads faster.\n\nEach read operation on a DRAM cell brings the voltage on its capacitor\ncloser to the intermediate voltage level, in effect destroying the\ndata in the cell.  DRAM is thus said to have { destructive reads}.\nTo preserve data during a read, the bits must be written back\ninto the cells after a read.  For example, the output of the sense \namplifiers can\nbe used to drive the bit lines, rewriting the cells with the\nappropriate data.\n\nAt the chip level, typical DRAM inputs and outputs differ from those\nof SRAM.  \n\nDue to the large size and high density of DRAM,\naddresses are split into row and column components and provided\nthrough a common set of pins.  The DRAM stores the components in\nregisters to support this approach.  Additional inputs, known as the\n{ row} and { column address} {{ strobes}---RAS} and\nCAS, {respectively---are} used to indicate when address\ncomponents are available.  As\nyou might guess from the structure of coincident selection, DRAM\nrefresh occurs on a row-by-row basis (across bit slices---on columns\nrather than rows in the figures earlier in these notes, but the terminology\nof DRAM is a row).  Raising the SELECT line for a\nrow destructively reads the contents of all cells on that row, forcing\nthe cells to be rewritten and effecting a refresh.  The row is thus a\nnatural basis for the refresh cycle.  The DRAM data pins provide\nbidirectional signals for reading and writing elements of the DRAM.\nAn { output enable} input, OE, controls tri-state buffers with\nthe DRAM to determine whether or not the DRAM drives the data pins.\nThe WE input, which controls the type of operation, is\nalso present.\n\n\nTiming diagrams for writes and reads on a historical DRAM implementation\nappear to the right.  In both cases, the row component of the address is \nfirst applied to the address pins, then RAS is raised.  In the\nnext cycle of the controlling logic, the column component is applied\nto the address pins, and CAS is raised.  \n\nFor a write, as shown on the left, the WE signal and the\ndata can\n\n\n{file=part3/figs/lec18-9.eps,width=4in}\n\n\nalso be applied in the second cycle.  The DRAM has internal\ntiming and control logic that prevent races from overwriting an\nincorrect element (remember that the row and column addresses have to\nbe stored in registers).  The DRAM again specifies a write cycle,\nafter which the operation is guaranteed to be complete.  In order, the\nWE, CAS, and RAS signals are then lowered.  \n\nFor a read operation, the output enable signal, OE, is raised after\nCAS is raised.  The DATA pins, which should be floating (in other\nwords, not driven by any logic), are then driven by the DRAM.  After the \nread cycle, valid data appear on the DATA pins, and OE, CAS, and\nRAS are lowered in order after the data are read.\n\nModern DRAM chips are substantially more sophisticated than those\ndiscussed here, and many of the functions that used to be provided\nby external logic are now integrated onto the chips themselves.\n\nAs an example of modern DRAMs, one can obtain\nthe data sheet for Micron Semiconductor's 8Gb ({2^b},\nfor example) DDR4 SDRAM, which is 366 pages long as of 11 May 2016.\n\nThe ability to synchronize to an external clock has become prevalent in \nthe industry, leading to the somewhat confusing term SDRAM, which stands \nfor { synchronous DRAM}.  The memory structures themselves\nare still unclocked, but logic is provided on the chip to synchronize \naccesses to the external clock without the need for additional \nlogic.\n\nThe clock provided to the Micron chip just mentioned\ncan be as fast as 1.6 GHz, and data can be\ntransferred on both the rising and falling edges of the clock\n(hence the name DDR, or { double data rate}).  \n\nIn addition to row and\ncolumn components of the address, these chips further separate cells into\n{ banks} and groups of banks.  These allow a user to exploit parallelism\nby starting reads or writes to separate banks at the same time, thus\nimproving the speed at which data can move in and out of the memory.\n\nFor the {2^b} version of the Micron chip,\nthe cells are structured into 4 groups of 4 banks (16 banks total),\neach with 131,072 rows and 1,024 columns.  \n\nDRAM implementations provide interfaces for specifying\nrefresh operations in addition to reads and writes.\nManaging refresh timing and execution is\ngenerally left to an external DRAM controller.\n\nFor the Micron chip, refresh commands must be issued every \n7.8 microseconds at normal temperatures.  Each\ncommand refreshes about 2^ cells, so 8,192 commands refresh\nthe whole chip in less than 64 milliseconds.\n\nAlternatively, the chip can handle refresh on-chip in\norder to maintain memory contents when the rest of the system is \npowered down.\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of DRAM over SRAM?\n2. What is the main disadvantage of DRAM?\n3. What is the difference between SDRAM and DDR SDRAM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Dynamic Random Access Memory*",
            "text": "{Dynamic Random Access Memory*}\n\nDynamic random access memory, or DRAM, is used for main memory in\ncomputers and for other applications in which size is more important\nthan speed.  While slower than SRAM, DRAM is denser (has\nmore bits per chip area).  A substantial part of DRAM density is\ndue to transistor count: typical SRAM cells use six transistors\n(two for each inverter, and two more to connect the inverters to the \nbit lines), while DRAM cells use only a single transistor.\nHowever, memory designers have also made significant advances in\nfurther miniaturizing DRAM cells to improve density beyond the \nbenefit available from simple transistor count.\n\n\nA diagram of a DRAM cell appears to the right.  \nDRAM storage is capacitive: a bit is stored by charging or not charging \na capacitor.  The capacitor is attached to a BIT line \nthrough a transistor controlled by a SELECT line.  \n\nWhen SELECT is low, the capacitor is isolated and \nholds its charge.  However, the transistor's resistance is\nfinite, and some charge leaks out onto the bit line.  Charge also\nleaks into the substrate on which the transistor is constructed.  After\nsome amount of time, all of the charge dissipates, and the bit is\nlost.  To avoid such loss, the cell must be { refreshed}\nperiodically by reading the contents and writing them back with active\nlogic.\n\n\n{file=part3/figs/lec18-8.eps,width=1.1in}\n\n\nWhen the SELECT line is high during a write operation, logic driving\nthe bit line forces charge onto the capacitor or removes all charge\nfrom it.  For a read operation, the bit line is first brought to an\nintermediate voltage level (a voltage level between 0 and 1), then\nSELECT is raised, allowing the capacitor to either pull a small\namount of charge from the bit line or to push a small amount of charge\nonto the bit line.  The resulting change in voltage is then detected\nby a { sense amplifier} at the end of the bit line.  A sense amp \nis analogous to a marble on a mountaintop: a small push causes the\nmarble to roll rapidly downhill in the direction of the push.\nSimilarly, a small change in voltage causes a sense amp's output to\nmove rapidly to a logical 0 or 1, depending on the direction of the\nsmall change.  As mentioned earlier, sense amplifiers also appear in \nSRAM implementations.\nWhile not technically necessary, as they are with DRAM, the use of a\nsense amp to react to small changes in voltage makes reads faster.\n\nEach read operation on a DRAM cell brings the voltage on its capacitor\ncloser to the intermediate voltage level, in effect destroying the\ndata in the cell.  DRAM is thus said to have { destructive reads}.\nTo preserve data during a read, the bits must be written back\ninto the cells after a read.  For example, the output of the sense \namplifiers can\nbe used to drive the bit lines, rewriting the cells with the\nappropriate data.\n\nAt the chip level, typical DRAM inputs and outputs differ from those\nof SRAM.  \n\nDue to the large size and high density of DRAM,\naddresses are split into row and column components and provided\nthrough a common set of pins.  The DRAM stores the components in\nregisters to support this approach.  Additional inputs, known as the\n{ row} and { column address} {{ strobes}---RAS} and\nCAS, {respectively---are} used to indicate when address\ncomponents are available.  As\nyou might guess from the structure of coincident selection, DRAM\nrefresh occurs on a row-by-row basis (across bit slices---on columns\nrather than rows in the figures earlier in these notes, but the terminology\nof DRAM is a row).  Raising the SELECT line for a\nrow destructively reads the contents of all cells on that row, forcing\nthe cells to be rewritten and effecting a refresh.  The row is thus a\nnatural basis for the refresh cycle.  The DRAM data pins provide\nbidirectional signals for reading and writing elements of the DRAM.\nAn { output enable} input, OE, controls tri-state buffers with\nthe DRAM to determine whether or not the DRAM drives the data pins.\nThe WE input, which controls the type of operation, is\nalso present.\n\n\nTiming diagrams for writes and reads on a historical DRAM implementation\nappear to the right.  In both cases, the row component of the address is \nfirst applied to the address pins, then RAS is raised.  In the\nnext cycle of the controlling logic, the column component is applied\nto the address pins, and CAS is raised.  \n\nFor a write, as shown on the left, the WE signal and the\ndata can\n\n\n{file=part3/figs/lec18-9.eps,width=4in}\n\n\nalso be applied in the second cycle.  The DRAM has internal\ntiming and control logic that prevent races from overwriting an\nincorrect element (remember that the row and column addresses have to\nbe stored in registers).  The DRAM again specifies a write cycle,\nafter which the operation is guaranteed to be complete.  In order, the\nWE, CAS, and RAS signals are then lowered.  \n\nFor a read operation, the output enable signal, OE, is raised after\nCAS is raised.  The DATA pins, which should be floating (in other\nwords, not driven by any logic), are then driven by the DRAM.  After the \nread cycle, valid data appear on the DATA pins, and OE, CAS, and\nRAS are lowered in order after the data are read.\n\nModern DRAM chips are substantially more sophisticated than those\ndiscussed here, and many of the functions that used to be provided\nby external logic are now integrated onto the chips themselves.\n\nAs an example of modern DRAMs, one can obtain\nthe data sheet for Micron Semiconductor's 8Gb ({2^b},\nfor example) DDR4 SDRAM, which is 366 pages long as of 11 May 2016.\n\nThe ability to synchronize to an external clock has become prevalent in \nthe industry, leading to the somewhat confusing term SDRAM, which stands \nfor { synchronous DRAM}.  The memory structures themselves\nare still unclocked, but logic is provided on the chip to synchronize \naccesses to the external clock without the need for additional \nlogic.\n\nThe clock provided to the Micron chip just mentioned\ncan be as fast as 1.6 GHz, and data can be\ntransferred on both the rising and falling edges of the clock\n(hence the name DDR, or { double data rate}).  \n\nIn addition to row and\ncolumn components of the address, these chips further separate cells into\n{ banks} and groups of banks.  These allow a user to exploit parallelism\nby starting reads or writes to separate banks at the same time, thus\nimproving the speed at which data can move in and out of the memory.\n\nFor the {2^b} version of the Micron chip,\nthe cells are structured into 4 groups of 4 banks (16 banks total),\neach with 131,072 rows and 1,024 columns.  \n\nDRAM implementations provide interfaces for specifying\nrefresh operations in addition to reads and writes.\nManaging refresh timing and execution is\ngenerally left to an external DRAM controller.\n\nFor the Micron chip, refresh commands must be issued every \n7.8 microseconds at normal temperatures.  Each\ncommand refreshes about 2^ cells, so 8,192 commands refresh\nthe whole chip in less than 64 milliseconds.\n\nAlternatively, the chip can handle refresh on-chip in\norder to maintain memory contents when the rest of the system is \npowered down.\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of DRAM over SRAM?\n2. What is the main disadvantage of DRAM?\n3. What is the difference between SDRAM and DDR SDRAM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Dynamic Random Access Memory*",
            "text": "{Dynamic Random Access Memory*}\n\nDynamic random access memory, or DRAM, is used for main memory in\ncomputers and for other applications in which size is more important\nthan speed.  While slower than SRAM, DRAM is denser (has\nmore bits per chip area).  A substantial part of DRAM density is\ndue to transistor count: typical SRAM cells use six transistors\n(two for each inverter, and two more to connect the inverters to the \nbit lines), while DRAM cells use only a single transistor.\nHowever, memory designers have also made significant advances in\nfurther miniaturizing DRAM cells to improve density beyond the \nbenefit available from simple transistor count.\n\n\nA diagram of a DRAM cell appears to the right.  \nDRAM storage is capacitive: a bit is stored by charging or not charging \na capacitor.  The capacitor is attached to a BIT line \nthrough a transistor controlled by a SELECT line.  \n\nWhen SELECT is low, the capacitor is isolated and \nholds its charge.  However, the transistor's resistance is\nfinite, and some charge leaks out onto the bit line.  Charge also\nleaks into the substrate on which the transistor is constructed.  After\nsome amount of time, all of the charge dissipates, and the bit is\nlost.  To avoid such loss, the cell must be { refreshed}\nperiodically by reading the contents and writing them back with active\nlogic.\n\n\n{file=part3/figs/lec18-8.eps,width=1.1in}\n\n\nWhen the SELECT line is high during a write operation, logic driving\nthe bit line forces charge onto the capacitor or removes all charge\nfrom it.  For a read operation, the bit line is first brought to an\nintermediate voltage level (a voltage level between 0 and 1), then\nSELECT is raised, allowing the capacitor to either pull a small\namount of charge from the bit line or to push a small amount of charge\nonto the bit line.  The resulting change in voltage is then detected\nby a { sense amplifier} at the end of the bit line.  A sense amp \nis analogous to a marble on a mountaintop: a small push causes the\nmarble to roll rapidly downhill in the direction of the push.\nSimilarly, a small change in voltage causes a sense amp's output to\nmove rapidly to a logical 0 or 1, depending on the direction of the\nsmall change.  As mentioned earlier, sense amplifiers also appear in \nSRAM implementations.\nWhile not technically necessary, as they are with DRAM, the use of a\nsense amp to react to small changes in voltage makes reads faster.\n\nEach read operation on a DRAM cell brings the voltage on its capacitor\ncloser to the intermediate voltage level, in effect destroying the\ndata in the cell.  DRAM is thus said to have { destructive reads}.\nTo preserve data during a read, the bits must be written back\ninto the cells after a read.  For example, the output of the sense \namplifiers can\nbe used to drive the bit lines, rewriting the cells with the\nappropriate data.\n\nAt the chip level, typical DRAM inputs and outputs differ from those\nof SRAM.  \n\nDue to the large size and high density of DRAM,\naddresses are split into row and column components and provided\nthrough a common set of pins.  The DRAM stores the components in\nregisters to support this approach.  Additional inputs, known as the\n{ row} and { column address} {{ strobes}---RAS} and\nCAS, {respectively---are} used to indicate when address\ncomponents are available.  As\nyou might guess from the structure of coincident selection, DRAM\nrefresh occurs on a row-by-row basis (across bit slices---on columns\nrather than rows in the figures earlier in these notes, but the terminology\nof DRAM is a row).  Raising the SELECT line for a\nrow destructively reads the contents of all cells on that row, forcing\nthe cells to be rewritten and effecting a refresh.  The row is thus a\nnatural basis for the refresh cycle.  The DRAM data pins provide\nbidirectional signals for reading and writing elements of the DRAM.\nAn { output enable} input, OE, controls tri-state buffers with\nthe DRAM to determine whether or not the DRAM drives the data pins.\nThe WE input, which controls the type of operation, is\nalso present.\n\n\nTiming diagrams for writes and reads on a historical DRAM implementation\nappear to the right.  In both cases, the row component of the address is \nfirst applied to the address pins, then RAS is raised.  In the\nnext cycle of the controlling logic, the column component is applied\nto the address pins, and CAS is raised.  \n\nFor a write, as shown on the left, the WE signal and the\ndata can\n\n\n{file=part3/figs/lec18-9.eps,width=4in}\n\n\nalso be applied in the second cycle.  The DRAM has internal\ntiming and control logic that prevent races from overwriting an\nincorrect element (remember that the row and column addresses have to\nbe stored in registers).  The DRAM again specifies a write cycle,\nafter which the operation is guaranteed to be complete.  In order, the\nWE, CAS, and RAS signals are then lowered.  \n\nFor a read operation, the output enable signal, OE, is raised after\nCAS is raised.  The DATA pins, which should be floating (in other\nwords, not driven by any logic), are then driven by the DRAM.  After the \nread cycle, valid data appear on the DATA pins, and OE, CAS, and\nRAS are lowered in order after the data are read.\n\nModern DRAM chips are substantially more sophisticated than those\ndiscussed here, and many of the functions that used to be provided\nby external logic are now integrated onto the chips themselves.\n\nAs an example of modern DRAMs, one can obtain\nthe data sheet for Micron Semiconductor's 8Gb ({2^b},\nfor example) DDR4 SDRAM, which is 366 pages long as of 11 May 2016.\n\nThe ability to synchronize to an external clock has become prevalent in \nthe industry, leading to the somewhat confusing term SDRAM, which stands \nfor { synchronous DRAM}.  The memory structures themselves\nare still unclocked, but logic is provided on the chip to synchronize \naccesses to the external clock without the need for additional \nlogic.\n\nThe clock provided to the Micron chip just mentioned\ncan be as fast as 1.6 GHz, and data can be\ntransferred on both the rising and falling edges of the clock\n(hence the name DDR, or { double data rate}).  \n\nIn addition to row and\ncolumn components of the address, these chips further separate cells into\n{ banks} and groups of banks.  These allow a user to exploit parallelism\nby starting reads or writes to separate banks at the same time, thus\nimproving the speed at which data can move in and out of the memory.\n\nFor the {2^b} version of the Micron chip,\nthe cells are structured into 4 groups of 4 banks (16 banks total),\neach with 131,072 rows and 1,024 columns.  \n\nDRAM implementations provide interfaces for specifying\nrefresh operations in addition to reads and writes.\nManaging refresh timing and execution is\ngenerally left to an external DRAM controller.\n\nFor the Micron chip, refresh commands must be issued every \n7.8 microseconds at normal temperatures.  Each\ncommand refreshes about 2^ cells, so 8,192 commands refresh\nthe whole chip in less than 64 milliseconds.\n\nAlternatively, the chip can handle refresh on-chip in\norder to maintain memory contents when the rest of the system is \npowered down.\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of DRAM over SRAM?\n2. What is the main disadvantage of DRAM?\n3. What is the difference between SDRAM and DDR SDRAM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Testing the Design",
            "text": "{Testing the Design}\n\nHaving a complete design on paper is a good step forward, but humans\nmake mistakes at all stages.  How can we know that a circuit that\nwe build in the lab correctly implements the FSM that we have outlined \nin these notes?\n\nFor the lab design, we have two problems to solve.\n\nFirst, we have not specified an initialization scheme for the FSM.\nWe may want the FSM to start in one of the PAID states, but adding\ninitialization logic to the design may mean requiring you to wire together\nsignificantly more chips.  Second, we need a sequence of inputs that\nmanages to test that all of the next-state and output logic implementations\nare correct.\n\nTesting sequential logic, including FSMs, is in general extremely difficult.\nIn fact, large sequential systems today are generally converted into \ncombinational logic by using shift registers to fill the \nflip-flops with a particular pattern, \nexecuting the logic for one clock cycle, and checking that the resulting \npattern of bits in the flip-flops is correct.  This approach is called \n{ scan-based testing}, and is discussed in ECE 543.  You \nwill make use of a similar approach\nwhen you test your combinational logic in the second week of the lab,\nbefore wiring up the flip-flops.\n\nWe have designed our FSM to be easy to test (even small FSMs\nmay be challenging) with a brute force approach.  In particular, we \nidentify two input sequences that together serve both to initialize and \nto test a correctly implemented variant of our FSM.  Our initialization\nsequence forces the FSM into a specific state regardless of its initial\nstate.  And our test sequence crosses every transition arc leaving the\nsix valid states.\n\n\n\nIn terms of T, the coin type, we initialize the FSM with the\ninput sequence 001.  Notice that such a sequence takes any initial \nstate into PAID2.\n\nFor testing, we use the input sequence 111010010001.  You should trace \nthis sequence, starting from PAID2, on the diagram below to see how the\ntest sequence covers all of the possible arcs.  As we test, we need also\nto observe the A and P outputs in each state to check the output\nlogic.\n\n{{file=part3/figs/lab-diag-notes.eps,width=4.25in}}\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of scan-based testing?\n2. How does scan-based testing work?\n3. What is the purpose of the test sequence 111010010001?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Testing the Design",
            "text": "{Testing the Design}\n\nHaving a complete design on paper is a good step forward, but humans\nmake mistakes at all stages.  How can we know that a circuit that\nwe build in the lab correctly implements the FSM that we have outlined \nin these notes?\n\nFor the lab design, we have two problems to solve.\n\nFirst, we have not specified an initialization scheme for the FSM.\nWe may want the FSM to start in one of the PAID states, but adding\ninitialization logic to the design may mean requiring you to wire together\nsignificantly more chips.  Second, we need a sequence of inputs that\nmanages to test that all of the next-state and output logic implementations\nare correct.\n\nTesting sequential logic, including FSMs, is in general extremely difficult.\nIn fact, large sequential systems today are generally converted into \ncombinational logic by using shift registers to fill the \nflip-flops with a particular pattern, \nexecuting the logic for one clock cycle, and checking that the resulting \npattern of bits in the flip-flops is correct.  This approach is called \n{ scan-based testing}, and is discussed in ECE 543.  You \nwill make use of a similar approach\nwhen you test your combinational logic in the second week of the lab,\nbefore wiring up the flip-flops.\n\nWe have designed our FSM to be easy to test (even small FSMs\nmay be challenging) with a brute force approach.  In particular, we \nidentify two input sequences that together serve both to initialize and \nto test a correctly implemented variant of our FSM.  Our initialization\nsequence forces the FSM into a specific state regardless of its initial\nstate.  And our test sequence crosses every transition arc leaving the\nsix valid states.\n\n\n\nIn terms of T, the coin type, we initialize the FSM with the\ninput sequence 001.  Notice that such a sequence takes any initial \nstate into PAID2.\n\nFor testing, we use the input sequence 111010010001.  You should trace \nthis sequence, starting from PAID2, on the diagram below to see how the\ntest sequence covers all of the possible arcs.  As we test, we need also\nto observe the A and P outputs in each state to check the output\nlogic.\n\n{{file=part3/figs/lab-diag-notes.eps,width=4.25in}}\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of scan-based testing?\n2. How does scan-based testing work?\n3. What is the purpose of the test sequence 111010010001?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Testing the Design",
            "text": "{Testing the Design}\n\nHaving a complete design on paper is a good step forward, but humans\nmake mistakes at all stages.  How can we know that a circuit that\nwe build in the lab correctly implements the FSM that we have outlined \nin these notes?\n\nFor the lab design, we have two problems to solve.\n\nFirst, we have not specified an initialization scheme for the FSM.\nWe may want the FSM to start in one of the PAID states, but adding\ninitialization logic to the design may mean requiring you to wire together\nsignificantly more chips.  Second, we need a sequence of inputs that\nmanages to test that all of the next-state and output logic implementations\nare correct.\n\nTesting sequential logic, including FSMs, is in general extremely difficult.\nIn fact, large sequential systems today are generally converted into \ncombinational logic by using shift registers to fill the \nflip-flops with a particular pattern, \nexecuting the logic for one clock cycle, and checking that the resulting \npattern of bits in the flip-flops is correct.  This approach is called \n{ scan-based testing}, and is discussed in ECE 543.  You \nwill make use of a similar approach\nwhen you test your combinational logic in the second week of the lab,\nbefore wiring up the flip-flops.\n\nWe have designed our FSM to be easy to test (even small FSMs\nmay be challenging) with a brute force approach.  In particular, we \nidentify two input sequences that together serve both to initialize and \nto test a correctly implemented variant of our FSM.  Our initialization\nsequence forces the FSM into a specific state regardless of its initial\nstate.  And our test sequence crosses every transition arc leaving the\nsix valid states.\n\n\n\nIn terms of T, the coin type, we initialize the FSM with the\ninput sequence 001.  Notice that such a sequence takes any initial \nstate into PAID2.\n\nFor testing, we use the input sequence 111010010001.  You should trace \nthis sequence, starting from PAID2, on the diagram below to see how the\ntest sequence covers all of the possible arcs.  As we test, we need also\nto observe the A and P outputs in each state to check the output\nlogic.\n\n{{file=part3/figs/lab-diag-notes.eps,width=4.25in}}\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of scan-based testing?\n2. How does scan-based testing work?\n3. What is the purpose of the test sequence 111010010001?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Testing the Design",
            "text": "{Testing the Design}\n\nHaving a complete design on paper is a good step forward, but humans\nmake mistakes at all stages.  How can we know that a circuit that\nwe build in the lab correctly implements the FSM that we have outlined \nin these notes?\n\nFor the lab design, we have two problems to solve.\n\nFirst, we have not specified an initialization scheme for the FSM.\nWe may want the FSM to start in one of the PAID states, but adding\ninitialization logic to the design may mean requiring you to wire together\nsignificantly more chips.  Second, we need a sequence of inputs that\nmanages to test that all of the next-state and output logic implementations\nare correct.\n\nTesting sequential logic, including FSMs, is in general extremely difficult.\nIn fact, large sequential systems today are generally converted into \ncombinational logic by using shift registers to fill the \nflip-flops with a particular pattern, \nexecuting the logic for one clock cycle, and checking that the resulting \npattern of bits in the flip-flops is correct.  This approach is called \n{ scan-based testing}, and is discussed in ECE 543.  You \nwill make use of a similar approach\nwhen you test your combinational logic in the second week of the lab,\nbefore wiring up the flip-flops.\n\nWe have designed our FSM to be easy to test (even small FSMs\nmay be challenging) with a brute force approach.  In particular, we \nidentify two input sequences that together serve both to initialize and \nto test a correctly implemented variant of our FSM.  Our initialization\nsequence forces the FSM into a specific state regardless of its initial\nstate.  And our test sequence crosses every transition arc leaving the\nsix valid states.\n\n\n\nIn terms of T, the coin type, we initialize the FSM with the\ninput sequence 001.  Notice that such a sequence takes any initial \nstate into PAID2.\n\nFor testing, we use the input sequence 111010010001.  You should trace \nthis sequence, starting from PAID2, on the diagram below to see how the\ntest sequence covers all of the possible arcs.  As we test, we need also\nto observe the A and P outputs in each state to check the output\nlogic.\n\n{{file=part3/figs/lab-diag-notes.eps,width=4.25in}}\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of scan-based testing?\n2. How does scan-based testing work?\n3. What is the purpose of the test sequence 111010010001?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Testing the Design",
            "text": "{Testing the Design}\n\nHaving a complete design on paper is a good step forward, but humans\nmake mistakes at all stages.  How can we know that a circuit that\nwe build in the lab correctly implements the FSM that we have outlined \nin these notes?\n\nFor the lab design, we have two problems to solve.\n\nFirst, we have not specified an initialization scheme for the FSM.\nWe may want the FSM to start in one of the PAID states, but adding\ninitialization logic to the design may mean requiring you to wire together\nsignificantly more chips.  Second, we need a sequence of inputs that\nmanages to test that all of the next-state and output logic implementations\nare correct.\n\nTesting sequential logic, including FSMs, is in general extremely difficult.\nIn fact, large sequential systems today are generally converted into \ncombinational logic by using shift registers to fill the \nflip-flops with a particular pattern, \nexecuting the logic for one clock cycle, and checking that the resulting \npattern of bits in the flip-flops is correct.  This approach is called \n{ scan-based testing}, and is discussed in ECE 543.  You \nwill make use of a similar approach\nwhen you test your combinational logic in the second week of the lab,\nbefore wiring up the flip-flops.\n\nWe have designed our FSM to be easy to test (even small FSMs\nmay be challenging) with a brute force approach.  In particular, we \nidentify two input sequences that together serve both to initialize and \nto test a correctly implemented variant of our FSM.  Our initialization\nsequence forces the FSM into a specific state regardless of its initial\nstate.  And our test sequence crosses every transition arc leaving the\nsix valid states.\n\n\n\nIn terms of T, the coin type, we initialize the FSM with the\ninput sequence 001.  Notice that such a sequence takes any initial \nstate into PAID2.\n\nFor testing, we use the input sequence 111010010001.  You should trace \nthis sequence, starting from PAID2, on the diagram below to see how the\ntest sequence covers all of the possible arcs.  As we test, we need also\nto observe the A and P outputs in each state to check the output\nlogic.\n\n{{file=part3/figs/lab-diag-notes.eps,width=4.25in}}\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of scan-based testing?\n2. How does scan-based testing work?\n3. What is the purpose of the test sequence 111010010001?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Analysis of a Stoplight Controller",
            "text": "{Analysis of a Stoplight Controller}\n\nIn this example, we begin with a digital FSM design and analyze it to\nunderstand how it works and to verify that its behavior is appropriate.\n\nThe FSM that we analyze has been designed to control the stoplights\nat the intersection of two roads.  For naming purposes, we assume that one\nof the roads runs East and West (EW), and the second runs North and \nSouth (NS).  \n\nThe stoplight controller has two inputs, each of which \nsenses vehicles approaching from either direction on one of the two roads.\nThe input V^=1 when a vehicle approaches from either the East or the\nWest, and the input V^=1 when a vehicle approaches from either the\nNorth or the South.  These inputs are also active when vehicles are stopped\nwaiting at the corresponding lights.\n\nAnother three inputs, A, B, and C, control the timing behavior of the\nsystem; we do not discuss them here except as variables.\n\n\nThe outputs of the controller consist of two {2-bit} values, \nL^ and L^, that specify the light colors for the two roads.\nIn particular, L^ controls the lights facing East and West, and\nL^ controls the lights facing North and South.  The meaning of these\noutputs is given in the table to the right.\n\n\n{c|c}\nL& light color \n0x& red\n10& yellow\n11& green\n\n\n\nLet's think about the basic operation of the controller.\n\nFor safety reasons, the controller must ensure that the lights on one\nor both roads are red at all times.  \n\nSimilarly, if a road has a green light, the controller should \nshow a yellow light before showing a red light to give drivers some\nwarning and allow them to slow down.\n\nFinally, for fairness, the controller should alternate green lights\nbetween the two roads.\n\nNow take a look at the logic diagram below.\n\nThe state of the FSM has been split into two pieces: a {3-bit} \nregister S and a {6-bit} timer.  The timer is simply a binary \ncounter that counts downward and produces an output of Z=1 when it \nreaches 0.  Notice that the register S only takes a new value\nwhen the timer reaches 0, and that the Z signal from the timer\nalso forces a new value to be loaded into the timer in the next \ncycle.  We can thus think of transitions in the FSM on a cycle by \ncycle basis as consisting of two types.  The first type simply\ncounts downward for a number of cycles while holding the register S\nconstant, while the second changes the value of S and sets the\ntimer in order to maintain the new value of S \nfor some number of cycles.\n\n\n\n3.45\n\n\nLet's look at the next-state logic for S, which feeds into the IN\ninputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice \nthat none of the inputs to the FSM directly affect these values.  The\nstates of S thus act like a counter.  By examining the connections,\nwe can derive equations for the next state and draw a transition\ndiagram, as shown to the right.\n\nAs the figure shows, there are six states in the loop defined by the \nnext-state logic, with the two remaining states converging into the\nloop after a single cycle.\n\nLet's now examine the outputs for each\nstate in order to understand how the stoplight sequencing\nworks.\n\nWe derive equations for the outputs that control the lights, as shown\nto the right, then calculate values and colors for each\nstate, as shown to the far right.  For completeness, the table \nincludes the states outside of the desired loop.  The \nlights are all red in both of these states, which is necessary for safety.\n\n\n{eqnarray*}\n\nS_2^+ &=& {S_2} + S_0\nS_1^+ &=& {S_2}  S_1\nS_0^+ &=& {S_2}\n{eqnarray*}\n\n{eqnarray*}\nL_1^ &=& S_2 S_1\nL_0^ &=& S_0\nL_1^ &=& S_2 {S_1}\nL_0^ &=& S_0\n{eqnarray*}\n\n\n\n{c|cc|cc}\n&&& EW& NS\n&&& light& light\nS& L^& L^& color& color \n000& 00& 00&    red&    red\n111& 11& 01&  green&    red\n110& 10& 00& yellow&    red\n010& 00& 00&    red&    red\n101& 01& 11&    red&  green\n100& 00& 10&    red& yellow \n001& 01& 01&    red&    red\n011& 01& 01&    red&    red\n\n\n\n\nNow let's think about how the timer works.  As we already noted, the\ntimer value is set whenever S enters a new state, but it can also be\nset under other conditions---in particular, by the signal F calculated\nat the bottom of the FSM logic diagram.  \n\n\nFor now, assume that F=0.  In this case, the timer is set only when\nthe state S changes, and we can find the duration of each state by\nanalyzing the muxes.  The bottom mux selects A when S_2=0, and \nselects the output of the top mux when S_2=1.  The top mux selects B\nwhen S_0=1, and selects C when S_0=0.  Combining these results,\nwe can calculate the duration of the next states of S when F=0, \nas shown in the table to the right.  We can then combine the next\nstate duration with our previous calculation of the state sequencing \n(also the order in the table) to obtain the durations of each state, also\nshown in the rightmost column of the table.\n\n\n{c|cc|cc}\n& EW& NS& next& current\n& light& light& state& state\nS& color& color& duration& duration \n000&    red&    red& A& C\n111&  green&    red& B& A\n110& yellow&    red& C& B\n010&    red&    red& A& C\n101&    red&  green& B& A\n100&    red& yellow& C& B \n001&    red&    red& A& ---\n011&    red&    red& A& ---\n\n\n\nWhat does F do?  Analyzing the gates that produce it gives \nF=S_1S_0{V^+{S_1}S_0{V^.  If we \nignore the two states outside of the main loop for S, the first term \nis 1 only when the lights are green on the East and West roads and the \ndetector for the North and South roads indicates that no vehicles are \napproaching.  Similarly, the second term is 1 only when the lights are \ngreen on the North and South roads and the detector for the East and \nWest roads indicates that no vehicles are approaching.\n\nWhat happens when F=1?  First, the OR gate feeding into the timer's\nLD input produces a 1, meaning that the timer loads a new value\ninstead of counting down.  Second, the OR gate controlling the lower\nmux selects the A input.  In other words, the timer is reset to A\ncycles, corresponding to the initial value for the green light states.\nIn other words, the light stays green until vehicles approach on \nthe other road, plus A more cycles.\n\nUnfortunately, the signal F may also be 1 in the unused states of S,\nin which case the lights on both roads may remain red even though cars\nare waiting on one of the roads.  To avoid this behavior, we must be \nsure to initialize the state S to one of the six states in the\ndesired loop.\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of the FSM design?\n2. What are the inputs and outputs of the FSM?\n3. How does the timer work in the FSM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Analysis of a Stoplight Controller",
            "text": "{Analysis of a Stoplight Controller}\n\nIn this example, we begin with a digital FSM design and analyze it to\nunderstand how it works and to verify that its behavior is appropriate.\n\nThe FSM that we analyze has been designed to control the stoplights\nat the intersection of two roads.  For naming purposes, we assume that one\nof the roads runs East and West (EW), and the second runs North and \nSouth (NS).  \n\nThe stoplight controller has two inputs, each of which \nsenses vehicles approaching from either direction on one of the two roads.\nThe input V^=1 when a vehicle approaches from either the East or the\nWest, and the input V^=1 when a vehicle approaches from either the\nNorth or the South.  These inputs are also active when vehicles are stopped\nwaiting at the corresponding lights.\n\nAnother three inputs, A, B, and C, control the timing behavior of the\nsystem; we do not discuss them here except as variables.\n\n\nThe outputs of the controller consist of two {2-bit} values, \nL^ and L^, that specify the light colors for the two roads.\nIn particular, L^ controls the lights facing East and West, and\nL^ controls the lights facing North and South.  The meaning of these\noutputs is given in the table to the right.\n\n\n{c|c}\nL& light color \n0x& red\n10& yellow\n11& green\n\n\n\nLet's think about the basic operation of the controller.\n\nFor safety reasons, the controller must ensure that the lights on one\nor both roads are red at all times.  \n\nSimilarly, if a road has a green light, the controller should \nshow a yellow light before showing a red light to give drivers some\nwarning and allow them to slow down.\n\nFinally, for fairness, the controller should alternate green lights\nbetween the two roads.\n\nNow take a look at the logic diagram below.\n\nThe state of the FSM has been split into two pieces: a {3-bit} \nregister S and a {6-bit} timer.  The timer is simply a binary \ncounter that counts downward and produces an output of Z=1 when it \nreaches 0.  Notice that the register S only takes a new value\nwhen the timer reaches 0, and that the Z signal from the timer\nalso forces a new value to be loaded into the timer in the next \ncycle.  We can thus think of transitions in the FSM on a cycle by \ncycle basis as consisting of two types.  The first type simply\ncounts downward for a number of cycles while holding the register S\nconstant, while the second changes the value of S and sets the\ntimer in order to maintain the new value of S \nfor some number of cycles.\n\n\n\n3.45\n\n\nLet's look at the next-state logic for S, which feeds into the IN\ninputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice \nthat none of the inputs to the FSM directly affect these values.  The\nstates of S thus act like a counter.  By examining the connections,\nwe can derive equations for the next state and draw a transition\ndiagram, as shown to the right.\n\nAs the figure shows, there are six states in the loop defined by the \nnext-state logic, with the two remaining states converging into the\nloop after a single cycle.\n\nLet's now examine the outputs for each\nstate in order to understand how the stoplight sequencing\nworks.\n\nWe derive equations for the outputs that control the lights, as shown\nto the right, then calculate values and colors for each\nstate, as shown to the far right.  For completeness, the table \nincludes the states outside of the desired loop.  The \nlights are all red in both of these states, which is necessary for safety.\n\n\n{eqnarray*}\n\nS_2^+ &=& {S_2} + S_0\nS_1^+ &=& {S_2}  S_1\nS_0^+ &=& {S_2}\n{eqnarray*}\n\n{eqnarray*}\nL_1^ &=& S_2 S_1\nL_0^ &=& S_0\nL_1^ &=& S_2 {S_1}\nL_0^ &=& S_0\n{eqnarray*}\n\n\n\n{c|cc|cc}\n&&& EW& NS\n&&& light& light\nS& L^& L^& color& color \n000& 00& 00&    red&    red\n111& 11& 01&  green&    red\n110& 10& 00& yellow&    red\n010& 00& 00&    red&    red\n101& 01& 11&    red&  green\n100& 00& 10&    red& yellow \n001& 01& 01&    red&    red\n011& 01& 01&    red&    red\n\n\n\n\nNow let's think about how the timer works.  As we already noted, the\ntimer value is set whenever S enters a new state, but it can also be\nset under other conditions---in particular, by the signal F calculated\nat the bottom of the FSM logic diagram.  \n\n\nFor now, assume that F=0.  In this case, the timer is set only when\nthe state S changes, and we can find the duration of each state by\nanalyzing the muxes.  The bottom mux selects A when S_2=0, and \nselects the output of the top mux when S_2=1.  The top mux selects B\nwhen S_0=1, and selects C when S_0=0.  Combining these results,\nwe can calculate the duration of the next states of S when F=0, \nas shown in the table to the right.  We can then combine the next\nstate duration with our previous calculation of the state sequencing \n(also the order in the table) to obtain the durations of each state, also\nshown in the rightmost column of the table.\n\n\n{c|cc|cc}\n& EW& NS& next& current\n& light& light& state& state\nS& color& color& duration& duration \n000&    red&    red& A& C\n111&  green&    red& B& A\n110& yellow&    red& C& B\n010&    red&    red& A& C\n101&    red&  green& B& A\n100&    red& yellow& C& B \n001&    red&    red& A& ---\n011&    red&    red& A& ---\n\n\n\nWhat does F do?  Analyzing the gates that produce it gives \nF=S_1S_0{V^+{S_1}S_0{V^.  If we \nignore the two states outside of the main loop for S, the first term \nis 1 only when the lights are green on the East and West roads and the \ndetector for the North and South roads indicates that no vehicles are \napproaching.  Similarly, the second term is 1 only when the lights are \ngreen on the North and South roads and the detector for the East and \nWest roads indicates that no vehicles are approaching.\n\nWhat happens when F=1?  First, the OR gate feeding into the timer's\nLD input produces a 1, meaning that the timer loads a new value\ninstead of counting down.  Second, the OR gate controlling the lower\nmux selects the A input.  In other words, the timer is reset to A\ncycles, corresponding to the initial value for the green light states.\nIn other words, the light stays green until vehicles approach on \nthe other road, plus A more cycles.\n\nUnfortunately, the signal F may also be 1 in the unused states of S,\nin which case the lights on both roads may remain red even though cars\nare waiting on one of the roads.  To avoid this behavior, we must be \nsure to initialize the state S to one of the six states in the\ndesired loop.\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of the FSM design?\n2. What are the inputs and outputs of the FSM?\n3. How does the timer work in the FSM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Analysis of a Stoplight Controller",
            "text": "{Analysis of a Stoplight Controller}\n\nIn this example, we begin with a digital FSM design and analyze it to\nunderstand how it works and to verify that its behavior is appropriate.\n\nThe FSM that we analyze has been designed to control the stoplights\nat the intersection of two roads.  For naming purposes, we assume that one\nof the roads runs East and West (EW), and the second runs North and \nSouth (NS).  \n\nThe stoplight controller has two inputs, each of which \nsenses vehicles approaching from either direction on one of the two roads.\nThe input V^=1 when a vehicle approaches from either the East or the\nWest, and the input V^=1 when a vehicle approaches from either the\nNorth or the South.  These inputs are also active when vehicles are stopped\nwaiting at the corresponding lights.\n\nAnother three inputs, A, B, and C, control the timing behavior of the\nsystem; we do not discuss them here except as variables.\n\n\nThe outputs of the controller consist of two {2-bit} values, \nL^ and L^, that specify the light colors for the two roads.\nIn particular, L^ controls the lights facing East and West, and\nL^ controls the lights facing North and South.  The meaning of these\noutputs is given in the table to the right.\n\n\n{c|c}\nL& light color \n0x& red\n10& yellow\n11& green\n\n\n\nLet's think about the basic operation of the controller.\n\nFor safety reasons, the controller must ensure that the lights on one\nor both roads are red at all times.  \n\nSimilarly, if a road has a green light, the controller should \nshow a yellow light before showing a red light to give drivers some\nwarning and allow them to slow down.\n\nFinally, for fairness, the controller should alternate green lights\nbetween the two roads.\n\nNow take a look at the logic diagram below.\n\nThe state of the FSM has been split into two pieces: a {3-bit} \nregister S and a {6-bit} timer.  The timer is simply a binary \ncounter that counts downward and produces an output of Z=1 when it \nreaches 0.  Notice that the register S only takes a new value\nwhen the timer reaches 0, and that the Z signal from the timer\nalso forces a new value to be loaded into the timer in the next \ncycle.  We can thus think of transitions in the FSM on a cycle by \ncycle basis as consisting of two types.  The first type simply\ncounts downward for a number of cycles while holding the register S\nconstant, while the second changes the value of S and sets the\ntimer in order to maintain the new value of S \nfor some number of cycles.\n\n\n\n3.45\n\n\nLet's look at the next-state logic for S, which feeds into the IN\ninputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice \nthat none of the inputs to the FSM directly affect these values.  The\nstates of S thus act like a counter.  By examining the connections,\nwe can derive equations for the next state and draw a transition\ndiagram, as shown to the right.\n\nAs the figure shows, there are six states in the loop defined by the \nnext-state logic, with the two remaining states converging into the\nloop after a single cycle.\n\nLet's now examine the outputs for each\nstate in order to understand how the stoplight sequencing\nworks.\n\nWe derive equations for the outputs that control the lights, as shown\nto the right, then calculate values and colors for each\nstate, as shown to the far right.  For completeness, the table \nincludes the states outside of the desired loop.  The \nlights are all red in both of these states, which is necessary for safety.\n\n\n{eqnarray*}\n\nS_2^+ &=& {S_2} + S_0\nS_1^+ &=& {S_2}  S_1\nS_0^+ &=& {S_2}\n{eqnarray*}\n\n{eqnarray*}\nL_1^ &=& S_2 S_1\nL_0^ &=& S_0\nL_1^ &=& S_2 {S_1}\nL_0^ &=& S_0\n{eqnarray*}\n\n\n\n{c|cc|cc}\n&&& EW& NS\n&&& light& light\nS& L^& L^& color& color \n000& 00& 00&    red&    red\n111& 11& 01&  green&    red\n110& 10& 00& yellow&    red\n010& 00& 00&    red&    red\n101& 01& 11&    red&  green\n100& 00& 10&    red& yellow \n001& 01& 01&    red&    red\n011& 01& 01&    red&    red\n\n\n\n\nNow let's think about how the timer works.  As we already noted, the\ntimer value is set whenever S enters a new state, but it can also be\nset under other conditions---in particular, by the signal F calculated\nat the bottom of the FSM logic diagram.  \n\n\nFor now, assume that F=0.  In this case, the timer is set only when\nthe state S changes, and we can find the duration of each state by\nanalyzing the muxes.  The bottom mux selects A when S_2=0, and \nselects the output of the top mux when S_2=1.  The top mux selects B\nwhen S_0=1, and selects C when S_0=0.  Combining these results,\nwe can calculate the duration of the next states of S when F=0, \nas shown in the table to the right.  We can then combine the next\nstate duration with our previous calculation of the state sequencing \n(also the order in the table) to obtain the durations of each state, also\nshown in the rightmost column of the table.\n\n\n{c|cc|cc}\n& EW& NS& next& current\n& light& light& state& state\nS& color& color& duration& duration \n000&    red&    red& A& C\n111&  green&    red& B& A\n110& yellow&    red& C& B\n010&    red&    red& A& C\n101&    red&  green& B& A\n100&    red& yellow& C& B \n001&    red&    red& A& ---\n011&    red&    red& A& ---\n\n\n\nWhat does F do?  Analyzing the gates that produce it gives \nF=S_1S_0{V^+{S_1}S_0{V^.  If we \nignore the two states outside of the main loop for S, the first term \nis 1 only when the lights are green on the East and West roads and the \ndetector for the North and South roads indicates that no vehicles are \napproaching.  Similarly, the second term is 1 only when the lights are \ngreen on the North and South roads and the detector for the East and \nWest roads indicates that no vehicles are approaching.\n\nWhat happens when F=1?  First, the OR gate feeding into the timer's\nLD input produces a 1, meaning that the timer loads a new value\ninstead of counting down.  Second, the OR gate controlling the lower\nmux selects the A input.  In other words, the timer is reset to A\ncycles, corresponding to the initial value for the green light states.\nIn other words, the light stays green until vehicles approach on \nthe other road, plus A more cycles.\n\nUnfortunately, the signal F may also be 1 in the unused states of S,\nin which case the lights on both roads may remain red even though cars\nare waiting on one of the roads.  To avoid this behavior, we must be \nsure to initialize the state S to one of the six states in the\ndesired loop.\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of the FSM design?\n2. What are the inputs and outputs of the FSM?\n3. How does the timer work in the FSM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Analysis of a Stoplight Controller",
            "text": "{Analysis of a Stoplight Controller}\n\nIn this example, we begin with a digital FSM design and analyze it to\nunderstand how it works and to verify that its behavior is appropriate.\n\nThe FSM that we analyze has been designed to control the stoplights\nat the intersection of two roads.  For naming purposes, we assume that one\nof the roads runs East and West (EW), and the second runs North and \nSouth (NS).  \n\nThe stoplight controller has two inputs, each of which \nsenses vehicles approaching from either direction on one of the two roads.\nThe input V^=1 when a vehicle approaches from either the East or the\nWest, and the input V^=1 when a vehicle approaches from either the\nNorth or the South.  These inputs are also active when vehicles are stopped\nwaiting at the corresponding lights.\n\nAnother three inputs, A, B, and C, control the timing behavior of the\nsystem; we do not discuss them here except as variables.\n\n\nThe outputs of the controller consist of two {2-bit} values, \nL^ and L^, that specify the light colors for the two roads.\nIn particular, L^ controls the lights facing East and West, and\nL^ controls the lights facing North and South.  The meaning of these\noutputs is given in the table to the right.\n\n\n{c|c}\nL& light color \n0x& red\n10& yellow\n11& green\n\n\n\nLet's think about the basic operation of the controller.\n\nFor safety reasons, the controller must ensure that the lights on one\nor both roads are red at all times.  \n\nSimilarly, if a road has a green light, the controller should \nshow a yellow light before showing a red light to give drivers some\nwarning and allow them to slow down.\n\nFinally, for fairness, the controller should alternate green lights\nbetween the two roads.\n\nNow take a look at the logic diagram below.\n\nThe state of the FSM has been split into two pieces: a {3-bit} \nregister S and a {6-bit} timer.  The timer is simply a binary \ncounter that counts downward and produces an output of Z=1 when it \nreaches 0.  Notice that the register S only takes a new value\nwhen the timer reaches 0, and that the Z signal from the timer\nalso forces a new value to be loaded into the timer in the next \ncycle.  We can thus think of transitions in the FSM on a cycle by \ncycle basis as consisting of two types.  The first type simply\ncounts downward for a number of cycles while holding the register S\nconstant, while the second changes the value of S and sets the\ntimer in order to maintain the new value of S \nfor some number of cycles.\n\n\n\n3.45\n\n\nLet's look at the next-state logic for S, which feeds into the IN\ninputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice \nthat none of the inputs to the FSM directly affect these values.  The\nstates of S thus act like a counter.  By examining the connections,\nwe can derive equations for the next state and draw a transition\ndiagram, as shown to the right.\n\nAs the figure shows, there are six states in the loop defined by the \nnext-state logic, with the two remaining states converging into the\nloop after a single cycle.\n\nLet's now examine the outputs for each\nstate in order to understand how the stoplight sequencing\nworks.\n\nWe derive equations for the outputs that control the lights, as shown\nto the right, then calculate values and colors for each\nstate, as shown to the far right.  For completeness, the table \nincludes the states outside of the desired loop.  The \nlights are all red in both of these states, which is necessary for safety.\n\n\n{eqnarray*}\n\nS_2^+ &=& {S_2} + S_0\nS_1^+ &=& {S_2}  S_1\nS_0^+ &=& {S_2}\n{eqnarray*}\n\n{eqnarray*}\nL_1^ &=& S_2 S_1\nL_0^ &=& S_0\nL_1^ &=& S_2 {S_1}\nL_0^ &=& S_0\n{eqnarray*}\n\n\n\n{c|cc|cc}\n&&& EW& NS\n&&& light& light\nS& L^& L^& color& color \n000& 00& 00&    red&    red\n111& 11& 01&  green&    red\n110& 10& 00& yellow&    red\n010& 00& 00&    red&    red\n101& 01& 11&    red&  green\n100& 00& 10&    red& yellow \n001& 01& 01&    red&    red\n011& 01& 01&    red&    red\n\n\n\n\nNow let's think about how the timer works.  As we already noted, the\ntimer value is set whenever S enters a new state, but it can also be\nset under other conditions---in particular, by the signal F calculated\nat the bottom of the FSM logic diagram.  \n\n\nFor now, assume that F=0.  In this case, the timer is set only when\nthe state S changes, and we can find the duration of each state by\nanalyzing the muxes.  The bottom mux selects A when S_2=0, and \nselects the output of the top mux when S_2=1.  The top mux selects B\nwhen S_0=1, and selects C when S_0=0.  Combining these results,\nwe can calculate the duration of the next states of S when F=0, \nas shown in the table to the right.  We can then combine the next\nstate duration with our previous calculation of the state sequencing \n(also the order in the table) to obtain the durations of each state, also\nshown in the rightmost column of the table.\n\n\n{c|cc|cc}\n& EW& NS& next& current\n& light& light& state& state\nS& color& color& duration& duration \n000&    red&    red& A& C\n111&  green&    red& B& A\n110& yellow&    red& C& B\n010&    red&    red& A& C\n101&    red&  green& B& A\n100&    red& yellow& C& B \n001&    red&    red& A& ---\n011&    red&    red& A& ---\n\n\n\nWhat does F do?  Analyzing the gates that produce it gives \nF=S_1S_0{V^+{S_1}S_0{V^.  If we \nignore the two states outside of the main loop for S, the first term \nis 1 only when the lights are green on the East and West roads and the \ndetector for the North and South roads indicates that no vehicles are \napproaching.  Similarly, the second term is 1 only when the lights are \ngreen on the North and South roads and the detector for the East and \nWest roads indicates that no vehicles are approaching.\n\nWhat happens when F=1?  First, the OR gate feeding into the timer's\nLD input produces a 1, meaning that the timer loads a new value\ninstead of counting down.  Second, the OR gate controlling the lower\nmux selects the A input.  In other words, the timer is reset to A\ncycles, corresponding to the initial value for the green light states.\nIn other words, the light stays green until vehicles approach on \nthe other road, plus A more cycles.\n\nUnfortunately, the signal F may also be 1 in the unused states of S,\nin which case the lights on both roads may remain red even though cars\nare waiting on one of the roads.  To avoid this behavior, we must be \nsure to initialize the state S to one of the six states in the\ndesired loop.\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of the FSM design?\n2. What are the inputs and outputs of the FSM?\n3. How does the timer work in the FSM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Analysis of a Stoplight Controller",
            "text": "{Analysis of a Stoplight Controller}\n\nIn this example, we begin with a digital FSM design and analyze it to\nunderstand how it works and to verify that its behavior is appropriate.\n\nThe FSM that we analyze has been designed to control the stoplights\nat the intersection of two roads.  For naming purposes, we assume that one\nof the roads runs East and West (EW), and the second runs North and \nSouth (NS).  \n\nThe stoplight controller has two inputs, each of which \nsenses vehicles approaching from either direction on one of the two roads.\nThe input V^=1 when a vehicle approaches from either the East or the\nWest, and the input V^=1 when a vehicle approaches from either the\nNorth or the South.  These inputs are also active when vehicles are stopped\nwaiting at the corresponding lights.\n\nAnother three inputs, A, B, and C, control the timing behavior of the\nsystem; we do not discuss them here except as variables.\n\n\nThe outputs of the controller consist of two {2-bit} values, \nL^ and L^, that specify the light colors for the two roads.\nIn particular, L^ controls the lights facing East and West, and\nL^ controls the lights facing North and South.  The meaning of these\noutputs is given in the table to the right.\n\n\n{c|c}\nL& light color \n0x& red\n10& yellow\n11& green\n\n\n\nLet's think about the basic operation of the controller.\n\nFor safety reasons, the controller must ensure that the lights on one\nor both roads are red at all times.  \n\nSimilarly, if a road has a green light, the controller should \nshow a yellow light before showing a red light to give drivers some\nwarning and allow them to slow down.\n\nFinally, for fairness, the controller should alternate green lights\nbetween the two roads.\n\nNow take a look at the logic diagram below.\n\nThe state of the FSM has been split into two pieces: a {3-bit} \nregister S and a {6-bit} timer.  The timer is simply a binary \ncounter that counts downward and produces an output of Z=1 when it \nreaches 0.  Notice that the register S only takes a new value\nwhen the timer reaches 0, and that the Z signal from the timer\nalso forces a new value to be loaded into the timer in the next \ncycle.  We can thus think of transitions in the FSM on a cycle by \ncycle basis as consisting of two types.  The first type simply\ncounts downward for a number of cycles while holding the register S\nconstant, while the second changes the value of S and sets the\ntimer in order to maintain the new value of S \nfor some number of cycles.\n\n\n\n3.45\n\n\nLet's look at the next-state logic for S, which feeds into the IN\ninputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice \nthat none of the inputs to the FSM directly affect these values.  The\nstates of S thus act like a counter.  By examining the connections,\nwe can derive equations for the next state and draw a transition\ndiagram, as shown to the right.\n\nAs the figure shows, there are six states in the loop defined by the \nnext-state logic, with the two remaining states converging into the\nloop after a single cycle.\n\nLet's now examine the outputs for each\nstate in order to understand how the stoplight sequencing\nworks.\n\nWe derive equations for the outputs that control the lights, as shown\nto the right, then calculate values and colors for each\nstate, as shown to the far right.  For completeness, the table \nincludes the states outside of the desired loop.  The \nlights are all red in both of these states, which is necessary for safety.\n\n\n{eqnarray*}\n\nS_2^+ &=& {S_2} + S_0\nS_1^+ &=& {S_2}  S_1\nS_0^+ &=& {S_2}\n{eqnarray*}\n\n{eqnarray*}\nL_1^ &=& S_2 S_1\nL_0^ &=& S_0\nL_1^ &=& S_2 {S_1}\nL_0^ &=& S_0\n{eqnarray*}\n\n\n\n{c|cc|cc}\n&&& EW& NS\n&&& light& light\nS& L^& L^& color& color \n000& 00& 00&    red&    red\n111& 11& 01&  green&    red\n110& 10& 00& yellow&    red\n010& 00& 00&    red&    red\n101& 01& 11&    red&  green\n100& 00& 10&    red& yellow \n001& 01& 01&    red&    red\n011& 01& 01&    red&    red\n\n\n\n\nNow let's think about how the timer works.  As we already noted, the\ntimer value is set whenever S enters a new state, but it can also be\nset under other conditions---in particular, by the signal F calculated\nat the bottom of the FSM logic diagram.  \n\n\nFor now, assume that F=0.  In this case, the timer is set only when\nthe state S changes, and we can find the duration of each state by\nanalyzing the muxes.  The bottom mux selects A when S_2=0, and \nselects the output of the top mux when S_2=1.  The top mux selects B\nwhen S_0=1, and selects C when S_0=0.  Combining these results,\nwe can calculate the duration of the next states of S when F=0, \nas shown in the table to the right.  We can then combine the next\nstate duration with our previous calculation of the state sequencing \n(also the order in the table) to obtain the durations of each state, also\nshown in the rightmost column of the table.\n\n\n{c|cc|cc}\n& EW& NS& next& current\n& light& light& state& state\nS& color& color& duration& duration \n000&    red&    red& A& C\n111&  green&    red& B& A\n110& yellow&    red& C& B\n010&    red&    red& A& C\n101&    red&  green& B& A\n100&    red& yellow& C& B \n001&    red&    red& A& ---\n011&    red&    red& A& ---\n\n\n\nWhat does F do?  Analyzing the gates that produce it gives \nF=S_1S_0{V^+{S_1}S_0{V^.  If we \nignore the two states outside of the main loop for S, the first term \nis 1 only when the lights are green on the East and West roads and the \ndetector for the North and South roads indicates that no vehicles are \napproaching.  Similarly, the second term is 1 only when the lights are \ngreen on the North and South roads and the detector for the East and \nWest roads indicates that no vehicles are approaching.\n\nWhat happens when F=1?  First, the OR gate feeding into the timer's\nLD input produces a 1, meaning that the timer loads a new value\ninstead of counting down.  Second, the OR gate controlling the lower\nmux selects the A input.  In other words, the timer is reset to A\ncycles, corresponding to the initial value for the green light states.\nIn other words, the light stays green until vehicles approach on \nthe other road, plus A more cycles.\n\nUnfortunately, the signal F may also be 1 in the unused states of S,\nin which case the lights on both roads may remain red even though cars\nare waiting on one of the roads.  To avoid this behavior, we must be \nsure to initialize the state S to one of the six states in the\ndesired loop.\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of the FSM design?\n2. What are the inputs and outputs of the FSM?\n3. How does the timer work in the FSM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Analysis of a Stoplight Controller",
            "text": "{Analysis of a Stoplight Controller}\n\nIn this example, we begin with a digital FSM design and analyze it to\nunderstand how it works and to verify that its behavior is appropriate.\n\nThe FSM that we analyze has been designed to control the stoplights\nat the intersection of two roads.  For naming purposes, we assume that one\nof the roads runs East and West (EW), and the second runs North and \nSouth (NS).  \n\nThe stoplight controller has two inputs, each of which \nsenses vehicles approaching from either direction on one of the two roads.\nThe input V^=1 when a vehicle approaches from either the East or the\nWest, and the input V^=1 when a vehicle approaches from either the\nNorth or the South.  These inputs are also active when vehicles are stopped\nwaiting at the corresponding lights.\n\nAnother three inputs, A, B, and C, control the timing behavior of the\nsystem; we do not discuss them here except as variables.\n\n\nThe outputs of the controller consist of two {2-bit} values, \nL^ and L^, that specify the light colors for the two roads.\nIn particular, L^ controls the lights facing East and West, and\nL^ controls the lights facing North and South.  The meaning of these\noutputs is given in the table to the right.\n\n\n{c|c}\nL& light color \n0x& red\n10& yellow\n11& green\n\n\n\nLet's think about the basic operation of the controller.\n\nFor safety reasons, the controller must ensure that the lights on one\nor both roads are red at all times.  \n\nSimilarly, if a road has a green light, the controller should \nshow a yellow light before showing a red light to give drivers some\nwarning and allow them to slow down.\n\nFinally, for fairness, the controller should alternate green lights\nbetween the two roads.\n\nNow take a look at the logic diagram below.\n\nThe state of the FSM has been split into two pieces: a {3-bit} \nregister S and a {6-bit} timer.  The timer is simply a binary \ncounter that counts downward and produces an output of Z=1 when it \nreaches 0.  Notice that the register S only takes a new value\nwhen the timer reaches 0, and that the Z signal from the timer\nalso forces a new value to be loaded into the timer in the next \ncycle.  We can thus think of transitions in the FSM on a cycle by \ncycle basis as consisting of two types.  The first type simply\ncounts downward for a number of cycles while holding the register S\nconstant, while the second changes the value of S and sets the\ntimer in order to maintain the new value of S \nfor some number of cycles.\n\n\n\n3.45\n\n\nLet's look at the next-state logic for S, which feeds into the IN\ninputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice \nthat none of the inputs to the FSM directly affect these values.  The\nstates of S thus act like a counter.  By examining the connections,\nwe can derive equations for the next state and draw a transition\ndiagram, as shown to the right.\n\nAs the figure shows, there are six states in the loop defined by the \nnext-state logic, with the two remaining states converging into the\nloop after a single cycle.\n\nLet's now examine the outputs for each\nstate in order to understand how the stoplight sequencing\nworks.\n\nWe derive equations for the outputs that control the lights, as shown\nto the right, then calculate values and colors for each\nstate, as shown to the far right.  For completeness, the table \nincludes the states outside of the desired loop.  The \nlights are all red in both of these states, which is necessary for safety.\n\n\n{eqnarray*}\n\nS_2^+ &=& {S_2} + S_0\nS_1^+ &=& {S_2}  S_1\nS_0^+ &=& {S_2}\n{eqnarray*}\n\n{eqnarray*}\nL_1^ &=& S_2 S_1\nL_0^ &=& S_0\nL_1^ &=& S_2 {S_1}\nL_0^ &=& S_0\n{eqnarray*}\n\n\n\n{c|cc|cc}\n&&& EW& NS\n&&& light& light\nS& L^& L^& color& color \n000& 00& 00&    red&    red\n111& 11& 01&  green&    red\n110& 10& 00& yellow&    red\n010& 00& 00&    red&    red\n101& 01& 11&    red&  green\n100& 00& 10&    red& yellow \n001& 01& 01&    red&    red\n011& 01& 01&    red&    red\n\n\n\n\nNow let's think about how the timer works.  As we already noted, the\ntimer value is set whenever S enters a new state, but it can also be\nset under other conditions---in particular, by the signal F calculated\nat the bottom of the FSM logic diagram.  \n\n\nFor now, assume that F=0.  In this case, the timer is set only when\nthe state S changes, and we can find the duration of each state by\nanalyzing the muxes.  The bottom mux selects A when S_2=0, and \nselects the output of the top mux when S_2=1.  The top mux selects B\nwhen S_0=1, and selects C when S_0=0.  Combining these results,\nwe can calculate the duration of the next states of S when F=0, \nas shown in the table to the right.  We can then combine the next\nstate duration with our previous calculation of the state sequencing \n(also the order in the table) to obtain the durations of each state, also\nshown in the rightmost column of the table.\n\n\n{c|cc|cc}\n& EW& NS& next& current\n& light& light& state& state\nS& color& color& duration& duration \n000&    red&    red& A& C\n111&  green&    red& B& A\n110& yellow&    red& C& B\n010&    red&    red& A& C\n101&    red&  green& B& A\n100&    red& yellow& C& B \n001&    red&    red& A& ---\n011&    red&    red& A& ---\n\n\n\nWhat does F do?  Analyzing the gates that produce it gives \nF=S_1S_0{V^+{S_1}S_0{V^.  If we \nignore the two states outside of the main loop for S, the first term \nis 1 only when the lights are green on the East and West roads and the \ndetector for the North and South roads indicates that no vehicles are \napproaching.  Similarly, the second term is 1 only when the lights are \ngreen on the North and South roads and the detector for the East and \nWest roads indicates that no vehicles are approaching.\n\nWhat happens when F=1?  First, the OR gate feeding into the timer's\nLD input produces a 1, meaning that the timer loads a new value\ninstead of counting down.  Second, the OR gate controlling the lower\nmux selects the A input.  In other words, the timer is reset to A\ncycles, corresponding to the initial value for the green light states.\nIn other words, the light stays green until vehicles approach on \nthe other road, plus A more cycles.\n\nUnfortunately, the signal F may also be 1 in the unused states of S,\nin which case the lights on both roads may remain red even though cars\nare waiting on one of the roads.  To avoid this behavior, we must be \nsure to initialize the state S to one of the six states in the\ndesired loop.\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of the FSM design?\n2. What are the inputs and outputs of the FSM?\n3. How does the timer work in the FSM?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "State Representation and Logic Expressions",
            "text": "{State Representation and Logic Expressions}\n\nLet's think about the representation for the FSM states.  The FSM has \nfive states, so we could use as few as three flip-flops.  Instead, we choose\nto use a { one-hot encoding}, in which any valid bit pattern has exactly\none 1 bit.  In other words, we use five flip-flops instead of three,\nand our states are represented with the bit patterns 10000, 01000, 00100,\n00010, and 00001.\n\nThe table below shows the mapping from each high-level state to \nboth the five-bit encoding for the state as well as the six control signals \nneeded for the datapath.  For each state, the values of the control signals\ncan be found by examining the actions necessary in that state.\n\n{\n{|c|c|cccccc|}\nstate& { S_4S_3S_2S_1S_0}& { IDX.RST}& { IDX.CNT}& { MIN.LD}& { A.LD}& { B.LD}& { CNT.RST} \n{ WAIT}& { 1 0 0 0 0}& 1& 0& 0& 0& 0& 0\n{ INIT}& { 0 1 0 0 0}& 0& 1& 1& 0& 0& 0\n{ PREP}& { 0 0 1 0 0}& 0& 0& 0& 1& 1& 1\n{ COMPARE}& { 0 0 0 1 0}& 0& 0& 0& 0& 0& 0\n{ COPY}& { 0 0 0 0 1}& 0& 1& { THEN}& 0& 0& 0 \n{}\n\n}\n\nThe { WAIT} state needs to set { IDX} to 0 but need not affect \nother register or counter values, so { WAIT} produces a 1 only for\n{ IDX.RST}.  The { INIT} state needs to load { values[0]} into \nthe { MIN} register while simultaneously incrementing the { IDX}\ncounter (from 0 to 1), so { INIT} produces 1s for { IDX.CNT}\nand { MIN.LD}.  The { PREP} state loads both shift registers\nand resets the counter { CNT} by producing 1s for { A.LD},\n{ B.LD}, and { CNT.RST}.  The { COMPARE} state does not\nchange any register values, so it produces all 0s.  Finally, the { COPY}\nstate increments the { IDX} counter while simultaneously loading a\nnew value into the { MIN} register.  The { COPY} state produces 1\nfor { IDX.CNT}, but must use the signal { THEN} coming from the\ndatapath to decide whether or not { MIN} is loaded.\n\n\n\nThe advantage of a one-hot encoding becomes obvious when we write\nequations for the six control signals and the next-state logic, as shown\nto the right.  \n\nImplementing the logic to complete our design now requires only a handful \nof small logic gates.\n\n\n{eqnarray*}\n{ IDX.RST} & = & { S}_4\n{ IDX.CNT} & = & { S}_3 + { S}_0\n{ MIN.LD} & = & { S}_3 + { S}_0  { THEN}\n{ A.LD} & = & { S}_2\n{ B.LD} & = & { S}_2\n{ CNT.RST} & = & { S}_2\n{eqnarray*}\n\n\n{eqnarray*}\n{ S}_4^+ & = & { S}_4  { START} + { S}_0  { DONE}\n{ S}_3^+ & = & { S}_4  { START}\n{ S}_2^+ & = & { S}_3 + { S}_0  { DONE}\n{ S}_1^+ & = & { S}_2 + { S}_1  { LAST}\n{ S}_0^+ & = & { S}_1  { LAST}\n{eqnarray*}\n\n\nNotice that the terms in each control signal can be read directly from \nthe rows of the state table and OR'd together.  The terms in each of the\nnext-state equations represent the incoming arcs for the corresponding\nstate.  For example, the { WAIT} state has one self-loop (the first\nterm) and a transition arc coming from the { COPY} state when the\nloop is done.\n\nThese expressions complete our design.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the advantage of using a one-hot encoding for the FSM states?\n2. How would the design be different if a different encoding was used?\n3. What are the control signals used in each state?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "State Representation and Logic Expressions",
            "text": "{State Representation and Logic Expressions}\n\nLet's think about the representation for the FSM states.  The FSM has \nfive states, so we could use as few as three flip-flops.  Instead, we choose\nto use a { one-hot encoding}, in which any valid bit pattern has exactly\none 1 bit.  In other words, we use five flip-flops instead of three,\nand our states are represented with the bit patterns 10000, 01000, 00100,\n00010, and 00001.\n\nThe table below shows the mapping from each high-level state to \nboth the five-bit encoding for the state as well as the six control signals \nneeded for the datapath.  For each state, the values of the control signals\ncan be found by examining the actions necessary in that state.\n\n{\n{|c|c|cccccc|}\nstate& { S_4S_3S_2S_1S_0}& { IDX.RST}& { IDX.CNT}& { MIN.LD}& { A.LD}& { B.LD}& { CNT.RST} \n{ WAIT}& { 1 0 0 0 0}& 1& 0& 0& 0& 0& 0\n{ INIT}& { 0 1 0 0 0}& 0& 1& 1& 0& 0& 0\n{ PREP}& { 0 0 1 0 0}& 0& 0& 0& 1& 1& 1\n{ COMPARE}& { 0 0 0 1 0}& 0& 0& 0& 0& 0& 0\n{ COPY}& { 0 0 0 0 1}& 0& 1& { THEN}& 0& 0& 0 \n{}\n\n}\n\nThe { WAIT} state needs to set { IDX} to 0 but need not affect \nother register or counter values, so { WAIT} produces a 1 only for\n{ IDX.RST}.  The { INIT} state needs to load { values[0]} into \nthe { MIN} register while simultaneously incrementing the { IDX}\ncounter (from 0 to 1), so { INIT} produces 1s for { IDX.CNT}\nand { MIN.LD}.  The { PREP} state loads both shift registers\nand resets the counter { CNT} by producing 1s for { A.LD},\n{ B.LD}, and { CNT.RST}.  The { COMPARE} state does not\nchange any register values, so it produces all 0s.  Finally, the { COPY}\nstate increments the { IDX} counter while simultaneously loading a\nnew value into the { MIN} register.  The { COPY} state produces 1\nfor { IDX.CNT}, but must use the signal { THEN} coming from the\ndatapath to decide whether or not { MIN} is loaded.\n\n\n\nThe advantage of a one-hot encoding becomes obvious when we write\nequations for the six control signals and the next-state logic, as shown\nto the right.  \n\nImplementing the logic to complete our design now requires only a handful \nof small logic gates.\n\n\n{eqnarray*}\n{ IDX.RST} & = & { S}_4\n{ IDX.CNT} & = & { S}_3 + { S}_0\n{ MIN.LD} & = & { S}_3 + { S}_0  { THEN}\n{ A.LD} & = & { S}_2\n{ B.LD} & = & { S}_2\n{ CNT.RST} & = & { S}_2\n{eqnarray*}\n\n\n{eqnarray*}\n{ S}_4^+ & = & { S}_4  { START} + { S}_0  { DONE}\n{ S}_3^+ & = & { S}_4  { START}\n{ S}_2^+ & = & { S}_3 + { S}_0  { DONE}\n{ S}_1^+ & = & { S}_2 + { S}_1  { LAST}\n{ S}_0^+ & = & { S}_1  { LAST}\n{eqnarray*}\n\n\nNotice that the terms in each control signal can be read directly from \nthe rows of the state table and OR'd together.  The terms in each of the\nnext-state equations represent the incoming arcs for the corresponding\nstate.  For example, the { WAIT} state has one self-loop (the first\nterm) and a transition arc coming from the { COPY} state when the\nloop is done.\n\nThese expressions complete our design.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the advantage of using a one-hot encoding for the FSM states?\n2. How would the design be different if a different encoding was used?\n3. What are the control signals used in each state?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "State Representation and Logic Expressions",
            "text": "{State Representation and Logic Expressions}\n\nLet's think about the representation for the FSM states.  The FSM has \nfive states, so we could use as few as three flip-flops.  Instead, we choose\nto use a { one-hot encoding}, in which any valid bit pattern has exactly\none 1 bit.  In other words, we use five flip-flops instead of three,\nand our states are represented with the bit patterns 10000, 01000, 00100,\n00010, and 00001.\n\nThe table below shows the mapping from each high-level state to \nboth the five-bit encoding for the state as well as the six control signals \nneeded for the datapath.  For each state, the values of the control signals\ncan be found by examining the actions necessary in that state.\n\n{\n{|c|c|cccccc|}\nstate& { S_4S_3S_2S_1S_0}& { IDX.RST}& { IDX.CNT}& { MIN.LD}& { A.LD}& { B.LD}& { CNT.RST} \n{ WAIT}& { 1 0 0 0 0}& 1& 0& 0& 0& 0& 0\n{ INIT}& { 0 1 0 0 0}& 0& 1& 1& 0& 0& 0\n{ PREP}& { 0 0 1 0 0}& 0& 0& 0& 1& 1& 1\n{ COMPARE}& { 0 0 0 1 0}& 0& 0& 0& 0& 0& 0\n{ COPY}& { 0 0 0 0 1}& 0& 1& { THEN}& 0& 0& 0 \n{}\n\n}\n\nThe { WAIT} state needs to set { IDX} to 0 but need not affect \nother register or counter values, so { WAIT} produces a 1 only for\n{ IDX.RST}.  The { INIT} state needs to load { values[0]} into \nthe { MIN} register while simultaneously incrementing the { IDX}\ncounter (from 0 to 1), so { INIT} produces 1s for { IDX.CNT}\nand { MIN.LD}.  The { PREP} state loads both shift registers\nand resets the counter { CNT} by producing 1s for { A.LD},\n{ B.LD}, and { CNT.RST}.  The { COMPARE} state does not\nchange any register values, so it produces all 0s.  Finally, the { COPY}\nstate increments the { IDX} counter while simultaneously loading a\nnew value into the { MIN} register.  The { COPY} state produces 1\nfor { IDX.CNT}, but must use the signal { THEN} coming from the\ndatapath to decide whether or not { MIN} is loaded.\n\n\n\nThe advantage of a one-hot encoding becomes obvious when we write\nequations for the six control signals and the next-state logic, as shown\nto the right.  \n\nImplementing the logic to complete our design now requires only a handful \nof small logic gates.\n\n\n{eqnarray*}\n{ IDX.RST} & = & { S}_4\n{ IDX.CNT} & = & { S}_3 + { S}_0\n{ MIN.LD} & = & { S}_3 + { S}_0  { THEN}\n{ A.LD} & = & { S}_2\n{ B.LD} & = & { S}_2\n{ CNT.RST} & = & { S}_2\n{eqnarray*}\n\n\n{eqnarray*}\n{ S}_4^+ & = & { S}_4  { START} + { S}_0  { DONE}\n{ S}_3^+ & = & { S}_4  { START}\n{ S}_2^+ & = & { S}_3 + { S}_0  { DONE}\n{ S}_1^+ & = & { S}_2 + { S}_1  { LAST}\n{ S}_0^+ & = & { S}_1  { LAST}\n{eqnarray*}\n\n\nNotice that the terms in each control signal can be read directly from \nthe rows of the state table and OR'd together.  The terms in each of the\nnext-state equations represent the incoming arcs for the corresponding\nstate.  For example, the { WAIT} state has one self-loop (the first\nterm) and a transition arc coming from the { COPY} state when the\nloop is done.\n\nThese expressions complete our design.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the advantage of using a one-hot encoding for the FSM states?\n2. How would the design be different if a different encoding was used?\n3. What are the control signals used in each state?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "State Representation and Logic Expressions",
            "text": "{State Representation and Logic Expressions}\n\nLet's think about the representation for the FSM states.  The FSM has \nfive states, so we could use as few as three flip-flops.  Instead, we choose\nto use a { one-hot encoding}, in which any valid bit pattern has exactly\none 1 bit.  In other words, we use five flip-flops instead of three,\nand our states are represented with the bit patterns 10000, 01000, 00100,\n00010, and 00001.\n\nThe table below shows the mapping from each high-level state to \nboth the five-bit encoding for the state as well as the six control signals \nneeded for the datapath.  For each state, the values of the control signals\ncan be found by examining the actions necessary in that state.\n\n{\n{|c|c|cccccc|}\nstate& { S_4S_3S_2S_1S_0}& { IDX.RST}& { IDX.CNT}& { MIN.LD}& { A.LD}& { B.LD}& { CNT.RST} \n{ WAIT}& { 1 0 0 0 0}& 1& 0& 0& 0& 0& 0\n{ INIT}& { 0 1 0 0 0}& 0& 1& 1& 0& 0& 0\n{ PREP}& { 0 0 1 0 0}& 0& 0& 0& 1& 1& 1\n{ COMPARE}& { 0 0 0 1 0}& 0& 0& 0& 0& 0& 0\n{ COPY}& { 0 0 0 0 1}& 0& 1& { THEN}& 0& 0& 0 \n{}\n\n}\n\nThe { WAIT} state needs to set { IDX} to 0 but need not affect \nother register or counter values, so { WAIT} produces a 1 only for\n{ IDX.RST}.  The { INIT} state needs to load { values[0]} into \nthe { MIN} register while simultaneously incrementing the { IDX}\ncounter (from 0 to 1), so { INIT} produces 1s for { IDX.CNT}\nand { MIN.LD}.  The { PREP} state loads both shift registers\nand resets the counter { CNT} by producing 1s for { A.LD},\n{ B.LD}, and { CNT.RST}.  The { COMPARE} state does not\nchange any register values, so it produces all 0s.  Finally, the { COPY}\nstate increments the { IDX} counter while simultaneously loading a\nnew value into the { MIN} register.  The { COPY} state produces 1\nfor { IDX.CNT}, but must use the signal { THEN} coming from the\ndatapath to decide whether or not { MIN} is loaded.\n\n\n\nThe advantage of a one-hot encoding becomes obvious when we write\nequations for the six control signals and the next-state logic, as shown\nto the right.  \n\nImplementing the logic to complete our design now requires only a handful \nof small logic gates.\n\n\n{eqnarray*}\n{ IDX.RST} & = & { S}_4\n{ IDX.CNT} & = & { S}_3 + { S}_0\n{ MIN.LD} & = & { S}_3 + { S}_0  { THEN}\n{ A.LD} & = & { S}_2\n{ B.LD} & = & { S}_2\n{ CNT.RST} & = & { S}_2\n{eqnarray*}\n\n\n{eqnarray*}\n{ S}_4^+ & = & { S}_4  { START} + { S}_0  { DONE}\n{ S}_3^+ & = & { S}_4  { START}\n{ S}_2^+ & = & { S}_3 + { S}_0  { DONE}\n{ S}_1^+ & = & { S}_2 + { S}_1  { LAST}\n{ S}_0^+ & = & { S}_1  { LAST}\n{eqnarray*}\n\n\nNotice that the terms in each control signal can be read directly from \nthe rows of the state table and OR'd together.  The terms in each of the\nnext-state equations represent the incoming arcs for the corresponding\nstate.  For example, the { WAIT} state has one self-loop (the first\nterm) and a transition arc coming from the { COPY} state when the\nloop is done.\n\nThese expressions complete our design.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the advantage of using a one-hot encoding for the FSM states?\n2. How would the design be different if a different encoding was used?\n3. What are the control signals used in each state?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "State Representation and Logic Expressions",
            "text": "{State Representation and Logic Expressions}\n\nLet's think about the representation for the FSM states.  The FSM has \nfive states, so we could use as few as three flip-flops.  Instead, we choose\nto use a { one-hot encoding}, in which any valid bit pattern has exactly\none 1 bit.  In other words, we use five flip-flops instead of three,\nand our states are represented with the bit patterns 10000, 01000, 00100,\n00010, and 00001.\n\nThe table below shows the mapping from each high-level state to \nboth the five-bit encoding for the state as well as the six control signals \nneeded for the datapath.  For each state, the values of the control signals\ncan be found by examining the actions necessary in that state.\n\n{\n{|c|c|cccccc|}\nstate& { S_4S_3S_2S_1S_0}& { IDX.RST}& { IDX.CNT}& { MIN.LD}& { A.LD}& { B.LD}& { CNT.RST} \n{ WAIT}& { 1 0 0 0 0}& 1& 0& 0& 0& 0& 0\n{ INIT}& { 0 1 0 0 0}& 0& 1& 1& 0& 0& 0\n{ PREP}& { 0 0 1 0 0}& 0& 0& 0& 1& 1& 1\n{ COMPARE}& { 0 0 0 1 0}& 0& 0& 0& 0& 0& 0\n{ COPY}& { 0 0 0 0 1}& 0& 1& { THEN}& 0& 0& 0 \n{}\n\n}\n\nThe { WAIT} state needs to set { IDX} to 0 but need not affect \nother register or counter values, so { WAIT} produces a 1 only for\n{ IDX.RST}.  The { INIT} state needs to load { values[0]} into \nthe { MIN} register while simultaneously incrementing the { IDX}\ncounter (from 0 to 1), so { INIT} produces 1s for { IDX.CNT}\nand { MIN.LD}.  The { PREP} state loads both shift registers\nand resets the counter { CNT} by producing 1s for { A.LD},\n{ B.LD}, and { CNT.RST}.  The { COMPARE} state does not\nchange any register values, so it produces all 0s.  Finally, the { COPY}\nstate increments the { IDX} counter while simultaneously loading a\nnew value into the { MIN} register.  The { COPY} state produces 1\nfor { IDX.CNT}, but must use the signal { THEN} coming from the\ndatapath to decide whether or not { MIN} is loaded.\n\n\n\nThe advantage of a one-hot encoding becomes obvious when we write\nequations for the six control signals and the next-state logic, as shown\nto the right.  \n\nImplementing the logic to complete our design now requires only a handful \nof small logic gates.\n\n\n{eqnarray*}\n{ IDX.RST} & = & { S}_4\n{ IDX.CNT} & = & { S}_3 + { S}_0\n{ MIN.LD} & = & { S}_3 + { S}_0  { THEN}\n{ A.LD} & = & { S}_2\n{ B.LD} & = & { S}_2\n{ CNT.RST} & = & { S}_2\n{eqnarray*}\n\n\n{eqnarray*}\n{ S}_4^+ & = & { S}_4  { START} + { S}_0  { DONE}\n{ S}_3^+ & = & { S}_4  { START}\n{ S}_2^+ & = & { S}_3 + { S}_0  { DONE}\n{ S}_1^+ & = & { S}_2 + { S}_1  { LAST}\n{ S}_0^+ & = & { S}_1  { LAST}\n{eqnarray*}\n\n\nNotice that the terms in each control signal can be read directly from \nthe rows of the state table and OR'd together.  The terms in each of the\nnext-state equations represent the incoming arcs for the corresponding\nstate.  For example, the { WAIT} state has one self-loop (the first\nterm) and a transition arc coming from the { COPY} state when the\nloop is done.\n\nThese expressions complete our design.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the advantage of using a one-hot encoding for the FSM states?\n2. How would the design be different if a different encoding was used?\n3. What are the control signals used in each state?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "State Representation and Logic Expressions",
            "text": "{State Representation and Logic Expressions}\n\nLet's think about the representation for the FSM states.  The FSM has \nfive states, so we could use as few as three flip-flops.  Instead, we choose\nto use a { one-hot encoding}, in which any valid bit pattern has exactly\none 1 bit.  In other words, we use five flip-flops instead of three,\nand our states are represented with the bit patterns 10000, 01000, 00100,\n00010, and 00001.\n\nThe table below shows the mapping from each high-level state to \nboth the five-bit encoding for the state as well as the six control signals \nneeded for the datapath.  For each state, the values of the control signals\ncan be found by examining the actions necessary in that state.\n\n{\n{|c|c|cccccc|}\nstate& { S_4S_3S_2S_1S_0}& { IDX.RST}& { IDX.CNT}& { MIN.LD}& { A.LD}& { B.LD}& { CNT.RST} \n{ WAIT}& { 1 0 0 0 0}& 1& 0& 0& 0& 0& 0\n{ INIT}& { 0 1 0 0 0}& 0& 1& 1& 0& 0& 0\n{ PREP}& { 0 0 1 0 0}& 0& 0& 0& 1& 1& 1\n{ COMPARE}& { 0 0 0 1 0}& 0& 0& 0& 0& 0& 0\n{ COPY}& { 0 0 0 0 1}& 0& 1& { THEN}& 0& 0& 0 \n{}\n\n}\n\nThe { WAIT} state needs to set { IDX} to 0 but need not affect \nother register or counter values, so { WAIT} produces a 1 only for\n{ IDX.RST}.  The { INIT} state needs to load { values[0]} into \nthe { MIN} register while simultaneously incrementing the { IDX}\ncounter (from 0 to 1), so { INIT} produces 1s for { IDX.CNT}\nand { MIN.LD}.  The { PREP} state loads both shift registers\nand resets the counter { CNT} by producing 1s for { A.LD},\n{ B.LD}, and { CNT.RST}.  The { COMPARE} state does not\nchange any register values, so it produces all 0s.  Finally, the { COPY}\nstate increments the { IDX} counter while simultaneously loading a\nnew value into the { MIN} register.  The { COPY} state produces 1\nfor { IDX.CNT}, but must use the signal { THEN} coming from the\ndatapath to decide whether or not { MIN} is loaded.\n\n\n\nThe advantage of a one-hot encoding becomes obvious when we write\nequations for the six control signals and the next-state logic, as shown\nto the right.  \n\nImplementing the logic to complete our design now requires only a handful \nof small logic gates.\n\n\n{eqnarray*}\n{ IDX.RST} & = & { S}_4\n{ IDX.CNT} & = & { S}_3 + { S}_0\n{ MIN.LD} & = & { S}_3 + { S}_0  { THEN}\n{ A.LD} & = & { S}_2\n{ B.LD} & = & { S}_2\n{ CNT.RST} & = & { S}_2\n{eqnarray*}\n\n\n{eqnarray*}\n{ S}_4^+ & = & { S}_4  { START} + { S}_0  { DONE}\n{ S}_3^+ & = & { S}_4  { START}\n{ S}_2^+ & = & { S}_3 + { S}_0  { DONE}\n{ S}_1^+ & = & { S}_2 + { S}_1  { LAST}\n{ S}_0^+ & = & { S}_1  { LAST}\n{eqnarray*}\n\n\nNotice that the terms in each control signal can be read directly from \nthe rows of the state table and OR'd together.  The terms in each of the\nnext-state equations represent the incoming arcs for the corresponding\nstate.  For example, the { WAIT} state has one self-loop (the first\nterm) and a transition arc coming from the { COPY} state when the\nloop is done.\n\nThese expressions complete our design.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the advantage of using a one-hot encoding for the FSM states?\n2. How would the design be different if a different encoding was used?\n3. What are the control signals used in each state?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Physical Design, Sensors, and Timing",
            "text": "{Physical Design, Sensors, and Timing}\n\n\nTo begin, let's review the FSM that we designed earlier for keyless \nentry.  The state transition diagram for our design is replicated to \nthe right.\n\nThe four states are labeled with state bits and output bits,\nS_1S_0/DRA, where D indicates that the driver's door should\nbe unlocked, R indicates that the rest of the doors should be\nunlocked, and A indicates that the alarm should be on.\n\nTransition arcs in the diagram are labeled with concise versions of \nthe inputs ULP (using don't cares), where U represents an unlock\nbutton, L represents a lock button, and P represents a panic \nbutton.\n\nIn this design, once a user presses the panic button P, the alarm\nsounds until the user presses the\n\n\n{file=part3/figs/ke-trans-diag-brief.eps,width=4.2in}\n\n\nlock button L to turn it off.\nInstead of sounding the alarm indefinitely, we might want to turn\nthe alarm off after a fixed amount of time.  In other words, after \nthe system has been in the ALARM state for, say, thirty or sixty seconds,\nwe might want to move back to the LOCKED state even if the user has\nnot pushed the lock button.  The blue annotation in the diagram indicates\nthe arc that we must adjust.  But thirty or sixty seconds is a large \nnumber of clock cycles, and our FSM must keep track of the time.\nDo we need to draw all of the states?\n\nInstead of following the design process that we outlined earlier, let's\nthink about how we can modify our existing design to incorporate the new\nfunctionality.  In order to keep track of time, we use a binary counter.\n\nLet's say that we want our timeout to be T cycles.\n\nWhen we enter the alarm state, we want to set the counter's value \nto T-1, then let the counter count down until it reaches 0, at \nwhich point a timeout occurs.\n\nTo load the initial value, our counter should have a parallel load \ncapability that sets the counter value when input LD=1.  When LD=0,\nthe counter counts down. \n\nThe counter also has an output Z that indicates that the counter's \nvalue is currently zero, which we can use to indicate a timeout on\nthe alarm.\n\nYou should be able to build such a counter based on what you have learned\nearlier in the class.  Here, we will assume that we can just make use of\nit.\n\nHow many bits do we need in our counter?  The answer depends on T.\nIf we add the counter to our design, the state of the counter is \ntechnically part of the state of our FSM, but we can treat it\nsomewhat abstractly.  For example, we only plan to make use of the \ncounter value in the ALARM state, so we ignore the counter bits in the\nthree other states.  In other words, S_1S_0=10 means that the system \nis in the LOCKED state regardless of the counter's value.\n\n\nWe expand the ALARM state into T separate states based on the value\nof the counter.  As shown to the right, we name the states ALARM(1) \nthrough ALARM(T).  All of these alarm states use S_1S_0=01, but\nthey can be differentiated using a ``timer'' (the counter value).\n\nWe need to make design decisions about how the arcs entering and\nleaving the ALARM state in our original design should be used once\nwe have incorporated the timeout.  As a first step, we decide that\nall arcs entering ALARM from other states now enter ALARM(1).  \nSimilarly, if the user presses the panic button P in any of the\nALARM(t) states, the system returns to ALARM(1).  Effectively, \npressing the panic button resets the timer.\n\nThe only arc leaving the ALARM state goes to the LOCKED state on \nULP=x10.  We replicate this arc for all ALARM(t) states: the\nuser can push the lock button at any time to silence the alarm.\n\nFinally, the self-loop back to the ALARM state on ULP=x00 becomes\nthe countdown arcs in our expanded states, taking ALARM(t) to ALARM(t+1),\nand ALARM(T) to LOCKED.\n\nNow that we have a complete specification for the extended design, we\ncan implement it.  We want to reuse our original design as much as possible,\nbut we have three new features that must be considered.  First, when\nwe enter the ALARM(1) state, we need to set the counter value to T-1.\nSecond, we need the counter value to count downward while in the ALARM\nstate.  Finally, we need to move back to the LOCKED state when a timeout\noccurs---that is, when the counter reaches zero.\n\n\n{file=part3/figs/ke-alarm-expansion.eps,width=1.75in}\n\n\nThe first problem is fairly easy.  Our counter supports parallel load,\nand the only value that we need to load is T-1, so we apply the constant\nbit pattern for T-1 to the load inputs and raise the LD input whenever\nwe enter the ALARM(1) state.  In our original design, we chose to enter\nthe ALARM state whenever the user pressed P, regardless of the other\nbuttons.  Hence we can connect P directly to our counter's LD input.\n\nThe second problem is handled by the counter's countdown functionality.\nIn the ALARM(t) states, the counter will count down each cycle, moving\nthe system from ALARM(t) to ALARM(t+1).\n\nThe last problem is slightly trickier, since we need to change S_1S_0.\nNotice that S_1S_0=01 for the ALARM state and S_1S_0=00 for the LOCKED\nstate.  Thus, we need only force S_0 to 0 when a timeout occurs.\nWe can use a single {2-to-1} multiplexer for this purpose.  The\n``0'' input of the mux comes from the original S_0^+ logic, and the\n``1'' input is a constant 0.  All other state logic remains unchanged.  \nWhen does a timeout occur? \n\nFirst, we must be in the ALARM(T) state, so S_1S_0=01 and the \ncounter's Z output is raised.  Second, the input combination must\nbe ULP=xx0---notice that both ULP=x00 and ULP=x10 return to \nLOCKED from ALARM(T).  A single, four-input AND gate thus suffices to\nobtain the timeout signal, {S_1}S_0Z, which we connect \nto the select input of the mux between the S_0^+ logic and the\nS_0 flip-flop.\n\nThe extension thus requires only a counter, a mux, and a gate, as shown below.\n\n{{file=part3/figs/ke-alarm-exp-impl.eps,width=2.65in}}\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of the counter in this design?\n2. How does the counter determine when a timeout has occurred?\n3. What is the purpose of the mux in this design?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Physical Design, Sensors, and Timing",
            "text": "{Physical Design, Sensors, and Timing}\n\n\nTo begin, let's review the FSM that we designed earlier for keyless \nentry.  The state transition diagram for our design is replicated to \nthe right.\n\nThe four states are labeled with state bits and output bits,\nS_1S_0/DRA, where D indicates that the driver's door should\nbe unlocked, R indicates that the rest of the doors should be\nunlocked, and A indicates that the alarm should be on.\n\nTransition arcs in the diagram are labeled with concise versions of \nthe inputs ULP (using don't cares), where U represents an unlock\nbutton, L represents a lock button, and P represents a panic \nbutton.\n\nIn this design, once a user presses the panic button P, the alarm\nsounds until the user presses the\n\n\n{file=part3/figs/ke-trans-diag-brief.eps,width=4.2in}\n\n\nlock button L to turn it off.\nInstead of sounding the alarm indefinitely, we might want to turn\nthe alarm off after a fixed amount of time.  In other words, after \nthe system has been in the ALARM state for, say, thirty or sixty seconds,\nwe might want to move back to the LOCKED state even if the user has\nnot pushed the lock button.  The blue annotation in the diagram indicates\nthe arc that we must adjust.  But thirty or sixty seconds is a large \nnumber of clock cycles, and our FSM must keep track of the time.\nDo we need to draw all of the states?\n\nInstead of following the design process that we outlined earlier, let's\nthink about how we can modify our existing design to incorporate the new\nfunctionality.  In order to keep track of time, we use a binary counter.\n\nLet's say that we want our timeout to be T cycles.\n\nWhen we enter the alarm state, we want to set the counter's value \nto T-1, then let the counter count down until it reaches 0, at \nwhich point a timeout occurs.\n\nTo load the initial value, our counter should have a parallel load \ncapability that sets the counter value when input LD=1.  When LD=0,\nthe counter counts down. \n\nThe counter also has an output Z that indicates that the counter's \nvalue is currently zero, which we can use to indicate a timeout on\nthe alarm.\n\nYou should be able to build such a counter based on what you have learned\nearlier in the class.  Here, we will assume that we can just make use of\nit.\n\nHow many bits do we need in our counter?  The answer depends on T.\nIf we add the counter to our design, the state of the counter is \ntechnically part of the state of our FSM, but we can treat it\nsomewhat abstractly.  For example, we only plan to make use of the \ncounter value in the ALARM state, so we ignore the counter bits in the\nthree other states.  In other words, S_1S_0=10 means that the system \nis in the LOCKED state regardless of the counter's value.\n\n\nWe expand the ALARM state into T separate states based on the value\nof the counter.  As shown to the right, we name the states ALARM(1) \nthrough ALARM(T).  All of these alarm states use S_1S_0=01, but\nthey can be differentiated using a ``timer'' (the counter value).\n\nWe need to make design decisions about how the arcs entering and\nleaving the ALARM state in our original design should be used once\nwe have incorporated the timeout.  As a first step, we decide that\nall arcs entering ALARM from other states now enter ALARM(1).  \nSimilarly, if the user presses the panic button P in any of the\nALARM(t) states, the system returns to ALARM(1).  Effectively, \npressing the panic button resets the timer.\n\nThe only arc leaving the ALARM state goes to the LOCKED state on \nULP=x10.  We replicate this arc for all ALARM(t) states: the\nuser can push the lock button at any time to silence the alarm.\n\nFinally, the self-loop back to the ALARM state on ULP=x00 becomes\nthe countdown arcs in our expanded states, taking ALARM(t) to ALARM(t+1),\nand ALARM(T) to LOCKED.\n\nNow that we have a complete specification for the extended design, we\ncan implement it.  We want to reuse our original design as much as possible,\nbut we have three new features that must be considered.  First, when\nwe enter the ALARM(1) state, we need to set the counter value to T-1.\nSecond, we need the counter value to count downward while in the ALARM\nstate.  Finally, we need to move back to the LOCKED state when a timeout\noccurs---that is, when the counter reaches zero.\n\n\n{file=part3/figs/ke-alarm-expansion.eps,width=1.75in}\n\n\nThe first problem is fairly easy.  Our counter supports parallel load,\nand the only value that we need to load is T-1, so we apply the constant\nbit pattern for T-1 to the load inputs and raise the LD input whenever\nwe enter the ALARM(1) state.  In our original design, we chose to enter\nthe ALARM state whenever the user pressed P, regardless of the other\nbuttons.  Hence we can connect P directly to our counter's LD input.\n\nThe second problem is handled by the counter's countdown functionality.\nIn the ALARM(t) states, the counter will count down each cycle, moving\nthe system from ALARM(t) to ALARM(t+1).\n\nThe last problem is slightly trickier, since we need to change S_1S_0.\nNotice that S_1S_0=01 for the ALARM state and S_1S_0=00 for the LOCKED\nstate.  Thus, we need only force S_0 to 0 when a timeout occurs.\nWe can use a single {2-to-1} multiplexer for this purpose.  The\n``0'' input of the mux comes from the original S_0^+ logic, and the\n``1'' input is a constant 0.  All other state logic remains unchanged.  \nWhen does a timeout occur? \n\nFirst, we must be in the ALARM(T) state, so S_1S_0=01 and the \ncounter's Z output is raised.  Second, the input combination must\nbe ULP=xx0---notice that both ULP=x00 and ULP=x10 return to \nLOCKED from ALARM(T).  A single, four-input AND gate thus suffices to\nobtain the timeout signal, {S_1}S_0Z, which we connect \nto the select input of the mux between the S_0^+ logic and the\nS_0 flip-flop.\n\nThe extension thus requires only a counter, a mux, and a gate, as shown below.\n\n{{file=part3/figs/ke-alarm-exp-impl.eps,width=2.65in}}\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of the counter in this design?\n2. How does the counter determine when a timeout has occurred?\n3. What is the purpose of the mux in this design?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Machine Models",
            "text": "{Machine Models}\n\nBefore we dive fully into FSM design, we must point out that we have\nplaced a somewhat artificial restriction on the types of FSMs that\nwe use in our course.\n\nHistorically, this restriction was given a name, and machines of the type\nthat we have discussed are called Moore machines.\n\nHowever, outside of introductory classes, almost no one cares about\nthis name, nor about the name for the more general model used almost\nuniversally in hardware design, Mealy machines.\n\nWhat is the difference?  In a { Moore machine}, outputs depend only on\nthe internal state bits of the FSM (the values stored in the flip-flops).\nIn a { Mealy machine}, outputs\nmay be expressed as functions both of internal state and FSM inputs.\n\nAs we illustrate shortly, the benefit of using input signals to calculate\noutputs (the Mealy machine model) is that input bits effectively serve \nas additional system state, which means that the number of internal \nstate bits can be reduced.\n\nThe disadvantage of including input signals in the expressions for \noutput signals is that timing characteristics of input signals may not\nbe known, whereas an FSM designer may want to guarantee certain\ntiming characteristics for output signals.\n\nIn practice, when such timing guarantees are needed, the designer simply\nadds state to the FSM to accommodate the need, and the problem is solved.\n\nThe coin-counting FSM that we designed for our class' lab assignments,\nfor example, \nrequired that we use a Moore machine model to avoid sending the\nservo controlling the coin's path an output pulse that was too short\nto enforce the FSM's decision about which way to send the coin.\n\nBy adding more states to the FSM, we were able to hold the servo in\nplace, as desired.\n\nWhy are we protecting you from the model used in practice?\n\nFirst, timing issues add complexity to a topic that is complex enough \nfor an introductory course.\n\nAnd, second, most software FSMs are Moore machines, so the abstraction\nis a useful one in that context, too.\n\nIn many design contexts, the timing issues implied by a Mealy model\ncan be relatively simple to manage.  When working in a single clock\ndomain, all of the input signals come from flip-flops in the same \ndomain, and are thus stable for most of the clock cycle.  Only rarely\ndoes one need to keep additional state to improve timing characteristics\nin these contexts.  In contrast, when interacting across clock domains,\nmore care is sometimes needed to ensure correct behavior.\n\nWe now illustrate the state reduction benefit of the Mealy machine\nmodel with a simple example, an FSM that recognizes the \npattern of a 0 followed by a 1 on a single input and outputs\na 1 when it observes the pattern.\n\nAs already mentioned,\nMealy machines often require fewer flip-flops.\nIntuitively, the number of combinations of states and\ninputs is greater than the number of combinations of states alone, and\nallowing a function to depend on inputs reduces the number of internal\nstates needed.  \n\nA Mealy implementation of the FSM appears on the left below, and\nan example timing diagram illustrating the FSM's behavior is shown on\nthe right.\n\nThe machine shown below occupies state A when the last bit seen was a 0, and\nstate B when the last bit seen was a 1.\n\nNotice that the transition arcs in the state diagram\nare labeled with two values instead\nof one.  Since outputs can depend on input values as well as state,\ntransitions in a Mealy machine are labeled with input/output\ncombinations, while states are labeled only with their internal bits\n(or just their names, as shown below).  Labeling states with outputs\ndoes not make sense for a Mealy machine, since outputs may vary\nwith inputs.\n\nNotice that the outputs indicated on any given transition\nhold only until that transition is taken (at the rising clock edge), as is\napparent in the timing diagram.  When inputs are asynchronous, \nthat is,\nnot driven by the same clock signal, output pulses from a Mealy\nmachine can be arbitrarily short, which can lead to problems.\n\n\n\n{{file=part3/figs/lec17-3.eps,width=5in}}\n\n\n\nFor a Moore machine, we must create a special state in which the\noutput is high.  Doing so requires that we split state B into two\nstates, a state C in which the last two bits seen were 01, and a\nstate D in which the last two bits seen were 11.  Only state C\ngenerates output 1.  State D also becomes the starting state for the\nnew state machine.  The state diagram on the left below illustrates \nthe changes, using the transition diagram style that we introduced \nearlier to represent Moore machines.\nNotice in the associated timing diagram that the output pulse lasts a\nfull clock cycle.\n\n\n\n{{file=part3/figs/lec17-4.eps,width=5in}}\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the primary difference between Moore and Mealy machines?\n2. What are some of the benefits of using a Mealy machine model?\n3. What are some of the disadvantages of using a Mealy machine model?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Machine Models",
            "text": "{Machine Models}\n\nBefore we dive fully into FSM design, we must point out that we have\nplaced a somewhat artificial restriction on the types of FSMs that\nwe use in our course.\n\nHistorically, this restriction was given a name, and machines of the type\nthat we have discussed are called Moore machines.\n\nHowever, outside of introductory classes, almost no one cares about\nthis name, nor about the name for the more general model used almost\nuniversally in hardware design, Mealy machines.\n\nWhat is the difference?  In a { Moore machine}, outputs depend only on\nthe internal state bits of the FSM (the values stored in the flip-flops).\nIn a { Mealy machine}, outputs\nmay be expressed as functions both of internal state and FSM inputs.\n\nAs we illustrate shortly, the benefit of using input signals to calculate\noutputs (the Mealy machine model) is that input bits effectively serve \nas additional system state, which means that the number of internal \nstate bits can be reduced.\n\nThe disadvantage of including input signals in the expressions for \noutput signals is that timing characteristics of input signals may not\nbe known, whereas an FSM designer may want to guarantee certain\ntiming characteristics for output signals.\n\nIn practice, when such timing guarantees are needed, the designer simply\nadds state to the FSM to accommodate the need, and the problem is solved.\n\nThe coin-counting FSM that we designed for our class' lab assignments,\nfor example, \nrequired that we use a Moore machine model to avoid sending the\nservo controlling the coin's path an output pulse that was too short\nto enforce the FSM's decision about which way to send the coin.\n\nBy adding more states to the FSM, we were able to hold the servo in\nplace, as desired.\n\nWhy are we protecting you from the model used in practice?\n\nFirst, timing issues add complexity to a topic that is complex enough \nfor an introductory course.\n\nAnd, second, most software FSMs are Moore machines, so the abstraction\nis a useful one in that context, too.\n\nIn many design contexts, the timing issues implied by a Mealy model\ncan be relatively simple to manage.  When working in a single clock\ndomain, all of the input signals come from flip-flops in the same \ndomain, and are thus stable for most of the clock cycle.  Only rarely\ndoes one need to keep additional state to improve timing characteristics\nin these contexts.  In contrast, when interacting across clock domains,\nmore care is sometimes needed to ensure correct behavior.\n\nWe now illustrate the state reduction benefit of the Mealy machine\nmodel with a simple example, an FSM that recognizes the \npattern of a 0 followed by a 1 on a single input and outputs\na 1 when it observes the pattern.\n\nAs already mentioned,\nMealy machines often require fewer flip-flops.\nIntuitively, the number of combinations of states and\ninputs is greater than the number of combinations of states alone, and\nallowing a function to depend on inputs reduces the number of internal\nstates needed.  \n\nA Mealy implementation of the FSM appears on the left below, and\nan example timing diagram illustrating the FSM's behavior is shown on\nthe right.\n\nThe machine shown below occupies state A when the last bit seen was a 0, and\nstate B when the last bit seen was a 1.\n\nNotice that the transition arcs in the state diagram\nare labeled with two values instead\nof one.  Since outputs can depend on input values as well as state,\ntransitions in a Mealy machine are labeled with input/output\ncombinations, while states are labeled only with their internal bits\n(or just their names, as shown below).  Labeling states with outputs\ndoes not make sense for a Mealy machine, since outputs may vary\nwith inputs.\n\nNotice that the outputs indicated on any given transition\nhold only until that transition is taken (at the rising clock edge), as is\napparent in the timing diagram.  When inputs are asynchronous, \nthat is,\nnot driven by the same clock signal, output pulses from a Mealy\nmachine can be arbitrarily short, which can lead to problems.\n\n\n\n{{file=part3/figs/lec17-3.eps,width=5in}}\n\n\n\nFor a Moore machine, we must create a special state in which the\noutput is high.  Doing so requires that we split state B into two\nstates, a state C in which the last two bits seen were 01, and a\nstate D in which the last two bits seen were 11.  Only state C\ngenerates output 1.  State D also becomes the starting state for the\nnew state machine.  The state diagram on the left below illustrates \nthe changes, using the transition diagram style that we introduced \nearlier to represent Moore machines.\nNotice in the associated timing diagram that the output pulse lasts a\nfull clock cycle.\n\n\n\n{{file=part3/figs/lec17-4.eps,width=5in}}\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the primary difference between Moore and Mealy machines?\n2. What are some of the benefits of using a Mealy machine model?\n3. What are some of the disadvantages of using a Mealy machine model?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Machine Models",
            "text": "{Machine Models}\n\nBefore we dive fully into FSM design, we must point out that we have\nplaced a somewhat artificial restriction on the types of FSMs that\nwe use in our course.\n\nHistorically, this restriction was given a name, and machines of the type\nthat we have discussed are called Moore machines.\n\nHowever, outside of introductory classes, almost no one cares about\nthis name, nor about the name for the more general model used almost\nuniversally in hardware design, Mealy machines.\n\nWhat is the difference?  In a { Moore machine}, outputs depend only on\nthe internal state bits of the FSM (the values stored in the flip-flops).\nIn a { Mealy machine}, outputs\nmay be expressed as functions both of internal state and FSM inputs.\n\nAs we illustrate shortly, the benefit of using input signals to calculate\noutputs (the Mealy machine model) is that input bits effectively serve \nas additional system state, which means that the number of internal \nstate bits can be reduced.\n\nThe disadvantage of including input signals in the expressions for \noutput signals is that timing characteristics of input signals may not\nbe known, whereas an FSM designer may want to guarantee certain\ntiming characteristics for output signals.\n\nIn practice, when such timing guarantees are needed, the designer simply\nadds state to the FSM to accommodate the need, and the problem is solved.\n\nThe coin-counting FSM that we designed for our class' lab assignments,\nfor example, \nrequired that we use a Moore machine model to avoid sending the\nservo controlling the coin's path an output pulse that was too short\nto enforce the FSM's decision about which way to send the coin.\n\nBy adding more states to the FSM, we were able to hold the servo in\nplace, as desired.\n\nWhy are we protecting you from the model used in practice?\n\nFirst, timing issues add complexity to a topic that is complex enough \nfor an introductory course.\n\nAnd, second, most software FSMs are Moore machines, so the abstraction\nis a useful one in that context, too.\n\nIn many design contexts, the timing issues implied by a Mealy model\ncan be relatively simple to manage.  When working in a single clock\ndomain, all of the input signals come from flip-flops in the same \ndomain, and are thus stable for most of the clock cycle.  Only rarely\ndoes one need to keep additional state to improve timing characteristics\nin these contexts.  In contrast, when interacting across clock domains,\nmore care is sometimes needed to ensure correct behavior.\n\nWe now illustrate the state reduction benefit of the Mealy machine\nmodel with a simple example, an FSM that recognizes the \npattern of a 0 followed by a 1 on a single input and outputs\na 1 when it observes the pattern.\n\nAs already mentioned,\nMealy machines often require fewer flip-flops.\nIntuitively, the number of combinations of states and\ninputs is greater than the number of combinations of states alone, and\nallowing a function to depend on inputs reduces the number of internal\nstates needed.  \n\nA Mealy implementation of the FSM appears on the left below, and\nan example timing diagram illustrating the FSM's behavior is shown on\nthe right.\n\nThe machine shown below occupies state A when the last bit seen was a 0, and\nstate B when the last bit seen was a 1.\n\nNotice that the transition arcs in the state diagram\nare labeled with two values instead\nof one.  Since outputs can depend on input values as well as state,\ntransitions in a Mealy machine are labeled with input/output\ncombinations, while states are labeled only with their internal bits\n(or just their names, as shown below).  Labeling states with outputs\ndoes not make sense for a Mealy machine, since outputs may vary\nwith inputs.\n\nNotice that the outputs indicated on any given transition\nhold only until that transition is taken (at the rising clock edge), as is\napparent in the timing diagram.  When inputs are asynchronous, \nthat is,\nnot driven by the same clock signal, output pulses from a Mealy\nmachine can be arbitrarily short, which can lead to problems.\n\n\n\n{{file=part3/figs/lec17-3.eps,width=5in}}\n\n\n\nFor a Moore machine, we must create a special state in which the\noutput is high.  Doing so requires that we split state B into two\nstates, a state C in which the last two bits seen were 01, and a\nstate D in which the last two bits seen were 11.  Only state C\ngenerates output 1.  State D also becomes the starting state for the\nnew state machine.  The state diagram on the left below illustrates \nthe changes, using the transition diagram style that we introduced \nearlier to represent Moore machines.\nNotice in the associated timing diagram that the output pulse lasts a\nfull clock cycle.\n\n\n\n{{file=part3/figs/lec17-4.eps,width=5in}}\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the primary difference between Moore and Mealy machines?\n2. What are some of the benefits of using a Mealy machine model?\n3. What are some of the disadvantages of using a Mealy machine model?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Machine Models",
            "text": "{Machine Models}\n\nBefore we dive fully into FSM design, we must point out that we have\nplaced a somewhat artificial restriction on the types of FSMs that\nwe use in our course.\n\nHistorically, this restriction was given a name, and machines of the type\nthat we have discussed are called Moore machines.\n\nHowever, outside of introductory classes, almost no one cares about\nthis name, nor about the name for the more general model used almost\nuniversally in hardware design, Mealy machines.\n\nWhat is the difference?  In a { Moore machine}, outputs depend only on\nthe internal state bits of the FSM (the values stored in the flip-flops).\nIn a { Mealy machine}, outputs\nmay be expressed as functions both of internal state and FSM inputs.\n\nAs we illustrate shortly, the benefit of using input signals to calculate\noutputs (the Mealy machine model) is that input bits effectively serve \nas additional system state, which means that the number of internal \nstate bits can be reduced.\n\nThe disadvantage of including input signals in the expressions for \noutput signals is that timing characteristics of input signals may not\nbe known, whereas an FSM designer may want to guarantee certain\ntiming characteristics for output signals.\n\nIn practice, when such timing guarantees are needed, the designer simply\nadds state to the FSM to accommodate the need, and the problem is solved.\n\nThe coin-counting FSM that we designed for our class' lab assignments,\nfor example, \nrequired that we use a Moore machine model to avoid sending the\nservo controlling the coin's path an output pulse that was too short\nto enforce the FSM's decision about which way to send the coin.\n\nBy adding more states to the FSM, we were able to hold the servo in\nplace, as desired.\n\nWhy are we protecting you from the model used in practice?\n\nFirst, timing issues add complexity to a topic that is complex enough \nfor an introductory course.\n\nAnd, second, most software FSMs are Moore machines, so the abstraction\nis a useful one in that context, too.\n\nIn many design contexts, the timing issues implied by a Mealy model\ncan be relatively simple to manage.  When working in a single clock\ndomain, all of the input signals come from flip-flops in the same \ndomain, and are thus stable for most of the clock cycle.  Only rarely\ndoes one need to keep additional state to improve timing characteristics\nin these contexts.  In contrast, when interacting across clock domains,\nmore care is sometimes needed to ensure correct behavior.\n\nWe now illustrate the state reduction benefit of the Mealy machine\nmodel with a simple example, an FSM that recognizes the \npattern of a 0 followed by a 1 on a single input and outputs\na 1 when it observes the pattern.\n\nAs already mentioned,\nMealy machines often require fewer flip-flops.\nIntuitively, the number of combinations of states and\ninputs is greater than the number of combinations of states alone, and\nallowing a function to depend on inputs reduces the number of internal\nstates needed.  \n\nA Mealy implementation of the FSM appears on the left below, and\nan example timing diagram illustrating the FSM's behavior is shown on\nthe right.\n\nThe machine shown below occupies state A when the last bit seen was a 0, and\nstate B when the last bit seen was a 1.\n\nNotice that the transition arcs in the state diagram\nare labeled with two values instead\nof one.  Since outputs can depend on input values as well as state,\ntransitions in a Mealy machine are labeled with input/output\ncombinations, while states are labeled only with their internal bits\n(or just their names, as shown below).  Labeling states with outputs\ndoes not make sense for a Mealy machine, since outputs may vary\nwith inputs.\n\nNotice that the outputs indicated on any given transition\nhold only until that transition is taken (at the rising clock edge), as is\napparent in the timing diagram.  When inputs are asynchronous, \nthat is,\nnot driven by the same clock signal, output pulses from a Mealy\nmachine can be arbitrarily short, which can lead to problems.\n\n\n\n{{file=part3/figs/lec17-3.eps,width=5in}}\n\n\n\nFor a Moore machine, we must create a special state in which the\noutput is high.  Doing so requires that we split state B into two\nstates, a state C in which the last two bits seen were 01, and a\nstate D in which the last two bits seen were 11.  Only state C\ngenerates output 1.  State D also becomes the starting state for the\nnew state machine.  The state diagram on the left below illustrates \nthe changes, using the transition diagram style that we introduced \nearlier to represent Moore machines.\nNotice in the associated timing diagram that the output pulse lasts a\nfull clock cycle.\n\n\n\n{{file=part3/figs/lec17-4.eps,width=5in}}\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the primary difference between Moore and Mealy machines?\n2. What are some of the benefits of using a Mealy machine model?\n3. What are some of the disadvantages of using a Mealy machine model?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Machine Models",
            "text": "{Machine Models}\n\nBefore we dive fully into FSM design, we must point out that we have\nplaced a somewhat artificial restriction on the types of FSMs that\nwe use in our course.\n\nHistorically, this restriction was given a name, and machines of the type\nthat we have discussed are called Moore machines.\n\nHowever, outside of introductory classes, almost no one cares about\nthis name, nor about the name for the more general model used almost\nuniversally in hardware design, Mealy machines.\n\nWhat is the difference?  In a { Moore machine}, outputs depend only on\nthe internal state bits of the FSM (the values stored in the flip-flops).\nIn a { Mealy machine}, outputs\nmay be expressed as functions both of internal state and FSM inputs.\n\nAs we illustrate shortly, the benefit of using input signals to calculate\noutputs (the Mealy machine model) is that input bits effectively serve \nas additional system state, which means that the number of internal \nstate bits can be reduced.\n\nThe disadvantage of including input signals in the expressions for \noutput signals is that timing characteristics of input signals may not\nbe known, whereas an FSM designer may want to guarantee certain\ntiming characteristics for output signals.\n\nIn practice, when such timing guarantees are needed, the designer simply\nadds state to the FSM to accommodate the need, and the problem is solved.\n\nThe coin-counting FSM that we designed for our class' lab assignments,\nfor example, \nrequired that we use a Moore machine model to avoid sending the\nservo controlling the coin's path an output pulse that was too short\nto enforce the FSM's decision about which way to send the coin.\n\nBy adding more states to the FSM, we were able to hold the servo in\nplace, as desired.\n\nWhy are we protecting you from the model used in practice?\n\nFirst, timing issues add complexity to a topic that is complex enough \nfor an introductory course.\n\nAnd, second, most software FSMs are Moore machines, so the abstraction\nis a useful one in that context, too.\n\nIn many design contexts, the timing issues implied by a Mealy model\ncan be relatively simple to manage.  When working in a single clock\ndomain, all of the input signals come from flip-flops in the same \ndomain, and are thus stable for most of the clock cycle.  Only rarely\ndoes one need to keep additional state to improve timing characteristics\nin these contexts.  In contrast, when interacting across clock domains,\nmore care is sometimes needed to ensure correct behavior.\n\nWe now illustrate the state reduction benefit of the Mealy machine\nmodel with a simple example, an FSM that recognizes the \npattern of a 0 followed by a 1 on a single input and outputs\na 1 when it observes the pattern.\n\nAs already mentioned,\nMealy machines often require fewer flip-flops.\nIntuitively, the number of combinations of states and\ninputs is greater than the number of combinations of states alone, and\nallowing a function to depend on inputs reduces the number of internal\nstates needed.  \n\nA Mealy implementation of the FSM appears on the left below, and\nan example timing diagram illustrating the FSM's behavior is shown on\nthe right.\n\nThe machine shown below occupies state A when the last bit seen was a 0, and\nstate B when the last bit seen was a 1.\n\nNotice that the transition arcs in the state diagram\nare labeled with two values instead\nof one.  Since outputs can depend on input values as well as state,\ntransitions in a Mealy machine are labeled with input/output\ncombinations, while states are labeled only with their internal bits\n(or just their names, as shown below).  Labeling states with outputs\ndoes not make sense for a Mealy machine, since outputs may vary\nwith inputs.\n\nNotice that the outputs indicated on any given transition\nhold only until that transition is taken (at the rising clock edge), as is\napparent in the timing diagram.  When inputs are asynchronous, \nthat is,\nnot driven by the same clock signal, output pulses from a Mealy\nmachine can be arbitrarily short, which can lead to problems.\n\n\n\n{{file=part3/figs/lec17-3.eps,width=5in}}\n\n\n\nFor a Moore machine, we must create a special state in which the\noutput is high.  Doing so requires that we split state B into two\nstates, a state C in which the last two bits seen were 01, and a\nstate D in which the last two bits seen were 11.  Only state C\ngenerates output 1.  State D also becomes the starting state for the\nnew state machine.  The state diagram on the left below illustrates \nthe changes, using the transition diagram style that we introduced \nearlier to represent Moore machines.\nNotice in the associated timing diagram that the output pulse lasts a\nfull clock cycle.\n\n\n\n{{file=part3/figs/lec17-4.eps,width=5in}}\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the primary difference between Moore and Mealy machines?\n2. What are some of the benefits of using a Mealy machine model?\n3. What are some of the disadvantages of using a Mealy machine model?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Machine Models",
            "text": "{Machine Models}\n\nBefore we dive fully into FSM design, we must point out that we have\nplaced a somewhat artificial restriction on the types of FSMs that\nwe use in our course.\n\nHistorically, this restriction was given a name, and machines of the type\nthat we have discussed are called Moore machines.\n\nHowever, outside of introductory classes, almost no one cares about\nthis name, nor about the name for the more general model used almost\nuniversally in hardware design, Mealy machines.\n\nWhat is the difference?  In a { Moore machine}, outputs depend only on\nthe internal state bits of the FSM (the values stored in the flip-flops).\nIn a { Mealy machine}, outputs\nmay be expressed as functions both of internal state and FSM inputs.\n\nAs we illustrate shortly, the benefit of using input signals to calculate\noutputs (the Mealy machine model) is that input bits effectively serve \nas additional system state, which means that the number of internal \nstate bits can be reduced.\n\nThe disadvantage of including input signals in the expressions for \noutput signals is that timing characteristics of input signals may not\nbe known, whereas an FSM designer may want to guarantee certain\ntiming characteristics for output signals.\n\nIn practice, when such timing guarantees are needed, the designer simply\nadds state to the FSM to accommodate the need, and the problem is solved.\n\nThe coin-counting FSM that we designed for our class' lab assignments,\nfor example, \nrequired that we use a Moore machine model to avoid sending the\nservo controlling the coin's path an output pulse that was too short\nto enforce the FSM's decision about which way to send the coin.\n\nBy adding more states to the FSM, we were able to hold the servo in\nplace, as desired.\n\nWhy are we protecting you from the model used in practice?\n\nFirst, timing issues add complexity to a topic that is complex enough \nfor an introductory course.\n\nAnd, second, most software FSMs are Moore machines, so the abstraction\nis a useful one in that context, too.\n\nIn many design contexts, the timing issues implied by a Mealy model\ncan be relatively simple to manage.  When working in a single clock\ndomain, all of the input signals come from flip-flops in the same \ndomain, and are thus stable for most of the clock cycle.  Only rarely\ndoes one need to keep additional state to improve timing characteristics\nin these contexts.  In contrast, when interacting across clock domains,\nmore care is sometimes needed to ensure correct behavior.\n\nWe now illustrate the state reduction benefit of the Mealy machine\nmodel with a simple example, an FSM that recognizes the \npattern of a 0 followed by a 1 on a single input and outputs\na 1 when it observes the pattern.\n\nAs already mentioned,\nMealy machines often require fewer flip-flops.\nIntuitively, the number of combinations of states and\ninputs is greater than the number of combinations of states alone, and\nallowing a function to depend on inputs reduces the number of internal\nstates needed.  \n\nA Mealy implementation of the FSM appears on the left below, and\nan example timing diagram illustrating the FSM's behavior is shown on\nthe right.\n\nThe machine shown below occupies state A when the last bit seen was a 0, and\nstate B when the last bit seen was a 1.\n\nNotice that the transition arcs in the state diagram\nare labeled with two values instead\nof one.  Since outputs can depend on input values as well as state,\ntransitions in a Mealy machine are labeled with input/output\ncombinations, while states are labeled only with their internal bits\n(or just their names, as shown below).  Labeling states with outputs\ndoes not make sense for a Mealy machine, since outputs may vary\nwith inputs.\n\nNotice that the outputs indicated on any given transition\nhold only until that transition is taken (at the rising clock edge), as is\napparent in the timing diagram.  When inputs are asynchronous, \nthat is,\nnot driven by the same clock signal, output pulses from a Mealy\nmachine can be arbitrarily short, which can lead to problems.\n\n\n\n{{file=part3/figs/lec17-3.eps,width=5in}}\n\n\n\nFor a Moore machine, we must create a special state in which the\noutput is high.  Doing so requires that we split state B into two\nstates, a state C in which the last two bits seen were 01, and a\nstate D in which the last two bits seen were 11.  Only state C\ngenerates output 1.  State D also becomes the starting state for the\nnew state machine.  The state diagram on the left below illustrates \nthe changes, using the transition diagram style that we introduced \nearlier to represent Moore machines.\nNotice in the associated timing diagram that the output pulse lasts a\nfull clock cycle.\n\n\n\n{{file=part3/figs/lec17-4.eps,width=5in}}\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the primary difference between Moore and Mealy machines?\n2. What are some of the benefits of using a Mealy machine model?\n3. What are some of the disadvantages of using a Mealy machine model?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Machine Models",
            "text": "{Machine Models}\n\nBefore we dive fully into FSM design, we must point out that we have\nplaced a somewhat artificial restriction on the types of FSMs that\nwe use in our course.\n\nHistorically, this restriction was given a name, and machines of the type\nthat we have discussed are called Moore machines.\n\nHowever, outside of introductory classes, almost no one cares about\nthis name, nor about the name for the more general model used almost\nuniversally in hardware design, Mealy machines.\n\nWhat is the difference?  In a { Moore machine}, outputs depend only on\nthe internal state bits of the FSM (the values stored in the flip-flops).\nIn a { Mealy machine}, outputs\nmay be expressed as functions both of internal state and FSM inputs.\n\nAs we illustrate shortly, the benefit of using input signals to calculate\noutputs (the Mealy machine model) is that input bits effectively serve \nas additional system state, which means that the number of internal \nstate bits can be reduced.\n\nThe disadvantage of including input signals in the expressions for \noutput signals is that timing characteristics of input signals may not\nbe known, whereas an FSM designer may want to guarantee certain\ntiming characteristics for output signals.\n\nIn practice, when such timing guarantees are needed, the designer simply\nadds state to the FSM to accommodate the need, and the problem is solved.\n\nThe coin-counting FSM that we designed for our class' lab assignments,\nfor example, \nrequired that we use a Moore machine model to avoid sending the\nservo controlling the coin's path an output pulse that was too short\nto enforce the FSM's decision about which way to send the coin.\n\nBy adding more states to the FSM, we were able to hold the servo in\nplace, as desired.\n\nWhy are we protecting you from the model used in practice?\n\nFirst, timing issues add complexity to a topic that is complex enough \nfor an introductory course.\n\nAnd, second, most software FSMs are Moore machines, so the abstraction\nis a useful one in that context, too.\n\nIn many design contexts, the timing issues implied by a Mealy model\ncan be relatively simple to manage.  When working in a single clock\ndomain, all of the input signals come from flip-flops in the same \ndomain, and are thus stable for most of the clock cycle.  Only rarely\ndoes one need to keep additional state to improve timing characteristics\nin these contexts.  In contrast, when interacting across clock domains,\nmore care is sometimes needed to ensure correct behavior.\n\nWe now illustrate the state reduction benefit of the Mealy machine\nmodel with a simple example, an FSM that recognizes the \npattern of a 0 followed by a 1 on a single input and outputs\na 1 when it observes the pattern.\n\nAs already mentioned,\nMealy machines often require fewer flip-flops.\nIntuitively, the number of combinations of states and\ninputs is greater than the number of combinations of states alone, and\nallowing a function to depend on inputs reduces the number of internal\nstates needed.  \n\nA Mealy implementation of the FSM appears on the left below, and\nan example timing diagram illustrating the FSM's behavior is shown on\nthe right.\n\nThe machine shown below occupies state A when the last bit seen was a 0, and\nstate B when the last bit seen was a 1.\n\nNotice that the transition arcs in the state diagram\nare labeled with two values instead\nof one.  Since outputs can depend on input values as well as state,\ntransitions in a Mealy machine are labeled with input/output\ncombinations, while states are labeled only with their internal bits\n(or just their names, as shown below).  Labeling states with outputs\ndoes not make sense for a Mealy machine, since outputs may vary\nwith inputs.\n\nNotice that the outputs indicated on any given transition\nhold only until that transition is taken (at the rising clock edge), as is\napparent in the timing diagram.  When inputs are asynchronous, \nthat is,\nnot driven by the same clock signal, output pulses from a Mealy\nmachine can be arbitrarily short, which can lead to problems.\n\n\n\n{{file=part3/figs/lec17-3.eps,width=5in}}\n\n\n\nFor a Moore machine, we must create a special state in which the\noutput is high.  Doing so requires that we split state B into two\nstates, a state C in which the last two bits seen were 01, and a\nstate D in which the last two bits seen were 11.  Only state C\ngenerates output 1.  State D also becomes the starting state for the\nnew state machine.  The state diagram on the left below illustrates \nthe changes, using the transition diagram style that we introduced \nearlier to represent Moore machines.\nNotice in the associated timing diagram that the output pulse lasts a\nfull clock cycle.\n\n\n\n{{file=part3/figs/lec17-4.eps,width=5in}}\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the primary difference between Moore and Mealy machines?\n2. What are some of the benefits of using a Mealy machine model?\n3. What are some of the disadvantages of using a Mealy machine model?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Machine Models",
            "text": "{Machine Models}\n\nBefore we dive fully into FSM design, we must point out that we have\nplaced a somewhat artificial restriction on the types of FSMs that\nwe use in our course.\n\nHistorically, this restriction was given a name, and machines of the type\nthat we have discussed are called Moore machines.\n\nHowever, outside of introductory classes, almost no one cares about\nthis name, nor about the name for the more general model used almost\nuniversally in hardware design, Mealy machines.\n\nWhat is the difference?  In a { Moore machine}, outputs depend only on\nthe internal state bits of the FSM (the values stored in the flip-flops).\nIn a { Mealy machine}, outputs\nmay be expressed as functions both of internal state and FSM inputs.\n\nAs we illustrate shortly, the benefit of using input signals to calculate\noutputs (the Mealy machine model) is that input bits effectively serve \nas additional system state, which means that the number of internal \nstate bits can be reduced.\n\nThe disadvantage of including input signals in the expressions for \noutput signals is that timing characteristics of input signals may not\nbe known, whereas an FSM designer may want to guarantee certain\ntiming characteristics for output signals.\n\nIn practice, when such timing guarantees are needed, the designer simply\nadds state to the FSM to accommodate the need, and the problem is solved.\n\nThe coin-counting FSM that we designed for our class' lab assignments,\nfor example, \nrequired that we use a Moore machine model to avoid sending the\nservo controlling the coin's path an output pulse that was too short\nto enforce the FSM's decision about which way to send the coin.\n\nBy adding more states to the FSM, we were able to hold the servo in\nplace, as desired.\n\nWhy are we protecting you from the model used in practice?\n\nFirst, timing issues add complexity to a topic that is complex enough \nfor an introductory course.\n\nAnd, second, most software FSMs are Moore machines, so the abstraction\nis a useful one in that context, too.\n\nIn many design contexts, the timing issues implied by a Mealy model\ncan be relatively simple to manage.  When working in a single clock\ndomain, all of the input signals come from flip-flops in the same \ndomain, and are thus stable for most of the clock cycle.  Only rarely\ndoes one need to keep additional state to improve timing characteristics\nin these contexts.  In contrast, when interacting across clock domains,\nmore care is sometimes needed to ensure correct behavior.\n\nWe now illustrate the state reduction benefit of the Mealy machine\nmodel with a simple example, an FSM that recognizes the \npattern of a 0 followed by a 1 on a single input and outputs\na 1 when it observes the pattern.\n\nAs already mentioned,\nMealy machines often require fewer flip-flops.\nIntuitively, the number of combinations of states and\ninputs is greater than the number of combinations of states alone, and\nallowing a function to depend on inputs reduces the number of internal\nstates needed.  \n\nA Mealy implementation of the FSM appears on the left below, and\nan example timing diagram illustrating the FSM's behavior is shown on\nthe right.\n\nThe machine shown below occupies state A when the last bit seen was a 0, and\nstate B when the last bit seen was a 1.\n\nNotice that the transition arcs in the state diagram\nare labeled with two values instead\nof one.  Since outputs can depend on input values as well as state,\ntransitions in a Mealy machine are labeled with input/output\ncombinations, while states are labeled only with their internal bits\n(or just their names, as shown below).  Labeling states with outputs\ndoes not make sense for a Mealy machine, since outputs may vary\nwith inputs.\n\nNotice that the outputs indicated on any given transition\nhold only until that transition is taken (at the rising clock edge), as is\napparent in the timing diagram.  When inputs are asynchronous, \nthat is,\nnot driven by the same clock signal, output pulses from a Mealy\nmachine can be arbitrarily short, which can lead to problems.\n\n\n\n{{file=part3/figs/lec17-3.eps,width=5in}}\n\n\n\nFor a Moore machine, we must create a special state in which the\noutput is high.  Doing so requires that we split state B into two\nstates, a state C in which the last two bits seen were 01, and a\nstate D in which the last two bits seen were 11.  Only state C\ngenerates output 1.  State D also becomes the starting state for the\nnew state machine.  The state diagram on the left below illustrates \nthe changes, using the transition diagram style that we introduced \nearlier to represent Moore machines.\nNotice in the associated timing diagram that the output pulse lasts a\nfull clock cycle.\n\n\n\n{{file=part3/figs/lec17-4.eps,width=5in}}\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the primary difference between Moore and Mealy machines?\n2. What are some of the benefits of using a Mealy machine model?\n3. What are some of the disadvantages of using a Mealy machine model?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Summary of Part 3 of the Course",
            "text": "{Summary of Part 3 of the Course}\n\n\nIn this short summary, we \ngive you lists at several levels of difficulty \nof what we expect you to be able to do as a result of the last few weeks \nof studying (reading, listening, doing homework, discussing your \nunderstanding with your classmates, and so forth).\n\nStudents often find this part of the course more challenging than the\nearlier parts of the course.\n\nIn addition to these notes, you should read Chapters 4 and 5 of the \nPatt and Patel textbook, which cover the von Neumann\nmodel, instruction processing, and ISAs.  \n\nStudents typically find that the homeworks in this part of the course\nrequire more time than did those in earlier parts of the course.\nProblems on the exam will be similar in nature but designed to require \nless actual time to solve (assuming that you have been doing the homeworks).  \n\nWe'll start with the easy stuff.  \n\nYou should recognize all of these terms and be able\nto explain what they mean.  For the specific circuits, you should be able \nto draw them and explain how they work.  Actually, we don't care whether \nyou can draw something from memory---a mux, for example---provided that \nyou know what a mux does and can derive a gate diagram correctly for one \nin a few minutes.  Higher-level skills are much more valuable.\n\n[t]\n{}{{}{}\n{}{}{}\n\n{digital systems terms\n{--}{{}{}\n{}{}{}\n module\n fan-in\n fan-out\n machine models: Moore and Mealy\n\n}\n\n{simple state machines\n{--}{{}{}\n{}{}{}\n synchronous counter\n ripple counter\n serialization (of bit-sliced design)\n\n}\n\n{finite state machines (FSMs)\n{--}{{}{}\n{}{}{}\n states and state representation\n transition rule\n self-loop\n next state (+) notation\n meaning of don't care in input  combination\n meaning of don't care in output\n unused states and initialization\n completeness (with regard to  FSM specification)\n list of (abstract) states\n next-state table/state transition table/state table\n state transition diagram/transition  diagram/state diagram\n\n}\n\n{memory\n{--}{{}{}\n{}{}{}\n number of addresses\n addressability\n read/write logic\n serial/random access memory (RAM)\n volatile/non-volatile (N-V)\n static/dynamic RAM (SRAM/DRAM)\n SRAM cell\n DRAM cell\n design as a collection of cells\n coincident selection\n bit lines and sense amplifiers\n\n}\n\n\n\n[t]\n{}{{}{}\n{}{}{}\n\n{von Neumann model\n{--}{{}{}\n{}{}{}\n{processing unit\n{--}{{}{}\n{}{}{}\n register file\n arithmetic logic unit (ALU)\n word size\n\n}\n{control unit\n{--}{{}{}\n{}{}{}\n program counter (PC)\n instruction register (IR)\n implementation as FSM\n\n}\n input and output units\n{memory\n{--}{{}{}\n{}{}{}\n memory address register (MAR)\n memory data register (MDR)\n\n}\n{processor datapath}\n\n{control signal}\n\n}\n\n{tri-state buffer\n{--}{{}{}\n{}{}{}\n meaning of Z/hi-Z output\n use in distributed mux\n\n}\n\n{instruction processing}\n{-}{{}{}\n{}{}{}\n\n\n\n{register transfer language (RTL)}\n\n\n{Instruction Set Architecture (ISA)}\n{-}{{}{}\n{}{}{}\n{instruction encoding}\n{field (of an encoded instruction)}\n{operation code (opcode)}\n{types of instructions}\n{-}{{}{}\n{}{}{}\n\n{data movement}\n{control flow}\n\n{addressing modes}\n{-}{{}{}\n{}{}{}\n\n\n{PC-relative}\n\n{base + offset}\n\n\n\n\n\n\n\n\n\n\n\nWe expect you to be able to exercise the following skills:\n\n{}{{}{}\n{}{}{}\n\n{Transform a bit-sliced design into a serial design, and explain the \ntradeoffs involved in terms of area and time required to compute a result.}\n{Based on a transition diagram, implement a synchronous counter from \nflip-flops and logic gates.}\n{Implement a binary ripple counter (but not necessarily a more general \ntype of ripple counter) from flip-flops and logic gates.}\n{Given an FSM implemented as digital logic, analyze the FSM to produce \na state transition diagram.}\n{Design an FSM to meet an abstract specification for a task, including \nproduction of specified output signals, and possibly including selection \nof appropriate inputs.}\n{Complete the specification of an FSM by ensuring that each state \nincludes a transition rule for every possible input combination.}\n{Compose memory chips into larger memory systems, using additional\ndecoders when necessary.}\n{Encode {LC-3} instructions into machine code.}\n{Read and understand programs written in {LC-3} assembly/machine code.}\n\n\nAt a higher level, we expect that you understand the concepts and ideas \nsufficiently well to do the following:\n\n{}{{}{}\n{}{}{}\n\n{Abstract design symmetries from an FSM specification in order to \nsimplify the implementation.}\n{Make use of a high-level state design, possibly with many sub-states \nin each high-level state, to simplify the implementation.}\n{Use counters to insert time-based transitions between states (such \nas timeouts).}\n{Implement an FSM using logic components such as registers, \ncounters, comparators, and adders as building blocks.}\n{Explain the basic organization of a computer's microarchitecture\nas well as the role played by elements of a von Neumann design in the\nprocessing of instructions.}\n{Identify the stages of processing an instruction (such as fetch,\ndecode, getting operands, execution, and writing back results) in a \nprocessor control unit state machine diagram.}\n\n\nAnd, at the highest level, we expect that you will be able to do the following:\n\n{}{{}{}\n{}{}{}\n\n{Explain the difference between the Moore and Mealy machine models, \nas well as why you might find each of them useful when designing an FSM.}\n{Understand the need for initialization of an FSM, be able to analyze \nand identify potential problems arising from lack of initialization, and \nbe able to extend an implementation to include initialization to an \nappropriate state when necessary.}\n{Understand how the choice of internal state bits for an FSM can \naffect the complexity of the implementation of next-state and output \nlogic, and be able to select a reasonable state assignment.}\n{Identify and fix design flaws in simple FSMs by analyzing an existing \nimplementation, comparing it with the specification, and removing any \ndifferences by making any necessary changes to the implementation.}\n\n\n\n\n\n{   }  empty 3rd page\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the difference between the Moore and Mealy machine models?\n2. What is the von Neumann model?\n3. What are the stages of processing an instruction in a processor control unit state machine diagram?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "I/O*",
            "text": "{I/O*}\n\nAs a final topic, we now consider how a processor\nconnects to other devices to allow input and output.  We have already\ndiscussed interrupts, which are a special form of I/O in which only\nthe signal requesting attention is conveyed to the processor.\nCommunication of data occurs through instructions similar to loads and\nstores.  A processor is designed with a number of {{ I/O\nports}---usually} read-only or write-only registers to which devices\ncan be attached with opposite semantics.  That is, a port is usually\nwritten by the processor and read by a device or written by a device\nand read by the processor.\n\nThe question of exactly how I/O ports are accessed is an interesting\none.  One option is to create special instructions, such as the {\nin} and { out} instructions of the x86 architecture.  Port\naddresses can then be specified in the same way that memory addresses\nare specified, but use a distinct address space.  Just as two sets of\nspecial-purpose registers can be separated by the ISA, such an {\nindependent I/O} system separates I/O ports from memory addresses by\nusing distinct instructions for each class of operation.\n\nAlternatively, device registers can be accessed using the same load and store\ninstructions as are used to access memory.  This approach, known as\n{ memory-mapped I/O}, requires no new instructions for I/O, but\ndemands that a region of the memory address space be set aside for\nI/O.  The memory words with those addresses, if they exist, can not be\naccessed during normal processor operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an interrupt?\n2. What is an I/O port?\n3. What is memory-mapped I/O?",
        "answers": "\n\n1. An interrupt is a special form of input/output in which only the signal requesting attention is conveyed to the processor.\n2. An I/O port is a read-only or write-only register to which devices can be attached with opposite semantics.\n3. Memory-mapped I/O is a system that requires no new instructions for input/output, but demands that a region of the memory address space be set aside for input/output."
    },
    {
        "positive_ctxs": {
            "title": "I/O*",
            "text": "{I/O*}\n\nAs a final topic, we now consider how a processor\nconnects to other devices to allow input and output.  We have already\ndiscussed interrupts, which are a special form of I/O in which only\nthe signal requesting attention is conveyed to the processor.\nCommunication of data occurs through instructions similar to loads and\nstores.  A processor is designed with a number of {{ I/O\nports}---usually} read-only or write-only registers to which devices\ncan be attached with opposite semantics.  That is, a port is usually\nwritten by the processor and read by a device or written by a device\nand read by the processor.\n\nThe question of exactly how I/O ports are accessed is an interesting\none.  One option is to create special instructions, such as the {\nin} and { out} instructions of the x86 architecture.  Port\naddresses can then be specified in the same way that memory addresses\nare specified, but use a distinct address space.  Just as two sets of\nspecial-purpose registers can be separated by the ISA, such an {\nindependent I/O} system separates I/O ports from memory addresses by\nusing distinct instructions for each class of operation.\n\nAlternatively, device registers can be accessed using the same load and store\ninstructions as are used to access memory.  This approach, known as\n{ memory-mapped I/O}, requires no new instructions for I/O, but\ndemands that a region of the memory address space be set aside for\nI/O.  The memory words with those addresses, if they exist, can not be\naccessed during normal processor operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an interrupt?\n2. What is an I/O port?\n3. What is memory-mapped I/O?",
        "answers": "\n\n1. An interrupt is a special form of input/output in which only the signal requesting attention is conveyed to the processor.\n2. An I/O port is a read-only or write-only register to which devices can be attached with opposite semantics.\n3. Memory-mapped I/O is a system that requires no new instructions for input/output, but demands that a region of the memory address space be set aside for input/output."
    },
    {
        "positive_ctxs": {
            "title": "I/O*",
            "text": "{I/O*}\n\nAs a final topic, we now consider how a processor\nconnects to other devices to allow input and output.  We have already\ndiscussed interrupts, which are a special form of I/O in which only\nthe signal requesting attention is conveyed to the processor.\nCommunication of data occurs through instructions similar to loads and\nstores.  A processor is designed with a number of {{ I/O\nports}---usually} read-only or write-only registers to which devices\ncan be attached with opposite semantics.  That is, a port is usually\nwritten by the processor and read by a device or written by a device\nand read by the processor.\n\nThe question of exactly how I/O ports are accessed is an interesting\none.  One option is to create special instructions, such as the {\nin} and { out} instructions of the x86 architecture.  Port\naddresses can then be specified in the same way that memory addresses\nare specified, but use a distinct address space.  Just as two sets of\nspecial-purpose registers can be separated by the ISA, such an {\nindependent I/O} system separates I/O ports from memory addresses by\nusing distinct instructions for each class of operation.\n\nAlternatively, device registers can be accessed using the same load and store\ninstructions as are used to access memory.  This approach, known as\n{ memory-mapped I/O}, requires no new instructions for I/O, but\ndemands that a region of the memory address space be set aside for\nI/O.  The memory words with those addresses, if they exist, can not be\naccessed during normal processor operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an interrupt?\n2. What is an I/O port?\n3. What is memory-mapped I/O?",
        "answers": "\n\n1. An interrupt is a special form of input/output in which only the signal requesting attention is conveyed to the processor.\n2. An I/O port is a read-only or write-only register to which devices can be attached with opposite semantics.\n3. Memory-mapped I/O is a system that requires no new instructions for input/output, but demands that a region of the memory address space be set aside for input/output."
    },
    {
        "positive_ctxs": {
            "title": "I/O*",
            "text": "{I/O*}\n\nAs a final topic, we now consider how a processor\nconnects to other devices to allow input and output.  We have already\ndiscussed interrupts, which are a special form of I/O in which only\nthe signal requesting attention is conveyed to the processor.\nCommunication of data occurs through instructions similar to loads and\nstores.  A processor is designed with a number of {{ I/O\nports}---usually} read-only or write-only registers to which devices\ncan be attached with opposite semantics.  That is, a port is usually\nwritten by the processor and read by a device or written by a device\nand read by the processor.\n\nThe question of exactly how I/O ports are accessed is an interesting\none.  One option is to create special instructions, such as the {\nin} and { out} instructions of the x86 architecture.  Port\naddresses can then be specified in the same way that memory addresses\nare specified, but use a distinct address space.  Just as two sets of\nspecial-purpose registers can be separated by the ISA, such an {\nindependent I/O} system separates I/O ports from memory addresses by\nusing distinct instructions for each class of operation.\n\nAlternatively, device registers can be accessed using the same load and store\ninstructions as are used to access memory.  This approach, known as\n{ memory-mapped I/O}, requires no new instructions for I/O, but\ndemands that a region of the memory address space be set aside for\nI/O.  The memory words with those addresses, if they exist, can not be\naccessed during normal processor operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an interrupt?\n2. What is an I/O port?\n3. What is memory-mapped I/O?",
        "answers": "\n\n1. An interrupt is a special form of input/output in which only the signal requesting attention is conveyed to the processor.\n2. An I/O port is a read-only or write-only register to which devices can be attached with opposite semantics.\n3. Memory-mapped I/O is a system that requires no new instructions for input/output, but demands that a region of the memory address space be set aside for input/output."
    },
    {
        "positive_ctxs": {
            "title": "I/O*",
            "text": "{I/O*}\n\nAs a final topic, we now consider how a processor\nconnects to other devices to allow input and output.  We have already\ndiscussed interrupts, which are a special form of I/O in which only\nthe signal requesting attention is conveyed to the processor.\nCommunication of data occurs through instructions similar to loads and\nstores.  A processor is designed with a number of {{ I/O\nports}---usually} read-only or write-only registers to which devices\ncan be attached with opposite semantics.  That is, a port is usually\nwritten by the processor and read by a device or written by a device\nand read by the processor.\n\nThe question of exactly how I/O ports are accessed is an interesting\none.  One option is to create special instructions, such as the {\nin} and { out} instructions of the x86 architecture.  Port\naddresses can then be specified in the same way that memory addresses\nare specified, but use a distinct address space.  Just as two sets of\nspecial-purpose registers can be separated by the ISA, such an {\nindependent I/O} system separates I/O ports from memory addresses by\nusing distinct instructions for each class of operation.\n\nAlternatively, device registers can be accessed using the same load and store\ninstructions as are used to access memory.  This approach, known as\n{ memory-mapped I/O}, requires no new instructions for I/O, but\ndemands that a region of the memory address space be set aside for\nI/O.  The memory words with those addresses, if they exist, can not be\naccessed during normal processor operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an interrupt?\n2. What is an I/O port?\n3. What is memory-mapped I/O?",
        "answers": "\n\n1. An interrupt is a special form of input/output in which only the signal requesting attention is conveyed to the processor.\n2. An I/O port is a read-only or write-only register to which devices can be attached with opposite semantics.\n3. Memory-mapped I/O is a system that requires no new instructions for input/output, but demands that a region of the memory address space be set aside for input/output."
    },
    {
        "positive_ctxs": {
            "title": "I/O*",
            "text": "{I/O*}\n\nAs a final topic, we now consider how a processor\nconnects to other devices to allow input and output.  We have already\ndiscussed interrupts, which are a special form of I/O in which only\nthe signal requesting attention is conveyed to the processor.\nCommunication of data occurs through instructions similar to loads and\nstores.  A processor is designed with a number of {{ I/O\nports}---usually} read-only or write-only registers to which devices\ncan be attached with opposite semantics.  That is, a port is usually\nwritten by the processor and read by a device or written by a device\nand read by the processor.\n\nThe question of exactly how I/O ports are accessed is an interesting\none.  One option is to create special instructions, such as the {\nin} and { out} instructions of the x86 architecture.  Port\naddresses can then be specified in the same way that memory addresses\nare specified, but use a distinct address space.  Just as two sets of\nspecial-purpose registers can be separated by the ISA, such an {\nindependent I/O} system separates I/O ports from memory addresses by\nusing distinct instructions for each class of operation.\n\nAlternatively, device registers can be accessed using the same load and store\ninstructions as are used to access memory.  This approach, known as\n{ memory-mapped I/O}, requires no new instructions for I/O, but\ndemands that a region of the memory address space be set aside for\nI/O.  The memory words with those addresses, if they exist, can not be\naccessed during normal processor operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an interrupt?\n2. What is an I/O port?\n3. What is memory-mapped I/O?",
        "answers": "\n\n1. An interrupt is a special form of input/output in which only the signal requesting attention is conveyed to the processor.\n2. An I/O port is a read-only or write-only register to which devices can be attached with opposite semantics.\n3. Memory-mapped I/O is a system that requires no new instructions for input/output, but demands that a region of the memory address space be set aside for input/output."
    },
    {
        "positive_ctxs": {
            "title": "I/O*",
            "text": "{I/O*}\n\nAs a final topic, we now consider how a processor\nconnects to other devices to allow input and output.  We have already\ndiscussed interrupts, which are a special form of I/O in which only\nthe signal requesting attention is conveyed to the processor.\nCommunication of data occurs through instructions similar to loads and\nstores.  A processor is designed with a number of {{ I/O\nports}---usually} read-only or write-only registers to which devices\ncan be attached with opposite semantics.  That is, a port is usually\nwritten by the processor and read by a device or written by a device\nand read by the processor.\n\nThe question of exactly how I/O ports are accessed is an interesting\none.  One option is to create special instructions, such as the {\nin} and { out} instructions of the x86 architecture.  Port\naddresses can then be specified in the same way that memory addresses\nare specified, but use a distinct address space.  Just as two sets of\nspecial-purpose registers can be separated by the ISA, such an {\nindependent I/O} system separates I/O ports from memory addresses by\nusing distinct instructions for each class of operation.\n\nAlternatively, device registers can be accessed using the same load and store\ninstructions as are used to access memory.  This approach, known as\n{ memory-mapped I/O}, requires no new instructions for I/O, but\ndemands that a region of the memory address space be set aside for\nI/O.  The memory words with those addresses, if they exist, can not be\naccessed during normal processor operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an interrupt?\n2. What is an I/O port?\n3. What is memory-mapped I/O?",
        "answers": "\n\n1. An interrupt is a special form of input/output in which only the signal requesting attention is conveyed to the processor.\n2. An I/O port is a read-only or write-only register to which devices can be attached with opposite semantics.\n3. Memory-mapped I/O is a system that requires no new instructions for input/output, but demands that a region of the memory address space be set aside for input/output."
    },
    {
        "positive_ctxs": {
            "title": "I/O*",
            "text": "{I/O*}\n\nAs a final topic, we now consider how a processor\nconnects to other devices to allow input and output.  We have already\ndiscussed interrupts, which are a special form of I/O in which only\nthe signal requesting attention is conveyed to the processor.\nCommunication of data occurs through instructions similar to loads and\nstores.  A processor is designed with a number of {{ I/O\nports}---usually} read-only or write-only registers to which devices\ncan be attached with opposite semantics.  That is, a port is usually\nwritten by the processor and read by a device or written by a device\nand read by the processor.\n\nThe question of exactly how I/O ports are accessed is an interesting\none.  One option is to create special instructions, such as the {\nin} and { out} instructions of the x86 architecture.  Port\naddresses can then be specified in the same way that memory addresses\nare specified, but use a distinct address space.  Just as two sets of\nspecial-purpose registers can be separated by the ISA, such an {\nindependent I/O} system separates I/O ports from memory addresses by\nusing distinct instructions for each class of operation.\n\nAlternatively, device registers can be accessed using the same load and store\ninstructions as are used to access memory.  This approach, known as\n{ memory-mapped I/O}, requires no new instructions for I/O, but\ndemands that a region of the memory address space be set aside for\nI/O.  The memory words with those addresses, if they exist, can not be\naccessed during normal processor operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an interrupt?\n2. What is an I/O port?\n3. What is memory-mapped I/O?",
        "answers": "\n\n1. An interrupt is a special form of input/output in which only the signal requesting attention is conveyed to the processor.\n2. An I/O port is a read-only or write-only register to which devices can be attached with opposite semantics.\n3. Memory-mapped I/O is a system that requires no new instructions for input/output, but demands that a region of the memory address space be set aside for input/output."
    },
    {
        "positive_ctxs": {
            "title": "I/O*",
            "text": "{I/O*}\n\nAs a final topic, we now consider how a processor\nconnects to other devices to allow input and output.  We have already\ndiscussed interrupts, which are a special form of I/O in which only\nthe signal requesting attention is conveyed to the processor.\nCommunication of data occurs through instructions similar to loads and\nstores.  A processor is designed with a number of {{ I/O\nports}---usually} read-only or write-only registers to which devices\ncan be attached with opposite semantics.  That is, a port is usually\nwritten by the processor and read by a device or written by a device\nand read by the processor.\n\nThe question of exactly how I/O ports are accessed is an interesting\none.  One option is to create special instructions, such as the {\nin} and { out} instructions of the x86 architecture.  Port\naddresses can then be specified in the same way that memory addresses\nare specified, but use a distinct address space.  Just as two sets of\nspecial-purpose registers can be separated by the ISA, such an {\nindependent I/O} system separates I/O ports from memory addresses by\nusing distinct instructions for each class of operation.\n\nAlternatively, device registers can be accessed using the same load and store\ninstructions as are used to access memory.  This approach, known as\n{ memory-mapped I/O}, requires no new instructions for I/O, but\ndemands that a region of the memory address space be set aside for\nI/O.  The memory words with those addresses, if they exist, can not be\naccessed during normal processor operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an interrupt?\n2. What is an I/O port?\n3. What is memory-mapped I/O?",
        "answers": "\n\n1. An interrupt is a special form of input/output in which only the signal requesting attention is conveyed to the processor.\n2. An I/O port is a read-only or write-only register to which devices can be attached with opposite semantics.\n3. Memory-mapped I/O is a system that requires no new instructions for input/output, but demands that a region of the memory address space be set aside for input/output."
    },
    {
        "positive_ctxs": {
            "title": "I/O*",
            "text": "{I/O*}\n\nAs a final topic, we now consider how a processor\nconnects to other devices to allow input and output.  We have already\ndiscussed interrupts, which are a special form of I/O in which only\nthe signal requesting attention is conveyed to the processor.\nCommunication of data occurs through instructions similar to loads and\nstores.  A processor is designed with a number of {{ I/O\nports}---usually} read-only or write-only registers to which devices\ncan be attached with opposite semantics.  That is, a port is usually\nwritten by the processor and read by a device or written by a device\nand read by the processor.\n\nThe question of exactly how I/O ports are accessed is an interesting\none.  One option is to create special instructions, such as the {\nin} and { out} instructions of the x86 architecture.  Port\naddresses can then be specified in the same way that memory addresses\nare specified, but use a distinct address space.  Just as two sets of\nspecial-purpose registers can be separated by the ISA, such an {\nindependent I/O} system separates I/O ports from memory addresses by\nusing distinct instructions for each class of operation.\n\nAlternatively, device registers can be accessed using the same load and store\ninstructions as are used to access memory.  This approach, known as\n{ memory-mapped I/O}, requires no new instructions for I/O, but\ndemands that a region of the memory address space be set aside for\nI/O.  The memory words with those addresses, if they exist, can not be\naccessed during normal processor operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an interrupt?\n2. What is an I/O port?\n3. What is memory-mapped I/O?",
        "answers": "\n\n1. An interrupt is a special form of input/output in which only the signal requesting attention is conveyed to the processor.\n2. An I/O port is a read-only or write-only register to which devices can be attached with opposite semantics.\n3. Memory-mapped I/O is a system that requires no new instructions for input/output, but demands that a region of the memory address space be set aside for input/output."
    },
    {
        "positive_ctxs": {
            "title": "Microprogrammed Control",
            "text": "{Microprogrammed Control}\n\nWe are now ready to discuss the second approach to control unit design.\nTake another look at the state diagram for the the {LC-3} ISA.  Does it \nremind you of anything?  Like a flowchart, it has relatively few arcs \nleaving each state---usually only one or two.\n\nWhat if we treat the state diagram as a program?  We can use a small\nmemory to hold { microinstructions} (another name for control words) \nand use the FSM state number as the memory address.  \n\nWithout support for interrupts or privilege, and with the datapath \nextension for JSR mentioned for hardwired control, the {LC-3} state \nmachine requires fewer than 32 states.\n\nThe datapath has 25 control signals, but we need one more for the\ndatapath extension for JSR.\n\nWe thus start with {5-bit} state number (in a register)\nand a {2^5 bit} memory, which we call\nour control ROM (read-only memory) to distinguish\nit from the big, slow, von Neumann memory.\n\nEach cycle, the { microprogrammed control} unit applies the FSM state \nnumber to the control ROM (no IR bits, \njust the state number), gets back a set of control signals, and\nuses them to drive the datapath.\n\n\nTo write our microprogram, we need to calculate the control signals\nfor each microinstruction and put them in the control ROM, but we also\nneed to have a way to decide which microinstruction should execute \nnext.  We call the latter problem { sequencing} or microsequencing.\n\nNotice that most of the time there's no choice: we have only { one}\nnext microinstruction.  One simple approach is then to add the address\n(the {5-bit} state ID) of the next microinstruction to the control ROM.\nInstead of 26 bits per FSM state, we now have 31 bits per FSM state.\n\nSometimes we do need to have two possible next states.  When waiting\nfor memory (the von Neumann memory, not the control ROM) to\nfinish an access, for example, we want our FSM to stay\nin the same state, then move to the next state when the access completes.\nLet's add a second address to each microinstruction, and add\na branch control signal for the microprogram to decide whether we\nshould use the first address or the second for the next\nmicroinstruction.  This design, using a 2^5 bit memory\n(1,152 bits total), appears to the right.\n\n\n{file=part4/figs/microprogrammed-no-decode.eps,width=2in}\n\n\n\nThe microprogram branch control signal is a Boolean logic expression\nbased on the memory ready signal R and \nIR[11].  We can implement it with a state ID comparison and\na mux, as shown to the right.  For the branch instruction execution state, \nthe mux selects input 1, BEN.  For all other states, the mux selects \ninput 0, R.  When an FSM state has only a single next state, we set both \nIDs in the control ROM to the ID for that state, so the value of R \nhas no effect.\n\n\n\n\n\n We can simplify the implementation of the microprogram branch control\n by setting both next-state addresses to the same value when a state\n does not branch.  Then the branch control becomes a don't care for that\n state.\n\n\nWhat's missing?  Decode!  We do have one FSM state in which we need to be\nable to branch to one of sixteen possible next states, one for each\nopcode.  Let's just add another mux and choose the state IDs for starting\nto process each opcode in an easy way, as shown to the right with\nextensions highlighted in blue.  The textbook assigns the first state \nfor processing each opcode the IDs IR[15:12] preceeded by two 0s (the\ntextbook's design requires {6-bit} state IDs).  We adopt the same\nstrategy.  For example, the first FSM state for processing an ADD is 00001, \nand the first state for a TRAP is 01111.  In each case, the opcode \nencoding specifies the last four bits.\n\nNow we can pick the remaining state IDs arbitrarily and fill in the \ncontrol ROM with control \nsignals that implement each state's RTL and the two possible next states.\nTransitions from the decode state are handled by the extra mux.\n\nThe microprogrammed control unit implementation in Appendix C of \nPatt and Patel is similar to the one that we have developed here,\nbut is slightly more complex so that it can handle interrupts\nand privilege.   \n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of microprogrammed control over hardwired control?\n2. What is the main disadvantage of microprogrammed control over hardwired control?\n3. How does microprogrammed control handle decode?",
        "answers": "\n\n1. One advantage of microprogrammed control is that the control signals can be easily modified, allowing for changes to be made quickly and easily.\n2. A disadvantage of microprogrammed control is that it is slower than hardwired control.\n3. Microprogrammed control handles decode by using a mux to select the next state based on the opcode."
    },
    {
        "positive_ctxs": {
            "title": "Microprogrammed Control",
            "text": "{Microprogrammed Control}\n\nWe are now ready to discuss the second approach to control unit design.\nTake another look at the state diagram for the the {LC-3} ISA.  Does it \nremind you of anything?  Like a flowchart, it has relatively few arcs \nleaving each state---usually only one or two.\n\nWhat if we treat the state diagram as a program?  We can use a small\nmemory to hold { microinstructions} (another name for control words) \nand use the FSM state number as the memory address.  \n\nWithout support for interrupts or privilege, and with the datapath \nextension for JSR mentioned for hardwired control, the {LC-3} state \nmachine requires fewer than 32 states.\n\nThe datapath has 25 control signals, but we need one more for the\ndatapath extension for JSR.\n\nWe thus start with {5-bit} state number (in a register)\nand a {2^5 bit} memory, which we call\nour control ROM (read-only memory) to distinguish\nit from the big, slow, von Neumann memory.\n\nEach cycle, the { microprogrammed control} unit applies the FSM state \nnumber to the control ROM (no IR bits, \njust the state number), gets back a set of control signals, and\nuses them to drive the datapath.\n\n\nTo write our microprogram, we need to calculate the control signals\nfor each microinstruction and put them in the control ROM, but we also\nneed to have a way to decide which microinstruction should execute \nnext.  We call the latter problem { sequencing} or microsequencing.\n\nNotice that most of the time there's no choice: we have only { one}\nnext microinstruction.  One simple approach is then to add the address\n(the {5-bit} state ID) of the next microinstruction to the control ROM.\nInstead of 26 bits per FSM state, we now have 31 bits per FSM state.\n\nSometimes we do need to have two possible next states.  When waiting\nfor memory (the von Neumann memory, not the control ROM) to\nfinish an access, for example, we want our FSM to stay\nin the same state, then move to the next state when the access completes.\nLet's add a second address to each microinstruction, and add\na branch control signal for the microprogram to decide whether we\nshould use the first address or the second for the next\nmicroinstruction.  This design, using a 2^5 bit memory\n(1,152 bits total), appears to the right.\n\n\n{file=part4/figs/microprogrammed-no-decode.eps,width=2in}\n\n\n\nThe microprogram branch control signal is a Boolean logic expression\nbased on the memory ready signal R and \nIR[11].  We can implement it with a state ID comparison and\na mux, as shown to the right.  For the branch instruction execution state, \nthe mux selects input 1, BEN.  For all other states, the mux selects \ninput 0, R.  When an FSM state has only a single next state, we set both \nIDs in the control ROM to the ID for that state, so the value of R \nhas no effect.\n\n\n\n\n\n We can simplify the implementation of the microprogram branch control\n by setting both next-state addresses to the same value when a state\n does not branch.  Then the branch control becomes a don't care for that\n state.\n\n\nWhat's missing?  Decode!  We do have one FSM state in which we need to be\nable to branch to one of sixteen possible next states, one for each\nopcode.  Let's just add another mux and choose the state IDs for starting\nto process each opcode in an easy way, as shown to the right with\nextensions highlighted in blue.  The textbook assigns the first state \nfor processing each opcode the IDs IR[15:12] preceeded by two 0s (the\ntextbook's design requires {6-bit} state IDs).  We adopt the same\nstrategy.  For example, the first FSM state for processing an ADD is 00001, \nand the first state for a TRAP is 01111.  In each case, the opcode \nencoding specifies the last four bits.\n\nNow we can pick the remaining state IDs arbitrarily and fill in the \ncontrol ROM with control \nsignals that implement each state's RTL and the two possible next states.\nTransitions from the decode state are handled by the extra mux.\n\nThe microprogrammed control unit implementation in Appendix C of \nPatt and Patel is similar to the one that we have developed here,\nbut is slightly more complex so that it can handle interrupts\nand privilege.   \n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of microprogrammed control over hardwired control?\n2. What is the main disadvantage of microprogrammed control over hardwired control?\n3. How does microprogrammed control handle decode?",
        "answers": "\n\n1. One advantage of microprogrammed control is that the control signals can be easily modified, allowing for changes to be made quickly and easily.\n2. A disadvantage of microprogrammed control is that it is slower than hardwired control.\n3. Microprogrammed control handles decode by using a mux to select the next state based on the opcode."
    },
    {
        "positive_ctxs": {
            "title": "Microprogrammed Control",
            "text": "{Microprogrammed Control}\n\nWe are now ready to discuss the second approach to control unit design.\nTake another look at the state diagram for the the {LC-3} ISA.  Does it \nremind you of anything?  Like a flowchart, it has relatively few arcs \nleaving each state---usually only one or two.\n\nWhat if we treat the state diagram as a program?  We can use a small\nmemory to hold { microinstructions} (another name for control words) \nand use the FSM state number as the memory address.  \n\nWithout support for interrupts or privilege, and with the datapath \nextension for JSR mentioned for hardwired control, the {LC-3} state \nmachine requires fewer than 32 states.\n\nThe datapath has 25 control signals, but we need one more for the\ndatapath extension for JSR.\n\nWe thus start with {5-bit} state number (in a register)\nand a {2^5 bit} memory, which we call\nour control ROM (read-only memory) to distinguish\nit from the big, slow, von Neumann memory.\n\nEach cycle, the { microprogrammed control} unit applies the FSM state \nnumber to the control ROM (no IR bits, \njust the state number), gets back a set of control signals, and\nuses them to drive the datapath.\n\n\nTo write our microprogram, we need to calculate the control signals\nfor each microinstruction and put them in the control ROM, but we also\nneed to have a way to decide which microinstruction should execute \nnext.  We call the latter problem { sequencing} or microsequencing.\n\nNotice that most of the time there's no choice: we have only { one}\nnext microinstruction.  One simple approach is then to add the address\n(the {5-bit} state ID) of the next microinstruction to the control ROM.\nInstead of 26 bits per FSM state, we now have 31 bits per FSM state.\n\nSometimes we do need to have two possible next states.  When waiting\nfor memory (the von Neumann memory, not the control ROM) to\nfinish an access, for example, we want our FSM to stay\nin the same state, then move to the next state when the access completes.\nLet's add a second address to each microinstruction, and add\na branch control signal for the microprogram to decide whether we\nshould use the first address or the second for the next\nmicroinstruction.  This design, using a 2^5 bit memory\n(1,152 bits total), appears to the right.\n\n\n{file=part4/figs/microprogrammed-no-decode.eps,width=2in}\n\n\n\nThe microprogram branch control signal is a Boolean logic expression\nbased on the memory ready signal R and \nIR[11].  We can implement it with a state ID comparison and\na mux, as shown to the right.  For the branch instruction execution state, \nthe mux selects input 1, BEN.  For all other states, the mux selects \ninput 0, R.  When an FSM state has only a single next state, we set both \nIDs in the control ROM to the ID for that state, so the value of R \nhas no effect.\n\n\n\n\n\n We can simplify the implementation of the microprogram branch control\n by setting both next-state addresses to the same value when a state\n does not branch.  Then the branch control becomes a don't care for that\n state.\n\n\nWhat's missing?  Decode!  We do have one FSM state in which we need to be\nable to branch to one of sixteen possible next states, one for each\nopcode.  Let's just add another mux and choose the state IDs for starting\nto process each opcode in an easy way, as shown to the right with\nextensions highlighted in blue.  The textbook assigns the first state \nfor processing each opcode the IDs IR[15:12] preceeded by two 0s (the\ntextbook's design requires {6-bit} state IDs).  We adopt the same\nstrategy.  For example, the first FSM state for processing an ADD is 00001, \nand the first state for a TRAP is 01111.  In each case, the opcode \nencoding specifies the last four bits.\n\nNow we can pick the remaining state IDs arbitrarily and fill in the \ncontrol ROM with control \nsignals that implement each state's RTL and the two possible next states.\nTransitions from the decode state are handled by the extra mux.\n\nThe microprogrammed control unit implementation in Appendix C of \nPatt and Patel is similar to the one that we have developed here,\nbut is slightly more complex so that it can handle interrupts\nand privilege.   \n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of microprogrammed control over hardwired control?\n2. What is the main disadvantage of microprogrammed control over hardwired control?\n3. How does microprogrammed control handle decode?",
        "answers": "\n\n1. One advantage of microprogrammed control is that the control signals can be easily modified, allowing for changes to be made quickly and easily.\n2. A disadvantage of microprogrammed control is that it is slower than hardwired control.\n3. Microprogrammed control handles decode by using a mux to select the next state based on the opcode."
    },
    {
        "positive_ctxs": {
            "title": "Microprogrammed Control",
            "text": "{Microprogrammed Control}\n\nWe are now ready to discuss the second approach to control unit design.\nTake another look at the state diagram for the the {LC-3} ISA.  Does it \nremind you of anything?  Like a flowchart, it has relatively few arcs \nleaving each state---usually only one or two.\n\nWhat if we treat the state diagram as a program?  We can use a small\nmemory to hold { microinstructions} (another name for control words) \nand use the FSM state number as the memory address.  \n\nWithout support for interrupts or privilege, and with the datapath \nextension for JSR mentioned for hardwired control, the {LC-3} state \nmachine requires fewer than 32 states.\n\nThe datapath has 25 control signals, but we need one more for the\ndatapath extension for JSR.\n\nWe thus start with {5-bit} state number (in a register)\nand a {2^5 bit} memory, which we call\nour control ROM (read-only memory) to distinguish\nit from the big, slow, von Neumann memory.\n\nEach cycle, the { microprogrammed control} unit applies the FSM state \nnumber to the control ROM (no IR bits, \njust the state number), gets back a set of control signals, and\nuses them to drive the datapath.\n\n\nTo write our microprogram, we need to calculate the control signals\nfor each microinstruction and put them in the control ROM, but we also\nneed to have a way to decide which microinstruction should execute \nnext.  We call the latter problem { sequencing} or microsequencing.\n\nNotice that most of the time there's no choice: we have only { one}\nnext microinstruction.  One simple approach is then to add the address\n(the {5-bit} state ID) of the next microinstruction to the control ROM.\nInstead of 26 bits per FSM state, we now have 31 bits per FSM state.\n\nSometimes we do need to have two possible next states.  When waiting\nfor memory (the von Neumann memory, not the control ROM) to\nfinish an access, for example, we want our FSM to stay\nin the same state, then move to the next state when the access completes.\nLet's add a second address to each microinstruction, and add\na branch control signal for the microprogram to decide whether we\nshould use the first address or the second for the next\nmicroinstruction.  This design, using a 2^5 bit memory\n(1,152 bits total), appears to the right.\n\n\n{file=part4/figs/microprogrammed-no-decode.eps,width=2in}\n\n\n\nThe microprogram branch control signal is a Boolean logic expression\nbased on the memory ready signal R and \nIR[11].  We can implement it with a state ID comparison and\na mux, as shown to the right.  For the branch instruction execution state, \nthe mux selects input 1, BEN.  For all other states, the mux selects \ninput 0, R.  When an FSM state has only a single next state, we set both \nIDs in the control ROM to the ID for that state, so the value of R \nhas no effect.\n\n\n\n\n\n We can simplify the implementation of the microprogram branch control\n by setting both next-state addresses to the same value when a state\n does not branch.  Then the branch control becomes a don't care for that\n state.\n\n\nWhat's missing?  Decode!  We do have one FSM state in which we need to be\nable to branch to one of sixteen possible next states, one for each\nopcode.  Let's just add another mux and choose the state IDs for starting\nto process each opcode in an easy way, as shown to the right with\nextensions highlighted in blue.  The textbook assigns the first state \nfor processing each opcode the IDs IR[15:12] preceeded by two 0s (the\ntextbook's design requires {6-bit} state IDs).  We adopt the same\nstrategy.  For example, the first FSM state for processing an ADD is 00001, \nand the first state for a TRAP is 01111.  In each case, the opcode \nencoding specifies the last four bits.\n\nNow we can pick the remaining state IDs arbitrarily and fill in the \ncontrol ROM with control \nsignals that implement each state's RTL and the two possible next states.\nTransitions from the decode state are handled by the extra mux.\n\nThe microprogrammed control unit implementation in Appendix C of \nPatt and Patel is similar to the one that we have developed here,\nbut is slightly more complex so that it can handle interrupts\nand privilege.   \n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of microprogrammed control over hardwired control?\n2. What is the main disadvantage of microprogrammed control over hardwired control?\n3. How does microprogrammed control handle decode?",
        "answers": "\n\n1. One advantage of microprogrammed control is that the control signals can be easily modified, allowing for changes to be made quickly and easily.\n2. A disadvantage of microprogrammed control is that it is slower than hardwired control.\n3. Microprogrammed control handles decode by using a mux to select the next state based on the opcode."
    },
    {
        "positive_ctxs": {
            "title": "Microprogrammed Control",
            "text": "{Microprogrammed Control}\n\nWe are now ready to discuss the second approach to control unit design.\nTake another look at the state diagram for the the {LC-3} ISA.  Does it \nremind you of anything?  Like a flowchart, it has relatively few arcs \nleaving each state---usually only one or two.\n\nWhat if we treat the state diagram as a program?  We can use a small\nmemory to hold { microinstructions} (another name for control words) \nand use the FSM state number as the memory address.  \n\nWithout support for interrupts or privilege, and with the datapath \nextension for JSR mentioned for hardwired control, the {LC-3} state \nmachine requires fewer than 32 states.\n\nThe datapath has 25 control signals, but we need one more for the\ndatapath extension for JSR.\n\nWe thus start with {5-bit} state number (in a register)\nand a {2^5 bit} memory, which we call\nour control ROM (read-only memory) to distinguish\nit from the big, slow, von Neumann memory.\n\nEach cycle, the { microprogrammed control} unit applies the FSM state \nnumber to the control ROM (no IR bits, \njust the state number), gets back a set of control signals, and\nuses them to drive the datapath.\n\n\nTo write our microprogram, we need to calculate the control signals\nfor each microinstruction and put them in the control ROM, but we also\nneed to have a way to decide which microinstruction should execute \nnext.  We call the latter problem { sequencing} or microsequencing.\n\nNotice that most of the time there's no choice: we have only { one}\nnext microinstruction.  One simple approach is then to add the address\n(the {5-bit} state ID) of the next microinstruction to the control ROM.\nInstead of 26 bits per FSM state, we now have 31 bits per FSM state.\n\nSometimes we do need to have two possible next states.  When waiting\nfor memory (the von Neumann memory, not the control ROM) to\nfinish an access, for example, we want our FSM to stay\nin the same state, then move to the next state when the access completes.\nLet's add a second address to each microinstruction, and add\na branch control signal for the microprogram to decide whether we\nshould use the first address or the second for the next\nmicroinstruction.  This design, using a 2^5 bit memory\n(1,152 bits total), appears to the right.\n\n\n{file=part4/figs/microprogrammed-no-decode.eps,width=2in}\n\n\n\nThe microprogram branch control signal is a Boolean logic expression\nbased on the memory ready signal R and \nIR[11].  We can implement it with a state ID comparison and\na mux, as shown to the right.  For the branch instruction execution state, \nthe mux selects input 1, BEN.  For all other states, the mux selects \ninput 0, R.  When an FSM state has only a single next state, we set both \nIDs in the control ROM to the ID for that state, so the value of R \nhas no effect.\n\n\n\n\n\n We can simplify the implementation of the microprogram branch control\n by setting both next-state addresses to the same value when a state\n does not branch.  Then the branch control becomes a don't care for that\n state.\n\n\nWhat's missing?  Decode!  We do have one FSM state in which we need to be\nable to branch to one of sixteen possible next states, one for each\nopcode.  Let's just add another mux and choose the state IDs for starting\nto process each opcode in an easy way, as shown to the right with\nextensions highlighted in blue.  The textbook assigns the first state \nfor processing each opcode the IDs IR[15:12] preceeded by two 0s (the\ntextbook's design requires {6-bit} state IDs).  We adopt the same\nstrategy.  For example, the first FSM state for processing an ADD is 00001, \nand the first state for a TRAP is 01111.  In each case, the opcode \nencoding specifies the last four bits.\n\nNow we can pick the remaining state IDs arbitrarily and fill in the \ncontrol ROM with control \nsignals that implement each state's RTL and the two possible next states.\nTransitions from the decode state are handled by the extra mux.\n\nThe microprogrammed control unit implementation in Appendix C of \nPatt and Patel is similar to the one that we have developed here,\nbut is slightly more complex so that it can handle interrupts\nand privilege.   \n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of microprogrammed control over hardwired control?\n2. What is the main disadvantage of microprogrammed control over hardwired control?\n3. How does microprogrammed control handle decode?",
        "answers": "\n\n1. One advantage of microprogrammed control is that the control signals can be easily modified, allowing for changes to be made quickly and easily.\n2. A disadvantage of microprogrammed control is that it is slower than hardwired control.\n3. Microprogrammed control handles decode by using a mux to select the next state based on the opcode."
    },
    {
        "positive_ctxs": {
            "title": "Microprogrammed Control",
            "text": "{Microprogrammed Control}\n\nWe are now ready to discuss the second approach to control unit design.\nTake another look at the state diagram for the the {LC-3} ISA.  Does it \nremind you of anything?  Like a flowchart, it has relatively few arcs \nleaving each state---usually only one or two.\n\nWhat if we treat the state diagram as a program?  We can use a small\nmemory to hold { microinstructions} (another name for control words) \nand use the FSM state number as the memory address.  \n\nWithout support for interrupts or privilege, and with the datapath \nextension for JSR mentioned for hardwired control, the {LC-3} state \nmachine requires fewer than 32 states.\n\nThe datapath has 25 control signals, but we need one more for the\ndatapath extension for JSR.\n\nWe thus start with {5-bit} state number (in a register)\nand a {2^5 bit} memory, which we call\nour control ROM (read-only memory) to distinguish\nit from the big, slow, von Neumann memory.\n\nEach cycle, the { microprogrammed control} unit applies the FSM state \nnumber to the control ROM (no IR bits, \njust the state number), gets back a set of control signals, and\nuses them to drive the datapath.\n\n\nTo write our microprogram, we need to calculate the control signals\nfor each microinstruction and put them in the control ROM, but we also\nneed to have a way to decide which microinstruction should execute \nnext.  We call the latter problem { sequencing} or microsequencing.\n\nNotice that most of the time there's no choice: we have only { one}\nnext microinstruction.  One simple approach is then to add the address\n(the {5-bit} state ID) of the next microinstruction to the control ROM.\nInstead of 26 bits per FSM state, we now have 31 bits per FSM state.\n\nSometimes we do need to have two possible next states.  When waiting\nfor memory (the von Neumann memory, not the control ROM) to\nfinish an access, for example, we want our FSM to stay\nin the same state, then move to the next state when the access completes.\nLet's add a second address to each microinstruction, and add\na branch control signal for the microprogram to decide whether we\nshould use the first address or the second for the next\nmicroinstruction.  This design, using a 2^5 bit memory\n(1,152 bits total), appears to the right.\n\n\n{file=part4/figs/microprogrammed-no-decode.eps,width=2in}\n\n\n\nThe microprogram branch control signal is a Boolean logic expression\nbased on the memory ready signal R and \nIR[11].  We can implement it with a state ID comparison and\na mux, as shown to the right.  For the branch instruction execution state, \nthe mux selects input 1, BEN.  For all other states, the mux selects \ninput 0, R.  When an FSM state has only a single next state, we set both \nIDs in the control ROM to the ID for that state, so the value of R \nhas no effect.\n\n\n\n\n\n We can simplify the implementation of the microprogram branch control\n by setting both next-state addresses to the same value when a state\n does not branch.  Then the branch control becomes a don't care for that\n state.\n\n\nWhat's missing?  Decode!  We do have one FSM state in which we need to be\nable to branch to one of sixteen possible next states, one for each\nopcode.  Let's just add another mux and choose the state IDs for starting\nto process each opcode in an easy way, as shown to the right with\nextensions highlighted in blue.  The textbook assigns the first state \nfor processing each opcode the IDs IR[15:12] preceeded by two 0s (the\ntextbook's design requires {6-bit} state IDs).  We adopt the same\nstrategy.  For example, the first FSM state for processing an ADD is 00001, \nand the first state for a TRAP is 01111.  In each case, the opcode \nencoding specifies the last four bits.\n\nNow we can pick the remaining state IDs arbitrarily and fill in the \ncontrol ROM with control \nsignals that implement each state's RTL and the two possible next states.\nTransitions from the decode state are handled by the extra mux.\n\nThe microprogrammed control unit implementation in Appendix C of \nPatt and Patel is similar to the one that we have developed here,\nbut is slightly more complex so that it can handle interrupts\nand privilege.   \n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of microprogrammed control over hardwired control?\n2. What is the main disadvantage of microprogrammed control over hardwired control?\n3. How does microprogrammed control handle decode?",
        "answers": "\n\n1. One advantage of microprogrammed control is that the control signals can be easily modified, allowing for changes to be made quickly and easily.\n2. A disadvantage of microprogrammed control is that it is slower than hardwired control.\n3. Microprogrammed control handles decode by using a mux to select the next state based on the opcode."
    },
    {
        "positive_ctxs": {
            "title": "Microprogrammed Control",
            "text": "{Microprogrammed Control}\n\nWe are now ready to discuss the second approach to control unit design.\nTake another look at the state diagram for the the {LC-3} ISA.  Does it \nremind you of anything?  Like a flowchart, it has relatively few arcs \nleaving each state---usually only one or two.\n\nWhat if we treat the state diagram as a program?  We can use a small\nmemory to hold { microinstructions} (another name for control words) \nand use the FSM state number as the memory address.  \n\nWithout support for interrupts or privilege, and with the datapath \nextension for JSR mentioned for hardwired control, the {LC-3} state \nmachine requires fewer than 32 states.\n\nThe datapath has 25 control signals, but we need one more for the\ndatapath extension for JSR.\n\nWe thus start with {5-bit} state number (in a register)\nand a {2^5 bit} memory, which we call\nour control ROM (read-only memory) to distinguish\nit from the big, slow, von Neumann memory.\n\nEach cycle, the { microprogrammed control} unit applies the FSM state \nnumber to the control ROM (no IR bits, \njust the state number), gets back a set of control signals, and\nuses them to drive the datapath.\n\n\nTo write our microprogram, we need to calculate the control signals\nfor each microinstruction and put them in the control ROM, but we also\nneed to have a way to decide which microinstruction should execute \nnext.  We call the latter problem { sequencing} or microsequencing.\n\nNotice that most of the time there's no choice: we have only { one}\nnext microinstruction.  One simple approach is then to add the address\n(the {5-bit} state ID) of the next microinstruction to the control ROM.\nInstead of 26 bits per FSM state, we now have 31 bits per FSM state.\n\nSometimes we do need to have two possible next states.  When waiting\nfor memory (the von Neumann memory, not the control ROM) to\nfinish an access, for example, we want our FSM to stay\nin the same state, then move to the next state when the access completes.\nLet's add a second address to each microinstruction, and add\na branch control signal for the microprogram to decide whether we\nshould use the first address or the second for the next\nmicroinstruction.  This design, using a 2^5 bit memory\n(1,152 bits total), appears to the right.\n\n\n{file=part4/figs/microprogrammed-no-decode.eps,width=2in}\n\n\n\nThe microprogram branch control signal is a Boolean logic expression\nbased on the memory ready signal R and \nIR[11].  We can implement it with a state ID comparison and\na mux, as shown to the right.  For the branch instruction execution state, \nthe mux selects input 1, BEN.  For all other states, the mux selects \ninput 0, R.  When an FSM state has only a single next state, we set both \nIDs in the control ROM to the ID for that state, so the value of R \nhas no effect.\n\n\n\n\n\n We can simplify the implementation of the microprogram branch control\n by setting both next-state addresses to the same value when a state\n does not branch.  Then the branch control becomes a don't care for that\n state.\n\n\nWhat's missing?  Decode!  We do have one FSM state in which we need to be\nable to branch to one of sixteen possible next states, one for each\nopcode.  Let's just add another mux and choose the state IDs for starting\nto process each opcode in an easy way, as shown to the right with\nextensions highlighted in blue.  The textbook assigns the first state \nfor processing each opcode the IDs IR[15:12] preceeded by two 0s (the\ntextbook's design requires {6-bit} state IDs).  We adopt the same\nstrategy.  For example, the first FSM state for processing an ADD is 00001, \nand the first state for a TRAP is 01111.  In each case, the opcode \nencoding specifies the last four bits.\n\nNow we can pick the remaining state IDs arbitrarily and fill in the \ncontrol ROM with control \nsignals that implement each state's RTL and the two possible next states.\nTransitions from the decode state are handled by the extra mux.\n\nThe microprogrammed control unit implementation in Appendix C of \nPatt and Patel is similar to the one that we have developed here,\nbut is slightly more complex so that it can handle interrupts\nand privilege.   \n\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the main advantage of microprogrammed control over hardwired control?\n2. What is the main disadvantage of microprogrammed control over hardwired control?\n3. How does microprogrammed control handle decode?",
        "answers": "\n\n1. One advantage of microprogrammed control is that the control signals can be easily modified, allowing for changes to be made quickly and easily.\n2. A disadvantage of microprogrammed control is that it is slower than hardwired control.\n3. Microprogrammed control handles decode by using a mux to select the next state based on the opcode."
    },
    {
        "positive_ctxs": {
            "title": "SEC-DED Codes",
            "text": "{SEC-DED Codes}\n\nWe now consider one final extension of Hamming codes to enable a system\nto perform single error correction while also detecting any two bit errors.\nSuch codes are known as { Single Error Correction, Double Error \nDetection (SEC-DED)} codes.  Creating such a code from a Hamming code is\ntrivial: add a parity bit covering the entire Hamming code.  The extra\nparity bit increases the Hamming distance to 4.  A Hamming distance of 4\nstill allows only single bit error correction, but avoids the problem\nof Hamming distance 3 codes when two bit errors occur, since patterns\nat Hamming distance 2 from a valid code word cannot be within distance 1\nof another code word, and thus cannot be ``corrected'' to the wrong\nresult.\n\nIn fact, one can add a parity bit to any representation with an odd\nHamming distance to create a new representation with Hamming distance\none greater than the original representation.  To proof this convenient\nfact, begin with a representation with Hamming distance d, where d\nis odd.  If we choose two code words from the representation, and their \nHamming distance is already greater than d, their distance in the \nnew representation will also be greater than d.  Adding a parity\nbit cannot decrease the distance.  On the other hand, if the two code\nwords are exactly distance d apart, they must have opposite parity,\nsince they differ by an odd number of bits.  Thus the new parity bit\nwill be a 0 for one of the code words and a 1 for the other, increasing\nthe Hamming distance to d+1 in the new representation.  Since all\npairs of code words have Hamming distance of at least d+1, the\nnew representation also has Hamming distance d+1.\n\n\n\n\n\n"
        },
        "questions": "\n1. What happens if two bit errors occur in a Hamming distance 3 code?\n2. How does adding a parity bit to a code word increase the Hamming distance?\n3. What is the Hamming distance of a SEC-DED code?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "SEC-DED Codes",
            "text": "{SEC-DED Codes}\n\nWe now consider one final extension of Hamming codes to enable a system\nto perform single error correction while also detecting any two bit errors.\nSuch codes are known as { Single Error Correction, Double Error \nDetection (SEC-DED)} codes.  Creating such a code from a Hamming code is\ntrivial: add a parity bit covering the entire Hamming code.  The extra\nparity bit increases the Hamming distance to 4.  A Hamming distance of 4\nstill allows only single bit error correction, but avoids the problem\nof Hamming distance 3 codes when two bit errors occur, since patterns\nat Hamming distance 2 from a valid code word cannot be within distance 1\nof another code word, and thus cannot be ``corrected'' to the wrong\nresult.\n\nIn fact, one can add a parity bit to any representation with an odd\nHamming distance to create a new representation with Hamming distance\none greater than the original representation.  To proof this convenient\nfact, begin with a representation with Hamming distance d, where d\nis odd.  If we choose two code words from the representation, and their \nHamming distance is already greater than d, their distance in the \nnew representation will also be greater than d.  Adding a parity\nbit cannot decrease the distance.  On the other hand, if the two code\nwords are exactly distance d apart, they must have opposite parity,\nsince they differ by an odd number of bits.  Thus the new parity bit\nwill be a 0 for one of the code words and a 1 for the other, increasing\nthe Hamming distance to d+1 in the new representation.  Since all\npairs of code words have Hamming distance of at least d+1, the\nnew representation also has Hamming distance d+1.\n\n\n\n\n\n"
        },
        "questions": "\n1. What happens if two bit errors occur in a Hamming distance 3 code?\n2. How does adding a parity bit to a code word increase the Hamming distance?\n3. What is the Hamming distance of a SEC-DED code?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "SEC-DED Codes",
            "text": "{SEC-DED Codes}\n\nWe now consider one final extension of Hamming codes to enable a system\nto perform single error correction while also detecting any two bit errors.\nSuch codes are known as { Single Error Correction, Double Error \nDetection (SEC-DED)} codes.  Creating such a code from a Hamming code is\ntrivial: add a parity bit covering the entire Hamming code.  The extra\nparity bit increases the Hamming distance to 4.  A Hamming distance of 4\nstill allows only single bit error correction, but avoids the problem\nof Hamming distance 3 codes when two bit errors occur, since patterns\nat Hamming distance 2 from a valid code word cannot be within distance 1\nof another code word, and thus cannot be ``corrected'' to the wrong\nresult.\n\nIn fact, one can add a parity bit to any representation with an odd\nHamming distance to create a new representation with Hamming distance\none greater than the original representation.  To proof this convenient\nfact, begin with a representation with Hamming distance d, where d\nis odd.  If we choose two code words from the representation, and their \nHamming distance is already greater than d, their distance in the \nnew representation will also be greater than d.  Adding a parity\nbit cannot decrease the distance.  On the other hand, if the two code\nwords are exactly distance d apart, they must have opposite parity,\nsince they differ by an odd number of bits.  Thus the new parity bit\nwill be a 0 for one of the code words and a 1 for the other, increasing\nthe Hamming distance to d+1 in the new representation.  Since all\npairs of code words have Hamming distance of at least d+1, the\nnew representation also has Hamming distance d+1.\n\n\n\n\n\n"
        },
        "questions": "\n1. What happens if two bit errors occur in a Hamming distance 3 code?\n2. How does adding a parity bit to a code word increase the Hamming distance?\n3. What is the Hamming distance of a SEC-DED code?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "SEC-DED Codes",
            "text": "{SEC-DED Codes}\n\nWe now consider one final extension of Hamming codes to enable a system\nto perform single error correction while also detecting any two bit errors.\nSuch codes are known as { Single Error Correction, Double Error \nDetection (SEC-DED)} codes.  Creating such a code from a Hamming code is\ntrivial: add a parity bit covering the entire Hamming code.  The extra\nparity bit increases the Hamming distance to 4.  A Hamming distance of 4\nstill allows only single bit error correction, but avoids the problem\nof Hamming distance 3 codes when two bit errors occur, since patterns\nat Hamming distance 2 from a valid code word cannot be within distance 1\nof another code word, and thus cannot be ``corrected'' to the wrong\nresult.\n\nIn fact, one can add a parity bit to any representation with an odd\nHamming distance to create a new representation with Hamming distance\none greater than the original representation.  To proof this convenient\nfact, begin with a representation with Hamming distance d, where d\nis odd.  If we choose two code words from the representation, and their \nHamming distance is already greater than d, their distance in the \nnew representation will also be greater than d.  Adding a parity\nbit cannot decrease the distance.  On the other hand, if the two code\nwords are exactly distance d apart, they must have opposite parity,\nsince they differ by an odd number of bits.  Thus the new parity bit\nwill be a 0 for one of the code words and a 1 for the other, increasing\nthe Hamming distance to d+1 in the new representation.  Since all\npairs of code words have Hamming distance of at least d+1, the\nnew representation also has Hamming distance d+1.\n\n\n\n\n\n"
        },
        "questions": "\n1. What happens if two bit errors occur in a Hamming distance 3 code?\n2. How does adding a parity bit to a code word increase the Hamming distance?\n3. What is the Hamming distance of a SEC-DED code?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "SEC-DED Codes",
            "text": "{SEC-DED Codes}\n\nWe now consider one final extension of Hamming codes to enable a system\nto perform single error correction while also detecting any two bit errors.\nSuch codes are known as { Single Error Correction, Double Error \nDetection (SEC-DED)} codes.  Creating such a code from a Hamming code is\ntrivial: add a parity bit covering the entire Hamming code.  The extra\nparity bit increases the Hamming distance to 4.  A Hamming distance of 4\nstill allows only single bit error correction, but avoids the problem\nof Hamming distance 3 codes when two bit errors occur, since patterns\nat Hamming distance 2 from a valid code word cannot be within distance 1\nof another code word, and thus cannot be ``corrected'' to the wrong\nresult.\n\nIn fact, one can add a parity bit to any representation with an odd\nHamming distance to create a new representation with Hamming distance\none greater than the original representation.  To proof this convenient\nfact, begin with a representation with Hamming distance d, where d\nis odd.  If we choose two code words from the representation, and their \nHamming distance is already greater than d, their distance in the \nnew representation will also be greater than d.  Adding a parity\nbit cannot decrease the distance.  On the other hand, if the two code\nwords are exactly distance d apart, they must have opposite parity,\nsince they differ by an odd number of bits.  Thus the new parity bit\nwill be a 0 for one of the code words and a 1 for the other, increasing\nthe Hamming distance to d+1 in the new representation.  Since all\npairs of code words have Hamming distance of at least d+1, the\nnew representation also has Hamming distance d+1.\n\n\n\n\n\n"
        },
        "questions": "\n1. What happens if two bit errors occur in a Hamming distance 3 code?\n2. How does adding a parity bit to a code word increase the Hamming distance?\n3. What is the Hamming distance of a SEC-DED code?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "SEC-DED Codes",
            "text": "{SEC-DED Codes}\n\nWe now consider one final extension of Hamming codes to enable a system\nto perform single error correction while also detecting any two bit errors.\nSuch codes are known as { Single Error Correction, Double Error \nDetection (SEC-DED)} codes.  Creating such a code from a Hamming code is\ntrivial: add a parity bit covering the entire Hamming code.  The extra\nparity bit increases the Hamming distance to 4.  A Hamming distance of 4\nstill allows only single bit error correction, but avoids the problem\nof Hamming distance 3 codes when two bit errors occur, since patterns\nat Hamming distance 2 from a valid code word cannot be within distance 1\nof another code word, and thus cannot be ``corrected'' to the wrong\nresult.\n\nIn fact, one can add a parity bit to any representation with an odd\nHamming distance to create a new representation with Hamming distance\none greater than the original representation.  To proof this convenient\nfact, begin with a representation with Hamming distance d, where d\nis odd.  If we choose two code words from the representation, and their \nHamming distance is already greater than d, their distance in the \nnew representation will also be greater than d.  Adding a parity\nbit cannot decrease the distance.  On the other hand, if the two code\nwords are exactly distance d apart, they must have opposite parity,\nsince they differ by an odd number of bits.  Thus the new parity bit\nwill be a 0 for one of the code words and a 1 for the other, increasing\nthe Hamming distance to d+1 in the new representation.  Since all\npairs of code words have Hamming distance of at least d+1, the\nnew representation also has Hamming distance d+1.\n\n\n\n\n\n"
        },
        "questions": "\n1. What happens if two bit errors occur in a Hamming distance 3 code?\n2. How does adding a parity bit to a code word increase the Hamming distance?\n3. What is the Hamming distance of a SEC-DED code?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "SEC-DED Codes",
            "text": "{SEC-DED Codes}\n\nWe now consider one final extension of Hamming codes to enable a system\nto perform single error correction while also detecting any two bit errors.\nSuch codes are known as { Single Error Correction, Double Error \nDetection (SEC-DED)} codes.  Creating such a code from a Hamming code is\ntrivial: add a parity bit covering the entire Hamming code.  The extra\nparity bit increases the Hamming distance to 4.  A Hamming distance of 4\nstill allows only single bit error correction, but avoids the problem\nof Hamming distance 3 codes when two bit errors occur, since patterns\nat Hamming distance 2 from a valid code word cannot be within distance 1\nof another code word, and thus cannot be ``corrected'' to the wrong\nresult.\n\nIn fact, one can add a parity bit to any representation with an odd\nHamming distance to create a new representation with Hamming distance\none greater than the original representation.  To proof this convenient\nfact, begin with a representation with Hamming distance d, where d\nis odd.  If we choose two code words from the representation, and their \nHamming distance is already greater than d, their distance in the \nnew representation will also be greater than d.  Adding a parity\nbit cannot decrease the distance.  On the other hand, if the two code\nwords are exactly distance d apart, they must have opposite parity,\nsince they differ by an odd number of bits.  Thus the new parity bit\nwill be a 0 for one of the code words and a 1 for the other, increasing\nthe Hamming distance to d+1 in the new representation.  Since all\npairs of code words have Hamming distance of at least d+1, the\nnew representation also has Hamming distance d+1.\n\n\n\n\n\n"
        },
        "questions": "\n1. What happens if two bit errors occur in a Hamming distance 3 code?\n2. How does adding a parity bit to a code word increase the Hamming distance?\n3. What is the Hamming distance of a SEC-DED code?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "SEC-DED Codes",
            "text": "{SEC-DED Codes}\n\nWe now consider one final extension of Hamming codes to enable a system\nto perform single error correction while also detecting any two bit errors.\nSuch codes are known as { Single Error Correction, Double Error \nDetection (SEC-DED)} codes.  Creating such a code from a Hamming code is\ntrivial: add a parity bit covering the entire Hamming code.  The extra\nparity bit increases the Hamming distance to 4.  A Hamming distance of 4\nstill allows only single bit error correction, but avoids the problem\nof Hamming distance 3 codes when two bit errors occur, since patterns\nat Hamming distance 2 from a valid code word cannot be within distance 1\nof another code word, and thus cannot be ``corrected'' to the wrong\nresult.\n\nIn fact, one can add a parity bit to any representation with an odd\nHamming distance to create a new representation with Hamming distance\none greater than the original representation.  To proof this convenient\nfact, begin with a representation with Hamming distance d, where d\nis odd.  If we choose two code words from the representation, and their \nHamming distance is already greater than d, their distance in the \nnew representation will also be greater than d.  Adding a parity\nbit cannot decrease the distance.  On the other hand, if the two code\nwords are exactly distance d apart, they must have opposite parity,\nsince they differ by an odd number of bits.  Thus the new parity bit\nwill be a 0 for one of the code words and a 1 for the other, increasing\nthe Hamming distance to d+1 in the new representation.  Since all\npairs of code words have Hamming distance of at least d+1, the\nnew representation also has Hamming distance d+1.\n\n\n\n\n\n"
        },
        "questions": "\n1. What happens if two bit errors occur in a Hamming distance 3 code?\n2. How does adding a parity bit to a code word increase the Hamming distance?\n3. What is the Hamming distance of a SEC-DED code?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Summary of Part 4 of the Course",
            "text": "{Summary of Part 4 of the Course}\n\nWith the exception of control unit design strategies and redundancy \nand coding, most of the material in this part of the course is drawn from\nPatt and Patel Chapters 4 through 7.  You may also want to read Patt and \nPatel's Appendix C for details of their control unit design.\n\nIn this short summary, we give you lists at several levels of difficulty\nof what we expect you to be able to do as a result of the last few weeks\nof studying (reading, listening, doing homework, discussing your\nunderstanding with your classmates, and so forth).\n\nWe'll start with the easy stuff.  You should recognize all of these terms\nand be able to explain what they mean.  \n For the specific circuits, you \n should be able to draw them and explain how they work.\n(You may skip the *'d terms in Fall 2012.)\n\n\n\n[t]\n{}{{}{}\n{}{}{}\n\n{von Neumann elements}\n{-}{{}{}\n{}{}{}\n{program counter (PC)}\n{instruction register (IR)}\n{memory address register (MAR)}\n{memory data register (MDR)}\n{processor datapath}\n\n{control signal}\n{instruction processing}\n\n\n{Instruction Set Architecture (ISA)}\n{-}{{}{}\n{}{}{}\n{instruction encoding}\n{field (in an encoded instruction)}\n{operation code (opcode)}\n\n\n{assemblers and assembly code}\n{-}{{}{}\n{}{}{}\n{opcode mnemonic (such as ADD, JMP)}\n{two-pass process}\n\n{symbol table}\n{pseudo-op / directive}\n\n\n\n\n[t]\n{}{{}{}\n{}{}{}\n\n{systematic decomposition}\n{-}{{}{}\n{}{}{}\n\n\n\n\n\n no documentation, and advanced topics ... no testing\n\n {logic design optimization}\n {-}{{}{}\n {}{}{}\n {bit-sliced (including multiple bits per slice)}\n \n {pipelined logic}\n {tree-based}\n \n\n{control unit design strategies}\n{-}{{}{}\n{}{}{}\n{control word / microinstruction}\n{sequencing / microsequencing}\n{hardwired control}\n{-}{{}{}\n{}{}{}\n{single-cycle}\n{multi-cycle}\n\n{microprogrammed control}\n {pipelining (of instruction processing)}\n\n\n{error detection and correction\n{--}{{}{}\n{}{}{}\n code/sparse representation\n code word\n bit error\n odd/even parity bit\n Hamming distance between code words\n Hamming distance of a code\n Hamming code\n SEC-DED\n\n}\n\n\n\n\n\n\n\n\n\n\n\n\nWe expect you to be able to exercise the following skills:\n\n{}{{}{}\n{}{}{}\n\n FIXME ... should write something about critical path, but expecting\n them to do much with it isn't reasonable\n\n {Implement arbitrary Boolean logic, and be able to reason about\n alternative designs in terms of their critical path delays and number\n of gates required to implement.}\n\n{Map RTL (register transfer language) operations into control words\nfor a given processor datapath.}\n\n{Systematically decompose a (simple enough) problem to the level \nof {LC-3} instructions.}\n\n{Encode {LC-3} instructions into machine code.}\n\n{Read and understand programs written in {LC-3} assembly/machine code.}\n\n{Test and debug a small program in {LC-3} assembly/machine code.}\n\n{Be able to calculate the Hamming distance of a code/representation.}\n\n{Know the relationships between Hamming distance and the abilities\nto detect and to correct bit errors.}\n\n\n\nWe expect that you will understand the concepts and ideas to the extent\nthat you can do the following:\n\n{}{{}{}\n{}{}{}\n\n{Explain the role of different types of instructions in allowing\na programmer to express a computation.}\n\n FIXME: ISA design is beyond the scope of this course; just include\n for interest, if at all\n\n {Explain the tradeoffs in different addressing modes so as to motivate\n inclusion of multiple addressing modes in an ISA.}\n\n{Explain the importance of the three types of subdivisions in systematic\ndecomposition (sequential, conditional, and iterative).}\n\n{Explain the process of transforming assembly code into machine code\n(that is, explain how an assembler works, including describing the use of\nthe symbol table).}\n\n{Be able to use parity for error detection, and Hamming codes for\nerror correction.}\n\n\n\nAt the highest level, \nwe hope that, while you do not have direct substantial experience in \nthis regard from our class (and should not expect to be tested on these\nskills), that you will nonetheless be able to begin\nto do the following when designing combinational logic:\n\n{}{{}{}\n{}{}{}\n\n{Design and compare implementations using gates, decoders, muxes, and/or memories \nas appropriate, and including reasoning about the relevant design tradeoffs \nin terms of area and delay.}\n\n{Design and compare implementation as a bit-sliced, serial, pipelined, or tree-based \ndesign, again including reasoning about the relevant design tradeoffs in\nterms of area and delay.}\n\n{Design and compare implementations of processor control units\nusing both hardwired and microprogrammed strategies,\nand again including reasoning about the relevant design tradeoffs in\nterms of area and delay.}\n\n{Understand basic tradeoffs in the sparsity of code words with error \ndetection and correction capabilities.}\n\n\n\n\n\n{   }   blank 3rd page\n\n\n\n\n"
        },
        "questions": "\n1. What is the role of instructions in allowing a programmer to express a computation?\n2. What are the tradeoffs in different addressing modes?\n3. What is the importance of the three types of subdivisions in systematic decomposition?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Adders and Word Size\\vspace12pt",
            "text": "{Adders and Word Size}\n\n\nNow that we know how to build an {N-bit} adder, we can add\nsome detail to the diagram that we drew when we \nintroduced 2's complement back in Notes Set 1.2, as shown to the right.\n\nThe adder is important enough to computer systems to merit its own\nsymbol in logic diagrams, which is shown to the right with the inputs\nand outputs from our design added as labels.  The text in the middle\nmarking the symbol as an adder is only included for clarity: { any time \nyou see a symbol of the shape shown to the right, it is an adder} (or \nsometimes a device that can add and do other operations).  The width \nof the operand input and output lines then tells you the size of the \nadder.\n\n\n{file=part2/figs/adder-trad.eps,width=1.3in}\n\n\nYou may already know that most computers have a { word size}\nspecified as part of the Instruction Set Architecture.  The word\nsize specifies the number of bits in each operand when the computer\nadds two numbers, and is often used widely within the \nmicroarchitecture as well (for example, to decide the number of \nwires to use when moving bits around).  Most desktop and laptop machines\nnow have a word size of 64 bits, but many phone processors (and\ndesktops/laptops a few years ago) use a {32-bit} word size.\nEmbedded microcontrollers may use a {16-bit} or even \nan {8-bit} word size.\n\n\nHaving seen how we can build an {N-bit} adder from simple\nchunks of logic operating on each pair of bits, you should not have\nmuch difficulty in understanding the diagram to the right.\n\nIf we start with a design for an {N-bit} adder---even if that\ndesign is not built from bit slices, but is instead optimized for\nthat particular size---we can create a {2N-bit} adder by \nsimply connecting two copies of the {N-bit} adder.  We give\nthe adder for the less significant bits (the one on the right\nin the figure) an initial carry of 0,\nand pass the carry produced by the adder for the less significant\nbits into the carry input of the adder for the more significant\nbits.  We calculate overflow based on the results of the adder\nfor more significant bits (the one on the left in the figure), \nusing the method appropriate to the \ntype of operands we are adding (either unsigned or 2's complement).\n\n\n{file=part2/figs/adder-x2.eps,width=2.15in}\n\n\nYou should also realize that this connection need not be physical.\nIn other words, if a computer has an {N-bit} adder, it can\nhandle operands with 2N bits (or 3N, or 10N, or 42N) by\nusing the {N-bit} adder repeatedly, starting with the\nleast significant bits and working upward until all of the bits\nhave been added.  The computer must of course arrange to have the\noperands routed to the adder a few bits at a time, and must\nensure that the carry produced by each addition is then delivered to\nthe carry input (of the same adder!) for the next addition.\nIn the coming months, you will learn how to design hardware that\nallows you to manage bits in this way, so that by the end of our\nclass, you will be able to design a simple computer on your own.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an adder?\n2. What is an N-bit adder?\n3. How can a 2N-bit adder be made from two N-bit adders?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Adders and Word Size\\vspace12pt",
            "text": "{Adders and Word Size}\n\n\nNow that we know how to build an {N-bit} adder, we can add\nsome detail to the diagram that we drew when we \nintroduced 2's complement back in Notes Set 1.2, as shown to the right.\n\nThe adder is important enough to computer systems to merit its own\nsymbol in logic diagrams, which is shown to the right with the inputs\nand outputs from our design added as labels.  The text in the middle\nmarking the symbol as an adder is only included for clarity: { any time \nyou see a symbol of the shape shown to the right, it is an adder} (or \nsometimes a device that can add and do other operations).  The width \nof the operand input and output lines then tells you the size of the \nadder.\n\n\n{file=part2/figs/adder-trad.eps,width=1.3in}\n\n\nYou may already know that most computers have a { word size}\nspecified as part of the Instruction Set Architecture.  The word\nsize specifies the number of bits in each operand when the computer\nadds two numbers, and is often used widely within the \nmicroarchitecture as well (for example, to decide the number of \nwires to use when moving bits around).  Most desktop and laptop machines\nnow have a word size of 64 bits, but many phone processors (and\ndesktops/laptops a few years ago) use a {32-bit} word size.\nEmbedded microcontrollers may use a {16-bit} or even \nan {8-bit} word size.\n\n\nHaving seen how we can build an {N-bit} adder from simple\nchunks of logic operating on each pair of bits, you should not have\nmuch difficulty in understanding the diagram to the right.\n\nIf we start with a design for an {N-bit} adder---even if that\ndesign is not built from bit slices, but is instead optimized for\nthat particular size---we can create a {2N-bit} adder by \nsimply connecting two copies of the {N-bit} adder.  We give\nthe adder for the less significant bits (the one on the right\nin the figure) an initial carry of 0,\nand pass the carry produced by the adder for the less significant\nbits into the carry input of the adder for the more significant\nbits.  We calculate overflow based on the results of the adder\nfor more significant bits (the one on the left in the figure), \nusing the method appropriate to the \ntype of operands we are adding (either unsigned or 2's complement).\n\n\n{file=part2/figs/adder-x2.eps,width=2.15in}\n\n\nYou should also realize that this connection need not be physical.\nIn other words, if a computer has an {N-bit} adder, it can\nhandle operands with 2N bits (or 3N, or 10N, or 42N) by\nusing the {N-bit} adder repeatedly, starting with the\nleast significant bits and working upward until all of the bits\nhave been added.  The computer must of course arrange to have the\noperands routed to the adder a few bits at a time, and must\nensure that the carry produced by each addition is then delivered to\nthe carry input (of the same adder!) for the next addition.\nIn the coming months, you will learn how to design hardware that\nallows you to manage bits in this way, so that by the end of our\nclass, you will be able to design a simple computer on your own.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an adder?\n2. What is an N-bit adder?\n3. How can a 2N-bit adder be made from two N-bit adders?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Adders and Word Size\\vspace12pt",
            "text": "{Adders and Word Size}\n\n\nNow that we know how to build an {N-bit} adder, we can add\nsome detail to the diagram that we drew when we \nintroduced 2's complement back in Notes Set 1.2, as shown to the right.\n\nThe adder is important enough to computer systems to merit its own\nsymbol in logic diagrams, which is shown to the right with the inputs\nand outputs from our design added as labels.  The text in the middle\nmarking the symbol as an adder is only included for clarity: { any time \nyou see a symbol of the shape shown to the right, it is an adder} (or \nsometimes a device that can add and do other operations).  The width \nof the operand input and output lines then tells you the size of the \nadder.\n\n\n{file=part2/figs/adder-trad.eps,width=1.3in}\n\n\nYou may already know that most computers have a { word size}\nspecified as part of the Instruction Set Architecture.  The word\nsize specifies the number of bits in each operand when the computer\nadds two numbers, and is often used widely within the \nmicroarchitecture as well (for example, to decide the number of \nwires to use when moving bits around).  Most desktop and laptop machines\nnow have a word size of 64 bits, but many phone processors (and\ndesktops/laptops a few years ago) use a {32-bit} word size.\nEmbedded microcontrollers may use a {16-bit} or even \nan {8-bit} word size.\n\n\nHaving seen how we can build an {N-bit} adder from simple\nchunks of logic operating on each pair of bits, you should not have\nmuch difficulty in understanding the diagram to the right.\n\nIf we start with a design for an {N-bit} adder---even if that\ndesign is not built from bit slices, but is instead optimized for\nthat particular size---we can create a {2N-bit} adder by \nsimply connecting two copies of the {N-bit} adder.  We give\nthe adder for the less significant bits (the one on the right\nin the figure) an initial carry of 0,\nand pass the carry produced by the adder for the less significant\nbits into the carry input of the adder for the more significant\nbits.  We calculate overflow based on the results of the adder\nfor more significant bits (the one on the left in the figure), \nusing the method appropriate to the \ntype of operands we are adding (either unsigned or 2's complement).\n\n\n{file=part2/figs/adder-x2.eps,width=2.15in}\n\n\nYou should also realize that this connection need not be physical.\nIn other words, if a computer has an {N-bit} adder, it can\nhandle operands with 2N bits (or 3N, or 10N, or 42N) by\nusing the {N-bit} adder repeatedly, starting with the\nleast significant bits and working upward until all of the bits\nhave been added.  The computer must of course arrange to have the\noperands routed to the adder a few bits at a time, and must\nensure that the carry produced by each addition is then delivered to\nthe carry input (of the same adder!) for the next addition.\nIn the coming months, you will learn how to design hardware that\nallows you to manage bits in this way, so that by the end of our\nclass, you will be able to design a simple computer on your own.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an adder?\n2. What is an N-bit adder?\n3. How can a 2N-bit adder be made from two N-bit adders?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Adders and Word Size\\vspace12pt",
            "text": "{Adders and Word Size}\n\n\nNow that we know how to build an {N-bit} adder, we can add\nsome detail to the diagram that we drew when we \nintroduced 2's complement back in Notes Set 1.2, as shown to the right.\n\nThe adder is important enough to computer systems to merit its own\nsymbol in logic diagrams, which is shown to the right with the inputs\nand outputs from our design added as labels.  The text in the middle\nmarking the symbol as an adder is only included for clarity: { any time \nyou see a symbol of the shape shown to the right, it is an adder} (or \nsometimes a device that can add and do other operations).  The width \nof the operand input and output lines then tells you the size of the \nadder.\n\n\n{file=part2/figs/adder-trad.eps,width=1.3in}\n\n\nYou may already know that most computers have a { word size}\nspecified as part of the Instruction Set Architecture.  The word\nsize specifies the number of bits in each operand when the computer\nadds two numbers, and is often used widely within the \nmicroarchitecture as well (for example, to decide the number of \nwires to use when moving bits around).  Most desktop and laptop machines\nnow have a word size of 64 bits, but many phone processors (and\ndesktops/laptops a few years ago) use a {32-bit} word size.\nEmbedded microcontrollers may use a {16-bit} or even \nan {8-bit} word size.\n\n\nHaving seen how we can build an {N-bit} adder from simple\nchunks of logic operating on each pair of bits, you should not have\nmuch difficulty in understanding the diagram to the right.\n\nIf we start with a design for an {N-bit} adder---even if that\ndesign is not built from bit slices, but is instead optimized for\nthat particular size---we can create a {2N-bit} adder by \nsimply connecting two copies of the {N-bit} adder.  We give\nthe adder for the less significant bits (the one on the right\nin the figure) an initial carry of 0,\nand pass the carry produced by the adder for the less significant\nbits into the carry input of the adder for the more significant\nbits.  We calculate overflow based on the results of the adder\nfor more significant bits (the one on the left in the figure), \nusing the method appropriate to the \ntype of operands we are adding (either unsigned or 2's complement).\n\n\n{file=part2/figs/adder-x2.eps,width=2.15in}\n\n\nYou should also realize that this connection need not be physical.\nIn other words, if a computer has an {N-bit} adder, it can\nhandle operands with 2N bits (or 3N, or 10N, or 42N) by\nusing the {N-bit} adder repeatedly, starting with the\nleast significant bits and working upward until all of the bits\nhave been added.  The computer must of course arrange to have the\noperands routed to the adder a few bits at a time, and must\nensure that the carry produced by each addition is then delivered to\nthe carry input (of the same adder!) for the next addition.\nIn the coming months, you will learn how to design hardware that\nallows you to manage bits in this way, so that by the end of our\nclass, you will be able to design a simple computer on your own.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an adder?\n2. What is an N-bit adder?\n3. How can a 2N-bit adder be made from two N-bit adders?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Adders and Word Size\\vspace12pt",
            "text": "{Adders and Word Size}\n\n\nNow that we know how to build an {N-bit} adder, we can add\nsome detail to the diagram that we drew when we \nintroduced 2's complement back in Notes Set 1.2, as shown to the right.\n\nThe adder is important enough to computer systems to merit its own\nsymbol in logic diagrams, which is shown to the right with the inputs\nand outputs from our design added as labels.  The text in the middle\nmarking the symbol as an adder is only included for clarity: { any time \nyou see a symbol of the shape shown to the right, it is an adder} (or \nsometimes a device that can add and do other operations).  The width \nof the operand input and output lines then tells you the size of the \nadder.\n\n\n{file=part2/figs/adder-trad.eps,width=1.3in}\n\n\nYou may already know that most computers have a { word size}\nspecified as part of the Instruction Set Architecture.  The word\nsize specifies the number of bits in each operand when the computer\nadds two numbers, and is often used widely within the \nmicroarchitecture as well (for example, to decide the number of \nwires to use when moving bits around).  Most desktop and laptop machines\nnow have a word size of 64 bits, but many phone processors (and\ndesktops/laptops a few years ago) use a {32-bit} word size.\nEmbedded microcontrollers may use a {16-bit} or even \nan {8-bit} word size.\n\n\nHaving seen how we can build an {N-bit} adder from simple\nchunks of logic operating on each pair of bits, you should not have\nmuch difficulty in understanding the diagram to the right.\n\nIf we start with a design for an {N-bit} adder---even if that\ndesign is not built from bit slices, but is instead optimized for\nthat particular size---we can create a {2N-bit} adder by \nsimply connecting two copies of the {N-bit} adder.  We give\nthe adder for the less significant bits (the one on the right\nin the figure) an initial carry of 0,\nand pass the carry produced by the adder for the less significant\nbits into the carry input of the adder for the more significant\nbits.  We calculate overflow based on the results of the adder\nfor more significant bits (the one on the left in the figure), \nusing the method appropriate to the \ntype of operands we are adding (either unsigned or 2's complement).\n\n\n{file=part2/figs/adder-x2.eps,width=2.15in}\n\n\nYou should also realize that this connection need not be physical.\nIn other words, if a computer has an {N-bit} adder, it can\nhandle operands with 2N bits (or 3N, or 10N, or 42N) by\nusing the {N-bit} adder repeatedly, starting with the\nleast significant bits and working upward until all of the bits\nhave been added.  The computer must of course arrange to have the\noperands routed to the adder a few bits at a time, and must\nensure that the carry produced by each addition is then delivered to\nthe carry input (of the same adder!) for the next addition.\nIn the coming months, you will learn how to design hardware that\nallows you to manage bits in this way, so that by the end of our\nclass, you will be able to design a simple computer on your own.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is an adder?\n2. What is an N-bit adder?\n3. How can a 2N-bit adder be made from two N-bit adders?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Summary of Part 2 of the Course",
            "text": "{Summary of Part 2 of the Course}\n\nThese notes supplement the Patt and Patel textbook, so you will also \nneed to read and understand the relevant chapters (see the syllabus)\nin order to master this material completely.\n\nThe difficulty of learning depends on the type of task involved.\nRemembering new terminology is relatively easy, while applying\nthe ideas underlying design decisions shown by example to new problems \nposed as human tasks is relatively hard.\n\nIn this short summary, we give you lists at several levels of difficulty \nof what we expect you to be able to do as a result of the last few weeks \nof studying (reading, listening, doing homework, discussing your \nunderstanding with your classmates, and so forth).\n\nWe'll start with the skills, and leave the easy stuff for the next page.\n\nWe expect you to be able to exercise the following skills:\n\n{}{{}{}\n{}{}{}\n\n{Design a CMOS gate for a simple Boolean function from n-type \nand p-type transistors.}\n\n{Apply DeMorgan's laws repeatedly to simplify the form of\nthe complement of a Boolean expression.}\n\n{Use a K-map to find a reasonable expression for a Boolean function (for\nexample, in POS or SOP form with the minimal number of terms).}\n\n{More generally, translate Boolean logic functions among \nconcise algebraic, truth table, K-map, and canonical (minterm/maxterm) forms.}\n\n\n\nWhen designing combinational logic, we expect you to be able to apply\nthe following design strategies:\n\n{}{{}{}\n{}{}{}\n\n{Make use of human algorithms \n(for example, multiplication from addition).}\n\n{Determine whether a bit-sliced approach is applicable, and, if so,\nmake use of one.}\n\n{Break truth tables into parts so as to solve each part of a function \nseparately.}\n\n{Make use of known abstractions (adders, comparators, muxes, or other\nabstractions available to you) to simplify the problem.}\n\n\n\nAnd, at the highest level, we expect that you will be able to do the following:\n\n{}{{}{}\n{}{}{}\n\n{Understand and be able to reason at a high-level about circuit design\ntradeoffs between area/cost and performance (and to know that power is also \nimportant, but we haven't given you any quantification methods).}\n\n{Understand the tradeoffs typically made to develop bit-sliced \ndesigns---typically, bit-sliced designs are simpler but bigger and \nslower---and how one can develop variants between the extremes of\nthe bit-sliced approach and optimization of functions specific\nto an {N-bit} design.}\n\n{Understand the pitfalls of marking a function's value as ``don't care'' \nfor some input combinations, and recognize that implementations do not \nproduce ``don't care.''}\n\n{Understand the tradeoffs involved in selecting a representation for\ncommunicating information between elements in a design, such as the bit \nslices in a bit-sliced design.}\n\n{Explain the operation of a latch or a flip-flop, particularly in \nterms of the bistable states used to hold a bit.}\n\n{Understand and be able to articulate the value of the clocked \nsynchronous design abstraction.}\n\n\n\n\n\n\n\nYou should recognize all of these terms\nand be able to explain what they mean.  For the specific circuits, you \nshould be able to draw them and explain how they work.\n\nActually, we don't care whether you can draw something from memory---a full\nadder, for example---provided that you know what a full adder does and can\nderive a gate diagram correctly for one in a few minutes.  Higher-level\nskills are much more valuable.  \n\n[t]\n{}{{}{}\n{}{}{}\n\n{Boolean functions and logic gates}\n{-}{{}{}\n{}{}{}\n\n\n\n\n\n\n\n{majority function}\n\n\n{specific logic circuits}\n{-}{{}{}\n{}{}{}\n{full adder}\n{half adder}\n{ripple carry adder}\n N-to-M multiplexer (mux)\n N-to-2N decoder\n{{- latch}}\n{{R-S latch}}\n{gated D latch}\n\n SSL altered term 3 Dec 21 \n\n{master-slave implementation of a positive edge-triggered D flip-flop}\n{dual-latch implementation of a positive edge-triggered D flip-flop}\n{(bidirectional) shift register}\n{register supporting parallel load}\n\n\n{design metrics}\n{-}{{}{}\n{}{}{}\n\n\n\n\n{power, area/cost, performance}\n{computer-aided design (CAD) tools}\n{gate delay}\n\n\n{general math concepts}\n{-}{{}{}\n{}{}{}\n{canonical form}\n{domain of a function}\n{{N-dimensional} hypercube}\n\n\n{tools for solving logic problems}\n{-}{{}{}\n{}{}{}\n{truth table}\n{Karnaugh map (K-map)}\n\n{prime implicant}\n{bit-slicing}\n{timing diagram}\n\n\n\n\n[t]\n{}{{}{}\n{}{}{}\n\n{device technology}\n{-}{{}{}\n{}{}{}\n{complementary metal-oxide semiconductor (CMOS)}\n{field effect transistor (FET)}\n{transistor gate, source, drain}\n\n\n{Boolean logic terms}\n{-}{{}{}\n{}{}{}\n\n{algebraic properties}\n{dual form, principle of duality}\n{sum, product}\n{minterm, maxterm}\n{sum-of-products (SOP)}\n{product-of-sums (POS)}\n{canonical sum/SOP form}\n{canonical product/POS form}\n{logical equivalence}\n\n\n{digital systems terms}\n{-}{{}{}\n{}{}{}\n{word size}\n{{N-bit} Gray code}\n{combinational/combinatorial logic}\n{-}{{}{}\n{}{}{}\n{two-level logic}\n{``don't care'' outputs (x's)}\n\n{sequential logic}\n{-}{{}{}\n{}{}{}\n\n{active low input}\n{set a bit (to 1)}\n{reset a bit (to 0)}\n\n SSL altered term 3 Dec 21 \n\n{master-slave implementation}\n{dual-latch implementation}\n{positive edge-triggered}\n\n{clock signal}\n{-}{{}{}\n{}{}{}\n{square wave}\n{rising/positive clock edge}\n{falling/negative clock edge}\n{clock gating}\n\n{clocked synchronous sequential circuit}\n{parallel/serial load of register}\n FIXME?  too informal to ask them to remember it\n {glue logic}\n{logical/arithmetic/cyclic shift}\n\n\n\n\n\n\n\n\n\n{   }  blank 3rd page\n\n\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the difference between a Boolean function and a logic gate?\n2. What is the difference between a SOP and a POS?\n3. What is the difference between a clock signal and a square wave?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Shift Registers",
            "text": "{Shift Registers}\n\n\nCertain types of registers include logic to manipulate data held\nwithin the register.  A { shift register} is an important example\nof this\n\n\n{file=part2/figs/lec16-4.eps,width=5in}\n\n\ntype.  The simplest shift register is a series of D flip-flops,\nwith the output of each attached to the input of the next, as shown to the\nright above.  In the circuit shown, a serial input SI accepts a single bit \nof data per cycle and delivers the bit four cycles later to a serial \noutput SO.  Shift registers serve many purposes in modern systems, from the\nobvious uses of providing a fixed delay and performing bit shifts for\nprocessor arithmetic to rate matching between components and reducing\nthe pin count on programmable logic devices such as field programmable\ngate arrays (FPGAs), the modern form of the programmable logic array\nmentioned in the textbook.\n\nAn example helps to illustrate the rate matching problem: \nhistorical I/O buses used fairly slow clocks, as they had to\ndrive signals and be arbitrated over relatively long distances.\nThe Peripheral Control\nInterconnect (PCI) standard, for example, provided for 33 and 66 MHz\nbus speeds.  To provide adequate data rates, such buses use many wires\nin parallel, either 32 or 64 in the case of PCI.  In contrast, a\nGigabit Ethernet (local area network) signal travelling over a fiber\nis clocked at 1.25 GHz, but sends only one bit per cycle.  Several\nlayers of shift registers sit between the fiber and the I/O bus to\nmediate between the slow, highly parallel signals that travel over the\nI/O bus and the fast, serial signals that travel over the \nfiber.  The latest variant of PCI, PCIe (e for ``express''),\nuses serial lines at much higher clock rates.\n\nReturning to the figure above, imagine that the outputs Q_i feed\ninto logic clocked at 1/4^ the rate of the shift register \n(and suitably synchronized).  Every four cycles, the flip-flops fill\nup with another four bits, at which point the outputs are read in\nparallel.  The shift register shown can thus serve to transform serial\ndata to {4-bit-parallel} data at one-quarter the clock speed.\nUnlike the registers discussed earlier, the shift register above does\nnot support parallel load, which prevents it from transforming a slow,\nparallel stream of data into a high-speed serial stream.  The use of\n{ serial load} requires N cycles for an {N-bit}\nregister, but can reduce the number of wires needed to support the\noperation of the shift register.  How would you add support for\nparallel load?  How many additional inputs would be necessary?\n\nThe shift register above also shifts continuously, and cannot store a \nvalue.  A set of muxes, analogous to those that we used to control \nregister loading, can be applied to control shifting, as shown \nbelow.\n\n{{file=part2/figs/lec16-5.eps,width=5.3in}}\n\nUsing a {4-to-1} mux, we can construct a shift\nregister with additional functionality.  The bit slice at the top\nof the next page allows us to build a { bidirectional shift register} with \nparallel load capability and the ability to retain its value indefinitely.\nThe two-bit control input C uses a representation that\nwe have chosen for the four operations supported by our shift register, \nas shown in the table below the bit slice design.\n\n\nThe bit slice allows us to build {N-bit} shift registers by\nreplicating the slice and adding a fixed amount of ``{ glue logic}.''\nFor example, the figure below represents a {4-bit} bidirectional \nshift register constructed in this way.  The mux\nused for the SO output logic is the glue logic needed in addition\nto the four bit slices.\n\nAt each rising clock edge, the action specified by C_1C_0 is taken.  \nWhen C_1C_0=00, the\nregister holds its current value, with the register\nvalue appearing on\nQ[3:0] and each flip-flop feeding its output back into its input.\nFor C_1C_0=01, the shift register shifts left: the serial input,\nSI, is fed into flip-flop 0, and Q_3 is passed to the serial\noutput, SO.  Similarly, when C_1C_0=11, the shift register shifts\nright: SI is fed into flip-flop 3, and Q_0 is passed to SO.\nFinally, the case C_1C_0=10 causes all flip-flops to accept new\nvalues from IN[3:0], effecting a parallel load.\n\n\n{file=part2/figs/lec16-6.eps,width=2.3in}\n{c|c}\nC_1C_0& meaning \n00& retain current value\n01& shift left (low to high)\n10& load new value (from IN)\n11& shift right (high to low)\n\n{-4pt}\n\n{{file=part2/figs/lec16-7.eps,width=5.2in}}\n\nSeveral specialized shift operations are used to support data\nmanipulation in modern processors (CPUs).  Essentially, these\nspecializations dictate the glue logic for a shift\nregister as well as the serial input value.  The simplest is a {\nlogical shift}, for which SI is hardwired to 0: incoming\nbits are always 0.  A { cyclic shift} takes SO and feeds it\nback into SI, forming a circle of register bits through which the\ndata bits cycle.\n\nFinally, an { arithmetic shift} treats the shift register contents\nas a number in 2's complement form.  For non-negative numbers and left\nshifts, an arithmetic shift is the same as a logical\nshift.  When a negative number is arithmetically shifted to\nthe right, however, the sign bit is retained, resulting in a function\nsimilar to division by two.  The difference lies in the rounding\ndirection.  Division by two rounds towards zero in most \nprocessors: -5/2 gives -2.\nArithmetic shift right rounds away from zero for negative numbers (and\ntowards zero for positive numbers): -5>>1 gives -3.  We transform our\nprevious shift register into one capable of arithmetic shifts by\neliminating the serial input and feeding the most significant bit,\nwhich represents the sign in 2's complement form, back into itself for\nright shifts, as shown below.  The bit shifted in for left shifts\nhas been hardwired to 0.\n\n{{file=part2/figs/lec16-8.eps,width=5.2in}}\n\n\n\n"
        },
        "questions": "\n1. What is a shift register?\n2. What is the purpose of a shift register?\n3. How does a shift register work?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Shift Registers",
            "text": "{Shift Registers}\n\n\nCertain types of registers include logic to manipulate data held\nwithin the register.  A { shift register} is an important example\nof this\n\n\n{file=part2/figs/lec16-4.eps,width=5in}\n\n\ntype.  The simplest shift register is a series of D flip-flops,\nwith the output of each attached to the input of the next, as shown to the\nright above.  In the circuit shown, a serial input SI accepts a single bit \nof data per cycle and delivers the bit four cycles later to a serial \noutput SO.  Shift registers serve many purposes in modern systems, from the\nobvious uses of providing a fixed delay and performing bit shifts for\nprocessor arithmetic to rate matching between components and reducing\nthe pin count on programmable logic devices such as field programmable\ngate arrays (FPGAs), the modern form of the programmable logic array\nmentioned in the textbook.\n\nAn example helps to illustrate the rate matching problem: \nhistorical I/O buses used fairly slow clocks, as they had to\ndrive signals and be arbitrated over relatively long distances.\nThe Peripheral Control\nInterconnect (PCI) standard, for example, provided for 33 and 66 MHz\nbus speeds.  To provide adequate data rates, such buses use many wires\nin parallel, either 32 or 64 in the case of PCI.  In contrast, a\nGigabit Ethernet (local area network) signal travelling over a fiber\nis clocked at 1.25 GHz, but sends only one bit per cycle.  Several\nlayers of shift registers sit between the fiber and the I/O bus to\nmediate between the slow, highly parallel signals that travel over the\nI/O bus and the fast, serial signals that travel over the \nfiber.  The latest variant of PCI, PCIe (e for ``express''),\nuses serial lines at much higher clock rates.\n\nReturning to the figure above, imagine that the outputs Q_i feed\ninto logic clocked at 1/4^ the rate of the shift register \n(and suitably synchronized).  Every four cycles, the flip-flops fill\nup with another four bits, at which point the outputs are read in\nparallel.  The shift register shown can thus serve to transform serial\ndata to {4-bit-parallel} data at one-quarter the clock speed.\nUnlike the registers discussed earlier, the shift register above does\nnot support parallel load, which prevents it from transforming a slow,\nparallel stream of data into a high-speed serial stream.  The use of\n{ serial load} requires N cycles for an {N-bit}\nregister, but can reduce the number of wires needed to support the\noperation of the shift register.  How would you add support for\nparallel load?  How many additional inputs would be necessary?\n\nThe shift register above also shifts continuously, and cannot store a \nvalue.  A set of muxes, analogous to those that we used to control \nregister loading, can be applied to control shifting, as shown \nbelow.\n\n{{file=part2/figs/lec16-5.eps,width=5.3in}}\n\nUsing a {4-to-1} mux, we can construct a shift\nregister with additional functionality.  The bit slice at the top\nof the next page allows us to build a { bidirectional shift register} with \nparallel load capability and the ability to retain its value indefinitely.\nThe two-bit control input C uses a representation that\nwe have chosen for the four operations supported by our shift register, \nas shown in the table below the bit slice design.\n\n\nThe bit slice allows us to build {N-bit} shift registers by\nreplicating the slice and adding a fixed amount of ``{ glue logic}.''\nFor example, the figure below represents a {4-bit} bidirectional \nshift register constructed in this way.  The mux\nused for the SO output logic is the glue logic needed in addition\nto the four bit slices.\n\nAt each rising clock edge, the action specified by C_1C_0 is taken.  \nWhen C_1C_0=00, the\nregister holds its current value, with the register\nvalue appearing on\nQ[3:0] and each flip-flop feeding its output back into its input.\nFor C_1C_0=01, the shift register shifts left: the serial input,\nSI, is fed into flip-flop 0, and Q_3 is passed to the serial\noutput, SO.  Similarly, when C_1C_0=11, the shift register shifts\nright: SI is fed into flip-flop 3, and Q_0 is passed to SO.\nFinally, the case C_1C_0=10 causes all flip-flops to accept new\nvalues from IN[3:0], effecting a parallel load.\n\n\n{file=part2/figs/lec16-6.eps,width=2.3in}\n{c|c}\nC_1C_0& meaning \n00& retain current value\n01& shift left (low to high)\n10& load new value (from IN)\n11& shift right (high to low)\n\n{-4pt}\n\n{{file=part2/figs/lec16-7.eps,width=5.2in}}\n\nSeveral specialized shift operations are used to support data\nmanipulation in modern processors (CPUs).  Essentially, these\nspecializations dictate the glue logic for a shift\nregister as well as the serial input value.  The simplest is a {\nlogical shift}, for which SI is hardwired to 0: incoming\nbits are always 0.  A { cyclic shift} takes SO and feeds it\nback into SI, forming a circle of register bits through which the\ndata bits cycle.\n\nFinally, an { arithmetic shift} treats the shift register contents\nas a number in 2's complement form.  For non-negative numbers and left\nshifts, an arithmetic shift is the same as a logical\nshift.  When a negative number is arithmetically shifted to\nthe right, however, the sign bit is retained, resulting in a function\nsimilar to division by two.  The difference lies in the rounding\ndirection.  Division by two rounds towards zero in most \nprocessors: -5/2 gives -2.\nArithmetic shift right rounds away from zero for negative numbers (and\ntowards zero for positive numbers): -5>>1 gives -3.  We transform our\nprevious shift register into one capable of arithmetic shifts by\neliminating the serial input and feeding the most significant bit,\nwhich represents the sign in 2's complement form, back into itself for\nright shifts, as shown below.  The bit shifted in for left shifts\nhas been hardwired to 0.\n\n{{file=part2/figs/lec16-8.eps,width=5.2in}}\n\n\n\n"
        },
        "questions": "\n1. What is a shift register?\n2. What is the purpose of a shift register?\n3. How does a shift register work?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Shift Registers",
            "text": "{Shift Registers}\n\n\nCertain types of registers include logic to manipulate data held\nwithin the register.  A { shift register} is an important example\nof this\n\n\n{file=part2/figs/lec16-4.eps,width=5in}\n\n\ntype.  The simplest shift register is a series of D flip-flops,\nwith the output of each attached to the input of the next, as shown to the\nright above.  In the circuit shown, a serial input SI accepts a single bit \nof data per cycle and delivers the bit four cycles later to a serial \noutput SO.  Shift registers serve many purposes in modern systems, from the\nobvious uses of providing a fixed delay and performing bit shifts for\nprocessor arithmetic to rate matching between components and reducing\nthe pin count on programmable logic devices such as field programmable\ngate arrays (FPGAs), the modern form of the programmable logic array\nmentioned in the textbook.\n\nAn example helps to illustrate the rate matching problem: \nhistorical I/O buses used fairly slow clocks, as they had to\ndrive signals and be arbitrated over relatively long distances.\nThe Peripheral Control\nInterconnect (PCI) standard, for example, provided for 33 and 66 MHz\nbus speeds.  To provide adequate data rates, such buses use many wires\nin parallel, either 32 or 64 in the case of PCI.  In contrast, a\nGigabit Ethernet (local area network) signal travelling over a fiber\nis clocked at 1.25 GHz, but sends only one bit per cycle.  Several\nlayers of shift registers sit between the fiber and the I/O bus to\nmediate between the slow, highly parallel signals that travel over the\nI/O bus and the fast, serial signals that travel over the \nfiber.  The latest variant of PCI, PCIe (e for ``express''),\nuses serial lines at much higher clock rates.\n\nReturning to the figure above, imagine that the outputs Q_i feed\ninto logic clocked at 1/4^ the rate of the shift register \n(and suitably synchronized).  Every four cycles, the flip-flops fill\nup with another four bits, at which point the outputs are read in\nparallel.  The shift register shown can thus serve to transform serial\ndata to {4-bit-parallel} data at one-quarter the clock speed.\nUnlike the registers discussed earlier, the shift register above does\nnot support parallel load, which prevents it from transforming a slow,\nparallel stream of data into a high-speed serial stream.  The use of\n{ serial load} requires N cycles for an {N-bit}\nregister, but can reduce the number of wires needed to support the\noperation of the shift register.  How would you add support for\nparallel load?  How many additional inputs would be necessary?\n\nThe shift register above also shifts continuously, and cannot store a \nvalue.  A set of muxes, analogous to those that we used to control \nregister loading, can be applied to control shifting, as shown \nbelow.\n\n{{file=part2/figs/lec16-5.eps,width=5.3in}}\n\nUsing a {4-to-1} mux, we can construct a shift\nregister with additional functionality.  The bit slice at the top\nof the next page allows us to build a { bidirectional shift register} with \nparallel load capability and the ability to retain its value indefinitely.\nThe two-bit control input C uses a representation that\nwe have chosen for the four operations supported by our shift register, \nas shown in the table below the bit slice design.\n\n\nThe bit slice allows us to build {N-bit} shift registers by\nreplicating the slice and adding a fixed amount of ``{ glue logic}.''\nFor example, the figure below represents a {4-bit} bidirectional \nshift register constructed in this way.  The mux\nused for the SO output logic is the glue logic needed in addition\nto the four bit slices.\n\nAt each rising clock edge, the action specified by C_1C_0 is taken.  \nWhen C_1C_0=00, the\nregister holds its current value, with the register\nvalue appearing on\nQ[3:0] and each flip-flop feeding its output back into its input.\nFor C_1C_0=01, the shift register shifts left: the serial input,\nSI, is fed into flip-flop 0, and Q_3 is passed to the serial\noutput, SO.  Similarly, when C_1C_0=11, the shift register shifts\nright: SI is fed into flip-flop 3, and Q_0 is passed to SO.\nFinally, the case C_1C_0=10 causes all flip-flops to accept new\nvalues from IN[3:0], effecting a parallel load.\n\n\n{file=part2/figs/lec16-6.eps,width=2.3in}\n{c|c}\nC_1C_0& meaning \n00& retain current value\n01& shift left (low to high)\n10& load new value (from IN)\n11& shift right (high to low)\n\n{-4pt}\n\n{{file=part2/figs/lec16-7.eps,width=5.2in}}\n\nSeveral specialized shift operations are used to support data\nmanipulation in modern processors (CPUs).  Essentially, these\nspecializations dictate the glue logic for a shift\nregister as well as the serial input value.  The simplest is a {\nlogical shift}, for which SI is hardwired to 0: incoming\nbits are always 0.  A { cyclic shift} takes SO and feeds it\nback into SI, forming a circle of register bits through which the\ndata bits cycle.\n\nFinally, an { arithmetic shift} treats the shift register contents\nas a number in 2's complement form.  For non-negative numbers and left\nshifts, an arithmetic shift is the same as a logical\nshift.  When a negative number is arithmetically shifted to\nthe right, however, the sign bit is retained, resulting in a function\nsimilar to division by two.  The difference lies in the rounding\ndirection.  Division by two rounds towards zero in most \nprocessors: -5/2 gives -2.\nArithmetic shift right rounds away from zero for negative numbers (and\ntowards zero for positive numbers): -5>>1 gives -3.  We transform our\nprevious shift register into one capable of arithmetic shifts by\neliminating the serial input and feeding the most significant bit,\nwhich represents the sign in 2's complement form, back into itself for\nright shifts, as shown below.  The bit shifted in for left shifts\nhas been hardwired to 0.\n\n{{file=part2/figs/lec16-8.eps,width=5.2in}}\n\n\n\n"
        },
        "questions": "\n1. What is a shift register?\n2. What is the purpose of a shift register?\n3. How does a shift register work?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Generalizations and Applications*",
            "text": "{Generalizations and Applications*}\n\nThe approaches that we illustrated to clean up the input signals to\nour design have application in many areas.  The ideas in this \nsection are drawn from the field and are sometimes the subjects of \nlater classes, but { are not exam material for our class.}\n\nPrioritization of distinct\ninputs is used to arbitrate between devices attached to a\nprocessor.  Processors typically execute much more quickly than do devices.\nWhen a device needs attention, the device signals the processor\nby changing the voltage on an interrupt line (the name comes from the\nidea that the device interrupts the processor's current activity, such\nas running a user program).  However, more than\none device may need the attention of the processor simultaneously, so\na priority encoder is used to impose a strict order on the devices and\nto tell the processor about their needs one at a time.\n\nIf you want to learn more about this application, take ECE391.\n\nWhen components are designed together, assuming that some input patterns\ndo not occur is common practice, since such assumptions can dramatically\nreduce the number of gates required, improve performance, reduce power\nconsumption, and so forth.  As a side effect, when we want to test a\nchip to make sure that no defects or other problems prevent the chip\nfrom operating correctly, we have to be careful so as not to ``test''\nbit patterns that should never occur in practice.  Making up random bit\npatterns is easy, but can produce bad results or even destroy the chip\nif some parts of the design have assumed that a combination produced \nrandomly can never occur.  To avoid these problems, designers add extra\nlogic that changes the disallowed patterns into allowed patterns, just\nas we did with our design.  The use of random bit patterns is common in\nBuilt-In Self Test (BIST), and so the process of inserting extra logic\nto avoid problems is called BIST hardening.  BIST hardening can add\n{10-20} additional logic to a design.\n\nOur graduate class on digital system testing, ECE543, covers this\nmaterial, but has not been offered recently.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of a priority encoder?\n2. What is the purpose of BIST hardening?\n3. What is the significance of the fact that \"more than one device may need the attention of the processor simultaneously\"?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Generalizations and Applications*",
            "text": "{Generalizations and Applications*}\n\nThe approaches that we illustrated to clean up the input signals to\nour design have application in many areas.  The ideas in this \nsection are drawn from the field and are sometimes the subjects of \nlater classes, but { are not exam material for our class.}\n\nPrioritization of distinct\ninputs is used to arbitrate between devices attached to a\nprocessor.  Processors typically execute much more quickly than do devices.\nWhen a device needs attention, the device signals the processor\nby changing the voltage on an interrupt line (the name comes from the\nidea that the device interrupts the processor's current activity, such\nas running a user program).  However, more than\none device may need the attention of the processor simultaneously, so\na priority encoder is used to impose a strict order on the devices and\nto tell the processor about their needs one at a time.\n\nIf you want to learn more about this application, take ECE391.\n\nWhen components are designed together, assuming that some input patterns\ndo not occur is common practice, since such assumptions can dramatically\nreduce the number of gates required, improve performance, reduce power\nconsumption, and so forth.  As a side effect, when we want to test a\nchip to make sure that no defects or other problems prevent the chip\nfrom operating correctly, we have to be careful so as not to ``test''\nbit patterns that should never occur in practice.  Making up random bit\npatterns is easy, but can produce bad results or even destroy the chip\nif some parts of the design have assumed that a combination produced \nrandomly can never occur.  To avoid these problems, designers add extra\nlogic that changes the disallowed patterns into allowed patterns, just\nas we did with our design.  The use of random bit patterns is common in\nBuilt-In Self Test (BIST), and so the process of inserting extra logic\nto avoid problems is called BIST hardening.  BIST hardening can add\n{10-20} additional logic to a design.\n\nOur graduate class on digital system testing, ECE543, covers this\nmaterial, but has not been offered recently.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of a priority encoder?\n2. What is the purpose of BIST hardening?\n3. What is the significance of the fact that \"more than one device may need the attention of the processor simultaneously\"?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Generalizations and Applications*",
            "text": "{Generalizations and Applications*}\n\nThe approaches that we illustrated to clean up the input signals to\nour design have application in many areas.  The ideas in this \nsection are drawn from the field and are sometimes the subjects of \nlater classes, but { are not exam material for our class.}\n\nPrioritization of distinct\ninputs is used to arbitrate between devices attached to a\nprocessor.  Processors typically execute much more quickly than do devices.\nWhen a device needs attention, the device signals the processor\nby changing the voltage on an interrupt line (the name comes from the\nidea that the device interrupts the processor's current activity, such\nas running a user program).  However, more than\none device may need the attention of the processor simultaneously, so\na priority encoder is used to impose a strict order on the devices and\nto tell the processor about their needs one at a time.\n\nIf you want to learn more about this application, take ECE391.\n\nWhen components are designed together, assuming that some input patterns\ndo not occur is common practice, since such assumptions can dramatically\nreduce the number of gates required, improve performance, reduce power\nconsumption, and so forth.  As a side effect, when we want to test a\nchip to make sure that no defects or other problems prevent the chip\nfrom operating correctly, we have to be careful so as not to ``test''\nbit patterns that should never occur in practice.  Making up random bit\npatterns is easy, but can produce bad results or even destroy the chip\nif some parts of the design have assumed that a combination produced \nrandomly can never occur.  To avoid these problems, designers add extra\nlogic that changes the disallowed patterns into allowed patterns, just\nas we did with our design.  The use of random bit patterns is common in\nBuilt-In Self Test (BIST), and so the process of inserting extra logic\nto avoid problems is called BIST hardening.  BIST hardening can add\n{10-20} additional logic to a design.\n\nOur graduate class on digital system testing, ECE543, covers this\nmaterial, but has not been offered recently.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of a priority encoder?\n2. What is the purpose of BIST hardening?\n3. What is the significance of the fact that \"more than one device may need the attention of the processor simultaneously\"?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Generalizations and Applications*",
            "text": "{Generalizations and Applications*}\n\nThe approaches that we illustrated to clean up the input signals to\nour design have application in many areas.  The ideas in this \nsection are drawn from the field and are sometimes the subjects of \nlater classes, but { are not exam material for our class.}\n\nPrioritization of distinct\ninputs is used to arbitrate between devices attached to a\nprocessor.  Processors typically execute much more quickly than do devices.\nWhen a device needs attention, the device signals the processor\nby changing the voltage on an interrupt line (the name comes from the\nidea that the device interrupts the processor's current activity, such\nas running a user program).  However, more than\none device may need the attention of the processor simultaneously, so\na priority encoder is used to impose a strict order on the devices and\nto tell the processor about their needs one at a time.\n\nIf you want to learn more about this application, take ECE391.\n\nWhen components are designed together, assuming that some input patterns\ndo not occur is common practice, since such assumptions can dramatically\nreduce the number of gates required, improve performance, reduce power\nconsumption, and so forth.  As a side effect, when we want to test a\nchip to make sure that no defects or other problems prevent the chip\nfrom operating correctly, we have to be careful so as not to ``test''\nbit patterns that should never occur in practice.  Making up random bit\npatterns is easy, but can produce bad results or even destroy the chip\nif some parts of the design have assumed that a combination produced \nrandomly can never occur.  To avoid these problems, designers add extra\nlogic that changes the disallowed patterns into allowed patterns, just\nas we did with our design.  The use of random bit patterns is common in\nBuilt-In Self Test (BIST), and so the process of inserting extra logic\nto avoid problems is called BIST hardening.  BIST hardening can add\n{10-20} additional logic to a design.\n\nOur graduate class on digital system testing, ECE543, covers this\nmaterial, but has not been offered recently.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of a priority encoder?\n2. What is the purpose of BIST hardening?\n3. What is the significance of the fact that \"more than one device may need the attention of the processor simultaneously\"?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Generalizations and Applications*",
            "text": "{Generalizations and Applications*}\n\nThe approaches that we illustrated to clean up the input signals to\nour design have application in many areas.  The ideas in this \nsection are drawn from the field and are sometimes the subjects of \nlater classes, but { are not exam material for our class.}\n\nPrioritization of distinct\ninputs is used to arbitrate between devices attached to a\nprocessor.  Processors typically execute much more quickly than do devices.\nWhen a device needs attention, the device signals the processor\nby changing the voltage on an interrupt line (the name comes from the\nidea that the device interrupts the processor's current activity, such\nas running a user program).  However, more than\none device may need the attention of the processor simultaneously, so\na priority encoder is used to impose a strict order on the devices and\nto tell the processor about their needs one at a time.\n\nIf you want to learn more about this application, take ECE391.\n\nWhen components are designed together, assuming that some input patterns\ndo not occur is common practice, since such assumptions can dramatically\nreduce the number of gates required, improve performance, reduce power\nconsumption, and so forth.  As a side effect, when we want to test a\nchip to make sure that no defects or other problems prevent the chip\nfrom operating correctly, we have to be careful so as not to ``test''\nbit patterns that should never occur in practice.  Making up random bit\npatterns is easy, but can produce bad results or even destroy the chip\nif some parts of the design have assumed that a combination produced \nrandomly can never occur.  To avoid these problems, designers add extra\nlogic that changes the disallowed patterns into allowed patterns, just\nas we did with our design.  The use of random bit patterns is common in\nBuilt-In Self Test (BIST), and so the process of inserting extra logic\nto avoid problems is called BIST hardening.  BIST hardening can add\n{10-20} additional logic to a design.\n\nOur graduate class on digital system testing, ECE543, covers this\nmaterial, but has not been offered recently.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the purpose of a priority encoder?\n2. What is the purpose of BIST hardening?\n3. What is the significance of the fact that \"more than one device may need the attention of the processor simultaneously\"?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Multi-Metric Optimization",
            "text": "{Multi-Metric Optimization}\n\nAs engineers, almost every real problem that you encounter will admit \nmultiple metrics for evaluating possible designs.  Becoming a good\nengineer thus requires not only that you be able to solve problems\ncreatively so as to improve the quality of your solutions, but also\nthat you are aware of how people might evaluate those solutions and\nare able both to identify the most important metrics and to balance \nyour design effectively according to them.  In this section, we\nintroduce some general ideas and methods that may be of use to you\nin this regard.\n\n{ We will not test you on the concepts in this section.}\n\nWhen you start thinking about a new problem, your first step\nshould be to think carefully about metrics of possible interest.\n\nSome important metrics may not be easy to quantify.  \n\nFor example, compatibility of a design with other products already \nowned by a customer has frequently defined the success or failure\nof computer hardware and software solutions.\n\nBut how can you compute the compability of your approach as\na number?\n\nHumans---including engineers---are not good at\ncomparing multiple metrics simultaneously.\n\nThus, once you have a set of metrics that you feel is complete, \nyour next step is to get rid of as many as you can.\n\nTowards this end, you may identify metrics that have no practical \nimpact in current technology, set threshold values for other metrics\nto simplify reasoning about them, eliminate redundant metrics,\ncalculate linear sums to reduce the count of metrics, and, finally,\nmake use of the notion of Pareto optimality.  All of these ideas are\ndescribed in the rest of this section.\n\nLet's start by considering metrics that we can quantify as real\nnumbers.\n\nFor a given metric, we can divide possible measurement values into\nthree ranges.\n\nIn the first range,\nall measurement values are equivalently useful.\nIn the second range, \npossible values are ordered and interesting with respect to\none another.\nValues in the third range are all impossible to use in practice.\nUsing power consumption as\nour example, the first range corresponds to systems in which\nwhen a processor's power consumption in a digital \nsystem is extremely low relative to the\npower consumption\nof the system.\nFor example, the processor in a computer might use less than 1 \nof the total used by \nthe system including the disk drive, the monitor, the power \nsupply, and so forth.  One power consumption value in this range \nis just as good as any\nanother, and no one cares about the power consumption of the processor \nin such cases.  In the second range, power consumption of the\nprocessor makes a difference.  Cell phones use most of their energy\nin radio operation, for example, but if you own a phone with a powerful\nprocessor, you may have noticed that you can turn off the phone and \ndrain the battery fairly quickly by playing a game.  Designing a\nprocessor that uses half as much power lengthens the battery life in\nsuch cases.  Finally,\nthe third region of power consumption measurements is impossible:\nif you use so much power, your chip will overheat or even burst\ninto flames.  Consumers get unhappy when such things happen.\n\nAs a first step, you can remove any metrics for which all solutions\nare effectively equivalent.\n\nUntil a little less than a decade ago, for example, the power \nconsumption of a desktop\nprocessor actually was in the first range that we discussed.  Power\nwas simply not a concern to engineers: all designs of \ninterest consumed so little power that no one cared.\n\nUnfortunately, at that point, power consumption jumped into the\nthird range rather quickly.  Processors hit a wall, and \nproducts had to be cancelled.  Given that the time spent designing\na processor has historically\nbeen about five years, a lot of engineering effort\nwas wasted because people had not thought carefully enough about\npower (since it had never mattered in the past).\n\nToday, power is an important metric that engineers must take into\naccount in their designs. \n\nHowever, in some areas, such as desktop and high-end server\nprocessors,\nother metrics (such as performance) may be so \nimportant that we always want to operate at the edge of the\ninteresting range.  In such cases, we might choose to treat \na metric such as power consumption as a { threshold}: stay\nbelow 150 Watts for a desktop processor, for example.  One still\nhas to make a coordinated effort to ensure that the system as\na whole does not exceed the threshold, but reasoning about \nthreshold values, a form of constraint, is easier than trying to\nthink about multiple metrics at once.\n\nSome metrics may only allow discrete quantification.  For example,\none could choose to define compatibility with previous processor\ngenerations as binary: either an existing piece of software\n(or operating system)\nruns out of the box on your new processor, or it does not.  If you \nwant people who own that software to make use of your new processor,\nyou must ensure that the value of this binary metric is 1, which\ncan also be viewed as a threshold.\n\nIn some cases, two metrics may be strongly { correlated}, meaning\nthat a design that is good for one of the metrics is frequently \ngood for the other metric as well.\n\nChip area and cost, for\nexample, are technically distinct ways to measure a digital design,\nbut we rarely consider them separately.\n\nA design that requires a larger chip is probably more complex,\nand thus takes more engineering time to get right (engineering time\ncosts money).  \n\nEach silicon wafer costs money to fabricate, and fewer copies of a \nlarge design fit on one wafer, so large chips mean more fabrication\ncost.\n\nPhysical defects in silicon can cause some chips not to work.  A large\nchip uses more silicon than a small one, and is thus more likely to suffer\nfrom defects (and not work).  Cost thus goes up again for large chips\nrelative to small ones.\n\nFinally, large chips usually require more careful testing to ensure\nthat they work properly (even ignoring the cost of getting the design\nright, we have to test for the presence of defects), which adds still\nmore cost for a larger chip.\n\nAll of these factors tend to correlate chip area and chip cost, to the\npoint that most engineers do not consider both metrics.\n\n\nAfter you have tried to reduce your set of metrics as much as possible,\nor simplified them by turning them into thresholds, you should consider\nturning the last few metrics into a weighted linear sum.  All remaining\nmetrics must be quantifiable in this case.\n\nFor example, if you are left with three metrics for which a given\ndesign has values A, B, and C, you might reduce these to one\nmetric by calculating D=w_AA+w_BB+w_CC.  What are the w values?\nThey are weights for the three metrics.  Their values represent the\nrelative importance of the three metrics to the overall evaluation.\nHere we've assumed that larger values of A, B, and C are either\nall good or all bad.  If you have metrics with different senses,\nuse the reciprocal values.  For example, if a large value of A is good,\na small value of 1/A is also good.  \n\nThe difficulty with linearizing metrics is that not everyone agrees\non the weights.  Is using less power more important than having a cheaper\nchip?  The answer may depend on many factors.\n\nWhen you are left with several metrics of interest, you can use the\nidea of Pareto optimality to identify interesting designs.\n\nLet's say that you have two metrics.  If a design D_1 is better than\na second design D_2 for both metrics, we say that D_1 \n{ dominates} D_2.\n\nA design D is then said to be { Pareto optimal} if no other design\ndominates D.  Consider the figure on the left below, which illustrates\nseven possible designs measured with two metrics.  The design corresponding\nto point B dominates the designs corresponding to points A and C, so \nneither of the latter designs is Pareto optimal.  No other point \nin the figure dominates B, however, so that design is Pareto optimal.\nIf we remove all points that do not represent Pareto optimal designs,\nand instead include only those designs that are Pareto optimal, we\nobtain the version shown on the right.  These are points in a two-dimensional\nspace, not a line, but we can imagine a line going through the points,\nas illustrated in the figure: the points that make up the line are\ncalled a { Pareto curve}, or, if you have more than two metrics,\na { Pareto surface}.\n\n{\n\n\n\n\nAs an example of the use of Pareto optimality, consider the figure\nto the right, which is copied with permission from Neal Crago's Ph.D. \ndissertation (UIUC ECE, 2012).  The figure compares hundreds of thousands \nof possible\ndesigns based on a handful of different core approaches for\nimplementing a processor.  The axes in the graph are two metrics \nof interest.  The horizontal axis measures the average performance of a \ndesign when\nexecuting a set of benchmark applications, normalized to\na baseline processor design.  The vertical axis measures the energy\nconsumed by a design when\n\n\n{file=part2/cited/bench_pareto.eps,width=3in}\n\n\nexecuting the same benchmarks, normalized\nagain to the energy consumed by a baseline design.  The six sets of\npoints in the graph represent alternative design techniques for the\nprocessor, most of which are in commercial use today.  The points\nshown for each set are the subset of many thousands of possible variants\nthat are Pareto optimal.  In this case, more performance and less energy\nconsumption are the good directions, so any point in a set for which\nanother point is both further to the right and further down is not\nshown in the graph.  The black line represents an absolute power\nconsumption of 150 Watts, which is a nominal threshold for a desktop\nenvironment.  Designs above and to the right of that line are not\nas interesting for desktop use.  The { design-space exploration} that\nNeal reported in this figure was of course done by many computers using\nmany hours of computation, but he had to design the process by which the\ncomputers calculated each of the points.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the first step you should take when thinking about a new problem?\n2. What are some of the ways you can reduce the number of metrics you have to consider?\n3. What is the Pareto optimal?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Multi-Metric Optimization",
            "text": "{Multi-Metric Optimization}\n\nAs engineers, almost every real problem that you encounter will admit \nmultiple metrics for evaluating possible designs.  Becoming a good\nengineer thus requires not only that you be able to solve problems\ncreatively so as to improve the quality of your solutions, but also\nthat you are aware of how people might evaluate those solutions and\nare able both to identify the most important metrics and to balance \nyour design effectively according to them.  In this section, we\nintroduce some general ideas and methods that may be of use to you\nin this regard.\n\n{ We will not test you on the concepts in this section.}\n\nWhen you start thinking about a new problem, your first step\nshould be to think carefully about metrics of possible interest.\n\nSome important metrics may not be easy to quantify.  \n\nFor example, compatibility of a design with other products already \nowned by a customer has frequently defined the success or failure\nof computer hardware and software solutions.\n\nBut how can you compute the compability of your approach as\na number?\n\nHumans---including engineers---are not good at\ncomparing multiple metrics simultaneously.\n\nThus, once you have a set of metrics that you feel is complete, \nyour next step is to get rid of as many as you can.\n\nTowards this end, you may identify metrics that have no practical \nimpact in current technology, set threshold values for other metrics\nto simplify reasoning about them, eliminate redundant metrics,\ncalculate linear sums to reduce the count of metrics, and, finally,\nmake use of the notion of Pareto optimality.  All of these ideas are\ndescribed in the rest of this section.\n\nLet's start by considering metrics that we can quantify as real\nnumbers.\n\nFor a given metric, we can divide possible measurement values into\nthree ranges.\n\nIn the first range,\nall measurement values are equivalently useful.\nIn the second range, \npossible values are ordered and interesting with respect to\none another.\nValues in the third range are all impossible to use in practice.\nUsing power consumption as\nour example, the first range corresponds to systems in which\nwhen a processor's power consumption in a digital \nsystem is extremely low relative to the\npower consumption\nof the system.\nFor example, the processor in a computer might use less than 1 \nof the total used by \nthe system including the disk drive, the monitor, the power \nsupply, and so forth.  One power consumption value in this range \nis just as good as any\nanother, and no one cares about the power consumption of the processor \nin such cases.  In the second range, power consumption of the\nprocessor makes a difference.  Cell phones use most of their energy\nin radio operation, for example, but if you own a phone with a powerful\nprocessor, you may have noticed that you can turn off the phone and \ndrain the battery fairly quickly by playing a game.  Designing a\nprocessor that uses half as much power lengthens the battery life in\nsuch cases.  Finally,\nthe third region of power consumption measurements is impossible:\nif you use so much power, your chip will overheat or even burst\ninto flames.  Consumers get unhappy when such things happen.\n\nAs a first step, you can remove any metrics for which all solutions\nare effectively equivalent.\n\nUntil a little less than a decade ago, for example, the power \nconsumption of a desktop\nprocessor actually was in the first range that we discussed.  Power\nwas simply not a concern to engineers: all designs of \ninterest consumed so little power that no one cared.\n\nUnfortunately, at that point, power consumption jumped into the\nthird range rather quickly.  Processors hit a wall, and \nproducts had to be cancelled.  Given that the time spent designing\na processor has historically\nbeen about five years, a lot of engineering effort\nwas wasted because people had not thought carefully enough about\npower (since it had never mattered in the past).\n\nToday, power is an important metric that engineers must take into\naccount in their designs. \n\nHowever, in some areas, such as desktop and high-end server\nprocessors,\nother metrics (such as performance) may be so \nimportant that we always want to operate at the edge of the\ninteresting range.  In such cases, we might choose to treat \na metric such as power consumption as a { threshold}: stay\nbelow 150 Watts for a desktop processor, for example.  One still\nhas to make a coordinated effort to ensure that the system as\na whole does not exceed the threshold, but reasoning about \nthreshold values, a form of constraint, is easier than trying to\nthink about multiple metrics at once.\n\nSome metrics may only allow discrete quantification.  For example,\none could choose to define compatibility with previous processor\ngenerations as binary: either an existing piece of software\n(or operating system)\nruns out of the box on your new processor, or it does not.  If you \nwant people who own that software to make use of your new processor,\nyou must ensure that the value of this binary metric is 1, which\ncan also be viewed as a threshold.\n\nIn some cases, two metrics may be strongly { correlated}, meaning\nthat a design that is good for one of the metrics is frequently \ngood for the other metric as well.\n\nChip area and cost, for\nexample, are technically distinct ways to measure a digital design,\nbut we rarely consider them separately.\n\nA design that requires a larger chip is probably more complex,\nand thus takes more engineering time to get right (engineering time\ncosts money).  \n\nEach silicon wafer costs money to fabricate, and fewer copies of a \nlarge design fit on one wafer, so large chips mean more fabrication\ncost.\n\nPhysical defects in silicon can cause some chips not to work.  A large\nchip uses more silicon than a small one, and is thus more likely to suffer\nfrom defects (and not work).  Cost thus goes up again for large chips\nrelative to small ones.\n\nFinally, large chips usually require more careful testing to ensure\nthat they work properly (even ignoring the cost of getting the design\nright, we have to test for the presence of defects), which adds still\nmore cost for a larger chip.\n\nAll of these factors tend to correlate chip area and chip cost, to the\npoint that most engineers do not consider both metrics.\n\n\nAfter you have tried to reduce your set of metrics as much as possible,\nor simplified them by turning them into thresholds, you should consider\nturning the last few metrics into a weighted linear sum.  All remaining\nmetrics must be quantifiable in this case.\n\nFor example, if you are left with three metrics for which a given\ndesign has values A, B, and C, you might reduce these to one\nmetric by calculating D=w_AA+w_BB+w_CC.  What are the w values?\nThey are weights for the three metrics.  Their values represent the\nrelative importance of the three metrics to the overall evaluation.\nHere we've assumed that larger values of A, B, and C are either\nall good or all bad.  If you have metrics with different senses,\nuse the reciprocal values.  For example, if a large value of A is good,\na small value of 1/A is also good.  \n\nThe difficulty with linearizing metrics is that not everyone agrees\non the weights.  Is using less power more important than having a cheaper\nchip?  The answer may depend on many factors.\n\nWhen you are left with several metrics of interest, you can use the\nidea of Pareto optimality to identify interesting designs.\n\nLet's say that you have two metrics.  If a design D_1 is better than\na second design D_2 for both metrics, we say that D_1 \n{ dominates} D_2.\n\nA design D is then said to be { Pareto optimal} if no other design\ndominates D.  Consider the figure on the left below, which illustrates\nseven possible designs measured with two metrics.  The design corresponding\nto point B dominates the designs corresponding to points A and C, so \nneither of the latter designs is Pareto optimal.  No other point \nin the figure dominates B, however, so that design is Pareto optimal.\nIf we remove all points that do not represent Pareto optimal designs,\nand instead include only those designs that are Pareto optimal, we\nobtain the version shown on the right.  These are points in a two-dimensional\nspace, not a line, but we can imagine a line going through the points,\nas illustrated in the figure: the points that make up the line are\ncalled a { Pareto curve}, or, if you have more than two metrics,\na { Pareto surface}.\n\n{\n\n\n\n\nAs an example of the use of Pareto optimality, consider the figure\nto the right, which is copied with permission from Neal Crago's Ph.D. \ndissertation (UIUC ECE, 2012).  The figure compares hundreds of thousands \nof possible\ndesigns based on a handful of different core approaches for\nimplementing a processor.  The axes in the graph are two metrics \nof interest.  The horizontal axis measures the average performance of a \ndesign when\nexecuting a set of benchmark applications, normalized to\na baseline processor design.  The vertical axis measures the energy\nconsumed by a design when\n\n\n{file=part2/cited/bench_pareto.eps,width=3in}\n\n\nexecuting the same benchmarks, normalized\nagain to the energy consumed by a baseline design.  The six sets of\npoints in the graph represent alternative design techniques for the\nprocessor, most of which are in commercial use today.  The points\nshown for each set are the subset of many thousands of possible variants\nthat are Pareto optimal.  In this case, more performance and less energy\nconsumption are the good directions, so any point in a set for which\nanother point is both further to the right and further down is not\nshown in the graph.  The black line represents an absolute power\nconsumption of 150 Watts, which is a nominal threshold for a desktop\nenvironment.  Designs above and to the right of that line are not\nas interesting for desktop use.  The { design-space exploration} that\nNeal reported in this figure was of course done by many computers using\nmany hours of computation, but he had to design the process by which the\ncomputers calculated each of the points.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the first step you should take when thinking about a new problem?\n2. What are some of the ways you can reduce the number of metrics you have to consider?\n3. What is the Pareto optimal?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Multi-Metric Optimization",
            "text": "{Multi-Metric Optimization}\n\nAs engineers, almost every real problem that you encounter will admit \nmultiple metrics for evaluating possible designs.  Becoming a good\nengineer thus requires not only that you be able to solve problems\ncreatively so as to improve the quality of your solutions, but also\nthat you are aware of how people might evaluate those solutions and\nare able both to identify the most important metrics and to balance \nyour design effectively according to them.  In this section, we\nintroduce some general ideas and methods that may be of use to you\nin this regard.\n\n{ We will not test you on the concepts in this section.}\n\nWhen you start thinking about a new problem, your first step\nshould be to think carefully about metrics of possible interest.\n\nSome important metrics may not be easy to quantify.  \n\nFor example, compatibility of a design with other products already \nowned by a customer has frequently defined the success or failure\nof computer hardware and software solutions.\n\nBut how can you compute the compability of your approach as\na number?\n\nHumans---including engineers---are not good at\ncomparing multiple metrics simultaneously.\n\nThus, once you have a set of metrics that you feel is complete, \nyour next step is to get rid of as many as you can.\n\nTowards this end, you may identify metrics that have no practical \nimpact in current technology, set threshold values for other metrics\nto simplify reasoning about them, eliminate redundant metrics,\ncalculate linear sums to reduce the count of metrics, and, finally,\nmake use of the notion of Pareto optimality.  All of these ideas are\ndescribed in the rest of this section.\n\nLet's start by considering metrics that we can quantify as real\nnumbers.\n\nFor a given metric, we can divide possible measurement values into\nthree ranges.\n\nIn the first range,\nall measurement values are equivalently useful.\nIn the second range, \npossible values are ordered and interesting with respect to\none another.\nValues in the third range are all impossible to use in practice.\nUsing power consumption as\nour example, the first range corresponds to systems in which\nwhen a processor's power consumption in a digital \nsystem is extremely low relative to the\npower consumption\nof the system.\nFor example, the processor in a computer might use less than 1 \nof the total used by \nthe system including the disk drive, the monitor, the power \nsupply, and so forth.  One power consumption value in this range \nis just as good as any\nanother, and no one cares about the power consumption of the processor \nin such cases.  In the second range, power consumption of the\nprocessor makes a difference.  Cell phones use most of their energy\nin radio operation, for example, but if you own a phone with a powerful\nprocessor, you may have noticed that you can turn off the phone and \ndrain the battery fairly quickly by playing a game.  Designing a\nprocessor that uses half as much power lengthens the battery life in\nsuch cases.  Finally,\nthe third region of power consumption measurements is impossible:\nif you use so much power, your chip will overheat or even burst\ninto flames.  Consumers get unhappy when such things happen.\n\nAs a first step, you can remove any metrics for which all solutions\nare effectively equivalent.\n\nUntil a little less than a decade ago, for example, the power \nconsumption of a desktop\nprocessor actually was in the first range that we discussed.  Power\nwas simply not a concern to engineers: all designs of \ninterest consumed so little power that no one cared.\n\nUnfortunately, at that point, power consumption jumped into the\nthird range rather quickly.  Processors hit a wall, and \nproducts had to be cancelled.  Given that the time spent designing\na processor has historically\nbeen about five years, a lot of engineering effort\nwas wasted because people had not thought carefully enough about\npower (since it had never mattered in the past).\n\nToday, power is an important metric that engineers must take into\naccount in their designs. \n\nHowever, in some areas, such as desktop and high-end server\nprocessors,\nother metrics (such as performance) may be so \nimportant that we always want to operate at the edge of the\ninteresting range.  In such cases, we might choose to treat \na metric such as power consumption as a { threshold}: stay\nbelow 150 Watts for a desktop processor, for example.  One still\nhas to make a coordinated effort to ensure that the system as\na whole does not exceed the threshold, but reasoning about \nthreshold values, a form of constraint, is easier than trying to\nthink about multiple metrics at once.\n\nSome metrics may only allow discrete quantification.  For example,\none could choose to define compatibility with previous processor\ngenerations as binary: either an existing piece of software\n(or operating system)\nruns out of the box on your new processor, or it does not.  If you \nwant people who own that software to make use of your new processor,\nyou must ensure that the value of this binary metric is 1, which\ncan also be viewed as a threshold.\n\nIn some cases, two metrics may be strongly { correlated}, meaning\nthat a design that is good for one of the metrics is frequently \ngood for the other metric as well.\n\nChip area and cost, for\nexample, are technically distinct ways to measure a digital design,\nbut we rarely consider them separately.\n\nA design that requires a larger chip is probably more complex,\nand thus takes more engineering time to get right (engineering time\ncosts money).  \n\nEach silicon wafer costs money to fabricate, and fewer copies of a \nlarge design fit on one wafer, so large chips mean more fabrication\ncost.\n\nPhysical defects in silicon can cause some chips not to work.  A large\nchip uses more silicon than a small one, and is thus more likely to suffer\nfrom defects (and not work).  Cost thus goes up again for large chips\nrelative to small ones.\n\nFinally, large chips usually require more careful testing to ensure\nthat they work properly (even ignoring the cost of getting the design\nright, we have to test for the presence of defects), which adds still\nmore cost for a larger chip.\n\nAll of these factors tend to correlate chip area and chip cost, to the\npoint that most engineers do not consider both metrics.\n\n\nAfter you have tried to reduce your set of metrics as much as possible,\nor simplified them by turning them into thresholds, you should consider\nturning the last few metrics into a weighted linear sum.  All remaining\nmetrics must be quantifiable in this case.\n\nFor example, if you are left with three metrics for which a given\ndesign has values A, B, and C, you might reduce these to one\nmetric by calculating D=w_AA+w_BB+w_CC.  What are the w values?\nThey are weights for the three metrics.  Their values represent the\nrelative importance of the three metrics to the overall evaluation.\nHere we've assumed that larger values of A, B, and C are either\nall good or all bad.  If you have metrics with different senses,\nuse the reciprocal values.  For example, if a large value of A is good,\na small value of 1/A is also good.  \n\nThe difficulty with linearizing metrics is that not everyone agrees\non the weights.  Is using less power more important than having a cheaper\nchip?  The answer may depend on many factors.\n\nWhen you are left with several metrics of interest, you can use the\nidea of Pareto optimality to identify interesting designs.\n\nLet's say that you have two metrics.  If a design D_1 is better than\na second design D_2 for both metrics, we say that D_1 \n{ dominates} D_2.\n\nA design D is then said to be { Pareto optimal} if no other design\ndominates D.  Consider the figure on the left below, which illustrates\nseven possible designs measured with two metrics.  The design corresponding\nto point B dominates the designs corresponding to points A and C, so \nneither of the latter designs is Pareto optimal.  No other point \nin the figure dominates B, however, so that design is Pareto optimal.\nIf we remove all points that do not represent Pareto optimal designs,\nand instead include only those designs that are Pareto optimal, we\nobtain the version shown on the right.  These are points in a two-dimensional\nspace, not a line, but we can imagine a line going through the points,\nas illustrated in the figure: the points that make up the line are\ncalled a { Pareto curve}, or, if you have more than two metrics,\na { Pareto surface}.\n\n{\n\n\n\n\nAs an example of the use of Pareto optimality, consider the figure\nto the right, which is copied with permission from Neal Crago's Ph.D. \ndissertation (UIUC ECE, 2012).  The figure compares hundreds of thousands \nof possible\ndesigns based on a handful of different core approaches for\nimplementing a processor.  The axes in the graph are two metrics \nof interest.  The horizontal axis measures the average performance of a \ndesign when\nexecuting a set of benchmark applications, normalized to\na baseline processor design.  The vertical axis measures the energy\nconsumed by a design when\n\n\n{file=part2/cited/bench_pareto.eps,width=3in}\n\n\nexecuting the same benchmarks, normalized\nagain to the energy consumed by a baseline design.  The six sets of\npoints in the graph represent alternative design techniques for the\nprocessor, most of which are in commercial use today.  The points\nshown for each set are the subset of many thousands of possible variants\nthat are Pareto optimal.  In this case, more performance and less energy\nconsumption are the good directions, so any point in a set for which\nanother point is both further to the right and further down is not\nshown in the graph.  The black line represents an absolute power\nconsumption of 150 Watts, which is a nominal threshold for a desktop\nenvironment.  Designs above and to the right of that line are not\nas interesting for desktop use.  The { design-space exploration} that\nNeal reported in this figure was of course done by many computers using\nmany hours of computation, but he had to design the process by which the\ncomputers calculated each of the points.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the first step you should take when thinking about a new problem?\n2. What are some of the ways you can reduce the number of metrics you have to consider?\n3. What is the Pareto optimal?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Multi-Metric Optimization",
            "text": "{Multi-Metric Optimization}\n\nAs engineers, almost every real problem that you encounter will admit \nmultiple metrics for evaluating possible designs.  Becoming a good\nengineer thus requires not only that you be able to solve problems\ncreatively so as to improve the quality of your solutions, but also\nthat you are aware of how people might evaluate those solutions and\nare able both to identify the most important metrics and to balance \nyour design effectively according to them.  In this section, we\nintroduce some general ideas and methods that may be of use to you\nin this regard.\n\n{ We will not test you on the concepts in this section.}\n\nWhen you start thinking about a new problem, your first step\nshould be to think carefully about metrics of possible interest.\n\nSome important metrics may not be easy to quantify.  \n\nFor example, compatibility of a design with other products already \nowned by a customer has frequently defined the success or failure\nof computer hardware and software solutions.\n\nBut how can you compute the compability of your approach as\na number?\n\nHumans---including engineers---are not good at\ncomparing multiple metrics simultaneously.\n\nThus, once you have a set of metrics that you feel is complete, \nyour next step is to get rid of as many as you can.\n\nTowards this end, you may identify metrics that have no practical \nimpact in current technology, set threshold values for other metrics\nto simplify reasoning about them, eliminate redundant metrics,\ncalculate linear sums to reduce the count of metrics, and, finally,\nmake use of the notion of Pareto optimality.  All of these ideas are\ndescribed in the rest of this section.\n\nLet's start by considering metrics that we can quantify as real\nnumbers.\n\nFor a given metric, we can divide possible measurement values into\nthree ranges.\n\nIn the first range,\nall measurement values are equivalently useful.\nIn the second range, \npossible values are ordered and interesting with respect to\none another.\nValues in the third range are all impossible to use in practice.\nUsing power consumption as\nour example, the first range corresponds to systems in which\nwhen a processor's power consumption in a digital \nsystem is extremely low relative to the\npower consumption\nof the system.\nFor example, the processor in a computer might use less than 1 \nof the total used by \nthe system including the disk drive, the monitor, the power \nsupply, and so forth.  One power consumption value in this range \nis just as good as any\nanother, and no one cares about the power consumption of the processor \nin such cases.  In the second range, power consumption of the\nprocessor makes a difference.  Cell phones use most of their energy\nin radio operation, for example, but if you own a phone with a powerful\nprocessor, you may have noticed that you can turn off the phone and \ndrain the battery fairly quickly by playing a game.  Designing a\nprocessor that uses half as much power lengthens the battery life in\nsuch cases.  Finally,\nthe third region of power consumption measurements is impossible:\nif you use so much power, your chip will overheat or even burst\ninto flames.  Consumers get unhappy when such things happen.\n\nAs a first step, you can remove any metrics for which all solutions\nare effectively equivalent.\n\nUntil a little less than a decade ago, for example, the power \nconsumption of a desktop\nprocessor actually was in the first range that we discussed.  Power\nwas simply not a concern to engineers: all designs of \ninterest consumed so little power that no one cared.\n\nUnfortunately, at that point, power consumption jumped into the\nthird range rather quickly.  Processors hit a wall, and \nproducts had to be cancelled.  Given that the time spent designing\na processor has historically\nbeen about five years, a lot of engineering effort\nwas wasted because people had not thought carefully enough about\npower (since it had never mattered in the past).\n\nToday, power is an important metric that engineers must take into\naccount in their designs. \n\nHowever, in some areas, such as desktop and high-end server\nprocessors,\nother metrics (such as performance) may be so \nimportant that we always want to operate at the edge of the\ninteresting range.  In such cases, we might choose to treat \na metric such as power consumption as a { threshold}: stay\nbelow 150 Watts for a desktop processor, for example.  One still\nhas to make a coordinated effort to ensure that the system as\na whole does not exceed the threshold, but reasoning about \nthreshold values, a form of constraint, is easier than trying to\nthink about multiple metrics at once.\n\nSome metrics may only allow discrete quantification.  For example,\none could choose to define compatibility with previous processor\ngenerations as binary: either an existing piece of software\n(or operating system)\nruns out of the box on your new processor, or it does not.  If you \nwant people who own that software to make use of your new processor,\nyou must ensure that the value of this binary metric is 1, which\ncan also be viewed as a threshold.\n\nIn some cases, two metrics may be strongly { correlated}, meaning\nthat a design that is good for one of the metrics is frequently \ngood for the other metric as well.\n\nChip area and cost, for\nexample, are technically distinct ways to measure a digital design,\nbut we rarely consider them separately.\n\nA design that requires a larger chip is probably more complex,\nand thus takes more engineering time to get right (engineering time\ncosts money).  \n\nEach silicon wafer costs money to fabricate, and fewer copies of a \nlarge design fit on one wafer, so large chips mean more fabrication\ncost.\n\nPhysical defects in silicon can cause some chips not to work.  A large\nchip uses more silicon than a small one, and is thus more likely to suffer\nfrom defects (and not work).  Cost thus goes up again for large chips\nrelative to small ones.\n\nFinally, large chips usually require more careful testing to ensure\nthat they work properly (even ignoring the cost of getting the design\nright, we have to test for the presence of defects), which adds still\nmore cost for a larger chip.\n\nAll of these factors tend to correlate chip area and chip cost, to the\npoint that most engineers do not consider both metrics.\n\n\nAfter you have tried to reduce your set of metrics as much as possible,\nor simplified them by turning them into thresholds, you should consider\nturning the last few metrics into a weighted linear sum.  All remaining\nmetrics must be quantifiable in this case.\n\nFor example, if you are left with three metrics for which a given\ndesign has values A, B, and C, you might reduce these to one\nmetric by calculating D=w_AA+w_BB+w_CC.  What are the w values?\nThey are weights for the three metrics.  Their values represent the\nrelative importance of the three metrics to the overall evaluation.\nHere we've assumed that larger values of A, B, and C are either\nall good or all bad.  If you have metrics with different senses,\nuse the reciprocal values.  For example, if a large value of A is good,\na small value of 1/A is also good.  \n\nThe difficulty with linearizing metrics is that not everyone agrees\non the weights.  Is using less power more important than having a cheaper\nchip?  The answer may depend on many factors.\n\nWhen you are left with several metrics of interest, you can use the\nidea of Pareto optimality to identify interesting designs.\n\nLet's say that you have two metrics.  If a design D_1 is better than\na second design D_2 for both metrics, we say that D_1 \n{ dominates} D_2.\n\nA design D is then said to be { Pareto optimal} if no other design\ndominates D.  Consider the figure on the left below, which illustrates\nseven possible designs measured with two metrics.  The design corresponding\nto point B dominates the designs corresponding to points A and C, so \nneither of the latter designs is Pareto optimal.  No other point \nin the figure dominates B, however, so that design is Pareto optimal.\nIf we remove all points that do not represent Pareto optimal designs,\nand instead include only those designs that are Pareto optimal, we\nobtain the version shown on the right.  These are points in a two-dimensional\nspace, not a line, but we can imagine a line going through the points,\nas illustrated in the figure: the points that make up the line are\ncalled a { Pareto curve}, or, if you have more than two metrics,\na { Pareto surface}.\n\n{\n\n\n\n\nAs an example of the use of Pareto optimality, consider the figure\nto the right, which is copied with permission from Neal Crago's Ph.D. \ndissertation (UIUC ECE, 2012).  The figure compares hundreds of thousands \nof possible\ndesigns based on a handful of different core approaches for\nimplementing a processor.  The axes in the graph are two metrics \nof interest.  The horizontal axis measures the average performance of a \ndesign when\nexecuting a set of benchmark applications, normalized to\na baseline processor design.  The vertical axis measures the energy\nconsumed by a design when\n\n\n{file=part2/cited/bench_pareto.eps,width=3in}\n\n\nexecuting the same benchmarks, normalized\nagain to the energy consumed by a baseline design.  The six sets of\npoints in the graph represent alternative design techniques for the\nprocessor, most of which are in commercial use today.  The points\nshown for each set are the subset of many thousands of possible variants\nthat are Pareto optimal.  In this case, more performance and less energy\nconsumption are the good directions, so any point in a set for which\nanother point is both further to the right and further down is not\nshown in the graph.  The black line represents an absolute power\nconsumption of 150 Watts, which is a nominal threshold for a desktop\nenvironment.  Designs above and to the right of that line are not\nas interesting for desktop use.  The { design-space exploration} that\nNeal reported in this figure was of course done by many computers using\nmany hours of computation, but he had to design the process by which the\ncomputers calculated each of the points.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the first step you should take when thinking about a new problem?\n2. What are some of the ways you can reduce the number of metrics you have to consider?\n3. What is the Pareto optimal?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Multi-Metric Optimization",
            "text": "{Multi-Metric Optimization}\n\nAs engineers, almost every real problem that you encounter will admit \nmultiple metrics for evaluating possible designs.  Becoming a good\nengineer thus requires not only that you be able to solve problems\ncreatively so as to improve the quality of your solutions, but also\nthat you are aware of how people might evaluate those solutions and\nare able both to identify the most important metrics and to balance \nyour design effectively according to them.  In this section, we\nintroduce some general ideas and methods that may be of use to you\nin this regard.\n\n{ We will not test you on the concepts in this section.}\n\nWhen you start thinking about a new problem, your first step\nshould be to think carefully about metrics of possible interest.\n\nSome important metrics may not be easy to quantify.  \n\nFor example, compatibility of a design with other products already \nowned by a customer has frequently defined the success or failure\nof computer hardware and software solutions.\n\nBut how can you compute the compability of your approach as\na number?\n\nHumans---including engineers---are not good at\ncomparing multiple metrics simultaneously.\n\nThus, once you have a set of metrics that you feel is complete, \nyour next step is to get rid of as many as you can.\n\nTowards this end, you may identify metrics that have no practical \nimpact in current technology, set threshold values for other metrics\nto simplify reasoning about them, eliminate redundant metrics,\ncalculate linear sums to reduce the count of metrics, and, finally,\nmake use of the notion of Pareto optimality.  All of these ideas are\ndescribed in the rest of this section.\n\nLet's start by considering metrics that we can quantify as real\nnumbers.\n\nFor a given metric, we can divide possible measurement values into\nthree ranges.\n\nIn the first range,\nall measurement values are equivalently useful.\nIn the second range, \npossible values are ordered and interesting with respect to\none another.\nValues in the third range are all impossible to use in practice.\nUsing power consumption as\nour example, the first range corresponds to systems in which\nwhen a processor's power consumption in a digital \nsystem is extremely low relative to the\npower consumption\nof the system.\nFor example, the processor in a computer might use less than 1 \nof the total used by \nthe system including the disk drive, the monitor, the power \nsupply, and so forth.  One power consumption value in this range \nis just as good as any\nanother, and no one cares about the power consumption of the processor \nin such cases.  In the second range, power consumption of the\nprocessor makes a difference.  Cell phones use most of their energy\nin radio operation, for example, but if you own a phone with a powerful\nprocessor, you may have noticed that you can turn off the phone and \ndrain the battery fairly quickly by playing a game.  Designing a\nprocessor that uses half as much power lengthens the battery life in\nsuch cases.  Finally,\nthe third region of power consumption measurements is impossible:\nif you use so much power, your chip will overheat or even burst\ninto flames.  Consumers get unhappy when such things happen.\n\nAs a first step, you can remove any metrics for which all solutions\nare effectively equivalent.\n\nUntil a little less than a decade ago, for example, the power \nconsumption of a desktop\nprocessor actually was in the first range that we discussed.  Power\nwas simply not a concern to engineers: all designs of \ninterest consumed so little power that no one cared.\n\nUnfortunately, at that point, power consumption jumped into the\nthird range rather quickly.  Processors hit a wall, and \nproducts had to be cancelled.  Given that the time spent designing\na processor has historically\nbeen about five years, a lot of engineering effort\nwas wasted because people had not thought carefully enough about\npower (since it had never mattered in the past).\n\nToday, power is an important metric that engineers must take into\naccount in their designs. \n\nHowever, in some areas, such as desktop and high-end server\nprocessors,\nother metrics (such as performance) may be so \nimportant that we always want to operate at the edge of the\ninteresting range.  In such cases, we might choose to treat \na metric such as power consumption as a { threshold}: stay\nbelow 150 Watts for a desktop processor, for example.  One still\nhas to make a coordinated effort to ensure that the system as\na whole does not exceed the threshold, but reasoning about \nthreshold values, a form of constraint, is easier than trying to\nthink about multiple metrics at once.\n\nSome metrics may only allow discrete quantification.  For example,\none could choose to define compatibility with previous processor\ngenerations as binary: either an existing piece of software\n(or operating system)\nruns out of the box on your new processor, or it does not.  If you \nwant people who own that software to make use of your new processor,\nyou must ensure that the value of this binary metric is 1, which\ncan also be viewed as a threshold.\n\nIn some cases, two metrics may be strongly { correlated}, meaning\nthat a design that is good for one of the metrics is frequently \ngood for the other metric as well.\n\nChip area and cost, for\nexample, are technically distinct ways to measure a digital design,\nbut we rarely consider them separately.\n\nA design that requires a larger chip is probably more complex,\nand thus takes more engineering time to get right (engineering time\ncosts money).  \n\nEach silicon wafer costs money to fabricate, and fewer copies of a \nlarge design fit on one wafer, so large chips mean more fabrication\ncost.\n\nPhysical defects in silicon can cause some chips not to work.  A large\nchip uses more silicon than a small one, and is thus more likely to suffer\nfrom defects (and not work).  Cost thus goes up again for large chips\nrelative to small ones.\n\nFinally, large chips usually require more careful testing to ensure\nthat they work properly (even ignoring the cost of getting the design\nright, we have to test for the presence of defects), which adds still\nmore cost for a larger chip.\n\nAll of these factors tend to correlate chip area and chip cost, to the\npoint that most engineers do not consider both metrics.\n\n\nAfter you have tried to reduce your set of metrics as much as possible,\nor simplified them by turning them into thresholds, you should consider\nturning the last few metrics into a weighted linear sum.  All remaining\nmetrics must be quantifiable in this case.\n\nFor example, if you are left with three metrics for which a given\ndesign has values A, B, and C, you might reduce these to one\nmetric by calculating D=w_AA+w_BB+w_CC.  What are the w values?\nThey are weights for the three metrics.  Their values represent the\nrelative importance of the three metrics to the overall evaluation.\nHere we've assumed that larger values of A, B, and C are either\nall good or all bad.  If you have metrics with different senses,\nuse the reciprocal values.  For example, if a large value of A is good,\na small value of 1/A is also good.  \n\nThe difficulty with linearizing metrics is that not everyone agrees\non the weights.  Is using less power more important than having a cheaper\nchip?  The answer may depend on many factors.\n\nWhen you are left with several metrics of interest, you can use the\nidea of Pareto optimality to identify interesting designs.\n\nLet's say that you have two metrics.  If a design D_1 is better than\na second design D_2 for both metrics, we say that D_1 \n{ dominates} D_2.\n\nA design D is then said to be { Pareto optimal} if no other design\ndominates D.  Consider the figure on the left below, which illustrates\nseven possible designs measured with two metrics.  The design corresponding\nto point B dominates the designs corresponding to points A and C, so \nneither of the latter designs is Pareto optimal.  No other point \nin the figure dominates B, however, so that design is Pareto optimal.\nIf we remove all points that do not represent Pareto optimal designs,\nand instead include only those designs that are Pareto optimal, we\nobtain the version shown on the right.  These are points in a two-dimensional\nspace, not a line, but we can imagine a line going through the points,\nas illustrated in the figure: the points that make up the line are\ncalled a { Pareto curve}, or, if you have more than two metrics,\na { Pareto surface}.\n\n{\n\n\n\n\nAs an example of the use of Pareto optimality, consider the figure\nto the right, which is copied with permission from Neal Crago's Ph.D. \ndissertation (UIUC ECE, 2012).  The figure compares hundreds of thousands \nof possible\ndesigns based on a handful of different core approaches for\nimplementing a processor.  The axes in the graph are two metrics \nof interest.  The horizontal axis measures the average performance of a \ndesign when\nexecuting a set of benchmark applications, normalized to\na baseline processor design.  The vertical axis measures the energy\nconsumed by a design when\n\n\n{file=part2/cited/bench_pareto.eps,width=3in}\n\n\nexecuting the same benchmarks, normalized\nagain to the energy consumed by a baseline design.  The six sets of\npoints in the graph represent alternative design techniques for the\nprocessor, most of which are in commercial use today.  The points\nshown for each set are the subset of many thousands of possible variants\nthat are Pareto optimal.  In this case, more performance and less energy\nconsumption are the good directions, so any point in a set for which\nanother point is both further to the right and further down is not\nshown in the graph.  The black line represents an absolute power\nconsumption of 150 Watts, which is a nominal threshold for a desktop\nenvironment.  Designs above and to the right of that line are not\nas interesting for desktop use.  The { design-space exploration} that\nNeal reported in this figure was of course done by many computers using\nmany hours of computation, but he had to design the process by which the\ncomputers calculated each of the points.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the first step you should take when thinking about a new problem?\n2. What are some of the ways you can reduce the number of metrics you have to consider?\n3. What is the Pareto optimal?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Multi-Metric Optimization",
            "text": "{Multi-Metric Optimization}\n\nAs engineers, almost every real problem that you encounter will admit \nmultiple metrics for evaluating possible designs.  Becoming a good\nengineer thus requires not only that you be able to solve problems\ncreatively so as to improve the quality of your solutions, but also\nthat you are aware of how people might evaluate those solutions and\nare able both to identify the most important metrics and to balance \nyour design effectively according to them.  In this section, we\nintroduce some general ideas and methods that may be of use to you\nin this regard.\n\n{ We will not test you on the concepts in this section.}\n\nWhen you start thinking about a new problem, your first step\nshould be to think carefully about metrics of possible interest.\n\nSome important metrics may not be easy to quantify.  \n\nFor example, compatibility of a design with other products already \nowned by a customer has frequently defined the success or failure\nof computer hardware and software solutions.\n\nBut how can you compute the compability of your approach as\na number?\n\nHumans---including engineers---are not good at\ncomparing multiple metrics simultaneously.\n\nThus, once you have a set of metrics that you feel is complete, \nyour next step is to get rid of as many as you can.\n\nTowards this end, you may identify metrics that have no practical \nimpact in current technology, set threshold values for other metrics\nto simplify reasoning about them, eliminate redundant metrics,\ncalculate linear sums to reduce the count of metrics, and, finally,\nmake use of the notion of Pareto optimality.  All of these ideas are\ndescribed in the rest of this section.\n\nLet's start by considering metrics that we can quantify as real\nnumbers.\n\nFor a given metric, we can divide possible measurement values into\nthree ranges.\n\nIn the first range,\nall measurement values are equivalently useful.\nIn the second range, \npossible values are ordered and interesting with respect to\none another.\nValues in the third range are all impossible to use in practice.\nUsing power consumption as\nour example, the first range corresponds to systems in which\nwhen a processor's power consumption in a digital \nsystem is extremely low relative to the\npower consumption\nof the system.\nFor example, the processor in a computer might use less than 1 \nof the total used by \nthe system including the disk drive, the monitor, the power \nsupply, and so forth.  One power consumption value in this range \nis just as good as any\nanother, and no one cares about the power consumption of the processor \nin such cases.  In the second range, power consumption of the\nprocessor makes a difference.  Cell phones use most of their energy\nin radio operation, for example, but if you own a phone with a powerful\nprocessor, you may have noticed that you can turn off the phone and \ndrain the battery fairly quickly by playing a game.  Designing a\nprocessor that uses half as much power lengthens the battery life in\nsuch cases.  Finally,\nthe third region of power consumption measurements is impossible:\nif you use so much power, your chip will overheat or even burst\ninto flames.  Consumers get unhappy when such things happen.\n\nAs a first step, you can remove any metrics for which all solutions\nare effectively equivalent.\n\nUntil a little less than a decade ago, for example, the power \nconsumption of a desktop\nprocessor actually was in the first range that we discussed.  Power\nwas simply not a concern to engineers: all designs of \ninterest consumed so little power that no one cared.\n\nUnfortunately, at that point, power consumption jumped into the\nthird range rather quickly.  Processors hit a wall, and \nproducts had to be cancelled.  Given that the time spent designing\na processor has historically\nbeen about five years, a lot of engineering effort\nwas wasted because people had not thought carefully enough about\npower (since it had never mattered in the past).\n\nToday, power is an important metric that engineers must take into\naccount in their designs. \n\nHowever, in some areas, such as desktop and high-end server\nprocessors,\nother metrics (such as performance) may be so \nimportant that we always want to operate at the edge of the\ninteresting range.  In such cases, we might choose to treat \na metric such as power consumption as a { threshold}: stay\nbelow 150 Watts for a desktop processor, for example.  One still\nhas to make a coordinated effort to ensure that the system as\na whole does not exceed the threshold, but reasoning about \nthreshold values, a form of constraint, is easier than trying to\nthink about multiple metrics at once.\n\nSome metrics may only allow discrete quantification.  For example,\none could choose to define compatibility with previous processor\ngenerations as binary: either an existing piece of software\n(or operating system)\nruns out of the box on your new processor, or it does not.  If you \nwant people who own that software to make use of your new processor,\nyou must ensure that the value of this binary metric is 1, which\ncan also be viewed as a threshold.\n\nIn some cases, two metrics may be strongly { correlated}, meaning\nthat a design that is good for one of the metrics is frequently \ngood for the other metric as well.\n\nChip area and cost, for\nexample, are technically distinct ways to measure a digital design,\nbut we rarely consider them separately.\n\nA design that requires a larger chip is probably more complex,\nand thus takes more engineering time to get right (engineering time\ncosts money).  \n\nEach silicon wafer costs money to fabricate, and fewer copies of a \nlarge design fit on one wafer, so large chips mean more fabrication\ncost.\n\nPhysical defects in silicon can cause some chips not to work.  A large\nchip uses more silicon than a small one, and is thus more likely to suffer\nfrom defects (and not work).  Cost thus goes up again for large chips\nrelative to small ones.\n\nFinally, large chips usually require more careful testing to ensure\nthat they work properly (even ignoring the cost of getting the design\nright, we have to test for the presence of defects), which adds still\nmore cost for a larger chip.\n\nAll of these factors tend to correlate chip area and chip cost, to the\npoint that most engineers do not consider both metrics.\n\n\nAfter you have tried to reduce your set of metrics as much as possible,\nor simplified them by turning them into thresholds, you should consider\nturning the last few metrics into a weighted linear sum.  All remaining\nmetrics must be quantifiable in this case.\n\nFor example, if you are left with three metrics for which a given\ndesign has values A, B, and C, you might reduce these to one\nmetric by calculating D=w_AA+w_BB+w_CC.  What are the w values?\nThey are weights for the three metrics.  Their values represent the\nrelative importance of the three metrics to the overall evaluation.\nHere we've assumed that larger values of A, B, and C are either\nall good or all bad.  If you have metrics with different senses,\nuse the reciprocal values.  For example, if a large value of A is good,\na small value of 1/A is also good.  \n\nThe difficulty with linearizing metrics is that not everyone agrees\non the weights.  Is using less power more important than having a cheaper\nchip?  The answer may depend on many factors.\n\nWhen you are left with several metrics of interest, you can use the\nidea of Pareto optimality to identify interesting designs.\n\nLet's say that you have two metrics.  If a design D_1 is better than\na second design D_2 for both metrics, we say that D_1 \n{ dominates} D_2.\n\nA design D is then said to be { Pareto optimal} if no other design\ndominates D.  Consider the figure on the left below, which illustrates\nseven possible designs measured with two metrics.  The design corresponding\nto point B dominates the designs corresponding to points A and C, so \nneither of the latter designs is Pareto optimal.  No other point \nin the figure dominates B, however, so that design is Pareto optimal.\nIf we remove all points that do not represent Pareto optimal designs,\nand instead include only those designs that are Pareto optimal, we\nobtain the version shown on the right.  These are points in a two-dimensional\nspace, not a line, but we can imagine a line going through the points,\nas illustrated in the figure: the points that make up the line are\ncalled a { Pareto curve}, or, if you have more than two metrics,\na { Pareto surface}.\n\n{\n\n\n\n\nAs an example of the use of Pareto optimality, consider the figure\nto the right, which is copied with permission from Neal Crago's Ph.D. \ndissertation (UIUC ECE, 2012).  The figure compares hundreds of thousands \nof possible\ndesigns based on a handful of different core approaches for\nimplementing a processor.  The axes in the graph are two metrics \nof interest.  The horizontal axis measures the average performance of a \ndesign when\nexecuting a set of benchmark applications, normalized to\na baseline processor design.  The vertical axis measures the energy\nconsumed by a design when\n\n\n{file=part2/cited/bench_pareto.eps,width=3in}\n\n\nexecuting the same benchmarks, normalized\nagain to the energy consumed by a baseline design.  The six sets of\npoints in the graph represent alternative design techniques for the\nprocessor, most of which are in commercial use today.  The points\nshown for each set are the subset of many thousands of possible variants\nthat are Pareto optimal.  In this case, more performance and less energy\nconsumption are the good directions, so any point in a set for which\nanother point is both further to the right and further down is not\nshown in the graph.  The black line represents an absolute power\nconsumption of 150 Watts, which is a nominal threshold for a desktop\nenvironment.  Designs above and to the right of that line are not\nas interesting for desktop use.  The { design-space exploration} that\nNeal reported in this figure was of course done by many computers using\nmany hours of computation, but he had to design the process by which the\ncomputers calculated each of the points.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the first step you should take when thinking about a new problem?\n2. What are some of the ways you can reduce the number of metrics you have to consider?\n3. What is the Pareto optimal?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Multi-Metric Optimization",
            "text": "{Multi-Metric Optimization}\n\nAs engineers, almost every real problem that you encounter will admit \nmultiple metrics for evaluating possible designs.  Becoming a good\nengineer thus requires not only that you be able to solve problems\ncreatively so as to improve the quality of your solutions, but also\nthat you are aware of how people might evaluate those solutions and\nare able both to identify the most important metrics and to balance \nyour design effectively according to them.  In this section, we\nintroduce some general ideas and methods that may be of use to you\nin this regard.\n\n{ We will not test you on the concepts in this section.}\n\nWhen you start thinking about a new problem, your first step\nshould be to think carefully about metrics of possible interest.\n\nSome important metrics may not be easy to quantify.  \n\nFor example, compatibility of a design with other products already \nowned by a customer has frequently defined the success or failure\nof computer hardware and software solutions.\n\nBut how can you compute the compability of your approach as\na number?\n\nHumans---including engineers---are not good at\ncomparing multiple metrics simultaneously.\n\nThus, once you have a set of metrics that you feel is complete, \nyour next step is to get rid of as many as you can.\n\nTowards this end, you may identify metrics that have no practical \nimpact in current technology, set threshold values for other metrics\nto simplify reasoning about them, eliminate redundant metrics,\ncalculate linear sums to reduce the count of metrics, and, finally,\nmake use of the notion of Pareto optimality.  All of these ideas are\ndescribed in the rest of this section.\n\nLet's start by considering metrics that we can quantify as real\nnumbers.\n\nFor a given metric, we can divide possible measurement values into\nthree ranges.\n\nIn the first range,\nall measurement values are equivalently useful.\nIn the second range, \npossible values are ordered and interesting with respect to\none another.\nValues in the third range are all impossible to use in practice.\nUsing power consumption as\nour example, the first range corresponds to systems in which\nwhen a processor's power consumption in a digital \nsystem is extremely low relative to the\npower consumption\nof the system.\nFor example, the processor in a computer might use less than 1 \nof the total used by \nthe system including the disk drive, the monitor, the power \nsupply, and so forth.  One power consumption value in this range \nis just as good as any\nanother, and no one cares about the power consumption of the processor \nin such cases.  In the second range, power consumption of the\nprocessor makes a difference.  Cell phones use most of their energy\nin radio operation, for example, but if you own a phone with a powerful\nprocessor, you may have noticed that you can turn off the phone and \ndrain the battery fairly quickly by playing a game.  Designing a\nprocessor that uses half as much power lengthens the battery life in\nsuch cases.  Finally,\nthe third region of power consumption measurements is impossible:\nif you use so much power, your chip will overheat or even burst\ninto flames.  Consumers get unhappy when such things happen.\n\nAs a first step, you can remove any metrics for which all solutions\nare effectively equivalent.\n\nUntil a little less than a decade ago, for example, the power \nconsumption of a desktop\nprocessor actually was in the first range that we discussed.  Power\nwas simply not a concern to engineers: all designs of \ninterest consumed so little power that no one cared.\n\nUnfortunately, at that point, power consumption jumped into the\nthird range rather quickly.  Processors hit a wall, and \nproducts had to be cancelled.  Given that the time spent designing\na processor has historically\nbeen about five years, a lot of engineering effort\nwas wasted because people had not thought carefully enough about\npower (since it had never mattered in the past).\n\nToday, power is an important metric that engineers must take into\naccount in their designs. \n\nHowever, in some areas, such as desktop and high-end server\nprocessors,\nother metrics (such as performance) may be so \nimportant that we always want to operate at the edge of the\ninteresting range.  In such cases, we might choose to treat \na metric such as power consumption as a { threshold}: stay\nbelow 150 Watts for a desktop processor, for example.  One still\nhas to make a coordinated effort to ensure that the system as\na whole does not exceed the threshold, but reasoning about \nthreshold values, a form of constraint, is easier than trying to\nthink about multiple metrics at once.\n\nSome metrics may only allow discrete quantification.  For example,\none could choose to define compatibility with previous processor\ngenerations as binary: either an existing piece of software\n(or operating system)\nruns out of the box on your new processor, or it does not.  If you \nwant people who own that software to make use of your new processor,\nyou must ensure that the value of this binary metric is 1, which\ncan also be viewed as a threshold.\n\nIn some cases, two metrics may be strongly { correlated}, meaning\nthat a design that is good for one of the metrics is frequently \ngood for the other metric as well.\n\nChip area and cost, for\nexample, are technically distinct ways to measure a digital design,\nbut we rarely consider them separately.\n\nA design that requires a larger chip is probably more complex,\nand thus takes more engineering time to get right (engineering time\ncosts money).  \n\nEach silicon wafer costs money to fabricate, and fewer copies of a \nlarge design fit on one wafer, so large chips mean more fabrication\ncost.\n\nPhysical defects in silicon can cause some chips not to work.  A large\nchip uses more silicon than a small one, and is thus more likely to suffer\nfrom defects (and not work).  Cost thus goes up again for large chips\nrelative to small ones.\n\nFinally, large chips usually require more careful testing to ensure\nthat they work properly (even ignoring the cost of getting the design\nright, we have to test for the presence of defects), which adds still\nmore cost for a larger chip.\n\nAll of these factors tend to correlate chip area and chip cost, to the\npoint that most engineers do not consider both metrics.\n\n\nAfter you have tried to reduce your set of metrics as much as possible,\nor simplified them by turning them into thresholds, you should consider\nturning the last few metrics into a weighted linear sum.  All remaining\nmetrics must be quantifiable in this case.\n\nFor example, if you are left with three metrics for which a given\ndesign has values A, B, and C, you might reduce these to one\nmetric by calculating D=w_AA+w_BB+w_CC.  What are the w values?\nThey are weights for the three metrics.  Their values represent the\nrelative importance of the three metrics to the overall evaluation.\nHere we've assumed that larger values of A, B, and C are either\nall good or all bad.  If you have metrics with different senses,\nuse the reciprocal values.  For example, if a large value of A is good,\na small value of 1/A is also good.  \n\nThe difficulty with linearizing metrics is that not everyone agrees\non the weights.  Is using less power more important than having a cheaper\nchip?  The answer may depend on many factors.\n\nWhen you are left with several metrics of interest, you can use the\nidea of Pareto optimality to identify interesting designs.\n\nLet's say that you have two metrics.  If a design D_1 is better than\na second design D_2 for both metrics, we say that D_1 \n{ dominates} D_2.\n\nA design D is then said to be { Pareto optimal} if no other design\ndominates D.  Consider the figure on the left below, which illustrates\nseven possible designs measured with two metrics.  The design corresponding\nto point B dominates the designs corresponding to points A and C, so \nneither of the latter designs is Pareto optimal.  No other point \nin the figure dominates B, however, so that design is Pareto optimal.\nIf we remove all points that do not represent Pareto optimal designs,\nand instead include only those designs that are Pareto optimal, we\nobtain the version shown on the right.  These are points in a two-dimensional\nspace, not a line, but we can imagine a line going through the points,\nas illustrated in the figure: the points that make up the line are\ncalled a { Pareto curve}, or, if you have more than two metrics,\na { Pareto surface}.\n\n{\n\n\n\n\nAs an example of the use of Pareto optimality, consider the figure\nto the right, which is copied with permission from Neal Crago's Ph.D. \ndissertation (UIUC ECE, 2012).  The figure compares hundreds of thousands \nof possible\ndesigns based on a handful of different core approaches for\nimplementing a processor.  The axes in the graph are two metrics \nof interest.  The horizontal axis measures the average performance of a \ndesign when\nexecuting a set of benchmark applications, normalized to\na baseline processor design.  The vertical axis measures the energy\nconsumed by a design when\n\n\n{file=part2/cited/bench_pareto.eps,width=3in}\n\n\nexecuting the same benchmarks, normalized\nagain to the energy consumed by a baseline design.  The six sets of\npoints in the graph represent alternative design techniques for the\nprocessor, most of which are in commercial use today.  The points\nshown for each set are the subset of many thousands of possible variants\nthat are Pareto optimal.  In this case, more performance and less energy\nconsumption are the good directions, so any point in a set for which\nanother point is both further to the right and further down is not\nshown in the graph.  The black line represents an absolute power\nconsumption of 150 Watts, which is a nominal threshold for a desktop\nenvironment.  Designs above and to the right of that line are not\nas interesting for desktop use.  The { design-space exploration} that\nNeal reported in this figure was of course done by many computers using\nmany hours of computation, but he had to design the process by which the\ncomputers calculated each of the points.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the first step you should take when thinking about a new problem?\n2. What are some of the ways you can reduce the number of metrics you have to consider?\n3. What is the Pareto optimal?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Proof Outline for Clocked Synchronous Design*",
            "text": "{Proof Outline for Clocked Synchronous Design*}\n\nThis section outlines a proof of the claim made regarding clock\nskew being the only source of essential hazards for clocked\nsynchronous sequential circuits.  A { proof outline} suggests\nthe form that a proof might take and provides some of the logical\narguments, but is not rigorous enough to be considered a proof.\nHere we use a D flip-flop to illustrate a method for identifying\nessential hazards ({ the D flip-flop has no essential hazards, however}),\nthen argue that the method can be applied generally to collections\nof flip-flops in a clocked synchronous design to show that essential\nhazards occur only in the form of clock skew. \n\n\n{\n\n&{1-2}\nlow&L&clock low, last input low\nhigh&H&clock high, last input low\npulse low&PL&clock low, last input high (output high, too)\npulse high&PH&clock high, last input high (output high, too)\n\n}\n\n\n{{file=part2/figs/lec15-8.eps,width=2in}}\n\n\nConsider the sequential feedback state table for a positive\nedge-triggered D flip-flop, shown above.  In designing and analyzing\nsuch circuits, we assume that only one input bit changes at a time.\nThe state table consists of one row for each state and one column for\neach input combination.  Within a row, input combinations that have no\neffect on the internal state of the circuit (that is, those that do \nnot cause any change in\nthe state) are said to be stable; these states are circled.  Other\nstates are unstable, and the circuit changes state in response to\nchanges in the inputs.\n\nFor example, given an initial state L with low output, low clock,\nand high input D, the solid arcs trace the reaction of the circuit to a\nrising clock edge.  From the 01 input combination, we move along the\ncolumn to the 11 column, which indicates the new state, PH.  Moving\ndown the column to that state's row, we see that the new state is\nstable for the input combination 11, and we stop.  If PH were not\nstable, we would continue to move within the column until coming to\nrest on a stable state.\n\nAn essential hazard appears in such a table as a difference between\nthe final state when flipping a bit once and the final state when\nflipping a bit thrice in succession.  The dashed arcs in the figure\nillustrate the concept: after coming to rest in the PH state, we reset\nthe input to 01 and move along the PH row to find a new state of PL.\nMoving up the column, we see that the state is stable.  We then flip\nthe clock a third time and move back along the row to 11, which\nindicates that PH is again the next state.  Moving down the column, we\ncome again to rest in PH, the same state as was reached after one\nflip.  Flipping a bit three times rather than once evaluates the\nimpact of timing skew in the circuit; if a different state is reached\nafter two more flips, timing skew could cause unreliable behavior.  As\nyou can verify from the table, a D flip-flop has no essential hazards.\n\nA group of flip-flops, as might appear in a clocked synchronous\ncircuit, can and usually does have essential hazards, but only dealing\nwith the clock.  As you know, the inputs to a clocked synchronous\nsequential circuit consist of a clock signal and other inputs (either\nexternal of fed back from the flip-flops).  Changing an input other\nthan the clock can change the internal state of a flip-flop (of the\n\n master-slave variety), but flip-flop designs do not capture the number\n\ndual-latch variety), but flip-flop designs do not capture the number\nof input changes in a clock cycle beyond one, and changing an input\nthree times is the same as changing it once.  Changing the clock, of\ncourse, results in a synchronous state machine transition.\n\nThe detection of essential hazards in a clocked synchronous design\nbased on flip-flops thus reduces to examination of the state machine.\nIf the next state of the machine has any dependence on the current\nstate, an essential hazard exists, as a second rising clock edge moves\nthe system into a second new state.  For a single D flip-flop, the\nnext state is independent of the current state, and no essential\nhazards are present.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the significance of an essential hazard in a sequential feedback state table?\n2. How do you detect essential hazards in a clocked synchronous design?\n3. What is the only source of essential hazards for clocked synchronous sequential circuits?",
        "answers": "\n\n1. Essential hazards are differences between the final state when flipping a bit once and the final state when flipping a bit thrice in succession.\n2. You can detect essential hazards by examining the state machine. If the next state of the machine has any dependence on the current state, an essential hazard exists.\n3. The only source of essential hazards for clocked synchronous sequential circuits is clock skew."
    },
    {
        "positive_ctxs": {
            "title": "Proof Outline for Clocked Synchronous Design*",
            "text": "{Proof Outline for Clocked Synchronous Design*}\n\nThis section outlines a proof of the claim made regarding clock\nskew being the only source of essential hazards for clocked\nsynchronous sequential circuits.  A { proof outline} suggests\nthe form that a proof might take and provides some of the logical\narguments, but is not rigorous enough to be considered a proof.\nHere we use a D flip-flop to illustrate a method for identifying\nessential hazards ({ the D flip-flop has no essential hazards, however}),\nthen argue that the method can be applied generally to collections\nof flip-flops in a clocked synchronous design to show that essential\nhazards occur only in the form of clock skew. \n\n\n{\n\n&{1-2}\nlow&L&clock low, last input low\nhigh&H&clock high, last input low\npulse low&PL&clock low, last input high (output high, too)\npulse high&PH&clock high, last input high (output high, too)\n\n}\n\n\n{{file=part2/figs/lec15-8.eps,width=2in}}\n\n\nConsider the sequential feedback state table for a positive\nedge-triggered D flip-flop, shown above.  In designing and analyzing\nsuch circuits, we assume that only one input bit changes at a time.\nThe state table consists of one row for each state and one column for\neach input combination.  Within a row, input combinations that have no\neffect on the internal state of the circuit (that is, those that do \nnot cause any change in\nthe state) are said to be stable; these states are circled.  Other\nstates are unstable, and the circuit changes state in response to\nchanges in the inputs.\n\nFor example, given an initial state L with low output, low clock,\nand high input D, the solid arcs trace the reaction of the circuit to a\nrising clock edge.  From the 01 input combination, we move along the\ncolumn to the 11 column, which indicates the new state, PH.  Moving\ndown the column to that state's row, we see that the new state is\nstable for the input combination 11, and we stop.  If PH were not\nstable, we would continue to move within the column until coming to\nrest on a stable state.\n\nAn essential hazard appears in such a table as a difference between\nthe final state when flipping a bit once and the final state when\nflipping a bit thrice in succession.  The dashed arcs in the figure\nillustrate the concept: after coming to rest in the PH state, we reset\nthe input to 01 and move along the PH row to find a new state of PL.\nMoving up the column, we see that the state is stable.  We then flip\nthe clock a third time and move back along the row to 11, which\nindicates that PH is again the next state.  Moving down the column, we\ncome again to rest in PH, the same state as was reached after one\nflip.  Flipping a bit three times rather than once evaluates the\nimpact of timing skew in the circuit; if a different state is reached\nafter two more flips, timing skew could cause unreliable behavior.  As\nyou can verify from the table, a D flip-flop has no essential hazards.\n\nA group of flip-flops, as might appear in a clocked synchronous\ncircuit, can and usually does have essential hazards, but only dealing\nwith the clock.  As you know, the inputs to a clocked synchronous\nsequential circuit consist of a clock signal and other inputs (either\nexternal of fed back from the flip-flops).  Changing an input other\nthan the clock can change the internal state of a flip-flop (of the\n\n master-slave variety), but flip-flop designs do not capture the number\n\ndual-latch variety), but flip-flop designs do not capture the number\nof input changes in a clock cycle beyond one, and changing an input\nthree times is the same as changing it once.  Changing the clock, of\ncourse, results in a synchronous state machine transition.\n\nThe detection of essential hazards in a clocked synchronous design\nbased on flip-flops thus reduces to examination of the state machine.\nIf the next state of the machine has any dependence on the current\nstate, an essential hazard exists, as a second rising clock edge moves\nthe system into a second new state.  For a single D flip-flop, the\nnext state is independent of the current state, and no essential\nhazards are present.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the significance of an essential hazard in a sequential feedback state table?\n2. How do you detect essential hazards in a clocked synchronous design?\n3. What is the only source of essential hazards for clocked synchronous sequential circuits?",
        "answers": "\n\n1. Essential hazards are differences between the final state when flipping a bit once and the final state when flipping a bit thrice in succession.\n2. You can detect essential hazards by examining the state machine. If the next state of the machine has any dependence on the current state, an essential hazard exists.\n3. The only source of essential hazards for clocked synchronous sequential circuits is clock skew."
    },
    {
        "positive_ctxs": {
            "title": "Proof Outline for Clocked Synchronous Design*",
            "text": "{Proof Outline for Clocked Synchronous Design*}\n\nThis section outlines a proof of the claim made regarding clock\nskew being the only source of essential hazards for clocked\nsynchronous sequential circuits.  A { proof outline} suggests\nthe form that a proof might take and provides some of the logical\narguments, but is not rigorous enough to be considered a proof.\nHere we use a D flip-flop to illustrate a method for identifying\nessential hazards ({ the D flip-flop has no essential hazards, however}),\nthen argue that the method can be applied generally to collections\nof flip-flops in a clocked synchronous design to show that essential\nhazards occur only in the form of clock skew. \n\n\n{\n\n&{1-2}\nlow&L&clock low, last input low\nhigh&H&clock high, last input low\npulse low&PL&clock low, last input high (output high, too)\npulse high&PH&clock high, last input high (output high, too)\n\n}\n\n\n{{file=part2/figs/lec15-8.eps,width=2in}}\n\n\nConsider the sequential feedback state table for a positive\nedge-triggered D flip-flop, shown above.  In designing and analyzing\nsuch circuits, we assume that only one input bit changes at a time.\nThe state table consists of one row for each state and one column for\neach input combination.  Within a row, input combinations that have no\neffect on the internal state of the circuit (that is, those that do \nnot cause any change in\nthe state) are said to be stable; these states are circled.  Other\nstates are unstable, and the circuit changes state in response to\nchanges in the inputs.\n\nFor example, given an initial state L with low output, low clock,\nand high input D, the solid arcs trace the reaction of the circuit to a\nrising clock edge.  From the 01 input combination, we move along the\ncolumn to the 11 column, which indicates the new state, PH.  Moving\ndown the column to that state's row, we see that the new state is\nstable for the input combination 11, and we stop.  If PH were not\nstable, we would continue to move within the column until coming to\nrest on a stable state.\n\nAn essential hazard appears in such a table as a difference between\nthe final state when flipping a bit once and the final state when\nflipping a bit thrice in succession.  The dashed arcs in the figure\nillustrate the concept: after coming to rest in the PH state, we reset\nthe input to 01 and move along the PH row to find a new state of PL.\nMoving up the column, we see that the state is stable.  We then flip\nthe clock a third time and move back along the row to 11, which\nindicates that PH is again the next state.  Moving down the column, we\ncome again to rest in PH, the same state as was reached after one\nflip.  Flipping a bit three times rather than once evaluates the\nimpact of timing skew in the circuit; if a different state is reached\nafter two more flips, timing skew could cause unreliable behavior.  As\nyou can verify from the table, a D flip-flop has no essential hazards.\n\nA group of flip-flops, as might appear in a clocked synchronous\ncircuit, can and usually does have essential hazards, but only dealing\nwith the clock.  As you know, the inputs to a clocked synchronous\nsequential circuit consist of a clock signal and other inputs (either\nexternal of fed back from the flip-flops).  Changing an input other\nthan the clock can change the internal state of a flip-flop (of the\n\n master-slave variety), but flip-flop designs do not capture the number\n\ndual-latch variety), but flip-flop designs do not capture the number\nof input changes in a clock cycle beyond one, and changing an input\nthree times is the same as changing it once.  Changing the clock, of\ncourse, results in a synchronous state machine transition.\n\nThe detection of essential hazards in a clocked synchronous design\nbased on flip-flops thus reduces to examination of the state machine.\nIf the next state of the machine has any dependence on the current\nstate, an essential hazard exists, as a second rising clock edge moves\nthe system into a second new state.  For a single D flip-flop, the\nnext state is independent of the current state, and no essential\nhazards are present.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the significance of an essential hazard in a sequential feedback state table?\n2. How do you detect essential hazards in a clocked synchronous design?\n3. What is the only source of essential hazards for clocked synchronous sequential circuits?",
        "answers": "\n\n1. Essential hazards are differences between the final state when flipping a bit once and the final state when flipping a bit thrice in succession.\n2. You can detect essential hazards by examining the state machine. If the next state of the machine has any dependence on the current state, an essential hazard exists.\n3. The only source of essential hazards for clocked synchronous sequential circuits is clock skew."
    },
    {
        "positive_ctxs": {
            "title": "Proof Outline for Clocked Synchronous Design*",
            "text": "{Proof Outline for Clocked Synchronous Design*}\n\nThis section outlines a proof of the claim made regarding clock\nskew being the only source of essential hazards for clocked\nsynchronous sequential circuits.  A { proof outline} suggests\nthe form that a proof might take and provides some of the logical\narguments, but is not rigorous enough to be considered a proof.\nHere we use a D flip-flop to illustrate a method for identifying\nessential hazards ({ the D flip-flop has no essential hazards, however}),\nthen argue that the method can be applied generally to collections\nof flip-flops in a clocked synchronous design to show that essential\nhazards occur only in the form of clock skew. \n\n\n{\n\n&{1-2}\nlow&L&clock low, last input low\nhigh&H&clock high, last input low\npulse low&PL&clock low, last input high (output high, too)\npulse high&PH&clock high, last input high (output high, too)\n\n}\n\n\n{{file=part2/figs/lec15-8.eps,width=2in}}\n\n\nConsider the sequential feedback state table for a positive\nedge-triggered D flip-flop, shown above.  In designing and analyzing\nsuch circuits, we assume that only one input bit changes at a time.\nThe state table consists of one row for each state and one column for\neach input combination.  Within a row, input combinations that have no\neffect on the internal state of the circuit (that is, those that do \nnot cause any change in\nthe state) are said to be stable; these states are circled.  Other\nstates are unstable, and the circuit changes state in response to\nchanges in the inputs.\n\nFor example, given an initial state L with low output, low clock,\nand high input D, the solid arcs trace the reaction of the circuit to a\nrising clock edge.  From the 01 input combination, we move along the\ncolumn to the 11 column, which indicates the new state, PH.  Moving\ndown the column to that state's row, we see that the new state is\nstable for the input combination 11, and we stop.  If PH were not\nstable, we would continue to move within the column until coming to\nrest on a stable state.\n\nAn essential hazard appears in such a table as a difference between\nthe final state when flipping a bit once and the final state when\nflipping a bit thrice in succession.  The dashed arcs in the figure\nillustrate the concept: after coming to rest in the PH state, we reset\nthe input to 01 and move along the PH row to find a new state of PL.\nMoving up the column, we see that the state is stable.  We then flip\nthe clock a third time and move back along the row to 11, which\nindicates that PH is again the next state.  Moving down the column, we\ncome again to rest in PH, the same state as was reached after one\nflip.  Flipping a bit three times rather than once evaluates the\nimpact of timing skew in the circuit; if a different state is reached\nafter two more flips, timing skew could cause unreliable behavior.  As\nyou can verify from the table, a D flip-flop has no essential hazards.\n\nA group of flip-flops, as might appear in a clocked synchronous\ncircuit, can and usually does have essential hazards, but only dealing\nwith the clock.  As you know, the inputs to a clocked synchronous\nsequential circuit consist of a clock signal and other inputs (either\nexternal of fed back from the flip-flops).  Changing an input other\nthan the clock can change the internal state of a flip-flop (of the\n\n master-slave variety), but flip-flop designs do not capture the number\n\ndual-latch variety), but flip-flop designs do not capture the number\nof input changes in a clock cycle beyond one, and changing an input\nthree times is the same as changing it once.  Changing the clock, of\ncourse, results in a synchronous state machine transition.\n\nThe detection of essential hazards in a clocked synchronous design\nbased on flip-flops thus reduces to examination of the state machine.\nIf the next state of the machine has any dependence on the current\nstate, an essential hazard exists, as a second rising clock edge moves\nthe system into a second new state.  For a single D flip-flop, the\nnext state is independent of the current state, and no essential\nhazards are present.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the significance of an essential hazard in a sequential feedback state table?\n2. How do you detect essential hazards in a clocked synchronous design?\n3. What is the only source of essential hazards for clocked synchronous sequential circuits?",
        "answers": "\n\n1. Essential hazards are differences between the final state when flipping a bit once and the final state when flipping a bit thrice in succession.\n2. You can detect essential hazards by examining the state machine. If the next state of the machine has any dependence on the current state, an essential hazard exists.\n3. The only source of essential hazards for clocked synchronous sequential circuits is clock skew."
    },
    {
        "positive_ctxs": {
            "title": "Proof Outline for Clocked Synchronous Design*",
            "text": "{Proof Outline for Clocked Synchronous Design*}\n\nThis section outlines a proof of the claim made regarding clock\nskew being the only source of essential hazards for clocked\nsynchronous sequential circuits.  A { proof outline} suggests\nthe form that a proof might take and provides some of the logical\narguments, but is not rigorous enough to be considered a proof.\nHere we use a D flip-flop to illustrate a method for identifying\nessential hazards ({ the D flip-flop has no essential hazards, however}),\nthen argue that the method can be applied generally to collections\nof flip-flops in a clocked synchronous design to show that essential\nhazards occur only in the form of clock skew. \n\n\n{\n\n&{1-2}\nlow&L&clock low, last input low\nhigh&H&clock high, last input low\npulse low&PL&clock low, last input high (output high, too)\npulse high&PH&clock high, last input high (output high, too)\n\n}\n\n\n{{file=part2/figs/lec15-8.eps,width=2in}}\n\n\nConsider the sequential feedback state table for a positive\nedge-triggered D flip-flop, shown above.  In designing and analyzing\nsuch circuits, we assume that only one input bit changes at a time.\nThe state table consists of one row for each state and one column for\neach input combination.  Within a row, input combinations that have no\neffect on the internal state of the circuit (that is, those that do \nnot cause any change in\nthe state) are said to be stable; these states are circled.  Other\nstates are unstable, and the circuit changes state in response to\nchanges in the inputs.\n\nFor example, given an initial state L with low output, low clock,\nand high input D, the solid arcs trace the reaction of the circuit to a\nrising clock edge.  From the 01 input combination, we move along the\ncolumn to the 11 column, which indicates the new state, PH.  Moving\ndown the column to that state's row, we see that the new state is\nstable for the input combination 11, and we stop.  If PH were not\nstable, we would continue to move within the column until coming to\nrest on a stable state.\n\nAn essential hazard appears in such a table as a difference between\nthe final state when flipping a bit once and the final state when\nflipping a bit thrice in succession.  The dashed arcs in the figure\nillustrate the concept: after coming to rest in the PH state, we reset\nthe input to 01 and move along the PH row to find a new state of PL.\nMoving up the column, we see that the state is stable.  We then flip\nthe clock a third time and move back along the row to 11, which\nindicates that PH is again the next state.  Moving down the column, we\ncome again to rest in PH, the same state as was reached after one\nflip.  Flipping a bit three times rather than once evaluates the\nimpact of timing skew in the circuit; if a different state is reached\nafter two more flips, timing skew could cause unreliable behavior.  As\nyou can verify from the table, a D flip-flop has no essential hazards.\n\nA group of flip-flops, as might appear in a clocked synchronous\ncircuit, can and usually does have essential hazards, but only dealing\nwith the clock.  As you know, the inputs to a clocked synchronous\nsequential circuit consist of a clock signal and other inputs (either\nexternal of fed back from the flip-flops).  Changing an input other\nthan the clock can change the internal state of a flip-flop (of the\n\n master-slave variety), but flip-flop designs do not capture the number\n\ndual-latch variety), but flip-flop designs do not capture the number\nof input changes in a clock cycle beyond one, and changing an input\nthree times is the same as changing it once.  Changing the clock, of\ncourse, results in a synchronous state machine transition.\n\nThe detection of essential hazards in a clocked synchronous design\nbased on flip-flops thus reduces to examination of the state machine.\nIf the next state of the machine has any dependence on the current\nstate, an essential hazard exists, as a second rising clock edge moves\nthe system into a second new state.  For a single D flip-flop, the\nnext state is independent of the current state, and no essential\nhazards are present.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the significance of an essential hazard in a sequential feedback state table?\n2. How do you detect essential hazards in a clocked synchronous design?\n3. What is the only source of essential hazards for clocked synchronous sequential circuits?",
        "answers": "\n\n1. Essential hazards are differences between the final state when flipping a bit once and the final state when flipping a bit thrice in succession.\n2. You can detect essential hazards by examining the state machine. If the next state of the machine has any dependence on the current state, an essential hazard exists.\n3. The only source of essential hazards for clocked synchronous sequential circuits is clock skew."
    },
    {
        "positive_ctxs": {
            "title": "Proof Outline for Clocked Synchronous Design*",
            "text": "{Proof Outline for Clocked Synchronous Design*}\n\nThis section outlines a proof of the claim made regarding clock\nskew being the only source of essential hazards for clocked\nsynchronous sequential circuits.  A { proof outline} suggests\nthe form that a proof might take and provides some of the logical\narguments, but is not rigorous enough to be considered a proof.\nHere we use a D flip-flop to illustrate a method for identifying\nessential hazards ({ the D flip-flop has no essential hazards, however}),\nthen argue that the method can be applied generally to collections\nof flip-flops in a clocked synchronous design to show that essential\nhazards occur only in the form of clock skew. \n\n\n{\n\n&{1-2}\nlow&L&clock low, last input low\nhigh&H&clock high, last input low\npulse low&PL&clock low, last input high (output high, too)\npulse high&PH&clock high, last input high (output high, too)\n\n}\n\n\n{{file=part2/figs/lec15-8.eps,width=2in}}\n\n\nConsider the sequential feedback state table for a positive\nedge-triggered D flip-flop, shown above.  In designing and analyzing\nsuch circuits, we assume that only one input bit changes at a time.\nThe state table consists of one row for each state and one column for\neach input combination.  Within a row, input combinations that have no\neffect on the internal state of the circuit (that is, those that do \nnot cause any change in\nthe state) are said to be stable; these states are circled.  Other\nstates are unstable, and the circuit changes state in response to\nchanges in the inputs.\n\nFor example, given an initial state L with low output, low clock,\nand high input D, the solid arcs trace the reaction of the circuit to a\nrising clock edge.  From the 01 input combination, we move along the\ncolumn to the 11 column, which indicates the new state, PH.  Moving\ndown the column to that state's row, we see that the new state is\nstable for the input combination 11, and we stop.  If PH were not\nstable, we would continue to move within the column until coming to\nrest on a stable state.\n\nAn essential hazard appears in such a table as a difference between\nthe final state when flipping a bit once and the final state when\nflipping a bit thrice in succession.  The dashed arcs in the figure\nillustrate the concept: after coming to rest in the PH state, we reset\nthe input to 01 and move along the PH row to find a new state of PL.\nMoving up the column, we see that the state is stable.  We then flip\nthe clock a third time and move back along the row to 11, which\nindicates that PH is again the next state.  Moving down the column, we\ncome again to rest in PH, the same state as was reached after one\nflip.  Flipping a bit three times rather than once evaluates the\nimpact of timing skew in the circuit; if a different state is reached\nafter two more flips, timing skew could cause unreliable behavior.  As\nyou can verify from the table, a D flip-flop has no essential hazards.\n\nA group of flip-flops, as might appear in a clocked synchronous\ncircuit, can and usually does have essential hazards, but only dealing\nwith the clock.  As you know, the inputs to a clocked synchronous\nsequential circuit consist of a clock signal and other inputs (either\nexternal of fed back from the flip-flops).  Changing an input other\nthan the clock can change the internal state of a flip-flop (of the\n\n master-slave variety), but flip-flop designs do not capture the number\n\ndual-latch variety), but flip-flop designs do not capture the number\nof input changes in a clock cycle beyond one, and changing an input\nthree times is the same as changing it once.  Changing the clock, of\ncourse, results in a synchronous state machine transition.\n\nThe detection of essential hazards in a clocked synchronous design\nbased on flip-flops thus reduces to examination of the state machine.\nIf the next state of the machine has any dependence on the current\nstate, an essential hazard exists, as a second rising clock edge moves\nthe system into a second new state.  For a single D flip-flop, the\nnext state is independent of the current state, and no essential\nhazards are present.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the significance of an essential hazard in a sequential feedback state table?\n2. How do you detect essential hazards in a clocked synchronous design?\n3. What is the only source of essential hazards for clocked synchronous sequential circuits?",
        "answers": "\n\n1. Essential hazards are differences between the final state when flipping a bit once and the final state when flipping a bit thrice in succession.\n2. You can detect essential hazards by examining the state machine. If the next state of the machine has any dependence on the current state, an essential hazard exists.\n3. The only source of essential hazards for clocked synchronous sequential circuits is clock skew."
    },
    {
        "positive_ctxs": {
            "title": "Proof Outline for Clocked Synchronous Design*",
            "text": "{Proof Outline for Clocked Synchronous Design*}\n\nThis section outlines a proof of the claim made regarding clock\nskew being the only source of essential hazards for clocked\nsynchronous sequential circuits.  A { proof outline} suggests\nthe form that a proof might take and provides some of the logical\narguments, but is not rigorous enough to be considered a proof.\nHere we use a D flip-flop to illustrate a method for identifying\nessential hazards ({ the D flip-flop has no essential hazards, however}),\nthen argue that the method can be applied generally to collections\nof flip-flops in a clocked synchronous design to show that essential\nhazards occur only in the form of clock skew. \n\n\n{\n\n&{1-2}\nlow&L&clock low, last input low\nhigh&H&clock high, last input low\npulse low&PL&clock low, last input high (output high, too)\npulse high&PH&clock high, last input high (output high, too)\n\n}\n\n\n{{file=part2/figs/lec15-8.eps,width=2in}}\n\n\nConsider the sequential feedback state table for a positive\nedge-triggered D flip-flop, shown above.  In designing and analyzing\nsuch circuits, we assume that only one input bit changes at a time.\nThe state table consists of one row for each state and one column for\neach input combination.  Within a row, input combinations that have no\neffect on the internal state of the circuit (that is, those that do \nnot cause any change in\nthe state) are said to be stable; these states are circled.  Other\nstates are unstable, and the circuit changes state in response to\nchanges in the inputs.\n\nFor example, given an initial state L with low output, low clock,\nand high input D, the solid arcs trace the reaction of the circuit to a\nrising clock edge.  From the 01 input combination, we move along the\ncolumn to the 11 column, which indicates the new state, PH.  Moving\ndown the column to that state's row, we see that the new state is\nstable for the input combination 11, and we stop.  If PH were not\nstable, we would continue to move within the column until coming to\nrest on a stable state.\n\nAn essential hazard appears in such a table as a difference between\nthe final state when flipping a bit once and the final state when\nflipping a bit thrice in succession.  The dashed arcs in the figure\nillustrate the concept: after coming to rest in the PH state, we reset\nthe input to 01 and move along the PH row to find a new state of PL.\nMoving up the column, we see that the state is stable.  We then flip\nthe clock a third time and move back along the row to 11, which\nindicates that PH is again the next state.  Moving down the column, we\ncome again to rest in PH, the same state as was reached after one\nflip.  Flipping a bit three times rather than once evaluates the\nimpact of timing skew in the circuit; if a different state is reached\nafter two more flips, timing skew could cause unreliable behavior.  As\nyou can verify from the table, a D flip-flop has no essential hazards.\n\nA group of flip-flops, as might appear in a clocked synchronous\ncircuit, can and usually does have essential hazards, but only dealing\nwith the clock.  As you know, the inputs to a clocked synchronous\nsequential circuit consist of a clock signal and other inputs (either\nexternal of fed back from the flip-flops).  Changing an input other\nthan the clock can change the internal state of a flip-flop (of the\n\n master-slave variety), but flip-flop designs do not capture the number\n\ndual-latch variety), but flip-flop designs do not capture the number\nof input changes in a clock cycle beyond one, and changing an input\nthree times is the same as changing it once.  Changing the clock, of\ncourse, results in a synchronous state machine transition.\n\nThe detection of essential hazards in a clocked synchronous design\nbased on flip-flops thus reduces to examination of the state machine.\nIf the next state of the machine has any dependence on the current\nstate, an essential hazard exists, as a second rising clock edge moves\nthe system into a second new state.  For a single D flip-flop, the\nnext state is independent of the current state, and no essential\nhazards are present.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the significance of an essential hazard in a sequential feedback state table?\n2. How do you detect essential hazards in a clocked synchronous design?\n3. What is the only source of essential hazards for clocked synchronous sequential circuits?",
        "answers": "\n\n1. Essential hazards are differences between the final state when flipping a bit once and the final state when flipping a bit thrice in succession.\n2. You can detect essential hazards by examining the state machine. If the next state of the machine has any dependence on the current state, an essential hazard exists.\n3. The only source of essential hazards for clocked synchronous sequential circuits is clock skew."
    },
    {
        "positive_ctxs": {
            "title": "The Multiplexer",
            "text": "{The Multiplexer}\n\nUsing the more abstract designs for checking ranges of ASCII characters,\nwe can go a step further and create a checker for both upper- and lower-case\nletters.  To do so, we add another input S that allows us to select the \nfunction that we want---either the upper-case checker U(C) or the \nlower-case checker L(C).\n\nFor this purpose, we make use of a logic block called a { multiplexer},\nor { mux}.\nMultiplexers are an important abstraction for digital logic.  In \ngeneral, a multiplexer allows us to use one digital signal to \nselect which of several others is forwarded to an output.\n\n\nThe simplest form of the multiplexer is the 2-to-1 multiplexer shown to \nthe right.   The logic diagram illustrates how the mux works.  The block \nhas two inputs from the left and one from the top.  The top input allows \nus to choose which of the left inputs is forwarded to the output.  \nWhen the input S=0, the upper AND gate outputs 0, and the lower AND gate\noutputs the value of D_0.  The OR gate then produces Q=0+D_0=D_0.\nSimilarly, when input S=1, the upper AND gate outputs D_1, and the\nlower AND gate outputs 0.  In this case, the OR gate produces Q=D_1+0=D_1.\n\n\n\n\n\nThe symbolic form of the mux is a trapezoid with data inputs on the \nlarger side, an output on the smaller side, and a select input on the\nangled part of the trapezoid.  The labels inside the trapezoid indicate \nthe value of the select input S for which the adjacent data signal, \nD_1 or D_0, is copied to the output Q.\n\nWe can generalize multiplexers in two ways.  First, we can extend the \nsingle select input to a group of select inputs.  An {N-bit}\nselect input allows selection from amongst 2^N inputs.  A {4-to-1} \nmultiplexer is shown below, for example.  The logic diagram on the left\nshows how the {4-to-1 mux} operates.  For any combination of S_1S_0,\nthree of the AND gates produce 0, and the fourth outputs the D input\ncorresponding to the interpretation of S as an unsigned number.\nGiven three zeroes and one D input, the OR gate thus reproduces one of \nthe D's.  When S_1S_0=10, for example, the third AND gate copies D_2,\nand Q=D_2.\n\n{{file=part2/figs/mux4-to-1.eps,width=5.60in}}\n\nAs shown in the middle figure, a {4-to-1} mux can also be built from\nthree {2-to-1} muxes.  Finally, the symbolic form of a {4-to-1} mux \nappears on the right in the figure.\n\n\n\nThe second way in which we can generalize multiplexers is by using\nseveral multiplexers of the same type and using the same signals for \nselection.  For example, we might use a single select bit T to choose \nbetween any number of paired inputs.  Denote input pair by i D_1^i \nand D_0^i.  For each pair, we have an output Q_i.  \n\nWhen T=0, Q_i=D_0^i for each value of i.\n\nAnd, when T=1, Q_i=D_1^i for each value of i.\n\nEach value of i requires a {2-to-1} mux with its select input\ndriven by the global select signal T.\n\nReturning to the example of the upper- and lower-case checker, we\ncan make use of two groups of seven {2-to-1} muxes, all controlled by\na single bit select signal S, to choose between the inputs needed\nfor an upper-case checker and those needed for a lower-case checker.\n\nSpecific configurations of multiplexers are often referred to\nas { N-to-M multiplexers}.  Here the value N refers to the\nnumber of inputs, and M refers to the number of outputs.  The\nnumber of select bits can then be calculated as _2(N/M)---N/M \nis generally a power of two---and one way to build such a \nmultiplexer is to use M copies of\nan  (N/M)-to-1 multiplexer.\n\nLet's extend our upper- and lower-case checker to check\nfor four different ranges of ASCII characters, as shown below.\nThis design uses two {28-to-7} muxes to create a single\nchecker for the four ranges.  Each of the muxes in the figure logically \nrepresents seven {4-to-1} muxes.\n\n{{file=part2/figs/ascii-four-range.eps,width=3.75in}}\n\n\nThe table to the right describes the behavior of the checker.\n\nWhen the select input S is set to 00, the left mux selects the value 0x00,\nand the right mux selects the value 0x1F, which checks whether the ASCII\ncharacter represented by C is a control character.\n\nWhen the select input S=01, the muxes produce the values needed to check\nwhether C is an upper-case letter.\n\nSimilarly, when the select input S=10,\n\n\n{c|c|c|c}\n& left& right& \n& comparator& comparator& \nS_1S_0& input& input& R(C) produced  \n00& 0x00& 0x1F& control character?\n01& 0x41& 0x5A& upper-case letter?\n10& 0x61& 0x7A& lower-case letter?\n11& 0x30& 0x39& numeric digit? \n\n\n\nthe muxes produce the values \nneeded to check whether C is a lower-case letter.\n\nFinally, when the select input S=11, the left mux selects the value 0x30,\nand the right mux selects the value 0x39, which checks whether the ASCII\ncharacter represented by C is a digit (0 to 9).\n\n\n\n\n"
        },
        "questions": "\n1. What is the difference between a 2-to-1 and a 4-to-1 mux?\n2. How can a 4-to-1 mux be built from three 2-to-1 muxes?\n3. What is the function of a multiplexer?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "The Multiplexer",
            "text": "{The Multiplexer}\n\nUsing the more abstract designs for checking ranges of ASCII characters,\nwe can go a step further and create a checker for both upper- and lower-case\nletters.  To do so, we add another input S that allows us to select the \nfunction that we want---either the upper-case checker U(C) or the \nlower-case checker L(C).\n\nFor this purpose, we make use of a logic block called a { multiplexer},\nor { mux}.\nMultiplexers are an important abstraction for digital logic.  In \ngeneral, a multiplexer allows us to use one digital signal to \nselect which of several others is forwarded to an output.\n\n\nThe simplest form of the multiplexer is the 2-to-1 multiplexer shown to \nthe right.   The logic diagram illustrates how the mux works.  The block \nhas two inputs from the left and one from the top.  The top input allows \nus to choose which of the left inputs is forwarded to the output.  \nWhen the input S=0, the upper AND gate outputs 0, and the lower AND gate\noutputs the value of D_0.  The OR gate then produces Q=0+D_0=D_0.\nSimilarly, when input S=1, the upper AND gate outputs D_1, and the\nlower AND gate outputs 0.  In this case, the OR gate produces Q=D_1+0=D_1.\n\n\n\n\n\nThe symbolic form of the mux is a trapezoid with data inputs on the \nlarger side, an output on the smaller side, and a select input on the\nangled part of the trapezoid.  The labels inside the trapezoid indicate \nthe value of the select input S for which the adjacent data signal, \nD_1 or D_0, is copied to the output Q.\n\nWe can generalize multiplexers in two ways.  First, we can extend the \nsingle select input to a group of select inputs.  An {N-bit}\nselect input allows selection from amongst 2^N inputs.  A {4-to-1} \nmultiplexer is shown below, for example.  The logic diagram on the left\nshows how the {4-to-1 mux} operates.  For any combination of S_1S_0,\nthree of the AND gates produce 0, and the fourth outputs the D input\ncorresponding to the interpretation of S as an unsigned number.\nGiven three zeroes and one D input, the OR gate thus reproduces one of \nthe D's.  When S_1S_0=10, for example, the third AND gate copies D_2,\nand Q=D_2.\n\n{{file=part2/figs/mux4-to-1.eps,width=5.60in}}\n\nAs shown in the middle figure, a {4-to-1} mux can also be built from\nthree {2-to-1} muxes.  Finally, the symbolic form of a {4-to-1} mux \nappears on the right in the figure.\n\n\n\nThe second way in which we can generalize multiplexers is by using\nseveral multiplexers of the same type and using the same signals for \nselection.  For example, we might use a single select bit T to choose \nbetween any number of paired inputs.  Denote input pair by i D_1^i \nand D_0^i.  For each pair, we have an output Q_i.  \n\nWhen T=0, Q_i=D_0^i for each value of i.\n\nAnd, when T=1, Q_i=D_1^i for each value of i.\n\nEach value of i requires a {2-to-1} mux with its select input\ndriven by the global select signal T.\n\nReturning to the example of the upper- and lower-case checker, we\ncan make use of two groups of seven {2-to-1} muxes, all controlled by\na single bit select signal S, to choose between the inputs needed\nfor an upper-case checker and those needed for a lower-case checker.\n\nSpecific configurations of multiplexers are often referred to\nas { N-to-M multiplexers}.  Here the value N refers to the\nnumber of inputs, and M refers to the number of outputs.  The\nnumber of select bits can then be calculated as _2(N/M)---N/M \nis generally a power of two---and one way to build such a \nmultiplexer is to use M copies of\nan  (N/M)-to-1 multiplexer.\n\nLet's extend our upper- and lower-case checker to check\nfor four different ranges of ASCII characters, as shown below.\nThis design uses two {28-to-7} muxes to create a single\nchecker for the four ranges.  Each of the muxes in the figure logically \nrepresents seven {4-to-1} muxes.\n\n{{file=part2/figs/ascii-four-range.eps,width=3.75in}}\n\n\nThe table to the right describes the behavior of the checker.\n\nWhen the select input S is set to 00, the left mux selects the value 0x00,\nand the right mux selects the value 0x1F, which checks whether the ASCII\ncharacter represented by C is a control character.\n\nWhen the select input S=01, the muxes produce the values needed to check\nwhether C is an upper-case letter.\n\nSimilarly, when the select input S=10,\n\n\n{c|c|c|c}\n& left& right& \n& comparator& comparator& \nS_1S_0& input& input& R(C) produced  \n00& 0x00& 0x1F& control character?\n01& 0x41& 0x5A& upper-case letter?\n10& 0x61& 0x7A& lower-case letter?\n11& 0x30& 0x39& numeric digit? \n\n\n\nthe muxes produce the values \nneeded to check whether C is a lower-case letter.\n\nFinally, when the select input S=11, the left mux selects the value 0x30,\nand the right mux selects the value 0x39, which checks whether the ASCII\ncharacter represented by C is a digit (0 to 9).\n\n\n\n\n"
        },
        "questions": "\n1. What is the difference between a 2-to-1 and a 4-to-1 mux?\n2. How can a 4-to-1 mux be built from three 2-to-1 muxes?\n3. What is the function of a multiplexer?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "The Multiplexer",
            "text": "{The Multiplexer}\n\nUsing the more abstract designs for checking ranges of ASCII characters,\nwe can go a step further and create a checker for both upper- and lower-case\nletters.  To do so, we add another input S that allows us to select the \nfunction that we want---either the upper-case checker U(C) or the \nlower-case checker L(C).\n\nFor this purpose, we make use of a logic block called a { multiplexer},\nor { mux}.\nMultiplexers are an important abstraction for digital logic.  In \ngeneral, a multiplexer allows us to use one digital signal to \nselect which of several others is forwarded to an output.\n\n\nThe simplest form of the multiplexer is the 2-to-1 multiplexer shown to \nthe right.   The logic diagram illustrates how the mux works.  The block \nhas two inputs from the left and one from the top.  The top input allows \nus to choose which of the left inputs is forwarded to the output.  \nWhen the input S=0, the upper AND gate outputs 0, and the lower AND gate\noutputs the value of D_0.  The OR gate then produces Q=0+D_0=D_0.\nSimilarly, when input S=1, the upper AND gate outputs D_1, and the\nlower AND gate outputs 0.  In this case, the OR gate produces Q=D_1+0=D_1.\n\n\n\n\n\nThe symbolic form of the mux is a trapezoid with data inputs on the \nlarger side, an output on the smaller side, and a select input on the\nangled part of the trapezoid.  The labels inside the trapezoid indicate \nthe value of the select input S for which the adjacent data signal, \nD_1 or D_0, is copied to the output Q.\n\nWe can generalize multiplexers in two ways.  First, we can extend the \nsingle select input to a group of select inputs.  An {N-bit}\nselect input allows selection from amongst 2^N inputs.  A {4-to-1} \nmultiplexer is shown below, for example.  The logic diagram on the left\nshows how the {4-to-1 mux} operates.  For any combination of S_1S_0,\nthree of the AND gates produce 0, and the fourth outputs the D input\ncorresponding to the interpretation of S as an unsigned number.\nGiven three zeroes and one D input, the OR gate thus reproduces one of \nthe D's.  When S_1S_0=10, for example, the third AND gate copies D_2,\nand Q=D_2.\n\n{{file=part2/figs/mux4-to-1.eps,width=5.60in}}\n\nAs shown in the middle figure, a {4-to-1} mux can also be built from\nthree {2-to-1} muxes.  Finally, the symbolic form of a {4-to-1} mux \nappears on the right in the figure.\n\n\n\nThe second way in which we can generalize multiplexers is by using\nseveral multiplexers of the same type and using the same signals for \nselection.  For example, we might use a single select bit T to choose \nbetween any number of paired inputs.  Denote input pair by i D_1^i \nand D_0^i.  For each pair, we have an output Q_i.  \n\nWhen T=0, Q_i=D_0^i for each value of i.\n\nAnd, when T=1, Q_i=D_1^i for each value of i.\n\nEach value of i requires a {2-to-1} mux with its select input\ndriven by the global select signal T.\n\nReturning to the example of the upper- and lower-case checker, we\ncan make use of two groups of seven {2-to-1} muxes, all controlled by\na single bit select signal S, to choose between the inputs needed\nfor an upper-case checker and those needed for a lower-case checker.\n\nSpecific configurations of multiplexers are often referred to\nas { N-to-M multiplexers}.  Here the value N refers to the\nnumber of inputs, and M refers to the number of outputs.  The\nnumber of select bits can then be calculated as _2(N/M)---N/M \nis generally a power of two---and one way to build such a \nmultiplexer is to use M copies of\nan  (N/M)-to-1 multiplexer.\n\nLet's extend our upper- and lower-case checker to check\nfor four different ranges of ASCII characters, as shown below.\nThis design uses two {28-to-7} muxes to create a single\nchecker for the four ranges.  Each of the muxes in the figure logically \nrepresents seven {4-to-1} muxes.\n\n{{file=part2/figs/ascii-four-range.eps,width=3.75in}}\n\n\nThe table to the right describes the behavior of the checker.\n\nWhen the select input S is set to 00, the left mux selects the value 0x00,\nand the right mux selects the value 0x1F, which checks whether the ASCII\ncharacter represented by C is a control character.\n\nWhen the select input S=01, the muxes produce the values needed to check\nwhether C is an upper-case letter.\n\nSimilarly, when the select input S=10,\n\n\n{c|c|c|c}\n& left& right& \n& comparator& comparator& \nS_1S_0& input& input& R(C) produced  \n00& 0x00& 0x1F& control character?\n01& 0x41& 0x5A& upper-case letter?\n10& 0x61& 0x7A& lower-case letter?\n11& 0x30& 0x39& numeric digit? \n\n\n\nthe muxes produce the values \nneeded to check whether C is a lower-case letter.\n\nFinally, when the select input S=11, the left mux selects the value 0x30,\nand the right mux selects the value 0x39, which checks whether the ASCII\ncharacter represented by C is a digit (0 to 9).\n\n\n\n\n"
        },
        "questions": "\n1. What is the difference between a 2-to-1 and a 4-to-1 mux?\n2. How can a 4-to-1 mux be built from three 2-to-1 muxes?\n3. What is the function of a multiplexer?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "The Multiplexer",
            "text": "{The Multiplexer}\n\nUsing the more abstract designs for checking ranges of ASCII characters,\nwe can go a step further and create a checker for both upper- and lower-case\nletters.  To do so, we add another input S that allows us to select the \nfunction that we want---either the upper-case checker U(C) or the \nlower-case checker L(C).\n\nFor this purpose, we make use of a logic block called a { multiplexer},\nor { mux}.\nMultiplexers are an important abstraction for digital logic.  In \ngeneral, a multiplexer allows us to use one digital signal to \nselect which of several others is forwarded to an output.\n\n\nThe simplest form of the multiplexer is the 2-to-1 multiplexer shown to \nthe right.   The logic diagram illustrates how the mux works.  The block \nhas two inputs from the left and one from the top.  The top input allows \nus to choose which of the left inputs is forwarded to the output.  \nWhen the input S=0, the upper AND gate outputs 0, and the lower AND gate\noutputs the value of D_0.  The OR gate then produces Q=0+D_0=D_0.\nSimilarly, when input S=1, the upper AND gate outputs D_1, and the\nlower AND gate outputs 0.  In this case, the OR gate produces Q=D_1+0=D_1.\n\n\n\n\n\nThe symbolic form of the mux is a trapezoid with data inputs on the \nlarger side, an output on the smaller side, and a select input on the\nangled part of the trapezoid.  The labels inside the trapezoid indicate \nthe value of the select input S for which the adjacent data signal, \nD_1 or D_0, is copied to the output Q.\n\nWe can generalize multiplexers in two ways.  First, we can extend the \nsingle select input to a group of select inputs.  An {N-bit}\nselect input allows selection from amongst 2^N inputs.  A {4-to-1} \nmultiplexer is shown below, for example.  The logic diagram on the left\nshows how the {4-to-1 mux} operates.  For any combination of S_1S_0,\nthree of the AND gates produce 0, and the fourth outputs the D input\ncorresponding to the interpretation of S as an unsigned number.\nGiven three zeroes and one D input, the OR gate thus reproduces one of \nthe D's.  When S_1S_0=10, for example, the third AND gate copies D_2,\nand Q=D_2.\n\n{{file=part2/figs/mux4-to-1.eps,width=5.60in}}\n\nAs shown in the middle figure, a {4-to-1} mux can also be built from\nthree {2-to-1} muxes.  Finally, the symbolic form of a {4-to-1} mux \nappears on the right in the figure.\n\n\n\nThe second way in which we can generalize multiplexers is by using\nseveral multiplexers of the same type and using the same signals for \nselection.  For example, we might use a single select bit T to choose \nbetween any number of paired inputs.  Denote input pair by i D_1^i \nand D_0^i.  For each pair, we have an output Q_i.  \n\nWhen T=0, Q_i=D_0^i for each value of i.\n\nAnd, when T=1, Q_i=D_1^i for each value of i.\n\nEach value of i requires a {2-to-1} mux with its select input\ndriven by the global select signal T.\n\nReturning to the example of the upper- and lower-case checker, we\ncan make use of two groups of seven {2-to-1} muxes, all controlled by\na single bit select signal S, to choose between the inputs needed\nfor an upper-case checker and those needed for a lower-case checker.\n\nSpecific configurations of multiplexers are often referred to\nas { N-to-M multiplexers}.  Here the value N refers to the\nnumber of inputs, and M refers to the number of outputs.  The\nnumber of select bits can then be calculated as _2(N/M)---N/M \nis generally a power of two---and one way to build such a \nmultiplexer is to use M copies of\nan  (N/M)-to-1 multiplexer.\n\nLet's extend our upper- and lower-case checker to check\nfor four different ranges of ASCII characters, as shown below.\nThis design uses two {28-to-7} muxes to create a single\nchecker for the four ranges.  Each of the muxes in the figure logically \nrepresents seven {4-to-1} muxes.\n\n{{file=part2/figs/ascii-four-range.eps,width=3.75in}}\n\n\nThe table to the right describes the behavior of the checker.\n\nWhen the select input S is set to 00, the left mux selects the value 0x00,\nand the right mux selects the value 0x1F, which checks whether the ASCII\ncharacter represented by C is a control character.\n\nWhen the select input S=01, the muxes produce the values needed to check\nwhether C is an upper-case letter.\n\nSimilarly, when the select input S=10,\n\n\n{c|c|c|c}\n& left& right& \n& comparator& comparator& \nS_1S_0& input& input& R(C) produced  \n00& 0x00& 0x1F& control character?\n01& 0x41& 0x5A& upper-case letter?\n10& 0x61& 0x7A& lower-case letter?\n11& 0x30& 0x39& numeric digit? \n\n\n\nthe muxes produce the values \nneeded to check whether C is a lower-case letter.\n\nFinally, when the select input S=11, the left mux selects the value 0x30,\nand the right mux selects the value 0x39, which checks whether the ASCII\ncharacter represented by C is a digit (0 to 9).\n\n\n\n\n"
        },
        "questions": "\n1. What is the difference between a 2-to-1 and a 4-to-1 mux?\n2. How can a 4-to-1 mux be built from three 2-to-1 muxes?\n3. What is the function of a multiplexer?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "The Multiplexer",
            "text": "{The Multiplexer}\n\nUsing the more abstract designs for checking ranges of ASCII characters,\nwe can go a step further and create a checker for both upper- and lower-case\nletters.  To do so, we add another input S that allows us to select the \nfunction that we want---either the upper-case checker U(C) or the \nlower-case checker L(C).\n\nFor this purpose, we make use of a logic block called a { multiplexer},\nor { mux}.\nMultiplexers are an important abstraction for digital logic.  In \ngeneral, a multiplexer allows us to use one digital signal to \nselect which of several others is forwarded to an output.\n\n\nThe simplest form of the multiplexer is the 2-to-1 multiplexer shown to \nthe right.   The logic diagram illustrates how the mux works.  The block \nhas two inputs from the left and one from the top.  The top input allows \nus to choose which of the left inputs is forwarded to the output.  \nWhen the input S=0, the upper AND gate outputs 0, and the lower AND gate\noutputs the value of D_0.  The OR gate then produces Q=0+D_0=D_0.\nSimilarly, when input S=1, the upper AND gate outputs D_1, and the\nlower AND gate outputs 0.  In this case, the OR gate produces Q=D_1+0=D_1.\n\n\n\n\n\nThe symbolic form of the mux is a trapezoid with data inputs on the \nlarger side, an output on the smaller side, and a select input on the\nangled part of the trapezoid.  The labels inside the trapezoid indicate \nthe value of the select input S for which the adjacent data signal, \nD_1 or D_0, is copied to the output Q.\n\nWe can generalize multiplexers in two ways.  First, we can extend the \nsingle select input to a group of select inputs.  An {N-bit}\nselect input allows selection from amongst 2^N inputs.  A {4-to-1} \nmultiplexer is shown below, for example.  The logic diagram on the left\nshows how the {4-to-1 mux} operates.  For any combination of S_1S_0,\nthree of the AND gates produce 0, and the fourth outputs the D input\ncorresponding to the interpretation of S as an unsigned number.\nGiven three zeroes and one D input, the OR gate thus reproduces one of \nthe D's.  When S_1S_0=10, for example, the third AND gate copies D_2,\nand Q=D_2.\n\n{{file=part2/figs/mux4-to-1.eps,width=5.60in}}\n\nAs shown in the middle figure, a {4-to-1} mux can also be built from\nthree {2-to-1} muxes.  Finally, the symbolic form of a {4-to-1} mux \nappears on the right in the figure.\n\n\n\nThe second way in which we can generalize multiplexers is by using\nseveral multiplexers of the same type and using the same signals for \nselection.  For example, we might use a single select bit T to choose \nbetween any number of paired inputs.  Denote input pair by i D_1^i \nand D_0^i.  For each pair, we have an output Q_i.  \n\nWhen T=0, Q_i=D_0^i for each value of i.\n\nAnd, when T=1, Q_i=D_1^i for each value of i.\n\nEach value of i requires a {2-to-1} mux with its select input\ndriven by the global select signal T.\n\nReturning to the example of the upper- and lower-case checker, we\ncan make use of two groups of seven {2-to-1} muxes, all controlled by\na single bit select signal S, to choose between the inputs needed\nfor an upper-case checker and those needed for a lower-case checker.\n\nSpecific configurations of multiplexers are often referred to\nas { N-to-M multiplexers}.  Here the value N refers to the\nnumber of inputs, and M refers to the number of outputs.  The\nnumber of select bits can then be calculated as _2(N/M)---N/M \nis generally a power of two---and one way to build such a \nmultiplexer is to use M copies of\nan  (N/M)-to-1 multiplexer.\n\nLet's extend our upper- and lower-case checker to check\nfor four different ranges of ASCII characters, as shown below.\nThis design uses two {28-to-7} muxes to create a single\nchecker for the four ranges.  Each of the muxes in the figure logically \nrepresents seven {4-to-1} muxes.\n\n{{file=part2/figs/ascii-four-range.eps,width=3.75in}}\n\n\nThe table to the right describes the behavior of the checker.\n\nWhen the select input S is set to 00, the left mux selects the value 0x00,\nand the right mux selects the value 0x1F, which checks whether the ASCII\ncharacter represented by C is a control character.\n\nWhen the select input S=01, the muxes produce the values needed to check\nwhether C is an upper-case letter.\n\nSimilarly, when the select input S=10,\n\n\n{c|c|c|c}\n& left& right& \n& comparator& comparator& \nS_1S_0& input& input& R(C) produced  \n00& 0x00& 0x1F& control character?\n01& 0x41& 0x5A& upper-case letter?\n10& 0x61& 0x7A& lower-case letter?\n11& 0x30& 0x39& numeric digit? \n\n\n\nthe muxes produce the values \nneeded to check whether C is a lower-case letter.\n\nFinally, when the select input S=11, the left mux selects the value 0x30,\nand the right mux selects the value 0x39, which checks whether the ASCII\ncharacter represented by C is a digit (0 to 9).\n\n\n\n\n"
        },
        "questions": "\n1. What is the difference between a 2-to-1 and a 4-to-1 mux?\n2. How can a 4-to-1 mux be built from three 2-to-1 muxes?\n3. What is the function of a multiplexer?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Further Optimization",
            "text": "{Further Optimization}\n\n\nLet's return to the topic of optimization.  To what extent \ndid the representation of the three outcomes affect our ability\nto develop a good bit slice design?  Although selecting a good \nrepresentation can be quite important, for this particular problem\nmost representations lead to similar implementations.\n\nSome representations, however, have interesting properties.  Consider\n\n\n{cc|l|l}\nC_1& C_0& original& alternate \n0& 0& A=B& A=B\n0& 1& A<B& A>B\n1& 0& A>B& not used\n1& 1& not used& A<B\n\n\n\nthe alternate representation on the right, for example (a copy of the \noriginal representation is included for comparison).  Notice that \nin the alternate representation, C_0=1 whenever A=B.  \n\nOnce we have found the numbers to be different in some bit, the end\nresult can never be equality, so perhaps with the right \nrepresentation---the new one, for example---we might be able to\ncut delay in half?\n\n\nAn implementation based on the alternate representation appears in the\ndiagram to the right.  As you can see, in terms of gate count,\nthis design replaces one {2-input} gate with an inverter and\na second {2-input} gate with a {3-input} gate.  The path\nlengths are the same, requiring 2N+2 gate delays for \nan {N-bit} comparator.\nOverall, it is about the same as our original design.\n\n\n{file=part2/figs/comparator-opt-alt.eps,width=4.1in}\n\n\nWhy didn't it work?  Should we consider still other representations?\nIn fact, none of the possible representations that we might choose\nfor a bit slice can cut the delay down to one gate delay per bit.  \nThe problem is fundamental, and is related to the nature of CMOS.\nFor a single bit slice, we define the incoming and outgoing \nrepresentations to be the same.  We also need to have at least\none gate in the path to combine the C_1 and C_0 inputs with\ninformation from the bit slice's A and B inputs.  But all CMOS\ngates invert the sense of their inputs.  Our choices are limited\nto NAND and NOR.  Thus we need at least two gates in the path to\nmaintain the same representation.\n\nOne simple answer is to use different representations for odd and\neven bits.  Instead, we optimize a logic circuit\nfor comparing two bits.  We base our design on the alternate \nrepresentation.  The implementation is shown below.  The left\nshows an implementation based on the algebra, and the right shows\na NAND/NOR implementation.  Estimating by gate count and number of\ninputs, the {two-bit} design doesn't save much over two\nsingle bit slices in terms of area.  In terms of delay, however,\nwe have only two gate delays from C_1 and C_0 to either output.\nThe longest path from the A and B inputs to the outputs is\nfive gate delays.  Thus, for an {N-bit} comparator built\nwith this design, the total delay is only N+3 gate delays.\nBut N has to be even.\n\n{file=part2/figs/comparator-two.eps,width=3.125in}\n{file=part2/figs/comparator-two-nn.eps,width=3.125in}\n\nAs you can imagine, continuing to scale up the size of our logic\nblock gives us better performance at the expense of a more complex\ndesign.  Using the alternate representation may help you to see\nhow one can generalize the approach to larger groups of bits---for\nexample, you may have noticed the two bitwise \ncomparator blocks on the left of the implementations above.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the fundamental problem with developing a bit slice design that would only require one gate delay per bit?\n2. How does using different representations for odd and even bits help to solve this problem?\n3. What are the tradeoffs of using larger groups of bits when designing a comparator?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Further Optimization",
            "text": "{Further Optimization}\n\n\nLet's return to the topic of optimization.  To what extent \ndid the representation of the three outcomes affect our ability\nto develop a good bit slice design?  Although selecting a good \nrepresentation can be quite important, for this particular problem\nmost representations lead to similar implementations.\n\nSome representations, however, have interesting properties.  Consider\n\n\n{cc|l|l}\nC_1& C_0& original& alternate \n0& 0& A=B& A=B\n0& 1& A<B& A>B\n1& 0& A>B& not used\n1& 1& not used& A<B\n\n\n\nthe alternate representation on the right, for example (a copy of the \noriginal representation is included for comparison).  Notice that \nin the alternate representation, C_0=1 whenever A=B.  \n\nOnce we have found the numbers to be different in some bit, the end\nresult can never be equality, so perhaps with the right \nrepresentation---the new one, for example---we might be able to\ncut delay in half?\n\n\nAn implementation based on the alternate representation appears in the\ndiagram to the right.  As you can see, in terms of gate count,\nthis design replaces one {2-input} gate with an inverter and\na second {2-input} gate with a {3-input} gate.  The path\nlengths are the same, requiring 2N+2 gate delays for \nan {N-bit} comparator.\nOverall, it is about the same as our original design.\n\n\n{file=part2/figs/comparator-opt-alt.eps,width=4.1in}\n\n\nWhy didn't it work?  Should we consider still other representations?\nIn fact, none of the possible representations that we might choose\nfor a bit slice can cut the delay down to one gate delay per bit.  \nThe problem is fundamental, and is related to the nature of CMOS.\nFor a single bit slice, we define the incoming and outgoing \nrepresentations to be the same.  We also need to have at least\none gate in the path to combine the C_1 and C_0 inputs with\ninformation from the bit slice's A and B inputs.  But all CMOS\ngates invert the sense of their inputs.  Our choices are limited\nto NAND and NOR.  Thus we need at least two gates in the path to\nmaintain the same representation.\n\nOne simple answer is to use different representations for odd and\neven bits.  Instead, we optimize a logic circuit\nfor comparing two bits.  We base our design on the alternate \nrepresentation.  The implementation is shown below.  The left\nshows an implementation based on the algebra, and the right shows\na NAND/NOR implementation.  Estimating by gate count and number of\ninputs, the {two-bit} design doesn't save much over two\nsingle bit slices in terms of area.  In terms of delay, however,\nwe have only two gate delays from C_1 and C_0 to either output.\nThe longest path from the A and B inputs to the outputs is\nfive gate delays.  Thus, for an {N-bit} comparator built\nwith this design, the total delay is only N+3 gate delays.\nBut N has to be even.\n\n{file=part2/figs/comparator-two.eps,width=3.125in}\n{file=part2/figs/comparator-two-nn.eps,width=3.125in}\n\nAs you can imagine, continuing to scale up the size of our logic\nblock gives us better performance at the expense of a more complex\ndesign.  Using the alternate representation may help you to see\nhow one can generalize the approach to larger groups of bits---for\nexample, you may have noticed the two bitwise \ncomparator blocks on the left of the implementations above.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the fundamental problem with developing a bit slice design that would only require one gate delay per bit?\n2. How does using different representations for odd and even bits help to solve this problem?\n3. What are the tradeoffs of using larger groups of bits when designing a comparator?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Further Optimization",
            "text": "{Further Optimization}\n\n\nLet's return to the topic of optimization.  To what extent \ndid the representation of the three outcomes affect our ability\nto develop a good bit slice design?  Although selecting a good \nrepresentation can be quite important, for this particular problem\nmost representations lead to similar implementations.\n\nSome representations, however, have interesting properties.  Consider\n\n\n{cc|l|l}\nC_1& C_0& original& alternate \n0& 0& A=B& A=B\n0& 1& A<B& A>B\n1& 0& A>B& not used\n1& 1& not used& A<B\n\n\n\nthe alternate representation on the right, for example (a copy of the \noriginal representation is included for comparison).  Notice that \nin the alternate representation, C_0=1 whenever A=B.  \n\nOnce we have found the numbers to be different in some bit, the end\nresult can never be equality, so perhaps with the right \nrepresentation---the new one, for example---we might be able to\ncut delay in half?\n\n\nAn implementation based on the alternate representation appears in the\ndiagram to the right.  As you can see, in terms of gate count,\nthis design replaces one {2-input} gate with an inverter and\na second {2-input} gate with a {3-input} gate.  The path\nlengths are the same, requiring 2N+2 gate delays for \nan {N-bit} comparator.\nOverall, it is about the same as our original design.\n\n\n{file=part2/figs/comparator-opt-alt.eps,width=4.1in}\n\n\nWhy didn't it work?  Should we consider still other representations?\nIn fact, none of the possible representations that we might choose\nfor a bit slice can cut the delay down to one gate delay per bit.  \nThe problem is fundamental, and is related to the nature of CMOS.\nFor a single bit slice, we define the incoming and outgoing \nrepresentations to be the same.  We also need to have at least\none gate in the path to combine the C_1 and C_0 inputs with\ninformation from the bit slice's A and B inputs.  But all CMOS\ngates invert the sense of their inputs.  Our choices are limited\nto NAND and NOR.  Thus we need at least two gates in the path to\nmaintain the same representation.\n\nOne simple answer is to use different representations for odd and\neven bits.  Instead, we optimize a logic circuit\nfor comparing two bits.  We base our design on the alternate \nrepresentation.  The implementation is shown below.  The left\nshows an implementation based on the algebra, and the right shows\na NAND/NOR implementation.  Estimating by gate count and number of\ninputs, the {two-bit} design doesn't save much over two\nsingle bit slices in terms of area.  In terms of delay, however,\nwe have only two gate delays from C_1 and C_0 to either output.\nThe longest path from the A and B inputs to the outputs is\nfive gate delays.  Thus, for an {N-bit} comparator built\nwith this design, the total delay is only N+3 gate delays.\nBut N has to be even.\n\n{file=part2/figs/comparator-two.eps,width=3.125in}\n{file=part2/figs/comparator-two-nn.eps,width=3.125in}\n\nAs you can imagine, continuing to scale up the size of our logic\nblock gives us better performance at the expense of a more complex\ndesign.  Using the alternate representation may help you to see\nhow one can generalize the approach to larger groups of bits---for\nexample, you may have noticed the two bitwise \ncomparator blocks on the left of the implementations above.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the fundamental problem with developing a bit slice design that would only require one gate delay per bit?\n2. How does using different representations for odd and even bits help to solve this problem?\n3. What are the tradeoffs of using larger groups of bits when designing a comparator?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Further Optimization",
            "text": "{Further Optimization}\n\n\nLet's return to the topic of optimization.  To what extent \ndid the representation of the three outcomes affect our ability\nto develop a good bit slice design?  Although selecting a good \nrepresentation can be quite important, for this particular problem\nmost representations lead to similar implementations.\n\nSome representations, however, have interesting properties.  Consider\n\n\n{cc|l|l}\nC_1& C_0& original& alternate \n0& 0& A=B& A=B\n0& 1& A<B& A>B\n1& 0& A>B& not used\n1& 1& not used& A<B\n\n\n\nthe alternate representation on the right, for example (a copy of the \noriginal representation is included for comparison).  Notice that \nin the alternate representation, C_0=1 whenever A=B.  \n\nOnce we have found the numbers to be different in some bit, the end\nresult can never be equality, so perhaps with the right \nrepresentation---the new one, for example---we might be able to\ncut delay in half?\n\n\nAn implementation based on the alternate representation appears in the\ndiagram to the right.  As you can see, in terms of gate count,\nthis design replaces one {2-input} gate with an inverter and\na second {2-input} gate with a {3-input} gate.  The path\nlengths are the same, requiring 2N+2 gate delays for \nan {N-bit} comparator.\nOverall, it is about the same as our original design.\n\n\n{file=part2/figs/comparator-opt-alt.eps,width=4.1in}\n\n\nWhy didn't it work?  Should we consider still other representations?\nIn fact, none of the possible representations that we might choose\nfor a bit slice can cut the delay down to one gate delay per bit.  \nThe problem is fundamental, and is related to the nature of CMOS.\nFor a single bit slice, we define the incoming and outgoing \nrepresentations to be the same.  We also need to have at least\none gate in the path to combine the C_1 and C_0 inputs with\ninformation from the bit slice's A and B inputs.  But all CMOS\ngates invert the sense of their inputs.  Our choices are limited\nto NAND and NOR.  Thus we need at least two gates in the path to\nmaintain the same representation.\n\nOne simple answer is to use different representations for odd and\neven bits.  Instead, we optimize a logic circuit\nfor comparing two bits.  We base our design on the alternate \nrepresentation.  The implementation is shown below.  The left\nshows an implementation based on the algebra, and the right shows\na NAND/NOR implementation.  Estimating by gate count and number of\ninputs, the {two-bit} design doesn't save much over two\nsingle bit slices in terms of area.  In terms of delay, however,\nwe have only two gate delays from C_1 and C_0 to either output.\nThe longest path from the A and B inputs to the outputs is\nfive gate delays.  Thus, for an {N-bit} comparator built\nwith this design, the total delay is only N+3 gate delays.\nBut N has to be even.\n\n{file=part2/figs/comparator-two.eps,width=3.125in}\n{file=part2/figs/comparator-two-nn.eps,width=3.125in}\n\nAs you can imagine, continuing to scale up the size of our logic\nblock gives us better performance at the expense of a more complex\ndesign.  Using the alternate representation may help you to see\nhow one can generalize the approach to larger groups of bits---for\nexample, you may have noticed the two bitwise \ncomparator blocks on the left of the implementations above.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the fundamental problem with developing a bit slice design that would only require one gate delay per bit?\n2. How does using different representations for odd and even bits help to solve this problem?\n3. What are the tradeoffs of using larger groups of bits when designing a comparator?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Further Optimization",
            "text": "{Further Optimization}\n\n\nLet's return to the topic of optimization.  To what extent \ndid the representation of the three outcomes affect our ability\nto develop a good bit slice design?  Although selecting a good \nrepresentation can be quite important, for this particular problem\nmost representations lead to similar implementations.\n\nSome representations, however, have interesting properties.  Consider\n\n\n{cc|l|l}\nC_1& C_0& original& alternate \n0& 0& A=B& A=B\n0& 1& A<B& A>B\n1& 0& A>B& not used\n1& 1& not used& A<B\n\n\n\nthe alternate representation on the right, for example (a copy of the \noriginal representation is included for comparison).  Notice that \nin the alternate representation, C_0=1 whenever A=B.  \n\nOnce we have found the numbers to be different in some bit, the end\nresult can never be equality, so perhaps with the right \nrepresentation---the new one, for example---we might be able to\ncut delay in half?\n\n\nAn implementation based on the alternate representation appears in the\ndiagram to the right.  As you can see, in terms of gate count,\nthis design replaces one {2-input} gate with an inverter and\na second {2-input} gate with a {3-input} gate.  The path\nlengths are the same, requiring 2N+2 gate delays for \nan {N-bit} comparator.\nOverall, it is about the same as our original design.\n\n\n{file=part2/figs/comparator-opt-alt.eps,width=4.1in}\n\n\nWhy didn't it work?  Should we consider still other representations?\nIn fact, none of the possible representations that we might choose\nfor a bit slice can cut the delay down to one gate delay per bit.  \nThe problem is fundamental, and is related to the nature of CMOS.\nFor a single bit slice, we define the incoming and outgoing \nrepresentations to be the same.  We also need to have at least\none gate in the path to combine the C_1 and C_0 inputs with\ninformation from the bit slice's A and B inputs.  But all CMOS\ngates invert the sense of their inputs.  Our choices are limited\nto NAND and NOR.  Thus we need at least two gates in the path to\nmaintain the same representation.\n\nOne simple answer is to use different representations for odd and\neven bits.  Instead, we optimize a logic circuit\nfor comparing two bits.  We base our design on the alternate \nrepresentation.  The implementation is shown below.  The left\nshows an implementation based on the algebra, and the right shows\na NAND/NOR implementation.  Estimating by gate count and number of\ninputs, the {two-bit} design doesn't save much over two\nsingle bit slices in terms of area.  In terms of delay, however,\nwe have only two gate delays from C_1 and C_0 to either output.\nThe longest path from the A and B inputs to the outputs is\nfive gate delays.  Thus, for an {N-bit} comparator built\nwith this design, the total delay is only N+3 gate delays.\nBut N has to be even.\n\n{file=part2/figs/comparator-two.eps,width=3.125in}\n{file=part2/figs/comparator-two-nn.eps,width=3.125in}\n\nAs you can imagine, continuing to scale up the size of our logic\nblock gives us better performance at the expense of a more complex\ndesign.  Using the alternate representation may help you to see\nhow one can generalize the approach to larger groups of bits---for\nexample, you may have noticed the two bitwise \ncomparator blocks on the left of the implementations above.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the fundamental problem with developing a bit slice design that would only require one gate delay per bit?\n2. How does using different representations for odd and even bits help to solve this problem?\n3. What are the tradeoffs of using larger groups of bits when designing a comparator?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Further Optimization",
            "text": "{Further Optimization}\n\n\nLet's return to the topic of optimization.  To what extent \ndid the representation of the three outcomes affect our ability\nto develop a good bit slice design?  Although selecting a good \nrepresentation can be quite important, for this particular problem\nmost representations lead to similar implementations.\n\nSome representations, however, have interesting properties.  Consider\n\n\n{cc|l|l}\nC_1& C_0& original& alternate \n0& 0& A=B& A=B\n0& 1& A<B& A>B\n1& 0& A>B& not used\n1& 1& not used& A<B\n\n\n\nthe alternate representation on the right, for example (a copy of the \noriginal representation is included for comparison).  Notice that \nin the alternate representation, C_0=1 whenever A=B.  \n\nOnce we have found the numbers to be different in some bit, the end\nresult can never be equality, so perhaps with the right \nrepresentation---the new one, for example---we might be able to\ncut delay in half?\n\n\nAn implementation based on the alternate representation appears in the\ndiagram to the right.  As you can see, in terms of gate count,\nthis design replaces one {2-input} gate with an inverter and\na second {2-input} gate with a {3-input} gate.  The path\nlengths are the same, requiring 2N+2 gate delays for \nan {N-bit} comparator.\nOverall, it is about the same as our original design.\n\n\n{file=part2/figs/comparator-opt-alt.eps,width=4.1in}\n\n\nWhy didn't it work?  Should we consider still other representations?\nIn fact, none of the possible representations that we might choose\nfor a bit slice can cut the delay down to one gate delay per bit.  \nThe problem is fundamental, and is related to the nature of CMOS.\nFor a single bit slice, we define the incoming and outgoing \nrepresentations to be the same.  We also need to have at least\none gate in the path to combine the C_1 and C_0 inputs with\ninformation from the bit slice's A and B inputs.  But all CMOS\ngates invert the sense of their inputs.  Our choices are limited\nto NAND and NOR.  Thus we need at least two gates in the path to\nmaintain the same representation.\n\nOne simple answer is to use different representations for odd and\neven bits.  Instead, we optimize a logic circuit\nfor comparing two bits.  We base our design on the alternate \nrepresentation.  The implementation is shown below.  The left\nshows an implementation based on the algebra, and the right shows\na NAND/NOR implementation.  Estimating by gate count and number of\ninputs, the {two-bit} design doesn't save much over two\nsingle bit slices in terms of area.  In terms of delay, however,\nwe have only two gate delays from C_1 and C_0 to either output.\nThe longest path from the A and B inputs to the outputs is\nfive gate delays.  Thus, for an {N-bit} comparator built\nwith this design, the total delay is only N+3 gate delays.\nBut N has to be even.\n\n{file=part2/figs/comparator-two.eps,width=3.125in}\n{file=part2/figs/comparator-two-nn.eps,width=3.125in}\n\nAs you can imagine, continuing to scale up the size of our logic\nblock gives us better performance at the expense of a more complex\ndesign.  Using the alternate representation may help you to see\nhow one can generalize the approach to larger groups of bits---for\nexample, you may have noticed the two bitwise \ncomparator blocks on the left of the implementations above.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the fundamental problem with developing a bit slice design that would only require one gate delay per bit?\n2. How does using different representations for odd and even bits help to solve this problem?\n3. What are the tradeoffs of using larger groups of bits when designing a comparator?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Further Optimization",
            "text": "{Further Optimization}\n\n\nLet's return to the topic of optimization.  To what extent \ndid the representation of the three outcomes affect our ability\nto develop a good bit slice design?  Although selecting a good \nrepresentation can be quite important, for this particular problem\nmost representations lead to similar implementations.\n\nSome representations, however, have interesting properties.  Consider\n\n\n{cc|l|l}\nC_1& C_0& original& alternate \n0& 0& A=B& A=B\n0& 1& A<B& A>B\n1& 0& A>B& not used\n1& 1& not used& A<B\n\n\n\nthe alternate representation on the right, for example (a copy of the \noriginal representation is included for comparison).  Notice that \nin the alternate representation, C_0=1 whenever A=B.  \n\nOnce we have found the numbers to be different in some bit, the end\nresult can never be equality, so perhaps with the right \nrepresentation---the new one, for example---we might be able to\ncut delay in half?\n\n\nAn implementation based on the alternate representation appears in the\ndiagram to the right.  As you can see, in terms of gate count,\nthis design replaces one {2-input} gate with an inverter and\na second {2-input} gate with a {3-input} gate.  The path\nlengths are the same, requiring 2N+2 gate delays for \nan {N-bit} comparator.\nOverall, it is about the same as our original design.\n\n\n{file=part2/figs/comparator-opt-alt.eps,width=4.1in}\n\n\nWhy didn't it work?  Should we consider still other representations?\nIn fact, none of the possible representations that we might choose\nfor a bit slice can cut the delay down to one gate delay per bit.  \nThe problem is fundamental, and is related to the nature of CMOS.\nFor a single bit slice, we define the incoming and outgoing \nrepresentations to be the same.  We also need to have at least\none gate in the path to combine the C_1 and C_0 inputs with\ninformation from the bit slice's A and B inputs.  But all CMOS\ngates invert the sense of their inputs.  Our choices are limited\nto NAND and NOR.  Thus we need at least two gates in the path to\nmaintain the same representation.\n\nOne simple answer is to use different representations for odd and\neven bits.  Instead, we optimize a logic circuit\nfor comparing two bits.  We base our design on the alternate \nrepresentation.  The implementation is shown below.  The left\nshows an implementation based on the algebra, and the right shows\na NAND/NOR implementation.  Estimating by gate count and number of\ninputs, the {two-bit} design doesn't save much over two\nsingle bit slices in terms of area.  In terms of delay, however,\nwe have only two gate delays from C_1 and C_0 to either output.\nThe longest path from the A and B inputs to the outputs is\nfive gate delays.  Thus, for an {N-bit} comparator built\nwith this design, the total delay is only N+3 gate delays.\nBut N has to be even.\n\n{file=part2/figs/comparator-two.eps,width=3.125in}\n{file=part2/figs/comparator-two-nn.eps,width=3.125in}\n\nAs you can imagine, continuing to scale up the size of our logic\nblock gives us better performance at the expense of a more complex\ndesign.  Using the alternate representation may help you to see\nhow one can generalize the approach to larger groups of bits---for\nexample, you may have noticed the two bitwise \ncomparator blocks on the left of the implementations above.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the fundamental problem with developing a bit slice design that would only require one gate delay per bit?\n2. How does using different representations for odd and even bits help to solve this problem?\n3. What are the tradeoffs of using larger groups of bits when designing a comparator?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Examples and a Generalization",
            "text": "{Examples and a Generalization}\n\nLet's use our construction to solve a few examples.  We begin with\nthe functions that we illustrated with the first truth table from this\nset of notes,\nthe carry out C and sum S of two {2-bit}\nunsigned numbers.  Since each output bit requires a separate expression,\nwe now write S_1S_0 for the two bits of the sum.  We also need to\nbe able to make use of the individual bits of the input values, so we \nwrite these as A_1A_0 and B_1B_0, as shown on the left below.\nUsing our \nconstruction from the logical completeness theorem, we obtain the\nequations on the right.\nYou should verify these expressions yourself.\n\n{\n\n{cccc|ccc}\n{c|}& \nA_1& A_0& B_1& B_0& C& S_1& S_0 \n0&0& 0&0& 0& 0&0\n0&0& 0&1& 0& 0&1\n0&0& 1&0& 0& 1&0\n0&0& 1&1& 0& 1&1\n0&1& 0&0& 0& 0&1\n0&1& 0&1& 0& 1&0\n0&1& 1&0& 0& 1&1\n0&1& 1&1& 1& 0&0\n1&0& 0&0& 0& 1&0\n1&0& 0&1& 0& 1&1\n1&0& 1&0& 1& 0&0\n1&0& 1&1& 1& 0&1\n1&1& 0&0& 0& 1&1\n1&1& 0&1& 1& 0&0\n1&1& 1&0& 1& 0&1\n1&1& 1&1& 1& 1&0\n\n\n\n{eqnarray*}\n\nC &=& \n{A_1} A_0 B_1 B_0 +\nA_1 {A_0} B_1 {B_0} +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} B_0 +\nA_1 A_0 B_1 {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_1 &=& \n{A_1} {A_0} B_1 {B_0} +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} B_0 +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} {B_0} +\nA_1 {A_0} {B_1} B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_0 &=& \n{A_1} {A_0} {B_1} B_0 +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} {B_0} +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} B_0 +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 {B_0}\n{eqnarray*}\n\n}\n\n\nNow let's consider a new function.  Given\nan {8-bit} 2's complement number, A=A_7A_6A_5A_4A_3A_2A_1A_0,\nwe want to compare it with the value -1.  We know that\nwe can construct this function using AND, OR, and NOT, but how?\nWe start by writing the representation for -1, which is 11111111.\nIf the number A matches that representation, we want to produce a 1.\nIf the number A differs in any bit, we want to produce a 0.\nThe desired function has exactly one combination of inputs that\nproduces a 1, so in fact we need only one minterm!  In this case, we\ncan compare with -1 by calculating the expression:\n\n{eqnarray*}\nA_7  A_6  A_5  A_4  A_3  A_2  A_1  A_0\n{eqnarray*}\n\nHere we have explicitly included multiplication symbols to avoid\nconfusion with our notation for groups of bits, as we used when \nnaming the individual bits of A.\n\n\nIn closing, we briefly introduce a generalization of logic\noperations to groups of bits.  Our representations for integers,\nreal numbers, and characters from human languages all use more than\none bit to represent a given value.  When we use computers, we often\nmake use of multiple bits in groups in this way.  A { byte}, for example,\ntoday means an ordered group of eight bits.\n\nWe can extend our logic functions to operate on such groups by pairing\nbits from each of two groups and performing the logic operation on each\npair.  For example, given\nA=A_7A_6A_5A_4A_3A_2A_1A_0=01010101\nand\nB=B_7B_6B_5B_4B_3B_2B_1B_0=11110000, we calculate\nA AND B by computing the AND of each pair of bits, \nA_7 AND B_7,\nA_6 AND B_6,\nand so forth, to\nproduce the result 01010000, as shown to the right.\nIn the same way, we can extend other logic\noperations, such as OR, NOT, and XOR, to operate on bits of groups.\n\n\n{ 0pt\n 0pt\n\n&A  & 0&1& 0&1& 0&1& 0&1\n  AND   &B& 1&1&1&1&0&0&0&0 \n&& 0& 1&0&1&0&0&0&0\n\n}\n\n\n\n\n\n\n"
        },
        "questions": "1. What is the significance of the logical completeness theorem?\n2. How can we use the construction from the logical completeness theorem to solve problems?\n3. What is the significance of extending logic operations to groups of bits?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Examples and a Generalization",
            "text": "{Examples and a Generalization}\n\nLet's use our construction to solve a few examples.  We begin with\nthe functions that we illustrated with the first truth table from this\nset of notes,\nthe carry out C and sum S of two {2-bit}\nunsigned numbers.  Since each output bit requires a separate expression,\nwe now write S_1S_0 for the two bits of the sum.  We also need to\nbe able to make use of the individual bits of the input values, so we \nwrite these as A_1A_0 and B_1B_0, as shown on the left below.\nUsing our \nconstruction from the logical completeness theorem, we obtain the\nequations on the right.\nYou should verify these expressions yourself.\n\n{\n\n{cccc|ccc}\n{c|}& \nA_1& A_0& B_1& B_0& C& S_1& S_0 \n0&0& 0&0& 0& 0&0\n0&0& 0&1& 0& 0&1\n0&0& 1&0& 0& 1&0\n0&0& 1&1& 0& 1&1\n0&1& 0&0& 0& 0&1\n0&1& 0&1& 0& 1&0\n0&1& 1&0& 0& 1&1\n0&1& 1&1& 1& 0&0\n1&0& 0&0& 0& 1&0\n1&0& 0&1& 0& 1&1\n1&0& 1&0& 1& 0&0\n1&0& 1&1& 1& 0&1\n1&1& 0&0& 0& 1&1\n1&1& 0&1& 1& 0&0\n1&1& 1&0& 1& 0&1\n1&1& 1&1& 1& 1&0\n\n\n\n{eqnarray*}\n\nC &=& \n{A_1} A_0 B_1 B_0 +\nA_1 {A_0} B_1 {B_0} +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} B_0 +\nA_1 A_0 B_1 {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_1 &=& \n{A_1} {A_0} B_1 {B_0} +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} B_0 +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} {B_0} +\nA_1 {A_0} {B_1} B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_0 &=& \n{A_1} {A_0} {B_1} B_0 +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} {B_0} +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} B_0 +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 {B_0}\n{eqnarray*}\n\n}\n\n\nNow let's consider a new function.  Given\nan {8-bit} 2's complement number, A=A_7A_6A_5A_4A_3A_2A_1A_0,\nwe want to compare it with the value -1.  We know that\nwe can construct this function using AND, OR, and NOT, but how?\nWe start by writing the representation for -1, which is 11111111.\nIf the number A matches that representation, we want to produce a 1.\nIf the number A differs in any bit, we want to produce a 0.\nThe desired function has exactly one combination of inputs that\nproduces a 1, so in fact we need only one minterm!  In this case, we\ncan compare with -1 by calculating the expression:\n\n{eqnarray*}\nA_7  A_6  A_5  A_4  A_3  A_2  A_1  A_0\n{eqnarray*}\n\nHere we have explicitly included multiplication symbols to avoid\nconfusion with our notation for groups of bits, as we used when \nnaming the individual bits of A.\n\n\nIn closing, we briefly introduce a generalization of logic\noperations to groups of bits.  Our representations for integers,\nreal numbers, and characters from human languages all use more than\none bit to represent a given value.  When we use computers, we often\nmake use of multiple bits in groups in this way.  A { byte}, for example,\ntoday means an ordered group of eight bits.\n\nWe can extend our logic functions to operate on such groups by pairing\nbits from each of two groups and performing the logic operation on each\npair.  For example, given\nA=A_7A_6A_5A_4A_3A_2A_1A_0=01010101\nand\nB=B_7B_6B_5B_4B_3B_2B_1B_0=11110000, we calculate\nA AND B by computing the AND of each pair of bits, \nA_7 AND B_7,\nA_6 AND B_6,\nand so forth, to\nproduce the result 01010000, as shown to the right.\nIn the same way, we can extend other logic\noperations, such as OR, NOT, and XOR, to operate on bits of groups.\n\n\n{ 0pt\n 0pt\n\n&A  & 0&1& 0&1& 0&1& 0&1\n  AND   &B& 1&1&1&1&0&0&0&0 \n&& 0& 1&0&1&0&0&0&0\n\n}\n\n\n\n\n\n\n"
        },
        "questions": "1. What is the significance of the logical completeness theorem?\n2. How can we use the construction from the logical completeness theorem to solve problems?\n3. What is the significance of extending logic operations to groups of bits?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Examples and a Generalization",
            "text": "{Examples and a Generalization}\n\nLet's use our construction to solve a few examples.  We begin with\nthe functions that we illustrated with the first truth table from this\nset of notes,\nthe carry out C and sum S of two {2-bit}\nunsigned numbers.  Since each output bit requires a separate expression,\nwe now write S_1S_0 for the two bits of the sum.  We also need to\nbe able to make use of the individual bits of the input values, so we \nwrite these as A_1A_0 and B_1B_0, as shown on the left below.\nUsing our \nconstruction from the logical completeness theorem, we obtain the\nequations on the right.\nYou should verify these expressions yourself.\n\n{\n\n{cccc|ccc}\n{c|}& \nA_1& A_0& B_1& B_0& C& S_1& S_0 \n0&0& 0&0& 0& 0&0\n0&0& 0&1& 0& 0&1\n0&0& 1&0& 0& 1&0\n0&0& 1&1& 0& 1&1\n0&1& 0&0& 0& 0&1\n0&1& 0&1& 0& 1&0\n0&1& 1&0& 0& 1&1\n0&1& 1&1& 1& 0&0\n1&0& 0&0& 0& 1&0\n1&0& 0&1& 0& 1&1\n1&0& 1&0& 1& 0&0\n1&0& 1&1& 1& 0&1\n1&1& 0&0& 0& 1&1\n1&1& 0&1& 1& 0&0\n1&1& 1&0& 1& 0&1\n1&1& 1&1& 1& 1&0\n\n\n\n{eqnarray*}\n\nC &=& \n{A_1} A_0 B_1 B_0 +\nA_1 {A_0} B_1 {B_0} +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} B_0 +\nA_1 A_0 B_1 {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_1 &=& \n{A_1} {A_0} B_1 {B_0} +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} B_0 +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} {B_0} +\nA_1 {A_0} {B_1} B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_0 &=& \n{A_1} {A_0} {B_1} B_0 +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} {B_0} +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} B_0 +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 {B_0}\n{eqnarray*}\n\n}\n\n\nNow let's consider a new function.  Given\nan {8-bit} 2's complement number, A=A_7A_6A_5A_4A_3A_2A_1A_0,\nwe want to compare it with the value -1.  We know that\nwe can construct this function using AND, OR, and NOT, but how?\nWe start by writing the representation for -1, which is 11111111.\nIf the number A matches that representation, we want to produce a 1.\nIf the number A differs in any bit, we want to produce a 0.\nThe desired function has exactly one combination of inputs that\nproduces a 1, so in fact we need only one minterm!  In this case, we\ncan compare with -1 by calculating the expression:\n\n{eqnarray*}\nA_7  A_6  A_5  A_4  A_3  A_2  A_1  A_0\n{eqnarray*}\n\nHere we have explicitly included multiplication symbols to avoid\nconfusion with our notation for groups of bits, as we used when \nnaming the individual bits of A.\n\n\nIn closing, we briefly introduce a generalization of logic\noperations to groups of bits.  Our representations for integers,\nreal numbers, and characters from human languages all use more than\none bit to represent a given value.  When we use computers, we often\nmake use of multiple bits in groups in this way.  A { byte}, for example,\ntoday means an ordered group of eight bits.\n\nWe can extend our logic functions to operate on such groups by pairing\nbits from each of two groups and performing the logic operation on each\npair.  For example, given\nA=A_7A_6A_5A_4A_3A_2A_1A_0=01010101\nand\nB=B_7B_6B_5B_4B_3B_2B_1B_0=11110000, we calculate\nA AND B by computing the AND of each pair of bits, \nA_7 AND B_7,\nA_6 AND B_6,\nand so forth, to\nproduce the result 01010000, as shown to the right.\nIn the same way, we can extend other logic\noperations, such as OR, NOT, and XOR, to operate on bits of groups.\n\n\n{ 0pt\n 0pt\n\n&A  & 0&1& 0&1& 0&1& 0&1\n  AND   &B& 1&1&1&1&0&0&0&0 \n&& 0& 1&0&1&0&0&0&0\n\n}\n\n\n\n\n\n\n"
        },
        "questions": "1. What is the significance of the logical completeness theorem?\n2. How can we use the construction from the logical completeness theorem to solve problems?\n3. What is the significance of extending logic operations to groups of bits?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Examples and a Generalization",
            "text": "{Examples and a Generalization}\n\nLet's use our construction to solve a few examples.  We begin with\nthe functions that we illustrated with the first truth table from this\nset of notes,\nthe carry out C and sum S of two {2-bit}\nunsigned numbers.  Since each output bit requires a separate expression,\nwe now write S_1S_0 for the two bits of the sum.  We also need to\nbe able to make use of the individual bits of the input values, so we \nwrite these as A_1A_0 and B_1B_0, as shown on the left below.\nUsing our \nconstruction from the logical completeness theorem, we obtain the\nequations on the right.\nYou should verify these expressions yourself.\n\n{\n\n{cccc|ccc}\n{c|}& \nA_1& A_0& B_1& B_0& C& S_1& S_0 \n0&0& 0&0& 0& 0&0\n0&0& 0&1& 0& 0&1\n0&0& 1&0& 0& 1&0\n0&0& 1&1& 0& 1&1\n0&1& 0&0& 0& 0&1\n0&1& 0&1& 0& 1&0\n0&1& 1&0& 0& 1&1\n0&1& 1&1& 1& 0&0\n1&0& 0&0& 0& 1&0\n1&0& 0&1& 0& 1&1\n1&0& 1&0& 1& 0&0\n1&0& 1&1& 1& 0&1\n1&1& 0&0& 0& 1&1\n1&1& 0&1& 1& 0&0\n1&1& 1&0& 1& 0&1\n1&1& 1&1& 1& 1&0\n\n\n\n{eqnarray*}\n\nC &=& \n{A_1} A_0 B_1 B_0 +\nA_1 {A_0} B_1 {B_0} +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} B_0 +\nA_1 A_0 B_1 {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_1 &=& \n{A_1} {A_0} B_1 {B_0} +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} B_0 +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} {B_0} +\nA_1 {A_0} {B_1} B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_0 &=& \n{A_1} {A_0} {B_1} B_0 +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} {B_0} +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} B_0 +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 {B_0}\n{eqnarray*}\n\n}\n\n\nNow let's consider a new function.  Given\nan {8-bit} 2's complement number, A=A_7A_6A_5A_4A_3A_2A_1A_0,\nwe want to compare it with the value -1.  We know that\nwe can construct this function using AND, OR, and NOT, but how?\nWe start by writing the representation for -1, which is 11111111.\nIf the number A matches that representation, we want to produce a 1.\nIf the number A differs in any bit, we want to produce a 0.\nThe desired function has exactly one combination of inputs that\nproduces a 1, so in fact we need only one minterm!  In this case, we\ncan compare with -1 by calculating the expression:\n\n{eqnarray*}\nA_7  A_6  A_5  A_4  A_3  A_2  A_1  A_0\n{eqnarray*}\n\nHere we have explicitly included multiplication symbols to avoid\nconfusion with our notation for groups of bits, as we used when \nnaming the individual bits of A.\n\n\nIn closing, we briefly introduce a generalization of logic\noperations to groups of bits.  Our representations for integers,\nreal numbers, and characters from human languages all use more than\none bit to represent a given value.  When we use computers, we often\nmake use of multiple bits in groups in this way.  A { byte}, for example,\ntoday means an ordered group of eight bits.\n\nWe can extend our logic functions to operate on such groups by pairing\nbits from each of two groups and performing the logic operation on each\npair.  For example, given\nA=A_7A_6A_5A_4A_3A_2A_1A_0=01010101\nand\nB=B_7B_6B_5B_4B_3B_2B_1B_0=11110000, we calculate\nA AND B by computing the AND of each pair of bits, \nA_7 AND B_7,\nA_6 AND B_6,\nand so forth, to\nproduce the result 01010000, as shown to the right.\nIn the same way, we can extend other logic\noperations, such as OR, NOT, and XOR, to operate on bits of groups.\n\n\n{ 0pt\n 0pt\n\n&A  & 0&1& 0&1& 0&1& 0&1\n  AND   &B& 1&1&1&1&0&0&0&0 \n&& 0& 1&0&1&0&0&0&0\n\n}\n\n\n\n\n\n\n"
        },
        "questions": "1. What is the significance of the logical completeness theorem?\n2. How can we use the construction from the logical completeness theorem to solve problems?\n3. What is the significance of extending logic operations to groups of bits?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Examples and a Generalization",
            "text": "{Examples and a Generalization}\n\nLet's use our construction to solve a few examples.  We begin with\nthe functions that we illustrated with the first truth table from this\nset of notes,\nthe carry out C and sum S of two {2-bit}\nunsigned numbers.  Since each output bit requires a separate expression,\nwe now write S_1S_0 for the two bits of the sum.  We also need to\nbe able to make use of the individual bits of the input values, so we \nwrite these as A_1A_0 and B_1B_0, as shown on the left below.\nUsing our \nconstruction from the logical completeness theorem, we obtain the\nequations on the right.\nYou should verify these expressions yourself.\n\n{\n\n{cccc|ccc}\n{c|}& \nA_1& A_0& B_1& B_0& C& S_1& S_0 \n0&0& 0&0& 0& 0&0\n0&0& 0&1& 0& 0&1\n0&0& 1&0& 0& 1&0\n0&0& 1&1& 0& 1&1\n0&1& 0&0& 0& 0&1\n0&1& 0&1& 0& 1&0\n0&1& 1&0& 0& 1&1\n0&1& 1&1& 1& 0&0\n1&0& 0&0& 0& 1&0\n1&0& 0&1& 0& 1&1\n1&0& 1&0& 1& 0&0\n1&0& 1&1& 1& 0&1\n1&1& 0&0& 0& 1&1\n1&1& 0&1& 1& 0&0\n1&1& 1&0& 1& 0&1\n1&1& 1&1& 1& 1&0\n\n\n\n{eqnarray*}\n\nC &=& \n{A_1} A_0 B_1 B_0 +\nA_1 {A_0} B_1 {B_0} +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} B_0 +\nA_1 A_0 B_1 {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_1 &=& \n{A_1} {A_0} B_1 {B_0} +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} B_0 +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} {B_0} +\nA_1 {A_0} {B_1} B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_0 &=& \n{A_1} {A_0} {B_1} B_0 +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} {B_0} +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} B_0 +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 {B_0}\n{eqnarray*}\n\n}\n\n\nNow let's consider a new function.  Given\nan {8-bit} 2's complement number, A=A_7A_6A_5A_4A_3A_2A_1A_0,\nwe want to compare it with the value -1.  We know that\nwe can construct this function using AND, OR, and NOT, but how?\nWe start by writing the representation for -1, which is 11111111.\nIf the number A matches that representation, we want to produce a 1.\nIf the number A differs in any bit, we want to produce a 0.\nThe desired function has exactly one combination of inputs that\nproduces a 1, so in fact we need only one minterm!  In this case, we\ncan compare with -1 by calculating the expression:\n\n{eqnarray*}\nA_7  A_6  A_5  A_4  A_3  A_2  A_1  A_0\n{eqnarray*}\n\nHere we have explicitly included multiplication symbols to avoid\nconfusion with our notation for groups of bits, as we used when \nnaming the individual bits of A.\n\n\nIn closing, we briefly introduce a generalization of logic\noperations to groups of bits.  Our representations for integers,\nreal numbers, and characters from human languages all use more than\none bit to represent a given value.  When we use computers, we often\nmake use of multiple bits in groups in this way.  A { byte}, for example,\ntoday means an ordered group of eight bits.\n\nWe can extend our logic functions to operate on such groups by pairing\nbits from each of two groups and performing the logic operation on each\npair.  For example, given\nA=A_7A_6A_5A_4A_3A_2A_1A_0=01010101\nand\nB=B_7B_6B_5B_4B_3B_2B_1B_0=11110000, we calculate\nA AND B by computing the AND of each pair of bits, \nA_7 AND B_7,\nA_6 AND B_6,\nand so forth, to\nproduce the result 01010000, as shown to the right.\nIn the same way, we can extend other logic\noperations, such as OR, NOT, and XOR, to operate on bits of groups.\n\n\n{ 0pt\n 0pt\n\n&A  & 0&1& 0&1& 0&1& 0&1\n  AND   &B& 1&1&1&1&0&0&0&0 \n&& 0& 1&0&1&0&0&0&0\n\n}\n\n\n\n\n\n\n"
        },
        "questions": "1. What is the significance of the logical completeness theorem?\n2. How can we use the construction from the logical completeness theorem to solve problems?\n3. What is the significance of extending logic operations to groups of bits?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Examples and a Generalization",
            "text": "{Examples and a Generalization}\n\nLet's use our construction to solve a few examples.  We begin with\nthe functions that we illustrated with the first truth table from this\nset of notes,\nthe carry out C and sum S of two {2-bit}\nunsigned numbers.  Since each output bit requires a separate expression,\nwe now write S_1S_0 for the two bits of the sum.  We also need to\nbe able to make use of the individual bits of the input values, so we \nwrite these as A_1A_0 and B_1B_0, as shown on the left below.\nUsing our \nconstruction from the logical completeness theorem, we obtain the\nequations on the right.\nYou should verify these expressions yourself.\n\n{\n\n{cccc|ccc}\n{c|}& \nA_1& A_0& B_1& B_0& C& S_1& S_0 \n0&0& 0&0& 0& 0&0\n0&0& 0&1& 0& 0&1\n0&0& 1&0& 0& 1&0\n0&0& 1&1& 0& 1&1\n0&1& 0&0& 0& 0&1\n0&1& 0&1& 0& 1&0\n0&1& 1&0& 0& 1&1\n0&1& 1&1& 1& 0&0\n1&0& 0&0& 0& 1&0\n1&0& 0&1& 0& 1&1\n1&0& 1&0& 1& 0&0\n1&0& 1&1& 1& 0&1\n1&1& 0&0& 0& 1&1\n1&1& 0&1& 1& 0&0\n1&1& 1&0& 1& 0&1\n1&1& 1&1& 1& 1&0\n\n\n\n{eqnarray*}\n\nC &=& \n{A_1} A_0 B_1 B_0 +\nA_1 {A_0} B_1 {B_0} +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} B_0 +\nA_1 A_0 B_1 {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_1 &=& \n{A_1} {A_0} B_1 {B_0} +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} B_0 +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} {B_0} +\nA_1 {A_0} {B_1} B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_0 &=& \n{A_1} {A_0} {B_1} B_0 +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} {B_0} +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} B_0 +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 {B_0}\n{eqnarray*}\n\n}\n\n\nNow let's consider a new function.  Given\nan {8-bit} 2's complement number, A=A_7A_6A_5A_4A_3A_2A_1A_0,\nwe want to compare it with the value -1.  We know that\nwe can construct this function using AND, OR, and NOT, but how?\nWe start by writing the representation for -1, which is 11111111.\nIf the number A matches that representation, we want to produce a 1.\nIf the number A differs in any bit, we want to produce a 0.\nThe desired function has exactly one combination of inputs that\nproduces a 1, so in fact we need only one minterm!  In this case, we\ncan compare with -1 by calculating the expression:\n\n{eqnarray*}\nA_7  A_6  A_5  A_4  A_3  A_2  A_1  A_0\n{eqnarray*}\n\nHere we have explicitly included multiplication symbols to avoid\nconfusion with our notation for groups of bits, as we used when \nnaming the individual bits of A.\n\n\nIn closing, we briefly introduce a generalization of logic\noperations to groups of bits.  Our representations for integers,\nreal numbers, and characters from human languages all use more than\none bit to represent a given value.  When we use computers, we often\nmake use of multiple bits in groups in this way.  A { byte}, for example,\ntoday means an ordered group of eight bits.\n\nWe can extend our logic functions to operate on such groups by pairing\nbits from each of two groups and performing the logic operation on each\npair.  For example, given\nA=A_7A_6A_5A_4A_3A_2A_1A_0=01010101\nand\nB=B_7B_6B_5B_4B_3B_2B_1B_0=11110000, we calculate\nA AND B by computing the AND of each pair of bits, \nA_7 AND B_7,\nA_6 AND B_6,\nand so forth, to\nproduce the result 01010000, as shown to the right.\nIn the same way, we can extend other logic\noperations, such as OR, NOT, and XOR, to operate on bits of groups.\n\n\n{ 0pt\n 0pt\n\n&A  & 0&1& 0&1& 0&1& 0&1\n  AND   &B& 1&1&1&1&0&0&0&0 \n&& 0& 1&0&1&0&0&0&0\n\n}\n\n\n\n\n\n\n"
        },
        "questions": "1. What is the significance of the logical completeness theorem?\n2. How can we use the construction from the logical completeness theorem to solve problems?\n3. What is the significance of extending logic operations to groups of bits?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Examples and a Generalization",
            "text": "{Examples and a Generalization}\n\nLet's use our construction to solve a few examples.  We begin with\nthe functions that we illustrated with the first truth table from this\nset of notes,\nthe carry out C and sum S of two {2-bit}\nunsigned numbers.  Since each output bit requires a separate expression,\nwe now write S_1S_0 for the two bits of the sum.  We also need to\nbe able to make use of the individual bits of the input values, so we \nwrite these as A_1A_0 and B_1B_0, as shown on the left below.\nUsing our \nconstruction from the logical completeness theorem, we obtain the\nequations on the right.\nYou should verify these expressions yourself.\n\n{\n\n{cccc|ccc}\n{c|}& \nA_1& A_0& B_1& B_0& C& S_1& S_0 \n0&0& 0&0& 0& 0&0\n0&0& 0&1& 0& 0&1\n0&0& 1&0& 0& 1&0\n0&0& 1&1& 0& 1&1\n0&1& 0&0& 0& 0&1\n0&1& 0&1& 0& 1&0\n0&1& 1&0& 0& 1&1\n0&1& 1&1& 1& 0&0\n1&0& 0&0& 0& 1&0\n1&0& 0&1& 0& 1&1\n1&0& 1&0& 1& 0&0\n1&0& 1&1& 1& 0&1\n1&1& 0&0& 0& 1&1\n1&1& 0&1& 1& 0&0\n1&1& 1&0& 1& 0&1\n1&1& 1&1& 1& 1&0\n\n\n\n{eqnarray*}\n\nC &=& \n{A_1} A_0 B_1 B_0 +\nA_1 {A_0} B_1 {B_0} +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} B_0 +\nA_1 A_0 B_1 {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_1 &=& \n{A_1} {A_0} B_1 {B_0} +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} B_0 +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} {B_0} +\nA_1 {A_0} {B_1} B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 B_0\n\n\nS_0 &=& \n{A_1} {A_0} {B_1} B_0 +\n{A_1} {A_0} B_1 B_0 +\n{A_1} A_0 {B_1} {B_0} +\n&& {A_1} A_0 B_1 {B_0} +\nA_1 {A_0} {B_1} B_0 +\nA_1 {A_0} B_1 B_0 +\n&& A_1 A_0 {B_1} {B_0} +\nA_1 A_0 B_1 {B_0}\n{eqnarray*}\n\n}\n\n\nNow let's consider a new function.  Given\nan {8-bit} 2's complement number, A=A_7A_6A_5A_4A_3A_2A_1A_0,\nwe want to compare it with the value -1.  We know that\nwe can construct this function using AND, OR, and NOT, but how?\nWe start by writing the representation for -1, which is 11111111.\nIf the number A matches that representation, we want to produce a 1.\nIf the number A differs in any bit, we want to produce a 0.\nThe desired function has exactly one combination of inputs that\nproduces a 1, so in fact we need only one minterm!  In this case, we\ncan compare with -1 by calculating the expression:\n\n{eqnarray*}\nA_7  A_6  A_5  A_4  A_3  A_2  A_1  A_0\n{eqnarray*}\n\nHere we have explicitly included multiplication symbols to avoid\nconfusion with our notation for groups of bits, as we used when \nnaming the individual bits of A.\n\n\nIn closing, we briefly introduce a generalization of logic\noperations to groups of bits.  Our representations for integers,\nreal numbers, and characters from human languages all use more than\none bit to represent a given value.  When we use computers, we often\nmake use of multiple bits in groups in this way.  A { byte}, for example,\ntoday means an ordered group of eight bits.\n\nWe can extend our logic functions to operate on such groups by pairing\nbits from each of two groups and performing the logic operation on each\npair.  For example, given\nA=A_7A_6A_5A_4A_3A_2A_1A_0=01010101\nand\nB=B_7B_6B_5B_4B_3B_2B_1B_0=11110000, we calculate\nA AND B by computing the AND of each pair of bits, \nA_7 AND B_7,\nA_6 AND B_6,\nand so forth, to\nproduce the result 01010000, as shown to the right.\nIn the same way, we can extend other logic\noperations, such as OR, NOT, and XOR, to operate on bits of groups.\n\n\n{ 0pt\n 0pt\n\n&A  & 0&1& 0&1& 0&1& 0&1\n  AND   &B& 1&1&1&1&0&0&0&0 \n&& 0& 1&0&1&0&0&0&0\n\n}\n\n\n\n\n\n\n"
        },
        "questions": "1. What is the significance of the logical completeness theorem?\n2. How can we use the construction from the logical completeness theorem to solve problems?\n3. What is the significance of extending logic operations to groups of bits?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Negating 2's Complement Numbers",
            "text": "{Negating 2's Complement Numbers}\n\nThe algebraic approach makes understanding negation of an integer\nrepresented using 2's complement fairly straightforward, and gives \nus an easy procedure for doing so.\nRecall that given an integer k in an {N-bit} 2's complement\nrepresentation, the {N-bit} pattern for -k is given by 2^N-k \n(also true for k=0 if we keep only the low N bits of the result).  \nBut 2^N=(2^N-1)+1.  Note that 2^N-1 is the pattern of\nall 1 bits.  Subtracting any value k from this value is equivalent\nto simply flipping the bits, changing 0s to 1s and 1s to 0s.\n(This operation is called a { 1's complement}, by the way.)\nWe then add 1 to the result to find the pattern for -k.\n\nNegation can overflow, of course.  Try finding the negative pattern for -8 \nin {4-bit} 2's complement.\n\nFinally, be aware that people often overload the term 2's complement\nand use it to refer to the operation of negation in a 2's complement\nrepresentation.  In our class, we try avoid this confusion: 2's complement\nis a representation for signed integers, and negation is an operation\nthat one can apply to a signed integer (whether the representation used\nfor the integer is 2's complement or some other representation for signed\nintegers).\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the algebraic approach to negation of an integer represented using 2's complement?\n2. What is the procedure for negation of an integer represented using 2's complement?\n3. What is the difference between 2's complement and negation?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Negating 2's Complement Numbers",
            "text": "{Negating 2's Complement Numbers}\n\nThe algebraic approach makes understanding negation of an integer\nrepresented using 2's complement fairly straightforward, and gives \nus an easy procedure for doing so.\nRecall that given an integer k in an {N-bit} 2's complement\nrepresentation, the {N-bit} pattern for -k is given by 2^N-k \n(also true for k=0 if we keep only the low N bits of the result).  \nBut 2^N=(2^N-1)+1.  Note that 2^N-1 is the pattern of\nall 1 bits.  Subtracting any value k from this value is equivalent\nto simply flipping the bits, changing 0s to 1s and 1s to 0s.\n(This operation is called a { 1's complement}, by the way.)\nWe then add 1 to the result to find the pattern for -k.\n\nNegation can overflow, of course.  Try finding the negative pattern for -8 \nin {4-bit} 2's complement.\n\nFinally, be aware that people often overload the term 2's complement\nand use it to refer to the operation of negation in a 2's complement\nrepresentation.  In our class, we try avoid this confusion: 2's complement\nis a representation for signed integers, and negation is an operation\nthat one can apply to a signed integer (whether the representation used\nfor the integer is 2's complement or some other representation for signed\nintegers).\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the algebraic approach to negation of an integer represented using 2's complement?\n2. What is the procedure for negation of an integer represented using 2's complement?\n3. What is the difference between 2's complement and negation?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Negating 2's Complement Numbers",
            "text": "{Negating 2's Complement Numbers}\n\nThe algebraic approach makes understanding negation of an integer\nrepresented using 2's complement fairly straightforward, and gives \nus an easy procedure for doing so.\nRecall that given an integer k in an {N-bit} 2's complement\nrepresentation, the {N-bit} pattern for -k is given by 2^N-k \n(also true for k=0 if we keep only the low N bits of the result).  \nBut 2^N=(2^N-1)+1.  Note that 2^N-1 is the pattern of\nall 1 bits.  Subtracting any value k from this value is equivalent\nto simply flipping the bits, changing 0s to 1s and 1s to 0s.\n(This operation is called a { 1's complement}, by the way.)\nWe then add 1 to the result to find the pattern for -k.\n\nNegation can overflow, of course.  Try finding the negative pattern for -8 \nin {4-bit} 2's complement.\n\nFinally, be aware that people often overload the term 2's complement\nand use it to refer to the operation of negation in a 2's complement\nrepresentation.  In our class, we try avoid this confusion: 2's complement\nis a representation for signed integers, and negation is an operation\nthat one can apply to a signed integer (whether the representation used\nfor the integer is 2's complement or some other representation for signed\nintegers).\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the algebraic approach to negation of an integer represented using 2's complement?\n2. What is the procedure for negation of an integer represented using 2's complement?\n3. What is the difference between 2's complement and negation?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Negating 2's Complement Numbers",
            "text": "{Negating 2's Complement Numbers}\n\nThe algebraic approach makes understanding negation of an integer\nrepresented using 2's complement fairly straightforward, and gives \nus an easy procedure for doing so.\nRecall that given an integer k in an {N-bit} 2's complement\nrepresentation, the {N-bit} pattern for -k is given by 2^N-k \n(also true for k=0 if we keep only the low N bits of the result).  \nBut 2^N=(2^N-1)+1.  Note that 2^N-1 is the pattern of\nall 1 bits.  Subtracting any value k from this value is equivalent\nto simply flipping the bits, changing 0s to 1s and 1s to 0s.\n(This operation is called a { 1's complement}, by the way.)\nWe then add 1 to the result to find the pattern for -k.\n\nNegation can overflow, of course.  Try finding the negative pattern for -8 \nin {4-bit} 2's complement.\n\nFinally, be aware that people often overload the term 2's complement\nand use it to refer to the operation of negation in a 2's complement\nrepresentation.  In our class, we try avoid this confusion: 2's complement\nis a representation for signed integers, and negation is an operation\nthat one can apply to a signed integer (whether the representation used\nfor the integer is 2's complement or some other representation for signed\nintegers).\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the algebraic approach to negation of an integer represented using 2's complement?\n2. What is the procedure for negation of an integer represented using 2's complement?\n3. What is the difference between 2's complement and negation?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Negating 2's Complement Numbers",
            "text": "{Negating 2's Complement Numbers}\n\nThe algebraic approach makes understanding negation of an integer\nrepresented using 2's complement fairly straightforward, and gives \nus an easy procedure for doing so.\nRecall that given an integer k in an {N-bit} 2's complement\nrepresentation, the {N-bit} pattern for -k is given by 2^N-k \n(also true for k=0 if we keep only the low N bits of the result).  \nBut 2^N=(2^N-1)+1.  Note that 2^N-1 is the pattern of\nall 1 bits.  Subtracting any value k from this value is equivalent\nto simply flipping the bits, changing 0s to 1s and 1s to 0s.\n(This operation is called a { 1's complement}, by the way.)\nWe then add 1 to the result to find the pattern for -k.\n\nNegation can overflow, of course.  Try finding the negative pattern for -8 \nin {4-bit} 2's complement.\n\nFinally, be aware that people often overload the term 2's complement\nand use it to refer to the operation of negation in a 2's complement\nrepresentation.  In our class, we try avoid this confusion: 2's complement\nis a representation for signed integers, and negation is an operation\nthat one can apply to a signed integer (whether the representation used\nfor the integer is 2's complement or some other representation for signed\nintegers).\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the algebraic approach to negation of an integer represented using 2's complement?\n2. What is the procedure for negation of an integer represented using 2's complement?\n3. What is the difference between 2's complement and negation?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Negating 2's Complement Numbers",
            "text": "{Negating 2's Complement Numbers}\n\nThe algebraic approach makes understanding negation of an integer\nrepresented using 2's complement fairly straightforward, and gives \nus an easy procedure for doing so.\nRecall that given an integer k in an {N-bit} 2's complement\nrepresentation, the {N-bit} pattern for -k is given by 2^N-k \n(also true for k=0 if we keep only the low N bits of the result).  \nBut 2^N=(2^N-1)+1.  Note that 2^N-1 is the pattern of\nall 1 bits.  Subtracting any value k from this value is equivalent\nto simply flipping the bits, changing 0s to 1s and 1s to 0s.\n(This operation is called a { 1's complement}, by the way.)\nWe then add 1 to the result to find the pattern for -k.\n\nNegation can overflow, of course.  Try finding the negative pattern for -8 \nin {4-bit} 2's complement.\n\nFinally, be aware that people often overload the term 2's complement\nand use it to refer to the operation of negation in a 2's complement\nrepresentation.  In our class, we try avoid this confusion: 2's complement\nis a representation for signed integers, and negation is an operation\nthat one can apply to a signed integer (whether the representation used\nfor the integer is 2's complement or some other representation for signed\nintegers).\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the algebraic approach to negation of an integer represented using 2's complement?\n2. What is the procedure for negation of an integer represented using 2's complement?\n3. What is the difference between 2's complement and negation?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Negating 2's Complement Numbers",
            "text": "{Negating 2's Complement Numbers}\n\nThe algebraic approach makes understanding negation of an integer\nrepresented using 2's complement fairly straightforward, and gives \nus an easy procedure for doing so.\nRecall that given an integer k in an {N-bit} 2's complement\nrepresentation, the {N-bit} pattern for -k is given by 2^N-k \n(also true for k=0 if we keep only the low N bits of the result).  \nBut 2^N=(2^N-1)+1.  Note that 2^N-1 is the pattern of\nall 1 bits.  Subtracting any value k from this value is equivalent\nto simply flipping the bits, changing 0s to 1s and 1s to 0s.\n(This operation is called a { 1's complement}, by the way.)\nWe then add 1 to the result to find the pattern for -k.\n\nNegation can overflow, of course.  Try finding the negative pattern for -8 \nin {4-bit} 2's complement.\n\nFinally, be aware that people often overload the term 2's complement\nand use it to refer to the operation of negation in a 2's complement\nrepresentation.  In our class, we try avoid this confusion: 2's complement\nis a representation for signed integers, and negation is an operation\nthat one can apply to a signed integer (whether the representation used\nfor the integer is 2's complement or some other representation for signed\nintegers).\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the algebraic approach to negation of an integer represented using 2's complement?\n2. What is the procedure for negation of an integer represented using 2's complement?\n3. What is the difference between 2's complement and negation?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "The Halting Problem*",
            "text": "{The Halting Problem*}\n\nYou might reasonably ask whether any problems can be shown to\nbe incomputable.  More common terms for such problems---those known\nto be insolvable by any computer---are { intractable} or \nundecidable.\n\nIn the same 1936 paper in which he introduced the universal computing\nmachine, Alan Turing also provided an answer to this question\nby introducing (and proving) that there are in fact problems that cannot be\ncomputed by a universal computing machine.\nThe problem that\nhe proved undecidable, using proof techniques almost identical to those\ndeveloped for similar problems in the 1880s, is now known as { the\nhalting problem}.\n\n\n\nThe halting problem is easy to state and easy to prove undecidable.\nThe problem is this: given a Turing machine and an input to the Turing\nmachine, does the Turing machine finish computing in a finite number\nof steps (a finite amount of time)?  In order to solve the problem, an\nanswer, either yes or no, must be given in a finite amount of time\nregardless of the machine or input in question.  Clearly some machines\nnever finish.  For example, we can write a Turing machine that counts\nupwards starting from one.\n\nYou may find the proof structure for undecidability of the halting problem\neasier to understand if\nyou first think about a related problem with which you may\nalready be familiar, the Liar's paradox\n(which is at least 2,300 years old).  In its stengthened form, it is\nthe following sentence: ``This sentence is not true.''\n\n\nTo see that no Turing machine can solve the halting problem, we begin\nby assuming that such a machine exists, and then show that its\nexistence is self-contradictory.  We call the machine the ``Halting\nMachine,'' or HM for short.  HM is a machine that operates on \nanother\n\n\n\n\n\nTuring machine and its inputs to produce a yes or no answer in finite time:\neither the machine in question finishes in finite time (HM returns\n``yes''), or it does not (HM returns ``no'').  The figure illustrates\nHM's operation.\n\n\nFrom HM, we construct a second machine that we call the HM Inverter,\nor HMI.  This machine inverts the sense of the answer given by HM.  In\nparticular, the inputs are fed directly into a copy of HM, and if HM\nanswers ``yes,'' HMI enters an infinite loop.  If HM answers ``no,'' HMI\nhalts.  A diagram appears to the right.\n\nThe inconsistency can now be seen by asking HM whether HMI halts when\ngiven itself as an input (repeatedly), as\n\n\n\n\n\nshown below.  Two\ncopies of HM are thus\nbeing asked the same question.  One copy is the rightmost in the figure below\nand the second is embedded in the HMI machine that we are using as the\ninput to the rightmost HM.  As the two copies of HM operate on the same input\n(HMI operating on HMI), they should return the same answer: a Turing\nmachine either halts on an input, or it does not; they are\ndeterministic.\n\n\n\nLet's assume that the rightmost HM tells us that HMI operating on itself halts.\nThen the copy of HM in HMI (when HMI executes on itself, with itself\nas an input) must also say ``yes.''  But this answer implies that HMI\ndoesn't halt (see the figure above), so the answer should have been\nno!\n\nAlternatively, we can assume that the rightmost HM says that HMI operating on itself\ndoes not halt.  Again, the copy of HM in HMI must give the same\nanswer.  But in this case HMI halts, again contradicting our\nassumption.\n\nSince neither answer is consistent, no consistent answer can be given,\nand the original assumption that HM exists is incorrect.  Thus, no\nTuring machine can solve the halting problem.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the Liar's paradox?\n2. What does it mean for a problem to be undecidable?\n3. What is the halting problem?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "The Halting Problem*",
            "text": "{The Halting Problem*}\n\nYou might reasonably ask whether any problems can be shown to\nbe incomputable.  More common terms for such problems---those known\nto be insolvable by any computer---are { intractable} or \nundecidable.\n\nIn the same 1936 paper in which he introduced the universal computing\nmachine, Alan Turing also provided an answer to this question\nby introducing (and proving) that there are in fact problems that cannot be\ncomputed by a universal computing machine.\nThe problem that\nhe proved undecidable, using proof techniques almost identical to those\ndeveloped for similar problems in the 1880s, is now known as { the\nhalting problem}.\n\n\n\nThe halting problem is easy to state and easy to prove undecidable.\nThe problem is this: given a Turing machine and an input to the Turing\nmachine, does the Turing machine finish computing in a finite number\nof steps (a finite amount of time)?  In order to solve the problem, an\nanswer, either yes or no, must be given in a finite amount of time\nregardless of the machine or input in question.  Clearly some machines\nnever finish.  For example, we can write a Turing machine that counts\nupwards starting from one.\n\nYou may find the proof structure for undecidability of the halting problem\neasier to understand if\nyou first think about a related problem with which you may\nalready be familiar, the Liar's paradox\n(which is at least 2,300 years old).  In its stengthened form, it is\nthe following sentence: ``This sentence is not true.''\n\n\nTo see that no Turing machine can solve the halting problem, we begin\nby assuming that such a machine exists, and then show that its\nexistence is self-contradictory.  We call the machine the ``Halting\nMachine,'' or HM for short.  HM is a machine that operates on \nanother\n\n\n\n\n\nTuring machine and its inputs to produce a yes or no answer in finite time:\neither the machine in question finishes in finite time (HM returns\n``yes''), or it does not (HM returns ``no'').  The figure illustrates\nHM's operation.\n\n\nFrom HM, we construct a second machine that we call the HM Inverter,\nor HMI.  This machine inverts the sense of the answer given by HM.  In\nparticular, the inputs are fed directly into a copy of HM, and if HM\nanswers ``yes,'' HMI enters an infinite loop.  If HM answers ``no,'' HMI\nhalts.  A diagram appears to the right.\n\nThe inconsistency can now be seen by asking HM whether HMI halts when\ngiven itself as an input (repeatedly), as\n\n\n\n\n\nshown below.  Two\ncopies of HM are thus\nbeing asked the same question.  One copy is the rightmost in the figure below\nand the second is embedded in the HMI machine that we are using as the\ninput to the rightmost HM.  As the two copies of HM operate on the same input\n(HMI operating on HMI), they should return the same answer: a Turing\nmachine either halts on an input, or it does not; they are\ndeterministic.\n\n\n\nLet's assume that the rightmost HM tells us that HMI operating on itself halts.\nThen the copy of HM in HMI (when HMI executes on itself, with itself\nas an input) must also say ``yes.''  But this answer implies that HMI\ndoesn't halt (see the figure above), so the answer should have been\nno!\n\nAlternatively, we can assume that the rightmost HM says that HMI operating on itself\ndoes not halt.  Again, the copy of HM in HMI must give the same\nanswer.  But in this case HMI halts, again contradicting our\nassumption.\n\nSince neither answer is consistent, no consistent answer can be given,\nand the original assumption that HM exists is incorrect.  Thus, no\nTuring machine can solve the halting problem.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the Liar's paradox?\n2. What does it mean for a problem to be undecidable?\n3. What is the halting problem?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "The Halting Problem*",
            "text": "{The Halting Problem*}\n\nYou might reasonably ask whether any problems can be shown to\nbe incomputable.  More common terms for such problems---those known\nto be insolvable by any computer---are { intractable} or \nundecidable.\n\nIn the same 1936 paper in which he introduced the universal computing\nmachine, Alan Turing also provided an answer to this question\nby introducing (and proving) that there are in fact problems that cannot be\ncomputed by a universal computing machine.\nThe problem that\nhe proved undecidable, using proof techniques almost identical to those\ndeveloped for similar problems in the 1880s, is now known as { the\nhalting problem}.\n\n\n\nThe halting problem is easy to state and easy to prove undecidable.\nThe problem is this: given a Turing machine and an input to the Turing\nmachine, does the Turing machine finish computing in a finite number\nof steps (a finite amount of time)?  In order to solve the problem, an\nanswer, either yes or no, must be given in a finite amount of time\nregardless of the machine or input in question.  Clearly some machines\nnever finish.  For example, we can write a Turing machine that counts\nupwards starting from one.\n\nYou may find the proof structure for undecidability of the halting problem\neasier to understand if\nyou first think about a related problem with which you may\nalready be familiar, the Liar's paradox\n(which is at least 2,300 years old).  In its stengthened form, it is\nthe following sentence: ``This sentence is not true.''\n\n\nTo see that no Turing machine can solve the halting problem, we begin\nby assuming that such a machine exists, and then show that its\nexistence is self-contradictory.  We call the machine the ``Halting\nMachine,'' or HM for short.  HM is a machine that operates on \nanother\n\n\n\n\n\nTuring machine and its inputs to produce a yes or no answer in finite time:\neither the machine in question finishes in finite time (HM returns\n``yes''), or it does not (HM returns ``no'').  The figure illustrates\nHM's operation.\n\n\nFrom HM, we construct a second machine that we call the HM Inverter,\nor HMI.  This machine inverts the sense of the answer given by HM.  In\nparticular, the inputs are fed directly into a copy of HM, and if HM\nanswers ``yes,'' HMI enters an infinite loop.  If HM answers ``no,'' HMI\nhalts.  A diagram appears to the right.\n\nThe inconsistency can now be seen by asking HM whether HMI halts when\ngiven itself as an input (repeatedly), as\n\n\n\n\n\nshown below.  Two\ncopies of HM are thus\nbeing asked the same question.  One copy is the rightmost in the figure below\nand the second is embedded in the HMI machine that we are using as the\ninput to the rightmost HM.  As the two copies of HM operate on the same input\n(HMI operating on HMI), they should return the same answer: a Turing\nmachine either halts on an input, or it does not; they are\ndeterministic.\n\n\n\nLet's assume that the rightmost HM tells us that HMI operating on itself halts.\nThen the copy of HM in HMI (when HMI executes on itself, with itself\nas an input) must also say ``yes.''  But this answer implies that HMI\ndoesn't halt (see the figure above), so the answer should have been\nno!\n\nAlternatively, we can assume that the rightmost HM says that HMI operating on itself\ndoes not halt.  Again, the copy of HM in HMI must give the same\nanswer.  But in this case HMI halts, again contradicting our\nassumption.\n\nSince neither answer is consistent, no consistent answer can be given,\nand the original assumption that HM exists is incorrect.  Thus, no\nTuring machine can solve the halting problem.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the Liar's paradox?\n2. What does it mean for a problem to be undecidable?\n3. What is the halting problem?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Changing Types in C*",
            "text": "{Changing Types in C*}\n\nChanging the type of a datum is necessary from time to time, but\nsometimes a compiler can do the work for you.\n\nThe most common form of { implicit type conversion} occurs with binary\narithmetic operations.  Integer arithmetic in C always uses types of\nat least the size of { int}, and all floating-point arithmetic uses\n{ double}.\n\nIf either or both operands have smaller integer types, or differ from\none another, the compiler implicitly converts them before performing\nthe operation, and the type of the result may be different from those of\nboth operands.\n\nIn general, the compiler selects the final type according to some\npreferred ordering in which floating-point is preferred over integers,\nunsigned values are preferred over signed values, and more bits are\npreferred over fewer bits.\n\nThe type of the result must be at least as large as either argument,\nbut is also at least as large as an { int} for integer operations\nand a { double} for floating-point operations.\n\nModern C compilers always extend an integer type's bit width before\nconverting from signed to unsigned.  The original C specification\ninterleaved bit width extensions to { int} with sign changes, thus\n{ older compilers may not be consistent, and implicitly require\nboth types of conversion in a single operation may lead to portability\nbugs.}\n\nThe implicit extension to { int} can also be confusing in the sense\nthat arithmetic that seems to work on smaller integers fails with\nlarger ones.  For example, multiplying two 16-bit integers set to 1000\nand printing the result works with most compilers because the 32-bit \n{ int} result is wide enough to hold the right answer.  In contrast,\nmultiplying two 32-bit integers set to 100,000 produces the wrong\nresult because the high bits of the result are discarded before it can\nbe converted to a larger type.  For this operation to produce the\ncorrect result, one of the integers must be converted explicitly (as\ndiscussed later) before the multiplication.\n\n\n\nImplicit type conversions also occur due to assignments.  Unlike\narithmetic conversions, the final type must match the left-hand side\nof the assignment (for example, a variable to which a result is assigned), and\nthe compiler simply performs any necessary conversion.\n\n{ Since the desired type may be smaller than the type of the value\nassigned, information can be lost.}  Floating-point values are\ntruncated when assigned to integers, and high bits of wider integer\ntypes are discarded when assigned to narrower integer types.  { Note\nthat a positive number may become a negative number when bits are\ndiscarded in this manner.}\n\nPassing arguments to functions can be viewed as a special case of\nassignment.  Given a function prototype, the compiler knows the type\nof each argument and can perform conversions as part of the code\ngenerated to pass the arguments to the function.  Without such a\nprototype, or for functions with variable numbers of arguments, the\ncompiler lacks type information and thus cannot perform necessary\nconversions, leading to unpredictable behavior.  By default, however,\nthe compiler extends any integer smaller than an { int}\nto the width of an { int} and converts { float} to\n{ double}.\n\n\nOccasionally it is convenient to use an { explicit type cast} to force\nconversion from one type to another.  { Such casts must be used\nwith caution, as they silence many of the warnings that a compiler\nmight otherwise generate when it detects potential problems.}  One\ncommon use is to promote integers to floating-point before an\narithmetic operation, as shown to the right.\n\n\n{\n\naaaa=\nint\nmain ()\n{\n>  int numerator = 10;\n>  int denominator = 20;\n>\n>  printf (\"fn\", numerator / (double)denominator);\n>  return 0;\n}\n\n}\n{-14pt}\n\nThe type to which a value is to be converted\nis placed in parentheses in front of the value.  In most cases,\nadditional parentheses should be used to avoid confusion about the\nprecedence of type conversion over other operations.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the most common form of implicit type conversion?\n2. What is the desired type of the result of an assignment?\n3. What is the type of the value assigned in an assignment?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Summary of Part 1 of the Course",
            "text": "{Summary of Part 1 of the Course}\n\nThis short summary provides a list of both terms that we expect you to\nknow and and skills that we expect you to have after our first few weeks\ntogether.  The first part of the course is shorter than the other three\nparts, so the amount of material is necessarily less.\n\nThese notes supplement the Patt and Patel textbook, so you will also \nneed to read and understand the relevant chapters (see the syllabus)\nin order to master this material completely.\n\nAccording to educational theory, the difficulty of learning depends on \nthe type of task involved.  Remembering new terminology is relatively \neasy, while applying the ideas underlying design decisions shown by \nexample to new problems posed as human tasks is relatively hard.\n\nIn this short summary, we give you lists at several levels of difficulty\nof what we expect you to be able to do as a result of the last few weeks\nof studying (reading, listening, doing homework, discussing your\nunderstanding with your classmates, and so forth).\n\nThis time, we'll list the skills first and leave the easy stuff for the \nnext page.\n\nWe expect you to be able to exercise the following skills:\n\n{}{{}{}\n{}{}{}\n\n{Represent decimal numbers with unsigned, 2's complement, and IEEE\nfloating-point representations, and be able to calculate the decimal value\nrepresented by a bit pattern in any of these representations.}\n\n{Be able to negate a number represented in the 2's complement\nrepresentation.}\n\n{Perform simple arithmetic by hand on unsigned and 2's complement\nrepresentations, and identify when overflow occurs.}\n\n{Be able to write a truth table for a Boolean expression.}\n\n{Be able to write a Boolean expression as a sum of minterms.}\n\n MOVED TO PART 4\n\n {Be able to calculate the Hamming distance of a code/representation.}\n \n {Know the relationships between Hamming distance and the abilities\n to detect and to correct bit errors.}\n\n{Know how to declare and initialize C variables with one of the \nprimitive data types.}\n\n\n\nAt a more abstract level, we expect you to be able to:\n\n{}{{}{}\n{}{}{}\n\n{Understand the value of using a common mathematical basis, such\nas modular arithmetic, in defining multiple representations (such as\nunsigned and 2's complement).}\n\n{Write Boolean expressions for the overflow conditions\non both unsigned and 2's complement addition.}\n\n MOVED TO PART 4\n\n {Be able to use parity for error detection, and Hamming codes for\n error correction.}\n\n{Be able to write single { if} statements and { for} loops\nin C in order to perform computation.}\n\n{Be able to use { scanf} and { printf} for basic input and \noutput in C.}\n\n\n\nAnd, at the highest level, we expect that you will be able to reason about\nand analyze problems in the following ways:\n\n{}{{}{}\n{}{}{}\n\n{Understand the tradeoffs between integer\n  FIXME?     not covered by book nor notes currently \n, fixed-point,    \nand floating-point representations for numbers.}\n\n{Understand logical completeness and be able to prove or disprove\nlogical completeness for sets of logic functions.}\n\n PARTIALLY MOVED TO PART 4\n\n {Understand the properties necessary in a representation, and understand\n basic tradeoffs in the sparsity of code words with error detection and\n correction capabilities.}\n{Understand the properties necessary in a representation: no ambiguity\nin meaning for any bit pattern, and agreement in advance on the meanings of \nall bit patterns.}\n\n{Analyze a simple, single-function C program and be able to explain its purpose.}\n\n\n\n\n\n\n\nYou should recognize all of these terms\nand be able to explain what they mean.\n(the parentheses give page numbers,\nor ``P&P'' for Patt & Patel).\n\nActually, we don't care whether you can draw something from memory---a full\nadder, for example---provided that you know what a full adder does and can\nderive a gate diagram correctly for one in a few minutes.  Higher-level\nskills are much more valuable.  (You may skip the *'d terms in Fall 2012.)\n\nNote that we are not saying that you should, for example, be able to \nwrite down the ASCII representation from memory.  In that example, \nknowing that it is a {7-bit} representation used for English\ntext is sufficient.  You can always look up the detailed definition \nin practice.\n\n[t]\n{}{{}{}\n{}{}{}\n\n{universal computational devices /  computing machines ()\n{--}{{}{}\n{}{}{}\n undecidable ()\n the halting problem ()\n\n}\n\n pre-Fall 2015 version\n\n {Turing machines\n {--}{{}{}\n {}{}{}\n  universal computational device/ computing machine\n  intractable/undecidable\n  the halting problem\n \n }\n\n{information storage in computers\n{--}{{}{}\n{}{}{}\n bits ()\n representation (P&P)\n data type ()\n unsigned representation ()\n 2's complement representation\n\n FIXME?  not covered by book nor notes currently\n  fixed-point representation\n\n IEEE floating-point representation\n ASCII representation\n equivalence classes\n\n}\n\n{operations on bits\n{--}{{}{}\n{}{}{}\n 1's complement operation\n carry (from addition)\n overflow (on any operation) ()\n Boolean logic and algebra\n logic functions/gates\n truth table\n AND/conjunction\n OR/disjunction\n NOT/logical complement/ (logical) negation/inverter\n XOR\n logical completeness\n minterm\n\n}\n\n{mathematical terms\n{--}{{}{}\n{}{}{}\n modular arithmetic\n implication\n contrapositive\n proof approaches: by construction, by contradiction, by induction\n without loss of generality (w.l.o.g.)\n\n}\n\n MOVED TO PART 4\n\n {error detection and correction\n {--}{{}{}\n {}{}{}\n  code/sparse representation\n  code word\n  bit error\n  odd/even parity bit\n  Hamming distance between code words\n  Hamming distance of a code\n  Hamming code\n  SEC-DED\n \n }\n\n\n\n[t]\n{}{{}{}\n{}{}{}\n\n{high-level language concepts\n{--}{{}{}\n{}{}{}\n syntax\n{variables\n{--}{{}{}\n{}{}{}\n declaration\n primitive data types\n symbolic name/identifier\n initialization\n\n}\n FIXME?  really not necessary for them\n strongly typed languages\n expression\n statement\n\n}\n\n{C operators\n{--}{{}{}\n{}{}{}\n operands\n arithmetic\n bitwise\n comparison/relational\n assignment\n address\n arithmetic shift\n logical shift\n precedence\n\n}\n\n{functions in C\n{--}{{}{}\n{}{}{}\n { main}\n function call\n arguments\n {{ printf} and { scanf}\n{--}{{}{}\n{}{}{}\n format string\n escape character\n\n}\n { sizeof} (built-in)\n\n}\n\n{transforming tasks into programs\n{--}{{}{}\n{}{}{}\n flow chart\n sequential construct\n conditional construct\n iterative construct/iteration/loop\n loop body\n\n}\n\n{C statements\n{--}{{}{}\n{}{}{}\n statement: null, simple, compound\n { if} statement\n { for} loop\n { return} statement\n\n}\n\n THESE ARE NOT REQUIRED TOPICS\n\n {execution of C programs\n {--}{{}{}\n {}{}{}\n  compiler/interpreter\n  source code\n  header files\n  assembly code\n  instructions\n  executable image\n \n }\n \n {the C preprocessor\n {--}{{}{}\n {}{}{}\n  #include directive\n  #define directive\n \n }\n\n\n\n\n\n\n{   }   blank 3rd page\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the value of using a common mathematical basis, such as modular arithmetic, in defining multiple representations (such as unsigned and 2's complement)?\n\n2. What are the properties necessary in a representation?\n\n3. What is the difference between a statement and an expression in C?",
        "answers": ""
    },
    {
        "positive_ctxs": {
            "title": "Overflow for 2's Complement Addition",
            "text": "{Overflow for 2's Complement Addition}\n\nUnderstanding overflow for 2's complement addition is somewhat trickier,\nwhich is why the problem is a good one for you to think about on your\nown first.\n\nOur operands, A and B, are now two {N-bit} 2's complement numbers.\nThe {N-bit} 2's complement representation \ncan represent integers in the range [-2^{N-1},2^{N-1}-1].\n\nLet's start by ruling out a case that we can show never leads to overflow.\n\n{ Lemma:} \n\nAddition of two {N-bit} 2's complement numbers A and B\ndoes not overflow if one of the numbers is negative and the other is\nnot.\n\n{ Proof:}\n\nWe again make use of the constraints implied by the fact that A and B\nare represented as {N-bit} 2's complement values.  We can assume\n{ without loss of generality}{This common mathematical phrasing\nmeans that we are using a problem symmetry to cut down the length of the\nproof discussion.  In this case, the names A and B aren't particularly\nimportant, since addition is commutative (A+B=B+A).  Thus the proof\nfor the case in which A is negative (and B is not) is identical to the\ncase in which B is negative (and A is not), except that all of the \nnames are swapped.  The term ``without loss of generality'' means that\nwe consider the proof complete even with additional assumptions, in\nour case that A<0 and B.}, or { w.l.o.g.}, \nthat A<0 and B.\n\nCombining these constraints with the range representable \nby {N-bit} 2's complement, we obtain\n\n{eqnarray*}\n-2^{N-1}  & A & < 0\n0  & B & < 2^{N-1}\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n-2^{N-1}  & C & < 2^{N-1}\n{eqnarray*}\n\nBut anything in the range specified by this inequality can be represented\nwith {N-bit} 2's complement, and thus the addition does not overflow.\n\n\nWe are now ready to state our main theorem.  For convenience, \nlet's use different names for the actual sum C=A+B and the sum S\nreturned from the add unit.  We define S as the number represented by\nthe bit pattern produced by the add unit.  When overflow \noccurs, S=C, but we always have (S=C)  2^N.\n\n{ Theorem:} \n\nAddition of two {N-bit} 2's complement numbers A and B\noverflows if and only if one of the following conditions holds:\n\n{A<0 and B<0 and S}\n{A and B and S<0}\n\n\n{ Proof:}\n\nWe once again start with the ``if'' direction.  That is, if condition 1 \nor condition 2 holds, we have an overflow.  The proofs are straightforward.\nGiven condition 1, we can add the two inequalities A<0 and B<0 to \nobtain C=A+B<0.  But S, so clearly S=C, thus overflow \nhas occurred.\n\nSimilarly, if condition 2 holds, we can add the inequalities A\nand B to obtain C=A+B.  Here we have S<0, so again\nS=C, and we have an overflow.\n\nWe must now prove the ``only if'' direction, showing that any overflow\nimplies either condition 1 or condition 2.  By the \n{ contrapositive}{If we have a statement of the form\n(p implies q), its contrapositive is the \nstatement (not q implies not p).\nBoth statements have the same truth value.  In this case, we can turn\nour Lemma around as stated.} of our\nLemma, we know that if an overflow occurs, either both operands are \nnegative, or they are both positive.\n\n\n\n\n\nLet's start with the case in which both operands are negative, so A<0\nand B<0, and thus the real sum C<0 as well.  Given that A and B\nare represented as {N-bit} 2's complement, they must fall in\nthe representable range, so we can write\n\n{eqnarray*}\n-2^{N-1}  & A & < 0\n-2^{N-1}  & B & < 0\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n-2^N  & C & < 0\n{eqnarray*}\n\nGiven that an overflow has occurred, C must fall outside of the \nrepresentable range.  Given that C<0, it cannot be larger than the\nlargest possible number representable using {N-bit} 2's\ncomplement, so we can write\n\n{eqnarray*}\n-2^N  & C & < -2^{N-1}\n{eqnarray*}\n\nWe now add 2^N to each part to obtain\n\n{eqnarray*}\n0  & C + 2^N & < 2^{N-1}\n{eqnarray*}\n\nThis range of integers falls within the representable range \nfor {N-bit} 2's complement, so we can replace the middle\nexpression with S (equal to C modulo 2^N) to find that\n\n{eqnarray*}\n0  & S & < 2^{N-1}\n{eqnarray*}\n\nThus, if we have an overflow and both A<0 and B<0, the resulting\nsum S, and condition 1 holds.\n\nThe proof for the case in which we observe an overflow when \nboth operands are non-negative (A and B)\nis similar, and leads to condition 2.  We again begin with\ninequalities for A and B:\n\n{eqnarray*}\n0  & A & < 2^{N-1}\n0  & B & < 2^{N-1}\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n0  & C < & 2^N\n{eqnarray*}\n\nGiven that an overflow has occurred, C must fall outside of the \nrepresentable range.  Given that C{}0, it cannot be smaller than the\nsmallest possible number representable using {N-bit} 2's\ncomplement, so we can write\n\n{eqnarray*}\n2^{N-1}  & C & < 2^N\n{eqnarray*}\n\nWe now subtract 2^N to each part to obtain\n\n{eqnarray*}\n-2^{N-1}  & C - 2^N & < 0\n{eqnarray*}\n\nThis range of integers falls within the representable range \nfor {N-bit} 2's complement, so we can replace the middle\nexpression with S (equal to C modulo 2^N) to find that\n\n{eqnarray*}\n-2^{N-1}  & S & < 0\n{eqnarray*}\n\nThus, if we have an overflow and both A and B, the resulting\nsum S<0, and condition 2 holds.\n\nThus overflow implies either condition 1 or condition 2, completing our\nproof.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the definition of an overflow?\n2. What is the difference between an overflow and a carry?\n3. What is the difference between an overflow and a borrow?",
        "answers": "\n\n1. An overflow occurs when the result of an operation is too large to be represented within the allotted space.\n2. A carry occurs when an addition operation results in a value larger than the maximum value that can be represented by the allotted space. A borrow occurs when a subtraction operation results in a value smaller than the minimum value that can be represented by the allotted space.\n3. An overflow can occur as a result of an addition or subtraction operation, while a carry can only occur as a result of an addition operation, and a borrow can only occur as a result of a subtraction operation."
    },
    {
        "positive_ctxs": {
            "title": "Overflow for 2's Complement Addition",
            "text": "{Overflow for 2's Complement Addition}\n\nUnderstanding overflow for 2's complement addition is somewhat trickier,\nwhich is why the problem is a good one for you to think about on your\nown first.\n\nOur operands, A and B, are now two {N-bit} 2's complement numbers.\nThe {N-bit} 2's complement representation \ncan represent integers in the range [-2^{N-1},2^{N-1}-1].\n\nLet's start by ruling out a case that we can show never leads to overflow.\n\n{ Lemma:} \n\nAddition of two {N-bit} 2's complement numbers A and B\ndoes not overflow if one of the numbers is negative and the other is\nnot.\n\n{ Proof:}\n\nWe again make use of the constraints implied by the fact that A and B\nare represented as {N-bit} 2's complement values.  We can assume\n{ without loss of generality}{This common mathematical phrasing\nmeans that we are using a problem symmetry to cut down the length of the\nproof discussion.  In this case, the names A and B aren't particularly\nimportant, since addition is commutative (A+B=B+A).  Thus the proof\nfor the case in which A is negative (and B is not) is identical to the\ncase in which B is negative (and A is not), except that all of the \nnames are swapped.  The term ``without loss of generality'' means that\nwe consider the proof complete even with additional assumptions, in\nour case that A<0 and B.}, or { w.l.o.g.}, \nthat A<0 and B.\n\nCombining these constraints with the range representable \nby {N-bit} 2's complement, we obtain\n\n{eqnarray*}\n-2^{N-1}  & A & < 0\n0  & B & < 2^{N-1}\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n-2^{N-1}  & C & < 2^{N-1}\n{eqnarray*}\n\nBut anything in the range specified by this inequality can be represented\nwith {N-bit} 2's complement, and thus the addition does not overflow.\n\n\nWe are now ready to state our main theorem.  For convenience, \nlet's use different names for the actual sum C=A+B and the sum S\nreturned from the add unit.  We define S as the number represented by\nthe bit pattern produced by the add unit.  When overflow \noccurs, S=C, but we always have (S=C)  2^N.\n\n{ Theorem:} \n\nAddition of two {N-bit} 2's complement numbers A and B\noverflows if and only if one of the following conditions holds:\n\n{A<0 and B<0 and S}\n{A and B and S<0}\n\n\n{ Proof:}\n\nWe once again start with the ``if'' direction.  That is, if condition 1 \nor condition 2 holds, we have an overflow.  The proofs are straightforward.\nGiven condition 1, we can add the two inequalities A<0 and B<0 to \nobtain C=A+B<0.  But S, so clearly S=C, thus overflow \nhas occurred.\n\nSimilarly, if condition 2 holds, we can add the inequalities A\nand B to obtain C=A+B.  Here we have S<0, so again\nS=C, and we have an overflow.\n\nWe must now prove the ``only if'' direction, showing that any overflow\nimplies either condition 1 or condition 2.  By the \n{ contrapositive}{If we have a statement of the form\n(p implies q), its contrapositive is the \nstatement (not q implies not p).\nBoth statements have the same truth value.  In this case, we can turn\nour Lemma around as stated.} of our\nLemma, we know that if an overflow occurs, either both operands are \nnegative, or they are both positive.\n\n\n\n\n\nLet's start with the case in which both operands are negative, so A<0\nand B<0, and thus the real sum C<0 as well.  Given that A and B\nare represented as {N-bit} 2's complement, they must fall in\nthe representable range, so we can write\n\n{eqnarray*}\n-2^{N-1}  & A & < 0\n-2^{N-1}  & B & < 0\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n-2^N  & C & < 0\n{eqnarray*}\n\nGiven that an overflow has occurred, C must fall outside of the \nrepresentable range.  Given that C<0, it cannot be larger than the\nlargest possible number representable using {N-bit} 2's\ncomplement, so we can write\n\n{eqnarray*}\n-2^N  & C & < -2^{N-1}\n{eqnarray*}\n\nWe now add 2^N to each part to obtain\n\n{eqnarray*}\n0  & C + 2^N & < 2^{N-1}\n{eqnarray*}\n\nThis range of integers falls within the representable range \nfor {N-bit} 2's complement, so we can replace the middle\nexpression with S (equal to C modulo 2^N) to find that\n\n{eqnarray*}\n0  & S & < 2^{N-1}\n{eqnarray*}\n\nThus, if we have an overflow and both A<0 and B<0, the resulting\nsum S, and condition 1 holds.\n\nThe proof for the case in which we observe an overflow when \nboth operands are non-negative (A and B)\nis similar, and leads to condition 2.  We again begin with\ninequalities for A and B:\n\n{eqnarray*}\n0  & A & < 2^{N-1}\n0  & B & < 2^{N-1}\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n0  & C < & 2^N\n{eqnarray*}\n\nGiven that an overflow has occurred, C must fall outside of the \nrepresentable range.  Given that C{}0, it cannot be smaller than the\nsmallest possible number representable using {N-bit} 2's\ncomplement, so we can write\n\n{eqnarray*}\n2^{N-1}  & C & < 2^N\n{eqnarray*}\n\nWe now subtract 2^N to each part to obtain\n\n{eqnarray*}\n-2^{N-1}  & C - 2^N & < 0\n{eqnarray*}\n\nThis range of integers falls within the representable range \nfor {N-bit} 2's complement, so we can replace the middle\nexpression with S (equal to C modulo 2^N) to find that\n\n{eqnarray*}\n-2^{N-1}  & S & < 0\n{eqnarray*}\n\nThus, if we have an overflow and both A and B, the resulting\nsum S<0, and condition 2 holds.\n\nThus overflow implies either condition 1 or condition 2, completing our\nproof.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the definition of an overflow?\n2. What is the difference between an overflow and a carry?\n3. What is the difference between an overflow and a borrow?",
        "answers": "\n\n1. An overflow occurs when the result of an operation is too large to be represented within the allotted space.\n2. A carry occurs when an addition operation results in a value larger than the maximum value that can be represented by the allotted space. A borrow occurs when a subtraction operation results in a value smaller than the minimum value that can be represented by the allotted space.\n3. An overflow can occur as a result of an addition or subtraction operation, while a carry can only occur as a result of an addition operation, and a borrow can only occur as a result of a subtraction operation."
    },
    {
        "positive_ctxs": {
            "title": "Overflow for 2's Complement Addition",
            "text": "{Overflow for 2's Complement Addition}\n\nUnderstanding overflow for 2's complement addition is somewhat trickier,\nwhich is why the problem is a good one for you to think about on your\nown first.\n\nOur operands, A and B, are now two {N-bit} 2's complement numbers.\nThe {N-bit} 2's complement representation \ncan represent integers in the range [-2^{N-1},2^{N-1}-1].\n\nLet's start by ruling out a case that we can show never leads to overflow.\n\n{ Lemma:} \n\nAddition of two {N-bit} 2's complement numbers A and B\ndoes not overflow if one of the numbers is negative and the other is\nnot.\n\n{ Proof:}\n\nWe again make use of the constraints implied by the fact that A and B\nare represented as {N-bit} 2's complement values.  We can assume\n{ without loss of generality}{This common mathematical phrasing\nmeans that we are using a problem symmetry to cut down the length of the\nproof discussion.  In this case, the names A and B aren't particularly\nimportant, since addition is commutative (A+B=B+A).  Thus the proof\nfor the case in which A is negative (and B is not) is identical to the\ncase in which B is negative (and A is not), except that all of the \nnames are swapped.  The term ``without loss of generality'' means that\nwe consider the proof complete even with additional assumptions, in\nour case that A<0 and B.}, or { w.l.o.g.}, \nthat A<0 and B.\n\nCombining these constraints with the range representable \nby {N-bit} 2's complement, we obtain\n\n{eqnarray*}\n-2^{N-1}  & A & < 0\n0  & B & < 2^{N-1}\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n-2^{N-1}  & C & < 2^{N-1}\n{eqnarray*}\n\nBut anything in the range specified by this inequality can be represented\nwith {N-bit} 2's complement, and thus the addition does not overflow.\n\n\nWe are now ready to state our main theorem.  For convenience, \nlet's use different names for the actual sum C=A+B and the sum S\nreturned from the add unit.  We define S as the number represented by\nthe bit pattern produced by the add unit.  When overflow \noccurs, S=C, but we always have (S=C)  2^N.\n\n{ Theorem:} \n\nAddition of two {N-bit} 2's complement numbers A and B\noverflows if and only if one of the following conditions holds:\n\n{A<0 and B<0 and S}\n{A and B and S<0}\n\n\n{ Proof:}\n\nWe once again start with the ``if'' direction.  That is, if condition 1 \nor condition 2 holds, we have an overflow.  The proofs are straightforward.\nGiven condition 1, we can add the two inequalities A<0 and B<0 to \nobtain C=A+B<0.  But S, so clearly S=C, thus overflow \nhas occurred.\n\nSimilarly, if condition 2 holds, we can add the inequalities A\nand B to obtain C=A+B.  Here we have S<0, so again\nS=C, and we have an overflow.\n\nWe must now prove the ``only if'' direction, showing that any overflow\nimplies either condition 1 or condition 2.  By the \n{ contrapositive}{If we have a statement of the form\n(p implies q), its contrapositive is the \nstatement (not q implies not p).\nBoth statements have the same truth value.  In this case, we can turn\nour Lemma around as stated.} of our\nLemma, we know that if an overflow occurs, either both operands are \nnegative, or they are both positive.\n\n\n\n\n\nLet's start with the case in which both operands are negative, so A<0\nand B<0, and thus the real sum C<0 as well.  Given that A and B\nare represented as {N-bit} 2's complement, they must fall in\nthe representable range, so we can write\n\n{eqnarray*}\n-2^{N-1}  & A & < 0\n-2^{N-1}  & B & < 0\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n-2^N  & C & < 0\n{eqnarray*}\n\nGiven that an overflow has occurred, C must fall outside of the \nrepresentable range.  Given that C<0, it cannot be larger than the\nlargest possible number representable using {N-bit} 2's\ncomplement, so we can write\n\n{eqnarray*}\n-2^N  & C & < -2^{N-1}\n{eqnarray*}\n\nWe now add 2^N to each part to obtain\n\n{eqnarray*}\n0  & C + 2^N & < 2^{N-1}\n{eqnarray*}\n\nThis range of integers falls within the representable range \nfor {N-bit} 2's complement, so we can replace the middle\nexpression with S (equal to C modulo 2^N) to find that\n\n{eqnarray*}\n0  & S & < 2^{N-1}\n{eqnarray*}\n\nThus, if we have an overflow and both A<0 and B<0, the resulting\nsum S, and condition 1 holds.\n\nThe proof for the case in which we observe an overflow when \nboth operands are non-negative (A and B)\nis similar, and leads to condition 2.  We again begin with\ninequalities for A and B:\n\n{eqnarray*}\n0  & A & < 2^{N-1}\n0  & B & < 2^{N-1}\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n0  & C < & 2^N\n{eqnarray*}\n\nGiven that an overflow has occurred, C must fall outside of the \nrepresentable range.  Given that C{}0, it cannot be smaller than the\nsmallest possible number representable using {N-bit} 2's\ncomplement, so we can write\n\n{eqnarray*}\n2^{N-1}  & C & < 2^N\n{eqnarray*}\n\nWe now subtract 2^N to each part to obtain\n\n{eqnarray*}\n-2^{N-1}  & C - 2^N & < 0\n{eqnarray*}\n\nThis range of integers falls within the representable range \nfor {N-bit} 2's complement, so we can replace the middle\nexpression with S (equal to C modulo 2^N) to find that\n\n{eqnarray*}\n-2^{N-1}  & S & < 0\n{eqnarray*}\n\nThus, if we have an overflow and both A and B, the resulting\nsum S<0, and condition 2 holds.\n\nThus overflow implies either condition 1 or condition 2, completing our\nproof.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the definition of an overflow?\n2. What is the difference between an overflow and a carry?\n3. What is the difference between an overflow and a borrow?",
        "answers": "\n\n1. An overflow occurs when the result of an operation is too large to be represented within the allotted space.\n2. A carry occurs when an addition operation results in a value larger than the maximum value that can be represented by the allotted space. A borrow occurs when a subtraction operation results in a value smaller than the minimum value that can be represented by the allotted space.\n3. An overflow can occur as a result of an addition or subtraction operation, while a carry can only occur as a result of an addition operation, and a borrow can only occur as a result of a subtraction operation."
    },
    {
        "positive_ctxs": {
            "title": "Overflow for 2's Complement Addition",
            "text": "{Overflow for 2's Complement Addition}\n\nUnderstanding overflow for 2's complement addition is somewhat trickier,\nwhich is why the problem is a good one for you to think about on your\nown first.\n\nOur operands, A and B, are now two {N-bit} 2's complement numbers.\nThe {N-bit} 2's complement representation \ncan represent integers in the range [-2^{N-1},2^{N-1}-1].\n\nLet's start by ruling out a case that we can show never leads to overflow.\n\n{ Lemma:} \n\nAddition of two {N-bit} 2's complement numbers A and B\ndoes not overflow if one of the numbers is negative and the other is\nnot.\n\n{ Proof:}\n\nWe again make use of the constraints implied by the fact that A and B\nare represented as {N-bit} 2's complement values.  We can assume\n{ without loss of generality}{This common mathematical phrasing\nmeans that we are using a problem symmetry to cut down the length of the\nproof discussion.  In this case, the names A and B aren't particularly\nimportant, since addition is commutative (A+B=B+A).  Thus the proof\nfor the case in which A is negative (and B is not) is identical to the\ncase in which B is negative (and A is not), except that all of the \nnames are swapped.  The term ``without loss of generality'' means that\nwe consider the proof complete even with additional assumptions, in\nour case that A<0 and B.}, or { w.l.o.g.}, \nthat A<0 and B.\n\nCombining these constraints with the range representable \nby {N-bit} 2's complement, we obtain\n\n{eqnarray*}\n-2^{N-1}  & A & < 0\n0  & B & < 2^{N-1}\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n-2^{N-1}  & C & < 2^{N-1}\n{eqnarray*}\n\nBut anything in the range specified by this inequality can be represented\nwith {N-bit} 2's complement, and thus the addition does not overflow.\n\n\nWe are now ready to state our main theorem.  For convenience, \nlet's use different names for the actual sum C=A+B and the sum S\nreturned from the add unit.  We define S as the number represented by\nthe bit pattern produced by the add unit.  When overflow \noccurs, S=C, but we always have (S=C)  2^N.\n\n{ Theorem:} \n\nAddition of two {N-bit} 2's complement numbers A and B\noverflows if and only if one of the following conditions holds:\n\n{A<0 and B<0 and S}\n{A and B and S<0}\n\n\n{ Proof:}\n\nWe once again start with the ``if'' direction.  That is, if condition 1 \nor condition 2 holds, we have an overflow.  The proofs are straightforward.\nGiven condition 1, we can add the two inequalities A<0 and B<0 to \nobtain C=A+B<0.  But S, so clearly S=C, thus overflow \nhas occurred.\n\nSimilarly, if condition 2 holds, we can add the inequalities A\nand B to obtain C=A+B.  Here we have S<0, so again\nS=C, and we have an overflow.\n\nWe must now prove the ``only if'' direction, showing that any overflow\nimplies either condition 1 or condition 2.  By the \n{ contrapositive}{If we have a statement of the form\n(p implies q), its contrapositive is the \nstatement (not q implies not p).\nBoth statements have the same truth value.  In this case, we can turn\nour Lemma around as stated.} of our\nLemma, we know that if an overflow occurs, either both operands are \nnegative, or they are both positive.\n\n\n\n\n\nLet's start with the case in which both operands are negative, so A<0\nand B<0, and thus the real sum C<0 as well.  Given that A and B\nare represented as {N-bit} 2's complement, they must fall in\nthe representable range, so we can write\n\n{eqnarray*}\n-2^{N-1}  & A & < 0\n-2^{N-1}  & B & < 0\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n-2^N  & C & < 0\n{eqnarray*}\n\nGiven that an overflow has occurred, C must fall outside of the \nrepresentable range.  Given that C<0, it cannot be larger than the\nlargest possible number representable using {N-bit} 2's\ncomplement, so we can write\n\n{eqnarray*}\n-2^N  & C & < -2^{N-1}\n{eqnarray*}\n\nWe now add 2^N to each part to obtain\n\n{eqnarray*}\n0  & C + 2^N & < 2^{N-1}\n{eqnarray*}\n\nThis range of integers falls within the representable range \nfor {N-bit} 2's complement, so we can replace the middle\nexpression with S (equal to C modulo 2^N) to find that\n\n{eqnarray*}\n0  & S & < 2^{N-1}\n{eqnarray*}\n\nThus, if we have an overflow and both A<0 and B<0, the resulting\nsum S, and condition 1 holds.\n\nThe proof for the case in which we observe an overflow when \nboth operands are non-negative (A and B)\nis similar, and leads to condition 2.  We again begin with\ninequalities for A and B:\n\n{eqnarray*}\n0  & A & < 2^{N-1}\n0  & B & < 2^{N-1}\n{eqnarray*}\n\nWe add these two inequalities and replace A+B with C to obtain\n\n{eqnarray*}\n0  & C < & 2^N\n{eqnarray*}\n\nGiven that an overflow has occurred, C must fall outside of the \nrepresentable range.  Given that C{}0, it cannot be smaller than the\nsmallest possible number representable using {N-bit} 2's\ncomplement, so we can write\n\n{eqnarray*}\n2^{N-1}  & C & < 2^N\n{eqnarray*}\n\nWe now subtract 2^N to each part to obtain\n\n{eqnarray*}\n-2^{N-1}  & C - 2^N & < 0\n{eqnarray*}\n\nThis range of integers falls within the representable range \nfor {N-bit} 2's complement, so we can replace the middle\nexpression with S (equal to C modulo 2^N) to find that\n\n{eqnarray*}\n-2^{N-1}  & S & < 0\n{eqnarray*}\n\nThus, if we have an overflow and both A and B, the resulting\nsum S<0, and condition 2 holds.\n\nThus overflow implies either condition 1 or condition 2, completing our\nproof.\n\n\n\n\n\n"
        },
        "questions": "\n1. What is the definition of an overflow?\n2. What is the difference between an overflow and a carry?\n3. What is the difference between an overflow and a borrow?",
        "answers": "\n\n1. An overflow occurs when the result of an operation is too large to be represented within the allotted space.\n2. A carry occurs when an addition operation results in a value larger than the maximum value that can be represented by the allotted space. A borrow occurs when a subtraction operation results in a value smaller than the minimum value that can be represented by the allotted space.\n3. An overflow can occur as a result of an addition or subtraction operation, while a carry can only occur as a result of an addition operation, and a borrow can only occur as a result of a subtraction operation."
    }
]