{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO :\n",
    "1. Alter prompt (use 4 or 5 shot prompting to make it follow the pattern)\n",
    "2. Final output formatting - first question and final answer QA pair\n",
    "3. Metaprompting techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "import json\n",
    "import transformers\n",
    "from transformers import GPT2Tokenizer\n",
    "import backoff\n",
    "from openai.error import RateLimitError\n",
    "import datetime\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import os\n",
    "from serpapi import GoogleSearch\n",
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        return infile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key =  #openai key\n",
    "serpapi_key = #serpapi key\n",
    "openai.api_key =api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_embedding(content, model='text-similarity-ada-001'):\n",
    "    try:\n",
    "        response = openai.Embedding.create(input=content, model=model)\n",
    "    except openai.error.APIConnectionError:\n",
    "        print(\"Failed\") \n",
    "    return response['data'][0]['embedding'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute cosine similarity\n",
    "def get_similarity(v1, v2):\n",
    "    cosine = np.dot(v1, v2)/(norm(v1)*norm(v2))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching through textbook \n",
    "def search_index(query, data, count=1):\n",
    "    question_vector = gpt3_embedding(query)\n",
    "    scores = []\n",
    "    for i in data:\n",
    "        score = get_similarity(question_vector, i['vector'])\n",
    "        scores.append({'content' : i['content'], 'score' : score})\n",
    "    most_relevant= sorted(scores, key=lambda d: d['score'], reverse=True)\n",
    "    return most_relevant[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, RateLimitError)\n",
    "def response_API(prompt, myKwargs = {}):\n",
    "\n",
    "  #default arguments to send the API, unless changed in function\n",
    "  kwargs = {\"model\" :\"text-davinci-002\",\n",
    "            \"temperature\" :0.7,\n",
    "            \"max_tokens\": 300,\n",
    "            \"best_of\" :5,\n",
    "            \"n\" :3,\n",
    "            \"top_p\" : 1,\n",
    "            \"stop\" : '\\n\\n\\n',\n",
    "            \"presence_penalty\" : 0}\n",
    "\n",
    "\n",
    "  for kwarg in myKwargs:\n",
    "    kwargs[kwarg] = myKwargs[kwarg]\n",
    "\n",
    "  r = openai.Completion.create(prompt=prompt, **kwargs)\n",
    "  return r['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_completions_with_backoff(passages): \n",
    "       \n",
    "    question_prompts = ['''Generate 5 interactive and coherent questions about this context. The questions should not be repeated from the previous step. The questions should consist of reasoning and procedural steps. \\n\n",
    "                        The questions should be precise and factual. Start the question with a '[Q]' ''',\n",
    "                        \n",
    "                        '''Generate 5 objective, concise and firm questions about this context. The questions should not be repeated from the previous step. \\n\n",
    "                        The questions should begin with any of Why/How/Where/Who/When. Start the question with a '[Q]' ''' ,\n",
    "                        \n",
    "                        '''Generate 5 thoughtful and compelling, steps-based procedural questions about this context that start with Why or How. The questions should not be repeated from the previous step. \\n\n",
    "                        The questions should be unique and creative with an abstract and subjective aspect. Start the question with a '[Q]' ''' ]\n",
    "    \n",
    "    n=len(question_prompts)\n",
    "    questions = []\n",
    "    for p in passages:\n",
    "        for j in question_prompts:\n",
    "                #prompt_tokens = calculate_tokens(j)\n",
    "                #context_tokens = calculate_tokens(p)\n",
    "                #max_tokens = 300\n",
    "                \n",
    "                #while(max_tokens+prompt_tokens+context_tokens < 4096):\n",
    "                prompt= \"%s \\n %s\" % (j, p)\n",
    "    \n",
    "                response = response_API(prompt)\n",
    "                \n",
    "                questions.append(response)\n",
    "                print(response)\n",
    "                      \n",
    "    question_list = [questions[i:i + n] for i in range(0, len(questions), n)]\n",
    "    \n",
    "    return question_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, data):\n",
    "    #most relevant passages\n",
    "    result = search_index(question, data) #get most relevant passages where answer could be\n",
    "    prompt = \"PASSAGE - %s \\n QUESTION - %s \\nAnswer this question in 2-3 concise sentences based on the passage. Be objective in the answer given and explain in a few lines only.\\n\" % (result['content'], question)\n",
    "    answer = response_API(prompt)\n",
    "    print(answer)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_answer(question):\n",
    "    params = {\n",
    "    \"api_key\": serpapi_key,\n",
    "    \"engine\": \"google\",\n",
    "    \"q\": question,\n",
    "    \"google_domain\": \"google.com\",\n",
    "    \"gl\": \"us\",\n",
    "    \"hl\": \"en\"\n",
    "    }\n",
    "\n",
    "\n",
    "    with io.capture_output() as captured: #disables prints from GoogleSearch\n",
    "        search = GoogleSearch(params)\n",
    "        res = search.get_dict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if 'answer_box' in res.keys() and 'answer' in res['answer_box'].keys():\n",
    "        toret = res['answer_box']['answer']\n",
    "    elif 'answer_box' in res.keys() and 'snippet' in res['answer_box'].keys():\n",
    "        toret = res['answer_box']['snippet']\n",
    "    elif 'answer_box' in res.keys() and 'snippet_highlighted_words' in res['answer_box'].keys():\n",
    "        toret = res['answer_box'][\"snippet_highlighted_words\"][0]\n",
    "    elif 'snippet' in res[\"organic_results\"][0].keys():\n",
    "        toret= res[\"organic_results\"][0]['snippet'] \n",
    "    else:\n",
    "        toret = None\n",
    "    return toret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(generated):\n",
    "    if '\\n' not in generated:\n",
    "        last_line =  generated\n",
    "    else: \n",
    "        last_line = generated.split('\\n')[-1]\n",
    "\n",
    "    if ':' not in last_line:\n",
    "        after_colon = last_line\n",
    "    else:\n",
    "        after_colon = generated.split(':')[-1]\n",
    "    \n",
    "    if ' ' == after_colon[0]:\n",
    "        after_colon = after_colon[1:]\n",
    "    if '.' == after_colon[-1]:\n",
    "        after_colon = after_colon[:-1]\n",
    "\n",
    "    return after_colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_question(generated):\n",
    "    if '\\n' not in generated:\n",
    "        last_line =  generated\n",
    "    else: \n",
    "        last_line = generated.split('\\n')[-1]\n",
    "\n",
    "    if 'Follow up:' not in last_line:\n",
    "      print('we probably should never get here...' + generated)\n",
    "\n",
    "    if ':' not in last_line:\n",
    "        after_colon = last_line\n",
    "    else:\n",
    "        after_colon = generated.split(':')[-1]\n",
    "    \n",
    "    if ' ' == after_colon[0]:\n",
    "        after_colon = after_colon[1:]\n",
    "    if '?' != after_colon[-1]:\n",
    "        print('we probably should never get here...' + generated)\n",
    "        \n",
    "    return after_colon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_line(generated):\n",
    "    if '\\n' not in generated:\n",
    "        last_line =  generated\n",
    "    else: \n",
    "        last_line = generated.split('\\n')[-1]\n",
    "\n",
    "\n",
    "    return last_line\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "directory = '../../notes'\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if not os.path.isfile(f):\n",
    "        for fn in os.listdir(f):\n",
    "            notes.append(f+'/'+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sections data\n",
    "'../../split_textbook/sections.json'\n",
    "s = open('../../split_textbook/sections.json')\n",
    "sections_data = json.load(s)\n",
    "\n",
    "#full textbook embeddings - vectors\n",
    "with open(\"../index.json\") as input_file:\n",
    "    data = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of only texts from the json file\n",
    "sections_list = list(sections_data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = open(\"GPT-3_semantic_search.json\")\n",
    "semantic_search_data = json.load(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for s in range(len(semantic_search_data)):\n",
    "    q = semantic_search_data[s]['GPT-3-Semantic-Search-Generations']['question']\n",
    "    questions.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: What is the design process for a digital FSM?\n",
    "# Are follow up questions needed here: Yes.\n",
    "# Follow up: What are the steps in the design process?\n",
    "# Intermediate answer: The steps in the design process are: develop an abstract model, specify I/O behavior, complete the specification, choose a state representation, calculate logic expressions, and implement with flip-flops and gates.\n",
    "# So the final answer is: develop an abstract model, specify I/O behavior, complete the specification, choose a state representation, calculate logic expressions, and implement with flip-flops and gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ['''Question: What is the output of a Gray code counter?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: What is the output of a three-bit Gray code counter?\n",
    "Intermediate answer: The output of a three-bit Gray code counter is a sequence of three-bit values that differ by only one bit.\n",
    "Follow up: What is the output of a two-bit Gray code counter?\n",
    "Intermediate answer: The output of a two-bit Gray code counter is a sequence of two-bit values that differ by only one bit.\n",
    "So the final answer is: a sequence of values that differ by only one bit.\n",
    "\n",
    "Question: How many transistors does an N-input gate require?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: How many inputs does a 2-input gate have?\n",
    "Intermediate answer: A 2-input gate has 2 inputs.\n",
    "Follow up: How many inputs does a 10-input gate have?\n",
    "Intermediate answer: A 10-input gate has 10 inputs.\n",
    "So the final answer is: a 2-input gate requires roughly 2 transistors, and a 10-input gate requires roughly 10 transistors.\n",
    "\n",
    "Question: ''', \n",
    "'''\n",
    "Are follow up questions needed here:''', ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ['''Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: How old was Muhammad Ali when he died?\n",
    "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
    "Follow up: How old was Alan Turing when he died?\n",
    "Intermediate answer: Alan Turing was 41 years old when he died.\n",
    "So the final answer is: Muhammad Ali \n",
    "\n",
    "Question: When was the founder of craigslist born?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the founder of craigslist?\n",
    "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
    "Follow up: When was Craig Newmark born?\n",
    "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
    "So the final answer is: December 6, 1952\n",
    "\n",
    "Question: Who was the maternal grandfather of George Washington?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the mother of George Washington?\n",
    "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
    "Follow up: Who was the father of Mary Ball Washington?\n",
    "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
    "So the final answer is: Joseph Ball \n",
    "\n",
    "Question: Are both the directors of Jaws and Casino Royale from the same country? \n",
    "Are follow up questions needed here: Yes. \n",
    "Follow up: Who is the director of Jaws? \n",
    "Intermediate Answer: The director of Jaws is Steven Spielberg. \n",
    "Follow up: Where is Steven Spielberg from? \n",
    "Intermediate Answer: The United States. \n",
    "Follow up: Who is the director of Casino Royale? \n",
    "Intermediate Answer: The director of Casino Royale is Martin Campbell. \n",
    "Follow up: Where is Martin Campbell from? \n",
    "Intermediate Answer: New Zealand. \n",
    "So the final answer is: No\n",
    "\n",
    "Question: ''', \n",
    "'''\n",
    "Are follow up questions needed here:''', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate = \"\\nIntermediate answer:\"\n",
    "followup = \"Follow up:\"\n",
    "finalans= '\\nSo the final answer is:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the output of a Gray code counter?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: What is the output of a three-bit Gray code counter?\n",
      "Intermediate answer: The output of a three-bit Gray code counter is a sequence of three-bit values that differ by only one bit.\n",
      "Follow up: What is the output of a two-bit Gray code counter?\n",
      "Intermediate answer: The output of a two-bit Gray code counter is a sequence of two-bit values that differ by only one bit.\n",
      "So the final answer is: a sequence of values that differ by only one bit.\n",
      "\n",
      "Question: How many transistors does an N-input gate require?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How many inputs does a 2-input gate have?\n",
      "Intermediate answer: A 2-input gate has 2 inputs.\n",
      "Follow up: How many inputs does a 10-input gate have?\n",
      "Intermediate answer: A 10-input gate has 10 inputs.\n",
      "So the final answer is: a 2-input gate requires roughly 2 transistors, and a 10-input gate requires roughly 10 transistors.\n",
      "\n",
      "Question:  How is a digital FSM designed from an abstract model?\\n\n",
      "Are follow up questions needed here:"
     ]
    }
   ],
   "source": [
    "cur_prompt = prompt[0] +  questions[10] + prompt[1]\n",
    "\n",
    "print(cur_prompt, end ='')\n",
    "\n",
    "ret_text = response_API(cur_prompt, myKwargs = {\"stop\" : intermediate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "So the final answer is:Question: What is the output of a Gray code counter?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: What is the output of a three-bit Gray code counter?\n",
      "Intermediate answer: The output of a three-bit Gray code counter is a sequence of three-bit values that differ by only one bit.\n",
      "Follow up: What is the output of a two-bit Gray code counter?\n",
      "Intermediate answer: The output of a two-bit Gray code counter is a sequence of two-bit values that differ by only one bit.\n",
      "So the final answer is: a sequence of values that differ by only one bit.\n",
      "\n",
      "Question: How many transistors does an N-input gate require?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How many inputs does a 2-input gate have?\n",
      "Intermediate answer: A 2-input gate has 2 inputs.\n",
      "Follow up: How many inputs does a 10-input gate have?\n",
      "Intermediate answer: A 10-input gate has 10 inputs.\n",
      "So the final answer is: a 2-input gate requires roughly 2 transistors, and a 10-input gate requires roughly 10 transistors.\n",
      "\n",
      "Question:  How is a digital FSM designed from an abstract model?\\n\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: What is an abstract model?\n",
      "Intermediate answer: \n",
      "An abstract model is a simplified representation of a complex system. It is usually used to help understand the system, or to make predictions about its behavior..\n",
      "So the final answer is:\n",
      "So the final answer is: A digital FSM is designed from an abstract model by creating a simplified representation of the system. This representation is used to help understand the system, or to make predictions about its behavior.\n"
     ]
    }
   ],
   "source": [
    "while followup in get_last_line(ret_text):\n",
    "      \n",
    "      cur_prompt += ret_text\n",
    "      question = extract_question(ret_text)\n",
    "      external_answer = get_google_answer(question)\n",
    "\n",
    "      if external_answer is not None:\n",
    "        cur_prompt += intermediate + ' ' + str(external_answer) + '.'\n",
    "        print(intermediate + ' ' + external_answer + '.', end='' )\n",
    "        ret_text = response_API(cur_prompt, myKwargs = {\"stop\" : intermediate})\n",
    "      else:\n",
    "        #We only get here in the very rare case that Google returns no answer.\n",
    "        cur_prompt += intermediate\n",
    "        print(intermediate + ' ')\n",
    "        gpt_answer = response_API(cur_prompt, myKwargs = {\"stop\" : '\\n'+followup})\n",
    "        cur_prompt += gpt_answer\n",
    "    \n",
    "if finalans not in ret_text:\n",
    "  cur_prompt += finalans\n",
    "  print(finalans, end = '')\n",
    "  ret_text = response_API(cur_prompt, myKwargs = {\"stop\" : '\\n'})\n",
    "\n",
    "  print(cur_prompt + ret_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28596858067060ee176f7bab50a17c769bfd8a96306468e7ae0695529617abaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
