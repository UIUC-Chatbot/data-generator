{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS workes just run all cells (when first pushed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using spacy <br>\n",
    "```\n",
    "conda install -c conda-forge spacy\n",
    "conda install -c conda-forge cupy\n",
    "python -m spacy download en_core_web_trf\n",
    "\n",
    "pip install langchain pinecone-client PyPDF2\n",
    "# maybe: conda install -c conda-forge -y ipykernel=6\n",
    "# maybe: conda install -c anaconda -y notebook\n",
    "```\n",
    "\n",
    "Note: \n",
    "* Flan T5 XL max length is 512\n",
    "* Flan T5 XXL max length is 1024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ECE120-2016-10-28-LEC-27-slides.mp4': \" stuff and a little bit of philosophical prattle to start off. One clarification too that's worthwhile from last lecture. Then we'll dive into von Neumann model and then look at LC3 as a von Neumann machine. And then I think we will manage to get through most, if not all of this instruction format stuff. After that on Monday, we'll start talking about instruction processing. I suppose there's some small chance we may get to that today. So before I do the clarification, do this. So if you're feeling now after having gotten your midterm back, you know, my TA, if I hadn't had this TA, I'd have gotten half the score. Then nominate them. Even if you don't feel that way, nominate them. Because you should be proud to be in 120. Otherwise the 210 TAs will win or the 2310 or some people like that. They just don't deserve it. Our TAs should win. I mean, they're good, but they're not as good as ours. So seriously, I mean, unless you feel strongly and you don't want to do it, at least think about it. Because we have some good TAs and it's nice for them to get the award. The award is something like a couple thousand dollars. Sometimes I don't know if they split it if they give it to two people. They have given it to two people sometimes or if they give them each 2,000. But it's a pretty nice chunk of money for a TA and more importantly, nice recognition for a job well done. So please do consider nominating them. I won't actually start teaching and take Ticto Code, even if you don't. But I may track whether you nominate them. I'm kidding. All right. So I want to make one. Oh, shoot. Sorry, I left this animation in. I wanted to make one clarification about this stuff. So I realized after talking to a couple of people after class that these RTL, these remember are FSM outputs, but they go to the data path. So the data path is basically all clocked logic. It's the components. So these actions happen at the rising edge of the clock. So the actions take effect in the next clock cycle. So there's a little bit of difference from how we wrote the state tables before because there we would have external outputs listed against each state. Whereas these actions are actually not external outputs, but outputs from the FSM to the data path. And so they take effect not in the current cycle. They're not outputs that are visible externally, but they're actually outputs that control the action of the data path. And so they take effect in the next clock cycle. So I know there's a little bit of confusion about that. For example, how when we get into the compare state, how count is equal to zero. Well that's because we set it to zero here and then in the next cycle when we're in the compare state, then count starts at zero and then starts counting. So sorry about that confusion. Just wanted to make sure it was clear for everyone before we move forward. Because we'll use the same kind of notation in the LC3 finite state machine and it'll have the same meaning that in a particular state, when you say the RTL for that state is such and such, that RTL will not actually happen effectively until the rising clock edge at which point you're in the next state. So just bear that in mind in terms of the meaning and the timing. And someone I think asked me, so why would I want to give you a hard problem to do? So I wanted to answer that. So this is just philosophy. So you seem surprised that I'd want to give you a hard problem. Not really on an exam. I mean exams are timed. I don't care if you can do it fast. So here's another problem. So write an assembler in C for the LC3. So take assembly code, which you haven't really seen much of. So I wanted to come up with some problems that maybe you can think about how hard they'd be. So write an assembler. You're seeing it in the lab now if you've played with the lab. And that assembler can take LC3 assembly code and actually do the encoding. So after a few weeks of assembly and a few weeks of C. You think you'd do that? Here's another one. A couple more. So how about a simulator? So how many of you played with LC3 in the lab? OK, so a few of you. So you write that simulator. Same few weeks of C. Seem good? Yeah? OK, good. I hope you think you can do this. Actually, I'm not sure if you think you can do this. You might think it's hard. So what about LC3 code generation? So the back end of a compiler. You do that, right? OK, so here's some quotes for you. So here's someone. This is Pete Sauer. So apparently, we faculty didn't realize that in order to win awards, we had to be nominated. So that was actually quite helpful. So they created this faculty awards committee. Turned out to be true. So it turns out also that if you don't try something, you can't do it. So it's probably not me. I'm sure there's someone more famous. Here's another quote. So this is my colleague, former colleague. Now she's at MIT. But we used to work together. We started here together. So what does she mean by that? So I would contend these things. I agree with her for the most part. So if you've never tried something that you couldn't succeed at, that your teacher or professor or whoever gave you the problem, you didn't know, OK, this is completely doable. I'll be able to do this in a certain amount of time. And it's on my homework. So of course, I'm going to be able to finish it by the end of the week. How are you going to know what you can do if you never try something that you're not sure if you can do it, not even sure if it's possible? No one else has done it before. So these things that I mentioned, those are about 1,000 lines of C code. This one, code generation, it's only a few hundred lines of C code. But it uses recursion. So usually, that's more complicated. So we put that after these. But those are real assignments. So in the old programming class, which is one semester, we give them a few weeks of assembly, a few weeks of C, then they'd have to do those things. And most students did them and did well and felt pretty happy. And they seem really hard at first. And people would be scared of them. And then they do them, and they think, wow, that's really cool. I can go build those tools I used at the beginning of the class to play with the LC3. So it was a sense of accomplishment. So all of you, as I told you at the start of the semester, you're all smart. You can all do incredible things in the world. So I suggest you try to solve hard problems. And sometimes you'll fail. So what? Sometimes you'll succeed. Sometimes you'll find out, oh, those aren't so hard after all. But you'll always learn. So that's why I want to give you that kind of problem. Because it's really not that hard. I thought of a couple of them. I might write one up. And then if you want to challenge yourself, you can. Actually, I'll just tell you, and then you can conceptualize it on your own. And then you can make whatever assumptions you want. There was one I was going to do in the LC3 data path. But you'd actually have to read ahead and learn some other stuff on your own first. But try to do like a microwave controller, right? Just 10 buttons, let's say. Set some time. Push Go. Run the microwave for a few minutes, whatever it says. Count it down. Show the display. Anyway, that's an idea. All right. So that was my philosophical prattling. So let's talk about von Neumann model. Hopefully you remember this diagram. So this is the seven layers, abstraction layers from Pat Patel chapter one. And so far, we've gone up to a few of these. I'll put an arrow on this in a second. But remember, up here is human language. And then we have software in green and hardware in blue. And so, so far, we've kind of worked up to how a computer works. We spent a week number three talking about the C programming language. But basically, now you're ready to see, you know, how does a computer actually work? So to remind you, the microarchitecture, this is the implementation. This is the thing that executes instructions from an ISA. So that's sort of the implementation of the computer. And that's going to look a lot like that finite state machine we designed. So it'll have a data path. It'll have a control unit, which is a finite state machine. And it'll execute instructions. So it'll look exactly like the thing we did on Monday and Wednesday. The core is an FSM. And then we're going to cover it kind of briefly. We'll go over it today and maybe on Monday a little bit more. And then we'll dive into the instructions. And then we'll talk about actually programming. At the start of the semester, when we talked about C, that was just so you could start using C, get familiar with the syntax, but not really how to program, right? Programming is breaking things down to the level that a computer can execute, which is pretty low level, pretty simple things. So we'll start thinking about that in the next few weeks. And above that is the ISA, the machine or instruction set architecture. So that's the interface between the green, the software, and the hardware in blue. Examples are things like x86, ARM, PowerPC. And we're going to follow Pat and Patel and develop this LC3 ISA. I'll tell you what that means in a few minutes. So in 1946, John von Neumann invented this model for computer organization. He said, well, here's how maybe we should be building our computing platforms, long before people had computers in their pockets and their desks and everything. So he said, well, it should have five parts. So one part is memory. So there's a memory. What's that memory look like? It's the same that you saw last week, right? So it's able to read or write every cycle, maybe take several cycles, but it's able to read or write. The computer's instructions on the program the computer is going to run, we're going to put into that memory. So that's part of the model. You could put it in a different memory. There were other models that had the program somewhere else, for example. But in the von Neumann model, the program and the data and everything will go in this one memory. So the memory is going to use two registers. So remember, we've got an address and we've got data. So we're going to use some registers to manage moving data in and out of the memory. And so we're going to have an address, memory address register associated with the memory. And that's just going to hold the address that we want the memory to read from or to write to. So there's what we call MAR, which is memory address register. And there's also what we call the MDR, memory data register. So when we want to do a write to memory, we'll put some bits in the MDR, and then we'll put the address in the MAR, and we'll say go. And the memory will store the bits from the MDR at MAR. And when we want to do a read, we will set the MAR to the address and say go. And the memory will put the bits from that memory location in MDR, and then we'll take them out of the register and do what we want with them. So that's how our memory will work in combination with these two registers just to help things move around in the data path. We're also going to have a processing unit. So the processing unit is going to do all the operations, and it's going to define what we call the word size. So you've probably heard, mostly probably about operating systems these days, but the underlying hardware also has a word size. So your processor might be a 64-bit processor or a 32-bit processor. Usually your laptop, your desktop are probably 64-bit processors. Your phone is probably a 32-bit processor. The processor in your watch might be 8 or 16 bits in terms of the word size. So what does that mean? Well, if it has an adder, if it has a multiplier, those are usually 8 or 16 or 32 bits. It depends on the word size. I'll show you some other pieces that will also usually depend on the word size. So typical word sizes are 32 and 64 bits, but you can go out and get small microcontroller chips that have still 8 and 16-bit word sizes. So inside the processing unit, we're going to again have two things. One will be what we call the arithmetic logic unit, or the ALU, and that'll do the work. It'll handle the operations like addition. If we have multiplication, we'll have that too. That's what operations we want the processor to be able to support. So we'll talk about that for LC3 later. The processing unit also has a register file. So the register file is going to have actually flip-flops, or registers. So it's not SRAM, it's actually registers. And that's basically going to just give us a place to put values temporarily. It'll be faster than the memory, faster even than SRAM, but it'll be smaller. So faster but smaller. So let me give you some details. So as I mentioned, it's going to use flip-flops, so they're actually on the same clock. So typically, you'll be able to read things out of the register file in one cycle. That's not usually going to be true for memory. Even SRAM, sometimes it's going to be slower than a cycle. So it's faster than SRAM, much faster than DRAM, but there's usually only 10 or 100 registers. Not quite. Cache is usually SRAM. And a cache is also not usually visible architecturally, meaning that from the writing of the program point of view, you don't know whether there's a cache or not. It's purely for implementation performance purposes. But let me give you an analogy. So you guys probably have your Pat and Patel sitting on your work desk in your apartment or your dorm or whatever. When you go back, you frequently need to do 120 work, and you probably got your boxed two or you didn't until this week, and it's right there next to you. That's kind of like the register file. You have very few things on your work desk, but those are the things you use a lot. You probably also maybe have a bookshelf. So you got your old calculus book or maybe your current calculus book. But some other things that you might want to look at once in a while, maybe even a dictionary. Well, I guess you do that online now. But you've got some things you don't use that often, but your desk is here and your bookshelf is there. And then probably most of you, I still have this stuff too, back at your parents' house, you probably have a room full of stuff. And that's where everything you've ever collected, you still have there. Takes a while to get there for most of us, but it's big. So that's kind of like the register file is your desk. The cache is sort of, it's not nameable, but it's sort of like your bookshelf. When you need things, things come off the shelf on your desk, you use them there. And then the memory is more like your parents' house. It takes a while to get out there. Actually hundreds of cycles sometimes to get to DRAM memory compared to a processor. So we have a memory hierarchy in most digital systems. And it's made up of the register file, SRAM, and DRAM. So the details of SRAM you'll learn in how it's used in caches, you'll learn in 4.11, if you take 4.11. So all right, so there are usually only tens or a hundred registers, again, for speed reasons. If you build something with a thousand or a million registers, usually that means you can't complete things in a cycle. Or rather, the clock speed of getting something out of that with the big muxes is too big for what you want the clock time to be, the cycle time. All right, so as you might expect, registers in the register file are named with bits. So there's a bunch of them, maybe eight, maybe 128, we name them with bits. So data moves between the memory and the processing unit. We'll do stores to move data into memory, loads to get it out. So these black arcs mean data moving between the pieces of the von Neumann model. So a computer also needs to be able to get input from the external world and also give output to the external world. So for example, keyboard, monitor, mouse, disk, printer, network, so forth. Someone asked me early in the class why I keep talking about the number 42. And in the same set of books, there's a story about people building a computer to answer, what is the meaning of life? And so for the first generation, they built the computer and they ran it and they ran it and they ran it and took several million years. So the people who built it, they didn't get to know the answer. But the people, when the computer was ready to give the answer, they found out that the designers forgot to include output. Start over, second generation. Yeah, so not with von Neumann. With von Neumann, we're going to have input and output. So those are two more of the pieces, some kind of input, some kind of output to make the computer useful. See, if they'd only studied 120, they wouldn't have done that. So what's missing? We're going to have a control unit. So we're going to have two registers in the control unit, in addition to the finite state machine, we're going to have a program counter. So the program counter is going to say, well, where is the next instruction? It's a memory address, right? Where is it? So that way, the control unit can go get that instruction and execute it. So when it gets the instruction, it's going to put it in another register called the instruction register. So you can have some representation for instructions. We'll go get the bits of the instruction out of memory at the address specified by the PC, and we'll put it into the IR, and then the finite state machine will look at the instruction and do whatever it says. But the bits of the instruction will go in the IR. Yeah, but historically, it's been named counter. But it is an address, yes. So you can think of it as pointing to the next instruction. Yeah, so for those of you who don't have much experience in the software world, there's a notion of pointers in languages, and it's one-to-one with addresses in memory. So a pointer is just an address. So when you start, I mean, in 220, you'll make use of that. But it's important to understand that a memory address is a pointer and vice versa. So counter may be not the best name. Instruction register 2, yeah, in fact, the Intel term for PC is IP, instruction pointer. So if you play with x86, you'll see that. OK, so control arc's going from control unit to everything. Control unit's in charge of everything. So that's our von Neumann architecture. So here's just a summary slide. So you've got the five pieces, processing unit, memory, input, output, control unit. So yes, it does, actually. I mean, there are signals, data path outputs that will come from the processing unit. I should have drawn them, but I didn't. They're data path outputs. They're not really control, because the control unit decides what to do with them. So it's kind of data. So I should have drawn a data arc coming from the processing unit to the control unit. And also, the control unit is fetching instructions from memory. So if you wanted to, you can think of it as data coming down here. Good question. Anything else? All right, so let's then go back through this and think about LC3 ISA. And we'll put numbers on each of the pieces and talk about a little more specific detail for the computer that we're going to look at. So what is LC3? So little computer three ISA was developed by Yale Pat and Sanjay Patel basically as an educational tool. So the design is every aspect they thought about, well, how is this going to help people learn? How are we going to avoid putting them off in the wrong direction so that later they can learn more, but make it simple enough that they can do it in one year? The book's meant to be a one year sequence. So as Yale says, it took them three tries to get it right. So they tried three times, and the third time it stuck. So this is LC3 as opposed to LC1 or 2. So that's where the name comes from. In our class, so LC3 is an ISA. It's only instruction set architecture. The book also has a microarchitecture. So you could build it any way you want. The ISA and the microarchitecture are two separate abstraction layers. You can build an LC3 processor any way you want. There's an LC3 processor implementation in the book. So we're going to look at that and build up towards that eventually in our class. There's some alternative strategies outlined in the notes, a little bit simpler maybe. But the one in the book is kind of the one we'll build towards. You can understand how that'll work. I put this slide in here just as review, but we just saw it. So let's start again with the memory. So in the LC3, memory is 2 to the 16 by 16 bits. So part of the ISA says, well, here's how big the memory is. So 2 to the 16 addresses, let's call that number X. X is 16. And 16-bit addressability, meaning every memory location has 16 bits. So let's call that 16Y. Both of them are 16. The reason I want to give them separate names is I want to ask you questions like this. So you want to remember the MAR stands for memory address register. So it's specifying if we want to do a load or a store to memory, it's telling us what's the address. So how many bits do I need, X or Y, for an address? So I have this many addresses. So how many bits do I need here? X. And I have this many bits at an address. So if I want to tell you an address, I'm going to need 16 bits to tell you which of these. So that's what I called X. At each address are 16 bits. So see, that's why I wanted to separate them out, because it's easy to get confused. The answers are going to be 16 all the time. So on an exam, you just write 16 or 42, which I'm sure is the same in some days. Maybe not. All right. So here, though, what matters, if I want to specify an address that I want to do a load or a store, I have to be able to tell you which address. And there are 2 to the 16th of them. So the number I need is this X, right? This 16 here. I have to tell you which address. So I need log base 2 of 2 to the 16, which is 16 bits to specify an address. So same question for the MDR. So MDR, memory data register, when we read memory, the bits from memory come back from one location and then go into the MDR. Similarly, when we write memory, we put the bits into the MDR before we send those bits to one memory location. So how many bits for MDR? 16. Good. X or Y? Y. Y, right? Good. Okay. All right. So I just want to make sure, because you can design an ISA that has, say, byte addressability. In fact, if you take 411, they'll do LC3B, which stands for byte addressable. And the memory there is 8-bit addressable instead of 16. And so then you have to think about, well, it actually still has the 16-bit loads. So you still need an MDR of 16 bits, but you could have an MDR of 8 bits instead, because the memory is 8-bit addressable. All right. So the ALU in the LC3 supports three operations. You can do and. I'm sorry, add. You can do, that's, choose complement add, by the way. You can do and, and you can do not, all on 16-bit numbers. Can I do anything with these? Okay. We had a name for that, right? Logical completeness. Okay. So you know the answer, you just forgot the name. Okay. What about, oh, I don't want to show you that yet. What about or? I thought what we proved was that. I showed you the answer. Darn it. Okay. Well, hopefully you knew this answer too, right? We proved that and, or, and not together were logically complete, right? We also talked about NAND by itself and NOR by itself. So you can kind of get at that here, right? You say, well, I can build NAND, right? I do the and and then I invert it. But and and not also, of course, are logically complete because of De Morgan's law. And if I want or, I do a compliment the not, not b and those together complement it. That gives me a or b. So this was purposely chosen as a set of things from which you could build anything just to make the point of, well, you can build anything out of this. And some mean person, I don't know who's responsible for making the homework, but you can enjoy doing XOR out of these things in an upcoming homework. It wasn't me. Okay. It was me. The register file has eight registers. Okay. So LC3's register file has eight registers. So what do you think we're going to call them? That's probably a good guess, but, oh, no, sorry. Wrong. Sorry, holidays are coming and just getting excited. Yeah, R0 through R7. The R is just for humans. The computer calls them 0 through 7. But we'll refer to them as R0 through R7. You'll see in the instructions, it'll just be three bits, 0 through 7. Yeah, so register renaming is useful for getting rid of false dependences and things like that. And it's way out of the scope of our class. It's 4.11 material. So happy to talk about it later. Okay. So LC3's word size is 16 bits. ALU operates on 16 bits. Registers are all 16 bits. Input and output. So we're going to have one input device. It's a keyboard. We're going to have one output device, which is a monitor. That's it for the LC3. Monitor, display. I always call it monitor. The book always calls it display, so I put both. Little extra information. This is all 220 stuff, so you don't really need to know this. But the way things interact, the keyboard, humans are kind of slow compared to a computer. So there's only a key when a human pushes a key. So there's also a keyboard status register that says, well, the human pushed a key. So that's what this status register is for, KBSR. It says, okay, human pushed a key. So your program can look at that and tell when a key has come in. The programming will do. There are some operating system services that handle dealing with all these registers. So you don't need to know this, really. But if you're interested, the keyboard data register then in the LC3 delivers that key in ASCII. So if you push the letter A, that lowercase, that would be 61 hex. So the keyboard status register would tell the LC3, hey, there's a key ready. And then when your program looked at KBDR, it would get the ASCII character for the letter A. So that's how this works. It's in chapter 8 if you're interested. So, there's also a display status register. Again, the processor is much faster than the display. And if all you do is pump data to the display, the display is going to drop some of it on the floor and it won't show what you want it to show. So you have to ask, are you ready for another character? You use the display status register for that. And then the display data register with the LC3 is set up. So you give it an ASCII character and it prints that ASCII character to the display for you. So that's how the devices work on LC3. But again, you don't need to use that until 220. You'll see it in the first three weeks or so of 220 when you take that class. So remember, the program counter stores the address of the next instruction. And LC3 memory is 2 to the X by Y bit, where X and Y are both 16. So how many bits do I need in my program counter? X, right? It needs to tell me an address. So it doesn't matter how many bits are at that address. What matters is how many addresses are there. So there are 2 to the X addresses. So if I take log base 2 of 2 to the X, I get X. So I need X, which is 16. Everything's 16. All right. So the instruction register then stores the encoded bits of the instruction being executed. How many bits in the IR? Why am I asking you? Because I want you to think. Okay. So why shouldn't you know the answer yet? You're making some assumptions, right? So how do you encode instructions? So you can encode instructions using some variable number of memory locations, right? So in x86, for example, an instruction can be from 1 to 16 bytes. In the LC3 ISA, every instruction is 16 bits. And that was deliberate. It was a deliberate choice to say, well, let's make the instructions all fit in one memory location. So it was a design choice by the authors of the textbook so that each instruction would fit in one memory location, makes the instruction set architecture and the microarchitecture substantially easier to understand for the first one you're looking at. You don't have to do it that way, but those were design decisions by the architects. So yeah, the IR requires 16 bits for those reasons. If you change the addressability of the memory, you could then ask, well, should we change the ISA completely? If we make it 8 bits, should it be an 8-bit instruction set architecture where every instruction takes 8 bits? Should we just keep it at 16? Should we go to 24 or 32? Many, I mean, basically anything you want, right, if you're designing the ISA. So these were just choices they made to decide that every instruction is going to require 16 bits. So here's what the data path looks like for the LC3. So this heavy black line here is a bus. I'll zoom in on a few pieces in a minute, but generally speaking, everything in this diagram you know how to build from transistors. So you can see the bus, if you look at the things going on to the bus, sorry, it's a little hard to see before I zoom in, but you can see there are tri-state buffers gating things going on to the bus. So basically there's a distributed MUX that says, well, which thing do you want to put onto the bus in any given cycle? And of course, the control unit is sending out control signals to decide that, right? So in a given finite state machine state, the control unit will say, well, maybe I want this ALU to put its answer on the bus, and then that answer will go back over here, and I'll store the sum of my addition back into the register file, for example. So this part here is basically the control unit in green circle. This part's the processing unit, the memory is down here, and then this part over here is IO. So you can kind of break the data path up into pieces. So let's take a look at those pieces and make sure we understand them. So here's the control unit part. So let's see. So up here is the program counter. The instruction register's down here. So I think on Monday I will show you how the control unit uses the PC, puts it out on the bus to go down to the memory, reads the instruction out, the bits of the instruction, then go into the IR, and then you can figure out what the instruction is and execute it. What's a bus? Ah, so remember when we talked about tri-state buffers, I said that you could hook all the outputs together, and if you did that, if you just had a bunch of wires with different tri-state buffer outputs onto them, you could call that a bus. So it's basically a bunch of wires with multiple pieces of logic gated with tri-state buffers that you can put their answers on by signaling the tri-state buffers. Does that make sense? So let's take a look here. So for example, I can take the PC and I can write the PC's value onto these wires by having these tri-state buffers copy it. I can also take, let's see if there's another example. Yeah, this is Marmux. This is calculating the memory address. So you can see there's another set of tri-state buffers here. So I can take the value calculated by this Marmux and I can also write that onto the bus. I'll go back a step. You can see the ALU output also has a set of tri-state buffers. So this is basically, these thick black lines are 16 wires that go around the chip. That's it. It's 16 wires. And there's a bunch of things, logic outputs that we decide which of those should we write to those 16 wires using tri-state buffers. And that's what we call a bus. It's not any more complicated than that. I think I mentioned that when we talked about tri-state buffers. That's right. They're just wires. And just like all other things, you can't short them. That's why they have all the tri-state gating in here. So we use the same, maybe I can zoom in on it. So you see there's an LDIR for that register. So just like when we built our data path, we said, well, the register is not going to load every cycle. So when the control unit wants a new value in the IR, it tells the IR to read the value from the bus and store that value. And when it doesn't, it sets LDIR to zero. And so pretty much everything that takes its value off the bus is gated in the same manner, that there'll be a load signal of some sort. Yeah. Sorry, I'm not sure what it is. I mean, that would be a point-to-point network. So I mean, a lot of modern chip designs are moving more towards point-to-point networks on the chip. But a bus is a shared medium. I mean, that's the other aspect to keep aware of a bus, is it is a shared medium. So all of these things can write to it, but if more than one write to it, in the electrical case, that'll be shorts. So it's a bad thing. Yeah. Eric? So, as long as the finite state machine follows the rules that it doesn't try to set gate PC to one at the same time that it sets gate Marmux to one, or any other tri-state buffers gating things onto the bus to one at the same time, then those wires will not create shorts. And so the finite state machine is responsible for guaranteeing that only one of the gating signals is one at a time. And so that's part of the FSM design at that point. Make sense? Yes, yes. So just like when we draw a MUX like this one, this is actually 16 two-to-one MUXes, remember? We said, well, this is not just one two-to-one MUX. We've got 16 here, 16 here, 16 coming out. This is actually 16 two-to-one MUXes controlled by the same signal. When we draw a tri-state buffer across a wire that should have a crosshatch on it, sorry about that, I just took the figure from Pat and Patel, it should be crosshatched with 16. So this is 16 tri-state buffers with the same enable signal. Yeah. I'm sorry? Yes, the bus has 16 wires because the word size is 16. And so everything we do, when we add things together, we're adding two 16-bit values and getting a 16-bit answer. When we move data from memory, it's 16 bits coming out. When we store data to memory, it's 16 bits going in. So that's why there are 16 wires. But everywhere here, there are 16 tri-state buffers because there are 16 wires on the bus. Yes, that's right. That's right. So, and it's up to the finite-state machine to guarantee that all of the tri-state buffers other than one set are in high impedance mode by sending them zero as they're enabled. Yes, the control unit controls every open signal you see here. So the address MUX input, the MARMUX input, the load PC, the load IR, the load condition code down here, every control signal of the data path is up to the control unit to control. Yeah. Yeah. So in that sense, it's identical to the data path that we developed. There are a set of control signals. In this data path, there are a lot more than the six we have. But it's up to the control unit to set those for each of its states. And we'll look at that in more detail later. We'll look on Monday at the process of fetching an instruction and then decoding it and think about how it would be executed. But we'll look in detail in a few weeks after we do some programming at how you would actually execute one or two instructions on this data path. If you want to read ahead, section 4.1 of the notes, we'll talk to you, we'll show you specific control signal implementations on this data path. Okay. So program counter, instruction register. So this is some miscellaneous instruction execution logic. It'll make more sense once you've seen what the LC3 instructions can do. This is our finite state machine generating all the control signals. So there's the state in here. And it basically sends out all the control signals. They're not wired up just to keep the diagram from getting too cluttered. But they drive all the control signals in the data path. Okay. So let's also take a closer look at the processing unit. So this was on the right side of that figure. This is just the bus coming around. You can see that you can take the ALU output and put that on the bus. The register file can read a value from the bus and store it into a register. So here's the ALU. It does these three operations, add, and, did not, all 16-bit, two's complement addition. There's the register file with the eight 16-bit registers. So one thing I want to make sure, because we didn't cover this explicitly in class, but I don't think it's that hard to do. So if I have eight registers and I have a three-bit number telling me which register I want to read, can you build that for me? On the reading side. So you've got eight registers and I want one of those registers to come out, say, on this set of wires. I want to pick one of eight. How do I pick things? A mux, right? If I want to pick things, I use a mux. So I want to pick one of the eight registers to read. I'll have eight to one muxes. I'll have 16 of them. And that'll give me one output. And then I'll have a bunch of other eight to one muxes for this output. On the write side, when I want to write to one of those registers, then I need the decoder. Then I need the decoder to tell that register, you should be storing the value. So I can route the input to all eight registers and then use a decoder to tell one of those registers, well, you should do a store now. You should load a new value from your input. So this register file is capable of doing one write and two reads all in the same cycle. So let's take a little look at the memory here. So here's the memory to the 16 by 16 bits. There's the MAR. There's the MDR. You can see the MDR is gated, but it can also take data off the bus and store in the MDR. So for a load, what we'll do is tell the memory to give us bits. And those bits, there's some address logic associated with the I-O, but they'll come back and go into the MDR. And then from the MDR, we can copy them onto the bus and put them where we want them. For a store, we'll first write the bits to the bus and put those into the MDR. And then from the MDR, we'll put those into memory for the store. So we can do loads and stores with this arrangement, with the MDR, MAR, and the memory down here. And the details of the I-O, I have it in the diagram, but I'll leave it for a 220. So more questions on Datapath? We talk about instruction formats. So how do we represent instructions? Good. Good. Yeah. Okay, so instructions are encoded by some representation. Whoever's going to design the ISA says, well, here it is. Here's the representation we're going to use. Design decision. 16 bits, that's a big representation. Should we get some paper out and start writing all the instructions? I take a while. We've got 65,000 choices more. All right. First, I want to do a little exercise. Yeah, it will be bits. It'll be bits. Yeah. There'll be bits involved, I guarantee it. Seem good? We're on? Okay, good. So since we're all on board, here, let me tell you what I want. You put in a quarter, you pick one of your favorite flavors. I mean, now, there used to be another flavor here. It was a beverage. It looks, yeah, it's not legal for some of you, so it's no longer here. So now we have cola, lemon, orange, and grape. A little dull, but I was a little worried about putting another copyrighted one trademarked one. I'll leave the design to you. I just need a little help. All right. So four flavors, and I want you to dispense one of those four flavors for 10 clock cycles. So let's count states. So let's see. So when you come up to the machine, the machine's off, and then you put a quarter in, and then that'll go to a half coin state. So that's two. Okay. So help me out here. So if you're going to dispense cola for 10 cycles, how many states do you need? 10. 10? All right. 10? Okay. 10. Good. What about lemon? I really like lemon. How many for lemon? 10? But I like lemon. You sure it's not 12? All right. What about orange? I hear 42s. This one takes three. All right. All right. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. All right. They're making fun of my slides now. Okay. Okay. So let's make a table. Did you get that? I heard this earlier. Awesome. I'm happy. Can you help me out again? I'm hearing some sixes. Six? Six? Okay. Whatever you guys say. Six is good. I have a suggestion. Instead of six, can we do seven? Because six sounds painful to me. Maybe you can try it, but I like to use seven. I want to have one bit that says, you know, did you put a coin in yet or not? I'm going to have two bits that say, well, we've got four flavors. Which flavor do you pick? I'm going to have four bits that will just be a counter that will count to 10 down or something. So here's how I think it'll work. So you put in your quarter, that turns on the coin bit, and you pick a flavor and that goes into the flavor bits, but you can only do it when the coin bit is on. Otherwise you have to put a coin first. So you pick your flavor, that loads 10 into the counter and it sets the flavor that you picked. And then the counter will start counting down. And then to dispense the soda, we'll have a decoder. We put the flavor into the decoder and then we'll put the counter nonzero signal, which we can just easily, you know, do an OR gate out of the counter bits or something. And we'll put that into the decoder enable so that if the counter is not zero, we'll get soda from one of the four flavors. And if it's zero, we won't get soda. One decoder, handful of gates, and an extra flip-flop over a six-bit solution. Yeah, so you might need a priority encoder. It's true. Good point. Okay. So put priority encoder down here too. Or just keep the humans away from the machine. All right. It's only for me. I promise not to push them off at one. All right. Kids, back away. All right. So why does this work well? So adding these extra bits lets us organize, adding one extra bit in this case, lets us break the bits into meaningful groups. So we can have the coin bit, we can have the two flavor bits, we can have the counter bits. And relevant here, so mathematically that means when we look at, well, what flavor do we want to send out, we don't have to look at the flavor bits and also at some function of the counter bits. We don't have to look at the coin bit at that point. But relevant is based on these meanings. So by making these things meaningful and separating them into groups, we actually not only make it easier for ourselves to understand, but we make the logic easier too. So remember when we talked about how do you pick representations for finite state machines? And I said, well, often you want to try to use human meaning. Now it's going to be much more important. We have a 16-bit representation to deal with for instructions. That's a lot of bits. That's a lot of meanings. So we're going to break things into what we call fields. So this is the real point. So pretty much any ISA you look at, except maybe x86, which is a little funky because it's grown over 30 or 40 years now. But most ISAs, and even there, where they have this simplification. So you'll have a bunch of fields. So separations of those bits and the encoded instruction. And the first one will be your operation code. So it'll be some bits that'll say, well, what do we want to do? What is the operation you want to do with this instruction? And then the other fields will tell you what the operands are. So well, you want to do an add? What do you want to add? Usually you add two things. So what are those two things? Those will be separate fields in the instruction. So we're going to use this idea that we just developed with our soda dispenser of breaking things into groups in order to design our instruction set architecture. So you'll see that when we look at LC3 instructions. So here, for example, is an LC3 instruction. So it's 16 bits. So over here in green is the opcode. So it turns out that's an opcode that's known as LDR for load register base, which you don't need to know yet. I'll just show you some examples. We'll go through the ISA in much more detail next week. So it has three other fields. One is the destination register. So what are the possible values here? 0 through 7, right? One of the registers. Good. So there's another register, base register. Possible values, 0 through 7. Good. And there's a 6-bit offset, which is a 2's complement offset. So what are the possible values there? So it's 2's complement. So the smallest one, the biggest one would be 0 followed by 5 ones. That would be, I think, 31. And so negative 32. Okay. So here's what it does. So it says, okay, take this offset, assign extended to 16 bits, add it to the contents of this register, go to that memory address, load the bits from that address, and copy them into the destination register. So in words, it's kind of long. That's why we write it in RTL. So you want to know what the RTL means, because otherwise, you don't want to have to write this. So again, take the offset, assign extended to 16 bits, add it to the bits stored in this register called base register, named by these three bits, and then go to that memory location, get the 16 bits out of that memory location and copy them into the DR. That's one instruction. So here's another instruction, which is add. So this is the add opcode over here. It also has three fields and then three things that have to be fixed to zero. So there's a destination register. That's where we're going to put our answer, 0 through 7. There's one source register, also 0 through 7. Good. And then there's another source register. So it says take two registers, add them together, put the answer, the sum, into destination register. That's all. What are the zeros for? Ah, so that's a good question. So why not just let those be don't cares? So there was this commercial architecture called the 6502, let those be don't cares. And it turned out that those don't cares produced some bizarre effects when software people used those instructions with different bits, because they just built a finite state machine and they left them as don't cares. And so it did something. And turned out it did something sort of interesting that the software people decided that they really wanted. And so they put those non-existence instructions in their software. And then when the 6502 architects wanted to produce a new generation, they found that in fact people had used bit patterns that didn't exist in the instruction set architecture. So the modern view of that is don't ever make that mistake again. If you ever want to extend your instruction set architecture, it's really useful to have undefined bit patterns. On the other hand, having software that takes advantage of a particular microarchitecture's don't cares mapped into something is not so attractive from a design point of view. So let me stop there and we'll look more at these next week. Have a good weekend.\"},\n",
       " {'ECE120-2016-11-07-LEC-31-slides.mp4': \" Okay, wow, I'm loud. Okay, I think it's three, so let's go ahead and start. Hope you had a good weekend. So midterm material three is over. So everything we talked about today is for the final but not for the midterm. Details, I'll go through that in a second, but details, it's probably best you look at the midterm three page because there's a little bit of midterm four, or rather section four, that we covered in the last week that we're going to include on the midterm three, just to kind of make it a little easier than having a full midterm on finite state machines, honestly. So we're going to have the LC3 ISA, so doing things like decoding instructions you'll need to do on midterm three, for example. So today we're going to go through another example, how to type in a number. So we'll say, well, how do we let the user sit down and type in a number? It'll come in in ASCII from traps, one character at a time, and we'll convert it into a two's complement number. So we'll figure out how to do that. That'll be the example. Then I want to spend a little time saying that computers are dumb just because it makes me feel good as a human. I'll give you some examples. We may or may not get to this today. Eventually, by either today or Wednesday, we'll talk about how we break down problems, and we will give some examples of that too. And then we'll do another long example and then go into assemblers. That's kind of the next four or five lectures. I may add some more examples because the programming stuff before we go back and play with control units, we're going to spend another five lectures through all this week. Review session Monday, and then two more lectures next week on assembly or LC3 binary and assembly programming. So third midterm's coming soon, next Tuesday night. I know you're all excited. You've been having so much fun with finite state machines. So same rules as before, same time, places will be up on Compass. If you need a conflict, do make sure to sign up today through the wiki if you didn't already do so. Coverage, section 3.8, and then the left half of the terminology, which is all LC3 ISA, von Neumann, stuff like that. And then a few of the bullets, which I copied into the midterm 3 page. So it's know how to decode LC3 binary instructions like we did last week. But look at those for details. All right, so review session on Monday, just like before. So come prepared with questions, and we'll do the same thing. I'll sit there. You tell me what you want to talk about. We'll vote on it. You'll vote on it. I promise not to vote. And then, well, at least not next week. You should vote this week. But then we'll do that just the same way. So vote tomorrow, and then vote again on Monday. All right, this slide, you know what it is. It's going to be there till Friday. So let's solve a problem. So yeah. I believe so. They usually try to. The question is, is Eta Kappa Nu going to hold another review session for you? They usually try to do that for most of the core classes. So I believe they will. I don't have the time or place. My guess, the first two were exactly the same time and place, relatively speaking, right? So it was Saturday. I think it was 2 to 4 PM, but I'm not positive. If you look back at the lecture slides, I put it in there. I think it's on the Wiki, too. So it's probably going to be Saturday 2 to 4, and I think it was in 1013B. So 1013 ECEB, rather. So probably all the same, but I'll tell you when I know. Yeah. Good question. So let's see. Yeah, I'll do the slide I had on resources again. I mean, it's things like, well, you can watch the video lectures. You can watch Professor Jaramillo's lectures. If you want to, you can go to the other review sessions, too. All of the four lectures will have review sessions. So if you want more review, you can go to those, Eta Kappa News review session. So let's see how we can take a problem in human terms and translate that into LC3 instructions. So for this one, for the most part, I'm going to do it for you. I may ask you to help me out here and there, but for the most part, I'm going to show you how it's done, and then later we'll talk about how we do it. And then on a bigger example, or another big example, I'll ask you to do it for me for the most part. So we're going to start by identifying, well, what do we need to keep track of? So I'll tell you what the task is. That's what we'll actually do first. But then we'll say, well, what do we need to keep track of? Those are things we're going to put in registers. We'll find at state machines, we had registers in a different sense. Now I mean registers in the register file. But when we were designing FSMs, we would identify information and then put it in registers and counters or state bits, and then we would figure out how we move between states. Here we're going to assign registers from the register file to those stored values, draw a flow chart for our code, roughly with one box corresponding to one or two or three instructions, and then write those instructions in some human readable form and then convert them to binary. And so the whole, this program we're about to do is available to you on the web page. I mean, I can bring it up, but it's the links page. So if you've got it bookmarked or something or type my name into Google, it'll take you to my home page and then go to fall 16, 120. At the bottom, there's a bunch of programs in LC3 or several programs in LC3. This is one of them. So you can download it. You can run it in the lab if you want. You can type in a number. One caveat, if you run it in the lab, I forget which way, but I think it's the GUI that actually changes the character that gets pressed when you hit the enter key. So the code may not work in the GUI because we only check for one key, and it may be a different key that comes in from the GUI. I don't remember right now. So here's what we want to do, though, which is let the user type in a number. So someone comes up and they're going to type in a number. Maybe there's a prompt, but we won't even print a prompt. They'll type a number from 0 to 32767 using the keyboard. When they're done typing their number, they'll press the enter key. So you can imagine why I picked 32767 as the upper bound, right? Okay, good. Yeah, I mean, it's the biggest twos complement number we can store in one memory location. So we're going to read in the number, convert it to twos complement, store it in one memory location, and if the user does something crazy like presses the letter L for LaMetta or something, we'll say you're a bad user and go away. Give them an error message. And if they type 100,000, then when they hit that last key, instead of 10,000, it becomes 100,000, we'll say you're a bad user, go away. And that's it. So we'll give them error messages if they break the rules. So what do we need to store? Before we answer that question, I just kind of wanted to point out that, well, this is a lot like when we were developing finite state machines, right? In fact, you can think of a program as a finite state machine. Your state in that case will be your variables in a C program. In LC3, it's going to be the things you put in registers or the bits you put in memory locations. So we need to think about, well, for this one, the keys are the inputs, including the enter key. The error messages are the outputs. The number typed is eventually read out. I mean, we'll put it in memory, but then if this were a bigger program, we'd take it out of memory and use it for something. So our program is kind of like a finite state machine. So what do we need to keep track of, or what other values might we want to keep around in registers to solve this problem? So user's going to be typing in a number. So they're going to press a key, right? So when they press a key, that's some number they're pressing. So maybe we need a place to keep track of that. So they press a key, better put that somewhere. But there's also some number they're typing. And so even when they're pressing, say, the third key, they've already pressed two, so we better know what they typed. So we better keep track of, well, what number did they type from their previous keystrokes? So there's a couple of things. Let's see, what else? How about FFD0? You like that number? I like that number. You know why? Now do you know why? So when we want to convert their ASCII keystrokes into two's complement, how will we do that? So there's a homework problem ages and ages ago, weeks and weeks. In semester time, it's eons. Remember, we can subtract this number, 30, right? So remember, if we type a number, a digit in ASCII, it's from 30 for 0, 31 hex, sorry, 30 hex for 0, 31 hex for 1, and so forth, up to 39 hex for 9. So if we subtract 30 hex, that'll turn it into a two's complement number from 0 to 1. So this is the number we want to subtract. If we negate that number, we get FFD0. So that's why. If we'd done that with ads, we'd need three ad instructions. Remember that the LC3's immediate ad operand only goes to, it's a five bit two's complement number. So the most you can subtract is 16, or 10 hex. So you'd have to have three separate ad instructions. So instead of doing that, we'll put FFD0 in a register, and then we can use one ad instruction to subtract 30 hex, and then we'll want to convert. And then I also want to have a temporary register. You'll see it's useful. Sometimes I just want to do calculations and then throw them away, right? So when I'm doing comparisons, for example, I need to set the condition codes, but I don't need the answer. So I'll have a temporary register. So let's put the things we want to store into registers. So we know when we use the getC trap20 hex to read a character, the keystroke's going to come back in R0. So whenever we call the operating system and say, okay, let the user type something now, the answer is going to come back to us in R0. And we need to store that somewhere, so let's just keep it in R0. Why make trouble so we have to move it somewhere else? We're going to say, yeah, R0 is the key they pressed. So that was pretty easy. R1 could be the current value of the number. R2 can hold this FFD0 constant, and R3 can be our temporary. So it's pretty straightforward. As long as you only have a few values, we have eight registers. Remember not to use R7. It doesn't really matter which ones we pick. So another question before we go on. So this one I need your help with. So when the user presses a key and we're keeping track of the current number that they've typed, how do we update it? So let me give you an example. So let's say that the user has pressed 3, 2, 7, and 6. So the number they've typed so far is 3,276. And then the user, say, types a 5 or something, or 7. So now they've typed 3, 2, 7, 6, 7. So how do we take the 3, 2, 7, 6, and the 7 and combine them? Well, I don't think this is a multiply by a power of 2. Multiply by 10, and then add this one, right? So let's see. So like that. Uh-oh. So we have to multiply by 10 and add the new digit. Is that right? People agree with that? You already know how to multiply by 10. You could, yes? That would be one answer. All right. So let's figure it out later. Let's do this flowchart. So I'll just draw a flowchart for you, but I'll put it together piece by piece. So when we start, the first thing we're going to do is initialize our variables. Generally speaking, any time we start a program, when we have things we're storing, we need to think about all of them and think, well, do I need to put some specific number in that register before I start, or can I just leave it as bits? So we'll go through and do that, but first let me go through the whole flowchart. So the first piece is, well, let's make sure if we need to, we initialize any variables, like r0 through r3. The next step then is, well, let's go to the keyboard, or rather go to the OS, and say, hey, let the user type a character. So once they type a character, then we have to ask, well, did they press the Enter key? And if they press the Enter key, then they're done typing, so we should store the number and finish. So if that answer is true, the key they pressed is Enter, then we're going to store the number, and then we're done. On the other hand, well, what if they didn't press Enter? Well, if they didn't press Enter, we have to ask, well, did they press a digit or not? Did they press something else? And if the answer is no, they didn't press a digit, well, then we should print the error message, and then we're done. We're not going to ask them to start over or anything nice like that. We just quit. All right. Very simple program. All right. If they do type a digit, then we have to do our multiply by 10 thing, add in the new digit, and, oh, check for overflow, right? We said, well, if there was overflow, then we'll print an error message. And if there's no overflow, what's next? Read another one, right? Let them type something else. OK, so that's it. That's our whole flowchart. It's not, it's hard to cram into a PowerPoint slide. It looked a little nicer on paper, but hopefully it's not too hard to follow with the animations. Yeah, Mohamed? If the conversion with the new digit has caused overflow, yeah, yeah, because remember, we can only go up to 32767. If we go beyond that, we're not going to be able to store it in one memory at a time. Anything else? All right. So here, now we're ready to write instructions. So we'll start with this one. So let's step back for a minute. Well, which ones do we need to initialize? So here's our table. So what about R0? Do we need to set that to anything? Why not? It's going to get filled in for us, right? We don't need to put any bits there, because when we call the trap to get a key from the keyboard, that trap's going to overwrite whatever bits we have in R0. So there's no point putting anything in there. So that'll get filled by Gitzee. What about R3? Just a temporary, right? So skip R3. R2, we better set to FFD0, right? Our code's going to assume it's got that in there, so we better set that. Uh-oh, what about this one? What should I set that to? You guys are good. It took me several slides to figure that out. All right. All right, fine. All right, so how do you figure that out? Well, you've got the rule that we developed earlier. And you say, well, when I start, if the first thing the user does is presses a key, like 5, then we want the new value to be 5. So we need to solve this equation, right? 5 is the thing we're going to calculate, the new value. And that'll be 10 times whatever we initialize current value to plus the key we pressed, which was 5. So if you solve this equation, you get current value equal to 0, right? So you want to initialize current value to 0. It has a strange side effect that if they run your code, you immediately push Enter, then you get the number 0, right? Which maybe you want to give them an error message on that, but I'll let you extend that in the code if you want to. So we'll initialize R1 to 0. This code won't do it. The code on the website either won't do it. So now we're actually ready to write some LC3 instructions. So how do I get FFD0 into R2? Well, one way is to use a load instruction, right? I can put FFD0 somewhere in memory, and then I can use an LD instruction to take it out of memory and copy it into R2. So let's use a load instruction. There it is, destination R2. And what's the offset? Yeah, we don't know where it is, right? Because it has to go after our program, but how big is our program? How many instructions is this going to take? We have no idea, right? So we just leave a blank line, and we'll come back to it and fill it in, right? Because we don't know where it's supposed to go right now. So we'll leave a blank line in our code. So for R1, if we want to put 0 in a register, we can use, for example, the AND instruction. Question? Could you build backwards? You could, yeah. That's one idea, but I kind of have the same problem. It's a little easier, so I could build backwards knowing that this is a 3000, and any time I need something, I could put something earlier and go and change the start of my program, make it earlier and earlier. One issue will be that when you load a program into the simulator, at least, the PC will get set to the start of your code. I'm sorry, not the start of your code, to the start of that block of bits. So if you set, for example, if you put it at 2FFF, then when you loaded your program, the PC would be 2FFF, not 3000 hex. So it's a little bit of a hassle with the tools we have. It's a perfectly valid way to do things, but it would be a little bit of a hassle with the tools. Yeah. Good question, though. Yeah. Yeah, so you can do that. We try to discourage you from interleaving code and data just because a human tends to get confused by that sort of thing, right? So it's good habit just to try to separate out your code and your data. And when you're really writing binary, it's a little bit hard, but as we get up into assembly language, it'll be much, much easier. And it's just good practice because when humans look at things, it's easier if you say, well, the data are in one part of my file and the code is in another. It's a little easier for people to read and understand most of the time. Yeah. It's a good question, though. I mean, sometimes that's not true. Sometimes there'll be data that are very tightly associated with a particular piece of code, and so those you might still put next to it. But literally putting, you know, OK, I need to load something. Let me just branch over it. That kind of thing people try not to do. It's also extra instructions, right? It's an instruction you didn't need to execute. So your code will run a little more slowly because you did that. Does that make sense? Yeah. So that is what Sasha was saying is we could, our code is going to go down, right? Because so Sasha was saying we could put it at 2FFF, for example, and we could do that. It's a little bit of a hassle with the tools you're going to use in the lab, so I don't want to just, I don't want to encourage it because it might lead to confusion. So there's a contiguous set of bits, and so they have, the tool has no way of knowing which things are data and which things are instructions. So it sets the PC when you load the contiguous set of bits to point to the first set of, the first word. So when you loaded your code, it would then, the PC would point to your data. You'd have to change the PC before you ran your code. And I think the other thing is we're going to have lots of offsets and not all of them would benefit from this solution of saying, well, OK, let's put it back. We're also going to have branches in the code, right? So we'll have to go to different pieces of code. Those we won't know where they are until we write them. So my point here is just to have these blanks because later, once we've written the code, we're going to have to go do counting and fill in the offsets. So even though, yeah, we could fill this one in, we won't be able to fill them all in. So that's kind of the point. So there's, so for R1, you will use the AND instruction. So AND R1, R1 with number 0. So that'll force a 0 into R1 and satisfy our initialization. So now we've finished initializing the variables. We can move on and read a character. So to read a character, we just use trap 20, so 20 hex, that is. So write trap 20, get C, and that'll get a character and bring it back in R0. It'll actually wait until the user presses a key. So our program will stall until the user's pressed a key. Then when it continues with the next instruction, there'll be a key in ASCII in R0, keystroke in ASCII in R0. So now I want to do this. What is that? Anyone know? And why would I want to do that? Yeah, so this one is the out trap. So that will actually send that key that they pressed back to the monitor and have it show up on the monitor. So when you read a character from the keyboard, it doesn't just echo to the monitor. If you wanted to write a video game or something, you don't want all the keys they're pressing to move whatever echoing back onto the monitor. So it's a separate trap. But when they're typing a number, it's kind of nice if they can see what they type. So we're going to have it echo that key back to them so they can see it as they type it. So it's not necessary. We could make them type their number blind, but it's a nice thing to do to echo it. So all right, so that's reading the character. So now we need to check that character for enter. The enter character is, or the enter key produces ASCII code 10, number 10, decimal 10. So R1 is the key pressed. So we're going to have, I'm sorry, R0 is the key pressed. So we're going to use an add instruction and subtract 10. And where should I put the answer? Maybe R3, right? I don't need the answer for anything. I just need the condition code. So I'm going to throw the answer away. So I'm going to add R0 to negative 10, decimal, and put the answer in R3. So now my condition codes are set, right? If they press the enter key, the zero condition code will be set. Otherwise, some other condition code will be set. So I can branch on negative, I'm sorry, branch on Z. That'll mean go somewhere if they press the enter key. So where should I go? I don't know. We didn't write that code yet. So we have to leave it blank. That code's somewhere in the future. I mean, we could write that code next, but then we'd still have the same problem, right? We'd have to figure it out how to branch around that code. So we'll branch for when they press the enter key, and we'll leave it blank. So remember, this instruction writes to R3. It writes to all of the bits of R3. So nothing reads R3 here. So whatever bits were in R3 get thrown away. Good question, but we never use the bits of R3. First thing we do is throw them away. So there's no point in setting them to anything beforehand. Yeah, yeah, that's next. So I'm just going through the flowchart in some order, but definitely following the arrows. So we did a branch. We got a blank label. So now what's next? We could go either way here, right, because we made a decision. We decided to go this way, to is a digit. This code will have to come back later and write this code and fill in the offset. So let's go up and check if it is a digit. So how do we check if it's a digit? So let's see. So R2 has negative ASCII digit 0, FFT 0 in it. So I could, for example, convert the key to binary, right? So we've got R0. So let's convert that R0 into a binary number. And if it's a digit, it'll be 0 to 9. So how do we convert it? Well, we just add R0 and R2 and store it back in R0. So now R0 will have an, if they type a digit, it'll have a number from 0 to 9. If they didn't type a digit, if, for example, they press something, if the answer is below 0, it wasn't a digit, right? So we can branch negative and we know it's not a digit and we can go somewhere. We don't know where, right, because we didn't write that code yet. So we have a blank. Okay. Now, at this point, R0 holds the original ASCII character minus 30 hex, right? So if that was a digit, it's 0 to 9. If it was less than 0, we already went away. So now it has to be anything from 0 up to 9, but it could be bigger, right? It could be they pressed a letter and now it's bigger than 9. So we need to figure out, well, did they press something like a letter or something beyond the digit 9 in the ASCII sequence or the ASCII code? So to do that, we could say subtract 10 and discard the result. So we'll add R3, we'll throw away the result, destination register R3. So we'll take what's in R0 now, add negative 10 to it. That'll produce a number from negative 10 up to negative 1 for digits, a negative number. And for non-digits, it'll be 0 or positive, right? So we can then say branch on 0 or positive somewhere. Okay. That make sense? I'll have a sip of coffee while you think. It's multiplied by 10. Okay, you want to switch? X86, it would be good for 391. All right. So here's some code. It's good, right? Okay, it all works. All right, let's try again. So let's use V to denote the original value of R1. This thing up here is a comment. So anything with semicolon is a comment. You'll know and love them because they'll explain what's really going on without your having to look at bits, or at least hopefully they'll match. So here's the first instruction. So it says, well, let's take R1, that's our current value, and add it to itself. So we'll call that V. So now after this instruction, I have V plus V, I put that in R3. So now after this instruction executes, R3 has 2V. The next instruction was add R3 to itself, put the answer back in R3. So R3 had 2V before this instruction. So 2V plus 2V is what? 4V. Good. Okay, so then we have this instruction, and that's R3, which is 4V, and R1, which is still V. We didn't change R1. So 5V. And then we have this instruction. What's the end? 10V? Good. So now you're happy? All right. You would have added 10 times, and that would have been a fine answer. Only six more instructions, no big deal. If on the other hand you wanted to add 1,000, then do it my way, please. 1,000 times anyway. Yeah, you can do this generally with any multiplication. It's basically just shifting and adding. Okay. Yeah, the number of lines should be roughly the number of bits in the thing you're multiplying, plus the number of 1 bits, roughly, and then minus 1. All right, so now we need to add the new digit in. So that's pretty easy. The new digit, remember, is in R0, and then our current value times 10 is in R1. So to add the new digit, just write back into R1, R1 plus R0. We already converted it earlier when we were checking the bounds to make sure it was a digit. We also converted it from ASCII into binary, into two's complement, 0 to 9. So we can just add it in from R0 and R1. R1, remember, is 10V at this point. So this is our final equation value. We store it back into R1. Now we've updated current value with a new key. Yeah. No. Ah, okay. Let me go back to where you can see the code. Yeah, we threw that number away. And that was important. We didn't want to have to add 10 back to it. Yeah, so when we checked the upper bound, we did the calculation, but we threw away the answer. We just used the Z and P conditions to check if it was above the digit 9. Yeah. But the answer, this one stayed the same. R0 stayed the same. So it still has our digit, which we know is a digit now, from 0 to 9 in two's complement. Okay. All right. So now we can check for overflow. Well, okay. Sort of. We can't really. So for example, the first thing we did was add. So if we had, let's see, let me think for a second. If we had 10,000 and we multiplied by 10 and added 0, let's say, then we'd have 100,000. And the answer is always correct mod 2 to the 16th, right? So if you subtract 65,536 from 100,000, you get something. Actually, is that? Yeah, maybe that's too big. So 90,000 or so, right? It's still a positive number, unfortunately. So if you wait until the end of the computation, there's no easy way to check for overflow. So what you have to do is you have to check basically after each of the ads. So for some number you're typing, each of those ad instructions, you have to branch if it becomes negative, right? It's overflowed if you add those two positive or non-negative numbers and then they become a negative number. So it's easy to check. We have to check after each of the five ads. So the code online actually does all of those checks for you, but you can't wait till the end. You have to do it in the middle. And so rather than adding all of those instructions, we'll just skip the overflow check here. So in class, we're not going to do it. But the code that I've given you online does all of the checking and error message printing. So if we're going to skip the overflow check, it's time to then just go get another digit, right? So what kind of branch should I use to go get another digit? So in this case, I always want to go get another digit, right? So yeah. Yeah, we did nothing to allow them to type a negative sign. Yeah, and in fact, we said that the range would be limited to 0 to 32767. So they could try to type some, if they were to try to type, for example, 40,000. One could have allowed them to then store that as a negative number, 40,000, whatever that is interpreted as two's complement as a 16th value, right? But we didn't. We decided that would instead print the overflow message. And that's what will happen if you run the code that is online. Okay, so let's just use an unconditional branch, right? We always want to go back. So we'll say, okay, brnzp, and then we'll figure out the offset later. So this part over here, we're going to leave on the web page. We didn't do it. But we need to store the number. So we can use an ST instruction to store it nearby. The numbers in R1, so source registers are one, where to store it again, we don't know the offset yet. So leave it blank. And then we're done, except we have a couple of, well, first a halt trap, right? So we want to stop our program. So trap 25x to halt it. And then we need a couple of things for data, right? So we need FFD zero. So let's just put that in memory here. And then we also need a place to store our number. So let's like a little place there for our number. So that's it. That's our program. And we have all those blank lines. Yeah, you ready? Were you going to say bits? I know, I'm sorry. Don't worry, one day we'll get to bits. All right. So there's that one up there. Where's that going? I wanted to put FFD zero in R2, right? Where's FFD zero? Oh, it's down here. Okay. So there should go from here to there. Where's the PC when I execute this load? 3001. Good. Okay. So there's PC. All right, I got to put my coffee down. This is hard. All right. So starting from here, we got one, two, feel free to count along. Three, four, five, six, seven, eight, don't get too excited. Nine, 10, 11, 12, 13, 14, 15, 16, 17. No, don't try to trick me. All right. So that's 11 hex, right? So 11. Good. We're not done. 17 is 11 hex. So one is 16 and the other one is one. 16 plus one is 17. Instead of writing number 17, I don't know, because we're going to change it to bits. So converting, I mean, at some point, it's much easier for me to convert from hex into binary. So I try to go from decimal through hex into binary. Why is the offset 17? That was the counting part. We counted. Yeah, but the offset, so remember on the load, we're going to do PC relative addressing. So we'll use the PC, which points here, and add 17 to it, 11 hex. So if you add 11 hex, you get 3012. So we could subtract, but it's much more fun to count. And actually, subtracting, I don't know, I always find it hard unless I use the ninth complement. All right. So where is this branch? So this was the case where we didn't get a, no, sorry, this was the enter key, right? So this should store our answer. So where is that? Yeah, this is the code to store the answer, right? So we want this branch to go here. And where's the PC for 3005? 3006. Good. Okay. So we're ready to count. One, so we started, this is zero, right? So if we set it to zero, it would just come to this add instruction. So one, two, three, four, five, six, seven, eight, nine, ten. Okay, and that's XA, right? Yeah. Okay. All right. This one, what is this? This is checking our digit, right? So if this is negative, this is not a digit. So I'm going to make that come down to here. But I'll imagine I wrote my error handling code afterwards. We're not actually going to write it. It's in the code online, but we're not going to write it in this code. So let's see. So PC is where? 3008. Okay. So one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve. That's C, right? You notice I'm getting better at counting already? All right. This one was also error checking. So I'm going to cheat a little bit. Let's see. So this is two down. And so if I subtract two from this offset, I should still get the right answer, right? So 12 minus two is ten, which is AX. So A. Okay. All right. What about this one? Where does this go? So that's our branch to go get another character, right? Up to here, 3002, right? This is reading a character. So it should go up to here. Okay. Good. So PC is there. So starting from here, I've got negative one, negative two, negative three, negative four, negative five, negative six, negative seven, negative eight, negative nine, negative ten, negative eleven, negative twelve, negative thirteen, negative fourteen. Okay. So I would write that this way, X negative E. Unfortunately, the negative XE doesn't actually work in the assembler. So we'll put that there. And then this one is easy, right? So where is this supposed to go? There's a place down here, right? So we want it to go there. And a PC is where? Are you getting tired of counting? I think this is the most fun we've had all semester. Okay. Fine, too. Okay. So we're done. Now we can write some bits, right? Oh, wait, there's a bug. We forgot the overflow. Okay, let's go do the counting again. Sorry. Yeah, now you know how much fun it'll be. Okay. So if you make any, if you have any bugs or anything, like you need, you realize you left out one ad, then you have to go recount and recalibrate, right? So it's really kind of a pain. You'll get tired of it soon if you're not already tired of it. So here's the first instruction. This notation, by the way, is assembly code. I think I mentioned that before. So it's very human friendly. But we need to turn this into bits, right? Because the computer only understands bits. So what is this opcode LD? You know? 0010? Okay. And then that opcode has two fields, right? So the first one, we want it to be R2. So what do I write here? 010. And then what do I write here? Okay, do you get it right? I hope so. All right. Yeah, as I think I said last time, you know, once you type all these in, so a couple notes. So one, when you type them in, include the spaces in your program because you want to make it easy to read, right? For yourself as well as people who are grading it or whatever, right? So just include the spaces and add a comment, the semicolon thing. I'll actually show you an example in a second. You can use the assembly notation. You can use RTL notation, whatever. Just make it clear what those bits were supposed to do. So it'll look something like this, right? And so forth, and just the rest of the code. Your program, by the way, starts with a starting address. So this is 3000 in hex or rather in binary, there's 3000 in hex over there to explain it to the humans. The other comment is even after you've done it this way, you're very prone to typing one instead of zero and vice versa or leaving out a zero or something. The tool will warn you if you don't have 16 bits. But if you manage to transpose digits or something, it doesn't know, right? If you have 16, it just says, okay, great. But what you can do is then once you run it, you can take it into the simulator and you can list it and make sure that the instructions that it shows you are the instructions you meant to happen. So and it'll show you, it'll show you hex, but it'll also show you assembly code. And if it does something strange, like turn one of your instructions into a dot fill, that means it wasn't a valid instruction. So usually it'll show you instructions, but for 16 bit values that don't correspond to real instructions, it'll do dot fill or something else when you list it. Okay, so one more, and then we'll, we'll just let you do the rest. So here's an and instruction. What's the opcode? 0101. And so and has a couple of a few fields always, right? It has a destination register. So what is that one? 001. And then source register one, 001. And then which mode? The one immediate mode, right? So once we have immediate mode, then there's a five bit twos complement field. That's the last field. And what should we put in there? A bunch of zeros. Good. So there's our last or second instruction. And I'll leave the rest for you. So I think you can manage it. Or you can just look it up. We have the code online. If you want, if you want the exercise, though, you know, do go through and change a few of them and you can compare it with the, with the results in the code. So you will have to do this at some point, both in the homework, you have one exercise this week, but you'll, you'll have more in the future, but then also on the final. So in the, in the midterm, it's just decoding, but in the final, it's like that'll be encoding as well. All right. Any questions on the example before we continue? You like the name. I like it too. So the handout I gave you, which I didn't bring with me, but that sheet with the data path and the finite state machine and the encoding diagram with all the RTL, that's exactly what you will get on the midterm three and on the final. So if you want to know, do I have it or not, just look on that sheet. It's also on the, on the wiki. If you lost it, it's under resources, LC3 sheet or something like that. And so that way, if there's anything that's not on there that you want, you can add it to your crib sheet. Okay. So computers are done. So think way, way back to the first day of class, I mentioned Church-Turing hypothesis, which tells us that anything a human can compute, a computer can also compute and vice versa. And so you might think, so what's the difference? What's the difference between humans and computers? They're equivalent. So here's the answer. Humans are smart. Computers are dumb. So what is this? Can you do that one? Anyone? It's 42. Good. All right. Computers can't do that. Seriously, computers can't do that. So it's very difficult to do that, in fact. And what you did is your brain recognizes digits because you think whatever I scribbled up there probably has to make some kind of sense if I'm asking you to think about it, right? And then you say, oh, it kind of looks like digits. And oh, it looks like 19 plus 23. And I know how to do that. Yeah, it's 42. But no one seems to know how to explain that to a computer. I mean, a lot of things our brains can do, we don't know how to systematically solve. And so because no one can get a computer to do things like that quickly, we can put things like that up and call them CAPTCHAs. And then if it happens quickly, if we get an answer quickly to, well, what text is here? Solve some little problem or do something like that in fuzzy, bizarre-looking text, usually that means there's a human doing that, as opposed to a computer robot who just wants to create lots of accounts on your website. So that kind of technique is just an example of many kinds of things that somehow human brains do really well and quickly, but we still don't know how to describe it. And computers can't figure it out themselves. So if a computer is going to do it, some human has to figure out how to do it systematically and break it down to the level that a computer can also do it. So I may have said, and I might say in the future, something like, oh, the LC3 only understands two's complement. So what does that mean? LC3 is not human. LC3 understands nothing. It's a computer. It's just bits. So what am I trying to say if I say something like that? Well, the LC3 hardware and instructions set architecture have a bunch of fields that are two's complement fields, and the hardware has a bunch of sign extensions. So part of the LC3 ISA interprets bits as two's complement values. When we add an immediate value, when we and an immediate value, when we add a PC relative offset, all of those are two's complement values, and they're interpreted as such because of the definition of the ISA and because of the hardware in the data path. On the flip side, when I say it only understands two's complement, what I mean is, well, if you want to do floating point, good luck. You're going to have to write all of that in software. There's nothing in the LC3 instruction set architecture to help you. It is complete. You can do anything. You can do any Boolean expression and so forth, but any other data type, you have to translate operations on those data types into instructions. So you have to write software to do those things. So here's an example of a software representation. So over here in memory, I've shown you three instances. One of them has an ASCII one digit. One of them has an ASCII nine digit. And then the last one has an ASCII null, which is just a zero. This is often how we store strings in memory. So if I want to store the string one nine, then I would put the one, the nine, and the null in consecutive memory locations. And then when I wanted to talk about this string, I would just tell you, OK, my string is at address 4012 hex. And if you wanted to read it, you'd go to 4012, and you'd look at the memory, and it'd say, oh, there's a one. And then you'd look at the next location and say, oh, there's a nine. And then you'd look at the next location and say, oh, OK, there's a null. That's the end. So if I wanted a longer string, I'd use more memory locations and so forth. So that's a string. So here's another string. What is it? 23, right? OK, good. So say that the LC3 does this. So you tell the LC3, OK, this is string one. It's 4012. So put 4012 in R1. And string two is 7196. So put that in R2 and then add them. What's R3? B1A8? If you tell the LC3 to add two 16-bit numbers, it adds the two 16-bit numbers, right? It doesn't know what they're meant to be. So what's stored at B1A8? Bits. Good answer. Bits. So unfortunately, I've actually met quite a few people who have never seen representations and don't know how computers work. And they make this kind of mistake in their programming languages and then they're just baffled. They don't know, well, why doesn't that work? I told it to add my two strings. Oh, I need your help. It pushed go. Which one's the biggest? This one here? This is the biggest of these three? No, it's 41962. I guess you're probably right. OK. What's the smallest? So that's the smallest. And then that one's the middle. You sure? You think that? Are you sure? Maybe double check my... Kind of strange. Really? Because the computer said this is the smallest and this one's the biggest. All right, let's put them side by side. All right. What's bigger, 4 or 9874? Good luck on the midterm. All right. Yeah. So 9874 is the biggest, huh? OK. All right. So computer one, students, how about these two? Let's see. So 4 is equal to 4. 1 is equal to 1. What about comma and 3? So comma. Comma is smaller than 3. So the middle one is 41321. And then the biggest one is... I'm sorry, the smallest one is this one here, 41962. So it seems the computer's right. Yeah. So it turns out if you sort strings in ASCII order, then that's the kind of answer you get. So you might think, well, OK, yeah, that's cute. Kind of silly example, but yeah, whatever. So take a look at the index. You see it here? Yeah..................................................................\"},\n",
       " {'ECE120-2016-10-21-LEC-24-slides.mp4': \" example. Just an example of how we how we build a finite state machine with components. And then what I'm going to do is actually we need to do memory before we look at a finite state machine with more components and think about separating how we control those components from our finite state machine design, which will then take us into how we build a computer. But for that design we want to have memory. So I thought maybe I'll move that forward and then if we have extra time relative to the other other lectures maybe we'll just do a finite state machine analysis example in class. But first let's finish the vending machine. Then we'll talk for whatever we can get through out of these memory topics. So first I'll give you an abstract model, talk about SRAM cells. I'll tell you what's in a DRAM cell. There's a picture in the notes if you want to see one. Talk about how we build bit slices and do coincident selection. And then trisate buffers and eventually we'll look at bigger and wider memories. Be sure to start lab 9 early if you haven't started it and when you go in the lab don't let the sunshine in. Because you're engineers not for any other reason. No, remember that the optical sensors if the sunshine hits them might generate noise and then people in the sunshine will have trouble with their lab. So try not to raise the blinds while people are trying to turn in their lab. Alright, so this is just a little review what we were building on Wednesday. So we have this vending machine that we wanted to use components like registers, adders, muxes, decoders. We built a new component called a priority encoder. That's not really one you need to know but it is one that's used for various purposes in practice. And we'll do one module today specific to this design. Basically just to translate our coin representation into a value in nickels. So we can add that number in. I remember we decided to have the the state of the system be some register a six-bit register n which represents the number of nickels held by the machine out of money the users put in so far. Inputs were this coin input which is a representation, three-bit representation, telling us what coin just came into the system. Product selection buttons for the three products that the user might want to buy, one, two, and three. And then the machine generates outputs, one coin except, kind of like the one in the lab, but there's a more complex vending machine saying yes or no, I'll take this new coin or I won't. And if it's rejected the coin mechanism will return the coin to the user. And then if we want to release a product, we've got three product release signals, R1, R2, R3. So we then decided or pointed out that since our finite state machines in our class always have outputs dependent only on state, that we wanted to calculate the outputs based on the current input and the current state, but then we just buffer those in flip-flops or a cycle. Those don't affect our state machine design, but it means they're delayed a little bit. And so we've got four flip-flops that will basically just keep track of the release outputs and the accept output and hold those high or low for a cycle after the state in which they're created. We decided to prioritize our input events. We had 48 arcs we had to think about. We decided, well, let's make it easier on ourselves. So we'll just strictly prioritize the eight different types of input event and the one no input event. So we decided that purchases are the highest priority. So item three, item two, item one, and then coin inputs are all distinct, right? The different patterns on the C input. And so we just prioritize purchases. And then if there are no purchases, we'll do a coin input. And this was a specific example, given three prices that are sitting in registers, a specific example of what our real state diagram next state table should look like. So we said, well, purchase three is the most important. So if I ask for item three by pushing button three, none of the other inputs matter. And in this case, I only had 50 nickels. I needed 60 to buy item three. And so I just sat in state 50. So we went through this table on Wednesday. So I won't go through everything again. But you can actually derive for a given set of prices. You can derive a full next state table at this point. So that's where we were. All right. So now it's time to start thinking about how we're going to implement this. We decided that purchases have priority. So the first thing I want to do is say, well, how are we going to decide which purchase they ask for? Remember, I said, well, if they pick button three, I'm going to ignore everything else. But if they don't pick button three and they pick button two, well, then I'll ignore button one and the coins. And then button one has the lowest priority amongst the purchases. So to put those together, what I'm going to use is something called a priority encoder. So this kind of thing is actually a way to do a priority encoder. So this kind of thing is actually used, for example, in deciding, well, if I have 10 devices that might need attention from my processor and they can give me a one bit signal, hey, I need some attention at the disk drive or I need some attention at the printer or I need some attention for the mouse. Each of them gives me a one bit signal. I'll use a priority encoder to make a decision about which one the processor looks at first. So they're actually used in situations like that. What we'll do is a four input priority encoder. So we only have three inputs we care about, but we'll just use one with four lines. And what it will produce is one signal P that says at least one of the inputs had a one. So whenever someone pushes a button, P will be one. So we'll put the buttons into these priority encoder inputs. And also the two bit signal encoding the highest priority active input. So it has four inputs. We'll call them 0, 1, 2, and 3. Surprise, surprise. And the output S will say 0, 1, 2, or 3 if P equals 1. Otherwise, we don't care what S is. So if they don't push any buttons, if all four inputs are zero, we should just ignore S. So let's write a truth table for that. So here's the truth table. So the first line says, well, if B3 is equal to 1, then I want P to be 1, right, because they pushed a button. And I want S to say, well, button 3 was pushed. And in that case, none of these others matter, right? B3 has the highest priority. The next line says, well, B3 was 0, B2 was pushed, then nothing else matters. I want P to be 1 still, and S should say number 2. Similarly, so forth and so on. So buttons 3 and 2 are not pushed. Button 1 is pushed. Ignore button 0. Say something was pushed. So P output is still 1. And here we say, well, button number 1 was the highest priority. And then this line says, OK, only button 1 was pushed. So we say, yes, I'm sorry, button 0. So a button was pushed, but it's number 0. And then last, if none of the buttons are pushed, P equals 0, and we don't care what S is. S should be ignored. So there's our truth table. We can then copy that into KMAPs. So here's KMAP for P. So what are the loops? It's an easy one, right? There's a midterm there. So here are some loops if you want to do it as SOP. And you get that. So a pretty easy circuit. How about this one? Pretty easy also? OK. So you guys know how to do this. OK, good. I'll skip it then. So this one is B3, B2. S0 is a tiny bit. Where's the other one? Square around here. Wraps around. Good. So if you write that one down, it's B3 ORed with B2 prime B1. Good. So there's an implementation. So not too hard. So this is a four-input priority encoder with priority on the 3. You could build 8. You could build 16. You just figure out the equations, and it's pretty straightforward, as you saw. All right. So we can then plug that in. So with this implementation now, this will only do purchases. So I want to build something that's only going to do purchases. We decided, remember, we're going to use an adder. Hopefully this is legible. Can people in the back read this? Yeah, good. OK. All right. So here's our register N in the middle. So that's our number of nickels. We've then got our priority encoder we just looked at up here. So the buttons are coming into the priority encoder. It's producing the P signal down here and the S signal up here. Remember, this is the register N, the number of nickels. So up here, there are registers storing the prices. Remember we said that instead of hardwiring specific prices, we would put each price into a register. So actually, these registers don't store P1, P2, and P3. What they store is negative P1, P2, and P3, so that we can simply feed them down here into an adder. So when we make a purchase, P will be 1, but S will also decide which of the three registers gets forwarded through this mux. So you see S here is used as the select lines on this 4-to-1 mux, or set of 4-to-1 muxes, which then outputs the price corresponding to the item that was selected by pushing one of the buttons. So the priority encoder, if you push more than one button, will only give 1, and S will say which one. So wait a minute, what happens if I don't push any buttons? What's S? Put a 0 in the equations I gave you? But we said don't care, right? So some bits come out of there, the mux forwards one of these down to here. So we better make sure that if we don't have P equals 1, this output is ignored. Because we don't really... I mean, that was the way we implemented priority encoder, but if we go buy one, who knows what will come out if P equals 0? So this adder then, whatever price comes out of here, will then go into the adder. You can see N is fed into the other part of the adder. So this adder now, for a purchase, will compute current number of nickels minus whatever price was selected. So the carryout then, since we're adding negative P1 to N, the carryout will equal 1 if and only if N is greater or equal to the price. So it's like a subtractor. So to overflow, meaning carryout is 1, these are unsigned values except we negated one of them, if we have enough money. So if we have enough money, carryout will be 1. If we don't have enough money, carryout will be 0. So then if you look over here, we have an AND gate. So it says, well, if the carryout was 1, that means you had enough money to buy the thing you wanted to buy. But you also have to look at, well, did you try to buy something? If you didn't try to buy something, some garbage is coming out of this muck, some bits. So we don't really care what happened in this adder. We want to make sure we ignore it. So unless you tried to buy something, unless you actually pushed a button, P will be 0. This AND gate will produce 0. So if you did try to buy something and you had enough money inserted into the machine, R will be 1. So R means, do we approve the request? Is it allowed? So R means request is approved. P is purchase requested. It says that one of the buttons was pushed. So if R is 1, you'll see that R comes around here and controls this mucks right here. So what does this mucks do? If R is 0, which means either you didn't push a button or you didn't have enough money. So if R is 0, where does that one come from? It comes straight from N. So we stay in the same state. So either of those conditions is true. We stay in the same state. On the other hand, if R is 1, well, that means you did push a button and you had enough money. So now the one input comes from the output of the adder. Well, that was N minus the price of the thing you wanted to buy. So now that's the right state to go into. That's fed back up into the register. So our next state is N minus P of whatever you tried to buy. All right, and then the last piece down here, you can see S, the thing that you picked, the item that you picked, is coming down here to this decoder. The enable is enabled by R. So if R equals 0, right, no purchase made because it was not approved or because you didn't ask, right, then this decoder outputs all zeros. So you don't release anything. These are going into flip-flops, one-bit registers, that will then control the release signals in the next cycle. And so that's where we're storing our output bits. So if the purchase is approved, meaning you tried to buy something and you had enough money and we changed the state to reflect that, then this decoder will have one 1. And the one 1 will correspond to the item that you bought. So one of the release signals will go out as a 1, and the item will drop out of the machine. And that will be selected by S, yes, which is the output of the priority encoder. So if you push B1, B2, and B3, it will say, oh, okay, you get 3. And assuming you have enough money to buy 3, it will take your money away, and it will output a 1 on the 3 output of the decoder. Any other questions? Yeah. Yeah, so remember that we don't want our inputs to directly affect our outputs. But we have to make a decision on the current state as to whether we're going to give them the product or not. So we make that decision, and that's R. But we can't just immediately give the R output. What we need to do is, because we want to build machines that don't have inputs directly as a function of outputs, is we simply add flip-flops after those outputs. So we're storing that output, which could have gone directly, but then it would have been a different kind of a finite-state machine. And in our class, we're always only going to change the outputs and make them dependent on the state. So when a state becomes part of the state, we latch those output values. They're held high or low for a cycle, which sometimes is important. So in the lab machine, for example, if you don't latch the gate output, then it'll just go down and up. And so whether you accept or not won't matter. It'll be too short to actually control the mechanical gate. So here, it might also be important. So we decide that we'll latch them into flip-flops for that reason. Anything else? In real life, of course. In an exam, no, we wouldn't do that. But we have had a fair number of problems where we have to analyze things. Maybe slightly less complex than this. Yeah, designing it, we might ask you to design part of it. The other problem is, honestly, if we did a full design like this, there would be so many different answers, it would be a nightmare to grade. So we might ask you to design part of this on an exam. So under exam three, there's a bunch of old exam problems from on finite state machines. So you can see the kind of things that you'll be expected to do. All right. Yes, I think I went through that one. So now let's think about what can we do to add the ability to put money in the machine. This machine we built, well, it's kind of cool. It handles purchases, but you can't actually put any money into it. So how could you ever buy anything? So let's figure out what do we need to do to handle purchases. Well, the first thing is we've got this coin input. So we've got the adder. So when a coin is coming in, we can use that adder to add the current state to the value of the inserted coin. The adder is already there, so we might as well use it for that too. And then write the sum back to the register if the sum doesn't overflow. Remember that if the sum overflows, we're going to have to either take away their money or not take their coin. So we decide to be nice and not take their coin. But what is the value of an inserted coin? We only have this three-bit representation. So here's our three-bit representation. I showed you the table before, but before this was number of nickels, and now this is a five-bit unsigned number, which is the value of each coin in nickels. So this is the number that we want to add. We've got a six-bit adder, so we're going to have to zero extend this out one extra bit. But let's convert from these three bits into a value. So how do we do that? Well, it's just k-maps. So here's B4. So there's our one loop. And here's the equation. There's B3. There's one loop. There's an equation. There's B2. There's one loop. There's an equation. So this is pretty straightforward. I'm going fast because on the harder k-maps, you told me it was too easy. So there's a big box for this one. So this is just C1 prime. And there's B0. This one could be what? Yeah, it could be XOR. I just did the C2 prime C1. Here's the implementation using those equations. So down here, you could have replaced this with an XOR2 and then not had to use the inverter. So here's our coin value module. So this is specific to RFSM. It takes the representation that we were given of what coin is this and spits out a five-bit coin value in nickels. So this is the kind of thing you did do on the midterm. So yeah, you would have this kind of problem. But until midterm three, we won't put it inside an FSM. All right, so the blue stuff is the new things. So the black stuff is the old purchase-only implementation. And so the blue color shows you what's been added. I know if you got the printed book, by the way, the blue doesn't show up too well. So you can look at the online version and you can see the colors if you want to see them. So what's in this diagram now? So up here is our coin value calculator. And you can see it's been zero extended. So this notation here, you can see this is five bits wide coming out of the coin value calculator. This is six bits wide going into the mux here. The fifth bit five, so these are bits four to zero. Bit five is a zero. So this kind of notation here means put one zero in front of the other five bits. And that'll become the six bits. You can see the bracketed bit indices there as notation. This mux then decides, well, are we going to put in the price or are we going to put in the coin value? Because we're going to use our adder for both adding value as well as subtracting out purchase prices. So how do we decide which one to put in? Well, we have this purchase signal P. Remember, they have priority. So if you push a purchase button, you put a coin in, it just ignores your coin, sends it back to you. The vending machine sends your coin back to you and ignores it. So in this case, we want to just look at the purchase price. So if P is one, we take our price out of this mux over here and forward that to the adder. But if P is zero, that means you didn't try to buy anything. So now we can look at the coin value and forward that to the adder. That gets added again into the current state, the number of nickels. And then it comes down here to this mux. So we have to decide, do we want to accept the coin? So how do we decide whether we accept the coin? We're adding the coin's value to the current state. So if we're going to be able to store the answer back, that sum has to fit in six bits. So how do we know? Well, just look at carry out. And if it overflows, carry out will be one. So if we get a one out of this adder, that will make this NOR gate go to zero. This NOR gate is generating the accept signal A. So if carry out is one, we have to reject the coin. Similarly, if they made a purchase, we always want to reject the coin. So if P equals one, goes to this NOR gate, also outputs a zero. So the only time you accept a coin is you didn't try to buy something and putting the coin in didn't overflow the sum. So if those two conditions are true, the NOR gate will give a one, and that will come down here and get latched into this one-bit register, just a flip-flop, one-bit register A. So same reason as for the R output. We're going to hold it high for a second. All right. So there's a little bit of logic left down here, right? There's this thing. So what is this thing? So whether or not we now stay in the same state or not depends on whether we're trying to make a purchase or trying to insert a coin. So in the case that we are trying to make a purchase, then this R signal might be high, in which case that will go and control our MUX just the way it did before. So remember, in order for R to be high, P has to be one. So the only time this gate matters is when P equals one. And the only time this gate matters is when P equals zero because if P equals one, this gate outputs a zero. So that going into the OR gate won't matter. So if P is zero, that's putting a coin in, right? No purchase. And so this gate then outputs accept. And if we accept the coin, this OR gate outputs a one. So this OR gate is either saying, well, we either decided to allow the user to buy something or we decided to accept their coin. So those are the two cases where this MUX takes its input from the adder and routes that back to be our next state. In the case where either we said, no, you're not allowed to buy that thing, you don't have enough money, or we said, we don't want your coin, this N input goes into zero input of the MUX, right? And we're picking zero, so that goes back and we stay in the same state, same number of nickels. I think that's it. Yeah, Eric. Yeah, so this NOR gate basically is generating the accept signal, right? You can see A is being latched out of this NOR gate. So when do you accept a coin? Well, there are two conditions. First of all, we said purchases have priority. So if they try to make a purchase by pushing a button, then the answer is you never accept it. So you can see priority encoder has the P output that says they pushed a button. That comes down here to the NOR gate. So one input to a NOR gate means a zero output. So in that case, since P was one, if they were allowed to make the purchase, then we'll still change the state to N minus whatever the current – whatever the price of the item they tried to buy. But if that purchase was rejected, we'll stay in state N. And similarly, if they didn't try to make a purchase, then this NOR gate reflects whether this carry out overflowed or not. On an overflow, that means we can't store the current state plus the value of the coin. So we reject it and we stay in state N. Yeah, yeah. So remember we – yeah, exactly. So if we had, for example, 60 nickels already and we tried to put a quarter in, well, we can't store the number 60 plus 5 is 65 in 6 bits. So we'd have to reject that coin. And that would show up as a carry out, right? Because you do a 6-bit add of 60 plus 5, you get a carry out. Yeah. Yes, that's right. So if you don't push anything, what actually goes on? So P is 0, right? So you're picking the coin value calculator. Let me flip – see how quickly I can flip back. So maybe I played a little trick here, which is that when you put nothing in, you get the value 0 out, right? I specified that in my KMAP, so that's definitely true out of our coin value calculator. So then the number 0 comes down to the mux. P was 0, so we pick it. We add N plus 0. That comes down here. And in that case, let's see what will happen. So no overflow and P was 0, so the NOR gate will give us a 1. This will give us a 1. We'll pick N plus 0, go back to there. So yes. So every cycle it will add N to 0 and write it back. A does not affect the coin value calculator at all. The logic is the other way. So you look at the value of the coin. You see if adding the coin makes your amount stored overflow, which is down here, the accept signal, and that is then stored. That is sent back to the coin mechanism, which is responsible for returning the coin if you say you don't want it. Just like in the lab that you're building, there's a gate mechanism that you had nothing to do with. You control it. You didn't build it. So there's some mechanism that some other designer builds that says, I'm going to look at your A signal, and if you say, don't take this coin, I'm going to give them back the coin. If you say, take the coin, I'm going to put it in a money box. Yeah, so that's an output. And this one is an input from probably the same mechanism that says, they just put in this coin. It has this type. This is the analog of the T input. It's more general because we allow many different types of coins, and this is the analog of the A output in the lab. So this is an output back to the mechanism like the gate in the lab. So they're held high for a cycle, high or low for a cycle. Yes. Yeah. Yes, yeah. So A is controlling whether the mechanical system accepts or rejects the coin. And N is the memory in the finite state machine of how many nickels we hold. And these R signals tell the mechanical system, let go of that product so they get it. Go ahead. Any other questions up here? Okay, so yes. So when we talked about MUXs, we talked about generalizing them. So you can see there's actually six inputs into each of these four for this 4-to-1 MUX. So in this diagram, this is actually six copies of a 4-to-1 MUX. And so anytime you see a MUX drawn with crosshatches on its inputs and outputs, that's multiple copies of that kind of MUX. So in particular, that would be six here. And if you wanted to make changes into 8-bit price registers, 8-bit nickel storage or whatever, then you would have eight MUXs. It's not much larger, no. So I think the trick wise, I think it's basically to break it up. So the way to work through these things is to try to figure out the human meanings. So usually there's some documentation on what the meanings are and to logically break it up into pieces. So that's what I tried to do for you walking through it. Yes, this is one 2-to-4 decoder with an enable. This is one 6-bit adder. You can build them any way you want. This is six 2-to-1 MUXs. This is six more 2-to-1 MUXs. I mean, I showed you a good diagram. Usually, something like a priority encoder you can usually pull off the shelf. Same thing for adders, registers. You've seen the implementations, right? You should know how they work. But usually people will provide these elements for you when you're building. In fact, once you even get into 385, I've mentioned this a couple times, but most of the building will be based on writing something similar to C code. So you'll say, oh, add A and B. And the tool will figure out that, well, I need an adder if you want me to add things. And so it'll put an adder down for you and route A and B into the adder. And then wherever you tell it to put the sum, it'll route the output of the adder to that place. So you're saying that this line here is taking its low bits from these five and the high bit from that five. We'll go on to memory. Let's go through this stuff then. All right. So I had a little bit of a memory block trying to get into these slides. So it will help. You're not that tired. I know it's Friday. Any other names? We're going to have a fair number of places. So I got A, B, C, oh, D. Good idea. Anyone else? Come on. I don't like those much. What else? E. Yeah. What else? F. I heard F. Okay. Those are good. Right on. That's six, right? A, B, C, D, E, F. Okay. Yeah. Okay. I think we're good. Okay. This might take you the rest of the hour. Really? A better idea? What? Did someone say bits? I heard bits. I heard someone say bits. Maybe I'm imagining. I don't know. Bits? Really? You want to name things with bits? All right. Really? Don't worry. Our names will be 0, 0, 0, 0, 0. All right. Fine. Do it your way. All right. So we'll use bits for names like you wanted. So we can probably build a circuit for that, right? Now we have bits. Name things with bits. So the circuit will let us read and write the bits stored in each of the 65,536 places. Right? So instead of having registers named A, B, C, we're just going to have a whole bunch of them. 65,000 of them. And they'll have names like, I really don't want to say 0 16 times. Imagine it. So a bunch of 0s or a bunch of 1s or 0, 1, 0, 1. So every combination of bits, let's call it an address. Okay? So you get a 16-bit pattern. We'll call that an address. So we'll have 2 to the 16th different addresses. Right? And that will let us name all of our places. And at every address, we'll have 32 bits. And we'll call that the addressability. So here's how we're going to use it. So if we want to read one of the places, right, each place is 32 bits. So if we want to read those bits and do something with them, then we're going to tell our circuit, well, here's the address of the bits that we want. Right? So we'll give it 16 bits and we'll say, these are the bits that we want. Somewhere there's, you know, that'll name one of those places. Then we'll wait for those 32 bits to come out. That'll be a read. If you want to change the bits in one of those places, then we'll tell the circuit, here's the place. Here's the 16-bit address. And then we'll give it the 32 bits. And it'll go put those 32 bits, store them at that place, the one that we named with the address. Oh, and we also need to tell the circuit, do you want to read or write? You need to say which one you want to do. So let's give these some I.O. names. So we'll say, well, the address will tell the circuit what we want to write to or read from, read or write, with address, ADDR. When the data come out, we'll have some data outlines. When we want to write the bits, we also have to give the address. We can use the same bit, the same input lines. Right? It's just an address, 16 bits, in the case we've been talking about. And then when we want to give the bits, we'll have some data input lines. And then we'll have a write enable signal that says either we want to do a write, in this case write enable will be 1, or we want to do a read, in which case write enable will be 0. All right. So here's a picture. Here's how we might draw it. We'll call it a memory. It has this one I generalized the number of addresses and the number of the addressability of this memory. So this one has 2 to the k addresses. So they're k address bits. So k could be 16, for example. And it has n bits at each address. So n could be 32, like we've been talking about. So that n bits at each place also means data input is n bits wide, and data output is n bits wide. And then it has this CS thing that we didn't talk about. There's write enable. There's CS. What's CS? CS means chip select. So often with memories, we're going to make use of many memories at a time. So we have a special control. It's like enable on some of the other components we've looked at. It's a little stronger than that in the sense that if chip select is 1, the memory is either going to do a read or write as we tell it to do. So we say chip select is 1, write enable is 0, it'll do a read. Chip select is 1, write enable is 1, it'll do a write. Chip select is 0, write enable is a don't care, it won't do anything. So if we turn chip select off, our memory will just not do anything. That's what it's for. That way we can have multiple chips and then decide which one we want to take action based on the chip select signals. No, no. So yeah, so that's a good question. So the question is, you know, if I turn chip select off, does the memory just get erased? No, not at all. It just means that it's not currently active. Its stored bits are still there. Good question. Go ahead. The realistic answer is, actually, I'm not sure. I think a lot of them are initialized to 0. I think when you power them on, they'll do, for the purposes of testing, they'll do some initialization and they'll end up all being 0 bits. There may still be memories that are just random bits when you turn them on. But I think most of them, when you power them on, will be all 0s. Yeah. Were there more? Edwin? Yes, yes. Each memory will have its own chip select. Oh, that's a good question. Let me come back to that one. Yeah, so when does data out become available? So yeah, it's kind of a complicated answer. So let me come back to that. All right, so the memory we're going to use in our class is random access memory, or RAM. So you may have heard of RAM. So what does it mean? It means that you can read and write addresses in any order, and that, more or less, the time to access any address is the same. So this is as opposed to things like tape, where one piece of the tape is next to the read head, and if you want to read other addresses, you have to turn the tape until you get close to that part of the tape. So those are serial memories. Random access memories, it doesn't matter what the address is. You can go read whatever address you want in any order, more or less at the same time to access them. In our class, we're only going to look at volatile forms of memory. So what does volatile mean? That's the part where they lose their bits. So if you turn off the electrical power, all of the memories we talk about, all the bits are going to go away. But turning off chip select will not remove the bits, just turning off the electrical power. Okay, so there's two kinds we're going to care about. One is called static RAM. It uses the two-inverter loop you've seen. So if you remember when we talked about storing a bit, we drew a couple of inverters back-to-back. That stores a bit. That stores a bit in SRAM, too, and I'll show you exactly what that looks like in a minute. So those will keep their bits indefinitely as long as you keep them powered on. So as long as you give them electricity, they'll keep their bits forever. In contrast, there's something called dynamic RAM or DRAM. This has a capacitor to store a bit. So there's a couple of charged plates, really tiny charged plates. There's some electrons on it. Remember, transistors don't really turn off. There's a transistor keeping the charge on those plates. They don't really turn off. So electrons can kind of go through the transistor even when it's supposed to be off. So eventually, those bits on the capacitor will go away. Sorry, the electrons on the capacitor will go away, and you'll lose your bit. So DRAM, the reason it's called dynamic is you have to rewrite it every so often. Every so often is typically tens of milliseconds. So you have to go rewrite every bit every so often. And so that's one issue with DRAM. I'll tell you more about it in a second as to why people use it, because that just seems kind of like a hassle, right? But there are big benefits to DRAM also. Both of these are volatile. So again, you turn them off, turn off the power, all the bits are gone. So SRAM is faster, uses the same semiconductor process as logic, which means you're designing a process or you're designing the logic you've been working on for the last, what, eight or nine weeks. All of those are able to be on the same chip, but it's much less dense than DRAM. DRAM is slower, and the refresh interferes with using it. If you have to refresh it, you might have to wait to be able to access it. But it uses a separate semiconductor process. So they're different chips. They're not on the same chip, usually. But it's much, much more dense. So you have more bits per chip area. So what do they usually use? What do most real systems use? Well, both and other storage types as well. So where is SRAM? SRAM is close to your processor. It's on the same chip. Your caches and things like that, don't worry if you don't know what a cache is. All the memory close to the chip for fast use is SRAM. The main memory of your computer, if you say, hey, my computer has 16 gigabytes, that's DRAM. You don't build, usually, 16 gigabytes of SRAM. That costs a lot of money still. And it wouldn't be on the same chip. It would be a box. So some storage, fast storage companies might use that kind of thing of SRAM. But a desktop or a laptop, this kind of size would be DRAM. So most systems often also have non-volatile memory. Your phone, your laptop, your desktop, servers, they have their own non-volatile memories. So some are flash or solid state disks, magnetic storage or hard drives, optical storage, DVD drives. Often you have all three. So what do you need to know in this memory stuff? So you need to know how to use memory. So the interface we talked about a couple minutes ago. The terms we just talked about. A little bit about how memories are built, which I'll show you shortly. So what SRAM and DRAM cells are inside, a capacitor versus a double inverter loop. Use of decoders to select cells. I'll show you how that works. Coincidence selection. I'll show you how that works also in a few slides. And then how to build bigger memories out of smaller ones. So if I give you a memory chip, can you put them together to build bigger memories? This is a common use. So I'll show you all of those things. What don't you need to know? Memory systems are analog circuits. So you really don't need to understand exactly how they work. I'll tell you a little bit about them, and I'll star them as we talk about them. Star the slides that are extra content. But fundamentally, they're analog designs. So understanding exactly what's going on is beyond 120. And also the details of DRAM operation, even how you interface the DRAM. If you're interested, section 364 will give you a brief introduction. All right, so here, as promised, is the double inverter loop. So this should look familiar, at least the circle part of it. What you won't necessarily understand yet is, well, we're using these n-type MOSFETs to connect these to what we call bit lines. They're bit and bit prime because they're going to be opposite values because of the way the double inverter loop works. So we have those. The MOSFETs are then controlled by select. So when we turn on the select line, these two inverters are connected to the bit lines. And when we turn off select, we set it to zero, these two MOSFETs will turn off. And then this double inverter loop will just store a bit. So to write a bit, what do we do? So we hold these bit lines at opposite values, and then we turn on select, and we force these inverters to accept our new value. So this circuit does something that we've told you never, ever do. Do you notice it? So if I'm going to set bit to one, and this thing is a zero, it's not oscillating. It's just short, right? Because inside those inverters, we are wiring this thing to ground, and this thing we just set is wired to high voltage. So we turn this transistor on, we have a short here and a short over here. I didn't expand those, but at these points, we were actually creating shorts. So that's one of the reasons you've got to design these systems carefully, thinking about, well, exactly what's going on at the transistor level and make sure these short circuits don't last very long because the short is going to generate power or get hot. So people have to think about this as an analog system. You don't just treat it as a digital system. Yes, yes. Inverter, there's nothing mysterious here. This is exactly the way we showed an inverter when we learned it the first time. I can, but I don't have a slide that does it. So, yes, let's do it after class. I'll draw it for you. So it's a major issue, right, because you don't want to generate too much power. So they're designed not to require too much power to store the bit. And you can do that by sizing transistors and using things like resistors in the right places. But it's an analog problem. It's not a digital problem at this point. Why don't they use two different select files? Between here and here? Here and here? I'm not sure I understand. I mean, so the reason we don't add a bunch more transistors in general is because that would be bigger. So the more transistors you add, the bigger this cell is to store one bit. So there are ways, and there are actually, this is the most common commercial cell. It's called a 6T cell. I have it on another slide. You can add more transistors to try to eliminate some of these problems, but in the end, it's still an analog design problem. So there are things you can try to do, but if you do it by making like an 8T or a 12T cell, then you've taken twice as much space for your one bit. And so it becomes less and less efficient. So there are some trade-offs there, but they're kind of outside the scope of 120 also. Yeah. Yeah. Yeah. A latch is much bigger. So a latch was four NAND gates and an inverter. As long as we drive it the right way, we do two NAND gates, so that would be eight transistors there. So, yeah, maybe I shouldn't overemphasize these. It's an analog design problem, so the way they build it, it's not that big of an issue. But you need to understand that you can't approach this as a digital design problem and just expect to put gates down, right, because you won't be able to solve it correctly. So at that point, you need to understand transistor sizing, IV curves as a function of sizing, and it's well beyond the scope of 120. That was kind of my point. So don't worry too much about it. Just realize that it's more complicated than you will see here and certainly more complicated than when you do the discussion section and you'll see a pretend version that you can use, but it's all digital. So it would be huge to do it that way. All right, so in order to read this bit, what ends up happening, again, it's analog, but you can think, well, all I do is I make these connections, I leave these bit lines floating, and then these inverters drive the bit lines either to 01 or to 10, depending what bit is stored. In practice these days, on SRAM or DRAM, always on DRAM, but in the last 10 or 15 years on SRAM also, these lines are actually charged to VDD over 2 and pre-charged before you turn select on. And then there's something called a sense amplifier, which basically watches the voltage from one bit line to the other, and as soon as it starts to drift away from zero, it pushes it all the way so that the voltage is digital 01 in one direction or the other, well, digital 1 in one direction or the other. Yeah, go ahead. No, it's mostly size, and in SRAM size is important. So here's my slide. So how many transistors is this? Six, right? So this is called a 6T cell. So you can add transistors, but if you add two more transistors, then you've got only, let's see, it would add 33% overhead, right? You've got about three quarters as many bits stored for the same area. And if you make it 12 transistors, you've got half as many bits. So two shown, two per inverter, 6T cell. So it's good reliability, small size, and it's one of the most common, and pretty good power too. So here, I think we're going to probably end up stopping soon. Let me talk a little bit about the bit slice. Yeah, I'll get about a minute. So this is a bit slice. So you'll see down here, I've labeled it with our abstract symbolic memory labels. I'll walk through it next time, but this is how you could build, for example, a 16-address, one-bit addressability memory. So you can see there's the analog logic over here. I think I did it in the next slide. Okay, so in this diagram, the select lines are vertical. The bit lines are now horizontal, and all of the cells are sharing one set of bit lines. So we're only going to read and write one cell at a time. And this over here is our sense amps and other analog circuits. So we're going to balance between the length of these bit lines, so usually they'll be bigger. We'll have lots and lots of cells per bit slice. And the reason for that is this logic here is relatively expensive compared to the cells, so we want to drive as many cells as we can with one copy of this logic. So let me stop there, and we'll pick it up on Monday. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\"},\n",
       " {'ECE120-2016-12-02-LEC-38-slides-start-at-22-min.mp4': \" you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you yeah, Eric? like, I forget one more thing you said that you can't represent one by one or you can represent one by one you can't have both you can't have two things which the things here are colors have the same bit pattern representation because then the then the representation is ambiguous right, so this one on the previous screen where these two colors were both represented by the same bit pattern that's not a good representation right okay okay alright, so so it's not it's not symmetric, right it's okay to have more than one pattern for the same color but not okay to have more than one color for the same pattern alright, so here's an example where we could we could do something like that I mean you've seen some already but in this example this is something called binary coded decimal this was used for a long time as the representation behind numbers and banking and things like that and business oriented software in fact the COBOL language would encode a lot of things using this sort of implicitly underneath and then certain ISAs also supported it so for example x86 actually still supports it because it was in the original x86 design so what is binary coded decimal? well you take your 10 decimal digits and for each decimal digit in your number you code it as a 4-bit value just using the binary representation of that digit and then these other 4-bit values well those don't mean anything okay, so you've got 6 4-bit patterns that just don't mean anything and each of your digits is one of the 10 binary values from 0 to 9 so it's not like a a number or a bit that your number is a key and you have to put them all in a sequence of digits? oh no, so this is representing larger numbers as a sequence of digits right, so if you wanted to have a number up to a billion you'd have to have 10 digits and each digit would be 4-bit so you'd end up having 40 bits instead of 32 bits in a more compact binary representation yeah, so it's less efficient but it's easier when you want to when you want for example to translate this to ASCII you don't have to do any conversion digit by digit you just add the 0 ASCII character and then print it out and vice versa so it's easier to use in some sense but it's less efficient all right, so what else can we do with these things? well what happens let's say we have an error so we see one of these six patterns so you have a number stored in your system supposed to be your account balance or whatever you see one of these six meaningless patterns well you know something went wrong so if you have this kind of redundancy in your representations you can say sometimes I'll be able to tell that something happened so can we use this idea to try to fix errors? well so what's an error? so here's an error a meteorite landed on some things here this is the crater in Arizona it's kind of cool to visit it if you've never been there but you know certainly you can't deal with all errors so some errors are going to be catastrophic you can't say oh I built this system it's going to be really reliable if a meteorite lands on ECEB the system is gone you didn't handle that unless you put a copy of your system elsewhere so you can't handle all errors because catastrophes are always possible and hopefully they're not common so let's focus on errors that are more frequent things that will happen a lot instead of things like meteorites hitting so errors are nothing new so when people wrote on stone stone kind of weathered and things started disappearing when people wrote on paper paper could get wet get crumpled and so forth when people write on flash well you know you put electrons here and then they tunnel their way to freedom and then they're gone if you didn't know that about flash don't ever put things you care about on flash they will do that in 20 years your data will be gone don't do that all right so our class is going to use a model that's slightly different that model I just showed you all of those examples are what are called erasures so the data are there you see that there's supposed to be some information there but you can't tell what it is because electrons got away or the paper is smudged or the stone is eroded so those are called erasures we're going to look at a more difficult type of error where things are actually replaced and so everything in our class is bits and so we'll look at bit flips so instead of a one you see a zero instead of a zero you see a one so that's our error model so let me show you the difference using English so this is erasures I put dots in place of the missing characters can you tell me very good very good okay here's errors exactly that goes this way yeah sorry now I kind of cheated if you look really carefully at these you'll notice they're both kind of compatible with one another but in general when you're doing coding and trying to correct this kind of things erasures are a little easier than errors because with errors you don't know what's wrong with erasures you know what's missing so erasures are typically easier than errors, mistakes where you don't know what's missing you don't know what's right or wrong so here is a probabilistic model so it's our bit flip model so a bit can change from a zero or a bit can change from zero I'm sorry one to zero or zero to one right and if we assume that all of the bit flips happen independently of all the others we have a lot of bits in our system at some point each of those bits might flip we have some very small probability that any bit might flip so we'll call that probability P then if we have n bits the probability that one of those bits has changed given the probability P for one bit and having n bits is the probability that we pick one bit which is n times the probability that that one bit flipped times the probability that all the other bits didn't flip so remember P is small right so this one minus P thing is is usually pretty close to one and the chance of getting two errors is this thing where this is the the ways to pick a pair of bits and then this is the chance that any particular pair of bits two of them have flipped so if you if you work out that math and you do the approximations then this one is about n times P times that one and in general we pick nP right if we know the probability then we pick n such that nP is much less than 1 and that means the chance of two errors is much much less than the chance of one error right so when we design our systems you have to kind of guess or know by measuring things well what's the chance of one bit changing and then you use that to decide how many how many bits you could protect right all right so let's look at another code so this is called a two out of five code this was actually used in a variety of telecommunication and computing systems and things like that so this instead of mapping into four bits this maps decimal digits into five bits and so you might notice the pattern each of these bit patterns of five bits has exactly two ones in it okay so each of the decimal digits then is mapped to a pattern of five bits with two ones so it's less efficient it takes more bits than binary coded decimal which is in turn less efficient than binary or choose complement but what's the advantage? so let's think what happens if we take some number coded with a two out of five code and one of the bits flips right so what what bit flips? well we don't know right so let's look at all the possibilities could be this one flips in which case we end up with this number here this bit pattern it could be that the second bit flips in which case we get this bit pattern could be the third bit flips that bit pattern the red in these is just for us to remember which bit flipped right you wouldn't get to know which one you would just see the bits fourth bit this pattern fifth bit that pattern do you notice anything about these five patterns? yeah none of them have two ones right none of them have two ones so as soon as you see any of these five patterns you say hey something went wrong you know something went wrong you detected the error so none of them means anything so we always detect that single bit error it turns out that regardless of which number I picked I just picked six I just picked seven but if you go back and look at this at this list any number you pick here regardless of what the original digit is if there's only one bit that flips you can always tell so with the two out of five code you can always detect one bit flip so that's that's error detection yeah Eric yeah Eric mm-hmm no no let's come back to that because I'll give you an example yeah so if you have two bits flip with the two out of five code you can't necessarily detect it good question but we'll come back to it anything else all right okay so first though I want to try to generalize this idea so let me go through that same exercise but ask you instead a slightly different question so we started with a two out of five code this is just one example the seven right and we said well we're going to flip a bit so let's ask instead how many one bits are there if we flip a bit so there's two choices we could flip a one or we could flip a zero if we flip a one bit how many how many ones are left? one if we flip a zero bit how many ones are left? three so regardless of which one we start with now by this reasoning now you should understand well it doesn't matter which one I started with all ten patterns had two ones and so after I flip a bit all ten patterns will have either one one bit or three one bits so it didn't matter which digit I started with right I can detect an error for any of the ten digits so what about other you know I just showed you decimal digits what about binary numbers, letters, colors is there some general strategy? I mean two out of five code only gives me ten patterns and so it's not what if I want to represent a floating point number? I probably don't want to write it out in decimal digits so is there some way that we could use this idea to have error detection for arbitrary representation? so let's see so we started with bit patterns with two one bits and we said well if you flip a bit flips from one to zero we have one bit and if a bit flips from zero to one we have three one bits so what if instead we started with an odd number of one bits so all of our bit patterns have an odd number of one bits then what happens if say a one flips to a zero? it becomes even right what if a zero flips to a one? also even so in other words if you start only using patterns that have an odd number of one bits then if there's one bit error that one bit error I mean it's either got to flip one to a zero or zero to one right but after that one bit error you always have a pattern with an even number of one bits and then you can look at it and say well that's not a valid pattern so then you know something went wrong right? so any bit flip gives what we call a non-code word the code words are the original valid patterns the ones that have meaning so this is what we call parity so if we add this extra bit a parity bit to each code word and choose that parity bits value right if we're going to add a bit well we can pick zero or one to put on the end and we'll pick it such that the number of one bits is odd just like we talked about and that's called odd parity you can also pick it to be even that would be called even parity you have to agree on which representation you want to use of course so here's three bit unsigned in the black digits with odd parity which is the blue digit I've added onto the end right so three bit unsigned goes from zero to seven and all I've done is add the add the parity bit on the end to make this a representation protected by parity so let's then take a look at well I want to define a distance so if I give you two bit patterns I want to define what I'm going to call hamming distance as the number of bit flips I have to do to move from one pattern to the other so here on the left I have 0101 and 0100 those two are only different in one bit so I'll say well this is distance one apart this top pattern from the bottom pattern this pattern over here 0101 from 0010 I'd have to flip three bits to go from here to there so I'm going to say this is distance three this is what we call hamming distance Richard Hamming was a Illinois alumnus in math he did his PhD here in math and then he ran Bell Labs Computing Center for a long time it's actually quite famous and he has many things named after him in various fields computing signal processing so hamming distance is number of bit flips right so for two patterns the hamming distance between them is the number of bits I have to change from one pattern to get to the other pattern that's the hamming distance so let's also define hamming distance for representation which I'm going to start calling a code so if I give you representation there's some patterns that are valid things right some that aren't but for the patterns that are valid things I want to ask well what's the minimum hamming distance between any two valid bit patterns any any two that mean something so the hamming distance of the code then or the representation is the minimum hamming distance between any two distinct code words so it's the minimum over all possible pairs so it could be hard to compute sometimes it'll be easy we'll do a couple of examples so what's the hamming distance of binary code a decimal one right you choose two code words for example zero and one and here this is distance one so there's an example of a pair at distance one you know that there any different pair is always at least distance one so then you have your answer right the hamming distance is distance one okay so BCD is hamming distance one what about hamming distance of two out of five so with two out of five codes if we have two different patterns a and b each of them have to have at least two one bits and they can't have the same two one bits right so that means a has to have at least one one where b has a zero and because they're different one bits and they only have exactly two and b also has to have a one where a has a zero so those are two bit differences I didn't put any constraints on which patterns I chose we've got two there right so you've got to have at least two hamming distance for the whole code and because of course I can I can easily find a pair that has exactly two the two out of five code has hamming distance two all right so what about parity so what's a what if I have a code with odd parity so like I give you the example of taking three bit unsigned but I can take a bigger representation I can I only protect a few bits with parity what if I had a thousand bit choose comp a thousand bit choose complement yeah could I protect that with one parity bit that seems kind of inexpensive yeah yeah that's right that's right yeah so that's a good analysis so there's two aspects one the single the single odd parity bit will work from a single bit flip but if you make the if you make the representation too big the chance that you actually have two bit flips goes up and with two bit flips we haven't shown it yet but I think maybe we sort of hinted at it with two bit flips of course you you won't necessarily be able to detect the problem so it's not limited from the theoretical sense but from the practical sense of the error probabilities going up too much for two it is limited all right so let's do this little yeah for small enough for a small enough number of bits you would I mean you would not need to do that you would I mean you would not go to a megabit with one parity bit but for for something like a 32 64 128 bit number if all you wanted was air detection a single parity is sufficient again it depends strongly on the error probability so it depends on the context for spacecraft the air probability is much much higher right because they're being bombarded by cosmic rays all the time yes yeah so you can always have you can always break things into into groups that you protect separately with individual parity bits good question another question over here okay all right so let's take a look at this this was just an example of parity and why the hamming distance is two so if you pick two distinct code words a and B we don't know what the bits are but we know that they have to be different right so let's just assume that they're only different one place that would make the hamming distance one so let's just assume that they're only different one place that would make the hamming distance one so let's just assume that they're only different one place that would make the hamming distance one so if we go forward without assumption well if that's true then A has odd parity we know because we said the whole everything has odd parity but then if they're ham if A and B are hamming distance one apart and A has odd parity then B has even parity but that can't be right because we assumed all of our bit patterns had odd parity right so this is a contradiction in our assumption that this location is unique therefore the location is not unique and so for any two bit patterns they have to differ in at least two locations that means hamming distance two so just a quick proof that with any representation one parity bit gives you hamming distance two all right so just this is then just a concrete example so this is three bit twos complement and you can see that I've added an odd parity bit on there and the difference between zero and one is two and so the hamming distance of this representation is exactly two you know from the previous slide that it's at least two for any parity based code but this one is exactly two so what happens if two bit errors occur this was the question you would ask Eric what happens if two bit errors occur when I have something like three bit twos complement with parity so here I have represented a zero and let's say the first bit error comes in and it flips the bit the zero here so now I have zero zero one one and then a second bit flip happens and I get zero zero one zero except that's the pattern for one all right so if I have those two bit flips happen to my original value I won't be able to know oh something went wrong I'll look at that and I'll say oh the parity is right it's correct it's a one right even though what really happened was two bit flips so I won't be able to know it so this is why you do have to worry about the possibility that more bit flips than you expect will happen so no error can be detected in this case all right so more generally if we start with a code of Hamming distance D and then we want to know well given Hamming distance D for my code how many how many errors can I detect remember that Hamming distance D implies that if I pick any two code words those two are at least D bit flips apart okay so if I start with one and I only flip D minus one bits or fewer I can't get to the other one right so if I start with a code word and then I flip one bit or two bits or up to D minus one bits I can't reach another code word and so I always stop at a place that isn't a code word so as long as there are somewhere between one and D minus one assuming that's meaningful if D is one then you can't detect any errors right but at least but between one and D minus one bit errors I can always detect if I have Hamming distance D for my code and so this is the relationship between error detection and Hamming distance this is why Hamming distance is a useful concept and if you know the Hamming distance of the code you know how many bit errors you can detect with that code it's just D minus one yeah no no this is a general code parity Hamming distance is two so it works for parity but this also works for any other code where your Hamming distance might be larger so later I will show you probably on Monday I will show you Hamming code which has Hamming distance three so those can be used for detection two-bit errors you can also build bigger codes I shall show you also Hamming distance four code which you could use to detect three errors if you wanted to up to three errors. It always refers to ones which is equivalent and the odd parity means an odd number of ones you can also have even parity which is an even number of ones and it's there's a one-bit difference. There's a one-to-one mapping right because if your characters are only zeros and ones as there are for all of our systems then the number of zeros is the number of bits minus the number of ones. Yeah, yeah, yeah and that it's a convention and the convention is necessary because otherwise if I say odd parity you wouldn't necessarily know whether it's whether it's odd number ones or zeros and then you wouldn't have a well-defined representation. So it's always the number of ones. Yeah. So these are errors remember so you don't want this to happen but you in order to protect it protect against it you need to make whatever number of bit flips you expect you need to have a Hamming code with a code with large enough Hamming distance that you can't happen as far as you're concerned. Now again you know when you say can't happen it's a probabilistic argument right so typical error rates the optical fiber error rates for example used to be something like one in a billion bits I'm sorry one in a billion flips per bit so if you sent a terabyte of information down you could you could do the math you know figure out how many bits are in a terabyte divide that by I'm sorry it was a trillion it was 10 to the 12th divide that by a trillion you would expect to see at the other side of your optical fiber. Optical fiber is actually quite good I mean copper and things like that much higher two or three orders of magnitude higher error rates and wireless is really bad so which you probably know from having just used it but it's because of the bit error rates and other phenomena. Okay so let's let's take a look then at error correction or at least get the motivation so sometimes that's just not enough. You know sometimes that's just not enough right hey I've got an error right so well what happens if your bank calls you up one day and say hey you know what there was an error it turns out there was an error with your account balance and the account balance now after the errors in there we can tell because the parodies are wrong but the error says you've got $500 so we're thinking we've got two options for you you know one is one is well maybe the parody bit got flipped right so okay that's fine you got $500 but we think probably what happened is the sign bit got flipped so when you can pay us the $500 let us know and I think hopefully all of you as you know ECE majors would go back to no, no, no, no what happened was the big the highest zero bit in the exponent got flipped and this was my balance. I just had a big deposit right so when you get this money let me know. All right so and you know so that's one example. Oh wait there's an alert. What's going on here? Oh good. Yeah. So another thing you never want to see again right so please if you work on we saw in the curriculum committee we were talking about where our students go and a bunch of people said they would go into medical devices right. Please never write this. Use something stronger. All right so error correction. Can we use redundancy to correct errors? Yeah but the overhead is going to be higher so if we want to correct errors we're going to need bigger more Hamming distance basically is the short argument and we can see more detail on that on Monday but let me just show you so here's our odd parity Hamming distance is two. Why can't we correct an error? So one bit flip remember could be from here so we see this pattern. It might have come from here. It might have been that we sent this pattern or we stored this pattern and this bit got flipped and we saw that. On the other hand it might have been that we stored the one and the other and this bit got flipped so if we see this pattern what should we pick? It's the same as the banking problem. We have no idea what we should pick. We don't know which one it came from so we don't have a good answer to that. So for Hamming distance is only two we're not going to be able to correct an error. We'll need a bigger Hamming distance so here's an example, very, very simple example, not a good strategy but here's two copies. So here's two bit unsigned copied three times just for us there's a black copy and a blue copy and a green copy but it's just a six bit pattern so now if we get one bit flip then something changes but only one of the three copies can change so now the other two copies you can look at all three copies and do a little voting exercise and the majority vote correct. So I got two, zero, two. Okay. That was a two. I'm done. So I can actually correct an error. What happens if I get two bit flips? So two bit flips then two things can change in different copies. I can do my little voting exercise. Two, zero, oh, this was a zero. Sorry. So it's important to realize in this case if you do correction you might actually get a good result. So be careful with that. We'll talk more about this on Monday and show you examples of good codes for error display. you you you you you you you you you you you you\"},\n",
       " {'ECE120-2016-09-09-LEC-08-slides-no-sound.mp4': \" Yn ystod yr oergell, mae'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Mae'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Mae'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Yn y gweithlu'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Yn y gweithlu'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Yn ffurfio, mae'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Yn ffurfio, mae'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Beth ydym ni'n ei wneud heddiw? Cofiwch y codi os nad oes un. Byddwn ni'n mynd i ddod yn ymgyrch programau i'w edrych. Cofiwch eu cymryd yn y gweithlu os oes gennych gyfrifiadau gyda chi. Ond, arall, gallwch edrych ar eu cyfrifiadau a dilynu arnynt. Byddwn i'n mynd i ddod yn ymgyrch i Notepad, a'n mynd i ddod i'r gwaith a chyfrifiadau. Mae angen i chi edrych ar y codi. Dw i am ymgyrchu'r lwybrau byw. Cofiwch y codi yn y gweithlu'r ddiweddarau. Yna, byddwn i'n mynd i ddod i'r programau cyfrifiadau. Cofiwch y lwybrau byw, y codi yno. Cofiwch y programau C. Mae un o'r programau yno. Cofiwch eich codi. Efallai na fyddwn i'n mynd i'r gweithlu. Nid wyf yn siŵr pa mor ffordd byddwn i'n mynd i'r gweithlu. Felly, bydd yr holl slaidiau, fel arfer, yn cael eu cyflwyno i chi. Mae'r rhain yn cael eu cyflwyno. Rwy'n cwestiynu am edrych ar y leicwyr, y fideo yn Chrome. Fe wnaethom ystyried hynny yn fy swyddfa, ac mae'n deimlo'n iawn. Rwy'n cysylltu â'r IT. Ond, yn aml, mae Chrome yn gweithio i mi hefyd. Felly, dechreuwch i ni edrych yn gyffredinol ar y llwybr pwll. Mae'r llwybr pwll yn cael 4 rhan. Mae yna ddynion cyfnodol, dynion test, dynion cyfnodol cyfnodol newid, a'r bod lwybr. Y ffordd y mae'n gweithio yw ei ddefnyddio'r adnodd unigol yn gyntaf, ac yna'i ddefnyddio'r adnodd test. Os yw'n ffwrdd, mae'n parhau. Yna, mae'n gweithio'r llwybr pwll, y ddatganiad o'r cyfnod, ac yna mae'n mynd i ddefnyddio'r newid, a'i gyrraedd yn ôl i'r stryd ddwy, a'i gwirio'r test eto. Felly, cofiwch, yn gyntaf, y adnodd unigol, ac yna'r test, y llwybr pwll, y newid, a'i gyrraedd yn ôl i'r stryd ddwy, a'i gyrraedd yn ôl i'r test. Byddai'n gallu bod nad yw'n mynd i'r llwybr pwll. Gall y test fod yn ffwrdd y pryd. Felly, pam y llwybr? Byddwn yn ddangos hyn i chi, ond byddwn yn ceisio'n fawr na'i defnyddio, fel y byddwch yn gael gwybod unig sut mae'r llwybr pwll yn gweithio. Mae'n gwirionedd yn ddim iawn. Felly, mae'r llwybr pwll yn unigol yn cael test, ond mae'r llwybr pwll yn ddim iawn. Felly, mae'n wirioneddol eang i chi, ond meddyliwch nad yw gennych y ddwy ffwrdd, felly nid oes unrhyw beth i'w wneud ar gyfer y rhanau hynny. Felly, yn benodol, os ydyn ni'n cymryd ein broses bwysig, byddwn yn nesu'r bwysig. Nid oes unrhyw beth. Yn gyntaf, byddwn yn cyfrifoldeb y test. Os yw'n ddifrifol, bydd yn parhau. Er allai, byddwn yn gweithio'r llwybr pwll. Felly, mae'r llwybr pwll yn ddifrifol. Gallwch ddod at y llwybr hwn yn 220. Mae'n ddifrifoldeb syntactig pan nad oes gennych test. Ond, dydych chi ddim yn ei gael. Iawn. Felly, dyma beth rwy'n eisiau ei wneud ar gyfer y rhan fwyaf o'r diwrnod. Felly, rwy'n eisiau mynd trwy rhai enghraifftau coed gyda chi, a gwneud yn siŵr bod chi'n dilyn, a'ch bod chi'n teimlo'n deall, a'ch bod chi'n deall sut mae'r coed yn gweithio. Bydd angen i chi ddysgu sut i'w gyrraedd. Rwy'n credu eich bod chi wedi gwneud hynny eisoes yn eich lab. Felly, bydd angen i chi ddysgu hynny yn y lab. Mae yna rhai gyrraeddau style ar y wiki y dylid i chi edrych arno ar unrhyw bwynt. Gallwch hefyd edrych ar y cyfrifau coed rydw i'n eu rhoi i chi i feddwl sut y gallwn fod yn dynnu fy nghwaraethau neu beth bynnag. Cysylltai enwau gwahanol. Byddwn yn ymddangos ar y rhai o'r rhain hefyd. Byddwn yn cyflawni'r pethau sy'n iawn oherwydd roeddwn i'n rhaid eu cyflawni i'r slyd. Byddwch yn gweld hynny'n y ffordd da yn y coed. Y pethau rydw i wedi'u rhoi i chi, byddai'r rhain yn ymgyrchu. Mae'r rhaglenau ar gael i chi ymgyrchu, felly dydynt i chi ddod â'u cysylltu neu rhywbeth. Felly, dyma'r llwybr Fibonacci a dyma'r llwybr y gwnaethom ni ei ddangos yn y diwrnod diwethaf. Felly, byddai'n werthfawr gael ymgyrchu o fapur. Byddwn yn newid i Notepad. Dyma'r rhaglen gyntaf ar y cyfnod. Rwy'n credu mai'r ddau o'r rhan ymlaen yw'r rhan yma. Felly, dyma'r hyn rydyn ni'n ei gael ar gael wrth i ni fynd ymlaen. Felly, byddwn yn gweithredu un peth ar y tro a byddwn yn rhoi coment yn ysgrifennu beth ydym yn ei wneud ac yna byddwn yn newid beth bynnag a bydd yna newid o fawr neu os oes printiaeth a bydd yn gwneud rhywbeth o ddifrif, byddwn yn rhoi yn y colwm beth yw'r ddifrif. Yn y slaidau, os edrychwch arnynt yn ddiweddar, byddwch yn gweld bod yna rhai pethau yno. Byddwn yn datblygu hynny ein hunain. Felly, os edrychwch yn ôl i'r slaidau, gallwch weld yr holl ddatblygiad honno, ond byddwn yn ei wneud yn y clas yn lle'n gwblhau'r slaidau. Felly... Yn y slaidau, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno.\"},\n",
       " {'ECE120-2016-11-30-LEC-37-slides.mp4': \" and Hamming codes and then also SECDEAD codes. I should mention, I think it's probably clear from the wiki, but there's a homework 14, but it's not actually due. So we'll give you solutions. I suggest that you do it because those kinds of problems will be on the final. So it'll be the kind of things we've been doing this week and the things we'll do today and Friday. So you won't have to turn it in, but you will get solutions for it and you can check your answers and stuff like that. Okay, so you've seen everything in the data path and how it works and how the control unit drives the data path to execute RTL for all of the states. So today what we're gonna talk about is, well, how do you actually go about building the finite state machine that the control unit is? How do you make it work? So I wanna go back and say, well, what does the control unit actually do? And so you know, it drives RTL with control signals, but well, as you should remember, it goes in, it fetches an instruction and it executes that instruction, goes back, starts over. Very exciting. The control unit. Okay, so how can we actually implement that? So let's start by making a simplifying assumption. Let's assume that we can fetch an instruction in a fixed number of cycles and that we can also execute any instruction in a fixed number of cycles. Not all ISAs, for not all ISAs is that the case unless your fixed number is very, very large. For example, x86 has a string copy instruction that takes a register as the length of the string. So you can copy, you know, a gigabyte of memory from one place to another with one instruction. So that's not the kind of thing we have in mind when we say fixed number of cycles, right? Be, I don't know, five, 10 cycles. Some processors had instructions that were 100, 150 cycles, but you know, some number of cycles that's reasonable. And in that case, sorry, we can use a counter, right? So we can actually build our finite state machine around a counter where we say, well, the first few cycles, whatever it takes are fetch, and then the rest of the cycles are executed and then we'll start the counter over and we'll start the process over and fetch a new instruction. So control unit FSM does the following. So given as inputs, the counter value, right? So we're gonna build it around this counter, the IR, the instruction register, that of course is gonna tell us the instruction. And as you know, those bits are meaningless until we fetch the instruction, right? So we're only using the IR in executing the instruction. During fetch, we're not gonna use it. Signals from the data path. So we'll talk about what those are in the context of LC3, but it could be whatever feedback is coming from the data path, some signals coming out of it. So given those things, then the control unit is gonna generate the data path control signals using combinational logic. So if we use combinational logic, we call that a hardwired control unit design. So hardwired just means somehow we're gonna design combinational logic. Could be with KMAPs, it could be, as you'll see, by figuring out all the bits and putting them in a read-only memory. And it doesn't really matter how we build the combinational logic. What matters is we're gonna use combinational logic and implement this control unit that translates these things into control signals. All right, so for a simple enough ISA and a powerful enough data path, arguably, you can have a single cycle hardwired control. If you can put everything into one cycle and get it all done, probably you need a fairly complicated memory, right? Because you gotta be able to fetch the instruction and execute it. So it's pretty complicated data path and usually a slow clock. So people don't really build things this way, but there is a name for it, single cycle hardwired control. The thing that's more interesting then would be multi-cycle hardwired control. So let's start with Pat and Patel's LC3 data path and their finite state machine state transition diagram, and think about how could we build a hardwired control unit that would actually make use of that design. So as you should remember, the LC3 data path in the book, I mean, it cannot fetch an instruction in a single cycle, it takes three states, and then the memory state might take many cycles, we have to wait for memory to finish. And it certainly can't execute in a cycle either, it's got five states for some of the instructions, like the LDI we looked at is five states long. So we can't fetch nor execute an instruction in a single cycle, but we can still use combinational logic for our design. So this is still a hardwired control unit, but it's gonna be multi-cycle. So how many cycles do we need in that design? So fetch has three states, or how many states, maybe I'll ask. So fetch has three states, remember we went through first you put the PC down into the MAR, increment the PC, then in the second state, you go read memory, and then third state you copy MDR across the bus into the IR. And then the longest instructions, LDI and STI take five states. So we saw one of those on Monday. So the total is eight states, so we can use just a three-bit binary counter to drive the core of our FSM. So here's just an example of what those would mean. So the counter value will run from zero through seven, the first three states will be the first, second and third fetch states. Yeah. Ah, so that's a good question. Let me come back to that in a second. So I didn't put decode up here, and that's a good question as well, where'd the decode go? Because remember in the Pat and Patel state machine, you've got the three fetch, then you have a decode, then you have the different execute states, right? So here in the counter, I've only allocated counter values for the three fetch states and five execute states. So what happened to decode? So, all right, so Pat and Patel have a different strategy, which we'll talk about later, it's called microprogramming. Their strategy, as I've talked about a couple of times, requires an explicit decode state, right? Because what's happening is in the third fetch state, we're actually bringing the bits across the bus from the MDR into the IR. That RTL executes on the rising clock edge, and so not until the fourth cycle are the bits actually in the IR. But you wanna use the bits of the IR then to go to different finite state machine states, okay? Here, our states are kind of implicit and our combinational logic uses these IR bits directly. So in the fourth cycle, once the bits are in the IR, they're going into the combinational logic and we can make use of them to actually execute, because we're also, we're looking at the opcode and we're looking at the counter value that says, okay, this is the first execute cycle. So the combinational logic just handles that directly and we don't need an explicit decode state. Pat and Patel with microprogramming do, because they have to split the state based on the IR and they can't use the IR until the fourth state. Make sense? All right, so what about the shorter instructions? So remember an add only takes one cycle, right? You do your three fetch and then do your add and it only takes one cycle. We allocated five cycles for instruction execution for LDI and STI, because those will take five or five states, I guess. So do we need to sit around and wait? What can we do? So what if I just, I get here and I finish my add and I finish my add, I just push my counter back to zero. What happens? It just goes and does another fetch, right? So what can I do to not wait around for four cycles? Just reset the counter, right? So I'll add a counter reset signal. So this won't just be a binary counter that just wraps around. I mean, that would work, right? But then we would have to wait around for four cycles. So add a reset signal. That'll be another control signal. Whenever we're done with an instruction, whether it's one cycle long or one state long or five states long or three states long, doesn't matter. At the last state, we'll exert counter reset and then we'll go back to fetch. So we'll only spend as much time as we need actually executing the instructions. Memory access can be slow. So do we need our clock speed to be slow enough for the memory? Or is there something else we can do? Yeah. Yeah. Let me. So the, for memory access, you can type in the process you set up and type in the information you need. Okay, so something like a memory ready signal or something? So what do we need to do with our counter? Oh, the counter that's not in the middle. Yeah, well, no, no, no. The counter that we're using to drive this one. Yeah. We better make sure it doesn't keep counting, right? Yeah, so we need to just stall it or pause it, right? So is that a pause signal? So we could call it stall, doesn't matter. Just some kind of signal to the counter that says, don't keep counting right now. We're still waiting for memory. Once memory finishes, which I'll just use in this design, I'll use the same signal that Pat and Patel use, which is the signal R, memory ready, meaning it finished its access. Once that signal is exerted by the memory, that means we can move on, right? So somehow we'll use that to decide how long we have to pause the counter before we can continue. And then our clock can run at the speed of the logic, which is what we want. Okay. So here's the general design. We've got some N-cycle binary counter. So for LC3, that's gonna be eight cycles, so three bits. You've got your IR and your PC feeding into combinational logic, producing control signals that drive the data path. The data path has some status signals that go back also into the combinational logic. We also can have the data path using the IR and the PC directly. But yeah, Mohamed. Yeah. No, because only in the states where you are waiting for memory, do you wait for memory. In the states like add execute, there's no memory operation. And so that takes exactly one clock cycle. And if memory is 50 times slower than their logic, then that's 50 times faster for the add execute state. Good question. All right, so this was, sorry. So this was our general model. I just added these arcs just to make sure you understand. I mean, these IR and PC are sort of sitting in the data path. You know they're being used anyway, but I didn't want you to think from the figure that they weren't being used. Yeah. Only if you try to pipeline and we're not pipelining our designs. Yeah, this is just executing one instruction at a time. Okay, one. Okay, so. All right, so how complex is this combinational logic? So we said, okay, we're just gonna build everything with combinational logic. And we know the inputs. We know we've got 25 data path signals plus our pause and our reset. So we also know for LC3, PC does not directly affect the control. And so if you look at all of the different states, we never use PC to make decisions. We use it as data, right? When you do PC relative addressing, or you change the PC for branches or other control flow instructions, but you don't actually make control decisions based on your PC. So we have as our finite state machine inputs, these three bits of counter state. We have the IR, which is 16 bits. So that's a lot of state. And we have data path status signals. So maybe that's, I don't know, around 24 bits or so, right? It could be around there. So get your KMAP pens ready. Ready for some 24 input KMAPs. So that's a lot, right? I mean, that's pretty nasty sounding functions. So at that point, really good design kind of comes to the rescue. So Pat and Patel spent a lot of time thinking about how can they design the LC3 data path to make control simpler. You've seen a bunch of examples of how that works. Things where, you know, bits in the instruction encoding can be used to specify the source register, for example, and those can then just be fed directly into the register file, rather than having to come up with those bits as part of the control unit. So you've seen a bunch of those examples already. So I won't spend a lot of time explaining it, but it's really through their effort that we can make these simplifications, right? So they design things so that it's easy to move bits around with wires rather than requiring lots of extra logic. So what inputs do we really need for the combinational logic? So if we think more carefully, well, we still need the three bits of counter state, right? As we walk through the different execute states, it's doing different RTL. So we need to know which state we're in. That's clear. We really only need the op code out of the IR. Everything else is kind of wired through muxes and we just need to control those muxes, right? The data path's been designed to let us not have to worry about those in terms of the states of the finite state machine. So we just really need those four bits. There's actually one instruction we didn't look at in our class called JSRR that uses IR11 as an addressing mode. So in fact, if you want to implement the full ISA, even without privilege and interrupt, you need IR11 as well. So we'll just add that in. And there's really only two data path signals we'll care about. One is the memory ready signal, R, that I mentioned a few minutes ago. And the other is the branch enable signal, right? The thing that we were calculating before in decode. So that will still have to be calculated at some point. So branch might get a little longer in this hardwired implementation because we couldn't use it until it's ready. Okay, so those are our signals. So if you add those up, let's see, we had three plus four plus one plus two is 10, right? So 10 bits of input, that's still somewhat complicated. So let's see, so how many control signals? So 10 bits of input. So control signals, 25 that we talked about on Monday, and then we added counter reset and counter pause, right? So we've got 27 total. So we still have 27, 10 input functions. So I think probably if I said, okay, get out your paper and solve all 27, 10 input functions, you'd probably be a little unhappy. So is there an easier way if we have all of those bits? So what if instead of really going and building from gates, we just said, well, let's just put a read only memory down. Right, so let's just figure out the bits and then we'll put them in a read only memory. That way it's also nice, if I figure out all the functions and I build it out of gates, and then I realize I messed something up and I left out a state or I did something wrong, I might have to go recalculate a lot of my functions, basically start from scratch. If I mess up some bits in a read only memory, if it's really read only, well, then I have to get a new read only memory and program it with the new bits, but I just have to change the bits, right? A lot of the, you can often get a programmable read only memories and change them, right? So if you make a little mistake in your design, just fix the bits and you're done. So, the 10 bits, how would we actually use this? The 10 bits of input are gonna act as an address. So we've got these 10 bits, the three bit counter state, five bits of the IR and two bits from the data path. We apply those bits as the address and outcome 27 control signals, right? So we need 27 bit addressability and that gives us this two to the 10 by 27 bit memory and total is over 27,000 bits. So that's not too bad, right? That's only 32K memory or something, less than 32K. I guess exactly 27K, but smaller memories would be faster, right? So if we wanted to make this a better design, we should think about, well, are there ways we can have fewer bits in that memory, right? Are there ways we can trim it down a little bit? So let's think a little bit. The data path in Pat and Patel was designed for their control unit, right? So if we are willing to make a few little changes here and there, we can actually make a better design for hardware control unit. So let's see how we can do that. So one piece is the memory ready signal, what's it used for, right? Anytime we access memory, whether it's instruction fetch or load or LDIs first load or store or any kind of store actually, anytime we use it, we're using the memory ready signal to wait to see, well, did that access finish, right? And we're just staying in that state until it finishes. So the only reason we use that is to generate our pause signal, right? So what's going on in this design as we've said it so far is well, memory ready signal goes in as one of the address bits. And for every one of these states, we actually have two different addresses. One is which memory is ready and one is with memory not ready. And one of them has pause on as one of the bits in that memory location and the other doesn't. So instead, we could just take that logic out of the ROM and put it into the data path. It's pretty simple logic. So for example, let's instead add a control signal called waitmem. So in the states where we have to wait for memory to finish, we'll exert the waitmem signal. And then the finite state machine states that stall, like I said, they'll set waitmem equal to one. And then in the data path, we'll just add this little bit of simple logic. So pause, the input to our counter pause will be R prime and it with waitmem. So the only time you're gonna pause is when memory is not ready and you're told from this control signal, well, you have to wait for memory to be ready. So we cut the control signals by one by removing pause, but we added a new one, waitmem. So the control signal is still 27 of them, but now we don't have to put the R signal as an address bits. We only have nine address bits. So that means now we only have half as many memory locations, so half the size of the memory. So one tiny little bit of logic added to the data path would cut the memory in half. So what about branch enable? So branch enable is used in the branch instruction, and if you see the branch enable is false, you go back to fetch. And if branch enable is true, you change the value of the PC before you go back to fetch. Well, so again, our initial design does that computation implicitly by having different addresses. We're routing branch enable as an address bit. The ones with branch enable turned on will continue and execute the PC change. And the ones with branch enable turned off will go back to fetch by resetting the counter. So instead, what we can do is add two more control signals. One will be branch reset. So the branch instruction will use this control signal, and all of the instructions when they're finished will exert a second control signal, second new control signal called instruction done. So then we can set in the data path, the reset signal will be calculated with this little bit of logic. So we'll say, well, whenever the instruction is done, we'll reset the counter. Or if we have branch reset exerted and branch enable is not true, that means we're doing a branch instruction, but the branch should not be taken. So now we just wanna reset the counter immediately. In either of those two cases, reset will be true. So now we have two more control signals generated. We're no longer generating reset from the control ROM. So we have one extra, so that gives us 28 and one fewer input. So again, cut roughly in half. So now we have one more bit of addressability, but we have half as many addresses. So now we're down to about a quarter, just with a couple, a few gates. So there's one more thing we can do very easily, which is this JSRR problem. IR11 is used only for that particular instruction to decide between JSR and the JSRR instruction. One uses a PC relative offset, the other uses a base register. So decide between those two, what we can do instead is connect the base register, which is an SR1 over to the fourth input of PCMUX, and then use IR11 directly in the data path with another control signal. And so if we add that extra control signal and take IR11 out of the inputs, then we're down to two to the seven addresses, seven bits of address, three for the counter, four for the opcode, and then 29 bits of addressability for control signals. So total is less than a seventh of the original design, so a little more than an eighth. These are some details, I don't think I'll go through these, but eventually these will go in the notes. Yeah, I realized, as you'll see, I realized that without doing the simplification, we can't actually get our hardware control design down to 32 states. So we do have to do the simplification to have only five bit addresses. All right. Any questions on that before we talk about microprogramming? Feel like you understand the hardwired design? Yeah. Mm-hmm. What's the, so the JSRR, what's the one thing, IR, that's what you're looking for? So what we did is we made a more powerful data path, but we didn't have to add much logic, right? So remember PCMUX had only three inputs connected. So there's a free input. So we use that free input to put SR1 onto that input. Yeah, there's actually a long story here that the, I think it was in the early days, but I think it was in the early days of the first PCMUX, and I think it was in the early days of the first PCMUX, and I think it was in the early days of the first PCMUX, and I think it was in the early days of the first PCMUX, but I think pretty much all of the versions you can find in the wiki and the webpage and the notes and so forth of the Pat and Patel data path are the old version, which has a bug in JSRR, which they then fixed in later instances. So those of you that have newer books probably have a slightly different finite state machine implementation of JSR and JSRR. So those can be combined with this little extension so that there's only one state instead of three states. No, LC3B stands for byte addressable. Let's use for 411. Yeah, no, it's not related. Okay, so let's talk a little bit about micro-programming then. So that was hardwired control. So here's the finite state machine, and this is the one, let's see. So in the newer versions, this R7 gets PC, gets copied down into both of these two states. This is the JSR and JSRR implementation here. This one is JSR, this one is JSRR. But that's not kind of the point. I just wanted to show you while we had it up. The point of this slide is, well, this is a pretty sparse, sparse finite state machine diagram, right? I mean, in theory, you can draw finite state machine diagrams, and there's so many bits of input here, you could have hundreds of arcs going out of every state. And we said, well, you have to make it complete. But this looks more like a flow chart or something, right? It's got one arc going out of most states. Sometimes you have two. The only place you've got more than two is decode. And everywhere else, there's only one or two arcs leaving. And so it's a pretty simple thing in terms of finite state machine transition diagrams, relatively simple, very few arcs. Yeah, go ahead. I mean, it has the same utility of jump versus branch, right? It's just longer range, because the PC offset is limited. Okay, so can we treat this as a program? So what if instead of thinking of this as a finite state machine design problem, we thought of this as a programming problem. So think of the control words, right? So each state has some RTL. That's what we looked at on Monday, taking that RTL, turning that into control signals, right? So you can think of those sets of 25 control signals as a control word. So each state has a control word, and maybe instead we'll call those micro instructions, right? So what the control unit is then gonna do is to execute micro instructions. And so the way it'll do that, the program will be this thing, right? And so each of these will be a micro instruction, and we'll go through and execute those one at a time. We'll store micro instructions in a ROM and use the state ID as the address to that ROM. So we'll read the micro instruction for that state and then use that micro instruction to drive the data path and then go on to the next micro instruction. And so this is called micro program control unit design. So if we ignore, again, interrupts and privilege and include that extension that I mentioned with JSRR and PCMUX, then we need fewer than 32 states. So then we can have five bit state IDs, which was kind of nice. And so very tiny state IDs. So our control ROM will be very small also. So control ROM will be only two to the fifth by 26 bits. Remember that extension we added one more control signal. So two to the fifth by 26 bits. So every cycle, this micro program control unit will take the five bit state ID, go to the control ROM, say, well, give me the micro instruction, and it'll get back 26 bits. It'll apply those as control signals to the data path and then go on to the next micro instruction and just execute one instruction at a time. And so the control unit will really look a lot like a processor, right? Except instead of executing instructions, it'll execute micro instructions, which are just the states of the FSM. Now notice that IR is not used as part of this address, right? It's only the states, right? We don't need to know the IR, that's implicit in the state diagram, right? Each op code has its own set of states. So we don't need IR as input to our control ROMs address. And so it's much smaller control ROM. So how do we handle these transitions though? And so we said, we'll go on to the next micro instruction. How do we find it? So that problem is called micro sequencing, or sometimes we just say sequencing. So let's look again at this diagram. So there's a lot of stuff in here that we never talked about. So most of these states, first of all, have a single arc, right? States like memory access actually have two arcs, right? Here's one going back to wait for memory to finish. JSRR had two arcs, although we're combining those. Where's the other one? Oh, here's branch up here. This has two arcs, right? This is the one branch is taken, goes down, branch not taken, goes back to fetch. So let's add a couple of state IDs to each of these micro instructions. So instead of just having the control signals for micro instructions, let's also store the next state ID. And so how do we figure out what's next? Well, we'll just store the next state ID. So here's an example of what that might look like. So we've got our state ID stored at a five bit register. That goes in as the address of this 32, two to the fifth by 36 bit memory. Those 36 bits then are the 26 control signals and then two five bit next state addresses. So those two next state addresses will go up here and then somehow we'll come up with some micro program branch control that will let us pick one of those two addresses and that'll be our next state. So most of the time, we've only got one or two next states. The only exception is decode. So this design will actually suffice for the entire state diagram except for decode. But we do need to figure out, well, what is this? What is this micro program branch control stuff? How complicated is that? So it turns out it doesn't have to be very complicated. In the state diagram, there's only two reasons to branch. Those states that have two outgoing arcs, they have it for two reasons. One is memory is ready or not. And the other is branches enabled or not. Those are the two data path signals we needed. So those are the reasons for branching. So here's a simple example. So here's a simple design. We'll take the state ID, we'll compare it to the branch state, and then we'll use a MUX. If the MUX says it's not the branch state, we'll pass the memory ready signal as a micro program branch control. If the MUX says it is the branch state, we'll pass branch enable as the branch as the micro program branch control. So that's fine for the states that actually branch. What about the states that don't branch? Well, we've got two state IDs, we'll just make them the same. If there's only one next state, we'll make the two possible next states the same. And then regardless of what R happens to be, it'll just go to that next state and we're done. So now we've handled everything except decode. So using one MUX, this little comparator for the branch state, and this memory, this is our control ROM, this is a five bit register, this is another MUX. So we've got, I guess, two MUXs. Yeah, Eric. Yeah, so for example, here in fetch state three, the next state is decode, right? And so here in fetch state three, you would set both next state IDs, both of these values here would be the decode state. And so then regardless of what this MUX does, it gets decode state as the next state. Okay, make sense? For every state that does not have two outgoing arcs, yes. Every state that has a single arc, so this one and this one and this one and this one and this one. So everywhere you see two outgoing arcs, then those would have different addresses, yeah. So the ones with self loops are two outgoing arcs, and then this branch here is two outgoing arcs. And then this one we haven't talked about, it has 16 outgoing arcs. So we need to do something about that, right? So what can we do about that? We'll borrow a trick from Pat and Patel. So let's just say that the first state of execution, we haven't done anything with our state numberings yet, right? So let's just say, well, we've got 16 opcodes, we've got 32 states, we need an opcode to start the execution of each, I'm sorry, we need a state to start the execution of each opcode. So let's take the first 16, zero through 15, and say those are the states where we'll start executing the corresponding opcodes. So add is opcode number one. So state one will be the one add execute state. Zero is branch, right? I can't remember too many opcodes. 10 is LDI. Each of those states from zero to 15 will be the first execute state for that opcode. So then we can do this. So I've added the blue stuff, right? So I've got a comparator, it says, is this the decode state? If it is the decode state, ignore the next states and just put in zero followed by the opcode. Okay? So that will give me the first execute state as this state address, right? Because I just defined them. So then on decode, my next state will be the first execute state for my opcode. For everything else, decode is not, it's not that state. So I'll pick the zero input, which is exactly what we had before. So then we're done. That's our control unit design. So we do actually need to assign the other values, right? So we've got 16 states left and we've got, I think, 15 states we'd have to give numbers to. So it's a somewhat tight fit, but then we can just go calculate the bits. And so once you assign all the states numbers, state IDs, and we've got 15 more to assign, then you can calculate all the bits. Control ROM total was two to the fifth by 36, right? So 1,152 bits, about 30% of what we needed with the hardwired design. And again, most of that is that in the hardware design, you're looking at both the IR, the opcode and the counter. And so you end up having a lot of redundancy, right? So if you think about, you've got a bunch of states that aren't used, which are the trailing execute states when the counter has a high value for opcodes like add and and, but you also have redundancy where all of the fetch states are the same. And so you're ignoring the IR bits, but you don't know what they are. So they have to be multiple addresses in the ROM for that. Yeah. Yeah. Yeah, so to some extent that's true, right? So let's go back. So to some extent, you've got similar, if not identical RTL, all of the memory access states, except for the store, which is this one, right? All of the memory access loads, so there are one, two, three, I guess only four, but the four memory access loads are the same, right? And so you could say, oh gee, can I combine those somehow? The next states are different, right? And so it would not be easy to come up with a control unit that saves you, you're only saving now four times 30, I guess three times 36 bits, right? But I mean, maybe you can find more redundancy in the RTL. So maybe it'd save a couple hundred more bits out of the 1152, but it'd be hard to make that work because you'd have to keep the same next states. Well, you'd have to have some way to make them work properly, right? You can't combine them in the finite state machine design. So you'd have to come up with an implementation that gave you the same answers without using as many bits, which I don't know how to do easily. Yeah. Yeah, they certainly have to be separate states logically. Whether you can come up with an implementation that's smaller easily is a different question, right? Logically, they have to be separate states because they do have different next states. So the behavior of the finite state machine after the memory finishes its access has to be different. I mean, you don't want your fetch suddenly turning into an STI, right? Okay. Let's see. Just finish that design. So any other questions on, yeah? So decode will have to assign some value, right? But it's just some fixed bit pattern. So we haven't assigned a value yet. But let's say we pick 16, right? Then all this thing has to do is compare these five bits to 16 in binary, right? And so logically, it's maybe some inverters and an AND gate. Actually, you can have inverted inputs out of the register, out of the flip-flops, right? So it's really just an AND gate with five inputs. Anything else? And the same is true for this comparator, right? We didn't, at this point, we hadn't even picked the branch state. It'll end up being zero, right? So this is just comparing to see if the state is all zero bits. Eric? Yeah, so this is the state ID after decode, right? So this is the state ID after decode. Yeah, so this is the state ID after decode, right? So this is the numbering of the first execution state for each of the opcodes. So the opcode is 0001, which is add. Then the state is 0 followed by 0001, which is 1 in decimal. So state 1 would be add. State 0 is branch, because the branch opcode is four 0 bits. State 15 would be trap, because the trap opcode is 1111. I don't know if you can see these. I kind of doubt. Sorry, I know it's, can people in the back read these numbers, the one I'm pointing to? Can you see those? It's too fuzzy, right? Well, those are the, so this one and this one, these are the first execute states for each of the opcodes. And if you could see the numbers, you'd see this is LDI, and this is 10. This is STI, this is 11. This is add, this is 1. This is and, this is 5. Those are the opcode values. And those are the state numbers, both in our design that we just finished and in the Pat and Patel design that I'll show you shortly. Except in Pat and Patel, they have one extra leading 0. But the numbers for the first execute states are all the same. Well, they have more than 32 states. So they need 6-bit IDs. All right, so let's go ahead and take a look at this. So with interrupts and privilege, they're going to have these 6-bit state IDs. So that was really the point of this slide. So we're going to have to do a slightly different design. So I want to look at the one in Pat and Patel now. And show you how their micro sequencer works primarily. And then go through and derive sequencing bits for the same states we did on Monday, meaning fetch, decode, and LDI execution. So this one is the arc for outgoing interrupts. That's actually in a completely separate figure in the appendix. So all of the states that are not shown in this diagram. All of these little numbers here, as I mentioned, are the state IDs. So I know you can't read them. But when you look at the figure or you get the figure in your exam, if you need the state IDs, they're all there. So you don't have to memorize them or anything. So interrupts and privilege add another 14 control signals. So the total control signals is 39. Pat and Patel micro instructions also include then 10 bits of sequencing information. So in the design I just showed you, we added 10 bits as two 5-bit state IDs. For their design, they add 10 bits as one 6-bit state ID. A condition for branching, which I'll explain in a minute. And then IRD, which is just a 1 when you're in the decode state and a 0 when you're not. So they add that as a bit in the control word, bit in the micro instruction. So here are the conditions. Only three of these are things that we've talked about in our class. One is unconditional, which means you only have one next state. The other two that we've seen are the memory-ready branch and then the branch-enabled bit branch. And then the three we haven't seen are the JSR or JSRR addressing mode bit, which is IR11. Privilege mode violation, which is PSR15. This is process status register. It's not even a register we've talked about. So you can just think of these as some 1-bit signals. And then interrupt occurred is the int signal. So we didn't talk about these three gray ones, these three at the bottom, but it's in their design. So I wanted to make sure you don't feel confused when you see the design. So here's the design of their micro sequencer. So first of all, it has the same thing that we had for managing decode. So they have the IRD signal coming out of those 10 bits. It says this is the decode state. When you're in the decode state, you get two zeros followed by the opcode as your next state number. So the same state IDs for the first state of any opcode execution as we defined for our machine for our micro program control unit a few minutes ago, but with one leading zero because they have 6-bit state IDs instead of 5. So they have two extra zeros. We had one. But otherwise, it's also the same MUX design. Now, the difference here is this is their micro sequencer for everything else. So what you can see here, this is basically like a decoder exploded for the conditions. So for each of these conditions, these are implicit inverters here. But each of these AND gates would be one minterm on the conditions. And so they're the minterms in this table. So there's no unconditional one, obviously, since you're not going to change anything in that case. But you can see for each of the AND gates, each of the five conditions, and they're not in order. They're kind of scrambled. So you have to kind of look at the thing to decipher it. But for each of the conditions, we change exactly one bit of the, sorry, there's the decode. There's the first states. For each of the conditions, we change exactly one bit of the address j. So the address j, which is stored as part of the micro instruction, that's the next state address. The only kinds of next state addresses we can use are addresses that differ in exactly one bit. The zero bit happens when the condition that we're looking at is false. And the one bit happens when it's true. So we have to pick our state numbering somewhat carefully. So let me explain that a little more. So for example, the memory ready signal or is in the bit number one or value two. You can see that here. Here's memory ready. That gets or'd into j sub one. So that or's in the value two. So if we want to wait for a memory access, we have to pick state numbers that differ in exactly that bit. And we have to have the memory not ready state have the address, the state ID with the zero bit. And then the next state where the memory access is complete has to have the address plus two or two, which is the same in this case because that bit is zero. Those constraints have to be obeyed. So you have to obey those constraints when you pick your state numbers if you want to use their micro sequencer. So of course, they did. And it's reflected in the state diagram. But occasionally, you'll see as you go study old final exams, you'll see things where we ask you to add an instruction and make use of free states in the Patten-Patel design. And you have to look at the micro sequencer and figure out how to make use of them in a way that works. So we'll go through some examples. Here's another example. So branch opcode is zero. So that's the first execute state. So that's the branch execution state is number zero. State zero branches on branch enable. When it's false, the branch is not taken. So the next state is fetch. And when it's true, the next state has to be 18 or four. So the next state has to be 22, which it is. And that's because it's branching on branch enable. And if you look back here, you can see branch enable goes into J sub 2 and puts a 1 into J sub 2 when it happens. So we have a few minutes left. I think we'll probably have time for this. I don't think it should take too much time. But I wanted to go through and take a look at all of the fetch and decode states and ask, well, what are those 10 bits for each of those states? We already did all the control signals on Monday. But let's look at the 10 micro sequencing bits for each of fetch and decode states. So these are the states again. So now, hopefully, these state numbers are visible. But I'll put them in the next slides anyway. So here are the state numbers in binary for fetch 1, fetch 2, fetch 3, and decode. Fetch 1 branches on the interrupt signal. The next states are fetch 2, which is this pattern. You can see it down there. And start of interrupt, which is over here. So the bit that's different then is this bit here, the bit number 4, counting from the right as number 0. So 0, 1, 2, 3, 4. That's what the interrupt signal changes. So what should j be? So remember, in their micro sequencer design, when the condition is true, it's going to change the bit from a 0 to a 1. So if in j, you make it already a 1, it will never branch. Oring in a 1 where something's already a 1 doesn't change it. So you have to pick, out of the two next state addresses, you have to pick the one with more 0's. So you have to pick this one, basically. So that has to be the next state address. If the interrupt signal is on, the micro sequencer will turn on this bit in j, and it will go to this state instead. If interrupt is off, it will go to fetch state 2. So that's how their micro sequencer works. Because as you fill in these bits, for every time you have a branching state, you've got two next states that have to differ in exactly one bit. The bit in which they differ always depends on the condition you're picking. The condition and the bit that differ have to match. And the pattern with the extra 0 in it is the one that has to go into the j value for the micro sequencer bits. So the condition in this case is 1, 0, 1 for the interrupt bit. So is this the decode state? No, so it's a 0. So what about fetch 2? So fetch 2 branches on memory ready. Fetch 2, we're going to memory, and we've put the PC into the MAR, copied the PC into the MAR, incremented the PC in fetch 1. Now we want to read from memory. So the next states are going back to itself, which is fetch 2. So it's that address again, or going on to fetch 3. So you can see the difference here is in bit number 1. And so fetch 2 has the 0, fetch 3 has the 1. So when memory is ready, it'll go to fetch 3. And when memory is not ready, it'll stay in fetch 2. So what should go into j? Fetch 2, the one with the extra 0. And the condition in this case, any time we want to branch on memory ready is 0, 0, 1. And then is this decode? No, that one's easy. Usually you probably want to look these up in the table. So we'll give you all these tables. All right, fetch 3 does not branch. The next state is decode. So what goes in j? Just decode. There's no branching. So what's condition? It's all 0s. That was the unconditional one. And is it decode? No. Next one is decode. All right, so decode goes from some state from 0 up to 15. Decode is where we're branching into one of the 16 different op code states to start execution of those op codes. Based on that op code, it picks one of those 16 states. So let's start over here. Is this decode? Yes, good. What are these things? Do they matter? So if you think back, I mean, I can see how quickly I can flip back to the micro sequencer. There it is. So when this mux goes from here, does this stuff matter? They're don't cares, right? So j is a don't care. And condition is a don't care, because whatever this thing puts out gets thrown away by the mux. That input is discarded. Because right now, we're looking at decode. We're taking this input, forwarding that to the next state. So we'll flip through this. Yeah, yeah. I mean, you could simplify by not muxing those bits, right? Yeah. Yeah, so you could do that. Yeah, you could simplify it a little and have two fewer muxes out of the six. I mean, I think they just wanted to simplify the diagrams in the book. Yeah, when you actually build it, I think you'd probably do that simplification. It's a good idea. All right, so the other set that I thought would be useful was LDI. We're kind of out of time, so maybe I won't walk you through this. But it's in the slides online. So all it is doing is looking, again, at the five LDI states and asking, well, what are the micro-sequencing bits for each of these five states? The one you're going to encounter most of the time is going to be the ready signal. And if we ask you to add an instruction on the exam or something, it's going to be something with a load or a store. You're going to have to do memory ready. You're going to have to have them off by the difference in bit one, so two. And the one where you're reading from memory has to be the one with a zero there. So you can look through those. And I will stop now and leave those to you. And on Friday, we'll do error control, redundancy, things like that. Thanks.\"},\n",
       " {'ECE120-2016-11-18-LEC-35-slides.mp4': \" during the break, then you can do Lab 14 early if you want to. It'll go up early. I know all of you are just itching to do more LC3 programming. There's also this sprite ASM file on the wiki, which is what the other lectures are doing. So if you want to see it in action, you can watch Professor Jaramillo's lecture. But you can also just go grab the code and take a look at it if you're interested. What we're going to do today is do some ASCII screen art, because I just like art. And so I'm going to ask you to write a program for me, and I'm just going to type. But it's going to be this program where actually, so I'll reveal who at the end. But someone sent me a file of tuples of positions on a screen and ASCII characters. And so we're going to take that file and figure out how to print it. So that's what we'll do today. I have a think-pair-share too, but I think I'll just skip it, especially because there aren't that many people here. So if you're interested, I might post the slides. Think-pair-share is I ask you to get together in small groups during class and think about things. I used to do a bunch of them in 190, the predecessor to this class. I don't do so many here, because we oriented the entire discussion section around that style of interaction. So we're already doing it every week, so we don't do it in the lecture very often anymore. But I thought it'd be fun, just before break, to go and develop a code together. So let me get my paper out. I told you never to start coding, so even though I have this part ready to go for coding, we're not going to do that first. See, I've got Notepad, my all-purpose programming tool. And I've got CGWIN LC3 tools here. So this file, we will write LC3 code here. So I learned the, I can type pretty quickly now, but when I learned to type, I didn't know enough to do what my department head did to me, which was, he said, oh, I can type now with more than two fingers. And he said, yeah, well, I used the double eagle version of typing. Wow, Dick. This was Dick Blahut. Wow, that sounds really impressive. I'm a faculty, so I don't just say, oh, thank you, double eagle, amazing. So what is the double eagle? The double eagle version. So tell your friends and family, I'm a double eagle typist, actually. All right, so let me see how quickly they can switch. I think it's not too bad. All right, so what I want to do is we're going to get this set of tuples. So it'll be an array of three tuples. So what it'll look like is basically consecutive memory locations like this. There'll be an x location, a y location, and some ASCII character. So for example, it might say, well, at position 5x, at position 10y, we want to draw the letter A, for example. And then after that, it might say, well, at position 5x, position 11y, we want to draw the letter T. So I'm putting them in quotes for the ASCII characters. Of course, they'll be ASCII coded. So what we want to do with that, when we're done with that, the end of the array, so we won't know how big it is, but we'll get an x value of negative x value, which will be the end of the array. So that's how we'll know where the end is. Like when we're looking at a string, we know the end because we see a 0, a null character in ASCII. For this array, it'll end with a negative x position. So if we get a negative x position, that means we're done. So what we need to do is figure out how to take this array and get it onto the LC3 screen. So here's a picture of what I want to draw to the screen. So you remember, with LC3, the only things we have for input and output are basically send a character to the output and read a character from the keyboard, right? So we don't have nice screen art where we can say, well, I want to move over here on the screen and put something there. And then I want to move up there on the screen and put something there. So in order to make this work, we're going to have to play a couple of tricks. In particular, what we're going to do is break this down into a few steps. Let me switch briefly back over to PowerPoint, and I will show you those steps. Oops. Oops, I was going to review this, but I'll just skip that. So this is our array, right? We've got x position, y position, ASCII characters. That's what I was drawing on the paper for you. So here's how we're going to tackle the problem. So instead of just drawing directly to the screen, because we can't control where we draw, we can just draw sequentially, what we're going to do is we're going to build up in memory a picture of a screen. So we're going to do that as a bunch of strings, one string for each row. So we'll start off by just filling that fake screen in memory with a bunch of spaces. And I'll actually use a null at the end of it, because I'm kind of lazy and I want to use putstrap, which I hadn't told you about. But the putstrap will send a whole string to the display. So we put r0 to the first character in the string. We call the putstrap, and that prints the whole string for us. So we'll make a bunch of strings, one per row of the screen. I'll draw that as a picture in a minute. And then we'll parse the array. We'll go through the array and say, well, here's a character at position 5, 3. We'll figure out where that should go in our fake screen, and we'll put that character into our fake screen. And then at the end, we'll dump the screen to the real monitor to see what it looks like. So those are the three steps. So let's go back over here. So here's our fake screen. So the idea is, well, somehow, maybe we've got some width here. We've got some height. So when I see something, so first I'll fill this with spaces, right? So first, fill with spaces. And put a null here that's not part of the screen. So a null here, a null here, a null here. Each row will have its own null. And each row is one set of spaces followed by a null, width spaces followed by a null. So fill it with spaces and write the nulls. And then step two is parse the array. So we'll parse the array. We'll parse the array. We'll parse the array. And then step two is parse the array. So for example, up here, I said, well, x position is 5. y position is 10. So if I were to draw all these positions, then let's see. We'll count this one as 0. This one is 1, 2, 3, 4, 5. And then this one is 0. This is 1, 2, 3, dot, dot, dot. Down to position 10. So here at 5 and 10, I want to plug in an a there. And that would be parsing the first 3-tuple from our array is to go, say, x position 5, y position 10, put the a there in our screen. And then once I've gone through this whole array and put all the characters in, then my screen is ready. And I can just print all the screens. We'll put s one at a time. So I'll go through the array one tuple at a time until I find the end of the array. Step two, parsing the array. And then step three is print the strings of the fake screen using putstrap. So those are our three steps. So let me switch over here. And we can get started just putting a few things in. Let's see. OK, good, it didn't. All right, so we'll do the first part first. But before I can do anything, this is LC3. So let me write my. So you can't actually type now. I brag too much. All right, there we go. So I'll put my dot orange dot in, give myself a little space. And then first step, fill the screen with spaces. So let's see, we want to have width and height parameters. So put those down at the bottom. So for width, why don't we say, I don't know, 40 spaces. For height, why don't we say 26 spaces. We could change those later if we wanted. We'll use them as parameters that we'll store in memory. So how do I write a bunch of, oh, I better make a space for this, huh? So let's put our screen somewhere. So let's put our screen at 4,000 hex. So our code's at 3,000, our screen's at 4,000. Let's say our array's at 5,000. So just put those in at the bottom of our code, and we can make use of them in our code. So the first step is fill the screen with spaces. So right now, there's just a bunch of bits in that memory. So I need to go through and somehow create one row, one string for each row. Yeah, Nathan? Really? Remember, that's 1,000 hex, 4 kilobytes. That's a good check, though. Someone's doing the checks. Because if you make one clobber the other, what happens? LC3 just does what you tell it, which means that you would overwrite the array with your spaces, and then you'd miss part of your array. So good call. But in this case, we're safe. So good check. All right, so yeah, if you make width and height too big, then we're in trouble. But for now, they're OK. Maybe we should put a comment there. OK, now we're safe. No one would ever change those to be more than 4 kilobytes. All right, so let's think about what we need to do to fill the screen with spaces. So I'll switch back over here. So here's my screen. How is this screen going to go into memory? Which way? I mean, this is an array. So let me draw a smaller screen. So let's pretend we've got a screen. And I'm going to draw a screen. And I'm going to draw a screen. And I'm going to draw a screen. And I'm going to draw a smaller screen. So let's pretend we've got 3 by 3. So I want a 0 here. So let me call these A, B, C, D, E, F, G, H, J. I'll skip I. So what should go first in memory? A, right? What's next? B. OK, so we're going to go across the first row. And then we're going to go down after the 0. So if my screen is 3 wide, I'm going to have three locations, one to hold that extra 0. So to linearize this in memory, it's going to look like this. A, B, C, 0, D, E, F, 0, G, H, J, 0. So this one is width plus 1. And this whole thing is width plus 1 times height memory So that's the thing that can't take more than 4K. It is that product there. So how should I break this down, filling A through J with spaces and putting those 0's in? Is that an iteration or a sequence or a conditional? It's a loop, right, an iteration. So loop over what? Rows or columns? Probably good to do rows first, right? Because then, actually, if I do rows first, then I'm just walking through memory, and I can have one pointer that fills things. If I do columns first, my pointer to what I'm writing has to jump around a lot. So maybe let's make our life easier. So we'll do the rows first. So we'll say something like, for every row, for every column, I fill a space and then increment the array pointer. And at the start of that loop, then I can say array pointer initialize to what was it? 4,000? OK, so if I initialize my array pointer to 4,000, and then for every row, for every column, I fill a space and increment my array pointer, that'll write the letters up there. What about the zeros? I'm sorry? You probably shouldn't assume that about LC3 memory. I mean, yes, it's true in the simulator, but yeah. Yeah, well, so for one thing, our program is not going to go up there, right? Our program is down at 3,000. So our program is not going there. And yes, the simulator will fill the rest of memory with zeros, but you're probably safer just not assuming that kind of thing because it'll tend to come by to you later. We're going to end up having to put a carriage return, but I was going to put that in the print loop. We want the zero because we're going to send, we want a null because we're going to send the entire string using put s. So we do need the zero. So we're going to have to write it there. So where should we fit that into our structure here, our loop structure? Yeah, we can put a zero in a register. So where would I put it in the memory? I'm sorry? So I want to put one for each row, right? So after I do my entire column, maybe down here. So after I fill a column, OK, so let's see what this is doing. I should have cut more pins out. So this is one row up here, right? So this loop here will fill that row. So after I do that row, then I want to put one zero. So fill one zero, and also increment the array pointer so that I don't overwrite it. So this is now something I do for every row, right? So if I add that little bit of code down there, that will write my zeros in for me. So these will be my spaces. Whatever my width is, I'll write that many spaces. I'll put the zero at the end of each row. And I'll do that for height number of rows. And then I'll be done. That make sense? OK, so what do we want to use for keeping track of these? OK, so what do we need to keep track of, first of all? So we need a row. We need a column. We need an array pointer. Someone said we should have a zero. That's a good idea. Uh-oh, what's going on with my laptop? Wants to reboot. Maybe not reboot. I think it decided to go to sleep. Hopefully, I can get it to wake up. And oh, what other thing do we need? We need one more thing. What else would be convenient to put in a register here while my laptop comes back? Anything? Sorry? Yeah, so height and width, we can maybe use the pointers and just count down, because we just need counts, right? So we could initialize the count. That's a good idea, but I think we can count the other way and then just use one for the row and column in this case. What about this one? Anything you might find convenient for filling a space? How are you going to write a space into memory? Yeah, you probably want it in a register, right? Because space is 20, so 20 hex. So maybe we'll put 20 hex, which is a space character. This is null. Well, maybe we're not going to be able to write code today. What's going on with my laptop? Oh, I have light. Try to get it to go to sleep and then wake up again. Into another register. Oh, I'm sorry, those A, B, and C initially will be spaces. Yeah, those I just wanted to illustrate the mapping between the screen we're trying to build and the memory organization. Yeah, but initially we'll want to make them all spaces, and then we'll fill them with real characters from the array. So we have to have a drawing canvas, right? So the drawing canvas is a bunch of spaces. So the array is mapped like this. So depending on the width and height, the number of memory locations, one row is mapped, is organized linearly in memory. And you have first row followed by second row, each of them with a zero at the end. So this array is three by three. So the first row is A, B, C. And so in memory, it's the A, B, and C characters. And then there's a null at the end. Yes. AUDIENCE 2 Ah, I'm sorry. I called two different things array, didn't I? I'm sorry. It was at 5,000, the tuples, the three tuples start at 5,000. AUDIENCE 2 So the three tuples are organized sequentially in memory as x, y character. The last one is a negative x position. And then the x and y positions are given according to this mapping. So 0 and 0 is the upper left corner. x positive is that way. y positive is down. Oh, yeah, they're unsorted. Yes, they're not sorted. Yeah. Yeah, and so that's one reason that we have no way to control moving around other than we can only print linearly with LC3. No, no, no, no. We make the blank canvas. And then we put characters in wherever they happen to fall. And then we have a picture. And we dump out the picture. Yes, yeah. So we're going to use the step two. We're going to go calculate the screen position for each array element, put the character there, and then we'll dump the screen in one big operation in part three, basically print a bunch of string. And this is actually technically similar to how real graphics work. Most of the time, the graphics cards are drawing the next frame in the background. They're not drawing it on the screen because it makes it flicker. So yeah. If you want, let's say, rotate the image, you can go ahead and swap them. Oh, yeah, yeah. I mean, all you have to do is treat them as opposite values. Yeah, so if you want to do an image transpose along the diagonal, although the characters are not square. But yeah, you can do that easily. Sorry, my laptop did decide it had to be rebooted. So we're waiting for it to come up. And then we'll type this first code. OK. All right, so. OK. Oh, I didn't save my code. Wow, that's sad. All right, so what did I have? A width, what did we say, 40? OK, so what we decided we needed in memory we need a row. Why don't I use this one for the 0, this one for the space? OK, so R2 can be our row. R3 can be our column. R4 can be our array pointer. I think that was all we needed. So let's first initialize our variables. So how do I get a 0 in R0? And good. And then how do I get a space in R1? Yeah, I could add, right? I'm kind of lazy, though. I think it's less typing for me. But yeah, I could do add 10x. No, I can't add 10x. I'd have to do three adds, wouldn't I? Because it's 20. Yeah. Yeah, I'm just going to fill, because I'm too lazy to type so many adds. All right, so for the row, let's see. So let's start the row at height. So this will be our row loop. And then I'll have to reinitialize the width every time. So let me load that here. And this will be our column loop. So then I need to store a space, right? So where's my array pointer? I better initialize that, too. How do I initialize R4? I want to initialize it to point to the, oh, I'm sorry. I really should call that screen at this point, huh? I want the screen pointer here. I will need an array pointer for the next part. So for now, I'll just leave that blank, though. So how do I initialize R4 to point to the screen? So the screen's at 4,000. I don't think I can get from down around 3,000 to 4,000. I do have it down here in this memory location, though. So is there a way to get it from, how can I get this value that I've stored down here into R4? Just another load, right? OK, good. Yeah, the assembler will take care of the offset. I could try to do an LEA, but I would have to calculate the offset myself, which is a pain. And then it's also probably out of range from this code, which is another pain. Yeah, I wouldn't be able to jump. I won't be able to LEA either. OK, so if I load it from here, then that will give me the value. Oops, but I don't want it there. I want it up here. OK, so that's got those ready. 0 is ready, 1 is ready, 2 is ready. Column was supposed to be 3, not 1. I should leave bugs for you. All right, so now I need to fill a space. How do I fill a space? How do I write a space to my current screen pointer? Yeah, not unless it takes me a lot of code. I mean, the PC offset is 9 bit, right? Yeah, yeah, that's just the value of x4000. No, no, no, no. OK, so someone said store. What kind of store? Really? OK, so st from my space register to where? Yeah, probably store register, right? I could use sti to this, but then I could only fill one space. I'm actually going to change r4. r4 is going to go through the screen and fill each place with a space. So I'm going to change r4. So let me use r4 offset here. And then I can increment r4 to point to the next one. So that'll give me one space for one column. And I just made the advance the screen pointer. So the next time I fill one, there'll be a different place to put a space. So now I need to count down my column loop. So how do I decrement? Ah, yeah, str, good. Thank you. So how do I decrement my column number? Add negative 1 to which register? Or 3, right? OK. Good. And then what? Branch, what condition? So if this were 5, then first time through, it would be 4, then 3, 2, branch positive, right? OK. So as long as we still have a positive number, we're going to go back for more. Where should we go back? Good. OK. So now we have one row done, but we didn't put our null yet. So how do we put the null? From r0, which is a 0, to where? 4. 4, good. Yeah, so we're just writing into this screen that we're creating, right? OK, and then I better advance the pointer. I really should leave bugs for you. I tried to leave one, but you caught it. All right, what do I do next? Just branch back to row loop? OK, branch, what condition? What do you want? So what do you want me to do? Add r2? Minus 1, good. OK, and then branch positive like that. Good. So we should be done. Try that. It worked. At least it compiled, or assembled. Let's see. I can dump 4,000. Hey, look, there's a bunch of spaces. Cool. Did I get it right? A lot of spaces. Think the code works? So when you do this kind of stuff, you probably want to make your life easier. Probably that one's easier to check, right? Let's do that. OK. So now there are a few less. I don't know, can you read this font? There's one, two, three spaces and a zero. One, two, three spaces and a zero. One, two, three spaces and a zero. So it looks pretty good. Actually, it's probably a bad idea to pick three and three. Why is that? Yeah, if I get them mixed up, I won't be able to tell, right? So maybe I'll do it a little bit differently. I'll make it four wide and three high. And then we'll run it one more time, and then we'll go back and do the second part. OK, so we have now one, two, three, four spaces and a zero. One, two, three, four spaces and a zero. One, two, three, four spaces and a zero, and then a bunch more zeros. If we really wanted to be careful, we could write non-zeros into some of these memory locations to make sure this last zero was actually written. But at this point, I think we're pretty good. Yeah, Rahul? Is that summation font the correct summation? How do you get all that? How do you get all the values? No, bang just repeats the last command, starting with whatever prefix you follow it with. So yeah, so bang LC3S means whatever last command issued starting with LC3S, do it again. So I don't have to keep typing it, because I get tired of typing. My fingers get sore. All right, so good. So we're done with the first part. We have a second part to do, right? OK, so let's copy our register table. We don't need all of them anymore. We'll just change the registers, potentially. So we need a row and a column for each of the elements, right? We'll need the array pointer, too, now. So maybe we don't need the space. So let me make this an array pointer. Let's see, what else will we need? Any ideas? Any ideas? We need a screen pointer. We need an array pointer, a row and a column. We need something for the ASCII character. We put that here, the one that we're going to write into the screen. We'll probably need some other temporaries, but maybe we'll come back when we need them. Just to make sure everyone's following, let me switch briefly over here and say, OK, so here's our array, right? So basically, in order to parse this array, what we're going to need to do, I need to pull it down to where I can reach it, what we're going to need to do is walk through these three tuples one at a time, and look at the x position, the y position, use those to calculate a position in our fake screen we just created, and then put this character at that location. So how do I figure out the position given the x and y coordinates in memory? Yeah, but would I multiply the x and y coordinates? Maybe not, right? So let's take a look at this drawing over here. It has the disadvantage, again, of width and height being the same. But where does the second row start? How many memory locations down from the first? So if I look at the difference between a and d, how far ahead is d? Four, right? Or width plus one, right? What about if I go two rows down? Three times that. It would be twice that, right? What about three rows down? Three times that. So if I multiply the vertical position by what? Width plus one. And then I can add the column, right? So let me write that formula down. So if I say my y position times width plus one, plus my x position, and then I add that to my base, so my base is here, the address of the first character, which is just 4,000. So if I calculate this expression here, that will tell me where to put the character, right? And you understand why, given the pictures? Make sense? Yeah? OK. x is, remember, each of our tuples has an x position, a y position, and a character. So the x position, if it's 0, then that would be the first character, the first column. The second column would be 1, and so forth. So if you add that offset, you'll get the position within the column. We're going to assume that the tuples know how big our screen is, that they don't give us bad values. We won't check the values. Yeah. OK, so we'll have to calculate this expression then. And other than that, we just need to go through and look at each of the tuple values. OK, so let's see. So let's make a loop. We'll start. We'll start. It was r4. Oh, we've got to reset r4, right? Because we advanced it as we were writing. We used r4 to write our whole screen. So r4 is no longer equal to 4,000. So let's set it back to 4,000. And then we could add it in later, too. So we'll do a loop. When we're done, we'll come down here. We need to point to the array. So let's see. How do I get my first x out of the array? Where is it? Remember, they are x, y, and character. So if r1 points to my next array element of this 3-tuple, so x is offset 0 relative to r1. So if I go in LDR, so this will give me my column. And then I can do another LDR into r2, offset 1. So this will get my data out of one 3-tuple. The offset 0 is the x position. I'll put that in r3. Offset 1 is the y position. I'll put that in r2. Offset 2 is the ASCII character. I'll put that in r0. And then I'll add 3 to r1 to point to the next tuple for the next iteration of the loop. When is my loop done again? How do I know my loop is done? How do I know when I've reached the end of the array? Sorry? x is a negative number, right? So where should I branch right after I load x? And what branch condition should I have? Branch negative, right? So if I get a negative x position, I shouldn't load the other ones. Where should I go? First done, good. So in other words, if I see a negative x, then I just quit. And I just come down here, I'm out of my loop, I'm done. So if I don't see a negative x, then I will load the y and, I want to give myself more space, load the y in character. And now I need to calculate where that should go in my screen. So let's see, I have to multiply y by width plus 1, right? So maybe I'd better start using some temporaries now. So multiply y by width plus 1. Let's see. Let me put width into r5. And let me put a 0 in r6. And then add, oops. OK, what do you think of that? So what I did is I put a 0 in r6 for my sum. So I'm going to sum, hopefully, width plus 1 times. Or I'm sorry, sum y plus 1 times. So I'm going to put width into r5. Oh, I did that the wrong way, didn't I? No, I did it the right way. I did width plus 1, yeah. OK, so we have to go back to the picture of the, remember these are the tuples. So in memory, each tuple has, in the first memory location, the x position, then the y position, then the ASCII character. x position, y position, ASCII character. So r1 initially points to this one. And so plus 0 is that memory location. Plus 1 is that memory location. Plus 2 is that memory location. Then we add 3 so that next time through the loop, we'll point to these three. So they're just three tuples with x, y, and ASCII character. Yeah. Mm-hmm. AUDIENCE 2. So the x and y coordinates are inside the screen? Yes, yeah, we're not going to check. We will not check that the x and y coordinates are inside our screen. We just assume that they're OK. Which, if they're not, then we'll end up writing outside of our screen, and we won't see those characters, or something worse could happen. So it's not the best way to do it. But just not to have too much to write in the space of an hour. All right. So switch back over here. Hopefully, we can get this part written. All right. So what does this do? So it puts a 0 in r6. And then how many times do I go through this loop? Ask it that way. Width plus 1. And the easy way is, if you start with width 0, then of course, you'll come through this once, because you don't branch before. And then you'll add negative 1 to 0. You get negative 1. You'll stop. So if you have a width of 0, you'll get 1. If you have a width of 1, you add 1 to negative 1. You get 0. But 0 goes back again for a second. So you get width plus 1 times. So if I take width plus 1, adding r2 to r6, then I get width plus 1 times r2. But r2 was the y position, right? Yeah. No? AUDIENCE MEMBER 2 Yes. But given the relative size of your screen, does that mean that you can't do it in the next step? Yes, probably. Depends on the relative size of your screen. But generally speaking, the screen will be wider than it is tall. So yeah, that would be faster. Yeah, so you could do it either way. Your way would be fewer instructions. Good point. So now we have that. So let's add in a couple of other things. So that's in r6, right? So let's add in the x offset. So now I claim r6 points to the place where we should write our ASCII character, because we've included y times width plus 1. Then we added in the x offset. So that's our formula. But we needed the screen base, which we had in r4 up there. So if we add those three pieces together, we get the plus 1. And then we get the minus 1. And then we get the minus 1. And then we get the minus 1. And then we get the minus 1. And then we get the minus 1. And then we get the minus 1. And then we get the minus 1. And there we get the place where we want to put our ASCII character in memory. Our ASCII character is in r0. So how do I put ASCII character in r0 into the memory address of r6? Yeah, did I screw that up? OK. Let's see. X offset. Yep, there it is up there. In r3, not in r1. So good call. Add that in r3. Thank you. OK, everything else work? OK. So how do I get my character from r0 into memory address pointed to by r6? STR again, right? Good. So source register is what? r0? Remember, we put the character in up here. We didn't change it. So it's still there for us. r6 is the pointer. Offset is 0. Good. So I just put one character. Maybe I should go get the next one from the array. So how do I get up there? Branch. What conditions? All, right? Always. Where? That'll go get the next one. We only come down to parse done after we're all done with the loop, which is when we find the negative x position. So this should parse the array. Let's see. So we've got a few minutes left. Not sure if we'll be able to make a fake one, I think. OK, so no errors in the compilation. Oops. Can't type this way now. No, it's OK. I'll do it quickly. OK, so we'll put the letter a at 1, 1. And then maybe at 2, 3, or 2, 2, we'll put the letter b. That should be enough just to sanity check it. We put it at 2, 3. How big did I make x? There we go. OK. Yes, thank you. Sorry, I'm just trying to write one of these little arrays quickly. I'm sorry. Still minus 1? It's OK. Yeah, that's the terminator that gives us negative x position. OK, so let me read in my fake one. And then read in my at 1. And then I can look at 4,000. So where did I put the fake one? So 1, 1. So here's my first row. It has nothing in it. On the second row in position 1, I have the letter a. You can see the a over here maybe. And then my second row in the third position has a letter b. So that worked. Good. OK, so our code worked. All right, so the question is, can we dump all the strings quickly? So our strings are ready. All we need to do is do a loop. Let me get the register table. Keep those. We need a row. We don't actually need a column pointer. We need a screen pointer. And r0 is going to be our string pointer. And actually, we won't need the screen pointer. So let's start by putting screen and r0, and then width plus 1 in r1. And then we can do a putstrap. So we want row. So we want height in r2. So putstrap. Putstrap. What did I do? And I want to add height plus 1 to my string pointer so that I'm pointing to the next row. And then I want to add minus 1 to my loop counter and branch back. Does that look good? OK, sorry. I had to write that pretty quickly if we're going to finish on time. So put a screen pointer in r0. That's a pointer to the first string. Remember, the strings are spaced at width plus 1. So every width plus 1 space is in memory is the start of a new row string. So I'm going to put width plus 1 into r1. And then I'm going to keep adding it in to get to a pointer to the next string in r0. Puts is the trap that prints a string to the screen. Our strings already end with nulls. I'm going to do one row, one string for each of my rows. So I load height into r2, add negative 1 to it, branch until I've printed all the rows. So I think this should work. There's no line feed. Thank you. Good call. OK, so I better put a line feed. So after the put s, I had better, oh, shoot. OK, then I need r0 for a line feed, don't I? So let me put this in r3. And then, sorry, let me copy it over to r0 there for the put s. And then I can get a line feed. Thank you. OK, so print. Oh, no, thank you. OK, so that printed that screen. OK, so now let me, so now I can decode this thing Rahul sent me last night, except for one thing. I better make my screen bigger. OK, so let's change our screen back to something realistic. Ready? What? Oh, I put a tab or something. Ta-da. There you go. Happy holidays. Enjoy your break.\"},\n",
       " {'ECE120-2016-11-14-MT3-review-slides.mp4': \" It's midterm review. Everyone ready for the midterm? No. OK. Can we just go home now? All right. So what do you want to review? Oh my gosh. We'll start and go back. Moore versus Mealy. OK. Yeah. And Mohammed, you had your hand up first. Oh, it's up there already. Mm-hmm. LC3 data path. Yeah. So I'm trying to remember the exact boundary. So you need to know control signals. You need to know how fetch works. But you don't need to do things yet like translate RTL into control signals for LC3 data path. And what? Eric? I think the thing that's a problem is that it's not like managing a hard-try method and just when the ISA where you have the MAR and the MBR, your instruction method, just knowing how to increment those and change those based on the instruction. So instruction processing, basically. OK. One, how to make an FSM smaller. OK. So just basically FSM design or? We didn't talk about state minimization. But no. I mean, I did it once, but we didn't talk about it as a subject. When we did the lab machine, I reduced states. But that was not. It's something you can do, but we didn't formally cover it. So we're not going to worry too much about that. Yeah. I'm sorry? FSM design. OK. OK. Anything else not on there? Yeah. I'm sorry. I made a mistake. OK. OK. Yeah. Yeah, I'm sorry. I'm sorry, LC3 what? Operands? Operands. I'm sorry, I made a mistake. OK. You mean in the sense of the different addressing modes? Or? OK. OK. All right. Anyone else want to put something up here before we go down and vote? All right, so Moore versus Mealy, how many people want to see something? What's that about? 35 to 40? Memory and building larger memories from smaller memories? OK, that's more like 50 to 60. LC3 data path? They're all popular topics. I'm going to guesstimate 30-ish. Von Neumann? OK, probably about 25 to 30. Instruction processing? That's probably about 5 to 10. Finance state machine design? About 20 or so. Serialization and trade-offs? OK, maybe 10 to 15. LC3 operands? OK. One. No one else? OK. You can ask me in office hours. All right. OK, so what's a popular topic? So let's start with memories. There are a couple of examples in the notes if you haven't seen those already. So do take a look at those. But remember, a memory model, I don't remember which ones we use where. But generally speaking, there's data input. There's data output. There's some kind of chip select, sometimes inverted, sometimes not. There's some kind of write enable. Sometimes we might write read or write bar. Sometimes we might write write enable. I think the book actually just writes RW, and it just assumes you'll put one bit for one of them and one bit for the other. And then, of course, there's address. So remind me, so let's see. So 2 to the, let's give these names. So what's the size of the address space for this generic thing here? 2 to the n, right? So the address space is this part. And what is it? How many bits do we need for address? n bits. OK, good. So this over here will be n bits wide. So this thing implies n bit addresses, right? And what's the addressability? m, right? So m is the addressability. And so what does that m imply about our box over here? So what's the addressability of this? m. So does it affect chip select? Data in and data out, which are how many bits wide? m, good. OK, so this is our generic design. So this is a 2 to the n by n bit memory. And let's say you wanted to build something with, sorry, I'm going to zoom out a little bit to be able to fit something else. So let's say you wanted to build something twice as wide, wider addressability. So say 2 to the m bit. I'm sorry, 2 m bits. So you'd get, say, two chips. You could also do four chips. Maybe we'll just do four. So this will be 4 m wide. So if I want to build the same size address space, but four times as wide, how many of these chips will operate at one time? Four, or if the other possibility is what? If we're not doing anything, how many chips will be chip selected? Zero, right? So all zero or four. So how should I wire up the chip select? Same chip select, right? So let's see. Let me call this external CS. And so that would go to all of their chip selects. I can spell chip select. All of their chip selects. What about read and write? Write and able, we'll call it. It's all the same, right? So if I'm going to do a read, I'll read from all four. If I do a write, I'll write to all four. In all of the designs we've looked at, but if you look at some of the test problems, it doesn't necessarily have to be identical. So let's say I want to do a read and write. It doesn't have to be identical signal. Usually you wouldn't have some of them reading and some of them writing. That would be strange, right? OK. I'll just label these separately to keep the diagram from getting too messy. What about address? Yeah, I probably could just take the external address. I didn't make the address space any different. But if I just take the external address and put it in, that's fine. So external address to all four also. So it's pretty easy to do the wider one, right? What about data in, data out? Yeah, so I'm going to have four M bits coming in, right? So I can make each one M wide. Really, it's a total of four M. So I'm breaking these out of something much wider. And then each of those M groups can go into one chip. Does it matter which M I put into which chip? Yeah, as long as they come out the same way, it doesn't matter. You can do whatever you want. When you get into later classes, I think I mentioned this. There are some tricks you might want to play that will affect performance. But correctness-wise, it doesn't matter at all, right? So as long as the input and the output have the same pattern of splitting the bits up and bringing them back together, it's fine. I'll ask you something else when we look at the other way for address, too. So let's do the same gathering in our outputs, then. Normally, we'd have to label this somehow. The best way would just be to not gather them and put them side by side like this. So those are the data outs coming out of the bottom. I won't go add all the labels. So it's pretty straightforward to make wider addressability, right? What about more addresses? What if we want to do more addresses? Let's see. You want to do four? Is it four? Yeah, there we go. OK. How many chips are going to be active? So now I'm going to have four times as many addresses with the same addressability. How many chips will be active at once? One or zero, right? So how do I set chip select? Yeah, so I need a decoder, right? So there are four of these. So how big a decoder? How many bits in? Two, good. And where should those come from? Two address bits. OK, good. Yeah. So two address bits. So let's say these are m plus 1 and m. So now I still have m minus 1 down to 0, which is m bits, right? So those I could put into here and here and here and here. Sorry, I think I scrambled my order a little bit. And each of these is m bits wide. OK, oh, but what if I don't want to do anything? What if I don't want to do an operation? This decoder, as I've drawn it, is always going to output a 1. I should use enable? What should I use to drive enable? CS, OK. So external chip select is going to drive this decoder. Does it matter which of these outputs I hook to the chip? What if I cross my wires? Does it matter? Yeah, they're identical chips, right? So if I call the name of the chip, it gets associated with whatever the output of the decoder is. But if I just flip the chips, they're the same chips. It doesn't matter. So that's fine. What about write enable? Yeah, whatever the external one is, only one of these chips is going to be active. So it's the only one that will be looking at write enable externally. So we'll drive all four of the write enables from the same signal. That's OK. Let's see. So then we only have one data in of m bits. So where should it go? All four? Really? Oh, yeah, only one chip's going to be active. So if we're actually doing a write, whatever chip that is, we'll look at the data we put in. The other ones will ignore it. OK, so here's the tricky part. What about data out? Where's it come from? Do I need a MUX? So remember, when we talked about the data chip, we're going to assume these chips are going to be tri-state buffered on the outputs. So if the chip is not chip selected and I look at its outputs, what logic values do they have? Yeah, high z. It's not even bits. It's disconnected. So if I have only one chip out of the four, or even zero chips out of the four, connected to the same set of wires, a bus, basically, only one of those is active. Only one of those is going to put zeros and ones onto those output wires. So that's safe. As long as I only have one chip chip selected, which is always true because of my decoder, most one of them is chip selected, I can take these four and just wire them together, and it'll be safe. Sorry, it's hard to see this. And that'll be m bits of data out. So whichever chip I say I want to read from, whichever chip I say I want to read from will produce my output data on the same m wires. And that'll be fine. What happens if I scramble my wires? I mean, it's kind of complicated. Like if I was building this on a protoboard and I scrambled my wires, would it matter? Doesn't matter, right, as long as they're self-consistent. What if I, here's a different question, what if I put by accident address m plus 1 into one of these bits, would that matter? So well, so be careful. So if I use these two bits for my decoder and then I reuse one of the bits for one of the addresses, maybe on all four chips, does that matter? It does, right? So let me give you a concrete example. Let's make it easy. We'll say that there's only a one bit address going into the chip. So if I use, so I'll have three bits of address in total. If I use address 2 and 1 here and address 1 going into the chips, so if I've done it this way by accident, how many addresses can I access total? How many bits am I using? I get two there, right? But that's not an extra one now. So total number of bits is only two. So I can only access four addresses. So if I make that mistake, I'm going to miss half of my cells in my memory. So it's not going to let me access everything. Does it matter which ones I choose, as long as the other m are over here? So why did I pick the high two bits? I just like the high two bits. It really doesn't matter. Any two bits is fine. Any two bits is fine. You could pick the low two bits. It would work fine. So any two bits to run the decoder, but don't reuse those bits as the address for the chips. Yeah. Yeah. Yeah. No. If your chips don't have it, then you need it. Right? If your chips don't have the tri-state buffering, you would need it, yes. If the chips have it, it's just a waste, and it will slow things down. So it's extra gates, extra chips, and it will slow things down. So if your chips have it, you wouldn't do it. And? Why do you need the mux? You don't. And that was the question. Radvith was asking, do we want to put a mux just in case? And I said, no. If you know you have tri-state buffers, which is our design, you do not need the mux, and you shouldn't put it in. Does that answer your question? So you don't have tri-state buffers? Yes. So if you don't have tri-state buffers on the chips, then these chips are driving active 0s and 1s. In other words, they're connecting the output wires to VDD or to ground. So if you connect those two output wires together, you have a good chance of creating a short. So in order to avoid that, you would need a mux. Good question. Peter, sorry. No? Yeah. The tri-state buffers are inside these chips. So in our abstract model, all of the memory chips we give you will be tri-state buffered. Internally, yeah, it would be driven by chip select. And in fact, it would be driven. There's a diagram in my PowerPoint slides also in the notes. But it's driven by a combination of chip select and write enable. So you only get data output when you are reading and your chip selected. So that's an interesting question. So if I send chip select 0, are my outputs 0s and 1s, or are they high impedance? Yeah, so I don't need any more tri-state buffers. This design is already tri-state buffered by virtue of having all of the chips be tri-state buffered and having the chip selects all be 0 if I didn't select this bigger system. Yeah, a good question. Yeah. So you need to know what it is. And you need to know why it's useful. So yeah, so how to implement it? The only useful way, like there was a homework problem that just made you replicate the logic of the decoder. So that was not a useful way. The useful way is to use the fact that you've got bit lines and you've got select lines. And each of those can be driven by a separate decoder. So yeah. So if you have a label, you add them to some of the lists and that's one address. You're only going to send 5.5 0 higher. And then they have to connect to the bigger abstraction. So you have m plus 2 bits of address coming into the bigger system. So giving them new names is fine. So long as you still connect them to the address bits. Yeah. Yeah, that's the only way you can name 2 times m plus 2 address, 2 to the m plus 2 power address. Yeah, this is four times as many addresses using equal chips. OK. All right, should we move on then? OK. All right, so back to topics briefly. Sure. So more papers on SRAM cells? No. You mean things like SRAM cells? No. No. OK, so let's see. So this one we finished. Thinking more versus Mealy. So you don't really need to know much about more versus Mealy. And really, honestly, the names. So the only thing in our class, we always do these. So these are a limited version of more machines in which inputs do not affect outputs directly. In other words, state is a function. I'm sorry, output is a function of state only. And Mealy is the more general model in which outputs can depend directly on inputs. And this is the one that's always used in practice is the Mealy machine, but not with names. So this is a very simple example of a Mealy machine. But not with names. It's just that if you want a more machine, you simply don't make your outputs depend directly on your inputs. So if you've designed one and the timing doesn't work, you can throw down a flip flop. Yeah. Yes, the next state logic can always depend on the input. On the states. That's right. That's right. Yeah, so the constraint is on the more machine, the output is purely a function of the state, not also of the input. And so that's the extra constraint. It does mean the slight difference in the transition diagrams and the way we draw them, also next state tables. So this is how more looks. So because the outputs are only a function of the state, we can label the outputs in each state. There's no input dependence. So we don't need to know what the inputs are. We can just put the output bits here. And then the input arcs, we have to have one arc per bit combination of inputs. With Mealy, however, the outputs depend on the, or can depend on the inputs as well. So what we have to do is label them this way. So for every state, remember, if there are, say, three inputs, we have two to the three or eight different possible arcs. And each of those arcs will have a different combination of outputs, potentially, because the outputs can depend on the inputs. So in the Mealy design, the transition diagrams, you've got to move the outputs to the transition arcs. Is a synchronous counter an example? A synchronous counter can be either. That's an orthogonal decision. A synchronous counter just means that all of your flip-flops, so synchronous means they all share a common clock. And the counter means that it's mostly, it doesn't have inputs. It's just a loop of a circle of states. So the idea is that you can have a synchronous counter. And the synchronous counter is a function of the inputs, so you can still do these either way. I guess, technically, if we say strictly that a counter has no inputs, then they're the same. So if you do things like reset, you could have a reset that forced the output immediately into whatever state you'd be resetting the counter into, for example. And that would be a Mealy counter versus a Moore counter that waited until the rising clock edge before accepting that reset signal. But it's largely orthogonal, too. Anything else on this topic? All right, let's move on. I think maybe LC3 data path, wow. Let's see. It kind of looks like this. It's a big bus. All right, so LC3 data path. So there are a lot of control signals, but you don't need to know how to use them until the final. The things you need to know are this instruction processing, which no one wanted to hear about, 5 to 10 people. Who asked this question? Just clarify what you wanted to know. And everyone liked it, so anyone can chime in here. Remembering the modified data plan, I'm going to talk a little bit about that. OK. So all right, so first of all, there's the state machine. So the state machine looks roughly like this, and you need to know a tiny bit about it. So this is kind of what you need to know. Just a second, let me finish it. I'm going to zoom out a little. OK, so this is the rough structure of the state machine. So you've got three fetch states, and you should know the RTL for those. You've got a decode state, and I'll explain why that needs to be separate again in a second. And then you've got instruction execution. I've drawn three. Of course, there are 16, right, because we have four bit opcodes. So there's 16 different sequences, each of which is executing one of the different opcodes. So the way the LC3 works is first you do your fetch, and then we'll talk about what RTL goes into those boxes in a second. Then you do your decode. Then you do the instruction execution for whatever that opcode is. So you do need to know at this point roughly how these instructions are processed, what fetch does, what decode does on the LC3 data path. You don't need to know, well, which control signals does that mean? I showed you, but we're not going to ask you to write control signals until the final. I did say until, so you do need to know that eventually, but not tomorrow. Yeah, then? Yeah, so this one, the sheet I gave you is what you'll get, which has this with all the RTL filled in, so you will have that also. You probably want to remember the thing that I've told you 25 times in our class, which is PC gets incremented in the first stage, so when your instruction executes. As long as you remember that, you'll be good. But you should know what the RTL is here. You can always look it up in the diagram. If you lost that page, it's under Resources, LC3 handout or something like that on the wiki, so if you want to look it up. It's also attached to most of the sample exams, and it will be attached to your exam tomorrow night. So you'll have the LC3 encoding with all the fields and the RTL. You have this one. You'll have the data path picture. A lot of this, you won't need much this exam, but you'll have them. You'll need it more on the final. OK, let's just fill these in. So do you remember what's here RTL-wise? No, M-A-R. M-A-R. OK, so the other thing to remember about RTL is these things happen simultaneously. So whichever order I write them doesn't matter. On the right side is the current value of the PC in the cycle, and on the left side is what the values will be in the next cycle. So at the rising clock edge, M-A-R will have the value currently in the PC in this cycle. PC will get incremented by 1. So then whenever our instruction gets executed, the address in the PC will be the instruction address, whatever one we're executing, plus 1. So what's next? So then we read memory. So memory, remember, the way the von Neumann machine is designed, the memory only reads from the M-A-R. So we just tell the memory, well, go do a read. And we wait until the bits are then in the MDR. So that's the second stage. If you look at the diagram, we've talked a couple of times about memory having a ready signal. So that just stays there as long as memory is not ready. So once memory finishes getting the bits, we move on down to here. What happens there? Yeah, so we copy across the bus from MDR to I-R. And that's the point at which we can decode. This actually sets branch enable here, but we didn't even talk about that. It's not that important right now. So the reason we need a decode stage is because the decode is going to make use of the I-R. But remember, we can't make use of the I-R until the instruction bits are in the I-R. And the instruction bits are not in the I-R until the rising edge after that third state. So in the fourth state, the bits are there for us to look at and to branch off into these different sub-sequences for each of the instructions. But before that fourth stage, we don't have the I-R sitting in the, I'm sorry, we don't have the bits of the instruction in the I-R yet. So we can't branch until that fourth cycle. Read or written. Yeah, so for a write, you fill MDR and then fill M-A-R and say, go to a write. And then for read, you fill M-A-R and say, go to a read. And then you pull the bits out of MDR after the memory says they're there. OK, anything else? I was looking on Big Ben. I'm looking on the mirror now. No, you can't ask that in the review session. Sorry, I can answer afterwards. OK, anything else? Yeah, anything else? So whenever we have that table where it says, as we go along through this floating point, we're going to start with an I-R here. And then we start at that point, and then we're going to do a value. And then we do all of that separate stuff. So how do you do that? Yes, yeah, yeah. So yeah, so I won't go through and do a detailed example now. But there are some detailed examples. I won't go through and do a detailed example now, but there are some detailed examples in the PowerPoint notes and in the recorded lectures that will remind you of exactly what values the PCI-R, M-A-R, MDR take as you go through and fetch and execute instructions, including loads and stores. Yeah? So are the coordinates for M-A-R and I-R important? When you start executing an instruction, yes. After that point, for a load or store, you're going to change MDR. For a load or store, right? So are they always the same? No. And after you load or store, are then what happens? How many different I-Rs are we using? During execution, you may need to use MDR. So you asked whether I-R and MDR are always the same. No, they're not. Yeah, that's it. You mean in my slides? Oh, yeah, unfortunately, I'm not sure that I can remember exactly what it looks like in the discussion. Yeah, except that I don't know what the discussion sheet looks like. I looked at it briefly. And then, yeah, if you have it and can show it to me, then I'll explain it. But I mean, we tend to ask you things like the sequences so that you fill them in as they change, right? So you do need to be able to walk through this and understand when a particular register changes and then put them in order, that kind of stuff. But I don't remember how that discussion sheet was organized off the top of my head. No. I mean, T flip-flop is not terribly complicated, but it's outside the scope of the class. People don't really use it anyway. I know, I know, yeah. It was not supposed to. OK, anything else? OK. All right, so which one is that? OK, so von Neumann architecture. All right, so von Neumann, there are five pieces, right? What are they again? Memory, good. As you name them, I can draw them. Control unit. You've got to remember my Tolkien joke. I'm sorry? Input and output, good. And processing unit, right? OK, and then there are a couple of registers here and there, right? So what are the pieces? Let's say we'll start with the order. I put them in the same place as before I did, right? So what do we have associated with the memory again? MAR and MDR, right? So memory, remember, always going to have an address, and we're going to use a register to hold that address when we load or store stuff from the memory. And then MDR we'll use as a register to move the bits in and out since the memory is asynchronous with respect to the processor. Memory is not clocked, remember? In the processing unit, we also had a couple of things. What were they? ALU, right? So arithmetic logic unit is what that stands for. Whatever set of arithmetic logic shift, whatever operations we want to do, we have some function unit that can do them for us. So for the LC3, it's relatively simple. Generally, it could be any set we want to implement. What was the other thing in the processing unit? A register file. So these are actually registers that are synchronous with respect to the processor and substantially faster than the memory. And they allow us to manipulate values quickly by just having a few of them in the processing unit. So it tends to be small and much faster than memory. Input and output, those are just devices. We talked in detail about the LC3, but you don't need to know those details until 220. And then what's in the control unit? So we have a lot of memory. We don't need to know those details until 220. And then what's in the control unit? PC and IR. So program counter, which is what again? The address of the next instruction, right? And what's the IR? Instruction register. And what does it hold? The bits of the current instruction. Right. OK. Anyone want to ask anything else about that? Oh, it captured my pen. I don't know how I froze it. Hopefully I can figure out how to unfreeze it before we run out of time. Ta-da. OK. Anything else you want to know? Can you go to the contact list for people who have lost it? No, you don't need to memorize those. You can always just look them up if you need to use them. I mean, I don't think we hand you anything that has them, but you don't need to know them. So nothing else on von Neumann? OK. All right. Finite state machine design. That's just kind of general, huh? So let's see. Yeah. I mean, those are... Let's see. So I was trying to think of another one we could do quickly. Yeah, we can do a counter quickly. That's a good idea. Or a sequence recognizer. Why don't we do one of both? So just someone make up some bits. Say three bits. 110. Next. 010. Next. Next. OK. There's a counter. That was tough. All right. So then, I mean, seriously, what we would do is write... So those we'll call S2, S1, S0. And we could write those out like this. So 000, we could say, well, I don't care. 001, you didn't give me either, so I don't care. 010. 111. 011. Where's that going? XXX. It's a pretty easy counter so far. 110. I'll eat those words. We'll see. OK. OK. So we can draw K-maps. So let's see. So we've got XX1X. And then 1X01. All right. XXOR? X and OR, huh? Or we could do this. Oh, we need that one. Yeah. We have just this one here, right? We'll go right back. Does that look OK? Simple enough? It could be simpler. Maybe I wouldn't get full points on this problem. All right. So XX1X again. 1X10. That look right? Yeah, that one looks easy, huh? OK. So S1 plus is what is that? S1 bar? Yeah, good. So XX1X and 0X00 and this one. Is that right? Oh, sorry. No, this doesn't look right, does it? I think I screwed something up. This doesn't look right. I think I screwed up on top of the... I know, I just don't know where you're looking. Sorry. All right. So 0X00. Which ones do I care about? Oh, how did I screw this one up? Oh, shoot, I copied it wrong, didn't I? Why didn't you guys tell me? Which way did I copy it wrong? So I went that way. So S2 should be on the left. Thank you. OK. That's what you're saying, on the left of all the K-maps. OK. So then these are all wrong. So this one should be S0 bar. Is that right? That looks right. This one should be S2 bar. And this one should be S2 bar, S1 bar, S0. OK. Does that look better? OK, thank you. So three flip-flops, and this one will be S2 bar, and this one will be S0 bar, and this one will be S2 bar, S1 bar, S0. And I think that's it. So if you wanted to, you could then ask, well, what happens if it starts in one of these four unknown states, and then figure out whether we need to initialize it, or we can just dump it into some random state and expect it to fall into our cycle of four? Oh, no, you can always write it like this. Yeah. Yeah. Yeah, we're not, I don't think we're checking anymore whether you can draw. We used to, right? But let's say not anymore. I think it's OK. All right. Used to a long time ago. All right, so let's do a little sequence recognizer then. Someone pick a sequence. 1, 1, 1? OK. So how many bits do we need to recognize that? Three. OK, so we'll have a start state. So usually, sequence recognizers, we just start by drawing what we want to recognize, right? So start would output a 0. This would output a 0. This would output a 0. This thing would output a 1. And then we can fill in the other arcs. So one question, since that can overlap with itself, what does that mean? So if this were an input sequence, these three should output a 1 in that cycle. But if our input sequence is 1, 1, 1, 1, well, that's going to output a 1 here. But then the question is, what about this one? So if we say, well, it's OK to overlap, then that question mark should be a 1. So the input is the top, the output is the bottom, and they're lined up cycle by cycle. So it takes an extra cycle of delay in order to get the output with a Mohr machine. So the question is, should that question mark be a 0 or a 1? So that output did. If we allow the overlap, then it should be a 1. If we say, no, they need to be separate sequences of 1, 1, 1, then it should be a 0. If we say they have to be separate, we can only get 1, 1 every three cycles at most. Yeah. On that last day, the one output, what changes when it comes back to itself? Does it overlap? Is it going to do that for days after start? Yeah. So if you allow overlap, then you'd put this back to itself, because that would be a continuous sequence of 1's. And if you didn't allow overlap, you should be going up to that one, because that's the new 1 for the next sequence. Yeah. So anyone have a preference? You want overlap or no overlap? Did you have a question? Yeah. So let me draw this more carefully. So this is input. This is output. And so the recognition will always be in the cycle after the sequence. So you won't recognize it until the rising clock edge. You're able to change the output to say, well, yeah, I saw the sequence. And so in terms of cycles, if you count this one on the left as, say, cycle 1, it'll be in cycle 4, three cycles later, that you see the output is equal to 1, the sequence recognition. And remember, then, in a Moore machine, the output is independent of the input. So even though that question mark I just added may affect our state transition, it can't affect the fact that we saw the sequence. OK. So what did we want to do? Overlap or no overlap? Overlap. OK. So if we're going to allow overlap, let's see. We don't have a 0 arc here. Where should that go? To itself? How about a 0 arc here? Back to start. This one's relatively easy. What about a 0 arc here? All right. What about a 0 arc here? Back to start. What about a 1 arc here? OK. I think we're done. Can we finish? OK. There's our sequence recognizer. Yeah, you have to complete it. So remember when we talked about designing finite state machines, you have to make sure that every state has a 0 and a 1 arc. There's one bit of input. If you had two bits of input, you'd need to make sure it has all four arcs. All right. And you can give these names if you wanted to, or say, well, let's recognize one bit, two bits, three bits. All right. We have two minutes. So serialization and tradeoffs. So generally speaking, let's just do it quickly generally. The serial design, if you're talking about a big bit slice design, it can take lots of gates, right? So when you do the serial design, you do have to put a few flip-flops down, but those flip-flops will balance against a few bit slices. And so if you're doing a many bit slice design, the serial one will be smaller. It will take fewer gates. It will also be slower. So you're doing a slower design, but a smaller design. Why is it going to be slower? There are several reasons. But basically, you're doing one bit per clock cycle. And so instead of being limited by the gate delays in your system, you're limited by the clock cycle, and you're doing one bit per clock cycle. The serial design may not be the limiting factor in your system. So the clock cycle may even be longer than the single flip-flop plus one bit slice delay. So that adds up pretty quickly. Numbers-wise, it was something like an order of magnitude slower in the designs we looked at in class. Those are two extrema, right? So you can say, well, instead of having one bit slice for my serial design, let me do two or four or five or eight or whatever. And so you can operate in between those two. You can also optimize. So instead of doing a bit slice design, you can optimize across a couple of bits. So there's one example of that in the notes, where we did the comparator that we did in class. And then it's not something we're going to ask you to do. But if you're interested, I did a two-bit design for the comparator, where you can handle two bits at a time and optimize the logic for that, just so you can see how you get smaller logic when you look at the more general function and optimize it with kmaps. So those are some of the tradeoffs to think about. Yeah, so let me stop there. If you have any real burning questions, you can ask me now. But I'm going to turn off the mic. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.\"},\n",
       " {'ECE120-2016-11-04-LEC-30-slides.mp4': \" Okay, so let's go ahead and start. So today we're going to go through an example. We might get into a second example, but I think not. So we're going to try to go through this example of counting to 10. My code is there for you on the page. You also have this handout I gave you last time. Hopefully you brought it back today on your LC3 reference sheet. I meant to bring some of the extras back, but we have a faculty retreat all afternoon, so I was just upstairs and didn't have the chance to run over to my office. So let's just go ahead and get started. Then on Monday, we'll start another lengthy example of typing in a number. And then we're going to work towards looking at how we break problems down. And we'll keep working back down to LC3 code. So just do a few examples. This slide again, sorry, I know you're tired of it now, but I'm going to keep showing it until this day. All right, so what I want to do is look at the infrastructure we need with LC3 to be able to do something 10 times. All right, so you know how to do this in C from, I guess, seven or eight weeks ago, right? But to use the LC3 instructions, there are a bunch of ways we can do it. There are three ways on the sheet I gave you. One, just to show you the different addressing modes. One with PC relative addressing, one with indirect addressing, and one with base plus offset addressing. So just using the different loads and stores to do the same thing. So let's work through the middle one, the second one, which is the indirect addressing using LDI and STI. And then do the others on your own just to practice, make sure you understand things. For some of your labs, notably, it's the last two labs in the class, not next week, but the ones after that. They are sort of substantially more programming, and so you will have opportunity to make use of your programming skills. And students have found them relatively heavy in the past, so do try to spend some time on this and make sure you're understanding it. This is also arguably one of the more important parts of the class, right? To learn how to program, because then at 220, you'll have an entire semester of programming, right? So I told you on the first day, well, we tried to spread this out for you, so make sure you're getting the most out of it. And there will be a fair bit of coverage, a little bit on midterm three of just looking at LC3 instructions, but then also writing programs on the final. All right, so this is the part of the sheet that we're going to solve. So this is the second piece of three, and this is the code for the indirect address loop. So it's got the PC, we're going to start at 3,000 hex by convention. And I don't know why I put zeros there, sorry, that's C notation. You probably know LC3 notation, we usually leave off the initial zero. So this is the first part of the code we'll look at, and then the last part of the code we'll look at down here. And then down here we have some data that I've placed in memory, some other bits that are non-instructions. And then in the middle here, I've left out something, which is whatever that some section of code we want to do ten times. So that would be our loop body. Okay, so our loop initialization would be up at the top there, our loop test actually ends up being down at the bottom here. Our update is also down at the bottom, but you'll see all of this in detail as we decode these instructions. So I'm going to use the same data path image I used before for the most part. So I filled in the values, the data values that I told you about in memory. I've got the eight registers over here in the register file. Not much of memory will we use, just those two locations. I've got four microarchitectural registers down here, but actually we're going to ignore these three. So at this point I think you understand how we go through and do fetch, how we do execution with regard to loads and stores using MAR and MDR. But we're going to ignore those this time and just focus on the register file, the memory on the right, and the PC down here. So where should I go to get my first instruction? 3,000, right? So to answer that question, you should say, well, the next instruction's always in the PC, the address of that instruction. So look down on the PC and say, okay, I should go to 3,000. So we'll go to 3,000, so we'll look at our code page, and 3,000's up there at the top, right? So here's address 3,000, and here are the bits at address 3,000. So let's take these bits and figure out what that's supposed to do. So there's the bits. So what kind of instruction is that? LDI, right? So hopefully, how many of you don't have your sheets? Is there someone you can sit with and look? And if you have your book, it's in the back, the back cover. All right, so LDI, right? And that has two fields. So the first one is, what is it again? Destination, right? So when we do a load, remember, bits are going to come out of memory and go into a register. So this is which register we're going to put it in. What register is that? R3, good. And this is going to be kind of a human-friendly notation I'll write underneath. Turns out later, we're going to call this assembly code, okay? So it'll be sort of like RTL, but this will be what you write after we've put you through enough pain and punishment writing bits, and you get tired of bits. I mean, the computer only understands bits, right? But you really don't want to write too many of those. All right, so there's one other field in LDI, which is the nine bit whose complement offset. And so what is this one in hex? Yeah, so this is the leading bit for the nine, so we'll sign extend to zero, right, so that's zeros. And this one is 1001, so nine. And what's the last one? F, okay, good. All right, so this is the RTL then, so if you look that up on the sheet, remember LDI takes the PC, adds it to this thing, sign extend it to 16 bits, which is 009F in hex, goes to memory, reads that value, then goes to memory a second time, right? Okay, so that's the LDI instruction, so let's see how it works. So let's first write that into our sheet. So we've got, this instruction really means LDI R3 X9F, or you could write that in RTL if you'd rather, either one's fine for now. So then let's go execute it. So we'll go back to our data path picture, and we've got this, I'm sorry, not to the data path yet. We've got this RTL down here, so what is this first memory address? Yeah, so what is PC? So let's see, 3001, why is it 3001? So, okay, so in fetch, it got incremented, right? So when we fetch the instruction, we increment PC, so when we execute it, it's the address of the instruction, which is 3000 plus 1, right? So we've got 3001 in PC, so go back here. So 3001 hex plus 9F hex gives us this number, at least if I did my math correctly. So we'll go to that address, so go back to the data path, so where's the address? So 30A0, and we'll read that address, so this is the first memory read, and what we get out of it really is these bits, right? But for humans, we're gonna call that 4123, right? So we get 4123 back, and then we're gonna read, that'll be the inside memory reference, so that one gives us 4123 hex. So then we're gonna go read memory again, this time from 4123. So where's 4123? It's down there, and that gives us 0, right? So there's our instruction, the second memory reference returns all 0 bits, so we're gonna go to R3 and fill that up with 0 bits. So we go to R3 and overwrite whatever bits were there and put 000. Now of course, that's really 16 0 bits, right, but for human convenience, we're gonna write that this way to the side. Okay, one instruction done, so time for another one. Where do we go? Yeah, we're gonna fetch from what address? Good, yeah, so we just go down and look at the PC, right? LC3 doesn't do anything smart. Okay, where do I go? PC, that's where. Okay, so 3001, the next one on our sheet, so let's go look at it and decode these bits now. So we'll copy them here, and what is that? That's an add, okay, and the first field is destination, and which register is that? R4, okay, and what's the next field? Okay, one of our source registers, okay, and which register is that? R3, good, what's the next field? Yeah, so it's the one, the mode that tells us what the addressing mode for the last operand, right? So what does this one mean? Immediate, right? So then we have this 5 bit 2's complement number as an immediate value in the instruction, and that number is 1, right? Okay, so this again is our assembly language, which is nice for humans. So basically all you do with LC3 is you write the human form of each of the fields, and then you get the assembly language form. You can see there are commas in between, right? So eventually you'll get to write this nice friendly form, but right now you still have to write bits. So, all right, so R3 gets, I'm sorry, R4 gets R3 plus 1, right? That's what our instruction's supposed to do. So we can go back, write that into our, into our, our sheet. So we've decoded the instruction, so that's what the second instruction means. Now let's go ahead and execute that on our data path. So we say, well, let's take R3, add 1 to it, write it into R4. So go to the data path, look for what's in R3. So R3 is here, so that's 0. And we add 1 to that, and we get 1, right? So we're going to write 1 into R4. So, do you have a question, Kyle? You're just stretching, okay. All right, so we wrote 1 into R4, all right? So now, whatever used to be in R4 is gone. Hopefully there was nothing important, right? Same thing for R3. If we started with some important bits there, those are also gone. Now they have 0 and 1, right? And we're done with another instruction. So, where to? 3002, right? Whatever's in the PC, that's where we're going to go. Good. All right, so let's take a look. 3002 is up here. Here are the bits in that memory location. So, same exercise, right? Go get those bits and figure out what they mean. So, here's the bits. What's that opcode? STI, okay. And STI's first field is what? Source register. And what is that one? Okay, so that's R4, right? Okay, and what's the next one? The PC, the 9-bit 2's complement offset, right? And what's this number in hex? So, 09D, right? Okay. All right, so here's RTL for it. Again, this is a store instead of a load, but it's store immediate, I'm sorry, store indirect STI. So, it uses the same address formation as we did with the LDI. So, we're going to go to PC, add this constant sign extended to 16 bits. Going to go to memory and get an address, right? Go to memory, get 16 bits, say, well, 16 bits, that's an address. And then we're going to do the store of R4 at that address that we got back from this memory location we calculated by adding 9D to the PC. All right, so let's write that into our sheet, and then we'll go execute it. So, let's see. So, I guess the first step again is PC plus 9D, right? So, what's that address? What's the PC? Yeah, so good. You remember, we have to increment in fetch, right? So, when this STI executes, the PC will be 3003, right? Because it got incremented from 3002, which is the address of the STI during the fetch part of instruction processing, all right? So, we'll add that again. So, notice that when we add 3003 to this constant, this constant is a little bit different. So, we still end up with the address 30A0, right? That was of course delivered in the code. So, both of the, both the LDI and the STI go indirectly through 30A0. So, here again is 30A0, that hasn't changed, right? Nothing changed those bits. So, when we read that, we again get back 4123, okay? So, the LC3 then says, okay, well, the first read returned 4123. Now in my RTL, I'm going to write to address 4123, write the bits out of R4 into that memory location. So, we'll go look at our data path. So, R4 has the value 1. So, we're going to take that value and copy it over here to memory address 4123. Okay, and then we're done with that instruction. Time for another fetch. Where from? 3003, good. Okay, so where is that? Yeah, it's not there, right? The part we left out. Okay, so now, after the LC3 has done those three instructions, there's going to be some loop body that we didn't write down. We don't know what it does, but we're just going to assume that it does something important that we want to do 10 times. So, whatever it is we want to do, we would write into those instructions that I have left out. And then eventually, the LC3 will hopefully get down here to the end, and PC, let's say, is 3010 in hex. The current value of this is now 0001. This one hasn't changed, so I didn't edit it. But we're going to start executing this instruction, right? So, it's going to do some loop body for us, and we'll get to the end of the loop. And now, we're going to do our loop management code down here, for these last two instructions. All right, so I want to make another little table, just to keep track of what's going on here. So, we just executed the loop body. We just did it the first time, right? So, I'll say, well, that's loop body execution number one. So, what was R4 when that was executing? Go back for a second. Yeah, what was R4? It's one, right? Okay, so put that in the table. And there's this other thing that I'll fill in later. Okay, so R4 was one during the first loop body execution. Okay, so now, here's address 3010. So, we said that after the loop body, eventually the PC's going to get down to 3010, right? So, this will be the next instruction we look at. So, let's go decode it. What kind of instruction is it? It's another add. Okay, good. And destination register, R4. Source register, R4. Immediate or immediate? And what's the number there? Okay, so remember, if we want to negate two's complement, flip all the bits and add one, or we can also, let's see, this would be negative 16, and this would be six, so negative 10, right? You can do it either way, but, and you can do it on paper in practice too, it's fine. All right, so negative 10. So, in LC3 notation, the pound sign means decimal. So, when you're writing in the tools, if you see the pound sign, just means it's a decimal number, or if you write the pound sign, it'll be a decimal number. So, what that means is our RTL, take R4, subtract 10 from it, 10 decimal, and put it back in R4. So, that's the instruction. So, we can go do that in the data path. Well, first let's write our instruction into our sheet. So, we've decoded it, add R4, R4, number negative 10. So, go execute it. So, what is R4? Let's look it up. R4 is one, right? So, go back and subtract 10 from that, and we'll get minus nine, which we're gonna then write back to R4. Question? No, okay. All right, so we'll write minus nine, which I'll just put in decimal, right? I'll write the bits in in a second, but from our point of view, it's just easier to know, well, right now that's minus nine, and we just put minus nine into R4. And it's time for another instruction fetch. So, where from? PC, always PC. It's getting kind of dull. All right, so go look at address 3011 hex. That one is here. So, what are those bits? Let's go decode them. What kind of instruction is that? A branch. Okay, and what is that first grouping there? It's NZ and P, right? When we have a branch, we have to say, well, under what conditions do we wanna change the PC? All right, so remember, these are the NZ and P bits. So, this is saying, well, branch, if the last result was a negative number. So, if the last thing we wrote to the register file was negative, we're gonna change the PC. And what does this part tell us? The offset. So, this part tells us, well, where are we gonna change the PC if we wanna change it? So, there's a nine bit twos complement offset. Oh, sorry. Anyway, you could translate that. One EE, right? So, it's a negative number, okay? So, in other words, if we just sign extend it, that'll be adding FFEE, or it'll be like subtracting something from the PC because there's, you know, the carryout will get discarded, right? The 16 bit adder, the carryout bit will be thrown away, and it'll be effectively like subtracting something from the PC. We'll do that in a second. Yeah, so, no ops are used for various purposes, sometimes for delay, right? So, if you need to wait for a device, like if you look in the old Linux code, often before interacting with devices, they would delay. They're also used for alignment purposes. Some microarchitectures do better if you have instructions aligned to some bigger addressability. So, there are, I know there's a question. So, if you're in the habit of reading through exercises and else in the Pat and Patel book, there's a question about, well, what instructions do no op? And yes, branch is one of them, right? If you set these three to zero, as Rahul points out, then it does nothing. And so, you have an instruction that does nothing. Yeah, Daniel? Yes, effectively. So, what Daniel's asking is, well, how can we make that happen? Do we have to specify in binary? Yes, because if you put BR, as I mentioned two days ago, it will give you BRNZP instead. So, if you write in an assembly, you can't easily make it the no op without just specifying the bits. Yeah, awesome. That's right, that's right. So, this is what we call conditional branch instruction. So, the conditions happen when one of these three bits matches the last thing that was written to the register file. It would not match in this case, yeah. Or if it was a zero value, yeah. So, the only time we're gonna change the PC is when the last thing, which is the big N here, the one bit condition code. And I guess I could have taken this off at that point, but this was the one that was left. So, the full condition, which I wrote up a couple days ago, was little n times big N, and not times, plus little z times big Z, plus little p times big P. Nathan? Yes, you could do it that way too. Yeah, BR with a zero offset, it doesn't matter whether the branch is taken because that would add PC, that would reduce to PC gets PC. So, good point. Yeah, you can write a NOOP and assembly that way also. Without writing bits, yeah, good point. Okay, so let's see. So, let's go do this. So, first we'll write our instruction in. So, we found this was branch negative offset 1EE and hex. So, let's go execute that. So, what was last written to the register file at this point, do you remember? Negative nine, right? Our add wrote a negative nine to the register file, right? So, R4 got negative nine, that's negative, so we're gonna take the branch or not? Yes. So, let's write that in here. So, R4 at this branch instruction was negative nine. Okay, so I'm just building up this table. We'll come back to why we're doing it later, but just have this table. So, for the first loop body execution, R4 in the loop body was one, R4 at the branch was negative nine, okay. So, the branch is taken. What's the current value of PC? So, the branch, remember, was at 3011, right? So, remember, it'll get an incremented and fetched. So, the current value of PC when we execute the branch is 3012 in hex, right? So, what happens when I add 3012? Well, I guess I wrote it up earlier, sorry. So, if you add 3012 to FFEE, you should notice that one, two, and EE, when you add those up, you'll get a round number, right? And so, that'll percolate through, you'll get 3000 back. So, this is effectively negative 12 hex, right? So, we're gonna write 3000 to the PC. So, we'll make that change. Then what happens? Start again, right? Instruction fetch time. So, PC, LC3 will go to PC, okay. So, let's go to 3000 because that's what it says to do. LC3 just does whatever you tell it to do. So, go back up here, but we've seen that code, right? We know that code already. So, we don't have to go through and decode it or anything. We know what it's gonna do. So, let's look at that. So, here's the RTL for the first three instructions. So, I just copied it from our previous pages. Now, the value of the PC for each of those instructions, the instruction didn't move, right? It's in the same place. So, the PC value is always the instruction address plus one. So, when we calculated those addresses before and we found 30A0, that's not gonna be any different the next time we execute them, or if we execute them a third time, or a fourth time, or a hundredth time, right? So, we can simplify our RTL a little bit and just replace these PC plus values with 30A0, right? So, let me do that. So, now I've got going to memory at 30A0, memory at 30A0 instead of depending on the PC, it's a little simpler. But let's also assume that the bits at that address didn't change, right? Now, how could they have changed? Yeah, so, I mean, but we didn't do that store, right? Could they have changed somewhere? Yeah, the loop body, right? I didn't tell you what the loop body did, right? So, we're gonna assume that the loop body didn't do this. Okay, and I might ask you later, well, what if it did? Right, but we'll assume the loop body didn't change this address, right? So, if we assume it didn't change the address, well, then 30A0 still has 4123 hex, right? So, now I can simplify my RTL further and say, well, when you go to memory at 30A0, you're gonna get 4123 back, right? Just like we did before. So, let's do that. So, now we've got much simpler RTL, right? It says, okay, R3 gets the value at memory address 4123, and down here, I'll store R4 to it. So, now let's go execute these three. So, here's R3. So, first one, read memory at 4123, write it to R3. Here's memory at 4123. So, I'm gonna copy that over to R3. Now, R3 has a one in it, and then, okay, so that's change is done, so that's checked off. Then add one to R3, copy it into R4. So, here's R3. So, I'll add one to that and write a two into R4. And then, the last step is take R4 and write it back to memory at 4123. So, here's R4, it's a two, write it over there. Now, we have two in memory address 4123. And so, these three instructions together, they go to memory address 4123, add one to it and write it back. Yeah, Eric? How do you get back to the PC? Remember, when we execute a branch, we are going to add the current value of the PC, which was 3012, to the offset, sign extended, which is FFEE. So, if you add 3012 to FFEE, you'll find that you get 3000. So, it's like a minus 12. Yes, FFEE is equivalent to minus 12. Yeah, that's right. Okay, sure. Yeah, you can put pound negative 12. I'm sorry, then it'd be negative 18, sorry, yeah. Good question, we'll come back to that one. We executed all these, right? Okay, okay. Anything else before we go on? Okay, all right. Okay, so, we're going to do a little bit of a recap. Okay, so, let's see. So, we get down here, we'll assume I finished our loop body a second time now. So, we get down to 3010 hex with our PC. So, let's go fill in our table. So, we have the second loop body execution. What was R4? Two, right? Okay, so we'll fill that in now. And then I want to go back and do the bottom part, right? The subtracting 10 from R4, and then checking that to see how big it is, and maybe doing a branch again. So, these were the two instructions at the end. Subtract 10 from R4, write it back to itself, and then do the branch. So, the PC on the right, again, only depends on the instruction address, right? So, we can just replace that also here. That, again, is going to be 3012 hex. So, when we add it, it's always going to be 3000, right? This branch instruction is never going to go somewhere else. So, we can just replace that with 3000. And so, now let's go execute these two instructions. So, we've got R4 gets R4 minus 10. So, R4 is 2. So, when we subtract 10, what do we get? Negative 8, right? So, we'll go write negative 8. Okay, so that's the first step. Oops. Ah, so let's fill in the table. So, now we're at the branch. So, R4, you said was negative 8, right? We put that in there. And it's negative. So, this branch then, what's going to happen? It's going to change the PC, right? Good. And it changed the PC to 3000. So, that's the second execution of our loop. And we just branched up back to here again. So, let's go back and look at that table now. Okay, so we've gone through the loop two times. So, if you look here, R4, every time the loop body executes, R4 is the number of times we've executed the loop body. So, the first time it was 1. Second time it was 2. Third time it'll probably be 3, right? So, when does R4 at the branch get to 0? When this one is 10, right? Okay, which means what about the loop body execution? It's also 10. So, why did I ask you when this one gets to 0? Yeah, so when it's 0, it's not negative, right? So, when it's 0, this branch will not be taken. In other words, after the 10th time we've done the loop body, we get to the branch, we don't take the branch. We keep going. Okay. So, in other words, after the 10th loop body, it's not taken, and the PC remains at 3012. So, guess what the LC3 does? It does a fetch. Good, good. We're going to stop. Okay. That's what the LC3 would do, right? So, unless you tell it to halt, it would keep going, keep executing. All right. So, some questions for you. So, one of them, Mohammed asked. We'll get there. All right. So, why is there a 0 stored at 4123? What if I just put some bits there? Wouldn't that be just as good? I mean, what, 0s, 1s, they're all the same, right? They're all bits. Yeah. So, what would happen if I just put some other bits there? Almost. Not quite random. So, what would change about what I wanted? Yeah. Or fewer than 10 times, right? Yeah. So, basically, this 0, this is what we used to decide effectively whether we would keep going through a loop or not. It's like saying, well, I want to count to 10. Negative 4000, negative, we just, negative 399, you're not going to let me go, right? You're going to tell me to stop and that you understand. I mean, if I don't start in the right place, if I don't start at 1 when I count to 10, it takes me a heck of a lot longer and I don't count 10 times, right? So, if I don't put that 0 there, whatever I put there, it's going to start that count or iteration in our table. I'm going back here for a second. This 1 was the original value of 4, 1, 2, 3 plus 1, right? So, if you would put negative 3000 there, then instead of 1, you'd have negative 2999. And then this question I asked you, well, when do you get to 0? Well, that would still be 10, but then the relationship between this column and that column would have changed, right? So, you would execute the loop many, many more times. All right? So, another question for you. So, more specific, what if I put 5 at 4, 1, 2, 3 before I ran my code? How many times would it execute? Five, right? Because instead of counting starting from 1, we'd count it starting at 6. So, 5 off. All right. What about if I start at negative 5? Then 15, right? What about 25? Okay. So, this one's tricky. So, can it ever execute less than once the way we wrote this code? It can't, right? It never checks before it executes. So, it's got to execute at least once. So, it gets down to the bottom, and you've taken 25 and added 1 to it. You get 26, you subtract 10, you get 16. Is that negative? So, you're done. So, how many times? One. All right. Good. All right. More questions. So, what if we leave that one? I guess I kind of asked already, right? Okay. Yeah. That's a compiler decision, and it's actually, you can write C code that does it either way. Yeah. I didn't teach you both variants, because you don't need so much C. Yeah. Okay. So, what happens if we change the value at 30A0 to, say, 3141? Because this is, I like this number, because it's sort of part of pi, right? 3141. So, then that'll be a better program, right? What'll happen? Yeah, it'll address a different memory if it's load and store indirect. What's up with that memory? Bits. Bits. So, it'll run some random number of times, and then it'll stop, right? We have no idea how many times, because we don't know what's there. We didn't say anything about what's there, except, well, you add some bits. Good. So, what happens if the loop body sets R4 to zero? I think this is what you asked me, so you can answer. So, your loop body, you know, somehow someone else writes that, and in the middle of the loop body, they set R4 to zero. So, what's going to happen? Yeah. So, you take, I mean, at the end, R4 has zero. Subtract 10 from zero, you get minus 10. And that's negative, right? Yeah, so it'll go forever, right? So, just keep going and going and going. What's in 4, 1, 2, 3 doesn't matter anymore. It'll keep getting incremented, but in the middle of the loop body, we set it to zero, and so you subtract 10 from zero. No matter how many times you do it, you still get negative 10, right? Yeah, that's an unfortunate thing since I wrote it, isn't it? It unfortunately sets them all to zero, and I sort of regretted that in retrospect. I should have set them to random bits, but that might have been more confusing to people. Yeah, so the simulator, this was the question. What is memory set to in the simulator initially? And it's all zeros. Real operating systems do that also for security reasons, right? So, if you run a program, and then I can come look at your program, and your program has your password stored, then it's a bad thing. And so, an operating system, typically, before it runs your program, will zero all the memory it gives you. So, it's not unrealistic. It's just that it does then sometimes confuse people when they're just learning that they see memory always starts at zeros, which isn't necessarily true. Okay. All right. So, there's a reference copy of the code, data down here. And that's it for that one. Yeah, okay. Yeah, I mean, that's, sure, there are insecure OSs, yes. Yeah, so, deallocation is not sufficient, right? So, I mean, you would have to zero things. I mean, it goes, there's a step further, right, which is, you know, when you take your hard drive and you want to get rid of it, it's actually possible, even if you reformat your drive, it's possible, unless you spend a fair bit of time writing random bits on it and deleting them and writing them again, that someone who really cares can come in and read the bits you have there. So, there are lots of security issues like that. But most modern operating systems will, before they give you memory, they will set it all to zeros. So, yeah. Yeah, so, in the LC3 ISA, the real use that's, the most useful thing I've found with those is that there's some I0 registers up in high memory and they're always in the same places. And so, rather than putting those, they're not reachable as PC relative numbers, so they tend to be addresses like FE00. And so, you need to either put them in a register and do an LDR or you can do an LDI directly, right? If you have the number close to you, you can do an LDI. So, it has that value. In terms of practical value as a real ISA or something, they're not quite right. I mean, there are real ISAs that have things like that that are a little bit different. And the little bit of difference makes them much more useful from an idea of like generating code from high-level languages like C. So, they're a little bit strange in that sense. And if you know other assemblies, you might think, well, why did they do it this way? The primary reason, as I mentioned when I introduced them, was that the authors of the textbook wanted to emphasize that if I go to memory and I get 16 bits, that can be a memory address, which is an important lesson because you can. So, they wanted to make sure that everyone realizes 16 bits, it can be a memory address, it can be a two's complement number, it can be an unsigned number, it can be anything you want. And it's up to you, the programmer, to say, well, how should the computer interpret those bits? Did you have a question, Nathan? Okay, Eric? You mean this thing? We did it 10 times. But we do it one time and then we check. So, this is basically equivalent to the for loop. So, we're initializing and then we've initialized by hand down here. So, the initialization is not actually present in our code. The initialization would be to say write a zero here. And then we can leave it as bits but have our code do that writing. Up here, what we're doing is the increment. So, we've actually done the increment of our variable and then we're executing the loop body and then we're checking, sorry, the loop body, and then we're checking whether we've gotten to 10. So, these are pieces of the for loop, if you will. But I mean, like, that's something that a lot of people have tried. That's not the STI. Oh, no, no, no. There's some other code that I have omitted here, right? I've done the adding. That does whatever we want to do 10 times. It doesn't matter. I thought that was the STI or you want to do 10 more times. Oh, no, no, no, no. Oh, sorry. Yeah. The loop body is any code that we want to execute 10 times. So, it doesn't matter what code we write there. It's just this is how we would create a loop to do something 10 times. Yeah. Yeah, yeah. It's the loop part. The loop body I left out. It could be anything. It's the instruction. So, let's see. How many did I... So, that would be 16 minus 3. So, there are 13 instructions that can do anything. But you have to be careful not to write R4. And you have to be careful not to write to 30A0 or 4123. Yeah. So, you can do any loop body you want, basically. As long as you can fit it in 13 instructions. Yeah. Yes. So, in assembly, you can specify any of the operands can be written in decimal or in hex or as labels, which we haven't introduced. But we'll talk about that when we do assembly. Yeah. Can you refer to the PC with decimal values? That part, not quite. Yeah, that part, not quite. So, like the... Well, maybe you can. Now, I take it back. You can. So, the only time you would use that would be... The only time explicitly there's... When you specify where your program starts, if you want, you can say 12288 decimal. But I'm not sure what the value at is, I guess. So, you can use decimal numbers more or less throughout your program if you want to. The tools you're going to use first will be binary. And you have to write everything in bits. Actually, there is a version you can write in hex, too. But I wouldn't suggest doing that. I would write it all in bits. Yeah, so if you wanted, for example, to terminate your loop, you could set R4 to a value that would force it to stop at the end. Yeah, so that's true. It's not necessarily a bug if you're writing that code. That's a complicated answer. I guess I would never write that code that way. But some companies have insisted that all of their employees write code that way. So, it's hard to say no. But I wouldn't advise it. Go back to the first... Yeah, you can make loops within loops. I mean, if you wanted this one to execute again, you would have to reset 4, 1, 2, 3 to 0 if you wanted to execute 10 times. But that was what I was saying. I left off that initialization from this loop. I did it by hand. But yes, you could do that. Okay. Yeah, Rahul? Sorry. I mean, there are only five or six, and they're all on page 543. You won't need any more for a class. The code's in the LC3OS, too, if you want to look at it. Yeah, yeah, you don't have to do this through memory. Part of what I wanted to illustrate with these examples was the use of the load and store instructions. So, yes, you could simply use another register. In fact, you could simply... You don't even need to use R5. You could simply keep it in R4. And you could write the difference to R5 so as not to change R4 when you did the calculation of whether you got to 10. Yeah, yeah. So there are many ways to do this kind of loop structure. And that was also part of what I wanted to illustrate is you have many options when you're writing LC3 code to do the same sort of thing. And any of them is fine. Okay. Yeah. Yeah. So, okay, so that's a tricky question. Is there a better way to write the load? So if you mean, couldn't we have an ISA that didn't have so many PC relative instructions? That would make your life much easier. As you'll see in our next example, we're going to end up spending a fair bit of time doing counting, right, because you have to count, you know, how many instructions do I need? Like this one, right? I didn't make you count this time. But basically, in order to figure out what this offset should be, I could subtract, right? I could take, I could say, okay, well, PC will be 3012, and I want to go to 3000, so I need negative 12, right? I can subtract, but I'll make you count in class. And the problem is, if you change the size of this, of this loop body, then you change the offsets, right? Any offsets that cross-code you've changed, you're going to have to recalculate them and put them back in bits again, which is a giant pain. And so by the time we get done with a couple examples, you'll be ready to have an assembler that will do that for you. And the assembler will make that easier, substantially easier, meaning you don't have to do it anymore. A computer will do it for you. As to whether it's better to have load and store instructions that are PC relative or absolute, there are advantages to both. I mean, if your load and store instructions are PC relative, that means I can take that code and I can put it anywhere in my memory and it'll keep working. Whereas if I have absolute addresses in my instructions, that's not true. I have to rewrite my code to be able to put it in a different set of memory locations. Does that make sense? So if I had, for example, you know, branch to 3000 here, and if 3000 were encoded as an immediate value in my instruction, as is the case in some instruction set architectures, then in order to take these same instructions and do the same kind of thing elsewhere, I would have to change that branch instruction to make it work. But the way it's written here in LC3, that's not the case. I can take exactly these same instructions, put them, shift them to another location, and they'll still work. Yeah. Honestly, the best thing to do is to make the computer work for you, which is an important lesson in our class. So as you're writing, it's a little bit of a pain, the binary part, and we won't ask you to write that much in terms of binary code, probably like 20 instructions or so. And the reason is it just gets painful. But sanity check yourself by taking your code, pushing it through the tool, and looking at it in the simulator. It will tell you the address, right? And you can say, oh, I got it wrong or I got it right. So you can double check it. If you don't double check it, you just expect it to work and run it, then good luck. But I would use that to check it myself rather than trying to just stare at it. It's a lot easier. So when you use the LC3 tools, you are doing cross-architecture compilation, right? So what Raul is asking about is, well, when we compile, when we use the LC3 tools, we're running on an x86 machine, right? We're not actually running on LC3, right? So the code that we're using to assemble code or to change bits in a file as ASCII zeros and ones into actual encoded instructions for a simulator or for a real LC3 processor, if you build one, that's not actually running on an LC3, right? So that's called cross-compilation or cross-generation of code. That's pretty common for microcontrollers and small ISAs. If you get an 8 or 16-bit microcontroller, you're not going to compile code for it on that controller. You'll compile it on your desktop, your laptop, your phone, and then download the code as bits to that microprocessor. So there's not anything particularly mysterious about it, just that the code in the back end, the tools, generate instructions for a different machine, for a different ISA. And then you put those bits in a file and ship them to the machine that should be executing them. How do you write the – Yeah, the compiler actually only generates assembly and then you have an assembler. So – No, it doesn't – no, it doesn't go through a translation process. Yeah, let's take this one offline because – All right, any other questions on the example or – Okay, so maybe we're not going to get far into the typing a number example. So I'll put that one up online if you want to look in advance. The code is actually already there on the webpage, so have a good weekend. Thank you Professor. Sure. Mind if I ask you that question? No, it's fine. So – Okay. Okay. Okay. Okay. Okay. Okay. Okay. You you you you you you\"},\n",
       " {'ECE120-2016-10-31-LEC-28-slides.mp4': \" and didn't get around to it. Or maybe I'm dressed as a professor or something like that. So we're going to finish up instruction formats and then start talking about instruction processing, so how the LC3 actually executes instructions, processes them one by one. I'll walk through a detailed example of instruction execution. I realize I turned my mic way up. And then we will, I think probably on Wednesday, go through the entire ISA and look at most of the instructions. Most meaning I'll leave a couple for 220, but for the most part, we'll look at the instructions you'll need in our class. So I wanted to put this up briefly again, and then I'll turn the volume down a little bit since it's not so much feedback. So yeah, again, please do think about nominating your TA for the Olson Award. It's a nice thing. These are for 225, so unless you're really into getting ahead. All right, so last time we saw that in order to simplify logic, we can actually break representations such as instruction encodings into fields. So we looked at that. We looked at a couple instructions, and we saw that there's an opcode, which tells us, well, what is this instruction supposed to do? What kind of instruction is it? And then the other fields will actually specify the operands for that particular opcode. So we looked at a few LC3 instructions. Sorry, I didn't remove the animation from these, I see now, one, two. One of those was LDR. So LDR then had three operands, a destination register, a base register, and a six-bit offset. And we saw that, OK, here's how that particular instruction works in RTL. We'll go through all of these in detail again. So primarily, what I want you to see here is this structure in the instruction encoding. So you've got the opcode, which is always the four high bits in LC3. And then you have the rest of the bits, the other 12, broken up into fields. So there's no overlap here. You don't have to do any complicated math or anything. There are three-bit register fields. There are multi-bit, two's complement numbers. For the add instruction, similarly, we looked at one variant of it. You'll see another one later. And this variant had three registers. So you take source register one, add it to source register two, and write the sum back into the destination register. Again, in fields, four-bit opcode, and then three three-bit register fields. We had some left over. And so we set those all to zero. Rather, Pat and Patel set those all to zero. There was one more I wanted to show you before we started talking about how the LC3 processes these instructions. So this is the STR instruction. So if you look at this opcode, you go look it up in the table. I don't expect you to memorize opcodes, but we'll give you a table for that. If you learn it a little, then you might go faster translating code and things like that. So it might be worthwhile. But I would recommend just getting it by practice, not bothering to try to memorize them or anything like that. So it has a source register. So this is a store. So this will have actually the same fields as the LDR instruction, except that the direction will now be from a register. Take some bits from a register and put those into memory. So remember, the LDR was take some bits from memory, copy them into an instruction. So in this case, you can see the address generation is the same. So we take this base register. We read 16 bits out of it. It's zero to seven. So any of the registers in the register file, read those 16 bits out. Take these six bits from the instruction, sign extend them out to 16 bits. This is a six-bit two's complement number. So we just copy this signed bit 10 more times. Add those two together, and then go to that memory location and store the bits in the source register named by these three bits of the instruction into that memory location. So that's an STR instruction. And then in words, of course, that's much longer than the RTL. It's one reason we like to write RTL. So that's what it does. So I wanted to go over briefly, well, what is it you need to know about this stuff? So one thing is what we saw at the end of the week last week, which is, well, why do we do it this way? Why do we break things up into bits? You'll see there's already a question on the homework that kind of gets at that in an upcoming homework. I guess maybe, I'm not sure if it's the one that's out now or the one that's coming next week. But you'll get a question about this kind of on a homework at some point. Know the terminology, so things like opcode and fields of instructions. And eventually, in the next today and Wednesday, I'll show you how the different kinds of operations work. And you should have some idea of how they work and the kinds of things you can do with instructions, because you will start to have to program in a class at the end of the class in the last few labs. And so you need to know what you're targeting when you're breaking down the tasks down to the instruction level. So the better you understand, well, what can a computer actually do in an instruction, the easier that process will be. And then finally, how those operations can be executed on the data path. So I'll show you that as we go through. So we're not even going to look at return from interrupt. We won't look at interrupts in our class. But if the question is, do you know how to take a finite state machine state in the LC3 and map that to control signals, yeah, for the data path in the book. That is one of the things we'd like you to be able to do. You've already seen that on the previous example in terms of a very simple data path with six control signals and a finite state machine. The LC3 is a bit more complicated. There are a couple of examples you can look ahead to in section 401. Eric, come back in a second. AUDIENCE 5 OK. So I hear two questions. One was, do you need to know where the fields are for each of the opcodes? No, but you need to be able to read the table, which means you need to be able to translate all the things in the table. So if we give you instructions, you need to know how they work. You don't need to memorize that. Then the first question was, well, why are they designed in LC3 the way they're designed? No, we're not going to go much into that, other than to say that they're split into fields to make the logic much simpler. So when you look at the data path, you'll probably notice that things are pretty simple. There isn't much extra logic, aside from a few muxes, sign extension, things like that, because they took the time to do a very careful job designing the ISA with that goal in mind. If you're interested in more general ISA design trade-offs, you can read section 4.3 of the notes, which is a starred section. But it'll talk about instructions that architect your design, but beyond our class. Kyle? So what is the requirement of the class instance? So that's just for this. This is one field for STR and LDR. And it's an offset, because it's being added to the value in this base register. So your memory address is taken by adding these two numbers together. So this is an offset relative to the value stored in the base register. Does that make sense? Yeah, the particular fields will be on a per-opcode basis. Each opcode will have a different set of fields for its operands. Mohamed? Yeah. The source register are the bits being stored to the memory address. So the base register and the offset are used to create the address, to calculate an address. And that address in memory is where we're storing the bits of SR. You're talking about add immediate? We haven't even gotten there yet. Let me come back there. Let me get there first. OK, so all right. So what don't you need to know? We don't care if you learn the LC3 encoding, as long as you can use it. So don't bother trying to memorize it or anything like that. In particular, if you want to know what we'll give you on the exam, under the Wiki, under Resources, LC3 handout, there's, I think, four pages that will attach both to midterm 3 and to the final exam. So you won't need all of it on midterm 3, but it'll all be there if you really want to look at it. It has things like the LC3 instruction encoding with RTL for every instruction. It has the LC3 finite state machine state diagram. It has explanations of the control signals. So that handout will be attached to both of the exams. OK, so let's then think about, well, how does the LC3 actually process these instructions? So you've seen some examples. The LC3 is going to execute those instructions using the data path, but the data path can only do so much. So for example, think about the memory. The memory, the way we designed it, you can either read. Actually, it takes more than a cycle. It says a cycle on the slide. But you can read or you can write. You can't do both. You can't do two. You can't say, hey, I want to do two reads or four reads. And it might take many cycles just for one. In Pat Patel's design, there was an R signal. And until the memory says it's ready for something else, you can't go ahead and do something else. But to do an instruction, well, the instructions are sitting in memory. So how do we know what the instruction is until we do a read? So to get the instruction, I read it from memory. But then what if it's a load? We have to read again. So what should we do? Don't panic. There's nothing new. So all we're doing is breaking things down. So the first day of class, I said, how do you make a peanut butter sandwich? And you helped me break things down step by step to try to help me keep less hungry. When we designed the keyless entry system, if you want to open all the doors in your car, you have to push the button twice. You push it once, your driver's door unlocks. You push it again for the other doors. So we just need to break instruction processing down into steps. And each step then has to execute on the data path that the LC3 has. So we have to simplify to the point that our states, our finite state machine states, can execute on the LC3 data path. So what kind of things do we need to do? So first thing is, well, we need to get the instruction. Computer's just going to execute instructions. Instructions are sitting in memory. Computer doesn't know, oh, that instruction does such and such until it actually goes to get the bits. So it has to fetch the instruction out of memory. Then it has to take a look at it, meaning there's going to be some finite state machine state that looks at the bits of the opcode. So it's, well, what are they? Is it an add? Is it a store? Is it a load? What is it? So that's called decode. Those always have to happen. So those two, every instruction, go get the instruction, look at it to see what it is. It has to happen. Otherwise, you don't even know what it is. For some instructions, then we need to evaluate an address. If you're going to do a load or a store, well, load or store to what memory address? So there might be some computation, as there was in LDR and SDR, to add things together, whatever, calculate the address for memory access. Fetch operands from the register file. If you're going to do an add, well, you need to take the bits out of two registers so you can put them in the ALU to add them. So fetching operands, another kind of thing we need to do. Execute. So when we do an add, we have to use the ALU to add things together. So we've got to do execution. And then storing the result back to the register file or back to memory. Once we get bits out of the memory, want to put it in a register, or we do a sum, we need to put it back in a register. So these are the kinds of things we need to do with instruction processing. Not every instruction needs all of them. So sometimes we'll do some of them, sometimes we won't. We'll always do fetch, and we'll always do decode. The rest of this stuff is just sort of general categories to help you think about the kinds of things you need to do when processing instructions. So don't worry too much about them. The book will mention them. The book will give you definitions. The definitions there are a little fuzzy too. What matters is you understand you have to take the LC3 instruction, the RTL for that, and break that down into steps that are simple enough to execute on the data path. And you'll always have fetch, and you'll always have decode, and then you'll have some more steps. As you'll see, it'll be one to five more steps for each of the instructions in LC3. So let's focus on these two parts that we need to do all the time, fetch and decode. So we'll start with fetch. So here's our data path. Hopefully, this is visible. I thought about giving you a handout. Can people read this in the back? We're getting a little fuzzy. If you've got your LC3, your patent to tell book, it's just taken from that, from figure C3 in the back. So where are the bits of the instruction before I go get them? They're in memory, right? So they're down here in memory. Good. And where do we want them to be? Well, remember, there's a special register as part of the control unit in the von Neumann model that's supposed to hold the instruction bits. Register file is part of processing unit. So control unit's over here. Yeah, instruction register. So in order to execute the instruction, we want to copy the bits out of memory into the instruction register. Then the finite state machine here can look at those instruction bits and do whatever it says. So we need to somehow get these bits out of memory over to the IR. So how are we going to do that? So the last step then is somehow copying bits into the IR. You can see that it copies off the bus. So memory, though, can't write to the bus directly, right? Memory's down here. And it can go to the MDR. OK, so maybe that's what we need to do. Memory can write into the MDR. And then that memory from the MDR, those bits can go over to the IR. And so those will be our last steps. So let's put those in context. So the last step is take MDR, copy it across the bus into IR. And then whatever we do right before this step, we're going to have to fill MDR. So in other words, we'll do a read operation. But when we do a read, whenever we do a read, remember there's also this MAR, memory address register. Whenever we read from the memory, memory reads from the MAR. So that'll copy memory at MAR into MDR. So here's our last two steps. We don't know how many states the whole fetch will take right now. So I called it state n. Copy memory at MAR into MDR. And then the last one, copy from MDR across the bus into IR. So how do we set MAR? Let's go back and take a look at the data path. So where is the next instruction? In other words, what's the address of the next instruction? In the program counter, right? Good. So it's up here in the program counter. So I need somehow to copy PC down to MAR. So how can I do that? Yeah, I just copy it. See, there's this gate PC here. So I'll just turn on the gate PC. PC will be copied onto these 16 wires. They'll go everywhere around this thick black line, the bus. And then in MAR, you can see that it loads from the bus. So I'll just turn on LDMAR. And that will give me PC copied into the MAR. So in the same cycle then, sorry, hopefully that was clear. So we'll set gate PC and we'll set load MAR as part of our control signals. In the same cycle then, I want to set PC to PC plus 1. Then we'll be ready for the next instruction. So the PC, after the first fetch cycle, will point to the instruction, the new next instruction. So instructions, we're going to execute just in order in memory. So we'll be at some address, say 5,000 hex, and then we'll go to 5,001, and 5,002, and so forth. So in the fetch, we're just going to, in the first cycle, copy PC into MAR, but we're also going to copy PC plus 1 back into PC. And notice this doesn't use the bus. The wires are all in this circle. And that's important because the PC is carrying, I'm sorry, the bus is carrying the PC. So the bus can't also carry PC plus 1. It's a different number. So here's our full fetch sequence. So we have three states. First one, we do two things. Remember, these are parallel. So MAR gets PC, and PC gets PC plus 1. Second state, memory accesses, does a read. So memory at MAR, the bits come out. They get put in the MDR. And in the third state, we copy the bits from MDR over to IR. So there's something I want you to notice here, which is if I execute an address, I'm sorry, if I execute a PC, an instruction at some address, what's the value of PC when the instruction executes after the fetch? PC no longer points to the instruction that we're executing. PC now points to the address of the next instruction. So it's the address of the current instruction plus 1. That'll be important because in LC3, we have a lot of instructions that make use of the value of the PC. So you need to remember that it's not the address of the current instruction. It's that address plus 1 in all cases. No, it is always true. It doesn't use PC. Whenever you use PC, PC is the address of the current instruction plus 1. Sasha? Yeah. Are you using 5, 2, or something else? That's this one up here, yeah. Yeah. That you turned off, that you have? No, this is all happening in one clock cycle. So this is a clock synchronous sequential circuit. So you can see there's a separate set of wires that come over here from the PC. And then they go through this plus 1, which is just some logic to add 1 to a 2's complement number or an unsigned number, either one. That then comes to this MUX. And we're going to select this input. And then we're going to set load PC. So on the rising edge of the clock, PC will become PC plus 1. On the same rising edge, MAR will copy the old value of PC off the bus. So it's just two separate registers that load new values in the same clock cycle. No, because remember that if the rising edge comes, these things happen simultaneously on the rising edge. It's just two separate registers. So it's no different. I mean, it's a good question. But there's no difference from our previous data path where we had multiple registers being loaded at the same time. And this is an important difference between hardware and software. So whenever you see RTL, these things will happen simultaneously if they're put in the same clock cycle. And so all the right sides have the old values. And all the left sides will be the new values. Anything else on this one? OK, so let's go forward and see how these three states can be accomplished. So we'll look at them in a little more detail. So here's the first state of fetch. So PC MUX is set to take this PC plus 1 input. So this is what I was just describing. So we'll go through it in a little more detail. Load PC is set to copy the output of the MUX, which is PC plus 1, back into PC. Gate PC is turned on to put PC back into PC. Turned on to put PC out on the bus. Now, that'll be the old value, not the new value. And then LDMAR is also set so that the value put onto the bus by gate PC, which is the old value of the PC, is copied into the MAR. So again, both of these changes to the registers happen on the rising clock edge. These are just normal flip-flop based registers. So when the rising clock edge comes, MAR will have now a copy of the old value of PC. And PC will now store PC plus 1, the old value of PC plus 1. Yeah. So why do you need to read the bus? Does the PC kind of start the whole read process in the memory that it gets? Because the MAR and the PC are on the bus. So you need to tell the memory what address to read from. And that address is stored in the PC. So the memory only looks at MAR when it does a read. So in order to get it to read from the address stored in PC, you have to copy the bits out of PC into MAR. Make sense? OK. Sure. Mohamed? Can you explain the second state of fetch? Yes. So in the second state of fetch, which we'll look at in a second, we'll tell memory to go do a read. And it will read from this address that we've just stored in MAR. Yeah. That's the third. And I'll illustrate that, too. OK. So here's the second state of fetch. So memory, we're going to enable by setting this input to 1. I've kind of masked out the I-O logic. This is the one, the figure I put in the notes. But the I-O logic, we're not going to use in our class. So you set memory enable to 1. Notice that this MUX is also controlled by memory I-O enable. So that will take the output from memory, which goes through this input. From memory, which goes through this I-O logic again. But it'll take the bits coming back from memory and store them into the MDR through this MUX. The read write signal is put here. So we're going to tell it to do a read when we're doing the fetch. And then the LDMDR signal is also set high. So that MDR, when memory comes back with bits, will store the bits of the instruction at the address MAR. OK, and they are there. So these are some control signals for the second state. So we're just copying, again, the memory at this address MAR into MDR. So we're just doing a read. This is how the read works on the memory. All right, then the last state is just to copy from MDR across the bus into IR. So that's relatively easy compared to the last two. So we set gate MDR to 1. That allows MDR to be copied out onto the bus. And LDIR is also set. So it takes the value of MDR, which is now on the bus. And it copies it, stores it into IR in the third state. Make sense? We're good? All right. OK, so fetch is done. So each type of instruction, then, is going to use a distinct sequence of finite state machine states to execute. So we'll have one set of states for AD, a different set of states for LDR, a different set of states for STR. And in order to get to that sequence, well, we need to say, well, what is the opcode? Now, the finite state machine can't look at the opcode, can't use those bits until they're in the IR. Remember, in fetch state 3, we're copying them into the IR. But they're not there until the rising clock edge. So we can look at them in cycle 4, state 4. So state 4, that's all it does, is it looks at them. And then it jumps to a new finite state machine state, one of 16, based on the opcode. That's all it does. So we call it a decode state. Actually, it does something else. I'll tell you later. But for now, the important part is switch to one of the 16 sequences for that particular opcode. Whatever the opcode is, the opcode is stored in IR 15 to 12, the first four bits, the high bits of the instruction register. All right. So here's what we've got. So instruction processing is going to look like this. These first three are fetch. So MAR gets PC. PC gets PC plus 1. That's in state 1. State 2, read memory in MAR, copy it into MDR. State 3, copy MDR into IR. State 4, decode, and then some variable number of executing the instruction. And that's how we process instructions for the LC3. In general, every processor is going to have fetch decode in some set of execution states. It's always going to take some number of cycles to fetch, some number of cycles to decode, some number of cycles to execute. So what's the relationship between states and cycles? Well, each of those states is going to require at least one cycle, but some might require a lot. So memory, remember, is fairly slow compared to the processor. Real DRAM memory would be even order 100 cycles compared to a modern processor, so quite slow. Memory access states, such as the second fetch state, can thus require more than one cycle. So those states will actually have self loops, or they'll sit in that second state of fetch until memory says, OK, the bits are now in the MDR. So that might take one cycle, might take 100 cycles. Doesn't matter. The finite state machine has to be designed to wait for the memory to finish. So here's the state diagram. So let me highlight some things for you. So here's fetch up here. Maybe you can read the RTL. That's just the RTL we've been looking at. Here's decode. And then you can see it branches out into a bunch of different chains of instructions. And there's just one sequence per opcode. So if you go through and look carefully, the shortest is 1. I think this is add over here. So the shortest is just one state to execute an instruction, and the longest is about 5. Some of these overlap. So some of these for the different loads and stores actually overlap in states. So they share some of their sub-sequences. But generally speaking, you do fetch, you do decode, you figure out what it is in decode, you go execute for a few states, and then you go back up and find a new instruction. So after you finish, you go back to the first fetch state. So finite state machine fetches an instruction, decodes the instruction, executes the instruction, starts over. And that's it. That's a computer. So now you know how to build it from transistors. So here's a little thought problem for you. And you can be honest or not. I won't really even ask you an answer, but think about it. So at the start of the class, I couldn't have even asked you this question. What I really wanted to ask you is, well, how many bits do you need for the finite state machine? So for this high-level state machine I just showed you, how many bits do you need to build a computer? Think about what you would have guessed. And you wouldn't know at that point. But I don't know what you would have guessed. I kind of feel like I would guess, I don't know, a million or something, something big. 42. That's probably a better answer. But Pat and Patel's answer is six. There are fewer than 64 states in that state diagram. So with a six-bit finite state machine, there's the IR, there's the PC. We're playing the same games we did with our abstraction before. But the high-level state diagram only needs six bits. So I find that pretty amazing. You can build a computer with a six-bit finite state machine. I think that's kind of cool. Any questions on this? Yeah? How much do you actually need? How much you actually? This is an actual computer. Yeah, so that's a good question. So if you look at it, it depends on the design. So if you look at something like x86, it's been building up a lot of complexity because it's been growing gradually over about 40 years. And so it's a very, very complicated design. I really, I'm not even sure I can make an estimate. Yeah, it does even things like the external instructions are actually translated internally in a lot of the implementations into simpler instructions for speed reasons. And so there's a lot of state on the chip that logically is part of the FSM. In terms of executing the micro-instructions, it's probably actually kind of comparable. But there's a lot of other things going on in a high-performance design. So for example, they've mentioned this in Pat and Patel, but when you fetch one instruction and then you're going to decode it, well, you could usually fetch the next one at the same time. And then while you're executing the first one and decoding the second one, you could fetch the third one. And executes more than one stage, so maybe you can overlap those two. And so that's called pipelining. And so most modern high-speed processors will do pipelining. There's also things like super-scalar execution, where instead of fetching one instruction, decoding one instruction, well, why not fetch two, or four, or eight? And so those kind of things, if you take 4.11, there's a design competition. And some of our students have tried to build those in their designs. So I mean, it's in the scope of what you can do. That's pretty aggressive. I mean, just to give you a number, some of my staff for 3.91, they had a team where they did actually one of the first super-scalar out-of-order processor designs in 4.11. And they told me they spent 1,000 hours between the three of them on that design. So that's sort of the high end of ECE design competitions. But 3.91 is more fun. But that's because it's in my class. Anyway, so let's see. So the simpler architectures like ARM or Alpha, I think, again, they have all of the things I mentioned, pipelining, super-scalar fetch and decode and issue. But the core is also probably pretty similar in complexity to LC3. And there, there's not the complexity of the translation process either. So we'll come back to that. Yeah, PC has to start somewhere, yes. And so we'll talk about that later, how we make PC point to a certain point and things like that. I mean, a real computer bootstrapping process, PC will be initialized to something. And there will be some code that goes and looks on a disk usually for a small chunk of memory, which is the core of the OS. And we'll load that into memory and then start from there. Or we'll go to a particular place and read only memory and use that to do some of that bootstrapping process. So that kind of thing, you can learn at least the fundamentals of it in 391. But we won't do much in our class. Yeah, yeah, in most laptops and desktops, there's a BIOS like that. That'll be in read-only memory. And that'll tell the computer where to go look for the first chunk of the OS. So there's a bootstrapping process to bring the OS up. OK. So let's, actually, some of these questions that you were just asking, Sasha. So we just looked at some instructions and said, OK, there'll be a PC. And so how does those instructions get there? But you can ask the same sort of questions. So when I made a peanut butter sandwich, why was the bag closed? Why didn't it come open when I wanted my bread? Where did the bread come from? Or why was it whole wheat? These are all perfectly valid questions. So in our model of programming, we'll put bits into memory and then tell the LC3 to interpret our bits. We can also put data bits in memory. And the LC3 can't tell the difference. So if you tell the LC3, oh, execute my data, it will just execute your data for you. And all this stuff that we were just talking about, about bootstrapping and things like that, you'll learn in later classes. You can kind of see how it's done in the simulator here. But in order to really understand it, I think wait until 3.91 or talk to me in office hours. I can tell you more, too. All right, so let's take a look at LC3 instruction processing, what we just did and actually illustrated. So I'll show you a few pieces of the data path. So I'll put memory, register file, PC and IR, MAR and MDR. So it'll look like this. So here's memory over on the right side. I've got 65,000 addresses, except I left a few of them out. Here's a register file on the left side. I put all eight of them there. Here's PC, IR, MAR, MDR. And there's some blanks. What's in those blanks? Wow, you're good at this. OK, there's no such thing as a blank, right? They're bits. They're never blanks. They're always bits. We don't know what the bits are. Why are some values in hex? So that hex is 0000. It's like where you put other hex areas, not like just 24. Yeah, yeah. So that's a slightly different question, right? I mean, normally in LC3 by convention, we'll put our program at 3,000, which is why I wrote 3,000 here. But what I was trying to ask is, well, how come there are hex numbers on here? Because the computer doesn't understand hex, right? It only understands bits. So that's just for humans. So the hex here is just for us, right? All these you should read as bits. If I put bits here, it'd be pretty big. So I got tired of writing bits. But the computer, it's all bits. So 3,000 is 0011 and 12 more zeros. So I got tired even trying to read it. But yeah, as Eric pointed out, the 3,000 is where we'll usually store our LC3 program. So when you get in the lab and write your code, you should write it at address 3,000 by convention. All right, so let's get started. So let's say that we tell the LC3 to go ahead and execute. And so the first fetch step is, well, MAR is going to get the PC. PC is going to get PC plus 1. So what will PC become? 3,001, right? It'll get this value plus 1. What about MAR? What will it become? 3,000. And that'll happen at the same time, as you can tell by the animation. So all right, so to get those new values, so let's put those in there. So fetch stage two, we're going to then go to memory at MAR and copy the bits there into MDR. So first, we'll go to memory at MAR, which is 3,000. Here's address 3,000. You can see the bits here, which for us humans, we can call 670A. And we'll copy those into MDR down here. All right, third stage of fetch, copy MDR into IR. Here's MDR 670A. So we'll overwrite whatever bits are in IR with 670A. Those are the three fetch stages. Now we have this instruction over here, 670A, and we can execute that. So these are the bits now sitting in the IR that we need to decode and execute. Eric? AUDIENCE 1 No, those are three separate states of the finite state machine. So they went in the order that I showed on the slides. So you go through the finite state machine one state at a time. And then decode, you would then start looking at this and decode it and execute it. So it's only in the first state of fetch that you add one to PC. Yeah. You wait till you start processing the next instruction to increment it again. So we will get there. But yeah, we have to wait till we finish processing this one. OK. All right, so 670A, let's put that out in bits. So there it is in bits. And then we have the next instruction, which is 670A. Let's put that out in bits, so there it is in bits. So what does that mean? So anyone remember what this one is? Yeah, it's LDR. OK, and this one is the destination register, so that's what? R3. OK. This one is the base register, so it's R4. Good. And this is the offset, which is what? In hex. Yeah, it's a two's complement, and so it's 0A in hex, right? So the 0 and then A is there. OK. So in RTL, that means, OK, take R4, add A, extend it out to 16 bits, so just put the leading zeros on there. That'll be a memory address, so go there in memory, read that out, and store it in R3, the destination register. So that's one instruction. So what's the memory address here? So let's go back and look at our data path pieces. So the memory address is R4. Here's R4. So R4 is 1230. And then we'll add the 000A to R4, so what do we get? 123A. So what's stored in memory address 123A? So go back to our thing over here, and it's there, right? So 0F, 0F. So we'll take those bits and copy those to R3. So 0F, 0F. So we're going to copy 0F, 0F into R3. So there's R3 over there. It had some bits in it. We'll just write over those and put 0F, 0F. And that's our instruction. That was the first instruction. So all that work for one instruction. So what's next? Fetch, good. Start over. OK, first fetch state. So MAR gets PC, and PC gets PC plus 1. So what does PC become? Good, and what's MAR become? Good, OK. Second state. So MDR gets memory at MAR. MAR is 3001. That was one of the ones I left out. So let's just say it's filled with 16C3. So then we'll copy 16C3 into MDR. And then in the third fetch state, we'll copy MDR over to IR. So IR will now also have 16C3 at the end of fetch. So next is decode. So this is just walking through the finite state machine states as we saw before. So we're going to decode the instruction in IR, which is 16C3. So let's write that out in bits as we did before. And do you remember what that opcode is? It's an add, yeah. OK, and then this is our destination register, which is R3. Source register, R3. Other source register, R3. So it says take R3, add it to itself, put it back into R3. So let's go do that. So we take R3 and change it from 0F0F to 1E1E, multiply by 2, and we add it to itself and store it back. That's it for that instruction. So what's next? OK. Yeah, you can stop. You get to stop in a few minutes. Imagine if you leave the simulator running in the lab. All right, so fetch state number one. What are we going to do? What's PC become? 3,003. What's MAR become? Good, OK. State two. Again, I didn't write this one. So let's say it's 770A. That's the memory at address 3,002. We'll copy that into MDR, so 770A. And then the third state, we'll copy from MDR over to IR. So IR will have 770A. Go into decode, take those instruction bits. So 770A looks like this. The opcode there is, you remember? Yeah, it's an STR. Good. And then this one is the source register, which is R3. This one's the base register, R4. This one's the offset, 0A again, right? Good, OK. So memory at R4 plus 0,0,0A gets R3. So what's the memory address? Same calculation as before, right, since R4 didn't change. So R4 is here. It's 1,2,3,0. We add 0,0,A. And what do we get again? 1,2,3,A. Good. So we're going to store the bits in R3 into memory address 1,2,3,A this time. So the bits in R3 are 1E, 1E. And we're going to store those bits into 1,2,3,A. So we now changed 1,2,3,A to 1E, 1E. All right, what's next? Yeah, for the LC3, back to work for us. Yeah, so that's the end of our instruction sequence. So that's three instructions. And all we did is we went to memory, we read the value out, we multiplied it by 2, we put it back, right? What if R3 had something important? What if it had the only copy of your secret key, your encryption key? Too bad for you. It's gone. Don't do that. You're the programmer. The programmer controls the computer. Computer just does what it's told. If you have something important and you overwrite the bits, those bits are gone, right? So be careful. The computer will do exactly what you tell it to do. And if you had something important and you lose it because you told the computer to overwrite it with something else, your bits don't just magically come back. The computer doesn't stop and say, you know, I think you care about this. It just throws them away for you. All right, yeah? So in our lab, there was a good point. So we'll get to that with part of the ISA. But let me just answer you briefly. So HALT, what it does in the virtual world of Pat Patel is it turns the computer off. What it does in the simulator is just makes the simulator stop running. And now it might change register values. So if you're trying to inspect things, tell the debugger or the simulator rather to do a breakpoint and stop at the breakpoint. But if you execute HALT, you should always end your program with a HALT, and that'll stop simulating. That'll stop the simulated processor continuing to work. Anything else before we go on? Yeah? What does it do for you? So pretty much any computer you use for any purpose is executing instructions. So at some level, your phone, even your watch these days, the software that's written on them has to be mapped down to this level in order to execute. So what it does is everything computers do. This is the only way in which you can make computers do things is to execute at this level. Now, we build things on top of it to make it easier. So the one that we'll get through in this class is an assembler so that we can write things. All right, let me go back a couple more. Things that look like this line instead of things that look like this line. So in next week, you'll be writing this kind of line with 0's and 1's. In a few weeks, you'll be writing this kind of line with R1, nice human-friendly terms. Next semester, you can actually write C and compile that down on x86 and run that. But at the end of every execution process, the only thing the computer knows how to do is these bits. I mean, it'll be a different encoding for x86 or for ARM, but it's still not much more powerful in terms of what it can do. Good question. Yeah. I'm not sure. I'm not sure. But you're changing the PC. You're not reading it. Yeah. Sorry, but the old value of the PC is not relevant if you're changing the PC. Yeah, yeah. You did add. You added one before you executed. You always add one in fetch. Yeah, yes. Yeah, the addition, the increment of the PC happens in fetch. So any time you use PC in the RTL of an instruction, the value of the PC for the execution is the address of the instruction plus 1. Yeah, when you're writing to the PC, the old value doesn't matter. All right. All right, so let's see. So we can talk a little bit about this, and then we'll pick it up on Wednesday in a couple minutes. So we'll talk about it a little bit. So in the ISA, we'll have three different kinds of opcodes. You've actually seen examples of a couple of them. So one is operations. So those are the things we'll do with the ALU. The second kind is data movement. So we have register bits moving to memory, memory bits moving to registers. So to and from memory, we call those data movement instructions. And then the third kind is control flow, where we want to conditionally change the program counter. So let's take a look at each of the three kinds. So when we talked about LC3, we mentioned that the ALU only does three different operations. So there's add, and, not. Each of those operations has at least one source register and one destination register. And then for add and and, we're going to have a second input operator. So where does that come from? We have a couple of choices. So one choice is, well, we could use another register. That's the one I've shown you already. The other choice is to store some bits in the instruction itself. That's called an immediate operand. And you have the choice of addressing mode for your second input operand. So you can have a register, or you can have an immediate value. So let me show you how that looks in terms of encoding. So first of all, two opcodes for the two input operands, the binary operators. So add is 0, 0, 0, 1. And is 0, 1, 0, 1. The mode bit here, IR5, is what decides which is the addressing mode of the second operand. So one choice is that mode bit is a 0. And that says, well, the second operand is also a register. So in that case, these two bits have to also be 0. And then you get SR2 here. Now, that's the one you've seen. So when we did an add before, we had two input registers. We added them together. We stored it to the destination. The other choice, though, is to put a 1 for the mode bit, in which case you get a 5-bit twos complement number. So that means the second operand, where you're add or you're and, will be this 5-bit twos complement number, sign extended out to 16 bits. So what can you do with immediate mode? Why bother to have it? So one thing is you can add small numbers. So for example, it's pretty common to want to increment or decrement. If you're going to run a loop, you want to do an increment, you do an increment, decrement. You can go up to or down to negative 16 with 5 bits, up to plus 15. You can also mask out your high bits. So if you want to just look at the low bits of a number, you can end it with immediate 1. Or the low 2 bits, you can end it with immediate 3. That'll throw away all the other bits in the register. All the other bits will be zeroed out. You can also mask out low bits. So if you want to zero the low bit here, you can end with minus 2. And that'll give you FFFE is minus 2. So the low bit will be set to 0. Or if you want the last two bits set to 0, you can end with minus 4. And then probably one of the most important things you can do is put 0 in a register. So if you want to count from 0 to 9, well, how do you get a 0 in LC3? So one way to do it is to use AND. You AND to 0, now your register is 0. So that's a common way to initialize a register to 0. So just some uses for the immediate mode. Yeah, let me show you this one, and then we'll stop for today. And I'll show you how that works in the data path on Wednesday. So this is the NOT. So you only have one operand. So in this case, IR5 to 0 have to be 1. So the NOT operand is 1001. So that takes SR1, calculates 1's complement of SR1, and puts it back into DR bitwise. So let me stop there, and I'll see you on Wednesday. Enjoy your Halloween. Thanks.\"},\n",
       " {'ECE120-2016-12-07-FIN-review-slides.mp4': \" All right. So someone, Daniel, just asked me, what's going on in the holiday party? Why is it so important you go there? There's a, I just, I was just there eating while you guys were waiting outside. I told ECE SAC to come down here and announce it. I don't know, I think they sent it out on Twitter instead. So if you didn't get the tweet, too bad. No, you can still go there until 430. They're doing like a gingerbread house competition. So if you can do a better house than everyone else in half an hour and post it on the, I think on the ECE SAC Facebook page, then you can win. But free cookies, free hot chocolate, stuff like that. So you should go up and hang out. This is just, you take the elevator to the third floor, turn left, there's a big ballroom-like area, and that's where it is. Okay, not quite as fun, but office hours next week, 12 to 2. And then today, I'm just gonna finish up the advice and then talk about review. So we'll do a little mini review session for the final, or maybe not mini, but a full hour, or half an hour, whatever I have left. Final exam coming soon. Coverage, you've seen this, so won't spend too much time on it. Again, this is in the video, too, so if you didn't write it down or whatever. One part each on, so one question, really. Part one, two, and three of the class, so each of the quarters. And then four parts on the last few weeks, so the material since midterm three. I don't need to push buttons here. All right, so this one I talked about, try to do a big project in the next few years. This actually means kind of your own project, so that you're in charge and you make decisions and you can learn how to design things and think about how to constrain things, too. Learn to use a debugger, learn to use tools, avoid optimizing prematurely. I don't remember who it was, I think Donald Knuth, who's a famous computer scientist, said premature optimization is the root of all evil, but it was mostly in context. But the main point is valid, so there's some other context involved. But the main point is that you really don't want to spend time making things smaller or faster or better that are not a significant part of a bigger design, right? So don't waste your time doing that. What you end up getting is a very complicated piece that maybe you have to throw away later anyway because someone has to modify it and no one understands how it works because you spent so much time making it complicated so that it would be smaller fast. So be careful about how you optimize. Make sure things work, right? Do all the debugging and testing and things like that. Then figure out, well, what's the part that actually takes the time or takes the space or takes the power or whatever you want to optimize? The thing that's taking too much and then go make that part smaller or faster or use less energy or whatever the metric is, right, or set of metrics. So use your time wisely in that sense. All right, so this is the one I stopped on. So Seymour Cray was the inventor of the supercomputer. There was a series of companies he founded actually based on supercomputing. But for many, many years in all the national labs and other places that wanted to do high performance computing, they bought Cray computers and that was basically the only thing they bought. But he lived in Minnesota and actually Cray Computer by name, there's still companies up in Minnesota. But he would, there are a lot of lakes in Minnesota, so every spring he would start building a boat to go sailing on the lakes. And in the summers he would sail around. And come fall he would pull the boat up on the beach and burn it. And the next year he would start over, using all the stuff he'd learned by building his boat the year before and the year before that and the year before that. So sometimes it's worthwhile as you're building systems, whether it's software or hardware or both, just say, I've learned a lot by putting this together, but it's better if I just start over and just chuck it and start over and rebuild it. There are other ways to do things and you need to learn those too, but this is one useful lesson is, well, when do I just need to start from scratch and do my own design, even though I've done this kind of thing before, I can do it better now because I know more. So it's worthwhile building even just a prototype and saying, well, what did I learn by that? What was the hard part? What was the easy part? Where should I put more time and energy and thought? Best designers are the best testers and debuggers, best debuggers. So we tried to talk about this when we introduced programming in the last part of the class, that you want to think about what your program's supposed to do before you sit down in front of a computer and start writing code. The people that think about it and draw pictures of their data structures, as I tried to do for you as we're developing code just before break, hopefully everyone at least watched that video. I know you're enjoying eating and relaxing over the holidays. But the people that think about, well, what is it I'm trying to build and have that model in their head, you're going to be a lot better at making sure that that's what's actually in your code, that's what your code is doing. And making sure that there aren't any bugs and that the code is really doing what you intended. So do think about that as you go forward and build your systems. Good code is like good prose. It should be easy to read your programs. I mean, sometimes you say, I can save an instruction or something. That's fine if you find some clever way to do something, but put a few comments in. If it's easy for people to read your code, then they can keep the code around. You can reuse it later when you say, hey, I need something that does this. Well, this old code I wrote is almost right, but now I understand how I made it work so I can change it. If your code is hard to read, for whatever reason, you don't put any comments, you make it cryptic, you do complicated things when simple things would have worked just fine, then you won't be able to do that. You'll go back and you look at it and you say, well, I don't know, or worse, you'll say, maybe, and you'll put it in and it won't work. Or worst of all, you'll say, maybe, and you'll put it in and it won't work, but you won't realize it, and then you'll give it to someone else and they'll laugh at you. Now, I guess worse is where someone actually gets hurt because you give them broken code, but try to make your code easy to read. Take on a big team project. So one of the reasons they want to put the old slides in as a review is you might think, wait, this is the same thing, but it's not. So you should have a project for yourself, but you should also make sure you have some chance to work with some other people. So one of the big changes actually between 190, which is the old version of the first class for ECE students in computing, or computing class for ECE students, maybe is a better way to say it, is that in that class, our discussion sections were kind of more like traditional discussion sections, which you've probably had here, or maybe you're not, because a lot of our departments are changing their intro classes now, where basically it's a little bit like a lecture, right, your TA stands up and maybe does some examples, or maybe just answers homework questions, or whatever. But it's not you getting together in groups and working on problems together. So we changed that, and part of the reason was for many, many years, our alumni and company reps and everyone's been saying, ECE students don't have enough soft skills, right? They know how to solve problems, but they don't know how to work with other people. So we've been trying to put more and more teamwork, but we still want you to build up your own skills. So we did that in this class in the context of discussion sections. You should also do it outside in your outside projects, right? So you should find some friends and build something together in the next few years, just for fun. I mean, not just for fun, for excitement, and you can even make a profit out of it if you'd like to. But fun should be a part of it, right? All right, don't be afraid to break things. There's a lot of stuff available to you as an ECE student. A lot of the independent study projects and labs and things like that, there's some budget lying around here or there. I mean, don't break expensive equipment in the labs. But don't be afraid to take code apart or look into things to figure out how they work, right? If people never did this, we'd never have new inventions, right? So don't worry too much about, if I do this, it's not gonna work. Go instead and see what happens, right? Figure out how it works and play with things. And so last part, hopefully you've seen examples from this. I'll mention one in a second, but look for opportunities to turn dredge work into inventions. Actually, I'm pretty sure I don't want to mention the one I just thought of on video, so. But you'll find lots of opportunities in your life where you're doing something quite repetitive. And you might think, well, gosh, a computer could do this. In fact, I could teach a computer to do that. Well, certainly you could make your life easier by then doing that, right? Maybe also other students. Now, if it turns out to be your ECE XXX homework, maybe that's not such a great idea, but XXX, replace with whatever you want. But there are lots of opportunities for that sort of stuff. So that's where things like assemblers came from, right? People got tired of writing binary code. And they said, well, couldn't we just write something simpler, right? Maybe we could write ASCII characters and we could write a program that turned that into bits for us, right? That's where high level languages came from. So that and lots of other things in the world now all came from this idea of, well, why do we need humans to do that, right? Couldn't we automate that? Couldn't we make that easier for people by having a computer help them out and do the easy parts? Right, so look for opportunities for that. And if you come up with good ones, then make them available to your friends. Or more broadly. So that's it for the advice stuff. And unless anyone wants to ask questions, we'll go into review session mode. No? Okay. That's it. Let me turn this off. All right, so we'll switch over here. And we'll do our customary survey of topics. So what would you like to talk about for review? Or do you just want to go upstairs and eat? Yeah, Eric? See programming? Okay, yeah. So part one of the class will be one question on the exam. The systematic decomposition, which is what I consider to be kind of the key, the core of programming, which is how do you take a task and break it down into pieces, yes, that's part of the most recent material. And there will be programming in that sense on the exam using LC3. Probably assembly more than binary just because although we think it's amusing, we know it's painful. So there'll be a little bit of binary, but programming there will be some of. C programming though, it's possible that one problem might include a little bit of it, but only at the level that we actually taught you, which was really one statement level kind of on the first midterm. Yeah, Nathan? Okay. There is a summary slide in the PowerPoint too for that, but I'll go through it. Yeah, yeah. Hazards. I thought that's start stuff. It is start. Okay. Yeah. Yeah. Run through the concepts we should know. Okay. That's it. Let's see. Where did my. Oh, this is nice. Okay. Skills from part one. You should be able to do those things. I think I even got it all on one page. Okay. Emily. I'm sorry. What? Okay. Okay. What level of detail do you want out of this? Okay. Okay. Yes. You should. I mean, so we didn't cover that many sequential components, right? And muxes and decoders, I would think you know. To know how to use it is sort of to know the equations, which is to know how to build it, because you know how to build combinational logic. So, I mean, I would hope you could reproduce it, even if you haven't memorized how to draw it. I mean, you should in real life, you probably never, unless you go and actually do the cell design for a new process or something, you probably never have to reproduce it. You could probably just drop it in place or even write it as hardware design code. But you should know how it works, and to me, to know how it works is to know the equations, which means, again, you know how to do combinational logic, so you should be able to build it from gates. And it's actually not impossible that, you know, say carbon nanotubes actually become viable as a replacement for CMOS, that, you know, more than one of you might actually be in the business of saying, well, how do we take a bunch of carbon nanotubes and build them into a mux? Right, so, yeah. Okay. There's actually a list over here hidden right now, so I will put it back up in a second. And then, so this is just the summary. The other half of the summary then is just knowing what these words mean. So, I'm going to read my mail now. Yeah, I'll just pop up that attachment. So, I'll be taking the final tonight. You've caught on to our secrets. All right. So, yeah, I mean, there's a terminology list, right? We should recognize all of these, hopefully. Yeah, and actually I put that on there already, so let me switch over. I'm going to zoom out a little. Hold on. Okay. Anything else we should add to this list for today? 320, so we have about 40 minutes, yeah. Glenn Norman? Sure. Okay. I'm going to write the acronym. Yeah, Eric? Yeah, so, okay. Let me put those two together and then put it on the list. Okay, anything else or should we vote? Okay, so, let's see, what was the first one? So, C programming with a two, three, okay. Two past process for the assembler. About 12. Hazards? Yeah, you got to vote for your own two. Control signals? Okay, so a bunch, maybe 20, 25. Micro sequencing? Okay. About 30 to 40. Floating point to decimal? About four. Von Neumann model? Okay, maybe about eight. For floating point to decimal, by the way, there is a tool that, you know, you can look at the videos for a review of examples over the PowerPoint slides, but there's also a tool that will help you do some examples. SecDED codes? Two, three. Hardwired versus micro program control unit design? Okay, so maybe about 10. Okay, so let's talk about micro sequencing then. So maybe I will, I need probably, well I don't need, but it's probably easier to do with pictures, so let me. Okay. Let me do the definition first. All right, so first I wanted to just redefine the problem, make sure everyone knows what it is. So mapping the control signals, which I think we'll end up talking about again anyway, but that's just a question of somehow figuring out how to look at the current FSM state of the control unit and produce the right bits for it, right? So once you've mapped everything into RTL for each of the states and the right sets of states and the sequencing between them, or this transition diagram, let's call it for now, then you have a couple problems. One is creating those bits, right? And that's the one we had last, which is, well, do I do it by combinational logic, which is a hardwired design, or do I do it by treating it as a little program, which is a micro program design? So we'll talk about that later. So the micro sequencing problem then is, well, I've got this state diagram and the finite state machine has to go from one state to another in that diagram following the arrows and following whatever branch decisions I've put in there. And, well, how do I build that logic, right? How do I make it go from the right state to the right next state so that it produces the right control signals to process the instructions for me? So that's the problem of micro sequencing. All right. That's the problem of micro sequencing. So if we take a look at, this is the Pat and Patel state diagram, right? So here's the level at which we've already completed the design so far, let's say. So you can see each of the finite state machines has FSM's RTL in it, rather. And, you know, we have the arrows and we have the branch decision saying, well, you know, here we're going to wait for the results to come back from memory. And if we get a memory-ready signal, we'll go on to the next fetch state. If we don't, we'll stay in this state. So we need some way of building logic that controls those state transitions. And we can separate that out from the output logic, which is implementing the RTL through control signals. So those are two separate logic, I don't want to say logically, we can kind of split those up into two pieces. One is, well, how do we generate the control signals? And then how do we generate the next state? Just like we generate outputs versus next state logic when we design simpler finite state machines. It's the same sort of separation of concerns. Now, at the end of the day, you might end up, you know, sharing gates between those implementations, just like in our designs, we just said, well, let's put all of those bits into the same memory, right? But you can think about them as different problems. So let's see. So we did a couple of these. Maybe I felt like this one was simpler. So I was going to skip ahead here and just look at the Pat and Patel micro sequencer again. Or do you want to look at this one again? Go back to Pat and Patel. Okay. Yeah, this one is also in the notes with a couple tweaks and also in the PowerPoint slides. Pat and Patel is also in the book. And also in the PowerPoint slides. So let me skip to... All right. So this is actually the micro sequencing part of the Pat and Patel design. So in their micro sequencer, they do it as follows. Actually, let me show you the state diagram. So remember that in these kinds of processor state diagrams, let me clear away the stuff. In these kinds of processor state diagrams, usually we only have one or two next states. So most of the time, we don't design them to have three or five or seven next states. They just make very simple decisions about how to process the instructions. Maybe they look at an address mode bit or something. I suppose you could design an ISA that had three address mode bits. But if you wanted to, you could branch on two of them and then branch again on the third in the next finite state machine state. So it's not too hard to get it down to one or two next states for almost all of the states. The exception then generally would be decode, where you're figuring out, well, what kind of instruction is this? Let me branch into a bunch of different execution paths for each of the opcodes, for example, in the LC3 architecture. So in order to put those things together, Pat and Patel for their micro sequencer said, well, we're going to have to have one next state ID. So generally, we've got at least one next state. So we'll have one ID for that next state. And then somehow when we're going to branch, we'll name a condition. So there are five branch conditions in their design, right? Five different reasons to branch to two different next states instead of one other than decode. And so we'll name one of those five conditions. For that, we'll need three bits. So we'll set the six-bit next state, the three-bit condition. And then in order to handle decode, we'll put one extra bit that says, well, should we branch like a decode state or not? And so only one state will have this bit set. It's the decode state. And all the other states are not the decode state. So all of the next state decisions can be made from these 10 bits, right? First, you say, well, is it decode? If it is, then I'm going to go to a particular state for that particular opcode. If it's not decode, I'm going to go to this state modulated by this condition. And so how does that – so these are the conditions. All right, Eric? Yeah, yeah, sorry. I'll give you more detail, and I'll show you the implementation again in a second. It's there. So these are the five conditions. This is the unconditional, meaning that some state has only one next state. So if a state has only one next state, you just set the con bits for it to 0, 0, 0. If it branches on memory like the one we were looking at a minute ago, you set the con state to 0, 0, 1. If it's your branch state and it should branch on the branch enable bit, then you set it to 0, 1, 0. And then there's some others in instructions and concepts that we didn't talk about in our class, but that are implemented in the full LC3 design. So there's some other conditions for that. This table I'm pretty sure is included in – not in this form, but I think the information is in the bits that are given to you on the handout. But if not, double-check and email me, but I'm almost positive. I think I visualized that part of it. And I hesitate to pull it up now, but does anyone have that one here? Some people have laptops, so check it if you don't mind while we're live. We don't care if you memorize this. I'm pretty sure we give it to you. There's really no value in your knowing, oh, the LC3! PSR 15 would be checked if you just set those con bits to one – whatever. But we want to know that you know how to use these tables and fill in the control memory. So we may well ask you to do this sort of stuff. All right, so this is the implementation. So what you can see here is, bottom line, if you have a decode, your J and your cond don't matter. Instead, what you're getting is 0, 0, followed by the opcode, and that's your next state. Remember, we set up those 16 chains based on the opcode, starting with states 0, 1, 2, 3, up to 15. So it's something we didn't study. It's basically the way that hardware enforces the separation between the operating system programs and the user programs. So it's something – if you take 391, you'll see how it works in x86, and you'll need to use it when you go build your operating system. But the design in the LC3 – I don't know, I didn't like it very much. You can read about it in, I think, like, section – chapter 8 or 9 or something like that. I don't remember exactly which chapter that's in. But the idea is basically just to protect the machine, the operating system, from malicious or buggy user programs. So it's a hardware state that separates one from the other. Okay, so – all right, so there's decode, and that overrides everything else. If you don't have the decode state, though, what you'll do is you'll take your J value – that was the 6-bit next state value – spread out this way. And for each of those bits, one of the conditions – so this is kind of like an exploded mux. Again, they're not in order, I think. So here's memory-ready. So this is cond 2 equals 0, cond 1 equals 0, cond 0 equals 1. So if the condition says memory-ready, then if the ready bit is set, the only time this AND gate will output a 1 is the cond is the memory-ready cond, and memory is actually ready, in which case J sub 1 gets ORed with 1. So that's how their micro-sequencer works. Each of the conditions turns on one bit in the next state address. So, of course, when you have a branching state, you have to have two next states that differ only in that bit, meaning the bit that corresponds to the particular condition on which you want to branch. So you have to look at the diagram, look at the bit that's going to change, and then pick two states that differ in that bit, and then the one with the 0 in that differing position has to go into the J value. And the next state that has the 1 bit is the one that'll happen when the condition is true. So it's fairly constrained design. Remember, J is the six bits that you put into the next state ID. So these are all, these 10 bits you specify for every state, and then you store them in the control realm associated with each state. They're just like control signals. So remember that to get these bits, you simply apply the current state ID to the control realm and out come all of the control signals, 39 for the full design, plus these 10 bits. So 49 bits in all for LC3 full design. Yeah, that's right. Yeah, so the implementation, I think I have a picture of it, or did I just, hold on. Where did I put it? Sorry, not in these slides. So basically this implementation is just a 39 plus 10, so 49 bit addressable read-only memory. And the number of addresses, it's a six bit state ID, so it's 2 to the 6 addresses. So 64 by 49 bit memory. And that is the control realm. And then the implementation is take the current state, which is a six bit register, apply it, and then use logic like this to find the next state, and then latch that in to the register every cycle, basically. There's no need to have a pause, as we did in the design I put into my slides, or into the notes. Yeah, they do pauses by self loops in the Pat Patel design. Yeah. Yeah, so the 25 was after we took out interrupts and privilege. So with interrupts and privilege, there are 39. Yeah. So if you look in Appendix C, if you look at that list, that'll be 39 bits. If you look at the list I gave you in the notes, that's 25 bits. And that's just a subset of those, which don't pertain to interrupt and privilege implementation part of the data. Yeah, and the 25 we used in class were the same as the 25 in the notes, and yeah. And the same as the 25 you did in discussion section, I think, last week. Same set. Or same subset, I should say. Okay. Should we move on? More questions on this? Yeah, I don't know if they draw it in the data path, except in the more detailed. So try to look at the most detailed one. The PSR? Yeah, it shows up in the simulator, too, prints the value. Yeah. This is the logic. So the J bits are simply ORed together with one bit for each of the possible conditions, but only one of those conditions can be true. Because this is like, these are midterms on the confits, and then ANDed with the conditions themselves. J5 never changes. So your next states always have to have J5 in common. Yeah, these are next states. So your next state depends on J, depends on COND, and depends on IRD. The 10 bits are used for micro sequencing. Yes. So these are just the, so I know people in the back can't see these, sorry. These are the diagrams that you'll get, allegedly, hopefully, there, all with a pretty small font and hard copy, too. These are the state numbers that Pat and Patola signed. So, for example, in this state, this is 24 and 26, so you would put 24 into the J value, and then, because this is conditioned for memory, when memory was not ready, you'd stay in 24, and when memory is ready, you'd go to 26. And actually, there's some examples of that worked out in these slides. So I went and worked out LDI. So let me go, actually, that one was memory, too, but we'll go down to LDI. So here, yeah, so LDI, that was actually maybe just the one I showed you. Yeah, so this is 24 and 26. So the J value is 24, the condition is 1, which means memory, and the IRD, of course, is 0. So what this does, thinking back to that logic, is the bit here will change when memory is ready, and you'll go instead to this state. Otherwise, you'll stay in this state, which is the same. Does that make sense? Yeah, no? No, no, no, no, so current state has to be a register, right? So the current finite state machine state now in this design is a 6-bit register. And so every cycle, you calculate a new next state, and you store that into the register. That register value, those 6 bits, are then applied to the control ROM, which is 2 to the 6 addresses. So 6 address bits go in there. Outcome, somehow I think it's 51, but by this math here, it's 49 bits, which are 10 bits of micro sequencing, the J, COND, and IRD, and then 39 bits of control signal. Yeah, yeah, so there's a 6-bit register that holds the current finite state machine state ID. Yeah, it switches into privileged mode. You can see it in the full state diagram if you want. No, this has nothing to do with the bus. This is all micro sequencer inside the control unit. Yeah, in that box marked control. Yeah, yeah, this is the implementation of the finite state machine. Okay, I think we probably should move on. So let's see, next on here was control signals, so let me maybe just switch over. So we won't ask you to do the interrupt and privileged control signals, so don't worry about that. Yeah. So maybe I'll go back to the examples we did. I know you did some like this too, so let me just kind of remind you what the rules are as we go through them. All right, so this was the fetch and decode example. So I just mostly want to remind you of the rules rather than derive them all again. I mean, you can look at the slides easily to see the answers. So remember what we're doing is we've got five different groups, right? So one group is the register loads. So what we do here is we just look at the RTL and there's some registers being written. In order to be written, the load signal has to be high, right? And you don't want registers written unless the RTL says they're supposed to change. So if the name doesn't appear here, it should be zero. So the easy way is you say, well, okay, there's MAR. So I go to LDMAR, I put a one. There's PC. It's also written. So I go to load PC, I put a one. Those are my ones. Everything else is zero. So that's your first group. Second group, you really have to look at the data path. So this is probably the trickiest part. So spending some time here just to kind of understand the different types of instructions and how they actually get implemented in the data path might be worthwhile. So why do you need to understand this? Because if you figure out which way the instructions flow, as I've drawn for you here for the first fetch cycle, then you can tell, well, what do the MUXs have to do? Do they have to do anything? What value has to go on the bus? So if you kind of know, well, when I want PC to get into MAR, how does it get there? Is there some funny wire that runs through the middle of the diagram, goes straight to MAR? If there is, maybe I don't need to do anything. Well, there's not. So you kind of have to look at the data path and know enough about what's possible so you can figure out how to implement the RTL. Once you do that, you'll end up with something like this. So I would suggest scribbling on the data path instead of trying to just put it in your head. So scribble on the data path, say, well, PC is coming across the bus going down to MAR. So that means I've got to have gate PC on. PC is also going around this way through the plus one back in through PC MUX and I can increment PC. So it means PC MUX better be set correctly, not to take whatever, say, this input is from the adder. So then we have the second set of signals, which is our gate signals. Only one of them can be set. Remember, these are a bunch of tristate buffer groups. So if we turn more than one of them on, we're going to get shorts. So we should always have at most one. Only one thing can cross the bus. If you think you've implemented the RTL by making two different values cross the bus, you did it the wrong way. Look for some wire inside that lets you route the other bits a different way. Yeah, sometimes you might be able to do that if you were able to actually put two values on the bus. But of course you can't. It doesn't work physically. So in our case, we said, what was it? PC, right? So PC is one. Everything else is zero. Again, go back to the diagram and say, well, what about the MUXes? The third group is our MUXes. Here's PC MUX. We care about that. The other MUXes, three of them here are for address generation. Those are address one MUX, address two MUX. I'm sorry, that's not a MUX. That's an adder. And MARMUX up here. So these three are address generation MUXes. So we don't care about those here. And the other two are not in the diagram. They're controlling what goes into the destination register and what comes out of SR2. So those two we don't care about either because the register file results and inputs are unused. So we only care about the PC MUX. So we have to go look up in the table what value it has. I don't have the table here, but this is the right value for PC plus one. And then the rest, we don't care. So I just want to remind you for each group. You've got the register loads, which is mostly, well, look at the RTL, find the registers that change. The ones on the left, mark the ones that change as one, mark the others as zero. The gating, for which you have to figure out what's going across the bus. The MUXes, for which you need to figure out, well, which MUXes actually carry some of the bits you want to move back to the register you're changing. And whether the ALU is used, which is mostly just for ALU operations like AND and ADD. Sometimes we need to pass something through onto the bus, but that's kind of rare. But there is that option. So a couple of the finite state machine states will use it. It depends what else you're doing. I think the other path you can take, so if you need to get SR1 onto the bus somehow, well, one route is down through the ALU, use PASA, and then gate it through gate ALU. I think the other route would be to send it over to address one MUX through the adder, put in a zero here. So that gives you SR1 on these wires, which you could then, if you need to store it in PC, you don't need to put it on the bus. But if you want to put it on the bus, you can go through MARMUX. So if you need to write, I guess it depends what you needed to write into PC. Let's say you wanted to take something out of the adder and put it in PC. Well, then you could not go this way. So it depends what other RTL. I don't remember that problem. But that was probably one of the things I wanted you to think about is trying to do a couple of things at the same time. If the only thing you need to do is what you asked, then yeah, either answer would be fine. Yeah, good question. Yeah. Absolutely. Either way would work. As in real life, you have many options, all of which work. And sometimes there are metrics that will differentiate them. But in this case, there are a bunch of bits in a control ROM. So as long as the bits you choose make it work correctly and implement the RTL, it doesn't matter. So sometimes you'll have equivalent options for everything you care about. I mean, you could say, oh, maybe we should simplify the data path. And we could save some transistors by not adding all these different ways to do the same thing. But maybe you need both of those paths for something else anyway. So there's this ALUK control. So that's the next group. So if you did need to use the ALU, there are four different choices. And there are add, and, not, and pass A. And those bits are all given to you. So if you need the ALU for something, you'll have to set the ALUK bits. Yeah, yeah. Yeah, do take at least a few minutes before the final to go back and look at that resource sheet. I didn't print it for you again. But if you go to resources, LC3 handout or something like that, or if you look at the old exams, it's this two pages with this data path, the state transition diagram, all of the bits we're talking about, and some other things too. So make sure you know what's on there so when you're preparing your crib sheet, you know what not to bother to put. Anything else on this one? Okay, so that's the fourth group is ALU that Mohamed was just asking about. So, oh, and I put the fifth group here too, which is memory. So in this case, Fetch is not using memory. Memory is down here. We're just putting things in the MAR. We're not actually using the memory. So for memory, we turn it off, which means the read-write control for memory doesn't matter either. And ALU doesn't matter. All right. Should we move on and try to do one more quickly? All right, so the next one, I think, actually, 2PASS process had slightly more. So let me do 2PASS process for the assembler. So let me just find the assembly summary. All right, so remember what the assembler is doing is going through your code one time, line by line, top to bottom, and generating what we call a symbol table. So for every label that you make up in your assembly program, the assembler says, well, let me start. Let's see, you told me ORJ 3000. First thing I see is at 3000. That's a one memory location instruction. The next one's at 3001. The next one's at 3002. It just counts, right? So it goes down, blah, blah, blah, blah, finds a label, foo. Okay, foo is at whatever that current address is. And it puts that in the symbol table. So it makes a symbol table in the first pass. That's all it does. It also checks as much as it can for you. So if it sees that you've tried to do the multiply instruction, it'll say, ah, there's no multiply instruction in LC3. That's bad. It'll tell you as soon as it can when it sees something wrong. If you see R42, hey, I want to put an R42, R9, whatever, right, something that doesn't exist, it'll tell you that doesn't exist. If you try to do a load from, well, let's say an add. Let's say you try to add 300. You can't add 300 in LC3. It'll tell you. You can't do this, right? So any bad operands, wrong kind of operands, wrong mnemonics, things like that, it'll tell you in the first pass. The other thing it can tell you is if you try to define the same label in two different places. And it's already in the symbol table, so the second time it sees it, it says, hey, that's already there. It can't add it. So it'll tell you, okay, too many. Those are the kinds of mistakes it'll tell you in the first pass. Then it says, okay, I got the symbol table. Let me go through the code again. Count from the beginning again. And now when I see something like branch NZ to done, well, then I can say, well, where is done? I'll go look in the symbol table. And if I find it in the symbol table, then I can get the address for the label, can subtract it from my address with the right arithmetic for PC plus one, et cetera, and generate the offset. Now, if that offset is then bigger than the nine bit value I can use for a branch, well, it just gives up and gives you an error. If you say, hey, branch 5,000 locations away. Sorry, that's not an LC3 instruction. So you can get a couple kinds of mistakes. One is, well, it didn't find the label in the table. The symbol table doesn't have that label. So where should it go? It's not going to guess. It'll just tell you, okay, you didn't define a label. Or the target address is too far away. So those are the mistakes you can get in the second pass. How do you undefine? No, you can't, because the assembler just scans from top to bottom. And so the label might be defined later. And it can't know. So if it goes and looks in the table for the label in the first pass, and it doesn't find it, well, is that because the label's below it? Or is that because the label doesn't exist? You can't know until later. So it doesn't try to make a guess. It doesn't try to wait until it finishes the file. It just says, well, we'll figure it out in the second pass. So that's why the undefined label only shows up in the second pass. Yeah. I'm sorry, if it does it, then? It looks for the definition of the label to assign the address. Yeah, yeah. I mean, until it finds the definition, the place on the left side is where you define the label. Yeah, the use of the labels might happen many times. Yeah, but the left side of it. So the reason it's in order is because as it finds them in order, it puts them in the symbol table in order. And then, yeah, I think it pretty sure it prints them out in address order in the LC3 symbol table. Yeah. I mean, sometimes some tools will do things like alphabetize your labels, right? Because maybe that's easier for some people to read or something. Okay. Any other closing questions? Okay. So hopefully see you next Wednesday. Thanks. Or next Tuesday, even, for office hours. Don't forget to go get some cookies and hot chocolate. Thanks. Bye. Bye. Bye. Bye. Bye. Bye.\"},\n",
       " {'ECE120-2016-10-03-LEC-17-slides-broken-video.mp4': \" pushed back, so 2 to 4 instead of 1 to 3. I think you got your midterms back, so if you want to chat with me, feel free to come by. We're going to start sequential logic today, talking about how we store a bit. So we'll look at a gated D-latch, and then we'll look at flip-flops, going into talking about digital time and the clock abstraction in all of the sequential systems that we'll look at, including the computer. I'll tell you more about that when we get there. We'll spend a little time talking about timing issues. In particular, take a look at static hazards and how we can fix them in two-level logic. That's all beyond the scope of the class, so that whole section is just so you understand a little more about timing. In our class, we're going to just sweep timing under the rug, and you won't have to worry about it too much. But it's good to know for later. In 385, you'll have to learn a little bit about it. And if you go into hardware design, it's a little bit more complicated. And if you go into hardware design, you'll have to understand it a little more deeply. But a lot of what people do these days is one common clock and let the circuits people worry about clock skew. So we'll see that and write it off and then move on to the easy stuff with our class. And then we'll talk about registers. So these four topics are supposed to carry us all the way through the end of the day on Wednesday. So we may or may not start serialization on Wednesday and move into part three of the class. This will be it for the second midterm. So basically, this stuff will define the second midterm, which I think is still two weeks out. That's right. Two weeks from tomorrow, maybe. Sounds about right. So that's the plan. So so far, we've talked just about what we call combinational logic. So the idea is that we have the following type of problem. So I give you some bits, A, B, whatever. And we want to combine them using Boolean expressions to produce some other bits. And so we have some input bits, we have some output bits. And we've learned, well, how do you make circuits that do that? We've learned a bunch of ways. We can go down to KMAPs, build them out of NAND, NOR gates, AND, OR, NOT. We can build them out of components like adders, comparators. But where do those bits actually come from? So that we haven't talked about it all yet. So where are these bits coming from? They've just been magically appearing as inputs to our circuits. So now we're going to say, well, how can we actually store a bit? When you have stored bits, instead of combinational logic, you have something called sequential logic, which is actually much, much more complicated to test and debug. Sequential logic stores bits as state. So there are going to be bits now somewhere in our system. We'll show you today how you store them using transistors again, of course. But sequential logic stores bits as state, and its behavior actually depends on those bits. So what a sequential circuit does depends on what the state of the bits is. That's what makes it so hard. Because you can imagine, today's modern processors might have hundreds of thousands of flip-flops, so the state of that chip is 2 to the 100,000, roughly. That's a big number. So you're never going to run through all those states. That's bigger than the number of electrons in the universe, et cetera. You're never going to test it fully. Even, actually, another good example that I steal from Janak Patel, if you think about a 64-bit adder, you think, well, surely they test the adder before they give it to me in the processor. Well, if you have two 64-bit values, that's 2 to the 128 different patterns. So they don't test all patterns for your adder. They can't. So they have to think of better ways to test things. For an adder, it's actually not that hard to come up with a good set of what we call test vectors. But the sequential circuits are actually pretty difficult to test. So we'll start thinking about these. But just like a C program can depend on the state of its variables, the sequential circuit's behavior will depend on the state, which is the values of the stored bits. So what's a one-input NAND gate? Wow, you know this stuff. OK, there's a circuit. What's it do? Stores a bit. Yeah, OK. But it doesn't have any input. I mean, can you prove that it stores a bit? What would you do? Go ahead. Test it. Yeah, unfortunately, there's just some squiggles on a PowerPoint slide. So how are we going to test it? When in doubt, go to truth table. Good. All right, so here's a truth table. It has no inputs, right? There's no inputs to the circuit. So to fill in our truth table, we'll just make a guess. We'll just say, OK, how about if Q equals 0? So pick a value. So Q equals 0. Put it in the table. So what does that mean about P if Q is 0? P is 1, right? Because it goes through an inverter, comes out at the 1. Good. And if P is 1, what does that imply about Q? Q is 0. It's important that you go through all the way and check that, because there are plenty of circuits where some states may not be stable. This is called a stable state. But some states might not be stable, and some circuits might have no stable states. So for example, if I were to put three inverters in a loop, it would have no stable states. That's a design called a ring oscillator. It's used to produce oscillating signals on chips. People actually use it, but it's an analog system, basically. It's beyond the scope of what we'll look at in our class. But if I draw that for you and I say, well, what are the stable states? You should say, well, there are no stable states. It's an oscillator. It just oscillates. So here's the stable state, 0 and 1. But we picked Q equals 0, right? So what happens if Q equals 1? Yeah, P equals 0. So we'll fill that in. And then, of course, we should check again. What does P imply for Q? Q equals 1 again. So that's a second stable state. So this two-inverter loop has two stable states. So we call it a bistable element, because there are two stable states. And bi, you probably remember that prefix, means two. So all of the bits on your chip are typically stored using this kind of dual inverter loop. So if you have 100,000 bits on your chip, there are at least 100,000 of these dual inverter loops sitting somewhere on the chip storing those bits. Well, OK, so that's cool. But how do we set it? I want to put a 0. What do I do? India? Is that an input? OK, there's an input, s bar. So what happens when s bar is 1? Really? So remember, that's an AND gate followed by a NOT. So if you put a 1 into an AND, what does it do? It depends what the other one is, right? 1 and something is something. So in other words, if s bar equals 1, it's just like we didn't add anything, right? Has the same behavior as before. So we can draw a truth table and say, well, if s bar equals 1, we've got the same truth table as we did before, two different rows by stable states. So again, if this s bar equals 1, 1 ANDed with something is just this something. And so this happens to be an AND instead of an AND, but the property of this part of the gate is the same, right? So now we've just got our dual inverter loop. The green part is our old truth table from the previous slide. And when s bar equals 1, s bar does nothing. What about s bar equals 0? Yeah, so that will force q equal to 1, right? Because 0 going into an AND gives me 0, NOT gives me a 1. And p equals 0 then, right? So in other words, s sets the bit q to 1. So the name s stands for set. So you want to set your bit to 1, then you put s bar to 0. Why is it called s bar? So we call it s bar because the action, meaning set the bit q, happens when s bar is 0. So it's called an active low input. So you've probably already seen this on some of the components in the lab. Anytime the input's activity, whether it's setting the bit, resetting the bit, doing something else, happens when you set the input to 0, we say it's an active low input. And usually we label them with bars or primes in order to tell the human, if you want to do this thing that the input's supposed to do for you, put a 0 in. You don't want that to happen, put a 1. You can also, of course, have active high inputs. So I think in the lecture notes on the wiki, you'll see the opposite design using NOR gates. So this one uses NAND gates. If you use NOR gates, you'll have active high inputs. So you can do it both ways. We'll look at the active low inputs. All right, so we can set q equal to 1. What if we want q equal to 0? Just turn it on and off. Eventually it'll be a 0, maybe. What should we do? Yeah, put another input. Maybe we'll call it a different name. Maybe call it R-bar for reset. What happens when R-bar is 1? Yeah, same thing, right? It's an AND gate. If you put a 1 into it, whatever was there before is still there. So 1 has no effect. So if you put R-bar equals 1 in this truth table, the rest of your truth table looks just like it did on the last slide, including all the S-bars. So we're just making our truth table bigger, but we still have exactly the same behavior as we did before. And I didn't highlight it, but this part down here, the lower right four boxes, that's just the original dual inverter loop, when both R-bar and S-bar are equal to 1. So what if R-bar is 0 and S-bar is 1? So S-bar is 1, so we can ignore that input. R-bar is 0. What does that imply? P is 1, right? And then Q is 0, right? Because we put a 1 here, S-bar is 1. 1 and 1 is 1 inverted. Q is 0. OK, so S, I'm sorry, the R-bar input resets the bit. That's where the name comes from. It's the reset input. Yeah, go ahead. AUDIENCE 2 If you're pushing an R-bar, does that mean you're using the same bit? Or is it just a function? Is it just a function? Is it just a function? No, it means when you put a 0, it resets. When you put a 0, it sets. It's active low inputs. AUDIENCE 2 But if you put an R-bar, actually, so the reason they're named this way is actually because of the sense of the input. So there's no inverter. I mean, it's the circuit you see here. And when it's a 0, it performs the activity, either set or reset the stored bit, which is Q. Considered to be Q. Yeah, good question. Wait one slide. S and R at the same time. Daniel? Yeah, so if you were to use NOR gates, then a 0 would have no effect on the OR. And so the low input would have no effect. And a 1 input would cause something to happen. It would cause the inversion and force the output of Q to be 0 in this case. So if you used a NOR here, then this would be the reset input. And this would be the set input to go the other way. And I think there's a picture of that in the notes connected from the Wiki. Almost, yeah. So the question is, is this why we've assumed in the past that inverted inputs are free? And the answer is yes, that since we're always storing bits in dual inverter loops, and eventually Q and P will always be complements of each other, then if you want the complement of Q, we'll just pull it off of this one. It will be in a second. Right now, it's because they're actually not always complements, as you'll see on the next slide. That's why I kept it as P for now. Good question. OK, ready to go to the next slide, answer Mohammad's question? All right, so actually one more slide. I'm sorry, two slides. So this circuit has a name. It's an R bar S bar latch. SR latch is with the NOR gates. This is R bar S bar latch. So we'll store a 1 bit by lowering S to 0, store a 0 bit by lowering R bar to 0. And so here's Mohammad's question. So what if we set both S bar and R bar to 0 at the same time? So what happens? So S bar is 0, R bar is 0. What's Q? 1, right? Because S bar is 0 forces Q to 1. What's P? 1, 1, 1. So that's why I left it as P, because they're not actually forced to be opposites in the R bar S bar latch. So you can do that. It's not going to hurt anything as is. The problem is now, depending which of those two inputs, S bar or R bar, you let go up first, you'll get one or the other bits. Unfortunately, if you let them go up back to high voltage close enough in time, your loop may settle into what we call a metastable state, where it's not actually any more digital voltage. So it's hovering somewhere around the VDD over 2 mark on both of the outputs. And so it's meaningless digitally. It's still an analog circuit. Electrons will move around. But what behavior it has is no longer something you can easily analyze. So don't lower both at once. You've probably heard the joke, right? The patient goes to the doctor. Doctor, my head hurts when I push on it. Don't push on it. So seriously, I mean, when you use S bar, R bar latches, then you just don't do this. You control it in a way that you simply don't do this. So on the other hand, we can also add some more NAND gates to keep ourselves from doing it. So here's a couple of NAND gates and a D input. So what effect does this have? So if I put, let's see, let's check the truth table. So if I put a D equals 0, then what is R bar? So 0, 1 here, 0 here, right? OK, so D equals 0 means R bar equals 0. What about S bar? 1, so 0, 1. So if I put R bar 0 and S bar 1, what are Q and P? So I think I had 0 here, you said, right? So 0 and R bar, so that resets Q to 0, and then P should be 1. Oh, I did it one at a time. Sorry. OK. So let's make sure we understand this. So R bar is 0, S bar is 1. So when R bar is 0, that forces P to 1, and P is 1. So that forces Q to 0, because S bar is also 1. Make sense? The same thing with Q. So Q is 1. Make sense? The same truth table as before. OK. Whoops, I went too far. OK, so when D is 1, again, two inverters here. So R bar is 1, S bar is what? 0. So what is Q? 1, because it's being forced to be set. And then P is what? 0. Good. All right, so now we can avoid the state. We wanted to not have the 0, 0 state on R bar, S bar. Yeah, Eric? Well, you can see D gets copied to Q, right? D copied to Q. D copied to Q. Yeah. Yeah. Oh, so where did D come from? Well, but this lets us store D, right? D gets stored in our dual inverter loop. So you're saying we could simplify this? OK, let's try to simplify this. You're right. It does the same thing. Good call. Good call. That's a good call. Hey, we saved ourselves some gates. Yeah, maybe it's not quite doing what we want, huh? Because it's always copying D to Q, right? If we look back at this, it always copies D to Q. This is a complete truth table, right? We didn't leave anything out. If D is 0, Q is 0. Yeah. Yeah, I evilly plan to add inputs there. That's a good question. So in order to prevent that nice wire-like behavior, instead, let's add some inputs. So there's some more inputs. So now it's not a wire anymore. It is a wire sometimes. So when right-enable, this thing down here, WE, right-enable, is equal to 1, it's still a wire. So when right-enable is 1, it copies from D to Q. Copies from D to Q when right-enable is 1. What happens when right-enable is 0? So right-enable 0 here, what's S bar? 1, 0 here, 1. So R bar and S bar are both 1. So in that case, so here I've used, hopefully you remember, but I'll remind you, here, I don't care what D is when right-enable is 0. So these are actually, each of these lines is like two lines in the truth table. So it doesn't matter what D is. When right-enable is 0, R bar and S bar are both 1. And I can either store a 0 or I can store a 1. Whatever the last value of D is, when right-enable goes down to 0, it keeps that value. Yes, Rob? AUDIENCE 1. So I can store a bit as long as I want? Yeah, so when you lower right-enable, then this holds a bit as long as you keep right-enable low. Yes. So this will store a bit as long as you want, until you set right-enable high, at which point it copies again. Yes. Yes, and as you'll see, we're going to use a clock signal to drive this down. Yes. Yes. Yeah, yeah. So the point that matters in time, and again, we're not going to do much with timing in our class, but the point that matters is what's the value of D when you switch right-enable from 1 to 0. That's the value that will continue to be stored. Yes, the question is, can you store only one bit? Yeah, you can only have 0, 1, or 1, 0. Yeah. Yeah, yeah, this thing, if you're not careful, can be metastable in most modern processes. So you do want to keep it away from that. Yeah, so most of the time, in fact, these will be initialized to keep them from being initialized into metastable states. When I mentioned flipping the power on and off, in most modern processes, you won't necessarily land in 0, 1. You might land in a metastable state. So typically, the flip-flops will be forcibly initialized to 0, 1 when you turn the power on. OK, so there's a gated D-latch. So remember, if I give you the picture again, yeah, there it is. So here's the gated D-latch inside. And then what that looks like, it's actually a little simpler in practice. This is how they used to be built. But you can do it with fewer transistors if you're willing to design at the transistor level. So this design is maybe actually roughly 2x as big as the real one. But you can think of it this way. It's how it works. And symbolically, we draw it this way. So it's just a box with a D input for the D, a right-naval input, and then Q and Q-bar. So now we're labeling them as Q and Q-bar because they're always opposites. So this is, in fact, where the, I think I mentioned it on a later slide, since Sasha already asked about it. This is why when we talked about evaluating the cost of combinational logic for delay in area, we said, well, let's just not count inverters on the literals. Because if your bits are coming from latches or from the flip-flops that we'll design in a minute, then if you want the complemented literal, you just take a different wire. You don't need an inverter physically. You just take the other wire coming from the other part of the two-inverter loop. So that's why we said they were free. OK, so any more questions on latches before we? Yeah. How do you? Yeah, so I mean, the same way you're doing in the lab now, on paper, we just draw the wire to the correct output of the latch or the flip-flop. So you draw it either to Q or to Q-bar. In the tool, you would do the same thing, and that would become a physical wire in your circuit. It would be a piece of copper sitting on a chip or some other metal maybe in the future. So these are active logic. So the question is, how long will these store bits? As long as you keep the power on, they'll store the same bit. Cosmic ray strikes can flip the bit because they can move electrons around. But for the most part, active logic is pretty robust. Because if you think back to what's going on inside these gates, we're actually connecting the high voltage in ground. So there's a constant influx. If there's any variation in the output voltage, this is connected. If this is storing a 1, for example, this is connected directly to high voltage through a transistor that's turned on. And the transistor is turned on because this one is at low. So to flip them, you actually have to do a little bit of work. And that's one reason that the real design provides electrical isolation also and uses pure transistors. Because otherwise, you have to actually, this design is good enough. But the feedback here, when we look at real memory cells, then there's some analog issues for overriding the paths inside through the transistors and avoiding creating shorts from high voltage to ground when you're switching bits. But in here, these are actively connected through the transistors. When it's storing a 1, it's actively connected to high voltage. When it's storing a 0, it's actively connected to ground. So it's rather difficult to make them flip accidentally. Why is not 0 D? And why is that so? So the question is, why does D not matter when right-naval is 0? So look at right-naval. If right-naval is 0, you get a 0 going into a NAND gate. So 0 and whatever is 0. NAND is 1. So right-naval, R-bar is 1 if right-naval is 0. Similarly, S-bar is 1 whenever right-naval is 0. I think we had that on the, oops. Sorry about that. Let me skip out of this. Oops. Here's our full truth table for this one. So when right-naval is 0, R-bar and S-bar are both 1. And in that case, you can store a bit using the bistable nature of the dual inverter loop. So in that case, D doesn't matter. It doesn't have any impact, because right-naval is 0 forces both R-bar and S-bar to 1 all by itself. So while right-naval is 1, you put whatever value you want to store on D. And that gets copied to Q. It acts like a wire. So you copy from D to Q while right-naval is 1. And then before you change D, you turn right-naval from 1 down to 0. And now it stores whatever bit you put there. Yes. Yeah. And once right-naval is 0, Q and P will not change again until you change right-naval back to 1. Any other questions on the latch before we move on? Yeah. So permanent storage is probably outside of the scope of what I want to talk about now. I can talk about it after class if you want, during office hours. Yeah. Yeah, they're usually magnetic or quantum well-based or things like that. Yeah. Or glass, anisotropic glass for CDs and DVDs. All right, so a lot of high-speed designs will actually use latches like this directly. So what do they do? They'll have latches that will store some of your bits. And then you'll use those latches as inputs to your combinational logic. From your combinational logic, you'll produce outputs. Those will get stored in some other latches and so forth. And eventually, those will come back and make a loop. So between sets of latches, you'll have combinational logic. And as you'll see, we'll flip the sense of the right-naval on the two latches. So this is where I was going to explain what I've already mentioned, which is this is why complemented literals are free. You can see into the combinational logic, you have both the Q and the Q bar from all of your latches. So you don't need inverters to get the Q bars. You just connect to the right place. All right, so clock signal, then, is idealized as a square wave. So we're going to use that square wave to drive the right-naval of our latches. So what is a square wave? So it's basically, if you have a 4 gigahertz clock, that means your period is a quarter of a nanosecond. So you've got 1 eighth of a nanosecond at zero voltage, 1 eighth of a nanosecond at VDD, and then that repeats. Let me show you what that looks like. It's something like this. It's a little faster at 4 gigahertz, but roughly like that. All right, so you have this kind of signal. And this is what we're feeding into our right-naval. So here, we alternate that clock signal to have the low and high phases of the clock drive alternating sets of latches. So for example, we might put the, when the clock is low, this set of latches will copy values from D to Q. And when the clock is high, so this copies from D to Q when clock is zero. And this set of latches over here will copy from D to Q when clock is 1. So in the first half of the clock cycle, whatever logic came before this is actually outputting its values and getting copied into this set of latches. But this set of latches, while the clock is low, is ignoring this combinational logic. Then when the clock changes from low to high, whatever values were here are copied into these latches. In the meantime, these latches are now ignoring their inputs while the clock is high. So they basically just shift back and forth with the clock. So in the low cycle, half of your logic is working in the high part of the clock. The other half is working. So the clock frequency is then limited by this logic delay. So before when we said, well, how many gate delays is something? Well, if it's five gate delays, then you can have a faster clock cycle than if it's 10 or 20 or 100 gate delays. So if you want to have a very fast clock, like a few gigahertz clock, you have to be careful about how many gate delays you have in your combinational logic. So that's where your clock speed limit comes from, is this notion of delay in your logic and being able to take the latch values here, calculate whatever Boolean expressions you want, and latch them into these latches here. These days, a lot of the chips will start to have different what we call clock domains, which means just different clock speeds. Historically, though, and still for almost all embedded systems and even a lot of processors, there's just one clock domain for the whole chip. Modula may be some I-O to the outside world. A lot of systems are just one clock domain, and for our class, certainly, you're just assuming one common clock. Good question. So the question is, how do you pick your clock speed, I think? So that's kind of a complicated answer. If you're doing something like an FPGA design, the tool will tell you what it thinks can work. But really, until you test it, you're not sure if it works. Often, it will sort of overestimate, and then you have to make it run more slowly. In practice, also, so you probably know that if you go out and buy a processor, you can get the 4.2 gigahertz, you can get the 4 gigahertz, you can get the 3.8 gigahertz, et cetera. Those are actually the same chip. So what companies like Intel do is they build the same chip, and then there's process variation. So one chip might be OK at 4.2 gigahertz. Another chip, if you run it over 3.5, it'll just break at some point, some point soon after 3.5. And so they do what's called speed binning. And they take all their chips, and they go see how fast they can run each one of them. And then if it's faster, they charge you more money. Oh. Oh. Oh. And that's why I have it. Has anyone overclocked your processor? OK. Wow. OK. So that's why it works, right? Because the bins, they have like four, six, or eight bins maybe. But of course, the answer is continuous, right? So given any bin, probably you can afford to go a little bit faster. You probably can't go to the next bin speed without running into problems. But you can go a little bit faster and overclock your processor and make it a little bit better. Yeah. It can be. Yeah. Yeah, at some point, there is basically an oscillator on the chip or several oscillators on the chip that are generating, or from off chip that are generating clock signals. And then there's also you have to distribute the clock. We won't spend much time at all here. But the reason I'm willing to kind of talk about it a little bit is because you should be aware that distributing the clock is a hard problem, right? And we make the circuits people deal with it so that we can have an easy abstraction, not only in our class, but also people who are designing chips. Is that a modern thought? I don't think so anymore, but I'm not sure. I'm not sure. I'd have to look at specific design. Yeah. Yeah. Yeah, I can't remember. But it should be. Yeah. Yeah, it should be. Yeah, so this, right. So once these values have been set, you have basically half of a clock cycle from when this value becomes visible until this one is going to copy, right, because the clock changed. So you have to split your logic up so that it finishes within the part of the clock cycle that's allocated to you. It's actually a much more complicated game than that, because really, through two sets of latches, that has to complete in one clock cycle. So you can have it be 2 thirds and 1 third, for example. So people do play games like that, but it's kind of beyond the scope of our class. You think of it as you need to finish. This logic has to finish in time for the next half of the clock cycle, because as soon as the clock changes, this latch will start copying from the output. And so if you make this delay too long, the answer won't be there. So if it takes 10 gate delays and your clock is such that it changes after eight gate delays, for some of the input-to-output paths, you simply won't have the right answer. Yeah. So if it's fast enough, extra delay doesn't matter. But the problem is when it's too slow. And so that's why, when you overclock, at some point, the clock is too fast for the logic. Yeah, I mean, well, or you'll get mistakes in what's going on in your processor, which sometimes you might be able to stand a few of those, but usually things will crash. So yeah, that's a good question, although it's getting into some things you'll start to see in 110, I think. And you'll definitely see in 210 and later circuits classes. The higher the voltage, the faster the electrons are going to move. And it's electric field. And so you need a certain number of electrons to fill the wire to bring the other voltage up. And so the faster they move, the sooner that happens. The higher your voltages are, the sooner your outputs will change. So if you raise the voltage, it'll go faster. But there's limits to that, too. Because then the next one, if it's at a higher voltage, it takes more electrons to bring it back down. So sometimes it works. And then if you go too far, it doesn't work anymore. It's a fairly complicated set of equations. It's way beyond our class stuff. So talk to me after class. Yes, at some point, you will use flip-flops to implement a finite state machine in your lab to control a coin machine. And you're building towards that already in the labs. Yeah, usually they'll ramp it up until it fails. And then they'll sell it at whatever the highest one at which it worked was. So the latch is what I've shown you in a flip-flop. I haven't shown you yet. So let's go do that. OK, so yeah, so this is just some comments on reality. So the clock is not really a square wave, because square waves don't exist. Things never happen instantaneously. So the sharp edges just don't happen. Getting it to all the latches at the same time, also, same time is not even meaningful. So we'll use a simpler abstraction than dealing with latches and combinational logic between them. But the problem of clock skew, getting the timing of all the clock edges to the latches or flip-flops at the same time, it's a hard problem. We're going to leave it to the circuit designers. So what we will use is what's called a flip-flop, which is this design here. So you can see I've built it out of two latches. So we're not going to allow any logic in the middle here. So we're only going to have logic between flip-flops. So we'll have pairs of levels of latches where each pair, each other pair, has no logic in between. So it's just back-to-back latches. And we'll have the clock signal inverted here so that, just like I showed you in the previous diagram, this latch copies from D to Q when the clock is 0. This one copies from D to Q when the clock is 1. So this is a flip-flop. This is, in particular, what we call a master-slave implementation of a positive edge-triggered D flip-flop. So where's the name come from? The master-slave part is because we have two gated D latches. So one is the master, one is the slave. The positive, oh, and also I wanted you to notice this. So on the flip-flop, the difference is instead of right navel, we put this little triangle, which means clock. So you put the clock input there. So where does the name come from? Flip-flop stores a bit and changes once each clock cycle. So every clock cycle, the flip-flop will take one new value, and that's it. It doesn't bounce around. It just changes once each clock cycle. A D flip-flop accepts the bit to store using a data input. There are other types of flip-flops. We're only going to use D flip-flops in our class. So you tell it, here's the bit I want to store. Once per clock cycle, it'll copy from its D input to its stored bit, and it'll then put the stored bit out for a full clock cycle. The positive edge-triggered means that the flip-flop's value actually changes on the rising edge of the clock. So when the clock goes from 0 to 1, that's the moment that the flip-flop copies from D to Q. So that's the meaning of this flip-flop, and the design is what I showed you. So what does our use of flip-flops and ignoring clocks to imply? It's discrete time. So for the purpose of our class, time is not a continuous number for our system. It's clock cycle 1, clock cycle 2, and so forth. So each clock cycle is one unit of time, and time is an integer. The flip-flops copy their D inputs to their Q outputs on the rising edge of the clock, and then between integer values of time, we just assume nothing changes. So for all the designs we're going to look at, nothing happens between clock cycle to clock cycle. Everything happens on the rising edge of the clock, so time is discrete. It's a lot easier model to deal with. The circuits people still have to deal with timing and clock scheme, but we don't. Yeah, that depends really strongly on what you're trying to build and what technology you're using. So gigahertz clocks have been around in different technologies for 35 or more years. The first craze to use gigahertz clocks, I think, were mid-'80s to late-'80s. The alpha processors that came out in the early-'90s were gigahertz clocks. The x86 designs, when did they start hitting gigahertz rates? Maybe around mid-'90s to late-'90s. And then power started to be the limiting resource in the early 2000s. So even though we could build faster clocks, the clock speed has actually gone down a little bit in the last 10 years or so, mostly because of power issues. People want to use less energy. Yeah, so that's gigahertz speeds on your typical, your phone is probably gigahertz processor, your laptop, desktop are all gigahertz processors. In contrast, if you look at a small embedded system, you might want to use very, very low power, in which case you might have a 250 megahertz clock or something like that. You can get even slower clocks, and they'll use much less power. So it really depends on the context in which you're asking the question. In the lab, they're going to be pretty slow, too. Yeah. Yeah, so the flip-flop is basically a simplification from the latches. So it's the same thing. It's going to store bits for us, and it's only going to change once per cycle. So it's going to give us this discrete time abstraction at this point x. All right, so remember, in the previous diagrams, I said, OK, we're going to have latch, combinational logic latch, combinational logic latch, and so forth. In the flip-flop, every other level of combinational logic I'm going to reduce to 0. So between the 0 right-naval latches and the 1 right-naval latches, I'll just cross out this combinational logic, and all of my combinational logic will be in alternating levels. Make sense? Yeah. OK, so this one was copying on 0s on clock 0. This was on 1. This was on 0. So instead of having every pair of every alternating set of latches potentially of combinational logic, I'm simply putting these things in a box and putting all my logic between this kind and the next kind. So this has been a flip-flop. So now things only change once per cycle. Instead of worrying about, well, which of the latches are changing when clock is high, which are changing when clock is low, and having different types of latches in my system and worrying about that, I simply make all of my logic go between the path on the rising edge of the clock. Everything changes on the rising edge of the clock. And I don't have to think about latches. I'll do this. Yeah. There are gate delays between. I mean, it takes time for the flip-flop to see the value on the input, and it takes time to get it to the output. So we'll look at that when we start to use them. We'll think about that. Ideally, no. You idealize it as clock is a square wave, flip-flops are instantaneous. And they're designed to have some reasonable flexibility. But in terms of analyzing the gate delays, you have to have a few gate delays for your flip-flops to act as well. Yeah, it's relatively fast. It's just a couple gate delays. But it adds. If you're trying to drive your clock to, say, five gate delays and your flip-flops take two of them or four of them, it's not so short. You only get what's left for your combinational logic. Yeah. Depends how fast you're trying to drive your clock. Yes, but with the flip-flop, again, all of the flip-flops we'll use will change their value simultaneously, because we assume common clock and we ignore clock skew, on the rising edge of the clock. So once per cycle, everything will change. So it's discrete time. So it's a little simpler to think. No, these latches change when clock is zero. These latches change when clock is one. Yeah, these change with zero. Yeah, so then you have to know which kind of latch is changing when. So it's more complicated to reason about. Yeah. A comment, though, for not using combinational logic. Not inside the flip-flop. Yeah. Yeah, so that's what I crossed out here. And that's what I highlighted on the flip-flop diagram here. So before, these two latches, we'd say, oh, well, I want to put some logic here. But we're not going to do that. Yeah, so there will be combinational logic here and combinational logic there. And this combinational logic has to settle before the rising clock edge. And whatever we put here has to settle before the next rising clock edge for the next flip-flop. All right. So free time, simplifying. All right. So here's a timing diagram. I wanted to just show you how it works inside and also show you what kind of behavior it ignores. So here, initially, the data input is high. The internal input is high because the clock is low. So d is being copied to x by the first latch. And the output, so the second latch, also just happens to start low. At the rising clock edge, x will get copied to q. And so q will go high at that point. But also at the rising clock edge, the first latch will stop copying d to x. So there's not much of a margin here. Sorry for that. But you can see d goes down here. But because the clock is high, the first latch ignores d. It doesn't copy to x immediately. Not until the clock goes low does d actually get copied to x again. So when the clock falls, d is copied to x. And x goes down as well. But when the clock falls, the second latch, which copies x to q, stops copying. And so when the clock falls, even though x goes low, q stays high for the full cycle. So until the next rising clock edge, q doesn't change at all. When the rising clock edge comes, look at the value of x, which is the value of d because it's being copied. And then that gets copied to q. So x is copied to q when the clock is high. d is copied to x when the clock is low. Now, you'll notice inside this clock cycle, d actually went up and then went back down. But it got ignored completely. Because, well, not completely. It got copied to x for part of the time. But because it went down before the rising clock edge, x was already low. And so here, at the rising clock edge, we look at x and copy it down here. So x is 0. q is also 0. So even though d went high in the middle, that never showed up on the output of the flip-flop. There are flip-flops that do things that are called things like ones-catching. So if the input ever goes high during that clock cycle, the next output will be a 1, even if it's just for a very short pulse. But the flip-flops we'll use are these positive edge-triggered d flip-flops. So this kind of behavior will never show up on the output. And this kind of behavior makes no sense in discrete time. If I think about this as a discrete time system, only at these dotted lines do I look at what's going on. So at these dotted lines, I say, well, what's d? Oh, it's 1. Copy it there. 1. Here it's 0. 0. Here it's 0. 0. That's it. So that's the simplifying assumption. The only time we ever look at the system is we look at the input to the flip-flop at the discrete time. We copy it to the output. It stays at the output for a full clock cycle. And then we look again, copy it again, stay for a full clock cycle, look again. So it makes analysis and developing, designing the systems much easier. And it will actually work so long as the circuit designers get the clock skew to work. It makes things easier. All right. So all of your designs will be what we call clocked synchronous sequential circuits. So these assume the use of flip-flops and then a common synchronous clock signal. That's what makes them synchronous, is they have a common clock. Latches and flip-flops are what we call sequential feedback circuits. So you should understand how they work. The analysis we did of, OK, draw the truth table, put a value in, see what happens, see what it does. So you should be able to analyze them, but we won't expect you to design any. Actually, not too many people design them anymore. Usually people who are building circuits will actually use what are called standard gate libraries. So there will be people responsible for developing latches and flip-flops for a given process, but there will be relatively few people. And then everyone will simply use their designs and say, OK, I want a latch. I want a flip-flop. And then we'll have a lot of people who will actually design the circuits. And say, OK, I want a latch, I want a flip-flop. Oh, it's getting towards the end of the hour. All right, so instead of going to static hazards, let's just stop there. It's a good time to stop. And we'll talk about hazards and registers on Wednesday. Thanks.\"},\n",
       " {'ECE120-2016-09-19-MT1-review-slides.mp4': \" Everything. Okay, I'll put that on the list. But anyone want to be more specific? Eric? C programming? Okay. Yeah. Okay. I'll just put that as IEEE floating point. I'll put to and from and see what... Flowcharts? Flowcharts! Technically, you are not supposed to have to make any flowcharts. I know there was one on the homework, but that's not part of our learning goals for this. Mohammed had one. Where'd he go? But he put his hand down. Okay, yeah. Sure. Sure. Let me add that to C programming. Remember that logical are technically also not part of what you're required to know. So only the bitwise ops, but I'll tell you the difference. Okay. I'll put that also under C. Anything else? Yeah. Sure. Sure. Yeah. Yeah. Yeah. You mean unsigned? Two's complement is a representation. Okay. Oh, I'm sorry. I thought you said versus. Okay. Anything else? Yeah. Okay. Anything else? Yeah. I'll put that with this one and we'll talk more generally about it when we do it. Yeah. Okay. Anything else to put on the list? All right, let's vote. So maybe you can vote as many times as you want, but I'm going to order them numerically from my rough counts, maximum to minimum, and then what we get to, we get to. So how many want to see something about C programming? Okay, I'm going to guesstimate about 60 to 70. 70, okay. IEEE floating point conversion. And it's about 50, I think. Flowcharts? Okay, about 15. Levels of abstraction? About 25 to 30. Two's complement arithmetic and overflow? About 10. And MOSFETs? Okay, about 25 to 30 again. Okay, so let's start with some C programming and then do floating point. All right, so a couple topics on there. Arithmetic versus logical shifts, logical versus bitwise. Before we start, let me just mention the kind of things we want you to be able to do in C. So one is analyze C code. So we'll give you a little program, you take a look at it and understand what it does. I actually didn't bring my computer thinking we were going to do this all on the board. I could pop up and write an example, but probably the best examples at this point would be, you know, they have answers with them in the online tool. So if you didn't do all 14 of them and you want practice on analyzing C code, go there, look at the code, figure out what it does, write your answer in before you pop the answer, because people tend to think they know it when they read the answer. So write down what you really think it does and then push check answer, it'll tell you what the code does. Or answer the question that's there on each of the examples, there are 14 examples. So that's one thing we want you to be able to do. Yeah, that's one. So if you go to my homepage and go down to F16, classes F16, come to the links page for our class, and then the exercise, which is C analysis, the online exercise. So write, you know, math formulas, formula, C. So those are just expressions. And then write conditional. So this is it. And then write loops, for loops. So those are the things that we'd wanted you to be able to do. So let's think of a quick example. So let's say, I think you saw this somewhere already, which I'm worried it's on the homework is due, you turned in that homework. So let's say you want to print, actually, those will get it bitwise too. Let's say you want to print a number as Say you want to print a number as binary in C. There's no percent B for binary. So let's say you want to enter a decimal number And print as binary. For example, So you'd start off, you're always going to start, we usually won't have you write this, but you want to standard IO. And we'll write our main function. What's the first thing we'll do Yeah, declare variables. So let's have We're gonna have to come up and do some more of these. But let's say make an unsigned number instead of a decimal. We'll come back and do some more. Run out of space, though. Okay, so how will I, how will I get the number of the user needs once printed. Yeah, I'll have to scan it. Maybe I should ask them for it first. What do I use to ask them for an F right okay so We've seen more variables later. Fitting. Okay, so just ask them something. What do you want converted and then we'll use scan F. So it should return one. And then we'll use scan F. Fitting. Okay, so just ask them something. What do you want converted and then we'll use scan F. So it should return one. Let's ask for an unsigned number. And what do I, what do I put here. ampersand num right that's where we want to put it. So this scan F. Remember, we'll, we'll wait for the user to type something and they're allowed to type an unsigned number, it'll convert that unsigned number because I said percent you into 32 bit unsigned representation and store that in the variable num. I don't know just did it's going to print in binary. It doesn't really matter. It'll work our code will work with all that usually whenever we do bit rise operators I try to use unsigned because otherwise sometimes it gets a little tricky if you If you do shifts right then you'll get arithmetic shift if you do choose compliment and sometimes you really don't want that cause bugs. Yeah. Yeah. Yeah, to evaluate. So this is a function call. We only showed you print F and scan F, but it has to evaluate the expression. And so when you make a function called part of the expression, it calls that function in order to get the value back. And remember the value that comes back from scan F is the number of things converted for if it fails to convert anything returns minus one. We just write that down. But shouldn't return zero if it doesn't convert anything in the return minus one, which is an error message. Is that legible that big enough. A little bigger. Okay. Okay. Okay, I'll try to write bigger. It just says what I what I said a minute ago, although there are plenty of seats for her. So feel free to come forward. I'll try to write bigger. Alright, so that will do our check for us. And then if that fails, we can just print an error message. I'll just make it something simple. And then just exit program. I don't know, I'll pick three. Okay, so otherwise we have a number. Yeah. Um, maybe. Hey, look at that. Yes, I can. I didn't know I could do that. There's a first time I've used this stuff. I'm not sure if I can do it. Oh, that's it's just the convention a long time ago was zero for success nonzero for for not success. And other than that, there was no convention. My personal convention is three for doing something wrong with a program. So there's no good answer other than don't return zero. That way, whoever started the program knows that the program did not succeed, something like that. Okay, so now we're going to do a little bit of a test run. And so what we'll do, we need to look at the at the top bit first. And then we also want to we also want to go back to the top bit and look at the top bit. And then we're going to do a bit of a test run. Okay, so now we're going to look at the top bit. In order to convert it, we're going to need to use bitwise operators, because we're gonna have to look one bit at a time. And so what we'll do, we need to look at the at the top bit first. And then we also want to We also want to go one step at a time through the 32 bits. I'm just going to assume it's a 32 bit number. I could be a 16 bit number on some platforms, but I'll assume it's 32 So we need to be able to pull out one bit at a time. So first, let me make a loop variable. So I'm just going to make that an int and I'll just call it i, that'll be a loop variable. And we also need a bit that will pull out using a bitwise and will pull out the bit of the number that we want to print. Okay, so we should set that I'll make that an unsigned. I'm going to shift that along step by step. So I found an unsigned. I'll call it mask and I'm going to set it initially equal to the high bit of 32 bit numbers. Okay, so that's the that's the bit 31 if you number them from zero up to 31 that's bit 31 of the unsigned number So now I can do a for loop down here. So how should I make i go from say zero to 31 Okay, so I'll initialize it to zero. And what should my test be So 30 I could do 32 greater than I or I could do 31 greater or equal to I either one's fine and then update I equals I plus one. Good. Okay, so now I will, I will let this this loop execute 32 times And I'll actually have to update mask as well. I'll just do that at the bottom. So in order to tell what kind of thing I have in my number, I need to use a bitwise and I'm going to shift over to another paper and develop the expression. So I have this number and I have a mask. So how do I pull out the corresponding bit of the number What operator Did I use so mask. Remember, just consider the first The first iteration mask is going to be this value. So one bit in there. So if I use what What operator and and right. So if I do a bitwise and between mask and numb. The answer is going to either be zero or it's going to be zero. Or it's going to be equal to mask. There's only one bit on in there. Right. So if I end them together with all the bits 31 out of 32 bits of mask or zero. So the answer 31 out of 32 bits have to be zero. The one bit that said in mask, maybe also a one in number. So the answer will be either be equal to that number up there that big number or it'll be equal to zero. So I can write something Where I say If Zero is not equal to mask and number In that case, then there's a one in that bit position of number. Right. And if that condition is not true, then there's a zero. There's only two possible values for that for that bitwise and it's pulling out one bit. That makes sense. When you do a bitwise and the answer is also in this case are two unsigned. So the answer will be an unsigned with 32 bits in it, but because my and remember this number here if I write it out in binary. There's 28 zeros here. Right. And so if I write out number in binary. I'm sorry. Ah, I have a little preview screen. Okay, so if I write number in binary. Remember bitwise and goes through like this, right. So all of these zeros over here. These all come out as zero. So you've got 31 bits in the mask. And this is the expression value. And this, this one here could be a one. Right. But all the others have to be zero. And so that's how we're looking at just the expression value. And this, this one here could be a one. Right. But all the others have to be zero. And so that's how we're looking at just that one particular bit using the mask. So we have one bit set in the mask. We use a bitwise and the answer is either zero all zero or is that one bit. Okay. Yeah, so it's an unsigned number. It's an unsigned number that happens to have at most one bit set. So it's either zero or not zero. Yes, yeah, yeah, yes, it's an unsigned number still. So it's interpreting it as two to the 31. Okay, but all we care about is zero or not zero, because later we're going to change mask to be a different bit. Alright, so if we find if we find it's not zero, what should we print for that particular bit. A one. So let's print a one. We don't need any format, any format specifiers. We'll just print the number one. And if it's not not zero. In other words, if it is zero, what should we print. Zero. Okay, so that will print one bit of our binary number. So we're going to put that in our loop. And maybe I won't transfer it over. Try to align my papers so you can read it. That legible enough. Okay, so once we're done with that particular bit. Now we're going to need to shift the mask over. So let's print a one. And we're going to print a one. This one. That legible enough. Okay, so once we're done with that particular bit. Now we're going to need to shift the mask over. So what I'll do is mask equals mask. Right shifted by one. Someone asked earlier, why did I use unsigned. So here, for example, if I had used the two's complement number and started with the high bit that would actually be a negative number. And when I right shifted, I would not get bit 30 set, I would get bit 30 and 31 set. Because seeing that it's a the compiler seeing that that was a two's complement number and integer would say, oh, you want an arithmetic right shift when in fact they don't want a logical right shift in this case. For unsigned numbers. Yes. So an unsigned number of the compiler would generate a logical right shift which puts zeros on the left side. If it's an integer, a two's complement number, it will generate an arithmetic right shift and put copy the sign bit on the left side. Because mask is unsigned it inserts zeros on the left. Now that I zoomed. This is legible in the back. I'm sorry. Yeah, thank you. The loop is actually down here. So Yeah, the mask equals was up there. I'm trying to get it all in the slide for you. Okay. Okay. Now we have the whole program. Thanks for that correction. Okay, so now that we've shifted our mask over if we end our loop, then that will change I can come over here for a minute. So we'll go to the next value of I and we will then compare with the next bit by doing another bitwise and after we've shifted mask down and now has bit 30 set So we'll check a bit 30 of the number and print a one or zero corresponding to that bits value, then we'll change mask to be bit 29 I will simply count for us. Once we get 32 of those mask will be down and actually turn to zero. So the other way to finish this loop would be to check when mask gets to zero because you can shift it right off. Shift that one bit right down to the end and out of the number. But once this loop finishes, we'll have printed all 32 of our bits. At that point to be to make it look nice. We might want to print a carriage return. So let's just toss one of those in there. I'm not sure I can fit it all anymore. Let me zoom out a tiny bit. And return zero to say we've succeeded. Okay, so sorry it's not lined up perfectly but Okay, so I think with this example we managed to cover the other topics. Was there anything else on C program. Any people want to talk about or any questions on this code. Why do I, why do I shift mask to the left to the right. So remember that we started mask as the left most bit the high bit. And so by shifting it to the right one step at a time. We're covering every single bit. Starting from bit 31 to 30 to 29. Remember when we write bits out we usually Write them. Sorry, I didn't have any chalk there. Maybe I don't have any chalk period. Okay. When we write bits out, we usually write them as the high bit. Down to Down to bit zero. So when I'm when I'm talking about bit 31 and a 32 bit value. That's the left most bit and then we're shifting to the right down to zero. That's the 32 steps of Yes, absolutely. So the question is, could you instead start with mask equal to one and left shift. The problem is that you probably want the printout the way we did it. Right. So you probably want the high bit first because people will expect to see the number that way. So you could do what you said, but you'd have to store the answer somewhere and then print them out in reverse to make it make sense to the human. Yeah. Yeah, you can do that. But again, that would that would go in the wrong direction. Right. So if you start with a with a low bit. That's the bit you want to print last so you could do it that way without creating a mask. You can also generate the mask on the fly. So you can write Not with the I we have, but you can write one left shifted by 31 minus I. And so if you use this expression, this takes I subtracted from 31. So when I zero that's 31 when I is one it's 30 and then that takes the number one and left shifts it by that much. That's, that's actually the best way to do it. So there are many ways you can solve the problem. Mask was initialized as bit 31 so in hex. It's eight followed by seven zeros. Um, yeah, I mean, do you need if you need to know what on the exam. And, you know, we would, I think we'd give you a hint there. But, but this that's bit 31 right so you can. The easy way to do that is the way that I just wrote it that that way you don't have to remember it. You can write one left shifted by 31 also if you want to initialize You can also write this So, do you need to remember it. No, you can simply write that in the code and the compiler will generate it will solve that without generating structure. Right. Right. Um, yeah. So I think understanding how gates are built is on there right and gates are built out of MOSFET. So to that extent. Yeah, I can't pull it up easily. But does someone have the shirts in there. How gates are how gates are built is not in one six Okay, I can look at it afterwards. It was also low on our topics list. I'm not sure if we're going to get to it. All right. Any other questions on this one. Are you ready to move on. Okay, so we'll check that one off. So I think we're going to I triple E floating point right and someone wanted to start with two and then I'll see how much interest there is in from So, zoom out a little bit. Okay, so remember The high bit in floating point is assigned it Then you have a exponent eight bits. Then you have 23 bits of Ventissa. And except for zero, which is all zero bits. We have possibly either sign all zero except the sign. We have the value is equal to negative one to the sign bit. Times one. This one's implicit Dot mantissa. So this is binary scientific notation times two to the exponent minus 127 You can treat exponent is unsigned. That will give you the right answer. Now there are two corner cases here. One is the one that's not a corner case. So you don't really need to know that except for the fact that there's a zero pattern. So you need to remember that, of course, we have a zero pattern. You can't have an explicit one. Otherwise, you can't write zero. And then the other one is for infinities and nads, right, which you don't need to know. So you can treat the exponent as unsigned. And then you have the value is equal to negative one to the sign bit. So you can treat the exponent as unsigned. And then you have the value is equal to negative one to the sign bit. So you can treat the exponent as unsigned. So in order to find the value just plug into the formula in order to convert to this format, you just write your number in binary scientific notation. So how do you write something in binary scientific notation. This is binary scientific notation. A little more space. Okay, so how do we do that. So say we have a number. Can't do a lot of fractions of powers of two in my head. So let's say we have something like negative 15.625. That one I can do. Okay, so let's say we want to convert this. So the first step is just to break it up into an integer and a fraction. And then we can convert the integer just using unsigned. Remember that the sign is going to go now into the sign bit. And so it's more like sign magnitude than it is like two's complement. Convert the integer using unsigned and then convert the fraction also using unsigned but as a fraction. And then we can put it into binary scientific notation from there. So let's start with the 15. So what's 15 and unsigned. Also, is it odd or even? Odd right so give us a one. So subtract the one divided by two. Is a seven right so odd or even. Seven minus one. Divide by two, we get three also odd three minus one divided by two one also odd. And then we're done right one minus one is zero. So 1111. So there's 15 And what about point 625 How do we do this one again. Multiply by two. So then I multiply by two, I get 1.25. So that's a one right so that'll give me a one and I'll subtract the one off. And multiply by two again. And what do I get 0.5 So that's less than one. So that gives me a zero. So 0.5 minus zero times two is what One gives me a one. One minus one is zero. So we're done. So this one goes this direction. So that's 0.101. Right. So if I put those together. I get 1111.101. So I need to write that in binary scientific notation. So remember how to write scientific notation. You just move the decimal point or in this case, the decimal point. Over after the first number. So we're going to have an exponent of 123. So this is equal to 1.111101 times two, two to the three. And then remember there was a minus sign in front of it, which we'll just put down there. So there's our number. Okay, so now we've converted negative 15 and 0.625 into binary scientific notation. From there, it's relatively simple to just transcribe this sign, this mantissa. Remember the one here is implicit and this exponent into the floating point. So let's go ahead and do that. The tricky part might be converting the number around 128. So what's the sign? 0 or 1? 1, right? Negative. So this is our sign bit. What's the exponent? 130. Right. So here's three. And remember that three is equal to whatever exponent bits are as unsigned minus 127. So what we need to write there is 130. So probably that conversion is a little bit of a pain, honestly, especially if it's small. So let me write it down and then explain. So if it's bigger than 128, remember that's the 128 bit. And so from there, you just need to convert the leftover two, which is down there. So the 128, the two makes 130. So that's our exponent. And then for the mantissa, we simply copy. So remember, this one here is implicit, so we don't write it at all. So the mantissa is these six bits. 111101. And then what? Zeros. So you got six more here, I think. What is that? 186. So 15. So yeah, one more there, I guess. Zero there, and then a lot of zeros down there. Yeah, 17 more. Sorry, I broke it up into two 16 bit chunks, right? But all of the rest are zeros. Yeah. Yeah, so once you've got your two 16 bit chunks, you can go ahead and write your next one. Yeah, so once you've got an in-binary, you mean before or after the binary scientific notation? Okay, so after you've got an in-binary scientific notation, remember from our formula that the actual exponent in binary scientific notation is the exponent bits in the floating point field minus 127. And so basically just invert that formula. Say, well, whatever I'm going to put here minus 127 has to equal my real exponent. So that was what I wrote down at the bottom. I said, okay, the real exponent is three. So whatever bits I write have to be equal to the exponent bits minus 127 have to be equal to three. So just solve that equation, you get exponent bits equals 130. Fill that in. Yeah. Yeah, so IEEE rounds off. You don't really need to understand a lot of the rounding issues. Just understand that it's not exact, right? So it's only 23 bits of precision. There are four rounding modes. The default mode is round to nearest. So whatever the closest answer is, it'll round that last bit off, up or down, depending on which one is closer to the number you're trying to represent. Yeah, so again, by solving this equation, so we saw in the binary scientific notation that the exponent we want is three. And in this form, remember that the exponent bits represented as unsigned minus 127 has to be equal to the real exponent. Yeah, so remember, we wrote it in binary scientific notation. It's right there. Make sense? Okay. Yeah. You need to know that there is a zero pattern, but you don't need to know how to interpret denormalized numbers. So you just need to know there's a zero. Otherwise, it's kind of a weird representation. It can't represent zero. So you should know that. So remember, you'd write it first in scientific notation. So 0.75, the fraction 0.75 is equal to 111. So that's 0.11. But you put that in scientific notation is this. It's not zero in front. Yeah, once it's in scientific notation in normalized form. Yeah. The other direction. Sure, sure, I can do that. You mean write it in decimal? We're not that mean. We're not that mean. If we do that, write it in decimal, it's not zero. It's not zero in front. You mean write it in decimal? We're not that mean. We're not that mean. If we do that, write it as 2 minus 17. But we're not that mean. Yeah. The question was whether we'd ask you to tell us what 2 to the minus 17 is in decimal. No. Because we don't allow calculators on the exam, right? I don't know what 2 to the minus 17 is. Okay. All right. So let me get a feeling. So Sasha, you'd ask that we do one also from the binary into decimal. How many people want to see that at this point? Okay. Okay. Let's just do one then. So. Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? So that to me looks like 11 sixteenths. And I'll cheat. I'm not writing it in decimal. Yeah? So that's 8 sixteenths, 2 sixteenths, and 1 sixteenth. So 11 sixteenths. I don't remember what a sixteenth is. Actually I do. I don't think you should need to. Yeah. Yeah. So I think whichever way you end up doing it just as a fraction is fine. Maybe don't write it as an expression. I mean you might have an integral part and a fractional part. So I mean don't make us solve equations to get it. So you wrote it, yeah. So I think turn it first into, you know, shift the binary point to the right position and then convert that one into integer and fraction. Yeah. I'm sorry, if the exponents were all one? Yeah, the exponents all one, remember, is a special case, but we don't expect you to remember how to use it. It's infinity and not a number. So if the mantis is zero, it's infinity. And if it's non-zero, it's called not a number. But that's more than you need to know for this class. Okay, anyone else for this? All zero bits. Yeah. And well, all zero bits except the sign which could be positive or negative, they're both zero. They're positive and negative zeroes. Anything else? Okay, so with that we finish the folding point. All right, so let me talk a little bit about levels of abstraction. So in Pat and Patel, I mean they don't put the electrons, but down below the devices were electrons. So Okay, so the levels that we'll look at mostly other than the C programming to just give you exposure to the syntax are the hardware levels, the devices, how we build gates, how we then use those gates to build Boolean expressions and then components like adders, which we'll start to look at soon, but are not part of this exam. The micro architecture, which is the way you design a processor out of those. And then the instruction set architecture we'll get to kind of at the end of our class. That's the interface between hardware and software. So that's what tells you what the computer can do with individual instructions. All of the software then has to be compiled when you write C code, it has to be compiled down into computer instructions, or in other languages, there might be another program that actually interprets your language. In that case, that program is written using computer instructions. So the software always has to come down to the level of instructions and then the microprocessor will actually go all the way up to the ISA level in hardware. So the processor in your laptop or in your phone will execute some instruction set architecture and the micro architecture then is just the way of building that. So remember that with a level of abstraction, what you're building, you can build in many different ways. So MOSFETs are one way to build gates. There were other ways to build gates. So historically, there were different transistor technologies that people used to build gates and they built their computers out of those gates. So there are many implementations at every level down. Similarly, the micro architecture, there are many ways to build a particular instruction set architecture. There are different companies that produce x86 processors for your laptops. There are different companies that produce ARM processors for your mobile phones. Those companies don't share their implementation designs. They know the ISA, they support a common ISA, sometimes different ones like ARM or x86, but the companies competing in one space will typically support the same ISA so your software runs on all of their platforms, but they don't share their designs. The designs are the micro architecture, the way of implementing. So the idea with the layer of abstraction is that you provide a certain functionality without telling people how things are built. And so that in the case of the instruction set architecture, what that means is, for encoding in bits of course of instructions, the computer, the micro architecture can execute the intent of those instructions, but you don't tell anyone the details of the implementation. Just like when you build a water faucet, people don't want to know how it works. You want to just be able to get your water out, use a simple interface, you maybe turn it, maybe pull it up, whatever. It's fairly simple. You know how to get the water out without understanding plumbing, without understanding how you make water pressure work. Yeah, absolutely. So there's, I mean, that's how they compete, right? They compete in the metrics we talked about. So area, right? So how big is it? Which means how much does it cost them to actually fabricate the chip? Power and speed. And so speed will determine how fast the processor can run. There's also trade-offs like parallelism for, I mean, this is one we didn't talk about, but how many instructions can they execute at the same time? And so there's that kind of design point, which also affects overall performance. But the raw performance based on gate delays in different parts of their design will also affect their performance. And then power efficiency. So you wouldn't want your typical server processor in your phone because your battery would not last. And so there are different design points there. And they compete in trying to find ways of being better in all of those. Maybe not at the same time. So their designs will have different values in each of those metrics, depending on how they go about building them. So I think understanding the idea of the black box where you've got functionality above and lots of ways to implement and being able to understand that in a way of realizing it. In other words, if we asked you, we might not ask you that question directly. So we could ask you something about whether implementation detail should be exposed or things like that. So let me answer that somewhat obliquely. I mean, in this class, probably not so much. In part of what I said the first day that we're trying to break you gently into the life of an ECE major. So we're shooting for a test average of about 10.5. And we're going to be doing a lot of testing. And we don't want to do this on purpose. We want to make sure that we're trying to break you gently into the life of an ECE major. So we're shooting for test averages like in 80s, whereas my historical average for all the ECE classes was 75. I wasn't really kidding. I mean, I think people didn't do it on purpose, but there have been class averages as low as 30 on exams out of 100. oh my gosh, how am I going to get a 30 on the exam and pass the class? The class is curved. So our class, we're also trying not to curve. The problem with the essay-like questions, I like them a lot. So when you get into later classes, it's a better way to make sure people understand engineering design and trade-offs and things like that. It's much harder to grade. It's also much harder for us to get an 80 average or 85 average. So when you start asking engineering design questions, it's more challenging. So there won't be that many on our exams in this class. But you should expect to see more in later classes, where you really have to integrate the knowledge and be able to answer more open-ended questions. Yeah, so it's a good question. In our class, not so much. But you'll see more in later classes. All right, so was that the people that asked originally about levels of abstraction, you feel like that was enough coverage? Or anything else people want to ask? Yeah, I mean, we also have a, I think the encapsulation idea is probably what they're looking for, whether you have to understand how it works in order to be able to use it. So I think that's the biggest issue, is that you provide that level of isolation, that I can use something, there's a well-defined functionality, without my understanding how it's built. And so that's the value in day-to-day human life, too. A lot of what everyone in the room uses, you probably couldn't build. You might be able to guess at it. You can probably look it up. And as engineers, you can probably even figure out how to do it. But if I just said, here, go play. You don't get to use the internet. Build me a toilet. Are you going to be able to make it work in a way that works nicely? I know I couldn't. But obviously, we know how to use those sorts of things. And so I think it's really the idea that you want to encapsulate something in a way that you really need to know nothing about the implementation. There's a certain functionality that you can expect to use, like a jar or a toilet or a faucet. And there's an interface that we all know how to use, but we don't know how to necessarily develop the implementation. All right, let me spend a little time then on MOSFETs before we finish. So remember, so the main things are two types. So there's P-type. And there's an N-type. The names are for charge carriers, so I'd suggest remembering how things work based on this bubble or no bubble, that the bubble turns on when there's a zero, when a logical zero turns on. And that's because the way the P-type works is there has to be a voltage from these terminals. This voltage is greater or equal to some threshold to turn it on. So if you put zero volts here and then you put high voltage, then that will turn it on. And the only way to turn it on with binary voltage levels is for this one to be zero and then these to be the high voltage. The N-type works with the voltage threshold in the other direction. So the voltage between the gate measured in that direction has to be greater or equal to the threshold to turn on. So you need to put VDD here and then zero volts on one of the terminals. And then the current can flow across the two terminals in that case. And it can pull the other one down to zero volts. In this case, it'll pull it up to VDD. So VDD is a one in binary. Zero volts is ground, is a zero in binary. So that's how they work. And then out of those, we use complementary sets of those, which in the case of the gates we looked at in class was just series and parallel. So we had series. Yeah, I'm sorry. Hold on a second. No, this is someone was pointing this out earlier. We did this after C, right? OK, why am I spending time on this? This is on the next midterm. So you're getting ready too far in advance. Anyway, you will know how to do those one day. Anything else people want to talk about before I stop? Yeah. From decimal to hex through binary. I wouldn't try it without that. It can be minus minus plus. Yeah, yeah, those are the two overflow. If you add plus and minus, it's always OK. It never overflows. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK.\"},\n",
       " {'ECE120-2016-12-05-LEC-39-slides.mp4': \" Okay, I think it's three o'clock. So what we're going to do to start off is just finish up error correction and Hamming codes and then sected codes, and then I'll spend the rest of the time just giving you free advice. So I plan to do this anyway, but I was, before I got clobbered by a virus over the weekend, I was going to actually add another piece of material here, but instead we'll do what all the other lectures do and do a review session on Wednesday. So we'll finish all of this stuff up I think today and then on Wednesday we'll do a review session, which is what all the other lectures are doing anyway. I did have to move my office hours. I'm not sure if it was kindness to the instructor or just feeling bad for the students. So when you get to 391 you'll understand you work really hard to do your OS, and right now there are 240 students in there and one professor, and so I felt like they should have some time explaining what cool stuff they did. So I agreed to spend all day Tuesday from eight o'clock in the morning until eight at night talking to students about their projects. So I won't be able to go to office hours. I was going to shift them, but instead the three of us still teaching lectures are going to have office hours on Tuesday, 13 December. I think they're starting at 10 and running till four and mine are in the middle. Mine will be in Daily Byte. Theirs I think are in 3017. There was an announcement on the wiki so you can look up all the details, but the important thing is don't come to Daily Byte looking for me tomorrow. I mean you can try to slip in in the 391 lab if you want, but I'll be there all day. But I will be there next Tuesday from 12 to 2, and I moved it to try not to overlap the final session because I know that some people might have finals starting at 1.30, so you should have some free time in there regardless of your final schedule hopefully. This is yeah, third midterm. Another third midterm. No, this should say final exam. Sorry. So the final exam. Retry. No. The final exam is as you hopefully know Wednesday, 14 December. For those of you that don't know, I guess some of you who are still new to the university, the university tells you at the very beginning of the semester how to map the start, the first time of your class to the final exam time, and most classes will announce time. So I think we announced this at the first day of class and it's been on the web, but for the most part you can figure out your whole schedule at the start of the semester. Anyway ours is Wednesday, 14 December. If that's a conflict for you, and again if you're new you should realize that the university has this niceness clause that says well no one should have to take three finals in a row. And so if you have three finals in a row, including overnight in a row, then the university says you're allowed to take a conflict for one of those. So which one? Well that depends on which classes, et cetera. We have pretty low priority because this is a combined class, right? We have four lectures taking one final. So it's probably going to be our class. But if you have back to back finals, three in a row, you're allowed to take one and take a conflict for it instead. So pay attention to that because otherwise you're, well I don't know, maybe some of you enjoy taking all of your tests in one box, right? Get it done with. But you have that option. So exam coverage, section 4.4, right? Everything since the third midterm in the notes. So section 4.4 is a summary of that. Okay, so again Wednesday will be our review session for the final. We'll spend all day doing that, so come prepared to ask questions. And it'll be on video, so once the final is closer you can go watch it again. Alright, so what's the exam going to be in terms of content? So it is cumulative in the sense that we have one part of seven each on parts one, two, and three of the class. So we'll have one problem on each of those parts, roughly a seventh in terms of points, maybe not exactly. And about four sevenths on the last few weeks, so the material since midterm three. So as you know, things kind of build up, right? If you still don't understand two's complement, then you might get hurt on these two. Alright, so here's where we left off. We were talking about error correction, and I gave you kind of a couple of examples of where it might be important. I don't think I mentioned it's actually now used at pretty much every level of memory hierarchy, even the memories closest to a processor, even on your GPUs. The first generation of graphical processing units didn't have error correction, but people started measuring them in high performance computing and realized, well, they were producing wrong answers often enough that they started putting error detection correction codes. So ECC, as it's called, error correction coding, is now used pretty much in every level of your memory hierarchy. Stronger codes than even the ones we'll talk about are used on disk drives because you have to worry about errors accumulating. And if you're not looking at your bits, then more and more bits will change over time, so the bit error rate goes up. So for the memories and things like that, the codes we'll talk about, like Hamming codes, are what's in use. Alright, so can we correct? I wanted to remind you all, is a Hamming distance code two, like a parity code, is that good enough to correct an error? So this was our 3-bit two's complement with odd parity, so 3-bit two's complement's in black for each of these eight values, and then the odd parity bit's in blue. And of course, if we have one possible error, so if we see this pattern, we know this is not odd parity, right, because it has two ones and two is not an odd number. But that could have been originally the value zero, which is coded this way, and then there was a bit flip that changed this zero to a one, but it's also possible that the original stored value was a one, which is coded this way, and then the parity bit got flipped and it was a one. So we don't know if we see this value, well originally was that a zero or a one. And of course, we can't really make a choice. Making a choice, we have no information other than these four bits. So we don't have any good way to distinguish between those two. So if we have a larger Hamming distance than we can, so this is the three copy code. This is a terribly inefficient code, but it's somewhat intuitive as to why this works. So if you take all your bits and you say, well let me make three copies of them. So here I've done that just with two bits. So three copies of two bits for a two bit unsigned representation. So what's the Hamming distance? Three, right? OK. Yeah, because if you look between any of these patterns, the minimum distance is three. Actually between one and two, the distance is six, right? But what matters for the distance of the code is the minimum distance. And so you can see between zero and one, for example, the distance is three. Between two and three, the distance is three. And then I guess between one and two, it's six, and zero and three, it's six. So depending which way you pick things, you'll get three or six. So the minimum is three. So what happens if one bit flips? This is also things we kind of glanced at quickly last time. If one bit flips, then only one of the three copies can get changed, right? If only one bit flips in the whole thing, that bit has to affect one of our three copies. So that means we can always just vote, and the other two will be their original values, and so they'll always outvote the wrong copy and we'll get the right answer. So what happens if two bits flip? Well, we only have three copies. So if those two bits happen to affect two different copies in the same way, then we're just out of luck. Now if it were a different two bit flips and then we got three different answers, we would know something went wrong, right? But there are cases where only two bits change, and now if we try to vote, well, these two zeros will outvote the two and we'll get the wrong answer, right? So we'll say, oh, you know, we try to correct, and then we'll say, well, this originally was zero, and of course it was two, right? Yeah, so if they were both blue, you would be able to correct, right? So if you flipped the two blue bits, you would be able to correct the answer. That's right. So the answer is sometimes, but in order to have strong error detection or correction properties, you want to be able to detect or correct regardless of which of the bits flip, right? So in this case, you always want to look for the worst case in your analysis. So in this case, the worst case is that the same relative bit in two of the copies flips, and that way you correct incorrectly, which is that red bit. Yeah, Robby? Sorry, that value. So I haven't told you the relationship between Hamming distance and the number of bits that you can correct, but yes, there will be a relationship. Yeah, so all I've shown you so far is that Hamming distance two cannot correct any errors. Hamming distance three can correct one error, but I haven't, I actually haven't even shown you in detail why that's true. So let me, it's a good question. So the question is, what's the overhead for doing this stuff? The overhead's not so big, but let me show you a code that they actually use, and then we can calculate it from there with a concrete code. Yeah, it's, I mean, the short answer is it's roughly logarithmic in the number of bits, right? Which is big if you want to protect two bits at a time, but very small if you have 50 or 100 or something like that. Okay, so, all right, so let's try to generalize a little bit. So let's say that we have a code word C. I want you to define the neighborhood, the K neighborhood around code word C as all of the bit patterns that have Hamming distance of less or equal to K from C. Okay, so this is what you get if you flip up to K bits, right? So if you flip up to K bits from some original pattern C, what you end up with will be in this neighborhood. So you don't flip more than K, you might flip less than K, but regardless of how many from zero to K you flip, whatever bit pattern you end up with will be in this neighborhood. And that's how we define the neighborhood. Yeah, Mohammed? Yeah, but only in chalk right now. I mean, I drew an illustration. I don't know if it will help. Let me, all right, so is it okay if I just start with all zeros? Okay, so for example, the neighborhood here, if you flip one bit, you'll get one of these four patterns. And then if you flip, sorry, I hope those are legible in the back. If you flip a second bit, then you would get 0, 0, 1, 1. So this is flipping a second bit on this one, not the same bit, of course. And then, let's see, this one would also be able to take you to here, but it would have two other patterns, which would be all of, these would all be two 1 bits down here. So all of those bit patterns together would be the two neighborhood around the 0, 0, 0, 0 pattern. So basically, anything you get by flipping up to K bits, any bit pattern you would include in the neighborhood. Yeah? Because that would just, I already have that. So that would just give me an example of, of flipping fewer than, fewer than K bits, or fewer than what I was flipping. Yeah? Purely within memory. So this is the idea that you're storing a bit or transmitting. I mean, it could be a transmission as well. So either I'm storing some bits somewhere, and I put some extra bits, like a parity bit, or for error correction, like a triple code is the only one you've seen so far. Later I look at it again, some of those bits have changed. So that's one model. The other is, I transmit bits to you, but some of those bits are corrupted, and you get them incorrectly. Yeah. Oh, that's way outside the scope. People, people do things like residue computation. So you can, for example, calculate some bits, mod some prime number, and then when you add things together, you can percolate that through your function unit, your adder, or multiplier, whatever, and make sure you get the right residue out. But that's outside the scope of what we're worried about. Those kind of errors are much less frequent anyway. So in practice, those kind of, those kind of capabilities are not on typical processor design. Yeah, it's a good question, but kind of outside what we're doing. Yeah, yeah, so k, it would be anything up to k, so including zero, right? So C itself is in the neighborhood as well. So C is up here. So all of the bit patterns, I didn't draw all of the patterns here, but including C, including everything next to C, one bit off, two spaces away. Okay, so when can we correct errors? So if we assume up to k bits flip in a stored bit pattern to produce a final bit pattern F, we know by the definition of the neighborhood that F is one of the patterns in the neighborhood around, of k bit flips around C, right? So we know F is in there. So when can we, if we know these two things, we know F and we know this neighborhood, when can we say, oh, that must have been C? Well, in order for us to be able to make that deduction, right, we can't make guesses, so unless those neighborhoods don't overlap, then we can't do it, and if they don't overlap, then we can do it, right? We can say, well, which neighborhood did F fall into? That tells us uniquely, well, what is C, as long as those neighborhoods don't overlap. All right, so here's the illustration. So if we want to, if we want to correct k errors, so here's my attempt to illustrate what I drew on the chalkboard there. So you've got some neighborhoods Nk of C, which is all of the up to k bit flips, all the bit patterns up to k Hamming distance away from C, right? So the farthest ones away are distance k. If there's some other code word that this thing you're looking at might have been, well, that'll be some other code word D, and so it also has a neighborhood around it. So if you want these to not overlap, then the things that are farthest away still have to be distance one, right? So in other words, the distance between the code words has to be k plus one plus k more, if you want to deal, if you want to deal with k bit flips. That will allow you to have disjoint neighborhoods. The neighborhoods don't overlap. So if you say, well, I saw this one here, this was F, you know that this F cannot also be in another neighborhood. You know that it can only be in one neighborhood because the neighborhoods are disjoint. They don't overlap. So if it's in one neighborhood, it's not in another, so you can uniquely identify the code word that generated that neighborhood. But that's just Hamming distance, right? The minimum distance between two code words in the whole code, that tells us the Hamming distance. So if my Hamming distance for my code is at least 2k plus one, it can correct k errors. Make sense? Okay, so distance, the Hamming distance D has to be at least 2k plus one. If you flip that around, you get k less or equal to D minus one over two, but k is an integer so usually we might write it with a floor function. So this is the thing to know basically, that if you want to, if you want, if you have a Hamming distance D, then subtract one, divide by two, round down, that's how many, that's how many errors you can fix. So with three, let me, let me give a couple more details and answer your question, Daniel, if D is three, right, three minus one over two is one, and round down you still have one, so with Hamming distance three, you correct one error. With Hamming distance four, four minus one is three, divided by two is one and a half, but round down, so still one. So yes, there is, and I'll show you that at the end. That's what a SECDED code is, is Hamming distance four. So, and that's, I mean, I can tell you just by the name, it's single error correction, dual error detection. So we'll come back to that at the very end, though. Good question. Okay. All right, so what's a Hamming code? So, did I tell you before who Hamming is? I did, right? Okay, so Hamming code, also named after Richard Hamming, is a general and efficient code with Hamming distance three. So it's a nice way to generate codes. It's particularly nice because it gives you, as you'll see, a very easy way to say, well, this was the bit that was flipped. Let me flip it back. All right, so it's very easy to do. And it's a general way for arbitrary number of bits of coming up with a set of parity bits that protect those sets of bits. The parity bits cover subsets of all of your bits, as you'll see. All right, so, so to define a Hamming code on n bits, start by numbering the bits from one to n. Okay, so not no zero bit, start from one to n. And then all of the powers of two are going to be even parity bits. And each even parity bit p, so p then is some power of two, is based on the bits with indices k for which bit p appears as a one in k. So in other words, k and p equals p. So the binary number that you get by writing the parity bits in error as ones then gives you the index of the bit that's mistaken. So let me make this concrete, because it'll be a lot easier to follow. So here's a 7-4 Hamming code. So here are the bits, right, numbered from one to seven. So the parity bits are x1, x2, and x4. The other four are data bits. Okay, so you get to put four data bits in, and then you have three parity bits. Now that doesn't seem terribly efficient, right? It's almost a factor of two, but, you know, that's because we picked such a small number. If we picked 1,000 bits, right, 1,023 for example, then you still only have 10 parity bits, but now you have 1,000 bits of data, or almost 1,000 bits of data, right? So it's logarithmic, and if you pick small numbers, it seems big, but if you pick bigger numbers, it's not so bad. Anyway, so in the 7-4 Hamming code, you've got these seven bits again. The data bits, sorry, the parity bits are x1, x2, x4, so 3, 5, 6, and 7 are data bits. You can put anything you want in there. So how do we calculate the parity? So the parity is even. So x1 is the parity on the bits for which the 1 bit is 1, in other words, the odd-numbered indices. Okay, so 3, 5, and 7. So you xor 3, 5, and 7 together, and then in order to get even parity, you set x1 equal to that, and that gives you an even number of 1s for those four bits. Make sense? Similarly, x2, so x2 is the indices for which the 2 bit is a 1. So if you, maybe I should write these out. Sorry, I should have done this on the slide. So remember, there's no, there's no 1 index, so the indices run from 1 through 7. So here you can see, these are the x1, there's a 1 bit, the 2 bit, and the 4 bit. So this is x1, which is defined as x3, x5, and x7. This is the 2 bit, so here is x2, but that's defined as x3, and then x6 and x7. So you're just taking the binary numbers and looking where they have 1s. So it's pretty straightforward. It sounds complicated in words, but pretty straightforward in practice. Okay, so that's where we get the 3, 6, 7 to define x2 here, and then x4 is just the positions where the 4, I'm sorry, the indices where the 4 bit is on, so that's these four down here. So here's x4, and then that's defined as x5, x4, x6, x4, x7. Make sense? Yeah, Emily? Yeah, so we'll do that in a second, and we'll go do, we will plug into these equations. I just want to make sure you understand where they come from. I mean, most of the stuff we'll ask you to do on exams too would be with, for example, a 7-4 Hamming code, but I want you to know how to do it if you need to someday generate a 31-bit Hamming code, for example. Yeah, Mohamed? Now these are XORed together, so it's even parity across these four bits. So it's x3 XORed with x5, XORed with x7. You XOR those three together, that defines x1. Okay, let me, let me, Eric? Oh, that's just how we define Hamming codes. I mean, it's a very easy way to find mistakes, but let me do a concrete example now. Okay, so if you want to encode something with a 7-4 Hamming code, what you do is you get to pick four data bits, which are these. So pick four bits for me. 1, 0, 0, 1. Okay. So then we just go plug in these equations. So x1, then, is even parity across these four. So this one, this one, this one, and itself. So since it's even parity, the way to figure out the bit is basically to XOR the other bits, or to count them if you'd prefer. So 1, not 1, 1. So it has two 1s. So in order to get an even parity, we should put a 0. Now if you plug into the XOR, you have, what did I put first, 3, 1, XORed with 0, XORed with 1, which is also 0. So that's where the x1 comes from. Like that. Yeah. So you mean which indices? That comes from this table over here. So the x1 bits are, we look at the indices where those indices have a 1 when written in binary. X2 when they have a 2 when written in binary. X4 when they have a 4 when written in binary. If you kept going, it'd be, you know, x128 when they have a 128 written in binary, and so forth. Yeah. Yeah, so those are all defined by the construction of the Hammond code, basically. Yeah. The not, you mean the data bits? You can put anything you want in the data bits. Yeah. You put anything you want in the data bits, and you calculate parity bits to find the code word. Yeah. And then it's protected. Okay. So to calculate x2, then, we would XOR x3 with x6 with x7. So this one, this one, and this one. So what do we get? Zero. And then for x4, we would XOR these three. So what do we get? One. So that would be our 7-bit Hammond code word. Okay. And then if something happened, we could figure out, I'll show you an example of how to figure it out, but we could figure out what went wrong if only up to one of those bits had flipped. Whoops. Here's a graphical version. We used to do this in discussion section. But, so this is a graphical version. This shows the interaction using, well, 2D spheres. So you can think of each of these as being the, each of these circles as being the one bit in red, the two bit in yellow, and the four bit in blue. So to find the parity bits, you can write your data bits into the three, five, six, and seven positions. And then you pick the parity bits such that each circle has even parity. And then to check the parity bits, you just check that each circle has an even number of ones in it. And to correct an error, you'd find the circles with odd parity and then flip the bit in the overlapping area that corresponds to which circles have the wrong bit. Okay. But I won't go through the graphical model. Let me do the algebraic model. Whoops. That was strange. All right. So this graphical approach does generalize, by the way, but it's hard to draw circles or spheres above two dimensions on paper. So unfortunately, it doesn't go much further than a seven-four Hamming code. All right. So here's the algebraic encoding. This is what we just did on the chalkboard. We said, well, let's say we want to store, oh, did I pick the same value? All right. Sorry. Yeah. Sorry about that. I didn't do that deliberately, really. All right. So anyway, so here's the three, the five, and the seven pulled out. We got, oddly enough, exactly the same answers you gave me a minute ago. So this is our coded word. So then let's say that a bit flips, and I didn't tell you which bit, which is purposeful. So this has one bit different, and I guess you can now look over there, but don't do it. So this is something with a bit error, right? So we start our value, and we came back, and one of the bits had changed. Let's see what happens when we try to correct it. So to correct it, what do we do? We recalculate this error bit, which is basically saying, well, for each of our parity bits, does it now have odd parity or even parity? It's supposed to have even parity. So if it has odd parity, something's wrong. All right. So we can take x1, 3, 5, and 7, XOR them together. Believe me, I just pulled these out. I think I'm right. 0, 1, 0, and 1, XOR those together, we get a 0. So there's nothing wrong with the one parity bit. E2 is 2, 3, 5, and, I'm sorry, 2, 3, 6, and 7. That's 1, 1, 0, and 1. XOR those together, we get a 1. So something went wrong amongst one of those bits. And then for E4, we take 4, 5, 6, and 7, XOR those together. That's 1, 0, 0, 1. That gives us a 0. And then all I have to do is write these three from high to low. That gives me 0, 1, 0. And that tells me this number 2 is the one that got flipped, which, in fact, if you now look at it, you'll see all I did was I flipped x2. So this is what I meant when I said it's easy to identify. All you do is you recalculate the parity bits, you line them up in order, and then that tells you a number in binary, which is the bit that you have to flip to get back to the right answer. Yeah, go ahead. Is the graph for ECC in the binary, right? So where does that, like, end up at? Oh, yeah, the LC3 doesn't have ECC in it. Yeah, sorry. Yeah, LC3 does not do error correction. Yeah. Yeah. I mean, you could have a memory that does error correction that, you know, all within the memory, for example, attached to the LC3, but there's no ECC in the LC3 data path. Yeah. Yeah. Okay, Sasha? Yeah. Yeah. So exactly. So what if no error occurs, right? So this is kind of your question. What, why is there no x0? So if there's, if there were an x0, you know, all, if there's no error, we get all of the E sub 1, 2, and 4 values, this should say E sub i or something, all of the error values will be zero, right? Because all the, all the parity bits are still correct. And so your error pattern will be 0, 0, 0, and that has to be able to tell you, well, nothing went wrong. You don't need to flip any bits, right? So we don't include a 0 bit for that reason. So, so there is no 0 bit. So if you get that pattern, that means there was no bit flip. You don't have anything to correct. Okay. Any other questions on that? Okay. Okay, so this is the, this is the SECDED code. So let me finish this and I'll see if you want to do another Hamming distance example. I'm sorry, not Hamming distance, Hamming code example. So what happens if we add a parity bit to a Hamming code? So in general, I won't prove this here, but it's, I think I put a proof or proof outline at least in the notes. If you add a parity bit to a code with, with odd Hamming distance, that actually gives you a code with, with one more Hamming distance, which is kind of cool. I mean, it's somewhat intuitive because you can think of the odd Hamming distance. They've got to have different parities. So if you add a parity bit, that means anything that was close together now has to be a little further apart. And so the codes that were close together, meaning at the minimum distance of D are now forced to D plus one. So now your new minimum is D plus one. Unfortunately, this is not so simple going from a code with, with even Hamming distance to one with odd Hamming distance. Otherwise we could just make Hamming distance arbitrarily large. But we can add, we can take our Hamming code and add a parity bit and that will give us a Hamming distance of four. So what's, what's good about that is we can then use that. We can still only correct one bit flip, right? But what we can do is we can, all I did is I plugged into the equation and got one, right? So we can only correct one bit flip. Sorry, I flipped through that slide too quickly. But if two bit flips occur, what actually happens, right? So you think about the, there are neighborhoods of one bit flip, right? Because we're only going to correct one bit flip. But if, if two bit flips happen, my code, the thing I see moves out of the neighborhood, right? So two bit flips will take me out of the neighborhood next to my code word of one bit flip away. So what I see, the final answer is not actually in any, is in, is not actually in any neighborhood of any code word. So I'll know something went wrong, right? So if I have a Hamming distance of four, unlike the Hamming distance of three examples I showed you before, with a Hamming distance of four, if two bit flips happen, I won't make the mistake of correcting to the wrong answer. I'll actually know, well, something else went wrong. I have to give up, right? So I can do single error correction, double error detection. And so I'll know the difference between one bit flip that I can correct and two bit flips that I have to give up. Three bit flips, of course, I'm just out of luck, right? Three bit flips, too bad. But you know, we, people play the probability game, right? So, so this is a SECDED codes for this acronym here. And they're, they're actually pretty common, too. Okay, so do people want to do another example or two of Hamming? Yeah, okay. All right. So let me, I think the next thing was advice. Yeah. So, so maybe I'll send around these sheets. I don't know if we'll actually finish it today, but this was my printed copy of advice for all of you. And let me switch over to the, to this thing, which hopefully won't take forever. See how quickly I can set it up. Oh, and then the question is, do I have any paper? Wow. We're very limited paper resources. Okay. So let's start by encoding something. So pick, someone pick a paper. Okay. So I'm going to pick four bits for me. 1, 1, 1, 1. Okay. Good choice. All right. So remember, this is X7, X6, down to X1. Maybe I'll number them all. Zoom for now. You'll have to zoom out later. Okay. And for the data bits, these four are data bits. Okay. So how do we calculate X1? So remember, X1 is, is the even parity across those indices with the one bit set, right? Which is just the odd bit. So 3, 5, and 7. So we'll look at 3, it's a 1. 5 is a 1. 7 is a 1. That's three 1s. So to make even parity, what should I put next one? A 1. So the other way to do this is as XOR, right? Okay. What about X2? Oops, sorry. I'm going to have to zoom out a little. Okay. So, oh, it didn't focus yet. Supposed to autofocus. All right. So X2 will be the indices where the two bit is on, right? So those were 2, of course, but 3, 6, and 7. So 2 is defined by 3, 6, and 7. So again, 1, 1, and 1. So what's X2? 1. Good. And what about X4? 1 also, right? It's X5, X6, X7. Those are the three where the one bit, I'm sorry, the four bit is on in the index, as you can see over in the table to the side there. And 1, X4, 1, X4, 1 is 1. Okay. So there's our coded Hamming word. So let's say something comes along and flips a bit. Who wants to pick a bit to flip? 5, 5, 1. Okay. So then we don't know what the original word is, right? All we see, so I won't even show it. I'll just say, well, what we see is 1, 1, 0, 1, 1, 1, 1. So those are the bits we see, and we have to figure out, well, did something go wrong? Let me try to see if I can get this to autofocus. I don't know why it didn't. There we go. All right. So let's see. How do we do that again? Yeah. So let's calculate error bit 1. So it's X1, X3, X5, and X7. So what is that? A 1. Okay. Okay. What about E2? It's a 2 XORed with what? Okay. So that's a 1 XORed with 3, XORed with 6, and then 7. So what is that? 0. Yeah, there's still four 1s, right? So that's even parity. Good. What about E4? It's 4, 5, 6, 7. Okay. So that gives me 1, 0, 1, 1. Which is what? 1. Okay. So if I write E4, E2, E1, then that gives me 1, 0, 1. So that means bit 5, X5 is wrong. Yeah? Make sense? You want to see what happens if two bits flip? Yeah? Okay. Someone else pick another bit to flip. I hear 3, 2, 4. Okay. Anyone against 4? Okay. We're going with 4. All right. So 6, 7, 6, 5, 4. Okay. So two of our bits have flipped. Our original pattern was all 1s, but we don't know that. So X5 and X4 flipped, and we want to go figure out, you know, what was this answer. With Hamming distance 3, we can correct a bit. We can detect, we can always detect two-bit errors, but we have to make a choice. And Hamming distance 3, I told you, well, you can detect D minus 1 if you have Hamming distance D. But if you choose to detect, you have to give up on all cases. You have to choose detection or correction for Hamming distance 3. So you know this is wrong. Some of the parity bits are wrong. So in that case, you could say, any time I see parity bits are wrong, I give up. And then you could always detect two errors. But if you choose to correct, and you only have Hamming distance 3, well, let's see what happens. So what's E1? So X1, 3, 5, 7, which is 1, 0, 1? 1. What's E2? 2, 3, 6, 7? What's that? 1, 1, 1, 1. Still the same? 0? What's E4? Sorry, I can't write quickly. So 0, 0, 1, 1. So what's that one? Aha. So E4, E2, E1 equals 0, 0, 1. So bit 1 was wrong. We fixed it. Yeah, exactly. So you will get an answer. And if you go change that bit, you will still have bits. You won't, however, know that those bits didn't happen to match the bits you put there originally. So the bits you'll get, by the way, if you look at this, you know that the pattern's coming out. If only bit 4 had flipped, the error pattern would have given us 1, 0, 0. Bit 5 flips, we would have gotten 1, 0, 1. If you XOR those two patterns together, you get that. So if you XOR 1, 0, 0 with 1, 0, 1, you get 0, 0, 1. So that's the answer you get. You won't know whether two bits flipped or only bit 1 flipped or whatever. You won't be able to know. Yeah, Eric? Yeah, I mean, if you say you want to do error correction, you're going to flip bit 1, and then you have the wrong answer. So you'll flip bit 1. You will not have flipped bit 4 nor bit 5. Because you have only Hamming distance 3. And so if you have two bit flips, what happened in terms of the neighborhoods was this, that we have our original code word, which is this one. And one of its neighbors is, for example, the X5 bit being mistaken. And then over here, we have another code word, which is, let's see, 1, 1, 0, 0, let's see, 1, 0, 1. And then here, one of its neighbors, which is 1, 1, 0, 0, 1, 1, 1. Zoom in on that. So the way the Hamming code works for error correction, it says, well, if you're in this neighborhood, I'll assume you got that one, right? You came from that one. If you're in this neighborhood, I'll assume you came from that one. But what happens with two bit flips is, well, start here. There's one bit flip. There's two bit flips. Now we're in the wrong neighborhood. So if you correct, you get the wrong answer. Yeah, if you want to correct two errors, you need actually Hamming distance 5. If you want to detect two errors, you need Hamming distance 4. Then you'll know something went wrong. That's a SECDEAD code. Yeah, yeah, that's right. OK, yeah. Oh, it doesn't matter where, so long as you remember it's the parity bit. Yeah, it would be parity over all bits in the Hamming code. So for example, you would put it anywhere, as long as you know that's the parity bit. Yeah. Yeah, it's just like I put it on the right side. But as long as you know it's the parity bit, you can put it anywhere. Yeah. I mean, when people do transmission codes, they tend to put it at the end, because that way you can calculate it as you transmit. You send all the bits, and by the time you've done, you've XORed all the bits together, and then you know which bit to send as the last bit. So people usually put parity bits at the end. Yeah, Dan? Yeah, I mean, usually those will go in higher-end storage systems. I'm trying to think of what the actual codes used to format information on the drives themselves are a little different, because you're physically writing magnetic fields on the hard drives. And so they're actually two-dimensional codes as well, because you've got a surface area that you're writing onto. So they're substantially more complicated in terms of how you figure them out and how you manage error information. Yeah, the kind of Hamming distance 5 stuff I was talking about is usually for high-end storage systems where you have lots of separate disks, and then you'll use Hamming distance 5 codes across disks. So if you have a disk failure, for example, you can deal with that kind of stuff. Or if you have bits being corrupted over time as well. Yes, it doesn't matter. The order doesn't matter. The order is purely for us to know where to go find the bits to include in each of the equations and things like that. In some areas, but not all. Yeah, sometimes. Okay. Wow, we're nearing the end of the hour. Okay. I may spend some of the time, maybe let me get started on some of the advice stuff, and then maybe we'll finish it up on Wednesday. Okay, so Sanjay Patel and I came up with this, wow, maybe 12, 13 years ago, when he started teaching with the book, Pat Patel here at Illinois, and he taught the first time he taught. He and I came up with a list of what we thought we should tell our students as they left the class. And so this list is from that. So I should give him credit for most of it. So one thing is take on a big project in the next few years. So the stuff you do in class will be useful, and we try to make it fun and exciting and worth your time. But if you really want to learn stuff, the best way is to be self-motivated and driven. And those kind of things will be good to talk about when you go to career fairs, and when you go out and even grad school. So figure out something that excites you and go spend some time on it. You can go to the place next to Daily Byte. There's student offices there. They have all kinds of projects. Do something with the AOH. There's all kinds of things you can do. But do something. Do something that you can talk about and say, hey, I worked on this really cool thing when I was an undergrad. Learn to use a debugger. So you've used the LC3 simulator, which kind of helps you walk through things and see what's going on. When you start doing C programming, there's a tool called a debugger that will help you, because it will help you look at state as the program is in the middle of executing. Unfortunately, it's hard to know when to give that to you, because some students will not need it yet. Their mental model of what's going on in the program is so good that they'll look at this thing and say, so I'm going to spend 10 hours learning that thing when I know how to fix my bugs? Wow, you're crazy. This is a waste of time. Then by the time they go back and realize that, well, we told you for a reason, they've been banging their heads on the keyboard for a while. Then other students, they could have used it three weeks earlier. So it's always hard for us to know exactly when to give it to you. But at some point, your bugs will be hard enough that a debugger will make your life vastly easier. So there are tools that will help you. They're like the LC3 simulator. You can go step by step. Say, well, what does this next instruction do? Let me watch. Let me do one instruction. So the same sort of thing, except in a debugger, it's usually an AC statement. Do one C statement. Let me look at the rest. Don't put off learning about tools. There are tools that will be useful for you, scripting languages, things like that, MATLAB. Don't put it off, because they will also make your life easier. Why are they there? Because someone ran into some problems that were painful to keep solving, and so they made a tool for it. I'd like you to know how to multiply matrices and invert matrices, but if you don't want to learn that, you can go use MATLAB, for example. Avoid optimizing prematurely. It's very tempting. Engineers like to optimize. They like to go down and make everything perfect. When you're working on bigger systems, don't spend your time on things that don't matter. Be careful about where you spend your time. There's something called Amdahl's Law. If you have a program and part of that program takes 1% of the time, and then you make that go 100 times faster, well, the other 99% is still just as slow. And so at the end, you're not going that fast. Don't spend your time making things go fast unless they matter overall. Be careful how you spend your time. There's some quotes on that, but maybe I'll skip it. This one has a story attached, so I'll do that one on Wednesday, and I'll try to keep the rest short for you so we can do a review session. Thanks.\"},\n",
       " {'ECE120-2016-08-22-LEC-01-slides.mp4': \" So maybe don't call me that. We have three other sections. You're welcome to go to any and all except the fire marshal doesn't like the room to be overcrowded and have people all over the aisles. So the big room there are two lectures. 1013 is a smaller room, but you know if you want to if you miss a lecture we have them video recorded so you can watch them online. I encourage you to come that way you can interact and ask questions and do things like that. So, please don't just only watch the lectures online, but we will record them for you if you want to review or something. If you're a James Scholar take a look at a wiki and then talk to Professor Varadayan and he will help you set up a scholar program in this class, which will be fun. So I want to start by just telling you a little bit about you know, what is this class? What are we trying to do and why? So you may have heard this pitch from Bill Sanders because I know he's been going around and giving this pitch. So, but what we wanted to do when we redid this class a few years ago was really try to give a systems perspective to our students. So we wanted to get people to understand that as an engineer you're going to need to solve problems and the tools at your disposal as an ECE major are hardware, software, some math, theory, things like that. But you really want to take the right tool for each problem, right? So you can learn to do software and then you can try to solve all problems with software and it's during complete which I'll explain in a minute, which means you can solve all problems. It's just not necessarily the right way to do it. You can do the same thing with hardware. You can solve all problems. Just not necessarily the right way to do it. So the question is how do we get people to do it the right way, right? How do we get our engineers to go out and be successful and be the people that get the right solutions to whatever problem they're trying to solve, even unsolved problems, and enable you to go down that path? As you probably know, our department has a huge history of success in that regard. What you may not know is that we've got alumni in fields all over the place. So you'll have an opportunity every year to see alumni award winners. I think we're getting them videotaped again. So I think you might be able to go back and look at the archives. But people like the founder, one of the co-founders of C-SPAN, for example, which you might not think, well, ECE major would go found a television network for documentary political television. But in fact they did the Mars Lander program. That's something more, yeah, probably someone in ECE is in charge of that, right? Let's see. What else? Patent lawyers, so antenna patents and things like that. Antenna designers. So many, many different fields. You can do whatever you want with an ECE degree. I was going to bring it up later, but maybe I'll bring it up now. We've got College of Medicine based on quantitative science coming together here in a couple of years. So if you're interested in medicine, but you really want to be more quantitative, you're in an ECE program, that's one path you might want to consider. You will need to get a little bit of chemistry, biology experience to apply to a medical program, obviously, but that'll be opening up here. So I wanted to encourage people to consider that. There's also a program with the business school. So if you're interested, you'll find out about it soon enough, but if you ask me I can explain it to you, come to office hours or something. So that was kind of what we wanted to be able to teach people. Some of the other things that we need to give you as your introductory class is just an introduction to kind of the ECE culture and the goals of the department. So I mentioned some of the goals, but the ECE culture, this is the hardest department in the campus, we like to say, and our students all tell us that. And we're proud of it, right? You're gonna work hard and hopefully you'll love it. And I mean if you don't love it, then... But you know, you don't necessarily know what you want to do when you sign up, right? So a lot of engineering schools make you choose going in. So many of you know, hey, I really absolutely want to do ECE. Some people are saying, well, I had to pick something. It sounded kind of cool. Some people maybe, I'm not sure, but we'll check it out, right? It doesn't matter, you know, if you like it, great. I love it, obviously, so I would like to share my love of it with you and have you love it, too. But it's okay if you don't. I mean, there are lots of other good things to do in life. So, but the culture is work hard and be successful and we'd like to see our students go out and be enabled to change the world. Right? So we're hoping that you can go out and change the world as have many alumni before you. Right? So we will train you to do anything and, you know, you can then go out and choose and you'll be able to choose between going and changing the world or if you want a more relaxed life, you can pretty easily take a job with, you know, 40 hours a week or whatever and that'll be fine. But it's up to you. You'll have those choices. All right. So expectation of engineers. You know, engineers are often in positions where what you do will matter in a lot of ways that you might not initially think about. So, you know, when I first created this class with Doug Jones, one of the examples he gave I really liked. It's kind of an ethical question. So, you know, when you design software, for example, your software will live on and people will use it and grab it. And so you have to think about how they're going to use it. Turned out that there was a piece of software that controlled a medical device, an x-ray machine. And so the software, the medical doctor would enter, well, how much radiation do you want to use for this dose? Because they would have to vary it. So they type in a number and they press go. Well, turned out the person who wrote the software didn't put any air checking. So if they mistyped something, it just translates whatever they type as an ASCII code and turn that into a number and irradiate the patient. Well, turned out that you could type lethal doses in and then the patient would get a lethal dose of radiation. All right. So it turned out someone died. So as an engineer, you kind of have to think, well, am I working on problems that one day may actually be safety critical? Right? Where you may have to think about, is there human life at risk? Is someone going to get hurt as a result? So there's a lot of ethical issues as an engineer. And, you know, we want you to understand you should be thinking about them. You should be thinking about what is the impact of what I'm doing, whether it's hardware or software or whatever. I mean, medical device technology, for example, when we talk to people in medical device companies or actually in the people that build the processors that are used, they say, well, you know, our processors are not designed for medical devices. We don't think they're reliable enough. But the people who want to build medical devices, well, they need processors. So they say, well, we're just going to use yours. So what happens if something goes wrong with the processor, if it has a hardware fault? Whose fault is that? So, I mean, whose problem is it that then the system crashes and something goes wrong and someone gets hurt? So as an engineer, you know, there's a lot of things you need to consider, right? And you're all smart. So otherwise you wouldn't be here. So you can handle those sort of things, but there are things that you want to be conscious of, that you're in a position of responsibility. You're also in a position where, you know, you can help society, right? So you can help your community and help people understand what the issues are, merging technology with life. Lifelong learning. So we can't teach you what you're going to use in 10 years, probably not even half of what you're going to use in five years, right? Things change all the time. So all we can teach you is how to learn about things, how things are designed, and maybe instead of learning about the next thing in five years, you'll be the one that designs it. That's probably where we'd like you to be. But, you know, you need to be able to learn for the rest of your life as an engineer. So that's really what we want you to take away. So there'll be concrete tools in our class, for example, and in many of the classes that you will pick up, and those will be relevant today, but those will probably not be the same tools you use in five years or ten years, right? So you need to be able to understand how and why those were built the way they were built and the engineering trade-offs. Again, in engineering, so I'm kind of moving to the next bullet, in engineering, there are always trade-offs, right? There's no meaning in most cases of, well, what is good? There's usually four or five meanings. So I'll give you examples of that in a few weeks, in particular for hardware design, but as an engineer, you need to understand trade-offs. And of course, we're quantitative people, right? We're engineers. So you want to be able to quantize them, but then also understand when you have more than one metric, more than one way to say what is good and measure what is good, how do you decide between them? So as an engineer, that'll be constantly the problem, is knowing, well, how do I measure goodness in the first place, right? Measuring goodness and then saying, well, is four better or six better? If good is bigger, right? That's not hard, right? But figuring out, well, how do I measure it in the first place? How do I get the four or the six for different design choices, right? Or if you've got more than one metric, how do you choose between them? When one is better with one metric and another one is better with the second metric or the third metric. So that's another issue. Look around, it's an international group, right? So you look around the room, you've got people from all over the world. This is a university where we draw students from everywhere and that's a big advantage. All of the engineering companies these days are global, okay? So you're working in a company, you're gonna have people on your team spread around the world, you have an opportunity here to learn different cultures. If you're an international student, of course, you've come to the US, you've got an opportunity to learn US culture. You also want to make sure you learn enough English that you can get as much as possible out of the program. Yeah, I know, well, all right. But if you're a domestic student, take the opportunity also to learn about other cultures by just meeting people in the room, right? You have a big opportunity in that sense here. Let me make one other comment about the English. You know, I've been in many different foreign countries and it's always really intimidating when your language and another language you feel is like not good enough. So I was teaching in Vietnam actually three weeks now, last three weeks, and my Vietnamese is awful. I mean, I don't know if anyone Vietnamese is in the room. It's embarrassing even to try it. But even to go somewhere and say, hey, you know, I want to try that food, right? It can be embarrassing and you feel kind of lonely and you feel like if there are other people that speak your language, hey, I'd like to just hang out with them and be able to relax when I'm not in class. Be careful, right? Be careful that you don't take advantage of the opportunity to improve your English so that you're getting again as much as you can out of your classes, right? If you're in a position where you're not able to follow your lectures, you're not able to do as well on the exams because your English is a stumbling block, it's your loss, right? So you really want to make sure that you're not in that position. So I want to encourage people not to do that. There's an international program, international program in engineering that brings people together and gives you free food. I mean, what could be wrong with that? So I'll try to tell you about the opportunities and I'd like everyone to show up. They don't actually have capacity for everyone in a class, but we'll try to overcapacity them. And I think you'll have fun with it. And I think it'll help you in terms of leveraging the international community here. All right, academic reality. I told you ECU was hard. So it turns out half of the people in the room are under average. Yeah, and you're probably thinking of LaMetta. Oh, sorry, wrong finger. So you get into grad school and it turns out half of grad students are under average. And you know, you'll be a faculty one day, professor somewhere, it turns out half of professors are under average. It really sucks if you get to that level and you're like, oh man. So you really have to remember what pool you're in, right? You're all ECE students. Well, some people transferring in, but you know, I think you'll all be ECE students. So you're in a pretty prestigious pool already, right? I've had advisees that had B- average or something and went on to get their dream job. And I see students that, you know, they get one B in their class and they're like, oh, I'm going to get a B. You know, they get one B in a class or they're headed towards a B and they come to me like, professor, should I stay in ECE? I don't know if I fit in. And the answer is absolutely. If you like what you're doing, absolutely. So, you know, I read pretty widely. I've been reading, I read this book that Steven Pinker, he's a developmental neurologist, neurobiologist. But he was talking about how people kind of, they build their egos around what they're good at. Right. So a lot of you are probably kind of the math and science go to person at your high school. Right. You feel like, hey, that's what I'm really good at. And, you know, look around here. Right. I mean, one of you in this room will be the best, the best of the class. Everyone else will not be. So your ego should not depend on this. I guarantee you that in a couple of years, when you go out to do internships, you will be the best. When you look at people from other schools, you say, wow, I really learned a lot. Let me help you with that. And in a general environment, when you're not amongst all the ECE students, you will be the best. So don't let that feeling of like, hey, you know, maybe I should transfer to that other department and then, you know, I could stand out as the best again, just like in high school. Don't worry about it. You will be. So we worry about that. I mean, we worry about that a lot because we don't want you to leave, leave the department thinking, you know, you won't be able to succeed when we know you will be able to. So what we decided in this class is to make grades a little easier. In fact, well, they wouldn't take me seriously. When we started the class, I told my colleagues, look, let's just give them all A's. OK, everyone, don't just give them A's. I mean, that's what MIT does. Freshman class is pass fail. You all pass. You're good. But we'll actually tell you the real grade. My colleagues were like, are you insane? So that didn't work. But eventually we agreed that we'll give an easier grading scale. So this class is honestly an easier grading scale than most of the ECE classes to help sort of nudge you in the right direction to not have this psychological shock. OK, so that said, that's the reason for it. And you don't have the perspective yet. Right. I said in two years when you go out and do internships, you'll meet people from other schools and you realize how much you know. Right. But until you get that perspective, you know, I can say whatever I want. And then the feeling versus the words are a little hard to match up. Right. So. So that's why. So. All right. Enough philosophizing. Let's talk a little bit about the content. So we're going to build computer systems from the ground up. We're going to start with bits and gates and build upwards through their extraction layers. And eventually, by the end of the semester, you'll know how to build a computer, how to design a computer from bits and gates. Why do we study computers first? If you talk to your friends in AeroAstro, I don't even know this term. I just picked it out as some advanced design. You know, do they start with a high bypass turbofan engine? You know, is that what they say? I'm a freshman in Aero. I'm going to look at the high bypass turbofan engine. No, that's probably something in a senior class or something. They're going to do dynamics, right, in physics and lift. Talk about airfoils or something like that. So why don't we build up to computers slowly? Why in this class are we going to start and build right into computers immediately? So in 1936, Alan Turing wrote a paper about universal computation devices. So take the space of all possible things you might want to do, things you might want to solve problems. And so some of them are computable. So I drew that in green there. So some of them you can answer questions. And then in that are the computers that can solve those kind of problems. So, you know, Blue Waters, the biggest and most powerful scientific supercomputer in the United States, a little bit south of here on the campus, versus iPad. Same power, same ability to solve problems. It's just memory and time. That's the difference. Blue Waters has a big chunk of memory, petabytes, but iPad, I don't think they have petabytes. Maybe there's a new option or something. So it's just memory, right, memory and time. But otherwise they can solve the same problems. Android phone, same thing. LC3, the computer, little computer 3 that the ISA will study in this class, the computer will study in this class. They're all the same. So if there's a problem you can solve with one, you can solve it with any of them. So that's one reason that we're going to look at computers first, is that things are either computers or they're not computers. There aren't different types of computers. They're all the same in that sense. So we're going to look at a somewhat simple design for a computer, but it can still solve all the same problems. And that'll be the LC3. There are undecidable problems. Probably won't talk about it much in class. There's some detail in the first section of the notes. So if you want to know, well, what is an undecidable problem? Actually, Alan Turing gave us an example in 1936 called the halting problem. So you can see something outside of this box and none of these computers can solve the halting problem. So those are undecidable problems. The Church-Turing hypothesis is worth mentioning. So one of the other things that Alonzo Church and Alan Turing both hypothesized was that this green thing here is the same as what humans can compute. So in other words, if you or I could solve a problem by sitting there and trying to work it out systematically, a computer can solve it too and vice versa. So that's the hypothesis. It's never been proven or disproven and it probably won't be. Because how can you prove what a human can or can't do? But most people in computing and technology believe this to be true. That computers and humans can do the same things. Now, there's a lot of stuff we don't know how to do systematically. So the things that our brains do with neurons, things even like vision, we don't know how to do systematically. So why do captures work? Why is it that when you make someone look at text that's been fuzzified a little bit, why does that keep a robot from being able to break into your website? Well, it's because we don't know how to solve that problem. Our brains do it very easily, but we don't know how to do it systematically. So we can't teach our computers, which are dumb. Computers are not smart. We can't teach them how to solve that problem. So until someone figures it out, captures are effective. Okay, so I promise I won't do this to you very often, but I'm going to read you a quote. All right. It even came out sort of big enough font, but it's in the notes that you can grab online if you want. You don't really need to know it or anything. The apparatus they, animals, use for timing their movements has more in common with an electronic computer, although it is strictly different in fundamental operation. The basic unit of biological computers, the nerve cell or neuron, is really nothing like a transistor in its internal workings. Transistors are what we're going to use to build our computers. Certainly the code in which neurons communicate with each other seems to be a little bit like the pulse codes of digital computers. But the individual neuron is a much more sophisticated data processing unit than the transistor. Instead of just three connections to other components, a single neuron may have tens of thousands. The neuron is slower than the transistor, but it's gone much farther in the direction of miniaturization, a trend which has dominated the electronics industry over the past two decades. It was in 1976, by the way. So he's talking about starting in 1956. This is brought home by the fact that there are some 10,000 million neurons in a human brain. You could pack only a few hundred transistors into a skull. So that was in 1976. So miniaturization from 1956 to 1976. Moore's Law continued in the intervening 40 years. So 1997, when the Pentium was released, there were 4.5 million transistors on it. Today there are chips you can go out and buy at Best Buy with 4.3 billion transistors on a chip with 541 millimeters squared and very, very thin. So if you do the math, you can see that you can pack a heck of a lot more transistors into a skull than you can neurons. So they're much, much smaller. There's still only three terminals. So complexity arguments. Yeah, we'll see. But certainly transistors and computers have gotten much, much more powerful. And there's interest and some promise in trying to see if we can get these digital systems to do what human brains do. So that was Richard Dawkins in his selfish gene book. All right. So what's happened in ECE in the last couple of decades is that we've seen really a digital convergence. So most people, even our EE graduates, have gone on and they end up being computer people, using computers in their daily life. I mean, you use computers in your daily life, I'm sure. Most of the solutions across our fields are digital. There's not much room left for analog engineering. I mean, it's kind of fun and it's hard, but there's not that many jobs out there and there's not that much research going on in a lot of fields with analog. Most things are digital. Digital system design thus provides you with a critical set of tools and a critical set of skills that all of our graduates need. And so we want to make sure that all of you have these skills, which is why we require that everyone take these classes. And you'll go a lot further and faster with these tools in your toolbox than without them. So that's why. I mean, sometimes, you know, this is in some sense the lead into computer engineering program, but at the same time, all of our EEs are in here. And so sometimes our EEs wonder why us? Well, because honestly, in most of the subfields of electrical engineering these days, these will also be critical skills for you. All right. So why do we do bottom up? So we really want you to have a firm understanding. We've seen far too many programs where people go from the top down and they end up kind of waving their hands and not really understanding what's going on underneath. And so we feel like, you know, this is it's important to have you understand what's going on underneath. Before you talk about what we build on top of it, you'll see that we'll build upwards through layers of abstraction in the class. Because then when something especially when you're trying to build something, when something goes wrong, you have a model of what's going on underneath. And you can understand and reason about the system as a whole instead of guesswork, instead of making guesses. So we don't want you making guesses about how to do things. We want you to be able to reason about it based on your understanding of the systems underneath. And so that's one reason. If you're designing at different levels, then it's critical that you understand the layers on what you're building. Because you need to be able to understand, well, if there's a problem at one of the layers, is it easier to push it into a layer underneath you, to hand it up to a layer above you? So these kind of decisions, if you're working in a sub area, in one of the layers of abstraction that I'll show you for digital systems, interacting with your adjacent layers, you really need to understand those to a certain degree. So we're building upwards so you have an understanding of all of them in your first class. And of course, our students have been successful with this approach. Okay, so where do you find information? Well, you start with a wiki. So one way is, you know, you can bookmark this or whatever, type it in one time. Unfortunately, you can't Google EC120 wiki and it won't come up. It won't work. So instead, you can Google my name. So if you can remember how to spell my name, then you can Google it. So just as a demonstration. Let's do it this way. I claim, if you type Steve Lomeda into Google, that I will be first. There we go. And then you can go down here to F16 under classes and go there. And then there's a link to the wiki at the top along with some other stuff I put there for you. So I won't show you the other stuff now, although actually down at the bottom is lecture slides. So if you want to see this stuff on your own. And so there's a link to the class wiki. If you haven't used a wiki before, you know, it's basically just a hierarchical web page. There is a menu, menu driven system on the left. The only thing I kind of don't like about it myself is that if you click something like syllabus, then you'll get a page with interesting information on it. And then down at the bottom, it'll say child pages. So if you want to see those child pages, you can expand the menu on the left. So I find, I don't know, I don't like that interface much, but that's the way it works. So this is the first place you should look is this wiki if you're looking for information about the class. And you should read it every day. We'll post announcements there. So do try to look at it every day. Let me go back to go back to this slide. Yeah, so take a look every day. So what you'll find there is announcements for the class, due dates for homework, assignments. You can pick up your assignments there. We'll post solutions for homework. Those will be there to course information, timing, office hours, staff members, names, email addresses, so forth and so on. It's also a place for exchanging information. So you can add questions and comments on assignments and then get answers there, which is the right way to do it. Right. Because if you have a question, chances are really good, lots of people have that question. Right. So don't feel shy about just putting your question there and then seeing what's the answer. You can try to help people if you feel you know the answer. That's fine. Don't post answers, please. Right. So if you have. That sounds weird. Don't post solutions. Right. So if you know the answer, the correct solution to a homework problem, don't post it on the wiki, please. And for one thing, you'll end up getting mad at you. But but they will also have to delete it. And it'll ruin all the fun for everyone else. But any non-personal questions you should put here. Right. So unless it's something like, hey, you know, I want to talk about my grade. Right. Those kind of questions you can use email. Anything else you should put on the wiki. Right. Because again, anything anything that isn't personal to you is probably something other people are going to want to know the answer to as well. And so we'd like to have that answer be public. So please use that for those reasons. What to read and what not to read. Here's our textbook. It's the second edition of Pat and Patel. Sanjay Patel is another one of our faculty members. Yale Pat is his advisor. He's still at Michigan. I'm sorry, not at Michigan. He's still at Texas, University of Texas, Austin. So this introduction to computing system. It's a good book. Doesn't go quite as much into digital design as we had wanted for this section. This two class sequence, 120-220. So there's also about 150 pages of notes that I wrote for you. So that's on the page. It's on the wiki. But the notes will help you read the book, read the notes. But suggested first you try to read them before and after class. The wiki will tell you the relevant sections. Students have told us sometimes you need to read things more than once. Actually, an alumni, quite a famous alumni came in and his comment to the students was, when I was in school, you know, I would sit down and I would read it once. Then I would read it again. And then because I knew I didn't really understand it, I'd read it a third time. So don't feel too bad if it takes a little while to sink in. I mean, I tried to put lots of examples. I think this is a great book. So hopefully it doesn't take so long. But if it does, really don't worry about it. You can go on and be successful and happy. I mean, this was again one of our famous alumni winning the Senior Alumni Award. So if you read it a couple of times, it's OK. But if you come if you read it, then you'll come prepared to have questions. And I would like this to be a dynamic, dynamic environment. So take a look at also the notes have summary sections that tell you the learning objectives. So if you want to know, well, what am I supposed to learn? It'll be summarized for you in those sections. I've never taught this class with PowerPoint. I always use the chalkboard. I'm going to try to switch over to PowerPoint. Just give you more resources. But so two things about that. One is I have to do a better job of rate controlling myself, which with chalk is a little bit easier. Although I'm told I'm one of the fastest writers in the department. But, you know, feel free to ask questions. So if you have questions, just raise your hand or for some reason I'm looking the wrong way, then just say hello and ask your question. OK. It's a small enough class that I think don't worry too much about about interrupting. I will repeat your question because since we're videotaping, I want to make sure they get on the on the recording. We have some online tools in JavaScript. So use those to practice your skills. They're for the first and second parts of the class. Class is divided into four sections by midterms and then the final at the end. So there's some tools you can use to practice your skills and make up random problems for you. They'll give you instant feedback on your answers. So it should be helpful. They're JavaScript based. You can run them on your desktop or your mobile. Unfortunately, I don't own an Apple product, so I can't debug them. And I know they're not so nice user interface wise on Apple. So I apologize to Apple users. But one of my students at Apple sent me one, then I'll be able to debug. Watch out for the web. Right. I mean, I do expect you to be able to go out and Google things. But on the flip side, I know there's a lot of bad information out there. So be careful about just trying to look up and learning from random stuff on the Web, because often the people writing it or shouldn't be writing it. They wouldn't be allowed to write it. So I've seen a lot of confusing things when I was looking for resources for this class. And, you know, I wouldn't point you there, but you can also find them. So just be a little careful because the Web is not filtered. Which I think you know, but sometimes it's worth being conscious of. All right. So let's spend some time talking about what are we going to do in the class and how are we going to grade you and stuff like that. So what's the workload? Every week you will have a lab. So software and hardware. Some will be programming. Some will be building hardware. You'll build a little finite state machine that interacts with the real world at some point with sensors and actuators. You will write some programs. So labs will vary from week to week in terms of what they are. And so how you turn them in will also vary. They're usually due Wednesdays at five. But look at the assignment because it will not always be the case every week. The first one is due next Wednesday. So not two days from now, but next Wednesday, 31st of August. Their weekly homework assignments. So those are paper and computer based. The paper stuff you'll turn in at a box near 3070 in this building, which is the student lounge, the undergrad lounge. And those are due Fridays at four. First one's next Friday. So you have a little time there. But you'll have those every week. And then, of course, we'll have some exams. We try to make more of these just so people don't feel so pressured by them. So you'll have four exams. So it kind of breaks the class up into four pieces. And we'll have evening exams. The philosophy is we don't want you to be time pressured. So these are designed to be 45 minute exams. And then we'll give you an hour and a half to do them. So hopefully by the end of the hour and a half, most people are gone. If you're still there, don't worry about it. We don't always get it right. I've gotten it really badly wrong sometimes and had almost all of my students there at the end. And I felt that. But yes, I see people smile. So it's funny because, you know, if we give an exam, I used to target 75 average. We're targeting a little higher now because we're moving on to definitely absolute scale, as I'll mention in a minute. But other schools, people target 50 because it gives you the most information. And I know most of you, most of you have probably gotten, you know, 90, 95, 98 through most of your life. And you come into college and you get a 50. Oh, man. And if no one tells you, oh, the average was 50 and, you know, you're in this great class of really good students, then you might not realize, well, that's pretty good score. Right. So it's really kind of psychologically challenging and traumatic sometimes. But so we're targeting higher averages with these. But we are. We do screw up sometimes. So, you know, if we screw up, we will account for that. So we'll give you an absolute scale. But if we mess up stuff and the average is lower than it should have been, we can push your grades up, but we won't push them down. So if you if you're on the absolute scale, then I'll show you in a few minutes and you get an A or B or whatever, then you'll definitely get that grade. And if we've messed up and given too hard exams, we'll fix it. Don't worry. All right. So three midterms, one final. Those are the times and dates are on the wiki too. So. If you have a conflict, let us know early. There are some rules that the university provides for figuring out if you have a conflict. But let us know. The finals rules actually depend on class sizes. So in some cases you won't know. Right. Because maybe not everyone comes to class or there sort of seems similar when you look around the room, in which case go to Laurie Fisher and she'll know because she can look at everything. She's up in the advising office. So. So if you can't figure it out, just ask her and do it soon enough that you know which classes are going to offer you a conflict. Some, some classes. I mean, I think we'll do this, but some classes will let you take a conflict if you need one. So if you need a conflict, sometimes the rules will say, well, that class has to do it for you. And if that class is offering a conflict or is not a well, sorry, let me make this clear. If you have two classes that conflict, then one of those classes definitely has to offer you a conflict. So you're protected from people saying, I don't want to be bothered. So you definitely deserve a conflict. Now, which class that is depends on the rules. Sometimes it's actually both have to offer you a conflict. But classes that don't have to offer anyone a conflict by the rules for finals might say, well, we don't want to create a conflict exam. You have to take the one that offers you one. Right. Other times, the bigger classes tend to say, well, if we're going to make the conflict exam available, then anyone who has a conflict can choose ours, even if even if technically they were supposed to choose the other one. OK, so this, I think, will become clearer over the next few years. But but the main point is, let us know early, because we do have to arrange to find a time with you that you can take the exam. So to let us know early, there's a default time. But but all of the classes, a lot of big classes will try to have default times. If the default time also doesn't work for you, it is the class's responsibility to find a time that does work for you. OK, but you but you do have to let us know. So let us know early. Oh, it's up to my. I want to ask you. All right. So no one asked a question yet. All right. So the question for you. What's the what skill is least developed in most in many of our grads? You saw the answer. It is so lame. Sorry. Oh, good answer. Good answer. I wonder how you knew that. I don't know why my laptop did that to me. So shameful. All right. So, yeah. So a lot of people, a lot of our alumni tell us in industry, industry contacts, people that come and recruit here say, you can probably do a better job with your soft skills. Right. So one of the things you will do in this class in discussion sections, you will work in groups. So you have an opportunity to meet people in the class, solve fun problems related to the lecture together and practice working with others. In later classes in ECE, there's a lot of teamwork. There's always hands on work and there's a lot of teamwork in later classes. This is actually feedback from a long time ago, although I think we can still continue to improve. But there's now required team projects, I think, in every route through ECE. So you will eventually have to do big class projects with team members. But even in these introductory classes, you're going to be working with people every week. OK, so so use it to meet people that you can work with, talk to, do your homework together and try to develop your soft skills because employers are looking for that. It is important. All right. So how are we going to grade? So we got 15 percent on labs, 15 percent on homework, 5 percent on discussion sheets, midterms. First one is 10. Others are 15 and the final is 25. A lot of people, if you are if this is your first semester in college, you might wonder on an exam, well, did I get an A or a B, etc. We don't typically do that in engineering classes. We just do points. Right. So you've got some number of points. And out of out of all the possible points, you'll get some number from zero to 100 percent of the points. And then we'll map that. I'll show you a mapping in a second. But it's your typical absolute scale. And so we'll map that to a grade only in the end. We will, as part of that calculation, drop your lowest score for your lab, your lowest score for your homework and your lowest score for your discussion sheets. So if you if you get sick and you miss a week or something, don't worry too much. But we don't accept late assignments. So make sure you turn things in on time. Part of that is part of that is that, you know, we're going to put homework solutions out. So once the homework solutions are out, we can't really take take the homework because the solutions up. So so do them on time, please. And the other reason, honestly, too, is if we extend an assignment with a 400 person class across many weeks, it becomes a challenge to grade. We have a big team of graders that's going to try to get your homework back quickly so that you can get the useful feedback in time. And if they then have to go back and grade previous week's homework because people turned them late, then it just becomes completely unmanageable. So it's another reason we just decided, you know, no, no late assignments. So finish them on time. And we do try to drop one of each to to account for, you know, S happens kind of things. I guess I can say it in other languages. So the ECE 120 grading scale is absolute. So, again, we calculate total points based on the percentages you just saw. If you get 90 percent of the points, you get an A of some sort. More details on the wiki. I think it's like 93 is 90 to 92 is an A minus 93 to 97 is an A, 98 and up is an A plus or something like that. Look on the wiki if you want more detail. 80 percent and up is a B of some sort. 70 percent is a C of some sort. Many of your classes here will be curved. Right. So many of your classes will just say, well, you know, we'll target something on the exams, maybe 75 percent, maybe 50. Actually, some ECE classes, I think we're targeting 30 based on their outcome. But that's the average. So remember, if you got like 35, that was actually a good score. Yeah. You can imagine that feeling right before you know the average. We've all been there. So it's OK. So many of your classes will be curved. Right. So just realize that for the future. And you can ask the professor in your class, is this curve? Is there a scale? What's the scale? In here, this will be this will be absolute unless we really blow it on an exam. And the exam average is 50, in which case we're going to we're going to raise up, raise people up so that more people are getting A's and B's than the absolute scale. So we will make it easier. We won't make it harder. All right. Again, I mentioned soft skills, but but do get to know people. Right. So, you know, talk to people in your lecture, talk to people in your discussion section, go to Open Lab. Once a week we have this Open Lab every Wednesday, nine to five in 2022. There's a Redbook. So if you want to if you want to meet people, there's a Redbook. You can sign up in Terry Peterson's office in the advising office. You know, I was sort of joking, but, you know, if you want to turn and say hi to your neighbors now, it'd be OK. I'll walk over there slowly. All right. So don't cheat. You know, this is always painful to talk about, but but it does happen sometimes. So I want to mention it just because we do say we do take it seriously. There's a code online that that describes it in a lot of gory detail for you, which you should read once in your life since you're here. So that's the number. If you type section one of one for two academic code UI, you see it'll come up. Discussion sections. So the other thing I actually much more serious note, every class is different. Right. So every class will have a different interpretation of what it means, what's allowed and what's not. So be sure in every class that you figure out what that class allows and what they don't, because the line's a little blurry and it's in different places for different classes. So make sure you know where the line is in every class. So this stuff is just meant to help you with what's the line in this class. So discussion sections are done in groups and some labs you'll have partners. Otherwise, your work should be your own. So you can talk to each other, you know, help each other understand, but don't give each other answers, share answers, give any kind of electronic answers. Let someone copy your answers. You know, if one person lets another person copy and we find out we give them both zeros. And we apply that penalty. So, so please don't. And I don't think any of you will, but somehow it happens. Your guide to the slides. I'll leave this. I won't go over it here, but, but it's there in the slides. So. All right. We've got a few minutes left. So let me talk about, you know, actually, with my remaining few minutes. I mean, you probably know this, but you can't eat here. So if you get a little peckish in the afternoon. Sorry. But I'm a professor. So. I can do what I want. Unfortunately. You know, it's a little embarrassing. I need, I need your help because my kids eat this thing called a peanut butter sandwich, but. It's a little embarrassing. I just need your help to tell me what to do. So I got some bread. It's sourdough bread. I hope that's okay. And I got some peanut butter. I got some paper towels because the janitors will still kill me. And I got some white paper towels too to destroy all the evidence. And I have this knife. What should I do? Can you help? Can someone help? What do I do first? Yeah. What's your name? Eric, what do I do? Open the bag? Okay. It's not working. Yeah. All right. It's open. It's open. What's next? Take the bread. Good bread. Someone else want to help me? Yes. What's your name? What should I do next other than chew? You're really going to let me do this? All right. So what's the point? There's abstraction, right? You kind of think I know how to use things like a plastic bag or maybe how to undo a lid. And humans have a lot of abstractions that we learn about. I'll give you a couple more examples in a minute. But that abstraction, we think about it in terms of interfaces. Like you tell me, okay, open the bag. Eric told me to open the bag. And Raul told me to open the jar. And you expect that I know what to do. And there's an implementation. There are lots of different jars. There are lots of different bags. And each of them has that interface of, well, open it, close it, take something out, put something in. And you expect that I'm going to know what that means and how to use it as a human. So an abstraction layer is just that. It's some implementation that provides you with a set of functions. And it's built on something underneath that also provides a set of functions to it. But many different ways to do it. Many different bottles, many different bags. So that's an abstraction layer. Just to give you a couple more examples, humans know all kinds of abstractions. So if you get in a taxi, you don't tell the taxi driver, okay, lift your right hand and put it on that stick there. You tell them, hey, I want to go to the airport. And you expect that the taxi driver is going to take that airport and turn it into driving instructions. And maybe even helping you put your bags in the back and so forth and so on. There's an abstraction of you just say where your destination is. Taxi driver takes you there and then takes the money. And you should tip. And then the water faucet. What's the abstraction? Well, the functions are get water at some fuzzy rate. There's a low rate and a high rate and maybe a medium rate. And there's a lot of ways to do it. You could use plumbing. You can use water tanks, cisterns, wells, aqueducts, valves, knobs. There's lots of ways to build a faucet. And you could probably use all of them as a human. But the abstraction is, you know, get some water. And you don't want to care. How many of you know how to build a faucet? Okay. So some people. Raul, right? Some people do. And probably most of you could drive a taxi for some form of drive a taxi. But, you know, there's lots of actually probably not many of you would know enough about the local area to drive a taxi well. But you could do the driving part. But the, I guess you can buy GPS. But those are abstractions. So starting, I guess we have a few minutes left. So maybe I'll start with the first few of these digital systems. We can break into seven layers. So this is taken from Pat and Patel. This is figure one six, as I recall. Digital systems break into seven layers. So down beneath this is the electrons. Right. So what we'd like to do is say, electrons, I want to go to the airport. And the electrons will form up a taxi and I'll climb in and then they'll zip me down to the airport. And then it'll be good. Unfortunately, no matter how much I talk, I don't talk to electrons. No matter how much we try, it doesn't work. Right. Electrons don't understand human language. So we've got all these other layers in between where we try to turn human language that describe problems and tasks into electrons moving around on a chip that can implement some problem solving. Problem solving for us, including autonomous driving. So not really too much of a joke to use a taxi. All right. So the color coding I've added human language theory is yellow. Software is green and hardware is blue. Those are sort of typical implementations of these layers. So let's let's go through these. So, yeah, that was my electron joke. Actually, I stole that one from E.L. Pat. So credit him. All right. So problems and tasks. So this is the first layer at the very top. So, for example, these are state and natural language. And I want you to answer this question. What's the sum of numbers between one and three? Think of it in your head. Don't shout it out. OK. Is it hard? You got it? You ready? I have to walk all the way back over here. So. All right. Sorry, your answer was wrong. It's mean to play tricks on your non-engineering friends and take money from this from this question. So don't do that. All right. So what's the sum? Did you answer? How many of you answered six? How many people said, oh, some of numbers from one or three? Yeah. Some people answered six. But no, because if I ask you, OK, look, here's my bread. Pretend this is a sandwich. What's between the bread and the sandwich? Is it the bread? So if I say what's between the bread, you wouldn't say, oh, it's the bread. The bread is between the bread. So you shouldn't add one and two. I'm sorry, one and three. Right. Well, what if you answer two? So you say, I have a better answer. No. What about two point five? Did you include what about pi over two? What about E? Do you add those in? Right. So maybe some of you did anyone answer infinity? OK. Oh, my gosh. Right. You can read. The answer is still wrong. The answer was six. All right. So what's the problem there? The problem is inherent to natural language. Right. There's ambiguity. What is between mean? Right. How did we know? Did I mean integers? Did I mean real numbers? Maybe I meant complex numbers between one and three. Right. Along the line in the complex plane. So another example, time flies like an arrow. What does it mean? How many of you do Pokemon Go? A lot, huh? So before Pokemon, there was Yu-Gi-Oh. You know Yu-Gi-Oh? And one of the Yu-Gi-Oh characters was Time Wizard. He looked kind of like this. This is Time Wizard. Time Wizard and I, we're good buddies. I'm on a first name basis. I call him Time. Turns out that when Time Wizard flies, don't try this at home. This is purely television, you know. Could hurt people if you try this at home. I talked about safety. Critical, critical technology. OK. I'm doing this really fast because we're running out of time. So it might not fly as well as it should. I'm not an aeronautical engineer anyway. Time flies like an arrow. Clearly that's what that means. Right. Time flies like an arrow. At least when you give him the proper plane. OK. So I don't want to run too much over time. So I will stop there. But I did want to show you. And you can just come down and look at them. Or maybe I'll take them outside. Here in Illinois, we have the, I think still the only fabrication facility. Intel donated one of their old tabs. These are examples of chips students have built here. So try to be careful with them. But you can see already some of them are broken. So don't feel bad if you break them. And I'll let you take a look if you're interested. And then maybe I'll drop them. But there's a lot of cool stuff you can do here. There's also a new nano lab just outside, up one floor. Transcribed by https://otter.ai you you you you you\"},\n",
       " {'ECE120-2016-08-31-LEC-05-slides.mp4': \" Okay, so yeah, I'm sure you saw your email. Well, hopefully you saw your email. So yeah, sorry about that last time. So today we're gonna talk about wrap-up fixed and floating-point. Maybe do another example, maybe on the tool or something. Talk about human text representations, and I want to give you kind of a taxonomy for thinking about bits versus representations versus data types as I'll use those terms in class. So before we get started, you know, since I taught this class a couple years ago, somehow they took five lectures and then they took some of it out and they left three, but I still have five lectures to deliver it. So we're a little bit ahead. So I have to speak really slowly. So how many of you saw Zootopia? Yeah, okay. So if I teach like a law... Yeah, anyway, so I can't stand it. I'm sorry. I'm gonna have to go back to fast mode. Oh, it's supposed to click. There we go. Yeah, how many of you watch movies? You like movies? Okay. So I figured I'd just waste some time and ask for your help. You know, I was talking to Ravi Iyer and he's teaching a junior-senior level probability class and he's saying, you know, I asked my students to do a Karnaugh map or he mentioned something they could use a Karnaugh map. You'll learn about those in a couple weeks. And they said they couldn't do it and his grad student said, well, it's probably context. And they're just out of context. All right, so let's talk about movies. So you watch movies, right? I need your help. So my friends want to have a movie club with me. So there's three we're thinking about that are coming out here. There's a Jackie Chan movie on the way. There's wildlife, there's animation. Both of those are kind of funny and there's a Beatles documentary coming up. And the problem is that, you know, I'm a professor and they're kind of picky too. And so we have to agree in advance which ones we're going to watch. Otherwise the deal's off. We're not going to go out together. So I need your help. So here's the rules. So for me, I was in Asia. Jackie's movie came out a while ago. I don't want to watch it again. It was good, but I don't want to watch it again. But I do want to, you know, what's the point of a movie club if you don't go see a movie, right? So I say got to have one movie, but I don't want to watch a Jackie Chan film because I saw it already. If you want to watch movies before they're out in the US, you have to go somewhere else in the world where they get released earlier. My first friend here says three is too many. So can't watch all three. My security friends Alice and Bob, Alice says let's watch exactly one comedy. Beatles or no Beatles is fine. And Bob says Bob loves the Beatles. So we have to see that one. So somehow I need your help. I mean, I need you to help me satisfy all of these people. Have any ideas? The last two? You just solved that problem in your head? Can you help me a little more slowly, please? Can we maybe apply something? I know you. Okay, maybe it's too easy. Sorry. Okay, so this first sentence, I won't watch Jackie Chan, so it means not Jay, right? Good answer. Okay, so we need to translate this into Boolean, I think, right? So won't watch Jackie Chan means not Jay. So I need to connect that then to this other clause. How should I connect it? So don't translate it yet. Once I translate it, what should I use? What operator should I use to connect my J prime to this next one? And, right? Because it has to both be true. Otherwise, I'm not satisfied, right? So I want J prime and, okay, now go ahead. What do you want this watch at least one to? So W or B. Technically, if I forget that I'm going to end it with this, it's actually all three, right? Watch one movie is just this thing. Now, you're right that the J doesn't matter because once I distribute this, I'll get J prime J, which is always zero. So I could just cross out the J. That would be the right answer, too. That's okay. And so some of you are kind of skipping it and, you know, optimizing it in your heads before you answer. So that's fine. But this is not optimized, right? Watch one movie means one of the three is true, right? Any of the three is true, an or function. So good. Good. I think we're making progress. So you've got LaMetta translated to Boolean. Okay. What about this next one? Three is too many. Okay, I'll let you all think about it. So not J or not W. Okay, here's how I did it. Does this look like... So I claim this. So if I don't watch this one, that's fine. Or I don't watch that one. That's fine. Or I don't watch that one. But one of the three I'm not going to watch. As long as I don't watch all three, that's okay. I think that's it. You know, there are lots of ways you can write any Boolean expression. So as long as your way was equivalent to this, that's fine. Okay. Actually, we'll look at good ways to write them in a couple of weeks too, Boolean optimization. All right. So Alice, my security friend. Many of you understand that joke? It's okay. You will later. The question is when you take a security class, whether you think, oh, now I get LaMetta's joke from two years ago. All right. In security protocols, the two people trying to communicate securely are always Alice and Bob. So these are my security friends. Yeah, it's a cheesy geek joke. I know. I know. I gave it away. I did the spoiler on the joke. So how do I set this into Boolean? Okay. So I'm hearing some J, X, or W. So let's watch exactly one comedy. There are two choices, right? So I can use XOR, the odd function, to say, well, I want either J or W. So J, X, or W. Is that right? Okay. And then Beatles or no Beatles is fine. So that's an and. And what does that give me? B or not B. And here I simplified and I just put a one. So yeah, B or not B would be a more accurate rendition, which of course B or not B is one. So I cheated and put the one. Okay. What about Bob? Just B. Bob says B. Anything else? Don't care. But B is not there. He's out. Okay. All right. So we've got the Boolean expressions. Now we need to satisfy all four of these people. So again, the all function, we need and. So pop up our handy truth table. So help me fill these in. So when I have an and, the easy way to fill in the truth table is to say, well, anytime any of these functions gives me a zero, that's a zero, right? Because in order for me to put a one, I have to have all of them be true. So what I can do is go one by one and look for the zeros, fill the zeros in. Whatever is not filled in is a one. So let's start at the top. Let's take my first clause, J prime. So J prime means anywhere that J is equal to one, that's going to be a zero. So this one, this one, that one, and that one. Those are not good options. Because I said I'm not going to watch the Jackie Chan movie. So those four options in my truth table are out. So then we'll go on to the next step. So what is this blue clause roll out? Yeah, good. So that zero, zero, zero line, that's not allowed because I said, well, we've got to watch some movie. It's a movie club. What's the point of saying, hey, I have this really cool movie club. Well, what did you watch? Well, we didn't watch anything. Wow. Okay. So that's that clause. What about this next one? Just the one, one, one, right? So that's already a zero. I'll just put the little color coding. I added that late. So if you look at the slides online, the extra color codings are not there. But, but that's just overlapping. That's already a zero. So what about, what about Alice's comedy role? So J or J X or W. Yeah. So zero, zero, one's not acceptable, right? Zero or zero X or zero is zero. So this one up here, that's not, that's not good. So there are some other ones. Yeah, the ones down, zero, one, zero is okay. Right? Zero, one, zero, we've got J is zero, W is one, so zero X or one is one. So that one's okay. This one's okay. These two, yeah, those two are not allowed. And this one up here also not allowed. So we could add those in, but they're already zeros. So let me add the little color stripes there. And so Alice would also rule out those, those three, but they're already zero. And then what about Bob? B has to be one. So this one here is out. And there's some other ones that, that Bob would also say no to, except they're also already zeros. So that one left. We've checked all the clauses. So that one that's left is a one. So got the right answer. Eric's answer was right. Okay. So you're able to apply this for useful, useful real life examples. Okay, I'm done. I'm going to watch my movies. Okay. They don't open till the second. So, and that's, that's the Jackie Chan film. So we're not going to watch that one. All right. It's a good movie though. I already watched it. Yeah. I didn't tell you the name. It's, should I say it on video? Yeah. There's a new Jackie Chan film. It was already out in Asia. So I watched it. It's out on the second tier. You should watch it. It's funny. All right. Yeah. Those were all actual movies. I pulled them up off the movie opening website last night. Okay. So let's, let's go back and look again at floating point. And I want to go through this and do a couple examples, but remember that we use 32 bits to store a floating point number in IEEE floating point. We've got a sign bit, we've got an eight bit exponent and we've got the 23 bit mantissa and the meaning for most of the numbers is given by this equation here, right? So we have the sign bit, which tells us positive or negative. We've got 23 significant binary digits. And then we've got an exponent that lets us run from about 10 to the negative 38, which is two to the minus one 26 up to 10 to the 38 or so. That was review. I mentioned, I mentioned denormalized numbers, infinities. Those are not things you need to know for exams, but I'll tell you a little more about them. Cause we do have a little time. So I added some starred, I added some starred slides. So this means not testing material up here. So if you see stars in the slides, just like if you see the starred sections of the notes, that's just so you can kind of learn ahead if you want to. So if you're excited about the material, you want to know more now, it's stuff you'll probably see in later classes, but you know, feel free to read it. Feel free to look at these slides. If you feel like you've, you've seen enough and you're getting stressed about exams, don't worry about this stuff. It's not going to be on there. So IEEE floating point was allowed, was designed to allow you to, to have solutions to problems like dividing by zero. So if you take a positive number, you divide it by zero. There's actually a representation for infinity. There's a representation for negative infinity, and there's a set of representations, anything with a non-zero mantissa and exponent 255 called not a number. So what is that, what is that good for? For one thing, if something goes wrong with your computation, you can kind of look at where the not of numbers, where the not a numbers are and figure out what went wrong. You can also ask things like, well, if I write some set of mathematical equations, let's say that I don't know one of my original variables, what are the outputs that depend on that variable? Rather than looking through the code and trying to understand it, you can simply set that input to not a number, run your code, and then whatever outputs end up as not a number, those are the ones that depended on that input. So there's some useful things you can do from kind of a software debugging point of view. You get not a numbers when you try to do things that don't make any sense from a numeric point of view, like you take infinity and multiply by zero. So it might've been had you not taken the infinity first, that this would be some finite value. But if you tell the computer multiply infinity by zero, it doesn't know whether it should give you one or five or zero or infinity. And so it gives you not a number, right? To say, well, I don't know what the answer is. But has that one useful extension. The other extension that I mentioned briefly because it gives you a zero, but it's the idea of denormalized numbers. So we talked about, go a couple of slides back to remind you. We talked about this implicit one, right? That the only in canonical scientific notation, normalized scientific notation, the only digit that we go at the start is a one because it's written in binary here, right? It can't be a zero, so it must be a one. Now that doesn't let you write zero. So that's one issue. But it also has this issue that if I were not to have denormalized numbers, my smallest exponent would be zero minus 127, right? So this would be the smallest number at the closest I could get to zero. So plus or minus two to the negative 127. And then I would have, if I just had a three bit mantissa, just for illustration purposes, I'd have seven digits spaced out to the next, I'm sorry, seven bit pattern spaced out to the next exponent at two to the minus 126, right? So the numbers I would be able to represent without denormalization would look like this around zero, actually would not have a way to represent zero either. So that's a different problem. But these are the numbers that I would get. Instead, what we do is we denormalize, which means instead of having the implicit one, if the exponent is zero in the IEEE format, then what happens is you have an implicit zero, right? And so then the representation represents the numbers as I've drawn them here. So you can see it just takes these same bit patterns and it spreads them out. And it gives you actually two different patterns, plus or minus zero, right? So it gives you a nicer set of numbers around zero. So that's why they included in the spec. And you certainly need some kind of representation for zero. And again, the representation for zero is the all zero bit. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. That's right. That's right. And so there's also an offset issue that the exponent for denormalized numbers is still two to the minus 126 instead of two to the minus 127, but the bits themselves then go down below that level because there's a leading zero instead of a leading one. So visually, there are 23 bits of mantissa, right? But that would be 8 million lines for me to draw here. So it'd be hard to understand the diagram. So this is what the three bit mantissa. You can see it a little more clearly how it works. But the idea is to get numbers spaced around zero instead of having numbers be scrunched up around the smallest leading one. So that's the denormalization idea. And that's why they put that into the spec. Okay, so I wanna go back and just do an example. There's an example in the notes, but let's not do that one. That one you can look over yourself at your leisure. Let's instead pull up the tool and we'll do an example. So we'll go in both directions. We'll do this one first maybe. So if we wanna convert from decimal to IEEE floating point, what we'll do is take our decimal number and convert first the integer part to decimal. You know how to do that, I think, from very start of class. And then we'll take the fractional part and convert that to decimal. That'll give us binary scientific notation. We'll normalize that. And then we'll take the three pieces, the sine, the mantissa, and the exponent, and we'll put that into our floating point format. So before we go off and do that, here's the math behind it. So if you take your fraction, again, you can write your fraction using a polynomial. So it would be the part after the binary point. So 0.101 or whatever. So those terms after the binary point can correspond to inverse powers of two. The first digit is the halves digit, the quarters digit, the eighths digit, and so forth. So in order to take this formula and get the individual A terms out, what we need to realize is that, well, it's a fraction, but if we multiply it by two, then it can become bigger than one. So fraction, I mean something between zero and one, or zero and smaller than one. But if we multiply it by two, it can become bigger than one, but that can only happen if this one, this term here is a one. Otherwise, all of these others, a quarter plus an eighth, et cetera, those don't add up to one. And so if we multiply by two, the only way we'll get something greater or equal to one is if A minus one is equal to one. So we can just multiply our number, our fraction by two, and that'll tell us A eighth minus one. So then we can subtract that term off, and we can do the same for A minus two. Then we can subtract that term off and do the same for A minus three, four, so forth. So let's go do that, not for this one. Okay. Let me make sure that it's gonna let you see what I'm doing. Okay, we'll go to representations and logic. All right, let's get a more intimidating looking one. So I'll just keep pushing new problem until we get something moderately long. Okay, how about that one? This one's a little easy because it doesn't have an integral part, but actually maybe that makes it a little more challenging. Okay, so let's figure out how to turn this into IEEE floating point. So we got 0.5625. So our integer part is zero. So let me go over to Notepad. So the fraction then is 0.5625. And so we'll multiply that by two. And what do we get? 1.125, all right. Looks right, I think it's right. Okay, so that's our first round. And you can see that's bigger than one. So that tells us A minus one is one. Okay, and then we'll have 1.125 minus one, subtract off the A minus one. That'll give us 0.125. Multiply that by two. That gives us a quarter. Now that one is less than one. So that means that A of minus two is what? Zero, right? Good. Okay, so I'd subtract zero. So let me write it out even though it's not gonna do anything. Oops, sorry. So my 0.25 minus zero. So I'll just be explicit. I do have to subtract the A minus two, but it's zero, right? So you don't really have to do this part when you do it yourself. I just wanna make it clear what we're doing. So two times 0.25 is 0.5. What's A minus three? Okay, so I'll just subtract the zero again. Two times 0.5 is one. So what's A of minus four? Good. And one minus one is zero. So, okay. So there are my four bits after the binary point. So the integer is zero. So I have 0.1001, and that's my fraction. Let's write that down here. So if I put that in binary scientific notation, what is it? Yeah, so I need to shift the binary point over here, right? Cause I need the leading one. So it'd be 1.001. And what's the exponent on the power of two? Negative one, like that. Okay, all right. I'm sorry. Oh, I screwed it up. I'm sorry, thank you. Okay. Yeah, same thing, right? All I did is shift the binary point over by one and put the exponent of negative one on the two. Good. All right, so now we can go back to our tool. And what's the sign? Zero, okay. Oops. The exponent then was negative one. And remember that we need to have negative one plus 127, right? So we should have 126. Right, cause we're gonna subtract whatever number we put here to get the exponent back, we're gonna subtract 127. So to go in this direction, we'll take the exponent minus one, add it to 126, and that'll give us the exponent value that we write into the floating point format. 126 is 7e. So this, unfortunately I had far too much experience translating decimal numbers into binary, but wouldn't expect you to do that in your head or anything. But 7e is the exponent. So let's go fill that in. Oops. There we go. So 01111110. Okay, ignore that last one. We can actually go check the answer now to see that we've got the exponent right. So the green means that we got it right. So we filled in the sign, filled in the exponent, those are both correct. And then for the bits, let's go back and look at our answer. Again, remember the leading one is implicit. So this is not represented in the floating point format. These are the bits of the mantissa. 001 followed by a bunch of zeros. So I'll go back to the tool, put in 001, and then hold zero down for a while, and check the answer. And ta-da, it was right. So that's it. So hopefully it's straightforward enough that everyone feels like they could do it themselves. We can also go in the other direction. So you can go push decode, and you get this rather intimidating looking bit pattern. Well, you'll notice there aren't a heck of a lot of, aren't a heck of a lot of one bits, right? And so it's not gonna be nasty to you. There won't be too many one bits in the tool. So if we wanted to translate this, let's see. So the first step would be to turn this into scientific notation. So what do we have? So what's our sign, positive or negative? Positive. And what's our exponent? This one's the 128 bit. That one's the one bit. So that's 129 minus 127. So two, right? Okay. And then mantissa, we just have a one. So let me go try to write that all down. So go up a little bit here. So we have 1.1. First one's implicit, right? And then the mantissa was one followed by a bunch of zeros times two to the two. You said it was the exponent. So maybe I'll translate that to regular binary. So that's one, one, zero. That's it, right? What number is that? Six, good. Six, correct. So it'll give you kind of a hint because it'll tell you how many digits you need for your typing, but you can do those exercises until you're happy and comfortable, which maybe is already the case. So you can use it to go back and forth and do those exercises. Do you feel comfortable with that? Feel like you could do it? How is it six? Okay. So let me highlight parts. Yeah, so there's this implicit one, right? This part is implicit. And then this part was the mantissa. There was just a one bit in the mantissa. Let me go back and show you that. So the mantissa here are the blue section of the bits and you can see it's all zeros except for that one, one. And so the binary scientific notation, there's the implicit one followed by the mantissa, which is just one, one. So 1.1. And then the exponent, remember the 128 plus the one bit. So that's 129 minus 127 is two. So that gave us our times two to the two. So that's where our scientific notation form came from, which is here. And then all I did is I shifted that bit over by two for the exponent to give myself one, one, zero, and then translated one, one, zero, which has no fractional part. So it was a relatively easy problem. Yeah. Yeah, sure. Let's get one with a fraction, right? I think that'd be better. Did you have another question? Yeah. Yes. The question is, there's a negate on the tool and what is it checking? Yes, it's checking that you were paying attention in class. Scale is kind of similar. Yeah, so how do you negate a floating point number? Well, you flip the sign bit and then you type all those others. So that's why there's lots of ones and zeros there, because it should be pretty easy to copy them. Yes. So hopefully you don't use this one too often. I mean, you just need to flip the sign bit. Scale too is, if you think about this a little bit, so it does things like asks you to multiply by powers of two or divide by powers of two. So you need to figure out how big a power of two and then just change the exponent. So some are easy, some are more challenging. Let's go back and do, let's see, oh, this one looks long. OK. Yeah, the question is whether I can do that fraction in my head. OK. I have a calculator. So all right, so let's do this one. So let's see, what's the exponent? That's the same one we had before, right? 126, so negative 1. OK. And then the sign, positive or negative? Negative, good. And then for mantissa, we've got an implicit one followed by four ones. Let me go put that in. OK, let me fill some space. Space. OK, so implicit one, four ones in the mantissa, exponent minus 1, and minus sign in front, I forgot. Did I forget anything else? Yeah, yeah, yeah. So this is just scientific notation, right? So if you were to change this into non-scientific notation, which we'll do before we convert it, you shift the binary point over left by 1, and then you'd put a leading 0 to make it look like a normal number. So this will be minus 0.11111, which is 31 32nds. Is that right? OK, so I'm going to cheat. And it's not really cheating. I don't really care if you know what 31 32nds is. 31 divided by 32, 96875. So this is equal to negative 0.96875. And we'll go over here and say negative 0.96. OK. Make sense? Yeah. OK, so the part without the calculator was this. Halves, quarters, eighths, sixteenths, 30 seconds. So this is 31 32nds. Yeah, yeah, the fraction is 31 32nds. Yes, this is a half, a quarter, an eighth, a sixteenth, and a 32nd. Yeah. Yeah, so all I did is I converted that to 31 32nds. I think someone in the audience said that's 31 32nds. So yeah. So I took that and took the calculator, 31 over 32, and it told me this answer. If you happen to know what a 32nd is, and you can subtract it from 1, you can do it that way too. I'd have to think about it for a minute. OK. All right, let's go back then. Let's go back and we'll skip over this part. So let's do this one. OK, so here's a trick question for you. What is that? Anyone? Now you're nervous? Do the minus 30? OK, good. What's this one? Really? That's not what my computer told me. OK, I'm hearing that makes sense. I mean, to me, I'm not sure it makes sense, but that's how floating point works. So let's explain why it works that way. So our first sum in that second problem was 2 to the minus 30 plus 1. So you want to put the 1, your exponent's got to be 0, right? To hold that integer 1, you need to have that be the leading term in your binary scientific notation. Well, so we got 23 mantissa bits. What are those? Those are powers of 2 down to 2 to the minus 23. So if you add in 2 to the minus 30, it's got no place to put that, right? So 2 to the minus 30 just kind of falls off the end. It's too small. So 2 to the minus 30 plus 1 is 1 in floating point. And then, yeah, 1 minus 1 is 0. That's exactly right. So floating point is not associative. So this can be a problem. It's a very hard problem, actually. I've seen people whose work is computational science sometimes not realize that this kind of problem is giving them wrong answers. I could tell you actually quite a few stories about that. There are fortunately some very good numerical analysts on this campus over in CS. So if you're interested in understanding exactly how to deal with these kind of problems, I would strongly suggest you take a numerical analysis class from them. My Keith, who used to teach them, but he's retired now, was also one of the best teachers on the campus. So I think there's some good classes you can take. Yeah? AUDIENCE 2. Is floating point associated with speed? So the question is, does the non-associativity affect speed? No, the non-associativity, I'm sorry, the speed is due to the fact that you're simply doing a much more complex operation. So if you think about, if I were to ask you to add two floating point numbers, what would you need to do? You'd have to look at the exponents, line them up, add them up, decide how to round. So there's actually quite a bit of complexity. And because it's more complicated when we build hardware, it tends to be slower. So, yeah? AUDIENCE 3. What happens to the bits that have some power? Yes. So kind of the point is that this can't be stored together with the number one, because there's only 23 bits of MENTISSA. So when you add those two in a floating point adder, the output has to discard that 2 to the minus 30 term. And anything else in those other ones as well. Now there's one slight difference. If you had one at 2 to the minus 24, then it has to decide whether to round up or round down. But if it's not 2 to the minus 24, then it's going to typically just throw it away. I guess if you round it up, maybe it would add it in. Yeah, so there's a rounding direction. I don't want to spend too much more time on this, but there are five different ways to round things in IEEE. I think it's five, maybe it's four. But people were seeing in one computation of weather prediction, seeing 30% differences in the final answers. And they traced back why. It turned out one machine rounded up, the other machine rounded down, down at the negative 23rd power level. So they can explode. They can be sort of chaotic behavior if you're not careful with your applications. All right, so here's hexadecimal. I want you to memorize this bit pattern. Do it quickly, because we're now running short of time. Computers always use bits, but for us humans, we can use hexadecimal, base 16. So you got that bit pattern? Good? Good. You're all ready, right? Got it? OK. All right, so here's hex. 16 digits. It's base 16, so that means each digit represents four bits. So each of the, we add in a through f, so a is 10, b is 11, so forth. And it's just a way to help us humans. So to make it easier for us to deal with bit patterns, because we can look at just digits instead of a lot of zeros and ones, which are hard to remember. Although I know you're good at it, because you memorized that bit pattern. OK. Ha ha ha. You're making it up. Ha ha ha. Ah. Ah. Terrible. Terrible. OK. So try it again. This time do it in hex. When we write hex, we usually have, in human form, we usually put some extra things. Because if I just wrote 1, 3, 5, 6, 7, you'd think I meant decimal. So usually we'll put something else in front of it, like an x, for example, to say, hey, this is hex. So this is all base 16 numbers. In C, we'll put another 0 in front of the x. But in Pat and Patel terms, just put an x in front. So that's hex. How do we represent text? Text was historically represented using an 8- or a 7-bit code called ASCII, American Standard Code for Information Interchange. But it was basically designed to represent English. So we had English letters, upper and lower case, Arabic digits, punctuation, some special symbols, like a dollar sign, a pound sign, hash mark, if you want to call it that, control characters for terminals. So people designed this code 50 years ago and kind of standardized it. And that became the thing everyone used for human text. Once most machines had 8-bit bytes in them, then most machines said, well, gee, we can do something with the other 128 patterns. So there were these extended ASCII character sets for graphics and things like that. But those more or less were not standardized, meaning that every manufacturer had a different meaning for those extra 128 patterns. There were standards, but no one really built machines to them. So other languages, other human languages, kind of caught on after Illinois invented the browser in 93. So MIT's media engine will tell you differently, but you should know the truth. Oh, well. MIT puts a lot of money into making you think that. But you're an Illinois student. So Unicode is the 16-bit modern form that includes most human languages. So Unicode will capture most other languages in the world. And that's the other one that probably I'd want you to know about. We'll try to differentiate in our class between representation and data type. I may have mentioned this before, but I want to use representation to describe a way of describing or turning something like signed integers into bit patterns, but not necessarily for a specific length. Whereas a data type will have a specific number of bits. So for example, we can talk about 32-bit unsigned or 64-bit unsigned. Unsigned is the representation. The 32 and 64 bits, those would be data types. The reason I want to make that distinction is when you get into higher-level languages, every variable that you use will be associated with a data type, meaning a specific number of bits. But the representations, in many cases, are just ways of encoding information into some variable number of bits. I'll show you this taxonomy that I dreamed up to try to help explain what I mean. So they're bits, and we use bits to represent everything. So whatever you want to represent in a computer, everything we've done, and vegetables as well, or ice cream flavors, you're going to use bits. For everything you might want to represent, there are different ways to represent them. So for non-negative integers, we looked at unsigned. We looked at a couple of ways to do just general integers. There are actually many floating point formats. IEEE is kind of the more modern standard that all the computers implement today, but there were other forms. There's fixed point as well. There's ASCII. There's Unicode. And then there's data types, where we say, OK, fixed number of bits. So for each of those, there are particular data types that we have particular number of bits. So this is kind of my attempt to try to help you organize some of the ideas that we've been playing with in the last few days or the last couple of weeks. All right. So most of the time, when you open a text file like you did in your lab, for example, everything in there is going to be either an ASCII or Unicode. So human text is generally going to be represented either ASCII or Unicode. What you type is going into ASCII, going into the computer in that form. Text is printed for you to read, comes out in ASCII on your monitor or in Unicode. But the computers don't understand what those bits mean. So when bits go in and out, they're just bits to the computer. So for example, if you tell a computer, hey, I want you to add the ASCII character for 3, the number 3. But it's the number, right? It's the ASCII digit 3. I want you to add that to 2. What do you think the computer will do? It'll add the bits. You told it to add the bits. It'll add the bits using an adder. You didn't tell it it was ASCII. You said, add the bits. OK. I know how to do that. So, oh, sorry. I was going to let you help me. 1 plus 0. 1, good. 1 plus 1. 0 carry the 1. 1. 0. 0 carry the 1. 1 carry the 1. You know what that one is? No, it's not an overflow. It's the letter E. You thought natural log was hard. Natural log is far. OK. Yeah, don't tell computers to do that. The right way to do that is you need to do something in software, probably, to convert your ASCII to 2's complement or unsigned, add those two numbers using an adder at that point, and then convert it back to ASCII if you want a human to look at the answer. So there's more steps involved to get it right. Yeah, there are other classes where, sadly, I've seen people struggle with this, where they write this kind of code in high-level languages, and they can't understand why the computer's not doing what they wanted. Hopefully, none of you will ever have that problem. Wow, good job. Excellent. OK. I think you get the point. I won't really give you any exercises to memorize this thing. Sorry, it's not a learning objective. But it's a lot easier. It's a lot easier to remember fewer digits than to remember lots of 0's and 1's and what order to put them in. Oops, wrong button, sorry. All right, so one more thing before we wrap up for the day. So this is it. And then we'll do C coding on Friday. So remember this overflow condition? We could give it a name. Let's call it V, that we developed for 2's complement. So I said that, well, there were two cases. And we actually wrote it originally in words. And then we wrote the Boolean expression for it. So you remember that we had two ways to overflow. If we wrote our addition this way, and A was the sine bit of one operand, B is the sine bit of the other, and then S is the sine bit of the sum, well, if I take a 1 in A, that means A is negative, and B is negative, and the sum is non-negative, something went wrong. Add two negative numbers, get a non-negative number, something went wrong. Or if I take a non-negative A and a non-negative B, and I add those up, and I get a negative sum, something went wrong. So those are the two cases that we had in overflow. And I said you should go read the proof. You did that, right? OK. In the other lectures, they were told a different formula. They were told that if I instead look at the carry out of bit n minus 1, the one that would feed in to add to A plus B, if I look at that and I XOR it with the carry out, that gives me overflow. So my question for you is, well, are those the same? We could use algebra. Want to use algebra? Not really that fun. I did it. It's not that fun. What about some brute force here? Brute force, yeah. Let's do a truth table. So we can calculate, if you think back to that sum, if I know Cn minus 1, I can add that to A and B. That'll give me S and Cn. If I add those three digits, I get the other two. So really I only have three variables. So that's only going to be eight lines. Let's do the truth table. So here on the left, I have the different possible values of the A bit, the sign bit of the first one, the B bit, and Cn minus 1. So if I add those three together, that'll give me a sum and then the carry. So what's 0 plus 0 plus 0? 0 carry 0. What about 0, 0, 1? 1 carry 0. 0, 1, 0? 0, 1, 1? 1, 0, 0? 1, 0, 1? 1, 0, 1? Good. 1, 1, 0? Good. And 1, 1, 1? OK. So now we can go calculate what we used as overflow. So if we have A and B the same, but S different than A and B, then that's an overflow. So the first line, we have A and B are 0, but S is also 0. So that's not an overflow. Here, a second line, A and B are 0 again, S is 1. So that's an overflow. Here, A and B are different, so we don't have to look at S. 0, 1, 0, A and B are different. A and B are different again, not an overflow. Different again, not an overflow. Different again, not an overflow. How about this one? It's an overflow, right? A and B are 1, but S is 0. So that's an overflow. And what about the last row? Not overflow. A and B are 1, but S is also 1. So all the numbers are negative. That's OK. All right, so now XOR the CN minus 1 and CN for me. First row, 0. Second row, 1. Third row, 0. Fourth, fifth, sixth, seventh, and eighth. Good, so we're done. Same columns, right? We just proved that the two are the same. Just fill in the truth table and compare the columns. They're the same function. Don't need to do algebra. All right, so that's the message. In a lot of the Boolean stuff, you can do algebra. You can prove by manipulating algebraic forms, which may be easy for you, especially if you do it a lot. But you can often prove things by pure algebra. But you can also, in many cases, simply write down a truth table. And if you're talking about two or three variables, that's four or eight different things to plug in and say, well, are they the same or not? So you definitely want to pick the easiest and fastest proof strategy. And brute force, especially in these kind of problems, is often something you seriously want to consider. Because you can get it done quickly and easily and have a correct proof. So let me leave you there. I guess you're 45 seconds early. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\"},\n",
       " {'ECE120-2016-11-02-LEC-29-slides.mp4': \" handout. Is there anyone sitting that doesn't have a handout already? We kind of need them in the middle, so let me try to pass a few around. And also come grab some candy if you'd like some. These are $2.25 in back. Let's see. You didn't have one, right? Okay. Yeah, one of each, one on top, one on the bottom. All right, so let's go ahead and get started. Let me go through this. So we'll talk mostly about LC3 ISA today, and then we might spend some time doing an example. Otherwise, we'll work through the example on Friday, examples counting to 10. I'll show you in a second where all the code, I just put up some more code for the next week or two. I may add some examples to that too as we go. So there are two handouts. One is the LC3 reference sheet. That's what will be attached to your midterm three and your final. And the other is the counting example code that we'll work through together in class. Let's see if it will let me switch over here. Okay, so now you can see that. All right, so if you go to this links page, and you go to the bottom, I added this LC3 code examples. So somewhere in PDF, if you want to play with the code, you can download it from the binary version, meaning LC3 binary that you can then compile with a tool. There's also assembly versions. We're not going to talk about subroutines in our class, but I just put the subroutine version up there if you're interested. There are also PDF versions, so you can just look at the code if you'd like to. So you can click on any of those. Let's see, let me go back to this mode. Okay, so those are all on the webpage now. This one again, I just keep reminding you until the deadline comes next Friday. All right, so the LC3, as we talked about a little bit last time, LC3 has three different kinds of opcodes. So there are operations that use the ALU, there are data movement where we move bits to and from, well, between registers and memory, and then there's control flow where we'll conditionally change the program counter. So control flow, if you remember when we talked a little bit about C, we said, well, you can break things down in sequences. That's what we get normally, right? We add one to the PC and fetch, and then we just walk through memory and execute, execute, execute. But if we want to do something like a condition or a loop that we do in C, well, we need some way to change the PC, right? It can't all be one line, a straight line of code through memory. So that's what those will be used for. So let's see, on Monday we talked a little bit about the operations, we reminded you that, well, the ALU and the LC3 data path only does these three things, add, and, and not on 16 bits each. All three of them, rather, have a source register and destination register, and then add and and have a second input operand. We said, well, there's two choices. We can either have another register, which is what you'd seen in detail in some of the earlier examples, or we can have an immediate number. And so we looked at how that got encoded. There's the opcode, which is either one for add or five for and. There's the destination register, these three bits from 0 to 7, and then source register 1. And then if mode bit here, IR5, is equal to 0, then that's the second register operand. So there are these next two bits, IR4 and 3, also have to be 0. And then the last three bits of the instruction specify the second register. So if you have this mode with this bit 0, IR5 equal to 0, then whether it's an add or an and, it takes source register 1, reads those 16 bits, source register 2, reads those 16 bits, does the operation through the ALU, and then writes the result back into the destination register. On the other hand, if the mode bit is a 1, then the second operand is an immediate value, which means that it's a number stored in the instruction. And so that number, since we only have five bits left, is a 5-bit 2's complement number that gets sign extended out to be a 16-bit value. And so when I say it's 2's complement, that means before you can put it into the ALU, you need 16 bits, so we're going to sign extend it to 16 bits. All right, and then we talked a little bit about what good are these instructions. So we said, well, if you want to add small numbers, you'll often do that when you're running a loop, right? You're adding one or subtracting one. You can add other small numbers too, but the range is pretty limited. If you want to add a bigger number or subtract a bigger number, then you need to use two register inputs for your add or your and. You can also mask out low and high bits of a particular register. So you can say, OK, just give me the low bit, just give me the two low bits, set the low bit to 0, so put two low bits to 0. Or you can put 0 in a register. So this one's kind of the most useful thing for and is just setting a register to 0, because we often need a 0 in a register. And then I think this was the last one we looked at on Monday. So this is the NOT encoding. NOT is opcode 9, destination register, source register. Since NOT does not have a second input operand, we just set all the rest of the bits to 1. So let's take a look at the data path now and see how we set up the data path to execute these operate instructions. So over here is source register 1. So there is a little logic that's not shown in this diagram. It's in the notes, but basically those three bits out of the instruction are used most of the time to set the source register, which then comes out of this port. So whatever 3-bit register name we give the register file, it delivers that register to this output port on the right here, the SR1 output. And similarly, SR2 would then go into the SR2 input of the register file, and SR2, whatever we've picked, will come out on this left port, read port of the register file. Now that's going to be true regardless of which operand mode we're using. As you'll see, we're going to read it all the time, and if we wanted the immediate value, well, we'll just throw away this answer. So the other thing that we'll always do is actually look at IR4-0, the 5-bit immediate opcode, sign-extended here. And then you can see this MUX over here. We're going to feed both the immediate value and source register 2 into the MUX, and that's the point at which IR5 will be used to say, well, which one do you want to use? And so if IR5 is 0, this input will get forwarded to the output of the MUX. If IR5 is 1, this input will get forwarded to the output of the MUX. So in hardware, typically, we'll actually look at both answers, and then we'll just pick one with the MUX. So there's SR2 MUX that decides which of those two is fed into the B port of the ALU. The ALU is then configured here with this ALUK control signal. And you'll notice that each of the three opcodes here have two initial bits. So for example, we could just feed IR15 and 14 into the ALU to decide what we want to do. That's one way to do it. So once we've set this all up, now we get the right answer. It comes out. It actually would go out onto the bus in one cycle and come back into the register file. I eliminated the bus from the figure. But you can see where DR gets fed into the register file. So when the rising clock edge comes, this answer is going around the bus and then being latched into whatever register we picked for the destination register. Now since this is a clock synchronous sequential circuit, you should realize it. But I'll just go over it just to make sure that you don't get confused thinking about it at the higher level. If your source register and your destination register are the same, that's OK. Even if both source registers and destination registers are the same, that's OK. Because when the rising edge comes, that's when the change happens. So just like a finite state machine, we make sure that the clock skew in the circuit is small enough that all of the flip-flops see the rising edge at the same time. So the old value and the new value, even if we're feeding one back into the other, it doesn't make any difference. All of the clock edges will happen at the same time. And when the register changes, it'll stop looking at the input. So when the register changes, then the output will change also. But that doesn't matter. We'll have the new value latched. And so it's safe to have one source register and have the same destination register. You don't have to worry about it. So let's take a look at loads and stores then. So data movement instructions are the next kind of instruction with LC3. And we're going to actually have four different addressing modes. There are loads. So a load, remember, takes data out of memory and brings it into a register. There are also stores. Stores take data from a register and put them somewhere in memory. So whenever we want to do that, well, it's easy to name the register. We need three bits to name a register. How many bits do we need to name a memory address? 16 in LC3. But we only have nine left. After we say we want to do a load or store of some sort, that takes four bits. We've got to say which register we want. So that's three more bits. We have nine bits left. So in fact, with most of the ways we're going to approach this problem, we can't go anywhere. We can't go to any address. We're going to have to somehow use bits from somewhere else to specify our address. But these nine bits with the different types of loads and stores will generate our address for us. It'll tell us how do we get the address for the load or the store. So let's take a look. So here's the first one. The first addressing mode is called PC relative. So what that means is we're going to use an address that's near the PC. So we're going to take those nine bits and say, well, let's start at the PC. And then we'll add that nine bit offset as a two's complement number. And that'll give us our address. So here's one opcode. This is LD. So LD says, well, take PC, add the immediate field here, nine bits of offset, sign extended to 16, add it to the PC. That's then our address. So go to that memory address, get the 16 bits. This is the load form. And bring those into the data path and store those in DR. And then the store form, of course, goes the other way. So you take for the address the same thing. So you see the address formulation is the same. So you take your PC, take your nine bit offset, sign extend that to 16 bits, add that to PC, and then use that as the memory address at which you store the bits in the source register. So same address generation for LD and ST. They just go in opposite directions. You could use this bit, IR12, the last bit of the opcode, as your memory rewrite control, for example. You'll notice as we go through the load and store style opcodes that in all cases, loads are zero and stores are one. Program counter. That's the address of our next instruction. It's a register. So wherever your address happens to be, remember fetch will increment it. So whenever you execute one of these instructions, PC will hold the address of the instruction plus one. But in general, it's a register sitting in the control unit. You will have to calculate the offset that you need here relative to the PC, which is relative to the instruction. So it's actually all of the PC relative instructions are relative to wherever the instruction happens to be. So it's very, very easy to do and very error prone because it's so simple. So you'll see as we write code, there's a lot of counting involved. So it's good that everyone here is good at counting because it'll take all the skill you have to stay focused. Yeah? So you need to know that PC, when it executes, holds the address of the instruction plus one. So you do need to remember that. And I'll go over that several times. In fact, very soon. Okay. So in fact, there it is. But I want to do an example just to make sure everyone understands. So PC is the value after fetch, right? When the instruction executes, that's when we evaluate this RTL here. And so it's the address of the loader store plus one. So for example, if I have a load at address 1480 in hex, and that load is destination register R3 offset nine. So this is just human notations convenient. So what would this instruction do? So if we go back and plug into our RTL, we've got memory at PC plus sign extended to 16 bits of hex 09. And then take that the memory at that location, store it to R3. So what is PC in this case? 1481, right? Because remember, after we fetch the instruction from this address, we'll also increment the PC in the same first fetch cycle. So PC will have value 1481 hex. So what's the answer? 148A, I think. So just make sure you don't think it's this. There are a couple of ways you can check, right? Once you write some code, you can go into the simulator and you can say, Oh, show me my code, make sure that whatever you did got the right answer, because it will show you the address. So it'll say load from this address when you tell it to show you the code. So you can check that your offset is correct that way. That's actually probably the best way to check is to have the computer check for you. But yeah, that's the easiest way. Okay. So time for quiz. So what's bits? Wow, you're good at this. I like this. 16 of them. Yeah. Okay. What's the next question? How do we name a memory address? That's good. Good. 16 of them, right? So what's the difference? 16 bits, 16 bits. If you were a computer, what's the difference between 16 bits and 16 bits? Nothing. Good. So I could, for example, say, well, 16 bits, it could be a memory address, right? And if I go to memory and I get 16 bits, well, it could be a memory address and I could keep going and going and going. So it's an important concept in software. And I'll come back to that in a second. But this indirect mode is going to do exactly that, but only do it one time. So what does it do? Well, it generates the address as if it were a PC relative address. But then what it does is it said, Okay, I'm gonna go to memory again. So here, what you can see is, well, we go to PC, we add sign extended immediate nine, just like before, just like PC relative. We go to memory and we get those bits. But wait a minute, there's another M outside of that. So those bits come back from memory, right? And then we say, well, that's an address. So we go again to memory using those 16 bits as an address. And we read memory again, we get a different 16 bits. Those are the 16 bits we then store in DR. So instead of just going once, we then take the 16 bits we get back and we go again to memory using those 16 bits as an address. And then we get 16 bits back again. Those are the bits we put in the register. What about the store? The first operation here is a read from memory, right? We still have to go generate our address by adding PC to the sign extended offset. Then we go to memory to get 16 bits. That's a read operation. Then we use the 16 bits we get back to do the store. So we do one read and one write for the STI. We do two reads of memory for the LDI. Yes, I can. Good call. All right. So why did they define this instruction? It's purely to make sure you understand what we talked about. 16 bits can be an address. An address is called a pointer in software. It's a really important concept for pretty much all of the higher level languages like C, C++. They're actually used in some level in other languages like Java, but you'll never know it. So they try to hide it from you. But in C and C++, you use pointers all the time. All of your data structures will be based on pointers and all pointers are as memory addresses. So if you understand what's a memory address, then you understand what a pointer is. How would you do recursive indirect? Well, I'll show you something in a second. You mean keep going and doing it? Okay, I'll show you another instruction in a second. Let me make sure. So you should realize this and indirect does it once, right? Go to memory, get 16 bits, use that as an address for your load or your store. Okay, so here's another one which you've actually seen. Once you get some memory bits into a register somehow, then you can use your register as the address of memory. So if you want to keep doing this as Daniel asked, you can use this instruction instead. So what is base plus offset mode? Well, your base is specified by another register. So now instead of only being able to access memory near the PC, right, plus or minus 255 or so, now you can use 16 bits of another register to generate your address. You can still add this six bit twos complement offset. So what we'll do is we'll take that six bit twos complement offset, sign extend it to 16 bits, but add it to some other register that's specified in the instruction. And that will give us our address. So then we'll go to memory, read 16 bits out, store that in DR. So for example, if you wanted to leverage the continued indirection, and often in software, you will build pointer based data structures where you might have to chase down them, you know, even a few hundred times for bigger data structures or thousands of times. But what you can do is put those bits that come back from memory in a register and then use LDR to go get the next 16 bits, put those in a register, use LDR to go get the next 16 bits and keep going and going and going and do what's called dereferencing your pointers in the software language for those of you who have done that. And the store side then, same address generation, take the offset, sign extend it to 16 bits, add it to your value of 16 bits from the base register, use that for the memory address, put the 16 bits from the source register into that memory location. Alright so how do you actually get an address into the register in the first place? So one option I'll show you in a second is a fourth addressing mode. You can also use load or store but you'll have to put data near the current instruction, right? The things I've showed you so far, other than LDR, STR, which then sort of begs the question of well how did I get some other address at all into the register so that I can then use that LDR, STR instruction. So those allow you to put data nearby and then to load those data into the register using LD or LDI. But if you want to just put an address directly into a register, there's a fourth addressing mode known as immediate. So here's an immediate value and what we'll do is generate the address in the same way that we did with PC relative addressing mode, but you'll notice there's not actually any memory access. So this is called load effective address, or LEA, and all it does is, so address is the same as PC relative but the memory is not accessed. So it's not even really a data movement instruction. Just generating an address, putting that address into the register, into DR. We can then use LDR to access adjacent memory locations using the offset. So this is the fourth addressing mode. There is no store form of LEA because it's not really even touching memory. So it's just loading the address into a register. Any questions on this? All right. Okay, so let's take a look in the data path. So first thing I want to show you is PC relative addresses. So up here you can see the PC is coming around and going into this MUX down here. So the PC goes along these wires. This is not the bus, right? So we're not using the bus for this. Goes into that MUX and then goes into the adder. So when we want to generate a PC relative address, sorry, I should have told you we'll configure this MUX to forward the PC input. Here's sign extended IR 8 to 0. So these are the low nine bits of the instruction. Those are sign extended to 16 bits. Then they go into this MUX, which we also select for PC relative addressing. We select this 8 to 0 sign extension. So those two then get added together. That's where the addition happens in this adder. PC plus the sign extended immediate nine field. That then comes out of this adder and goes into the MARMUX, which is then sent, forwarded that input onto the bus. So that goes out into the bus and goes into the MAR. So when we want to generate a PC relative address, these are the pieces we use in the data path to generate the address, the PC relative address, send it out on the bus into the MAR. Then we can simply tell memory, go read or go write. If we want to do a store, we'll put the bits into the MDR next. Those also have to go across the bus. Then we'll tell memory to do a write. If we want to do a read, we've got the address there. So we'll tell memory, do your read. And then we'll take the bits out of the MDR, put them across the bus into the destination register. Here's the data. So for a load, the MDR, after memory is told to read, will be copied across the bus and then stored in the register file. For a store, the ALU actually has a pass. So we'll take SR1 and we will pass it out through the ALU, ignoring the B input. So there's a fourth operation of the ALU, which was just give output A and put that onto the bus to move it to the MDR, which we can then tell the memory to write at the address in the MAR the bits of MDR, which is the source register. Make sense? Andy's wearing off, isn't he? All right. So LDI and STI, how can we do that? So there we're going to have to get 16 bits back in the MDR and that's going to be our address. Well, that's actually not too tough, right? So this is zoomed in on the bus near the MAR and MDR. So all we have to do is say, well, take the MDR after we do the read and copy it across the bus into the MAR and then we can do our load or store, right? Our LDI or STI, the second step is either storing or loading. So once we've gotten the first read set up for the LDI or STI, the second step, another read for an LDI or a store for a STI, we simply need to move these bits that we've gotten back from memory into MAR. And then for a store, we would use the previous mechanism to put the bits we want to write into MDR for a load. We just go ahead and exercise memory after setting up the MAR and then move the final result out into the destination register. All right. So one more, which is the base plus offset mode. So in this case, you can see here's the base register that falls in the same place as SR1. So that now comes out and instead of forwarding the PC from this address one MUX, we forward SR1. And so that comes in here. You can see the sign extended five to zero piece also of IR0 also goes into address two MUX. So we then pick the six bit sign extended field from the instruction, add that to the base register that gives us our base plus offset. And then again, that just goes through the MARMUX, gets selected to be put out on the bus, goes around the bus to the MAR. All right. Okay, so that's it for data movement. So the last kind of instruction is for control flow. So after we execute, so far what we've seen is we executed some address, call it A, and then the address is stored in the PC that gets incremented in the first phase of fetch. So it'll store A plus one. So after we finish our instruction, we say, well, let's go get another instruction. Well, we go to A plus one. And then in first stage of fetch, it'll get incremented A plus two. Then when we finish the instruction, we'll say, okay, let's go get another instruction. And I'll start looking at A plus two and so forth. But what about things like if statements and loops? We need some way to be able to say, well, I don't want to go just get the next one in memory. I want to go somewhere else because I want to have the ability to branch. I don't want to be able to do a conditional test and then execute two different pieces of code or do a loop, right? Go back and do the same code again. So control flow instructions will conditionally change the PC. So I'll explain what the conditions can be now. The LC3 actually has three condition registers that I hadn't mentioned before. We call them condition codes, but they're really three one bit registers sitting in the data path called N, Z, and P. So these are based on the last value that you wrote to the register file. So if you do an add, that writes to the register file. If you do a load, that writes to the register file. It's actually only for the operations and the data movement. There's some instructions. We're not going to talk about the details that also write to the register file, but they don't set the condition codes, just the operations and the loads. So the three choices, well, it's some last value. Treat that last 16 bit value as a two's complement number. And then you say, well, was it negative? And if it was negative, you've got this N bit set. And if it was zero, you've got the Z bit set. And if those 16 bits were a positive number, then you've got the P bit set. So obviously, exactly one of these three bits is one in any cycle. Always, if you've got a 16 bit two's complement number, it has to be negative zero or positive. It can't be a combination of them or anything like that. So you've got exactly N or Z or P, one of those three. So here's a conditional branch. It happens to be opcode zero. What you see here is three choices. So when you write your instruction, you can pick, do you want to look at the N condition code or the Z condition code or the P condition code or some combination thereof? So I'll tell you a little bit later how we combine them. But once you make that decision, that gets fed into this branch enable condition. And then the branch enable condition, we'll call it Ben. It's a little register also, one bit register, is used to decide, well, should you change the program counter or not? And only if the branch enable is set is the branch taken, in which case the PC gets changed to current value plus this nine bit value sign extended to 16 bits. So when you do a branch, the first thing that happens is the processor needs to check, well, let me look at the last thing that was written at the condition codes. Let me see what you're asking for. And if you want to, if that sets the branch enable bit, then we'll take this branch by changing the PC. If the branch is not taken, if the branch enable bit is false, nothing happens. Branch does nothing. And then you go to whatever your current instruction was for the branch plus one current address. All right, so for example, if you have, we write the branch instruction as humans with the bits attached. So we might write BRNP. It's actually case insensitive with assembly code. But we write BRNP to mean, well, the N bit is a one, the P bit is a one, and the Z bit is a zero. All right, so how is the Ben calculated? Well, it's calculated actually in the decode state. So the other thing that happens in decode, in addition to just doing a transition into some sequence for that particular opcode, is we actually calculate the value of the branch enable bit. And it's calculated like this. So you take your negative condition code and you AND it with the bit of the instruction IR11 that says whether this branch instruction wanted to look at the negative condition code. And then you do the same for Z and the same for P. So you take these three bits and AND each one of them with the corresponding condition code bit. And then you OR those three together. And then that's stored in the Ben. And the Ben is then used to calculate whether or not you take the branch, whether or not you change the PC. So let me do a few examples with you. So the first one up there, BRNZ. So when would you take the branch? When would you change? Yeah, N or Z. The condition codes, remember, only one of them can be true. So N or Z, which generally you can interpret as not positive. So branch if it's not positive. What about the second one? Always, right? So you can write unconditional branches by just putting all three. One of those three is always true. So if you take all three together, it's always going to branch. What about BRNP? Yeah, not zero, right? Because we left the Z bit out. So if it's negative or positive, whatever the last value after the register, if it's negative or positive, you'll take the branch. Otherwise, you won't. So by convention, you might run into this. So I just want to warn you, if you type BR with nothing, you might think, oh, that just does nothing. Well, no, by convention, BR means unconditional branch. And so if you type BR into one of the LC3 tools, you're going to get BRNZP. Yeah. So remember, let me go back to this. So whenever you write something into the register file, we're going to set the condition code. So the reason is, when we want to test, if we're counting, for example, let's just make it easy. Let's say we're counting down, and we're decrementing our register over and over again. That add instruction will generate a result that's written back to the register file. And so we can test, well, did we reach zero yet by checking when the Z flag, the Z condition code goes high. Because before that, presumably, it's a positive number we're counting down. And so until we reach zero, the P flag will be set. And then on the instruction that generates the one to zero transition by subtracting one from that register will generate the Z condition code instead, because we're at zero back to the register file. So anytime we write back to the register file with a load or an and, an add, a not, then we're going to go set one of these three condition codes based on the value that's written back to the register file. Trying to remember if I have the data path in a convenient spot. I don't think I do. Okay. Ah, here's a data path. So you can actually see it down here. I wasn't going to highlight this for you, but you can see the condition codes down there. There's also a control signal to tell the, tell the data path to load these three. It's not shown here. This actually comes straight off the bus. So it's whatever value is going back to the register file across the bus, you can, you can also tell the condition codes to just look at that value and set one of the three bits appropriately. Yeah. Well, yes, it's deciding. So for not, so n does not need to, right? So if you want to know is a number negative, you don't need to look at all 16. Yeah. But for zero and positive, you have to look at all 16. So how can you tell whether a number is positive? Well it can't be zero. Yeah. So both of those two, I mean, you can use the same logic to make the decision, right? You look at it if it's zero, and then if it's, if it's not zero, and it's not negative, then it must be positive. So yeah. That's right. Yeah. Yes. NZNP, exactly one of them will be one. You just changed a PC. Yes. So if you, if this, if branch enable is false, that means whatever the address of this branch is, PC will have been incremented. And so you will simply go to the next instruction in memory. If the branch is taken, you can change it to some other address. Right? You've got this offset encoded in the branch instruction. So you specify when you write the instruction, where should it go if this condition holds? And you specify the condition also by specifying the branch instruction. I'm sorry, on your code on the- Yeah. Yes. Yes. Yeah. So you have to put some other code elsewhere and then target that, that other piece of code with your branch instruction. Yes, that's right. That's right. And we'll do that a few times. All right. All righty. So let's take a look at this. So here again, let's look at the PC, the mechanism for changing the PC. So we'll take the PC. We're going to add again sign extended eight to zero, right? Because again, it's an eight, or I'm sorry, nine bit offset, sign extended to 16. So same nine bits coming out of the IR, sign extended, going through the address two mux. Address one mux is set to forward the PC. So we add PC to the sign extended nine bit offset. And that then will not go out onto the bus because it's not going to MAR, it's going back into PC. So this PC mux will be selected to have the output of the adder come through and will set load PC to one. So that'll change the PC. Now, actually, the new PC is only loaded on branch enable, right? So we'll change the PC if the branch is enabled, and we won't if it's not. Now the branch can only reach plus or minus 255, right? It's a nine bit offset, so minus 256 to plus 255. And then the PC is your branch address plus one. So if you add those all up, it's roughly, you know, plus or minus 255. But what if you want to go further away, right? What if you've got a lot of code, you couldn't quite squeeze that target where you want to go with your branch, couldn't get it close enough? What are you going to do? Well, there's another instruction for you. I won't tell you the encoding. If you want to use it, you can look it up. But it's called the jump instruction. I don't think you'll need to write this much code anytime soon. Yeah, so you can hop. Yeah, you can do that. But you have to have a place to put that other branch too. So yeah. Yeah, at that point, it's probably better form to hop over one jump instruction and use the jump instruction to go farther. Yeah, and change the branch condition the other way. Yeah. Yeah. No, so the idea is this is some arbitrary 16-bit value you can put in a register. So you can go anywhere with the jump instruction. You can put any address into a register. And so you can do a jump instruction to any address, whereas a branch can only reach about 512 addresses. Does that make sense? Yes, that's it. That's all. That's the RTL. You take your base register, take the bits, you put them into your PC. Because you then have to put the bits into a register before you can branch. So yeah, and this is unconditional. So in order to use the conditions, you need a branch. There's no conditions on this jump. It's just change PC to base register. Yeah. Yeah, so that's two important parts, actually. So let me make sure everyone understands that. Eric asked, well, why not just use jump all the time? Isn't it more powerful? Well, it doesn't have condition codes, right? So we would have the same problem we did before. We could make an infinite loop. We could go somewhere else. But we wouldn't be able to make a decision, right? Because jump does not have any condition. And the other issue is just that, you know, in order to go somewhere, you first have to prepare a register with the target, the new address you want to reach. So it's not quite as simple as, well, just do a jump. You have to somehow get the bits into a register. Then you can do the jump. All right. So one more instruction for the ISA. There are actually a few more. So if you want to read them, you can. You won't need them. Some you'll never need. Some you might use. JSR you'll use in 220. But for us, we want to look at trap. So trap is the last control flow instruction we'll look at. And what it does, from our point of view, it just invokes operating system services. So again, if you want more details, this is starred in a couple of senses. So this is 220 material. So if you want to understand how it works and you want to go look at the operating system code and understand devices, read chapters 8 and 9 of Pat and Patel. But from our point of view, it just invokes one of these operating system services. And which service depends on this 8-bit vector. So trap has opcode 1111. These four bits are 0. And then you can specify any 8 bits there. But there are only three useful 8-bit patterns for us. These, by the way, are page 543 of Pat and Patel. There are a couple others you could use if you wanted to. So one is the trap vector. I'm sorry, this is the trap vector number. So hex 20 is the getC trap. So what that does is it says, well, give me a character from the keyboard. So it will actually wait for the user to push a character on the keyboard. And it will give you that character back as ASCII in R0. So when you call this trap, you first need to make sure that you don't have anything important in R0. Because when that trap finishes, R0 is going to hold the ASCII character. So whatever bits you have there are gone. So if you're writing your code in the lab, make sure if you need to do a trap, you don't put important stuff in R0 before you execute a getC trap. The out trap then is kind of the opposite. It says, OK, give me one ASCII character, put that in R0, and then invoke trap 21 hex, and that will send that ASCII character to the monitor for you. So this is how you print to the screen as you send it ASCII characters using the out trap. Again, you need to have R0 free to do that. So you need to put the ASCII character there. You can't put it in R3 and a computer won't figure it out. You have to put it in R0. And then the last one, which you should always put at the end of your program, is, well, stop my program, go back to the operating system. So I think in the lab it talks about the difference between halt and end. And end will show up in assembly language. End tells the assembler that you're done writing assembly code, and halt tells your program to stop running. So you always need a halt in your program. So those are the three traps we'll look at. There's one side effect of trap I do want to mention, and this has to do with how it actually works. Anytime you do a trap, R7 will get changed. So when you write code in the lab for R class, the easy answer is don't use R7. You've got eight registers, don't use R7. Now you have seven registers. There are better answers if you really want, but you probably don't need eight registers for the kind of code you'll need to write for R class anyway, so just don't pick R7. If you do, anytime you do a trap, it'll change its bits, and so that'll be confusing. And also your code will not work if you cared about those bits. So this is the easy way to handle it for now. And again, if you really want to understand why and how it really works, you can go look at that. It's to do with the way it works. What it's really doing, and again, this is beyond the scope of our class, but what it's really doing is there's a routine that interacts with the I O devices. It's a piece of code. And so what the trap instruction really does is it goes to that routine, and it executes that code, and then it comes back when it's done. And how does it know where to come back to? Well, it puts the address of your code in R7. So now you all know. So if you want, you can play with I O registers directly. The LC3 simulator has all the LC3 OS code, so you can go read that by just listing it. You can download the source yourself if you'd rather read it in assembly language. It's all available to you. Yes. Yeah, you get a, the computer says you're not allowed to execute that instruction. But we're not going to, all right. So again, this is kind of out of the scope. Computers sometimes run into problems they don't know how to solve, and so they generate things called exceptions. So the hardware will say, well, I have some condition I don't know how to handle. So if you give it an illegal instruction, that's an exception. If you tell it to divide by zero, that's an exception. There are a bunch of others in real processors. You'll learn more if you take 391. But what really happens when that exception occurs? Well, the hardware literally goes to some other piece of software, just like a trap, and then the operating system says, well, what should I do? If you generate an exception in your operating system, typically it'll panic, right? And then, because the operating system shouldn't have buggy code. But if you generate an exception in your user-level program, typically the operating system will say, well, you're a bad user-level program and just terminate it. So, but the hardware generates that exception. And it does so on things like illegal instructions, divide by zero. Yeah, we're not going to talk about privilege in our class, but it's mentioned in the book. So if you look at Pat Patel's privilege implementation, if you try to do something where you don't have privilege and it's supposed to be privileged, it'll generate an exception there too. And there are lots of other cases in real processors having to do with more advanced design issues. Okay. Where are we on time? Sorry. We started well. All right. So maybe we can, hmm. We're not going to get too far in seven minutes. All right. So let me set up the problem. Actually, I'm going to summarize first. So we just looked at the LC3 ISA and went through a more or less complete subset. So the ISA, you know, I wanted to give you kind of a definition after having seen one, right? So the ISA is going to answer these three questions, right? So first of all, what's possible, right? So we went through and we looked at all the different instruction opcodes in LC3. We said, well, what are the things you can do with instructions? So why does that matter? Well, when you write programs in LC3 assembly or LC3 binary, it can only do the things that the ISA defines, right? So you have to break your human task down to the level of LC3 instructions. And that's always happening, right? So even if you write something like C or Java, you know, at some point things have to be broken down to the instruction level for the processor in which you run them, because that's all the processor knows how to do. So once you know, well, what are the operations it can do? Well, what are the operands you can use, right? How can you specify the operands for each of these operations? That's another thing, another question the ISA has to answer. And then finally, well, what is the representation we use, right? We have to express the instructions to the hardware. How do we encode those? What do the instructions look like? So all of the previous slides today were the encodings for the different opcodes in the fields, right? But that's part of the ISA is to tell the programmer, well, how do you actually express these things? And also to tell the person implementing the processor, if you see this instruction, what does it mean? Because the ISA is the interface between the hardware and the software. And so some set of people is building a processor that looks at these bit patterns and says, okay, when I see that bit pattern, I have to do this set of operations. And then the other part is the people writing the instructions somehow, whether it's because they're writing a compiler or writing assembly or binary instructions directly, saying, okay, here's what I want the computer to do. Let me put those bits together and put them in memory. And those two people, they don't even have to communicate so long as there's a clear and well-defined ISA. So here's kind of what we saw for the LC3. We had three operation or operates, ALU operations and, and, and, I should say add, and did not. Loads and stores, this was the PC relative, indirect mode, base plus offset mode, and immediate mode. And then the control flow instructions we just looked at were branch, jump, and trap. The data types, so why did I put data types up here? Anytime you do operations inside the data path, right, you can, you can imagine supporting different representations, right? When we started our class, we said, well, let's build an unsigned adder. And then we said, oh, look, it's the same as a two's complement adder, right? If we built a multiplier, then those two aren't quite the same, right? When we did a comparator, we also had to change things a little bit. So the question is, well, what kind of hardware do you actually have in your data path? The only hardware the LC3 has, it's all aimed at two's complement. All the offsets are two's complement, all the, the ALU, I mean, it does logic operations too, but the ALU, when it does add, you can think of it as two's complement. So everything about LC3 is two's complement in terms of how it operates on, on values that are passing, passed around in the data path. The addressing modes we saw for various instructions were register, immediate, PC relative, indirect, and base plus offset. The three condition codes we provided are negative, zero, and positive. Some, some processors will give you more condition codes, right? So you'll notice, for example, you can't check whether an add overflowed. There's no overflow bit here, right? There's no carry out bit either, right? So you can't easily check in LC3 whether you're, you're 16 bit addition overflowed. You have to go check it by hand by looking at the bits. Now you can do that, but it's not that pleasant. The only thing you can do with LC3, you can write an algebraic expression and then you can rework it to compare it with zero, right? So then you can compute the algebraic expression and you can check whether it was negative, zero, or positive. And so when you, when you start at a high level, you're going to have to cast everything in terms of a comparison with zero, because that's the only thing you can do with your branches in LC3. And then for the encoding, you know, again, you've got a, you've got a sheet that shows you that. Don't worry too much about the details there so much as how to use it. All right, so I think we're not going to get too far in this, but let me just say a few words about what we'll start on Friday. So we're going to count to 10 together. It'll be exciting. There's actually three variants on the sheet. So we'll do indirect addressing together, and I'll leave you to do PC relative and base plus offset on your own. So here's, here's what the sheet looks like. So there's some starting code, which we'll decode together. There's the loop body here. Actually, I can walk through this. So the PC, we're going to start at 3000. Then we'll do this code, second part down here, some values, some data we've placed in memory, and then here's the loop. Okay, so we're going to look at how we actually execute a loop 10 times, see what instruction scaffolding we build around that using LC3 instructions to make it happen, talk about what happens if we change things a little bit. And then after that, we'll do some examples of like typing in a number and stuff, stuff that you've seen at the start of class on the website. So let me just stop there and I'll see you on Friday. Thanks. Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai\"},\n",
       " {'ECE120-2016-10-05-LEC-18-slides.mp4': \" Hello. Test. Okay. Sorry, a little late. The batteries, no one apparently replaced them. So all right. So we're going to pick up with talking about static hazards. We'll actually talk a little bit briefly about other kinds of hazards too. I should have put a star here. Sorry. All the hazard stuff is a timing detail. I just want you to kind of see it so you understand the types of behaviors that real circuits have that we will have to, well, we don't have to, we're going to sweep under the rug in our class and just use discrete time, make our lives a little easier. A lot of these problems are actually also simplified in typical real processor architecture design, for example, but often you avoid thinking about timing by using a common clock. So a lot of digital system design, we push these issues off on the circuit designers and just say, well, give us a common clock and then, you know, fetch your job. And then we go off and have fun with discrete time. So I just want to give you a few pointers about that. I think there's still things we have to think about timing in EC385. So you will need to have a little bit more understanding of these later in your career, but for our class, it's just for your enjoyment and also to see some of the complexity. Then we'll spend the rest of the day probably talking about registers. We may get a little bit into serialization, but that's supposed to be the third part of the class. So we're going to start that on Friday, definitely, but that's kind of where we're headed. So I wanted to do a little bit of review. So this was our flip-flop. So this is a master-slave positive edge trigger D flip-flop. So it gives us the notion of discrete time. I have a timing diagram again, just to show you, but it's basically two of these D latches with one inverted on the right navel sense from the clock signal. So the first one copies from D to Q when the right navel is low, right? So, or rather when the clock is low, sorry, where enable is high. And the second one copies when the clock is high. And so what this effectively gives us is when the rising edge of the clock comes, this first latch here will have been copying during the low phase of the clock. And then when we switch to the high phase of the clock, whatever value was last stored there is locked in place because the clock has gone high, which means this one's right navel is low. And then at the same time, this latch starts to copy from its D, which comes from this first latch is Q. Let's call it X, I guess, from X to Q here. And so whatever value was present on the input right when the rising edge starts will actually be stored here in the flip-flop for a full cycle. The second latch will not change value again until the next rising edge, because this first latch can't change until the falling edge. But then at the falling edge, this latch is again no longer copying because when our clock is low, this latch holds its value. And so effectively what we've built here is something that gives us discrete time. So once a cycle at the rising clock edge, we copy a new value from D over to Q, we keep that value for one full clock cycle. So everything about, well, time is continuous, you have to worry about timing issues, this lets us just ignore that. So we build out of these flip-flops. So it gives us the discrete time. And we're going to assume that between integer values of time, nothing's going to change. So all of our flip-flops will have constant output. You will in your lab see a non-square wave clock signal. So we wanted to do something in the lab where you interact with the real world. So you can have fun doing sensors and actuators and realize that you can build robots and other things with what you're learning in 120. But you'll do a finite state machine that interacts with the real world as a vending machine sort of. You put coins in, and it's actually the coins that will drive your clock. So when they go past a sensor, that'll drive the clock signal in one direction. And when they're past the sensor, the clock will follow in the other direction. So that'll be your clock signal coming from the coin rolling past the sensor. So that'll be more continuous time. But logically, it's the same discrete time, but that gives you one clock signal. So you can read about that ahead in the notes if you'd like. There's a section on how the lab was designed in that relationship. So all of the designs in our class will be clock synchronous sequential circuits. You do need to know a little bit about sequential feedback circuits like latches and flip-flops. So you should understand how they work, basically. So in class on Monday, we looked at the design of the latch and the design of the flip-flop. And we did the analysis where we said, well, what if we start with a zero on this loop? How does the feedback work? And how does it settle into a stable state? So we expect you to be able to work through those kind of things if we'll give you a different design. But we won't give you very complicated designs, usually one or two loops. So let's talk a little bit about static hazards. So again, you only need to understand the basics of timing. So how to estimate delay as gate delays, simple heuristic for delay of circuits, how to check for stable states that I just mentioned. In later classes, you will have to have a deeper understanding of timing and probably even run into timing bugs in some of your designs. Even if you're building hardware on FPGAs, sometimes the tools may not actually get the timing perfect. And so your synthesized version may actually exhibit timing errors, essentially, where something hasn't finished before your clock says, well, I'm going to grab the new value. So let's take a look just for a preview at how timing can matter. Why do we care? Why is it not just all easy, even if we have more complicated timing? So I'm going to give you some terminology first. So if a circuit may have a problem, so if I have a circuit design and that circuit may have a timing issue, we say that circuit has a hazard. So that doesn't mean it shows up. It just means that circuit may have a problem because of timing. If it shows up, if some output from my circuit becomes a variation in my output voltage, we say that that circuit exhibited a glitch in its output. So a hazard is a potential problem. A glitch is a problem that actually happens in the output. And then if you have a sequential circuit and that circuit changes its state in a way that was not designed to do, not because you built it the wrong way, but because of some hazard or glitch, we say that it had an error. So hazard, glitch, and error. Now typically, if you have an error, it could just be a bug in your design. Whatever you built was just wrong. But assuming that you built it correctly, typically if you have an error, that means that something in there had a glitch. It actually changed the output bit and that bit got latched, got stored in a latch or a flip-flop. And a glitch implies a hazard. You don't get a glitch unless you have a hazard, but the opposite direction doesn't hold. So you might have a circuit that has hazards, but it doesn't matter because they can't turn into glitches. Or you might have a circuit that exhibits glitches, but they can't have errors. So for example, when we assume that we only look at the rising edge as the only point at which we sample our data input, well, even if that data input has glitchy behavior, even if it's bouncing around, so long as it's stable at the rising edge of the clock, we don't care. So that's one reason that you don't have to actually solve some of the static hazards we're about to talk about. Because in the space in which we're designing clock-synchronous sequential circuits, we only care at the rising clock edge. And so the fact that something input to our flip-flop might be bouncing around beforehand, that doesn't make any difference. So it's okay for your combinational logic to have the static hazards I'll show you, because you're working with clock-synchronous designs. All right, so if you want to read more, section 2, 6, 3, 4, and 5 are the three types of hazards. Static hazards, I just want to give you a definition. So with a static hazard, the idea is that you've got some combinational logic circuit, and you're going from an input combination that produces, say, a 1, to another input combination that produces the same value, so say again a 1. And so you think, well, if it's supposed to start at 1 and end at 1, it should always be 1, right? It shouldn't go bouncing around. If your circuit has a static hazard, that might not be true. It might be possible that even though one input combination gives you a 1 for output, second input combination also gives you 1 in between, drops down, goes to 0. So that's the hazard. That one is called a static 1 hazard. It's also a static 0 hazard. It's supposed to be 0 and 0. Instead, it bounces up to 1 and goes back down. So static 1, static 0 hazards. Yeah, Eric? So the static refers to the fact that the output is not supposed to change. So both of the two input combinations are supposed to produce the same output value, either a 1, which makes it a static 1 hazard, or a 0. So static refers to this static nature of the output. So we'll go through a detailed example. Yeah. Yeah, so. Okay, so let me be careful here. Yeah, so the question is, what's the cause of a static hazard? No, it's not metastability, if that's what you're thinking about. But it is the case that if you have multiple levels of logic, different gates may actually be changing from 1 to 0 and 0 to 1. And those gates might be input to another set of gates. And so the output of that additional set might be bouncing around. And so that'll be the example I give in a few slides. That was a good question. Yeah. All right. So before I give you the static hazard example, though, let me also define other types of hazards. I won't go through examples of these in the class. They're substantially more complicated to understand and figure out. Static are relatively easy. Dynamic hazards, and here again, dynamic refers to the output. So in this case, the output is supposed to change. We have an input combination that, say, produces a 1. And then one of the inputs changes. And the new input combination is supposed to produce a 0, for example. So what we'd like is a clean transition. We'd like the output to start at 1 and then at some time go down to 0. And that's it. It changes once. If you have a dynamic hazard, the output may actually bounce around. So it may drop to 0, then go back to 1, then drop to 0. It may do that many times. So hazard just says that it might not change cleanly. It may bounce around before it settles to its final value. That's a dynamic hazard. Again there's an example in the notes, but I'm not going to do that example in the class. It requires more deeper circuits, more than two-level logic, to actually have any dynamic hazard behavior. So there's an example in the notes if you really want to go understand it. But I'll show you static hazards in class. The last one is actually quite important, but it occurs in sequential circuits. They're called essential hazards, and they're related to the function that you're implementing. So for static and dynamic hazards, you can change your design in a way to get rid of them. So you can say, well, I don't want to have static hazards, so let me change my design. I'll show you how. And that will get rid of my static hazards so I don't have glitches from static hazards. Similarly, again it's harder, but you can change your design for dynamic hazards so that you don't have dynamic hazards anymore. Essential hazards, there's nothing you can do. Having the essential hazard is part of the function you're trying to build, and there's no way you can build it and not have the hazard. So they're quite problematic in that sense. They can't be eliminated. On the other hand, by using this abstraction, this clock synchronous sequential design, sequential circuits, what we're doing is taking all essential hazards in any design we do and manipulating them so they show up as clock skew. So the only essential hazard you'll have in a clock synchronous design, one where you have common clock going to all of your flip flops, is clock skew. Which again, we're going to push off on the four circuits people and say, well, good luck. Yeah, Eric? Yeah. Yeah, it's how you implement the function. You can change, and we'll see that with the static hazard example, that if we change the implementation we can get rid of the static hazard. It's not always easy, but you can do it. Whereas essential hazards, you can't get rid of them. There's nothing you can do. You can change where they show up, but you can't get rid of them. You're always going to have potential essential hazards. The reason this matters, actually, by the way, so when you build a chip, it's not just design that goes into your chip. There's also variations. These are quantum phenomenon. So if you've taken quantum mechanics, this will make a lot of sense. If not, think of it as we've got now maybe 10 atoms of thickness between our transistor and the part that would let it leak electrons out into the world. So sometimes it might be 9. Sometimes it might be 8. Sometimes it might be 12. But that's a 20% variance in that transistor. So that's a huge swing because of quantum mechanics, that they're quantum devices. Similarly, there's a small number of dopant atoms. Those things also, there's a discrete number of atoms. You never have 3 and 1 half atoms. You've got 3 or 4 or 5. And so the variations that we see now in modern processes are pretty big. And so even though you design your circuit so that it should work, you can get timing behavior because of the variations. And so that makes it very, very hard to design it and have all of these problems be solved and guaranteed to be solved. That's why we have to do very careful testing of chips that we build because the variations can affect their behavior a lot. And so I think on Monday I was talking about speed bending. That's one of the side effects of having process variations in the semiconductor world. Those are all research topics too. So you don't need to understand them too deeply for our class. Not at all. But it's fun. All right. So let me give you the static hazard example. So here's a little circuit. So it's built out of a couple of inverters and a few gates. So what is S in terms of A, B, and C? Yeah. So A and B in this hand gate. And this is B0, C0. And then we OR those together. Good. So now let's think about, so what happens when we move from ABC110 to ABC100? So take a look at the function and verify that you think the answer should be 1 in both cases. You agree? OK. So in the first case, we've got A and B equal to 1. So this should be 1. And then OR it with something. That gives us S1. And over here, B is 0 and C is 0. So B prime C prime should be 1. OR 1 with something, we get a 1. And so we should get 1 in both of those input combinations. Only one bit has changed. Only the B has changed. So let's take a look at what might happen. So B changes. Let's say that's step 1. B changes from 1 to 0. So what happens as a result of B changing? So this one changes, right? Because that one went, this was 1 and this is 0. So our AND gate now produces a different value. So that's going to change. Good. So the AND output's going to drop to 0. What else happens? Yeah, there's an inverter down here, right, taking B. So that's going to change. So that NOT output rises to 1. That happens roughly at time 2, let's say. These could be gate delays. I would have made this one 0 and these 1, right? So wait a minute. Now this NOT output's going to go to this AND gate. So what's going to happen over here? It's going to go to 0, because this AND gate's currently outputting 0, right? When we're in this state, this AND gate was outputting 0. So now this has got 0 OR 0. What's 0 OR 0? It's 0, right? So the OR output is going to drop briefly to 0. Later, it's going to come back, because this AND gate now has 1 and 1. It's going to produce a 1. It's going to turn the OR gate back on. But for a brief amount of time, that OR gate at the end is going to give us a 0. So that's the glitch. So here it is in a timing diagram. So you can see, you can go verify that I got these answers right if you want to, but this is the transition that we're talking about. We have A equals 1, B equals 1, C equals 0, S was currently 1, and then B drops down. That causes B to go low briefly. And then when B prime goes high out of the inverter, that drives S back up. So this is our glitch. Yeah, so in the past, when we were introducing those ideas, it was, let's look at combinational logic in isolation. And so often, you're building combinational logic between sets of flip-flops, right? And so if it's a flip-flop coming in, as you saw yesterday, I'm sorry, not yesterday, but Monday, then you can get both Q and Q prime for free, right, without a gate delay. They're both available at the same time. So that was why they were free. If for some reason you don't have your logic coming out of flip-flops or your, I mean, here, we're not assuming, we didn't assume that we had this for free, partly because I wanted to show you the glitch, right? So I came up with an example that would show you a glitch. So you got me. But one can imagine making a different circuit where we didn't have that, or in some cases, in fact, we won't always have the complemented inputs if the values are not coming directly from flip-flops or latches. So in this case, it was a little bit contrived, and so that was why I wanted to count it, but to show you the glitch. But there are designs where you might not have the availability of complemented inputs, in which case you do need the, you do need to count the inverter. So in fact, even in the bit slices, right, where we're going bit to bit, we don't produce complemented outputs. So really, we should have counted the inverters there, but I was trying to make life simpler at that part of the class. Good question. Yeah. Yeah. Yes, so I showed you something with the latches and the flip-flops timing diagram. So clock skew is, we assume that the rising clock edge arrives to all of the flip-flops all at the same time. So we have a common clock, and the rising edges arrive at each flip-flop at the same time. Now, that's one, that's not really possible to do, and two, it actually doesn't mean anything in the real world because special relativity tells us the same time in two different places doesn't have meaning, which if you haven't learned yet, you'll have fun learning. But if they arrive sufficiently far apart in time that information can propagate between one flip-flop and another, then that can actually cause us problems in the behavior, right, because one flip-flop may change its value, and then its output may affect the input to the other flip-flop. And so if the clock edges don't arrive simultaneously to all of the flip-flops, that can cause problems. And that's clock skew, is differences in the arrival time of the rising edge of the clock. Yeah, good question. Yeah. Well so, I'll show you a fix in a minute, but the, yes, the delays through the circuit as designed are opening the possibility, or are a hazard, and open the possibility for a glitch. Now, if we just assign different amounts of time to these various gates, we could set it up so that the glitch never showed up, right. So this, a hazard doesn't necessarily ever show up as a glitch, but this circuit has a hazard regardless because if I put the wrong amounts of time through these gates, then it can show up at the output, right. So if this path from here through here is slower than this path through here, then it'll show up. Yeah. Yes, and more particularly, there are two separate paths from B to S, and the timing of those paths may be such that even though the end value of S is the same, the timing of those paths creates a downtime in S. Yeah, it's the longer delay along this bottom path through the inverter and this AND gate and this OR gate. Yeah. So all we really need for the glitch to show up is for this path to be slower. So I didn't even really need to add the gate, I just need to have that path be slower for whatever reason. But that's harder to explain, right. I mean, I don't really want to have to have everyone understand process variations, but it's possible for even without this inverter, even if I had the complement available for that path to happen to be slower than the top. But this makes it, I think, easier to understand that we can just count gate delays. Okay. All right. So what can we do? Briefly, yeah, just like this. Depends what you're doing with it, right. So humans, for example, are pretty good at catching flickers, right, because our lives used to depend on catching the predator flickering amongst the leaves, right. So if you're driving some output that a human can see, they might actually see that it's doing something weird, right. If for some reason, whatever you're doing might also use this value and expect it to be constant. And if you have something that realizes it's gone low and does something in response, it will also react. It doesn't have to be a human, it could be some electronic circuit. Yeah. Is there another question? Yeah. So that's one answer. I mean, as long as I guarantee that my clock edge doesn't come in the glitch. Yeah. As long as I wait long enough to make sure that all of the paths have settled through my circuit, right. So I can count, like you said, I can count the paths, find the longest one, make sure that my clock between the change and the latching of the output is sufficiently long that all of my paths have settled, then I can use a D flip-flop and I'm guaranteed never to see this behavior. And that's practically what we're going to do in our class, right, is to say we're going to ignore this kind of stuff, because we always wait long enough and run our clock slowly enough that we just never see the glitches. Good answer. But I can actually change the circuit too, so I don't see the... So how about this? Let's take a look at the K-map. So those are the AND gates, right? Those two loops are the AND gates. So remember there was AB, which is this one here, right? And there was B'C', which is this loop on the left. So the behavior we're seeing is this input combination, so 0, 1, 0. I'm sorry, 1, 1, 0. So A is 1, 1, 0, going to 1, 0, 0. So you can see it's crossing between loops. So in other words, one of the AND gates is going to switch from producing a 1 to a 0, the other is producing 0 to 1. So how can I prevent the output, which is the OR of these loops, from going down? Yeah, I can add another one, right? Well, let's add a new loop, another AND gate. Cost me a little extra area, got to have the extra AND gate. But now this purple AND gate here, this new loop, that's 1 for both input combinations. So that AND gate's going to always produce a constant 1, which is going to go into the OR gate. The OR gate's going to produce a constant 1 also. You can imagine this is substantially more complicated if you have more than two levels of logic. It's more complicated if you have to draw extra loops between all of your loops to make sure there's never a transition that isn't covered. So it's not necessarily easy, but you can do it. You can add extra gates and get the answer. So that new AND gate's going to stay at 1. So we can fix our static hazard that way. So it's going in any transition. So when we analyze sequential circuits, we assume that inputs don't change simultaneously, that only one input changes at a time. So what that means is a KMAP is moving from adjacent box to adjacent box. So you only move from one input combination to adjacent boxes at any time. So all of the transitions you have to analyze are the edges between the boxes in the KMAP, and a static 1 hazard would be to go from any 1 to any 1. So you then look at all of the loops you have and make sure that anywhere you can go from 1 to 1, it's always inside some loop. And that will be an AND gate that produces a 1 constantly during that transition. And if you did POS, you would do the same, except that for all of your 0 to 0 transitions, you'd always have a loop that enclosed every transition. And that would guarantee that those OR gates would always produce a 0 during that transition for static 0 hazards. If you do SOP design, you don't have static 0 hazards because none of the AND gates is on. So you're going from no AND gates to no AND gates. So you don't have to worry. All right. So I think that was it for our fun time with hazards. Any other questions before we go back and talk about registers? Yeah. So generally speaking, we always assume with any kind of sequential logic analysis that only one input changes at the same time, that the transistors react quickly enough that any tiny little difference in changes will be seen sequentially, that one change will happen before the other. So we simply ignore that possibility. That would correspond to two box change. But we assume that never happens. Yeah. Again, we assume that one input changes at a time, that even if they're very close in time, the transistors react very quickly. And so they're separable and serial. And so we assume that only one input bit changes at any time, never simultaneous input transitions. Yeah. OK. It's not always the perfect assumption, right? But as I already mentioned with latches, right, if they happen, if you let, with the R bar S bar latch, if you let them both go up at the same time, you might get metastable states, right? So it doesn't always work, but that's generally the assumption when people analyze sequential circuits. OK. Yeah. Yeah. It can bounce, yes. Yeah. So if you took our circuit here and you connected S to another piece of combinational logic, well, you're changing the input, right? So the outputs, of course, can also change. Yeah. That's right. So these changes, if you connect this to more combinational logic, will propagate through. And that's where dynamic hazards come from. So if you look at the example in the book, you take a static hazard, then you add some logic to it, and then that can create a dynamic hazard. All right. So let's spend a little time on registers then. All right. So, so far, we talked a lot about representations, right? We had usually a bunch of bits together in groups, like unsigned, two's complement, floating point, ASCII. And we talked on Monday about how we store a bit, right? So flip-flop's going to store one bit. Well, what if I want to store a 32-bit unsigned number? Well, let's build something to let us do that. We'll call it a register. So it's a storage element that we're going to build out of flip-flops. And it's going to store things, groups of bits. Again, all of our flip-flops will operate on a common clock. Now, a flip-flop stores a new bit every cycle. With a register, we want to have some control. We don't want it to just store some new bits every cycle. We want to be able to say, well, in this cycle, I want to put a new 32-bit unsigned number in my register. And I want it to stay there until I tell the register to put a new value in again later. So I'm going to add a load input, maybe LD or load. So when load is 1 on a rising clock edge, the register will store a new set of bits. Otherwise, it'll just keep the same bits. So the only time it's going to change is when load is 1 on a rising clock edge. Otherwise, constant value is stored. So how am I going to do this? So here's an attractive option. It might seem attractive. You say, well, OK, so I'll hide the rising clock edge. You don't want to see the rising clock edge. You don't want to change your bits. So hide the rising clock edge. I can add some logic down here. You probably don't want to use this. Until even a few years ago, it goes in phases. So for a while, people were doing clock gating. Then they realized, as I'll talk about in a minute, it adds to clock skew. And so they said, don't do this because it makes the circuit people's lives miserable. So for many years, we've said, no, never do clock gating. Just rule it out completely. There are power reasons that people are starting to think about it again. It can save you power sometimes. But for our class, never think about doing clock gating. It will introduce clock skew. And so it will introduce ways to have nasty, subtle bugs with essential hazards. And if you do it in your lab, good luck. Don't do it. So here's another reason. You have to actually be careful with how you manage your load signal. So load affects your perceived clock, C. So your perceived clock is now this signal, C, here. So your perceived clock, you can get specious rising and falling edges. So for example, here, while the clock is low, if I raise load, I get a specious falling edge. That doesn't matter because I have a positive edge trigger, D flip-flop. This was a real clock edge, so that's OK. But unfortunately, if I lower load while clock is low, I get a specious rising edge. So in the middle of my clock cycle, I do a load. So if you're not careful, you can make your flip-flop store values even in the middle of a clock cycle. That's probably not what you want to do. So you have to manage your various signal timing in addition to thinking about the clock and worrying about clock skew. So that's the main reason is the extra logic contributes to clock skew. It slows the rising edge to the clock. So you want to avoid doing that. So we will have one application that uses a different clock for some flip-flops. It's called ripple counters. You'll see it in maybe one or two weeks. But otherwise, you should always assume common clock signal to everything, and you shouldn't try to build clock gate. What should we do? And with the input. And what with the input? But then that would load a zero, right? Yeah, so you're building up to something that we've seen. So we want to pick between keeping the old value and taking a new value. What should I use if I want to make a choice? Say loud. A mux. Good. Okay, there's a mux. And it's true, Peter, what you were saying that inside of that we're ending the load signal with one and ending the old value with another min term of the load signal, I should say. That's how mux works internally. So you're on the right track. But let's just plop it down as a mux. So what happens here, when load is equal to zero, we take the Q output of our flip-flop, which I probably should have drawn there, and bring it back. That's a zero input of the mux. So the mux forwards the old bit, and that just gets stored again. So it just retains its value. When load equals one, we take in, and we copy it to D, and then at the rising edge, D stores that value for us. So this is one bit of a register, and then we'll use that design as a bit slice. So for an n-bit register, we'll have n of these, n muxes, n flip-flops. So here's an example for four bits. This design here, we say it uses parallel load. So we've got four input wires, and they're coming down. The load controls all four of the muxes. So when load equals one, the entire four-bit register stores a new value. When load equals zero, the same four bits are stored there until load equals one again, and it sees a rising clock edge. Again, common clock. At some point, I'll no longer even draw the clock signals. Right now, I'm still drawing it just to show you there's one signal that goes to all four of these. With a 32-bit register, same thing. One clock signal to all of them, one load signal to all 32 muxes, and then 32 separate wires for parallel load for the different bits. So that's a register. Now sometimes, we want to load registers one bit at a time instead of loading them all at once in parallel. So we have a notion of a shift register for that. So here's a shift register. So you can see what happens. We have a serial input on the left. That's the thing that puts a value into this flip-flop here. This flip-flop's value, stored value, in the next clock cycle is then shifted over to this flip-flop. At the same time, this flip-flop's value is shifted to this flip-flop, and so forth, all the way through the shift register. So if you think about cycle to cycle, what's happening is we have the input. We're putting one bit at a time, and those bits are just shifting through our register. That's why we call it a shift register. At the end, we have a serial output. So we can see the bits coming out one bit at a time from the serial output. Or we can look at all of the bits at once if we want to. So those are the parallel outputs. So if you want to look at the value of the shift register, you can simply look at these output wires, and that'll give you all of the bits at one time. So I'll talk about a couple of applications. In some cases, we want to look at the bits in parallel, and in some cases, we want to look at them in serial. So it depends what you're trying to do. You can look at a shift register's stored value in parallel, or you can look at it in serial. It depends what you want to do with it as to which way you want to look at it. So let me give you a couple of examples. So there are lots of applications. One is SERTIs. So optical networks, for example, go at about 100 gigabits per second. You can't clock the typical CMOS processes at 100 gigahertz. So what happens is you get the optical fiber coming in. It's producing 100 billion bits per second. And 100 bits per second, you could probably do in CMOS. So 100 billion bits per second, and you use other semiconductor processes to build this logic, but you put that into a shift register. So they're going in there at 100 billion bits per second, and then you pull them out using these parallel wires. Say you built a 25-deep shift register. You pull them out at 4 gigahertz. So every 25 cycles of 100, you pull out 25 bits. And so now that's clocked at 4 gigahertz, which you can do on CMOS. So you hand those to a normal CMOS chip, and you get 25 wide at 4 gigahertz instead of 1 wide at 100 gigahertz. So this is deserialization of the optical signal. You also use a similar strategy for serialization. When you want to go from a 4 gigahertz processor to 100 gigabit per second optical line, you do a serialization process. So it's a similar application. So that's one thing to use shift registers for. My postdoc was actually using shift registers a couple weeks ago, so I thought I'd just mention it. He's working on computational genomics applications. We get data coming in from memory, let's say, at one clock cycle, but then we need to feed this computation with different parts of the data at different clock cycles. So how do you delay it? Well, put it into a shift register. Want to delay it two cycles? Put it into a shift register two deep. Each bit gets delayed two cycles. You want to delay it five cycles? Five deep. So it's good for delay applications as well. So we can also design them to stop shifting. So of course, if we want a shift register that we can say, well, in this cycle, I want you to shift. Next cycle, I don't. I want you to just hold your value for a while. Well, of course, we could just put a MUX down. So SI is now going in to the left, just as before. As before, Q3 is coming up to the one input here. So if shift equals one, this behaves like the old design. If shift equals zero, it just freezes and holds its value as long as shift equals zero. Some other things we use shift registers for. So the serial load idea that we use with a shift register is critical when we don't have a lot of wires. So for example, well, what does that mean? So in the parallel load, remember one wire per bit. So if you've got a 32-bit register, you have to have 32 wires to fill it. On a chip, for example, we have 100,000 flip-flops. So if you want to test the chip and you need to fill 100,000 bits, you don't have 100,000 pins. Nothing will give you 100,000 pins into one chip these days, maybe a few hundred. So how do you fill them? Well, you use shift registers. So you use fewer pins and you shift bits in through the flip-flops, one flip-flop to the next. You fill them all up with bits to test your chip. You run your chip for one cycle, and then you shift out the answers while you shift in a new test vector. So we're using shift registers to test our chips. Reconfiguring hardware. So how are field-programmable gate arrays that you use in 385? How do you configure them to execute hardware? Well, again, we don't have so many pins to shift everything in in one clock cycle. It would also melt the chip. So we shift things in using shift registers. So all of your hardware designs that you build and synthesize in 385 will be shifted into the FPGA through shift registers in order to configure the hardware to simulate your design. So both of those applications use shift registers. All right. So I wanted to give you some terminology. So you can do left shift, right shift. Yeah. Yeah. Yeah. So you're filling up your shift register with 25 cycles of 100 gigahertz, and then you're pulling that out. I mean, the rate at which you take data out is 4 gigahertz. Now, you don't have one, what is it, a quarter of a nanosecond. You don't have a full quarter of a nanosecond to pull it out. You've only got 1 one hundredth of a nanosecond, 10 picoseconds to pull it out. But once you get it out, then you can treat it as a normal 4 gigahertz clock once you copy it out of the shift register. Now, you pull all of the bits out simultaneously using these wires down here. No, because you wait for it to fill up again. I mean, here we're only showing 4, but if you wanted to do it 25 to 1, you would have 25 deep. You'd fill all 25 using a serial input, pull 25 bits out, fill all 25, pull 25 bits. Make sense? All right. So let's see. So this one we talked about. All right. So right and left just corresponds to what we might put in in terms of representation. So if it's on a piece of paper, they correspond to the piece of paper. If it's in a representation, it'd be from least to most would be left, and from most to least significant would be right. Hopefully you remember the difference between logical and arithmetic shifts. So if you have a shift register that's supposed to operate on unsigned values, then you would use a logical right shift. If you wanted it to operate on two's complement values, you'd use an arithmetic right shift, which would copy the signed bit. So remember logical, you shift in zeros. Arithmetic, you copy the signed bit when you shift right. Both directions shifting left, you shift in zeros. And then there's also applications of cyclic shift registers where you bring one bit from the serial output back to the serial input, sometimes going through another register. That allows you to build bigger shifts. So typical modern processors will allow you to build, say, 64, 128 arbitrarily large shifts by doing 32 or 64 bits at a time. So you do a cyclic shift, you bring one bit out into what's called a carry register, and then the next set of 64 bits, let's say you shift your carry register in on one end, pull another bit out, go to the next set of 64 and keep doing that. So that's why processors often support this idea of cyclic shift. It's just a circle in your shift register. All right, so we don't have to pick one design. So let's build one register that does one of four things. How can we do this? I want one register, I want two control wires, C1 and C0. And if I put in 00, I want it to hold its current value. If I put in 01, I want it to shift left from low to high bits. From 10, I want to load a new value, parallel load, from I'll give you some wires in sub i. And then if I have 11, I want it to shift right from high bit to low bit. How can I build something like that? When I want to pick one of four answers, a MUX, right? Yeah, a decoder will give us the minterms. So you could do it and then you could use logic of the minterms. You'd get the same effect. But the MUX already gives me what I need to bring it together. So all I'm going to do with that output out of those four possibilities is put it into my flip-flop. So next cycle, it's going to store one of the four answers. So I could do this with a decoder too and then put the extra logic to bring the four outputs together and put that into d, but MUX already does it for me. So usually if we need to pick among several things, we're going to use a MUX. Decoder is only when we need to do separate operations on the four outcomes. So here, let's take a look at this design, make sure it actually works. So I said zero, it's going to hold its value, right? So if I put 00 here, I pick the zero element that comes from its current value. So this is my bit slice. Anytime I set C equal to 00, then this register here is going to just keep its value as long as I set C equal to 00. If I set C equal to 1, 01 in particular, then this comes from QI minus 1. So that's a less significant bit. So that's going to shift left from low to high. So this QI minus 1 is the next bit over here. It's going to take its current value of that bit and copy it into that, the bit that I'm showing on the slide. So that's a left shift. If I set C equal to 10, the number 2 in the decimal, then it's going to take this input wire for this particular flip-flop and store that into my flip-flop. So that's a parallel load. And then last, if I set C equal to 11, 3, then I got QI plus 1. So that's some bit I haven't shown over to the left. So we're shifting now to the right. We're taking the high bit, shifting it down to the next lower bit. So that's a right shift, which is what we had in our last diagram. So by using this 4-to-1 MUX and wiring it up correctly for each of our bit slices, we can build a register that does any of these four operations and does whichever operation we tell it in each of the cycles. So you can do arbitrary combinations of these things. If we were to ask you on a homework or an exam, OK, we want you to shift left. We want you to do arithmetic right shift. We want you to do logical shift left. We want you to do cyclic shift. Just any combination, really all you have to do is this MUX and then maybe some logic at the end. If we say arithmetic versus logical right shift, you have to decide what to do with that input on that side. But for the most part, this MUX design will allow you to combine arbitrary register designs pretty easily. So I think that was the last slide on registers. There's a few more pictures of these things built out into multi-bit registers with the bit slicing in the notes, if you want to see that. It's sort of the same as the earlier ones I showed you, but it has this bit slice in it. All right, let's see. We've got a couple minutes. I'll just give you the idea of what we're going to do here. So more on Friday now, but if you think back to bit slices, each of the bit slices we worked with would have some number of inputs, operands, like the comparator had two operands, the adder would have two operands, a power of two checker would have one operand, but we actually did it two bits wide, so it had two. It produces some number of outputs for each bit slice. The comparator produced nothing, and the adder produced just the sum bit. The power of two checker also produced nothing down here. And then some number of bits between bit slices. For an adder, just the carry bit. For a comparator, we had two. For a power of two checker, we had two between bit slices. So you can do sort of a general model with p bits in, q bits out, and n bits in between. And then what we're going to do with that is use flip-flops to produce a serial design. So remember when we were talking about this initially, someone said, well, can we, instead of putting n bits back to back with hardware, couldn't we use fewer bits and then use software to make the bits flow through them? We can. In fact, we can make the bits cycle through the same physical hardware in hardware also. So what we'll do on Friday is think about how can we use flip-flops to take our bit slice design and turn it into a serial design. So we'll have one copy of the bit slice, just one. And we can do arbitrarily large operations by just using it cycle to cycle for n cycles instead of building a big design. So we'll trade a smaller area for a slower speed. Thanks......................................................................\"},\n",
       " {'ECE120-2016-10-26-LEC-26-slides.mp4': \" Okay, ready to start? So not much on here. Since this is a kind of complicated example, we'll spend most of the day, I'll try to spend all of the day actually finishing up this example of building a finite state machine to implement some C code. If I don't manage that, we might start on von Neumann model, but otherwise we'll do that on Friday, and that's Pat Patel chapter four. This example is the notes three seven. So I wanted to just go through this a little bit, what we talked about. So we set out to develop a finite state machine to implement a piece of C code. And we're going to take our strategy to build with abstraction. So we decided we're going to store variables from the C code and registers, counters, things like that, sequential logic, right, what you've learned a few weeks ago, and then execute the statements using components like comparators. So here was the C code. So what this thing does is basically just find the minimum of 10 numbers. So this, remember, is an array of 10 integers, 32-bit 2's complement values. And the way this code works is first we take the first value, value sub zero, and copy that into min. And then we look at the other nine values from one to nine, according to this loop control. We compare each one with the current minimum. And then if it's smaller, we replace the current minimum with that value. Once we look at all of the other nine, we're guaranteed to have found the smallest of the 10. And so when this loop is done, we'll have the smallest of the 10 values in this variable min. So we built up this flowchart to show how it works, sort of the same thing, just in color-coded statements. So initialize the variable min, and then start the loop. So initialize index to 1, compare it to 10. Once that's false, we're done. That's the whole program. But as long as it's true, we go around this little piece. This blue is the if statement. So check if the thing we're looking at, values subindex, is less than the minimum. If so, copy it into minimum. Otherwise, just update the loop by incrementing the index, and go around nine times. So we decided the array was going to become a memory. We know how to build a memory, so we'll use a memory for that. Other variables we decided would be registers and counters. The if statement will be a comparator. And I said that we're going to use a serial comparator. So I just wanted to kind of make clear why. There's no good reason. The reason is purely to show you that just like before, when we did the keyless entry extension where we had a hierarchy of states, we showed you the high-level four-state diagram. We kept that throughout. Even after we'd done the extension, we still had that same state diagram at a high level. But the alarm state became something like five billion states. And of course, we didn't draw five billion states on paper. But we had a hierarchy of states. Here again, we're going to have a state that uses the comparator. And in order to use a serial comparator, we have to compare one bit at a time. These are 32-bit values in our code. So we're going to execute for 32 cycles looking at one bit at a time. And when that's done, at the high-level states, we'll move to the next state. But we'll also have that one high-level state for comparison that takes 32 cycles. And it's really 32 different states. So I just wanted to illustrate that for you again. That's why I decided to use a serial comparator in this design. Now in order to use a serial comparator, we needed some other components. So we need two shift registers to put bits into the serial comparator. Remember the way it works, it looks at one bit every cycle. We have two shift registers to give it one bit every cycle that it can compare. And then we also need a counter. How do we know when 32 cycles are over? Well, we have to count them. So we have a counter for that. So those are our pieces. Now I mentioned this, but I kind of realized talking with people in office hours maybe wasn't entirely clear, it's hard to make it clear without having you actually do the process. But whenever you're doing a design process, you don't just make decisions and then that's set in stone. Typically you're going back and forth. So we talked about components. The components we chose affect how we can pick the states, how we can design our states, how we can break up the pieces of the flowcharts into states. And then vice versa, the way we want to do that affects which components we need. So it'll be clear at the end, you'll see how things fit together. But usually when you do this kind of thing, it's not that you just say, OK, let me throw some things down and then I'll just straightforward break the states up. Usually you're going to say, oh, well, there's this other thing that I don't know how to resolve given the components I put into my data path. Let me go back and add something. Or go from the components to the states and figure out how you want to fit the states to the components. So it's really a back and forth design process. Now this is what we did with our flowchart. So we broke things up into five states. So the first state, remember, let me just explain it a little more. So in this init state, we're doing three different things. So the three things we're doing is we're putting a new value into the min register. Turns out index will actually be a counter, but it doesn't matter. We're putting a new value into min, a new value into index. Those are separate pieces of logic. So in one cycle, we can put a new value in both of them. And it doesn't matter. That's why we're allowed to put two different pieces of our flowchart into one state. They actually happen simultaneously. What about this one? Well, the first time we go through the loop, index is one. And you know that 10 is greater than one. So you don't need to do any work in your finite state machine to figure out that 10 is still greater than one whenever it runs. So that's why we're able to pull that in the first time. You might wonder, well, what about this part, where we come back after our loop is done and we check it? So what's going to happen there is index is just a counter. So we can look at its value when we're in this green state, the copy state down here. And when it's equal to 9, then after we change it, it'll be 10. And 10 is not less than 10. So instead of doing anything here, we can simply make copy go directly to done, the wait state, when index is 9. So that's how we're going to resolve the other use of this box here. So you'll see that as we walk through the design. But basically, we never really have to do this comparison. It can all be done ahead of time and using in the copy state using the index's value comparing it to 9. So I'll show you how that works. But just wanted to go through it more slowly. All right, so this is what we got generalizing our state machine. So we'll start in the wait state. The idea is that we've got this finite state machine, some other logic is going to fill the memory up with 10 different numbers. Then we're going to say go or start rather. And the start signal will tell the finite state machine, OK, go out of wait and start doing your initialization. So that was the gray states on the previous slide. Initialization takes a cycle. So the next state will always be the prep state. Remember, that's where we had to set up to use the serial comparator. So we're putting values into the shift register, and we're resetting the counter so that the serial comparator can do its work while the counter is counting to 32 for us. Because that's a prep state. Then we'll let the counter run. So prep also takes always one cycle. So then we'll go to compare. Compare will take 32 cycles. So we're going to look at the counter value. And until the counter says 31, which will be the 32nd cycle, until the counter says 31, we're just going to stay and compare. When the counter says 31, we're going to move to copy. Now in that cycle, when we're in copy, the comparator, the serial comparator, will be telling us whether A was less than B. In other words, or A was greater than B, I think is what it ended up being. But it'll be telling us whether min is greater than the new value we're looking at from the array. And that's the case in which we want to copy that value into array. We'll use that serial comparator output as the load input to our register to perform the copy. So this one copy state does both the then case of the if, as well as logically sort of the comparison. And also the update of index. And that was shown in the flowchart. So let me flip back there. So the copy state will do this copy if it's appropriate, if we came down the true arc. And that'll be stored as the comparator output. And it will also do the index equals index plus one. So both of those in one cycle. So once we're done with copy, I mentioned we would look at index. The index register, if it's not nine, we still need to keep going. And if it's nine in the cycle in which we're copying, then by adding one to it, we'll make it 10. That's when the loop is done. So if it's not nine, it's not the end of the loop. We'll go back and start to look at another value. If it is nine, we're done. And that's it. So this is our high level state diagram. And this is where we kind of left off on Monday. OK, so that's our abstract state diagram. So now let's talk a little more detail. Now that we have an idea of what we're going to do with our finite state machine, let's put a little more detail into the components and what they need to be able to do. So we said that index in the C code is a 32-bit choose complement value, an int. So what we're going to use instead, we're only using it to count from actually one to nine. So let's just use the four-bit binary counter. We don't really need it to be a 32-bit value. We just need four bits. It just goes from one to nine in the loop. Now in copy, we're going to increment our index. That was a state where we're at the end of the loop and we do the loop update. So we want to count input to control the counting, because we're not incrementing in every state, just once we go around the loop, which is multiple FSM states. So we'll have this count input that says, go ahead and count. And if that's zero, the counter won't count. It'll just hold its value. Now similarly, if we want to, in the wait state, we can reset the counter to one. And then in init, instead of having another way to set it to one, we can just let it count. So normally, you'd have a reset input that resets it to zero. We can use a reset input in that way. In the wait state, we'll set the counter to zero, the IDX counter to zero. And then in init, it'll go from zero to one. And then here in copy, it'll be incremented using the count input. So those are the controls we'll need on the index counter, the reset for setting it to zero, and count to tell it to go ahead and count up one. But what about the array? We need 10 32-bit 2's complement values. So instead of just having enough cells to store 10, let's just stick down a standard memory. So some power of two addresses. So we'll round up. We'll say, OK, we've got 16 addresses, each of which stores 32 bits. And so you hopefully remember how to build this kind of memory. We've got read right here. We've got address here. I didn't put a chip select down just because it's always going to be on with our finite state machine. So you could hardwire chip select to one if you had a memory with a chip select. We're only going to read. The only thing we ever did in our finite state machine was read those values out. So from our point of view, obviously, someone else is going to have to override this at some point. But from our point of view, we could just always set this to one. Now before, I had this as write enable. Here I have it as rwbar. So here, a 1 means the r. So it just means always read. And if you look back at the code, whenever we read from this memory, we always read value subindex. So in particular, in the first state, we read value subzero. But remember that in that first state, in init, the counter index, we decided to set it to zero. So if we read value subindex, we're always going to be reading the right value. So in other words, this input here for address, I can just take the value of the index counter and hardwire it in there. And then it'll always be coming out down here, value subindex. So I don't need to do anything with that other than connect the wires. And you'll see that in the full data path in a minute. Make sense? Let's keep going. Almost to the data path, just need to talk about a couple more components. What about this min register? So min keeps track of the smallest number we've seen so far. It's a 32-bit two's complement value. So we need a register. So we'll have a 32-bit register. We'll call it min. So I'm using the fonts here. So this is the C code variable. This is our register and our data path. But otherwise, they have the same names. So what do we need for that? We need to be able to change it. So once in a while, we write a new value into min. So let's have a load input, like a parallel load input for a register. And so of course, we have to have it coming from somewhere. Well, where does it come from? So in copy, we copy value subindex into min. And in init, we copy value subzero into init into min. But in init, as I mentioned on the last slide, index is zero. So we can take the output from the memory, which was value subindex at all times, because we're going to hardwire the address port to the output of the index register, or counter, sorry. We just take that and put that directly in here. And whenever we set load to 1, min will copy value subindex. And so another thing we don't have to do anything to control in our finite state machine, it's always the same. Anytime we set this load signal to 1, min will then copy values subindex. Whatever index value is, that'll go into the address port of the memory. Out will come the 32 bits stored at that address, and that'll get copied into our min register. I'll go over this in the data path, too. OK, so then we had a couple more shift registers, shift registers A and B. Now, we decided we wanted to put values in those in one cycle. It's a little bit painful if we try to shift them in a bit at a time. We'd need to also count how many cycles that took. So we need something to just do a parallel load, let's say. So we've got a parallel load input on each of these two shift registers. They're right shifting, and then the bits will come out here. Remember that our serial comparator looked at the least significant bit first. So we want to look at the least significant bit first and work our way up to the top bit. So we're going to right shift those bits out of these shift registers. But when we want to load them in prep, we want to do a parallel load using this load input here. The 32 bits will come down from the top, get latched into the 32 bits of the shift register, and then they'll shift out one bit at a time in the compare state. So now, those only load one value. A is always set to min. B is always set to value subindex. So again, we can take the min register and take its value and just copy it directly into A, just wire it down here. And value subindex, we can wire directly down into B. And then whenever we want to set those values, we just set load and load to 1. OK. Last piece before we show the whole data path. So we need this counter to drive the serial comparator for 32 cycles. So we'll use a 5-bit binary counter. We'll call it count. We'll need a reset input, because again, when we're going to prep for the comparison, we need to reset that counter so it can count for us. Remember that the comparator here has a first bit indicator. So we have to tell it this is the first bit of the comparison. So that will be generated by a 0 signal. So when the counter holds the value 0, it'll generate 0 equals 1. And that will tell the serial comparator that the first bit is coming out to be compared. There's also the bits coming from the A and B shift registers down into the serial comparator. And so it's always just comparing the two serial output bits of the two shift registers. All right, so there it is in its full glory. So all this is, then, is the pieces I've shown you, and then a couple of other parts that we'll talk about later, like this done signal and this last signal and the then signal here. But you can see the memory. So the memory is always reading. It's taking its address from index. Here's our binary counter index. So it's driving the address port of the memory. The value subindex, then, is copied both into min and to B, but only when they exert their load signals. So if we want to copy value subindex into min, we set min's load to 1. If we want to copy value subindex into B, we set B's load to 1. The shift register A copies from the min register here, again, only when we set load to 1. A and B, then, feed the serial comparator. And then here's the counter that counts 32 cycles. Yeah? OK. Yes, so remember that the way this finite state machine will be used is some other logic will fill the memory with values. And then it will exert the start signal on the finite state machine, which will take it out of the wait state and start it doing its computation. And then once it's done, it'll go back to the wait state. And the external logic, whatever that might be, can come read this register value. And that will hold the minimum of the 10. Any other questions on this one? Yeah, Eric? Why is it so hard? Yeah, so we'll come back to this. We'll come back to this. We're going to use this. The counter will count from 0 to 31. And then when it equals 31, we shift out of the compare state into copy. And that will have been 32 full cycles in the compare state. That's right. That's right. After 32 cycles, the comparator's done. All right. So now we have all these components. We have them wired up nicely. So how does it actually relate to this finite state machine state transition diagram we drew? What's the connection? So not all of the signals in the data path are fixed. We still have a bunch of load signals and things like that. I'll highlight them in a second. What's left, those remaining input signals, are what you can call control signals, or what we call control signals. So the control signals tell the data path what to do in any given cycle. And it's the finite state machine that will decide what values the control signals will take. So the finite state machine will have, as outputs, those control signals. There are going to be six of them in this design. So using these signals, these control signals, the state of the finite state machine will cause the data path to perform the actions associated with that particular state. So I'll show you what I mean by that. First, let me show you the control signals for our data path. So on index, we've got index reset. The finite state machine has to decide, do I want to reset the counter now or not? Similarly, do I want to make the counter count now or not, for each state? Again, for, let's see, min, there's min LD. Do I want min to load a new value? There's also A, the A register. Do I want A to load a new value or not? So just ones and zeros. B, do I want B to load a new value or not? And then there's one more, which is counter reset, which is down here. Do I want to reset that counter? So by generating those six bits, the finite state machine controls all of the components in the data path to execute whatever action those particular states want to take. We haven't defined those yet. We've just talked about them. So how does the finite state machine then move between states? Well, aside from the logic we've already talked about, that well, after a knit, we always go into prep. I mean, that one's easy. We don't have to look at any inputs. The data path generates a few signals that the finite state machine can use as inputs for its transition. So there are three that we're going to care about. And they're these. So there's a done signal, which says, well, we're done with the last loop iteration. We've done this comparison nine times. We started with the first value. We compared the nine other values. And we're just done. The whole loop is done. We should go back to wait. And that's when index equals 9. So I'll show you that again in the data path in a second. There's the last signal. So that's raised in the last cycle of the counter. Counter is going to go from 0 to 31. When it gets to 31, after that cycle, we'll be 32. So in that cycle, that's when we want to transition the state machine out of the compare state into the copy state. So that last signal will just be equal to, does the counter equal 31? That's all. And I'll show you that in the data path in a second, too. The then signal, it says that a new minimum value has been found. We did the serial comparator. And it says, well, a is greater than b. We were comparing min to value subindex. And so if that's the case, we need to copy value subindex into min. And so this is the comparator output that says a was greater than b. These signals are going to be inputs to the FSM. So here they are. So here's done. You can see we take the index value. We compare to see, is it equal to 9? And if the answer is yes, then done is 1. If the answer is no, done is 0. Here we compare the counter value to 31. If the answer is yes, then last is 1. If the answer is no, last is 0. And then using the representation for a comparator, which you can look up in the notes, or just this is the right answer, z1 out of the comparator means a greater than b for the design we did in the notes. So this will tell us that, in fact, the two values we put in the shift registers, min and value subindex, min is greater than value subindex. And that was the condition under which we want to copy value subindex into min. So those are our three outputs from the data path that we'll use to drive the finite state machine. So why didn't I bother saying much about these? If I were to ask you to build this, would it be hard? Somebody said, OK, get out a piece of paper. You have five minutes to build this. Could you do it? You could. So what would you do? What's 9 in binary? 1, 0, 0, 1, right? So that means the four bits of the counter have to be 1, 0, 0, 1. That's all. And so it's just a minterm. So you'd say, OK, take the high bit. I don't know, call it index sub 3. And that with index sub 2 prime, index sub 1 prime, and index sub 0. If the pattern in the counter matches 1, 0, 0, 1, it's equal to 9. Otherwise, it's not equal to 9. So it's really maybe an AND gate and maybe a couple of NOT gates. That's it. Same thing down here. In fact, I think this is just an AND gate, all ones pattern. So those are easy. This is literally just the Z1 output. All right, so everything in the data path you know how to build. So let's go through then and make an abstract next state table. So we have five states. I want to use something called register transfer language. So what is that? It's just a way of describing how bits are moving around in our data path. So for example, start with a wait state. So for example, I'll show you RTL in a second. What does a wait state do? So wait is the state in which the FSM sits when we're waiting for some other logic to fill up our memory with values, so we can go compare them. Yeah. What? AUDIENCE 1. How do you compare them? How do you compare them? How do you compare them? How do you compare them? So if you remember the way our serial comparisons worked, the first F means first. Yeah, F means first. So for the first bit, you give it a 1. And for all the other bits, you give it a 0. All right, so wait is going to be the state we sit in. So what do we do? Well, when we get to init, remember, we wanted IDX to be 0. So we'll set IDX to 0 and wait. That way, when the start signal comes, index will always be 0 in the init state. And then we just sit there in the wait state until we see the start signal. So that's all this wait state's going to do. So we'll write that index gets 0 in RTL as follows. So you can see the thing you're writing into is on the left. You have a left arrow. And then the thing you're writing into it, the bits, on the right. So this could be some other register value on the right. That's what you'll see in some later RTL examples. But it's very simple. So there's an assignment operator, which is this arrow. So let's write that into the table. And then we'll have two next states. So the condition for the first next state will be, well, let's see if we see the start signal. I put one up there for you. So on start, we'll move to init. So if we see the start signal, we'll go to init. What if we don't see the start signal? Stay in wait. So if start is false, then we'll stay in wait. And that's it for our next state diagram, for this particular state, our next state. Let's look at init. So init is going to perform two different actions. So one is it's going to copy value sub 0 to min. And it's going to set index to 1. So how's it going to set index to 1? Well, just by telling index to count. So it'll actually set index to index plus 1. And then the next state from init is always going to be prep. So let's go back to our state table. So init does two things. So it sets min to value sub index. Remember, index in this state is 0. So this is the RTL that's actually executed, is to copy value sub index into min. And index plus 1 copied into index. That's the way we express things in RTL. So there's one thing I want to point out here. So in RTL, things are happening in the same cycle. So we might have a whole bunch of different actions. They all happen at the same time in parallel. The order that we list them cannot matter. So here, you see I'm changing index. So if this were C programming language or something, if I put this line down here in front of the other line, you might think, oh, I should use the new value of index when I go read the array. That's not the case with RTL. Even if you swap this order, you get the same result. Things happen at the same time. There's a piece of hardware. They happen in one cycle. You take the old value of index on all of the right sides. The fact that you're changing index, that happens in the next clock cycle. So just make sure you understand the notation, because otherwise, when you try to understand the diagram and the data path, and then later in 385, you'll also get confused. So in RTL, everything, all the actions happen in the same cycle. So just make it just to be clear. It doesn't matter what order we put them here. It means the same thing. So the next state, then, is always prep. Make sense? Let's go on. So the prep state, we have to do three things. We have to copy min to the A register. We have to copy values of index to the B register. These are both the shift registers. And we have to reset the counter to 0. And then we're always going to move from prep down to compare. So let's go back to our table. All in one cycle, all three actions. So condition, always, next state, compare. So remember, the counter, CNT, is what keeps track of the 32 cycles for our comparison. So by setting it to 0, we're getting ready to start counting. If we don't reset it, it's going to have some random bits in it. Good question. So let's go look at compare. So when we get into compare, A and B are ready to go. They got the 32-bit values. They're ready to shift out the first bit. The counter is just reset to 0, just as we talked about. So when we enter this state, that's what's set up for us. So all we need to do is just let the zero compare to do its work. We just need to sit there and wait, not do anything on anything else in the data path. The comparator and the shift registers will just keep shifting one bit at a time into the comparator. Comparator will keep cranking away, saying, well, what do I think about this bit? What do I think about these bits? And it'll keep doing its thing until the counter gets to 31. So this is a little easy to get confused. So maybe look at the extrema. If you wanted this to operate for one cycle, then on the first cycle, the counter value is 0. And so if you compared counter to 0, that would mean you spent one cycle in compare. So compare to 0, you spend one cycle. Compare to 1, you spend two cycles. Compare to 31, you spend 32 cycles. So we compare to 31. And then at the end of the 30-second cycle, we shift over into copy. And that means our serial comparator is fully done. And the comparison output are latched into the output flip-flops of the serial comparator. So we can then compare, was a greater than b? Remember, a was set to min, and b was set to value subindex. So when we're done with that, we'll go, when counter's 31 on the last signal, we'll go over to copy. So there's nothing to do in the data path, no RTL. So what are the next states? So what if last is true? Where do we go? Go to copy. What if last is false? Just stay and compare. I didn't draw the self-loop on the diagram, but just stay and compare. No, the shift registers are always shifting. We didn't put control. Only if you need to do something. Yeah, so OK, so the question is, do we need to do anything to make our shift registers shift? If we had had a shift input where we allowed ourselves to say, well, if I set the shift input to high, then they shift. And if I don't, then they don't. Yeah, the shift registers we put in are shifting every cycle all the time, regardless of what else is going on. So we don't need to take any action. Yeah. Yeah, so that was a more complicated shift register, just to show you how you could use a MUX to do different kinds of shifts in the same register. We don't need anything so complicated. Yeah, we only need a right shift register that's capable of parallel load. Yeah. 32. Yeah, so remember, these are all 32-bit values. And this is a serial comparator. It compares one bit per cycle. So to compare 32 bits, we have to wait for 32 cycles. Why does the counter start from 0? Because we reset it right here. Yeah, OK, so why did we compare to 31? So imagine that instead you compared to 0. How many cycles would you spend here? But when you first cycle, you come in, it's set to 0, right? So then in the first cycle, you would immediately move to copy. So if you compared to 0, you would spend one cycle here. If you were to change it to 1, compare to 1, you would move to copy. So if you compare to 0, you would spend one cycle here. If you compare to 1, you would spend one cycle with counter at 0. Counter would count to 1. And after two cycles, you would move to copy. If you compare to 2, 0, 1, on 2, the third cycle, you'd move. So whatever you put here, you'll spend this number plus 1. So by putting compare with 31, it means we move on the 32nd. Yeah, this is easy to get confused. So when you design these things, it's easy to be off by 1. It's like the A and C code, actually. It's very easy to be off by 1. So those are the kind of mistakes that people make all the time. And it's important to go through and look and make sure that you're really doing exactly the right number of cycles. Because if you compare for 33 cycles, you'll never have the right answer, right? It'll just be some random bits coming out of the comparator. Actually, that's not true. The way our comparator works, it'll shift more zeros in. So you can, our comparator is forgiving, but most hardware won't be. OK? All right. OK, one more state. So this finite state machine is going to move to prep or wait based on the data out, data, whoops, data path output done. So remember, done was going to compare index with 9 to see if we've looked at all of the array values. So done is equal to 1 when index is equal to 9. Copy, then, is going to, before it moves, it's going to increment index. And it's going to also copy values indexed to min if and only if the then signal coming out of the comparator is 1. So let me show you how we write that. So you can see there's two pieces of RTL. So again, they execute in parallel, right? So this index on the right and this index, OK, this thing is getting flaky. The two index values on the right, I'll stop using my laser, sorry. The two index values on the right are the same. And they're the old value of index. Index only changes in the next cycle. So again, the RTL is parallel. The two different statements happen at the same time. The then colon notation means that the action after the copying value subindexed to min only happens if then is equal to 1. So this is how you write conditional statements in RTL. You put the condition, you put a colon, and you put the actions that follow. So this says, well, if then is equal to 1, we'll copy values subindexed to min. If then is equal to 0, we do nothing for that first statement. There's no else clause in RTL, at least usually. I suppose you could write else and then do something else. Normally, you would write a then prime clause instead. So you'd have multiple conditional clauses. The index equals index plus 1 is not conditioned by then. So the counter will always increment. Now, when we see the done signal, we go to wait. Get my laser to work. When we see the done signal, we'll go to wait. If done is off, we'll go to prep. We're never sitting in copy for more than one cycle. Here. AUDIENCE MEMBER 2 Are not, like, inside the states? That's right. There's no difference? Yeah, on the right here, these are the transitions. And these are the actions inside the states. So if you remember, when we wrote next state tables before, we had state output and next state. These are actually the coded outputs. The RTL is the coded outputs. We're going to translate that in a minute into the data path control signals. So each statement in RTL, we have to be able to translate into data path control signals. And that's the part where you might have to go back and forth. If you realize you don't have components that can execute what you want done, you might have to change your components. All right. So it's time. I know you've been waiting. You're excited. Oh, I gave you the answer. How many bits do we need? Three? OK. Is that OK? Two flip-flops? Can you give me two flip-flops? So we're going to do something called a one-hot encoding. Why we're going to do that, you'll see shortly. You'll see what it makes easier. So here's what it means. So in each of our states, there will be one 1 in one flip-flop. All the other flip-flops will be 0. So it's one-hot. There's one 1. So the wait state will be 1 and a bunch of 0s. The init state will be 0, 1, 0, 0, 0, and so forth, as you see there in the table. So let's fill in the control signals. In wait, we have to set index to 0. So what should we do for index reset? Put a 1 there. That'll force index in the next cycle to have the value 0. What about count? Probably safe to do 0. We didn't actually define the behavior for our counter if we tell it to count and reset in the same cycle. So let's just set it to 0. For the rest of them, they probably actually don't care. But I'm just going to make things simple and just set them all to 0, because we don't want to change any of those other things. We don't want to change min. We don't want to change a, b. Otherwise, we'd see it in the RTL. So we don't need to reset the counter. Let's just set all of those to 0. So here's init. We do two actions. So we're going to set min to value subindex and index to index plus 1. So what about index reset? What should that be? 0. We don't need to change index. What about index subcount? Or we do need to change index, but we don't need to force this to 0, I should say. What about index subcount? 1. What about min load? 1. So wait a minute. So all I did is min load. How do I make value subindex get into min? So if you think back to the data path, any time you set min load, it's always going to load the same thing. And the same thing is whatever is on its input wires, which is always value subindex. So in the way we built the data path, any time you put something new into min, that something new is going to be value subindex. That's just the way the data path works. All right. What about a subload? 0. Don't want to change a, right? How about b? 0. Count reset? Good. All right. How about prep? So in prep, we had three things to do. So set a to min, b to value subindex, count to 0. So what's index reset? 0. Index count? 0. Min load? 0. a load? 1. b load? Good. Count reset? Good. OK, so compare. We had no RTL. What's index reset? 0. Keep going. 0, 0, 0, 0. Good. All right. There's no RTL, right? The counter, the way we set this up, the serial comparison and shift registers, they just do their thing. We don't have any work to do. And so we just send all 0s as our control signals. What about copy? So this one's a little tricky. So we need to increment the counter. And then conditionally on the data path output then, we need to copy value subindex into min. So what's index reset? 0. What's index subcount? 1. What about min load? Then. Good answer. So somehow, we need to make sure that this min load only happens when the then signal is true. So we're going to use then as the bit that we send. Good. What about a load? 0. b? 0. And then count reset? OK. So now you'll understand why one-hot encoding is nice. What's index reset? Come on. Hurry up. S4. Good. That was easy, right? That's why one-hot encoding is nice. What's index count? S3 or S0? Good. What's min load? S3 or then S0? Good. And then what are the rest of them? S2. Pretty easy, right? No k maps at all. So often, if you do the one-hot encoding, you have this table of control signals. You just write it down, you're done. It's very, very easy. For two flip-flops, we saved ourselves a lot of time. If you want, you can go back and do this the hard way. Why don't you use it all the time? Once in a while, you might want to have a more compact. If you really want to minimize your design, you know how to do it. But this is easier. Also, we had only five states. If you had 1,000 states, maybe you don't want 1,000 flip-flops. It depends on the complexity of your design. The trade-off is still exponential. But the exponent here is tiny. Y is what? S0, because you have to be in this state in order to. So each of the states has its own S variable. And this one, we have to AND it with then in order to make sure we're in copy when we apply the bit. All the other, well, not all of the other bits, but the three other states here, if we just put then in, we would have all these four states included. And the then output, the comparator is always outputting 0 or 1. So we don't want to change states. I'm sorry, we don't want to change min just because the comparator happens to output a 1 bit in some random cycle. So let's see. Next state logic is also pretty easy. But in order to figure it out, we have to look at the incoming arcs. So let's do that. So here's the wait state. What are the incoming arcs? So I didn't draw the self loop. But whenever you don't have a start signal, you stay in wait, which is an incoming arc. And it also comes from copy at the end of the loop. So that's on the done signal. So you've got two incoming arcs. So to write that, we'll say we're in the wait state S4. And we don't see the start signal. So S4 ANDed with start prime. Or we're in the copy state, which is S0. And we see the done signal. Those are the two cases in which we're going to move into the wait state. Now, again, it's really easy here because we just have to calculate the cases in which S4 is 1 in the next state, which means the incoming arcs. So this is the answer for S4 plus. So what about S3 plus? Start ANDed with something? S4, right? We want to make sure we're in wait. We don't want to just go there any time we see a start signal. So S4 ANDed with start, good, is S3 plus. What about prep comes from init, right? And from copy, but only when the done signal is on. So what should S2 plus be? I'm hearing an S3. Yeah, OK, so this is S3, right? Or S0 ANDed with done, done not, yeah, sorry. Good, so that's S2 plus. What about compare? Well, I did leave the self loop out, right? So S2 will bring it from prep, ORed with S1 ANDed with what? And last. Then, remember, is the then statement in the original code. So it's the thing that changes if we find a smaller value. Changes min if we find a smaller value. All right, so copy then comes from compare when we see the last signal out of the counter, right? So what's the S0 plus? S1 and last, good. OK, we're done. So this is a pretty complex, confusing design, I know. But hopefully, we went through it carefully enough that you feel like you understand it. It is in the notes. A lot of finite state machines will look like this. But more importantly, this is what a computer is going to look like. So we're going to break up our computer into a data path, which will have a bunch of components that can execute instructions. So instead of taking a fixed piece of code, we're going to have little pieces of code, which logically do small amounts of processing. And those will be our instructions for a computer. And the finite state machine then, all it's going to do is it's going to say, OK, I'm a computer. I'll go fetch the instruction. You're going to store all those instructions in memory. That'll be your program. So the finite state machine will go fetch an instruction from memory, look at the instruction, figure out what you want it to do. There'll be a representation for your instructions. And you'll say, OK, I can do that. It'll go through a few states to execute that instruction. Then it'll start over. Another instruction. Do its thing. Oh, another instruction. And that's a computer. Just infinitely, finite state machine, fetch an instruction, decode it, execute it. Fetch it, decode it, execute it. Yeah, a modern calculator will have a processor inside of it. And the processor is doing that. It's running a little program that corresponds to watching key entries and displaying. The computer processor itself is based on FSMs. The program is written as software is encoded instructions and stored in memory. And the processor is basically the finite state machine and the data path. Finite state machine will look at the instruction, fetch the instruction, look at it, decode it, and execute it, and then do that over and over again forever. No, because next is von Neumann model. But I want to just make sure if anyone has any questions about the design or anything, too. So any questions on that design? Feel like you understood it well enough? I know it's pretty fast. No, I mean, realistically, we couldn't ask you to design something this complicated on an exam. I wish I could. But there are so actually, OK, so in terms of the exam, the thing to look at is the examples from previous exams. A lot of it is analysis. So there is, I think at this point, we won't have time to cover it in class. But there's an example of analysis of a traffic light controller in the notes in section 3.3 at the end. And part of the point of that is helping you to learn how to go look at the diagram and analyze it, understand what the human meanings are, and things like that. There's also a little bit, there's a little mistake there. So you want to go through, I mean, purposely there's a mistake in the design. So you can do the analysis and understand how it's supposed to work, and then understand what the issue is. And it'll lead you through that. We often have that kind of thing in homeworks and exams. So I mean, it can't be as complicated as the one in the notes. That'll take you a while to work through. But you'll see, if you look under midterm 3, there's a whole bunch of old 190 problems that I solved for you. And so there's a couple of packets, one of the problems and one of solutions. And so I'd highly recommend people go through those. There aren't online tools for finite state machines yet. So look at all those examples, solve them. If you don't understand the solution or you find some of the other old exams with examples, I'm sure you can. I'm happy to talk about them in office hours. Come show me your answer, and we'll talk about it. But I think do spend some time on it, because we probably will have an analysis kind of question, where we say, here's a state machine. Figure out what it does, and figure out how it works. Which would be, look at the data path and figure it out. On the final two, I mean, we're going to start looking at the LC3 design. And on the final, you'll be expected to understand that well enough to make use of it. But we have a few weeks for that. Yeah. All right. Yeah. Yeah. I can't find it. Mm-hmm. I can't find it. Yeah. So how do you figure out how to break things up? It's partly, again, dependent on the components. So what you can do is just try to map it onto the set of components you're thinking about using. If you can't make it work in terms of control signals, then either you add components or you add states. And then you have to do one or the other. So it's up to you to make them match, that you have more freedom than I showed you here. Because you can also add components. You can make more sophisticated components. We could have started out, as I mentioned, on Monday, and said, oh, you want to compare 10 things? I know how to build a 10 operand comparator. We're done. Finite state machine. Run comparator. Get answer. Done. All right. We'll start over. OK. Does it make sense? OK. And I think we're out of time. If you want to ask more questions, come on down. Otherwise, we'll start by Noem in on Friday. Thanks. Thank you.\"},\n",
       " {'ECE120-2016-10-19-LEC-23-slides.mp4': \" I know midterm. Yeah, another midterm tomorrow night. No, I'm just kidding. All right, so sorry I'm a little running a little late. So today we're going to do start talking about designing finite state machines using components. So the first thing we'll do is take our keyless entry design and add a timeout. So we'll use a counter to do that. And so we'll, we'll talk about how to do it and then show how we can do it without actually even knowing what the implementation is. So we'll use whatever you came up with. So remember, I left that open for you to do the next state logic. And we'll just take whatever your next state logic was and extend it using a box. So then we'll do a vending machine. So both of these are just examples taken from the notes. So you can look there for more detail if you want. So to get started, first, I wanted to just remind you that, you know, when we did combinational logic design, the first thing we looked at was just taking it all the way down. We did truth tables into k maps, we solved k maps for good forms, either SOP or POS. And then we took those and turned them into gates. So we can always go down to that level or even lower. We can optimize at the transistor level if we want to. But it's often easier to build combinational logic with components. So we can pull an adder off the shelf, a mux, a decoder, whatever, comparators, and then plug things together and then just kind of get the meaning and build it pretty quickly. Won't be as small or as fast, but it will be much easier and much less likely to have errors. So we can do that with combinational logic. We can do the same thing for finite state machines. So we can always go through the way we've been doing it and say, OK, for each state, we're going to draw a circle. We're going to think about how many states there are. We're going to do log base 2, round it up, figure out how many flip-flops we need, assign just as many bit patterns as we need, and then go from there, do the logic with k-maps, et cetera. But we can also organize them hierarchically. So we can think of a circle as representing a bunch of states. And we can think about motion between those groups of states. And we can build our finite state machines up hierarchically. So to do that, we can use both the combinational logic components, things like I mentioned on the last slide, adders, comparators, muxes, decoders. But we can also use things like registers and shift registers. So registers and shift registers can hold part of our state for a finite state machine. So let's go through the keyless entry just to remind ourselves of what it was in terms of inputs, outputs, state machines, stuff like that. This was a week or two ago, right? One midterm ago, as we measure time. So as you may recall, the finite state machine design only reacted to user input. So we had unlock, lock, and panic buttons, which if you have one of these things, I happen to have one in my pocket, you can see the little red panic button on there. Actually, mine has a trunk button too. So if the user pushes the panic button and didn't do anything else, then the alarm would stay on forever, right? Or until the car battery dies, whichever comes first. So let's modify that design. So let's make the finite state machine actually turn the alarm off after some amount of time. So if you push panic, the alarm starts sounding, and then you walk away. So maybe you were just out of hearing range and you pushed it, your car starts making loud noises, but you don't notice it. So you go into your lab or whatever and you come out 12 hours later and your car battery is dead. So instead, let's make the finite state machine turn it off after some time. So here were the outputs for our keyless entry system. So just to remind ourselves, so we had D, R, and A. So that was D means if it's one, that means we've unlocked the driver's door, zero would still be locked. The other doors, all the other doors controlled by this R signal, one again means unlocked. The alarm is on when the A signal is one. So those are outputs. And then our inputs were unlock button, lock button, and panic button. And we get one when that's pressed by the user and zero if it's not. So then we had our state table. This is just the state table with bits. So we had four states, the lock state, the driver state, the unlock state, and the alarm state. And then these are the outputs for each of those states over here and the representation we picked for the states. And then this thing is our full state transition diagram. So I color coded these when we built it up. So maybe I'll just go through them color coded again. So the normal protocol of walking up to your car and unlocking it and maybe someone else is with you, so you unlock it again. So the first time you push unlock, you go from the locked state over to the driver state. And then you push it again, you go from driver down to unlocked, and you can keep pushing it if you want to, but you stay in that state. All of these, oh, sorry, I guess I left this loop off. There's a self loop here for staying in the driver state if you don't push anything. But if you push the lock button, that has second priority, actually second to panic, which are the red arcs. But the second priority is the lock button. So if you push lock, it doesn't matter whether you push unlock. So this is X for the U input here. But all the black arcs go into the lock state. And then similarly, the red arcs out of all of the states into the alarm state. So if you push the panic button, we said that has the highest priority. So regardless of what's going on with the other buttons, XX1 and ULP arcs, they all go into this alarm state. So that was our design, our initial design. So what exactly do we want to do with that? So after user turns on the alarm, we want the finite state machine to start measuring time. And then once a certain amount of time has passed, the finite state machine should turn off the alarm. So how does a, how does a, well, in what unit can a finite state machine measure time? Yeah. Question or answer? Okay. Yeah. So that's, that's the same thing I'm trying to describe. So my, my question for you then is the same. How can you measure time? Clock cycles, right? Yeah. Good. Did you have a question, Daniel? You're just going to answer. Okay. You're going to answer. Good. In clock cycles. So what component can we use for that? Someone already said it. Counters. Yeah. So we can use counters. You can use a ripple counter. You can use a binary counter. I'm not even going to look at the counter, right? I'm just going to say there's a counter, right? We know how to design counters. Actually, we'll look at the counter a little bit. So we'll use a counter. Here's the counter we're going to use. So it's a down counter. So it's going to count down. We're going to put in some value from the top and we'll decide what value later. I should have next slide, but we'll put in a value by, by putting this load input equal to one. So when we set load to one, the counter will load a new value and then I'll start counting down from that value. When it gets to zero, it'll produce Z equals one. Okay. So this will count some number of clock cycles for us. And after that many clock cycles, it'll generate the Z equals one signal to tell us, okay, the time's up. You know how to build one. Right? So if I said, okay, get out a piece of paper, I'd expect you would all be able to do this for arbitrary size counter. It's just going down instead of up. It's just a binary counter. So the counter gives our finite state machine some new inputs and outputs. So first of all, we've got this output Z from the counter, which is an input to our finite state machine. So that's a new input. And then to control the counter, the finite state machine has to output this LD signal to tell the counter when it should load a new value. And it has to somehow set the counter input value. But I claim that the counter input value is just going to be a fixed timeout, right? We're always going to have the same timeout. We're not going to say, well, this time, let's make it five minutes. Next time, let's make it 13 minutes. Well, now seven minutes, right? It's always going to be the same amount of time. So let's just hardwire the value input. So some T cycles, I'll set T minus one as the counter input. And I'll illustrate why it's T minus one instead of T in a second, that T will be the timeout in cycles. So the number of bits in the counter then depends on T. If we're going to load T minus one into the counter, the number of bits we need depends on T. And that in turn depends on the clock speed. So I pulled a 16-bit microcontroller from TI off the web, and its clock speed was 16 megahertz. So if you go buy one today, that's the typical clock speed. So if you want a five-minute timeout, well, that's 300 megahertz. And the clock speed is 1.6 times 10 to the 7 cycles per second, 16 megahertz. So you need this many cycles, 4.8 billion cycles to count. So you need a 33-bit counter. And once it's counted to 4.8 billion or down from 4.8 billion, five minutes have passed. I got that right. Sounds big. But you need a 33-bit counter. OK, so I couldn't fit those many circles on my slide. So I'm going to draw a few. So let's use those counter bits, which I'll call timer, to split the alarm state. So we had one alarm state. So now we're going to split it up into, I guess, four or almost five billion states. So we'll have lots of states. When the user turns on the alarm, the system will enter the alarm zero state. That'll be the first alarm state. By setting timer equal to t minus 1, which means just setting load high. And that'll force the counter to load t minus 1 into the timer bits in the state of the counter. And it will be done. So we've got a few states here, I guess almost five billion. So this dot, dot, dot is 4,000,900,000. So that's what we're going to draw it as. So we've got the alarm zero state on the left. And there we've loaded the timer bits with t equals 1. So this is the first alarm state. And then after a cycle, we go to the second alarm state, alarm 1, which has timer t minus 2. And then we just keep going and going and going. And eventually, we might reach alarm of t. I guess that should be t minus 1, sorry. Alarm of t minus 1, where timer equals 0. And that would be the state where the counter output z equals 1 to say it's reached 0. So this is why I set it to t minus 1. This should take t minus 1 steps to get to there. And then once z equals 1, the finite state machine can turn the alarm off. And so that's t cycles after you've turned it on. So t is some really large number. Yeah. And if you had a 16, so going back a slide, if you had a 16 megahertz clock, t would be this. Yeah, 4.8 billion. So it's a fairly large number. Not for computers, but for us. All right. So before we had S1 and S0. So in all of these states, we're going to keep S1, S0 to be the alarm, the original alarm representation. So when S1, S0 equals 0, 1, that still means alarm. Our output logic will be the same. Actually, the logic for all of the states except the alarm state will be the same. So we're going to replicate all the outgoing arcs from alarm, because we've already got logic that takes the system out of the alarm state to other state when things like you push the lock button. So if you push the lock button, you want to go to the lock state. So that was an outgoing arc. So for each of these states, we're going to have an arc labeled ULP X1, 0, meaning we don't care what unlocked was, but if they push lock, then we're going to go to the lock state. So if the alarm's been going off, doesn't matter how long it's been going off, you push the lock button, the car locks, the alarm turns off, just as before. So what if the user pushes panic? What should we do? So the alarm's on, and say two minutes have gone by, and they push the panic button again. We should reset. Good. That's what I thought, too. I mean, you could just let it keep counting down, but then every five minutes if there's still panic, or for some reason they have to keep pushing it. So let's go ahead and reset it. So what does that mean? Well, that means all of the transitions with ULP XX1, any time they push the panic button, which I didn't draw here, but any time they push the panic button, they go back over to the left side. So they're going to reset the timer back up to T minus 1, and then the timeout will actually happen five minutes or whatever we represented, five minutes after the last time they push panic. That's when the system will turn the alarm off. So you've noticed I've added, or you may notice I've added these down here as well. So now that we have this arc I'm not showing with XX1, then we know the leftover, the motion between these states is when you don't push panic or unlock. Remember, this is UL and LP. Unlock, remember, we decided when we did the original design, we decided that unlock would not affect the alarm. So if you push the unlock button, it doesn't turn the alarm off. So similarly here, if you push the unlock button, it doesn't matter. You just keep counting along and eventually you'll turn the alarm off automatically. So what happens then when the timer reaches zero? So the counter is going to output Z equals 1, and the finite state machine can use that to leave the alarm state. So where should it go? Locked. So why not unlock the driver? Yeah, it's probably not a good idea. I mean, it's a design decision, but you turn your alarm on and you walk away, and then when you come back, your car is unlocked. Not the best thing, right? All right. So sometimes design decisions, they seem like there's a good answer, right? But no one would think about it. It's just the right answer. All right, so let's say locked. So we'll add that in. Whoops. We'll add that in down here. So I've added this little arc saying, well, once you time out, that transition that turns the alarm off will go back to the lock state. All right. Well, that's the design so far. So we're going to treat these other states as just single states, right? I mean, the bits are there in the timer. The finite state machine state now consists of, let's say, 33 extra bits. But we're not going to even think about, well, what about the driver state, right? It's now 4 billion states also, right? But it's OK. We're just going to treat it as one group of states that has the same behavior and has no dependence at all on these timer bits. Same thing for locked. Same thing for unlocked, right? They have no dependence at all on the timer bits. Oh, yeah, that's a good. I'll let you do that on an exam. That's a good question. I don't know what to say. I actually did put that on an exam. But maybe I won't do it for you now. In fact, I was surprised because I put it on an exam. And then, of course, I wanted to solve it before I put it on the exam. And I found that it actually further simplified the design. I was very surprised. So yeah, you can use the same timer to, say, do something as Advaita is suggesting that after you've unlocked the doors, maybe they automatically lock after a certain amount of time. And that time doesn't have to be the same, right? If we picked a different time, say, Q, what would we do to decide whether to put Q or T into the counter? Amox, right? Yeah, good. Can you have asynchronous finite state machines? Yeah, you can. Yes, you can. And I mean, the finite state machine abstraction in general doesn't need to be synchronous with regard to anything. But in our class, we're only looking at digital systems based on clock synchronous design. So I mean, in any real world system where time is a continuous variable. So I mean, when we model aircraft behavior or things like that, we don't model it as a time dependent. Anything where there's rates of change also, they're not synchronous. So the states are split, but their behavior is independent. So we're going to keep treating them as single states and not worry about it. We could use the timer for other purposes. We could use it, as Advaita suggested, to turn off the, or I'm sorry, to lock the doors after a certain amount of time. But we don't have to. So let's think about the implementation. Can we use the old design? Yes, we can pretty easily. We just have two things we need to think about how to do, right? So if we have the old design, we put the timer down, the counter down, I should say. What do we need to do? Well, first we need to set the timer to T minus one whenever we enter the alarm zero state. And so if we enter that state, we need to make sure the timer bits are accurate. The counter, actually I'll jump down, the counter is actually going to handle the transitions between those states, right? It's the down counter. So every cycle, it's just going to count down. That'll take us from alarm zero to alarm one to alarm two, et cetera. So we don't need to do anything there, right? The counter already has that logic. To move from alarm to locked when Z equals one. So somehow we have to set up logic somewhere in our next state diagram or our next state logic to make sure that when we hit alarm T minus one, that we take the system from alarm to locked, right? And that we'll know when to do it because we'll see Z equals one. All right, so let's look at this first one. So we want to set the timer to T minus one when alarm zero is entered. So remember that we decided when are we going to enter alarm sub zero? Well, anytime we press the panic button, right? So what signal should I use to load the timer? Just P, right? If I just do this, I put up, sorry. If I put P into LD, right? Then anytime you push the P button in the next cycle, the counter will load T minus one. So as long as we also make, well, we already know actually in the original design, whenever you push the P button, you'll go into the alarm state. So I guess this solves the whole problem, right? The other logic for going into alarm sub zero is already part of our state machine. We've already got the logic to go S1, S0 equals zero one. So now we also have the logic here, just by putting, connecting P to LD. We also have the logic to make sure that we're going into the alarm sub zero state anytime you push the panic button. So that serves both to enter the alarm state as well as to reset the timer if you're, if you're pushing it again. Pretty simple. All right, so we're half done. What about this one? This one's a little trickier. So we want to go from alarm. Alarm is S1, S0, zero one over to locked, which is zero zero when Z equals one. So we only need to change S0. So how can we do that? Is there an easy way or do we need to go look at the big state table and, you know, add another variable? We had five already. You want to do a six variable Kmap? Okay. So do you think of a way that I can, I can somehow, I don't know, choose between the old stuff and the new stuff? I liked, I liked the besides the something. If you put a, if you put a flip flop in the middle, you're going to end up delaying things by a cycle, right? If you use that as state, but maybe. Yeah, I think, I think I'm hearing mucks and mucks a couple of places. So let's just use a mucks. So we've got the thing that you were supposed to build on your own, right? This original S0 plus logic, right? I showed you the table and I said, okay, you know how to do this stuff, so I'll leave it to you. Let's say someone's done it, right? So we've got that. We'll just put the zero input of the mucks from there and we'll have the one input of the mucks be zero, right? So when the, when we want to go, when we want to force the system to move from alarm to lock, we'll set the mucks selection input to one and it will go to that state. And then otherwise if the mucks select input is zero, it'll just act as it always did before. Okay. So all I did is kind of push the problem around a little bit, right? So what controls the mucks select? So when do we want to go from one to the other? Z is one. I put that last, so we'll remember that one. Okay. What else needs to be true to force this transition? Yeah, no panic, right? What about other buttons? So unlock we decide to ignore, right? Okay. So unlock doesn't matter. What about lock? Yeah, it's, it turns out it won't matter either. But, but in terms of the transition that we're adding, we said it was ULP equals X zero zero, right? And what about just being in this alarm state? What is the alarm state? Zero one, right? S one S zero zero one. So we don't want to force, if we're in some other state, we need to be a little careful. We don't want to force this, this S zero to zero for in some other state, right? So I would argue the first, the first thing we need to make sure is we're actually in the alarm state. So if we're in the alarm state, and there's other things that people mentioned that we need ULP equals X zero zero. So it didn't push locked in push panic. That was our transition label. So this is the state, right? So all I really did is I read, okay, I want to go from alarm to locked. Here's the state that I'm starting in, here's the transition label. And by the way, I wanted to add this thing, which is the other thing people mentioned, right? So this thing says, okay, the timer has now counted down to zero. So if I put all those three conditions together, I get S one prime S zero from this, I get L prime T prime from from the transition label, and I get Z. Now, as someone already mentioned, if we press L, we're also going to locked, right? So our system is already going to do that to us. So it doesn't much matter if we just drop the L prime, right? If we drop the L prime, this is this is going to give us the same behavior. Alright, so here's the diagram. So you'll notice that I've encapsulated the S one plus and S zero plus logic in these little boxes, right? Whatever someone already solved, that's all done. It's just a box, it takes ULP S one and S zero, and it calculates next state for S one plus calculates next state for S zero, sorry, which is S zero plus. And those would have normally just gone into S ones D input and S zeros D input. And that was our finite state machine. Now we've added our counter, we've taken P and connected it to the load input as before, put t equals one hard coded bits into the counter, parallel load input. And then down here, we have z equals one and it with P nodded, so P equals zero and it with S one nodded and it with S zero. So this is our mux control signal. So if that thing is on, we want to force S zero to be zero, which we do with this mux input is one, you get the zero and put that into S zero. Otherwise, you've got a zero on the mux select, then S zero plus just goes in there and the finite state machine acts like it used to. So all we needed was a counter, a couple of inverters, an AND gate and a mux. That's all. Any questions? The output logic is also the same. I didn't draw it on here, but we don't need to touch it. So whatever we calculated before, we just keep the same output logic. All right. So there are a few examples, we won't go through all of them. But I wanted to do at least one. So I think we'll start this, I doubt we're going to finish it today. So this is a vending machine. It's more complex than the one you do in the lab. So it's a more realistic vending machine. But I wanted to show you how you can build things out of components. So we're going to use a few different components for this vending machine. We'll have registers, we'll have adders, we'll have muxes, we'll have decoders. We're also going to develop a new component, priority encoders. So the priority encoders are often used for things like deciding which device gets attention when you have multiple devices on one processor. So you prioritize them, and you put the inputs about getting attention from the processor into priority encoder, and out comes an encoded number saying, well, this particular device you should look at now for the processor. So we'll also do one little module specific to this FSM design, which will translate an input representation into a value for us. Not unlike the one on the midterm last night, actually. So let's assume that we're going to sell three items. So why three? So every item we put into our machine is going to have a price. So we have to keep track of that. We have an input to identify it like a button. So when you have your vending machine, you have to be able to buy that thing. So you're usually going to have a button or some set of buttons that scale up with the number of things you could buy. And they'll also need a release mechanism to drop that product when you buy it. So if we choose three items, it's big enough to be interesting. So all of the pieces we'll have to develop, we'll have to think about and think about how we would scale. But it's small enough that we can fit it on slides and kind of show you easily. So that's why the vending machine will sell three. I think once you understand this implementation, you could pretty easily say, well, I want a vending machine that sells 100 things and just go extend those. It's not that hard. So let's think a little bit before we start. How is our vending machine going to work? So I claim this is kind of a general protocol for a vending machine. So you walk up to the machine, say you're the user. You look through the items. You say, OK, I want that thing. It's probably Dew or Nutella or something. And you see you want to buy it. And you then put some money into the machine as the next step. The machine has to keep track of how much money you put in. So we need some state in the machine to do that. When the user has put enough money for the item, then the user pushes a button. So this is our expected protocol. This is the abstract model design process, the first step of designing a finite state machine. So you push a button. And then the machine checks, of course, how much money you've put in. And it sees you've put in enough money, releases the item for you, and deducts the price of the item from how much is stored inside of it. So it has to keep track of that, too. Often, most machines you'd encounter would then give you back all the money that was left. Our machine won't. It'll just keep your money and hope you'll buy something else, mostly for simplicity. But we won't do this last step. So I'll just read it out. So what's going to be the main state of the vending machine? OK, so let me ask this a little different way. So yeah, I mean, if you get no input, you'll stay in the same state in the couple meanings of state. So what I meant here is, what information does the vending machine have to keep track of? It's the money, right, is the main thing. So simplest answer is maybe how much money is being stored. And as people said, if we don't do anything to it, it'll store the same amount of money. That amount will only change when the user pushes buttons or puts coins or bills in or something. So let's use a register. Let's use a register to hold the amount of money. So when the money is inserted, we can use an adder. You put some money in, you've got some money there, put some more money in. How much money is there altogether? Well, why don't we just add it? We'll store it as a number. We'll add the new number, put it back in the register. So what about when I buy something? What should I use? So subtractor, which is also an adder, by the way. So when we want to make a purchase, we'll subtract. So we'll just represent the amount of money as some integer. And then when we put money in, we'll add to that integer, put it back in the register. When we buy something, we'll subtract from that integer and put it back in the register. So those are some of the pieces we'll use. So how much do products usually cost in a vending machine? A couple of dollars? Yeah, that's what I thought too. So $1 to $2. I've seen them up at like $5 to $10, but I don't go back to those vending machines. So how much money can the machine store? What do you think? Yeah, OK. Yeah, I said $2 to $4. So that's probably about enough. We can make it bigger pretty easily. Coins or bills or both? Yeah, probably both, right? Or credit cards, even better. Our answer is going to be coins. So we're going to accept coins, but no pennies. So let's count money in nickels. So the amount of money we'll store will be a number of nickels. So our state is register N, which is the number of nickels stored. I just really like nickels. So I just wanted to have, it doesn't actually matter much at all, right? So I wanted to have a variety of values that were around the cost of an item. And so if you put coins in, then those are all close enough to the, somewhere under a dollar, up to a couple of dollars cost. So it gives some variety. That was why, to make it more interesting. Plus, I can use the N for the register name. I needed other letters for other stuff. All right, so the machine we said should store a few dollars. The value of N is in units of $0.05, $0.05. So N should hold maybe 40 to 80. So we'll just have a six-bit register. Again, you can take this design. You can make it eight bits. You can make it 20 bits if you want pretty easily. Just cross out the sixes, replace it with whatever size you want, right? So it's pretty easy to extend this. So in this case, the maximum is 63 or $3.15. So that's what our machine will be able to store. So we have to pick something, right? It doesn't much matter for the design process what we pick, but we have to pick something when we build it. So what about item prices? So these should be easy to change, right? So we could say, OK, to make our design easy, we could hard-code these prices. So item 1 will be $1. Item 2 will be $1.50. But instead, let's keep those in registers. So we'll throw some more six-bit registers in to hold item prices for our three items. Whoever owns the machine can then set the prices. And I wanted to also introduce this idea of abstraction in the sense that we're now going to design a finite state machine where decisions will be based on numbers, but those numbers will actually be in registers. So we won't be able to even know, well, what exactly transitions do we have without thinking about specific values of these registers? So we're actually going to abstract away the notion that, well, we have to look at every arc. I mean, every arc has to be specified. We'll actually specify them in terms of unknown values. The values are there in the registers, but we have to read them out to use them. So the prices will be stored here in registers P1, or rather, as values P1, P2, and P3. We'll store those in six-bit registers. So those are state. That's another 24, I'm sorry, 18 bits of state there. But again, we're going to abstract those away for the most part. So we're going to design our finite state machine, assuming that our prices are constant, but they're not known in advance. So they're just going to be numbers. So the user will set the prices, and then the finite state machine will operate. But we won't know what those are until we're actually operating. OK, so now we have a model of what we want to do. We can start to draw an abstract state table. So here are a couple entries. There's a more complete table in the notes with all of the possible inputs. So here's just an example. Well, so here's the first one that someone already mentioned. So if nothing happens, if the user does nothing to the machine, all of these lines are coming from state n. So if you're in state n, meaning that you've got n nickels, and nothing happens, they don't push any buttons, they don't put any money in, then what happens is you always stay in that state. You don't accept any coin, or rather, this x says, I don't care if the coin accept signal is yes or no, because you didn't put a coin in. And you don't release any products. You don't just drop products out every once in a while. All right, so that would be nice, but maybe not to the owner. So the other thing here, I want to mention now the condition. So you can see there are two input events, quarter and serdu. So what actually happens depends on the current state. So well, there's a design decision implicit here, actually, in the answer. So what should happen, do you think, if you've got, what do we say, up to 315? So you've got $3 in the machine, you put a quarter in, what should you do? Steal the money. Okay, we need to change this. Yeah, so I've used those machines too, but we're going to design a nicer machine. Yeah, I've used the machines where you don't have to have $3. You can have nothing, and you put the quarter in, and it just goes away. What quarter? No, but if you're going to overflow your register, right, if you're going to go above 63, instead, we'll just return the coin. Okay, so this is checking, right, a quarter is 25 cents, so it's five nickels. So if you add five to 59, you get 64. So we don't have space for that in our six bit register. So if n is greater or equal to 59, then we'll stay in state n and reject the coin. So we'll send the quarter back. We still won't release the product. On the other hand, if we can add five, the value of the quarter to n, then we'll go to state n plus five, keep the coin, and also not release any products, of course, for coin insertion. Okay? Make sense? Okay. So here's another couple of examples. These are for the product selection. Again, they're actually same things for item two and three. All of these are in the notes if you want to see the big table. So again, starting from state n, again, two choices, and then this condition. So in this case, what we do depends on whether n is greater or equal to the price. So here the user is trying to pick item one, we have price one for item one. So if the money in the machine n is at least as big as p1, we're going to sell them the item. So to sell them the item, we make two changes. First, we subtract p1 from our current number of nickels held. So we go to state n minus p1. And then we also release the product number one. So we give them the product and we take away their money. Except coin doesn't matter here because we're just doing the abstract model. So there is no coin. And so we just don't care. On the other hand, if they haven't put enough money in, then we just ignore them. We stay in the same state, we don't release a product, and except coin again doesn't matter. All right, so you would you would flesh all of these out as part of your abstract state table for all the different possible inputs. So then let's go on to step two of our FSM design process and say, well, what exactly do we want our inputs and outputs to look like? Right, we need bits. So input, we're going to get a coin sometimes. So it's going to be a three bit value, c. It's going to be c21c1c0. We're going to assume that someone's providing us with a representation. So I'll show you that representation on the next slide. But we don't get to pick it. It'll just be this is the kind of coin you're getting. And here's here's the three bit value to tell you that. So get that input. We'll also get product selection buttons. So these will be like the UL and P buttons before except it'll be well if I want product one, I'll push b1 and then b1 will be a one. There's also b2 and b3. So those are inputs, six bits of input. Our outputs will be coin accept. So one means accept the coin that just came in. Zero means rejected. And then item release signals are one or two or three, each of which means release one particular item. So if you set that high, that gives them one of those items. So that's our I O. This was the representation I mentioned. So often, I talked about this a little bit earlier when we first talked about designing I O, but often someone else is going to pick the representation, right? You're going to have to interface with some standard or you're going to interface with a component someone has already built or is just buying off the shelf. And so what information it gives you and how that information is represented, you don't get to control, right? If you want, you can translate it to a different representation. But again, you have to build logic to do that, right? So here's the representation we'll assume. So if no coin comes in a cycle, we'll get one one zero. If a nickel comes in, we'll get zero one zero and so forth. So we've got five different kinds of coin. We've got this no coin input, right? That's the no event, or no input event. These are the values in dollars. These are the values in nickels. That's for later. But this is the representation we're going to use. So of course, two patterns are not used, right? There's only five coins and one no coin. So two patterns are not used. And when we use this, we'll put don't cares for those because we'll assume that this representation is valid and the coin mechanism is never going to give us the other two patterns. So one aspect of the outputs that we need to be careful about, and we need to make sure that we communicate with the people building the other parts of the system, we decided that the finite state machine never produces outputs based on inputs. So in other words, these tables, the abstract state tables I just looked at, and the next state table we just looked at, it gave the outputs as a function of the inputs, but we don't build things that way in our class, right? So we're going to calculate the outputs based on the state and the inputs, but then we're just going to put those in flip-flops. So the output for the coin, you put a coin in cycle 10. In cycle 11, the coin mechanism will get the accept signal. So the coin mechanism designer needs to know, well, you're not going to get the answer until next cycle. They can keep putting coins in every cycle, they'll get an answer delayed one cycle, because we don't want our output to depend directly on the input. So we'll just put those in flip-flops, but those outputs now are also state. So we've got four more bits of state. So we have an abstract model, we have IO, what's next? Remember we had this six-step process, right? We said, okay, do an abstract model, specify your IO, then you've got to complete your specification, right? Okay, good. So how many bits of state do we have? So if we ignore the prices, let's see, ignoring the prices, we have six-bit register for the number of nickels. What else do we have? Four bits of shared output, of stored output, right? So 10 bits, okay, 1,024 states. Not too bad, right? Anyone want to draw 1,024 circles? What about inputs? Remember? We have coin, right, which is three bits, and then we have three buttons, so six bits. Okay, so 1,024 states, each with 64 arcs. Remember, digital system has to be complete, so we have to know what each of those does. Good luck. All right, so we better simplify. So first of all, this poor output bits, those don't have any impact on where we go next, right? So even though we have 1,024 states, we're going to ignore the output bits. We're just storing them because we want them to be held for a cycle so that the coin mechanism can see clearly, accept or reject for a full cycle, can use it to drive its gate or whatever, right? So those we're going to ignore. So each of our state sub-ends will then be actually 16 equivalent states. So just like we said, well, the driver state, it's got the 33-bit counter, but it's all just one state for our purposes, right? So here, each of these states, based on the number of nickels, nothing matters. Sorry, these output bits don't matter at all, so they all look the same regardless of what the output bits are. So we'll have 16 equivalent states, but we'll just represent it as state of n. So that reduces from 1,000 states down to 64 states. So the other thing to notice is that we have these two unused bit patterns in our coin input, so really it's not 8 times 8. It's not 2 to the 6th. It's 8 from the button input. It's 8 different button combinations and 6 choices of coin. So we only have 48 arcs. That's still a lot, right? 64 states, 48 arcs each, that's a lot. So before we make it easier, so our table had only 9 input events, right? So we had nothing happen with 5 types of coin and we had 3 types of purchases. So where did the other 39 arcs come from? How come we have 48 arcs? So when we completed specs before, what kind of things do we have to worry about? Short answer is humans, right? Long answer is people pushing more than one button, people putting a coin in while they make a purchase. These input events are only 9 of them that we care about, but nothing keeps a human user from doing them at the same time. So when we multiply them all out, we get 48. I wonder how we map them to a function that says... In the past, we did pretty simple strategies. I wouldn't say they don't care. You do have to make a decision that makes sense. I mean, for example, probably a user wouldn't be happy if they put a coin in and push the button, it happens to be the same cycle, so you just decide to eat their coin. An owner wouldn't be happy. I mean, if you said it don't care, you could also release all 3 products, right? Yeah, so that's a good answer, right? So one strategy is just to say, well, let's pick a priority, and that's what we'll do, is we'll pick a priority, and then we'll say, we're just going to strictly prioritize. I'll show that in detail in the next slide. Do you want to say something? I was going to ask, like... Yeah, yeah. So Eric's suggesting that, well, what if we just say, if you do more than one input, we ignore all the inputs. And absolutely, yeah. So if you do more than one input, we could say, okay, in that case, we do nothing, right? The choice we'll make this time is just to pick a prioritization order. So let's choose a strategy. So we'll prioritize, and we'll prioritize strictly, so meaning that we'll ignore the lower priority events and try to execute the highest priority event. Now this is a little... There's going to be a little strangeness here in the following sense. So let's say that your highest priority event is a purchase, so you put a dollar in and you push the button too quickly. Your dollar's enough to pay. Without the dollar, you didn't have enough to pay, and we're going to prioritize purchases. So we check, do you have enough money? We say no, we don't let you buy it. We're not then going to go say, oh, but you put a dollar in. No, we're just going to ignore all the other input events. So your dollar will get returned also. It's a little strange. You could make it more flexible if you wanted to, but it's a little more complicated. So we're going to have it very simple. We'll prioritize them strictly and try to execute just one of them. So our strategy will be purchases are highest priority. Item three is the highest priority. So if you push button three, the only thing the system will do is try to sell you item three. If you didn't push button three, then it'll see if you tried to buy item two, then item one. If you didn't try to buy anything, then it'll see if you tried to put a coin in. Now the coin inputs are all distinct. We're getting this three bit input that says nickel or dollar. You can't put both in at the same time, so we don't need to do anything there. We don't need to pick a priority. All right, so now we can actually go back and write a complete next state table. It's actually quite large, so you don't want to really do it. But just to show you what the kind of thing it would look like, so if you pick some prices, so let's say that P3 is 60 nickels, P2 is 10 nickels, P1 is 35 nickels. And let's say that we're in state 50. So I've ordered these in priority order. So the first one says, well, if you push button three, then it doesn't matter whether you push the other two buttons. So those are don't cares on the input side. It doesn't matter if you put a coin in or not. Don't care about that pattern at all. Your final state will be state 50. Wait a minute, why is that? So you tried to buy item three. You had 50 nickels. Oh, but item three costs 60 nickels. So the answer is no. You only put 50 nickels into the machine. You tried to buy something for 60 nickels. So the answer is no, you can't buy it. So don't release anything. R3 is zero, R2 is zero, R1 is zero. We don't release any product. Why do I have zero here instead of don't care? Yeah, so we said we don't care what coin they put in, but if they put a coin in, it should come back to them. We don't want to take it just because they happen to try to buy something in the same cycle. So even though in the abstract diagram when we try to make a purchase, we said we didn't care, in this case, we actually do care. We want to return the coin to them. So the next line is trying to purchase item two. So we're kind of running out of time, so I think I'll try to finish this one up and maybe start again with it on Friday. Try to purchase item two. In that case, item one doesn't matter, coin doesn't matter. The cost is only 10, right? So we'll go ahead and let them purchase it, which means we'll go from state 50 down to state 40 by subtracting 10, and then we'll release item two for them. Similarly, we're going to reject any coin they happen to put in. Technically, yes, but we're going to design with components and make sure that our rules are followed. So that's why I said you wouldn't want to really write this out, because it also depends on the prices. So when we get to this level of abstraction, you really don't want to have to—you want to be able to verify your ideas without going to this level, because this level will blow up. Yeah, so I mean, we would still say go from—we would still have our conditions and still say to go from n to n minus p. Yeah, yeah. Okay, let's stop there and we can we can follow up more offline if you want, because the time's up. Don't want to hold people up. Thanks.\"},\n",
       " {'ECE120-2016-10-12-LEC-21-slides.mp4': \" Okay, so I think it's three. So today we're gonna start off with binary counters so we can start doing some finite state machine designs. It looks like the amplitude is up. So we'll talk about synchronous counters, we'll talk about ripple counters. Synchronous counters are clock synchronous sequential circuits and ripple counters, the flip-flops of some, I'm sorry, the flip-flop outputs drive the clocks of other flip-flops. I'm gonna turn this down slightly. Okay, maybe that's better. Then we'll talk about machine models. So in our class, we'll assume that outputs are never a function directly of inputs, but I'll show you a machine model where that is the case and talk about the differences and why we choose not to allow that dependence in our class. And then finally, we'll go through a six step design process for finite state machines and use that for a small example. On Friday, I think we will cover mostly the design of the lab FSM that you'll be building on your protoboards. I mean, you've already started building that, but actually implementing it in the protoboard in the next week and a half, and maybe two weeks. So that's the plan. We did get your feedback surveys and we have the tallies. I read through most of the written comments. The only thing is they didn't correlate the written comments yet with those which are from you versus those from other students. So I'll look at it more deeply over the weekend and come back on Monday. So reminder, we have midterm coming up, which hopefully you know. Next week, next Monday, we have a review session and this slide you've seen a couple of times, so I won't spend too much time on it. Oh, there is one other bit of information I have, except I should have written it down from the email. Eta Kappa Nu is running another review session on the weekend. It's on the 15th, I think it's on the 15th. I'll give you the details on Friday, but you can probably also find it out from Eta Kappa Nu people, or post it on their site or something. As always, we can't endorse, if they make mistakes in the review session, we can't endorse that, unfortunately, but it should be useful. All right, so what happens if we think about a finite state machine that has no inputs? And so it's gonna start in some state, and then where's it gonna go in the next clock cycle? Oh, it goes to some other state, right? There's no input, so there's exactly one arc going out of the state, it goes to some other state. And then what will happen next? Go to some other state. We'll keep doing that, right? But at some point it'll run out of states because of the finite state machine, there are finite many states. So eventually it's gotta go back to one of these states. So eventually it's gonna go back to a state. So let's just go back to that one, and we're gonna get a loop, right? Yeah. Sure. So it doesn't have to change state, that would be a loop of one state, right? So it would also be a loop. So you can decide how many states you want in your loop, it could be one, it could be four, it could be a thousand, but it has to be finite, right? And that's a good question. Okay, so it'll go around in some loop of some number of states. Now, if we have such a finite state machine, we call that a counter. Now, counters sometimes will add inputs to them. So we might say, well, I wanna be able to start and stop my counter, so I'll use an input for that. Or maybe I want a counter that counts up and down, so both ways around the loop. So maybe I'll add another input for that. Sometimes maybe I wanna reset it, so I wanna force it back to a known state, maybe I'll add an input for that. But generally speaking, when we talk about counters, we're talking about something with one loop and it's normal operation is just to go around that loop of states. So we're gonna talk about two kinds of counters. One is synchronous counters, which are clock synchronous sequential circuits. So these are the same kind of designs we've been talking about for the last couple of weeks. We use flip-flops to build them, we use a common clock to all of the flip-flops and they all change state and allow us, they all change state on the rising edge of that clock and allow us to think of time as being discrete. And so time's just an integer. We'll also look briefly at ripple counters where the flip-flops of some, I'm sorry, the outputs of some flip-flops are used as the clock signal to other flip-flops. We're only gonna look at binary counters for these, so simple designs. But so the reason we'll look at them is they can actually save you a lot of energy. Let's start with an example of a counter, we'll do a synchronous counter first. So here's a state transition diagram with eight elements. And if you look at these, these are just counting from zero and unsigned, zero, one, two, three, four, five, six, seven, go back to zero. And so this is a three bit binary counter. So in order to build this thing, first thing we'll do is just copy that into a next state table. So what's the next state from zero, zero, zero? Good, and then? Good, keep going. Good, good, okay. So you realize this is very easy for this one, right? Generally speaking, it's not too hard for a counter. What if I had six states? What would I do with the other two rows? Just put Xs, right? Because I don't care. Now, we'll look at a design like that probably on Wednesday, because on Friday, we'll do the lab design. We might get to it on Friday. On Monday is a review session. So we'll look at a design where we have some Xs later. For now, let's just do K-map. So we'll start with S0. So here's K-map. So let's copy. So remember when we copy, what I did is I put S1 as zero on the top here. So right across the rows, as S1 as zero changes. And then since this is gray code order here and the K-map binary order here, I'm gonna go first, zero, zero, zero, one, over to one, zero, and back to one, one. So one, zero, one, zero, one, zero, over to here, one, and then back to the one, one slot, zero. And then one, zero, one, zero again. So one, zero, one, zero. Okay. So what's the, what's, what loop should I circle there? The square on the outside? Yeah, okay. I'll do all of these SOP, by the way. Yeah, good, good thinking, those of you who are about to ask me about POS. It's just as good, right? It's actually the same answer here. So I think that's the S0 prime loop there, which you could also choose to write as S0 XORed with the one value. You'll understand why later. So then what about S1 plus? So throw up a K-map, copy. So zero, one, one, zero, zero, one, one, zero, and then zero, one, one, zero again. What are the loops here? Yeah, so these two and these two, right? Okay, good. So that's S1, S0 prime, S1 prime, S0. And that's just S1 XORed with S0, right? Okay, so we have S1. So what about S2? So, I'm sorry, zero, zero, zero, one, zero, zero, zero, one, and then one, one, one, zero, one, one, one, zero. Oh, this one's messier. Okay, so there's one. What else? These two over here on the left, okay. And then two again. Okay, good. So if I wrote those out, that's S2 prime, S1, S0, the same order. So that's this one. S2, S1 prime is this one. And then S2, S0 prime is the one that wraps around there. Okay, so that's a little messier looking. Maybe we should try to do five bit and see if it gets uglier, we think. All right. So I wanna ask you a different question. When you count, have you been counting recently? Yeah, counting is important. When you've been counting, when does the place value change? So for example, you're counting along and you get to what number that say the thousands place value changes? 999, like here. So you're at 0999. Sorry, I'm a computer engineer, so I put a leading zero. So then the thousands place changes, right? Or if you're at, what's the next one? 1999 or 2999? What about the 10 thousands place? When does that change? Ah, so 0999. Do I say enough lines? Anyway, it's up there. So like that, right? So you see the rule? What's the rule? All the lower digits have to be nine, right? So that's when a place value changes. So what do you think that rule is in binary? All ones, good. Okay, so, so far, whoops, you didn't answer. So, so far we have these equations. So we have S0 plus is S0 plus XORed with one. S1 plus is S1 XORed with S0. S2 plus is this nasty thing. Can you simplify that? So remember, it's gonna change when the lower digits are all one, right? So here, there are no lower digits. So the lower digits are always all one. So we XOR the digit with one. Here, the lower digits is just S0. So we XOR the digit with the lower digits, which is just X0. So here, we've got two lower digits. So we should XOR S2 with what? S1, S0. So I'll leave it to you to verify that these two are the same. I think they're the same. Is it that easy? Okay, yeah. If you apply to Morgan's, I'm sure, yeah, you'll get this one out, right? Okay, good. I can't say it that quickly, but I'll believe you. All right, so let's use our general theorem to build a bigger design. So what if we wanted a four-bit binary counter? Do we need to draw a K-map or can we just write down S3 plus? Sure, what is it? Like that? Okay, good. And then S4, sorry, I skipped ahead. Okay, and what's S5 plus? Like that. Okay, so we can build an arbitrary big counter, right? So here is a counter using what's called parallel gating. And so you can see that in this design, we're basically just using the equations. So here, I've just fed the inverted output back. So that's equivalent to XORing with Y, right? Here, I am XORing the current value of S1 with S0 from over here. Notice that I've drawn these flip-flops backwards, right? So the least significant bits now on the left. I did that just because it's easier to draw the logic. So most significant bits are over on the right. The next digit, we've got S1 ANDed with S0 out of these two flip-flops, then XORed with S2, and then the last one ANDs all three of them together before feeding into the XOR. So these are just the equations we saw. Yep. That's okay. Good question. Here's an answer. Here's a serial gating. So what you should notice is, as Raul pointed out, so now we have, instead of, let me go back a second. So here we were starting to build up, right? This AND gate has three inputs. If we continue, the next AND gate would have four, AND gate after that would have five, but here's S5 plus, right? It has an AND gate with five inputs. S6 plus would have six inputs. S10 plus would have 10 inputs, right? Bigger and bigger AND gates. So instead of doing that, we can build in this serial approach where it's the same label, but you can see I'm using S1 as zero. I'm reusing the output in order to calculate S2, S1, S0, right? So these are serialized so that each of these AND gates, instead of getting bigger and bigger, is now only two input. So I'm saving a little area. And the expense, as Raul also pointed out, is that, well, now I have to wait to go from here through here, through here, through here, instead of, in the parallel design, taking the outputs and all merging them into through this one gate. Now, of course, the gates are actually gonna be limited in number of inputs, so we couldn't really build it exactly this way. So in practice, they use a combination, right? So parallel gating gives bigger gates, so more area and less delay. Serial gating gives smaller gates, so less area, but more delay. In practice, your gate sizes are limited. You can't have 20 inputs. So you use a combination of the two. Yeah, Raul. Yeah. Time. So usually, it's a function of the actual semiconductor process. So the process technology will tell you which implementation would be faster. And there's actually, usually, you're also leaving things like transistor sizing for the tools to finish off for you. So it's really, without going into those proprietary parameters in the process, you probably couldn't answer that question precisely. So it's, now, in terms of rules of thumb, usually, maybe four inputs and drive four outputs is about the point at which you wanna go to more gates instead of bigger gates or more outputs. Okay. So that was a synchronous binary counter, right? So what does that mean? Ripple counter, one loop of states. Binary just means the outputs are binary, hence, I have numbers going in order. And synchronous means they have this common clock. So now, let's go take a look at a binary ripple counter in which the clock is not shared. Okay, so now, the flip-flop clocks will not have all the same clock input. The flip-flops will not have the same clock input. So in a ripple counter, we're gonna take the outputs from some of the flip-flops and use those as the clock input to other flip-flops. And I'll show you an example in a second for a binary counter, binary ripple counter. Why are we gonna do that? So remember, when we talked about power, I mean, I said, mostly, it's outside the scope of the class, so don't worry too much. But remember, when you change a transistor, you're gonna have electric current flowing, right? So you're gonna change some voltage from zero to one, one to zero, electric current's gonna flow, it's gonna generate energy, basically, flowing through a resistance, it's gonna take energy, right? It's gonna take power. So it'll increase power consumption. And so by clocking the flip-flops more slowly, then what happens is we reduce that power consumption. So total energy is reduced. So in a lot of embedded systems, people use ripple counters. The trade-off then is that the changes to the internal state instead of just happening at the same rising edge of the clock, in order for that change to happen throughout the counter, well, what you'll see is the change has to go through one flip-flop, then the next flip-flop, then the next flip-flop, and so on, till it gets to the end. So the changes, just like the ripple carry adder are gonna ripple through the counter, they'll be much slower. And we won't actually quantify that, but you'll see that it's slower than synchronous counters. The other thing you might think about... Let's take that offline. I mean, basically higher voltage is a stronger electric field, so electrons will move more quickly. So you're fighting the delay issues. As you'll see that it will be a bit-sliced design. I wouldn't say that in general, you couldn't do anything more complicated, but for our class, the only one we'll look at is a bit-sliced design. So what about clock skew? We said, well, let's avoid clock skew. In general, it could be an issue. We're just gonna look at one simple design. And honestly, more complicated ripple counters, as long as you're operating, as long as the clock is just managed within the counter, you can say, well, as long as the circuit person gives me a level clock edge into my ripple counter, I'll manage the clock delivery within that counter. So it's not really as hard as general circuits problems. All right, so here's the ripple counter we're showing. So you can see this is a simple bit-slice. So each of these is just replicated four times. And then what's going on is for each of the, the bits are again backwards. So least significant bit takes the real clock. And then the next least significant bit takes the inverted output of the first bit, of the lowest bit as its clock input. And then the second bit does the same. Third bit does the same from the previous bit. So Si plus one takes its clock input from Si inverted, Si prime. So that's these circles down here. Also notice that Si prime is also the D input. So for each of these flip-flops, the bit-slice takes the inverted output and feeds that back into the D input. So what that means is every time any of these flip-flops sees a rising clock edge, it's going to toggle its value. If it's holding a zero, it'll become a one. If it's a one, it'll become a zero. Okay? All right. Yeah, go ahead. The initial state of Q naught, if we assume that the bits are starting all zero, then the initial state of Q naught would be one. Yes. Yeah. Okay. So let's take a look at a timing diagram so that we can understand what's going on. So up here, I've drawn a square wave clock, and these dotted vertical lines are the rising clock edges of the clock. So that clock is going into Z naught. And then the clock is going to be a one. So that clock is going into Z naught. So these are the initial values of the three bits we're storing. So they're all starting low. So at this rising clock edge, what's going to happen to Z zero? It's going to flip, right? Remember that on all of these, we fed the value complement back into the D input. So anytime we see a rising clock edge, we're going to flip the value. What about this rising clock edge? It'll go back to zero, right? Good. How about that one? Up to one. Good. What about the next one? Zero. And that one? One. Good. And one more. Good. All right. So then let's think about, well, what about this Z one? So remember Z one sees Z zero inverted as the clock signal. So when you've got this rising edge in Z zero, that's a falling edge for Z one's clock. So when a flip clock sees a falling edge, what does it do? Nothing, right? These are positive edge triggered flip flops, just like we've been using. Right? So when it sees a falling edge, just ignores it. Z one stays the same. What about when Z zero drops here? What happens? It's going to flip Z one, right? Good. What about when it rises? Nothing. Good. Falls? Flip. Okay. And then I'll skip the next one because that's just another rise, which when you invert that, sees another falling edge in Z one's clock. So what about this last one here? Flip again. Right? Good. Okay. And so Z two then, remember, sees Z one inverted as the clock signal. So Z one is flat. So this one also won't change, right? What about on this? Would it follow Z zero? So Z two, the only clock it sees is Z one inverted. So Z one inverted doesn't change here at this dotted line. So it's just a solid, Z one inverted is a solid one. So that clock for this flip-flop does nothing but stay high through this dotted blue line, the first dotted blue line. So Z two doesn't change. What about when Z two goes from low to high? Going to ignore it, right? Because remember it's Z one inverted is the clock input for Z two. So this is a falling edge for the clock of Z two. So it gets ignored. And this one is flat. So ignores that. What about this falling edge in Z one? It's going to flip, right? Because the falling edge in Z one is a rising edge in the complement of Z one. So that'll change Z two. And that'll stay fixed because we don't have any other falling edges in Z one. Yeah, Rahul? The flip-flop's expected to stay at a constant height. Yes. So the observation Rahul made is that basically the period of each of these flip-flops, if you look at it as a period, so this one is twice the clock period, right? So if our clock, for example, were in gigahertz, this would be flipping at half a gigahertz. This would flip at a quarter gigahertz. This would be an eighth and so forth. Okay, so what that means is basically, if you remember summing up exponential powers, if you had an infinite number of these bits, the first one flips half the time, the next one flips a quarter, the next one flips an eighth. If you add all of those up and you say, well, on average, how many of my bits will flip? It'll be two, right? I'll show that in a second, but thank you. Yes, it's counting. But the point there was two bits will flip on average, whereas if you're toggling all of your clocks, then internally those latches will be changing a little bit. The clock will be recognizing that the, I'm sorry, the flip-flops will recognize that the clock input has changed. Some of those transistors will turn on and off. And as a result, you will be burning energy. Here, you're only flipping on average, you're only showing the clock edge to two of your flip-flops on average, right? And so you're using a lot less energy for that reason. So let's look at the counting comment. So I want to make sure you understand how to read these. So I'm going to draw a line down in this clock cycle to the left of the first dotted line. So remember, this is the high bit, right? So this is zero, zero, zero. So that's a zero. What about this one here, this clock cycle? Zero, zero, one, right? So that's one. This clock cycle, zero, one, zero is two. Zero, one, one, three. One, zero, zero, four. One, zero, one, five, and one. I see we're going to have to put counting on the exam. Okay. Yeah. Yeah. Yeah. So it's a ripple counter, but yeah. So you're worried about the speed? Yeah, I mean, the speed is going to be slower. Keep in mind, it's only rippling here through three flip-flops, right? So it takes, the clock speed may be limited by the delay of rippling through three flip-flops. So that may be the longest delay in your system. So that may limit your base clock speed. It wouldn't be what? It depends what you're trying to do. If you're talking about an embedded, so the question is, is this useful for a 32-bit processor? If you have an embedded system at the low power design, so your clock is probably not multiple gigahertz anyway. And so since you're not trying to pressure clock speed high, it doesn't matter that this part is relatively slow. And it also saves you a lot of power. So I think it depends in context of embedded systems, the low power designs go sort of hand-in-hand with slower clocks. You really don't need your intellect breaking system and sampling it, 100 megahertz even, right? I mean, human real world events just don't happen at that speed. So you don't need a processor that runs at that speed and you don't wanna drain your battery, even though it's just your car battery. Okay, so let's then talk a little bit about machine models. So there are two machine models. These are mostly names of historical entrance. So we've said a few times now, the FSM outputs in our class are gonna depend only on the state, right? So FSM outputs could depend on inputs, but in our class will only depend on state. So historically that kind of finite state machine was called the Moore machine. And the more general model in which these outputs could also be a direct Boolean expression of including the input variables was called a Mealy machine, right? So in practice, once you go out in the industry and you start building these things, even in 385, I think, you can always use Mealy machines, right? To the point that most of my alumni in industry come back and tell me, why do you still teach these things? I don't even know what they mean. So the names are really just historical interest. There's reason for this and I'll kind of illustrate why. And I also wanna tell you, well, so if everyone is using this one in industry, why are we teaching you the simpler version? So if a designer wants an output in industry or in practice, let's say, if you want an output to be independent of inputs, well, you simply write equations that don't include the inputs, right? You want them not to include the inputs, we'll write equations that don't include inputs. You're done. So it's not that hard. So why do we use, why use the general model in industry and in practice? Well, inputs carry information, right? There's information in your inputs. And if you use that information, sometimes your finite state machine will be a little smaller, a little faster and so forth. So people say, well, of course, we're gonna just try to use it. So why not? Why don't we use it in our class? So as you'll see in a second, if your outputs depend on your inputs, what that means is your output timing depends on your input timing, right? And so now instead of having this nice model of discrete time, now we've reopened the timing issues, right? And so instead of allowing that to happen without thinking about it too carefully, we simply use the Moore model and say, well, output should not depend directly on inputs. Well, let me give you an example to illustrate the timing issues. So let's say that we wanna recognize the sequence zero one on an input. So the idea is we've got some serial input, every clock cycle, there's a new value on this, sorry, this should say in, not B, and this should say out, not Z. So whenever the input is zero in one cycle and one in the next, we want our output to be equal to one. So this is something we call a zero one pattern recognizer. So here's a design for it. So this is a Mealy machine to solve this problem. So we've got a flip-flop and we've got an AND gate. So we've got the input here, goes into the D, and then we've got the AND gate with a complimented value of the stored bit and the current input. So output is now a direct function of input. So what is the next state equation here? What is S zero plus? Just whatever goes in here, right? So what is that? Just in, not meant to be hard. All right, what's the output equation? So what's out in terms of this one and that one? So in ANDed with S zero prime, right? So if you look at the output equation, in means that the current input value is one and S zero prime means that the last input was zero. And so we said, we're going to do zero one recognizer. If you take these two conditions and AND them together, you've seen a zero one, so the output is high. Otherwise you didn't see a zero one, so the output is low. So remember that we are assuming still on the SO values, these only change at the rising clock edge. Not so easily, not so easily, because then you'd have to factor in all the gate delays and go back to continuous time. Now, if you can do full simulations between the time is continuous and that output and language and dots Time 0 last to last impacts, then we don't need 1, 7, 2, 7, 6. simulations, treating time as a continuous variable and doing transistor simulations and IV curves? Yeah, I mean, you don't need it, but you'd probably want to. You can do it by hand if you want, but it's not that fun. To some extent, I mean, to some extent, that's what we were doing when we were counting gate delays. So I mean, you do the same thing. You count gate delays. That's an estimate. OK, so all right. So let's then draw the state diagram for this thing. So we have two states. We have S0, so just one flip-flop. So we have a 0 and a 1 state. Now, state diagrams are going to look a little different, because outputs, so here you'll notice there's no output bit. And that's because outputs now depend on inputs. So it's not a function of the state anymore. It depends on the input, too. And if the input changes, the output will also change. So we can no longer label our states with output values. So instead, those are going to go in the arcs, in the transition arcs. So now our states will just have state bits. So this is S0 equals 1. This is S0. I'm sorry, S0 equals 0. This is S0 equals 1. And our arcs will be labeled with input in slash output out. Let me add some arcs here. So when I get a 0, I'm going to go into the 0 state. And when I'm going into the 0 state, well, that means my output is always 0. Also, so this is 0 slash 0. So input and output are both 0. When I'm already in the 0 state, well, I stay in the 0 state, right? My D input is still 0. So I've got a self loop from 0 back to 0 labeled 0 slash 0. So what about if my input is 1? If I'm over here in the 0 state and I have an input of 1, well, then my next state is 1. In is 1. And my current output is 1 also here. So that's 1 and 1. So my output should be 1. So the arc here going from 0 to 1 when I have a 1 input will also produce the 1 output. That means I've recognized the 0, 1 combination. All right, then I have a self loop 1, 0. So again, if I see a 1 on the input, my next state is 1. But if I'm already in the 1 state, now this output is low. And so my AND gate produces a 0. So this is the complete state transition diagram for our 0, 1 recognizer as a Mealy machine. So let's take a look at what that does in timing. So remember, out is in ANDed with S0 prime. So first of all, in this diagram, you see a rising clock edge here. That rising clock edge causes S0 to accept input as its current value. So after this first rising clock edge, S0 is 0. Once this input then goes from low to high, so S0 is 0. So this output is high. Once in goes high, this output now produces a 1. So this input rising edge produces a rising edge in output, even though the clock cycle has not changed. We're still within the first clock cycle. Now, that output stays high only until the next rising edge of the clock. As soon as the rising edge of the clock comes, input is high. So S0 will change to 1. That means the output will go low again. So once we get over here, the output will drop back down. So I've drawn this pretty thin. And the thing is that, well, if that rising edge on input came later, it would be even thinner. In fact, it can be arbitrarily thin. Its width depends on the timing of this input rising edge here. And if that arrives at some arbitrary time with respect to our clock, we can't put a lower bound on how thin that output pulse is. So it could be very, very thin, that we only produce this little tiny bit of 1 output. So usually, that doesn't matter so much. So if your inputs come from some flip-flops on the same clock and your changes arrive early enough, it may limit your clock speed. But usually, it doesn't matter. If you're coming from some other flip-flops on a common clock and you're using flip-flops, or rather, you're driving other flip-flops with a common clock with your outputs, it's not going to make much difference, which is why, in practice, people just use this model and don't worry too much about it. The problems will come if you have inputs that are external. So if there's some human user producing inputs or some other system with a completely different clock producing inputs, or if your outputs are used by some other system that's not on the same clock, in that case, you really do have to worry about the relative timing. So when you start putting things together in later classes or in industry or something, you will have to worry about these kind of things at the edges of your designs, and not in the same clock domain, really. And in our class, you don't have to worry about it. So how do we fix this? Should we just go redesign it all with a Moore machine? What should we do? Can you turn this into a Moore machine for me? How about this? Just throw a flip-flop in. So if I just add a flip-flop, now there's a Moore machine. I mean, this is the state bit, so I can affect the output with a state bit. Wait a minute, that's sort of delaying things. In fact, if you think back to our serialized designs, we always delay things. The output of these machines is never reflecting all of the inputs until the next clock cycle. So let's take a look at a timing diagram, but I claim it's no different from the things you've already seen, which is a factor with using Moore machines. So let's take a look at it. So what this is going to do, by adding this flip-flop here, we're actually logically splitting this one state into a 1, 1 state and a 0, 1 state. Now, the 1 and the 0 are different, because they call this one S1. So that's the high bit. So we've got three states now. And now we can put our inputs or outputs into our state. So we've got the 0, 0 state, which is 0 here and 0 here. In that case, remember, output is just S1. So S1 is 0, so output is 0. Here's a 1, 1 state. Output is just the same as S1, so the output is 1. And here's a 0, 1 state. Again, 0 is just equal to that 0 there. So now the outputs are part of the state, just like you saw when we talked about finite state machine transition diagrams on Monday. And that's because there's a Moore machine. So here, sorry, I meant to do this analysis first. Well, n is just going to S0. So if I have a 0 on my n, then S0 plus will be 0, because that just goes straight there. Similarly, n goes over to this AND gate. So if my input is 0, S1 plus will also be 0. So that's why any 0 takes me from any state into 0, 0 state. So I have these three arcs all going into 0, 0. What happens when n equals 1? So then S0 will be 1. I'm sorry, S0 plus will be 1. So if I give a 1 input, my next S0 plus bit will be 1. And let's see, S1 plus will be 1 ANDed with S0 prime. So S1 plus will just be S0 prime. So from here, I'll go to 1, and then S0 is 0, so to 1, 1. So if I see a 1 in the 0, 0 state, I'll go over here. Now, I claim that's actually my recognizer. So to be in this state, I should have seen a 0. And after that 0, I saw a 1. And that'll produce one cycle of my output 1. And that's what I wanted. I wanted to recognize 0, 1. So what if I see another 1? Well, I shouldn't produce another cycle of 1, because that would say, well, 0, 1, 1. So I should stop producing output 1 at that point. So if I get another 1, I'll go from here or here. In both cases, S0 is equal to 1. So S0 prime is equal to 0. And so S1 plus is also equal to 0. So both of these states on a 1 are going to go down to this state and not produce a 1 output. Yeah, Will? What if I see another 1? Yeah, that's a good question. So that's why I didn't put it on the slide. So why didn't I put a 1, 0 state on the slide? I'm sorry, 0, 1 state, 1, 0, 1, 0 state. That should be 1, 0. Yeah. Oh, why didn't I put the 1, 0 state on the slide? It's not reachable. So this is the full state diagram for these states. You can see there's no arrow going to 1, 0. Once you're in these states, you can never go to 1, 0. When you turn on the machine, it may start in 1, 0. But after that first cycle, it'll never be in 1, 0 again. So that's why I didn't bother to draw it here. I thought it would be more confusing to the thinking about what's going on. So let's take a look at the timing diagram. So here we have our new Moore design. We have the same issues. So here at s0, this rising clock edge, input is low. So s0 becomes 0 at this rising clock edge. But now, even though input goes high here, the output doesn't change. That just changes s1 plus. And s1 is ignoring that input right now. So that's a good thing. And s1 is ignoring that input right now. Until the rising clock edge, s1 does nothing with that input. This flip clock does nothing with that input. So when the clock edge comes, then output goes high. So you can see this is slightly delayed. So instead of seeing the output equal to 1 as soon as the input goes to 1, even though we know there's been a 0, 1, we delay that output until the next clock cycle. On the flip side, we then keep output high for an entire clock cycle. The output has no difference. The width of that output pulse does not depend on when the input arrives. It's always full clock cycle. So that's the nice timing aspect. So that gives us discrete time on our outputs. We've got a full clock cycle of 1. But it's a little bit delayed. So that's the price we're paying. So out is high for a full clock cycle. So to summarize, the more machines that we're using in class, the outputs depend only on the state, not on the inputs. The Mealy machine outputs also depend on inputs. In practice, everyone uses Mealy because you can get a smaller design, but you might have these thinner output pulses. To fix it, it's pretty easy. You just throw some more flip-flops down, and then you're done. Any questions on that? So we'll use the more machine throughout in the rest of our designs. So you can always assume that inputs will never directly affect your outputs. Outputs will only be a function of state. Before the output. Yeah, so you can certainly do it that way. You're not going to be able to make that output visible earlier in that kind of design. So you might be able to get away with fewer flip-flops if you rethink your entire design. I mean, not in this one, but in a more complicated design, you might be able to manage to use fewer. Whether that's a worthwhile exercise or not depends how much you need to think about your area. Anything else? All right, so what I want to do in the last 10 minutes or so is give you an outline for how you design a finite state machine. So we really kind of walked through this on Monday with our keyless entry system. But now I want to give you an overview of the process. This is mostly just to give you a way of thinking about what are the steps you need to do to design a finite state machine. Here's a structured methodology, six steps. So develop an abstract model. I'll go through each of these in more detail. So develop an abstract model. Specify your I-O behavior. Complete the specification. Remember that for a digital system, it has to be complete. A digital system just runs on bits. There's never blank bits or anything like that. So we need to make sure we think about what's going to happen when something is outside of the intended behavior. So we'll have to complete our spec. Choose the state representation. That's going to affect our logic. So we'll talk a little bit about how we think about doing that. Calculate logic expressions for next state logic and output logic. And then just implement with flip-flops and gates. So those are our six steps. All right, so the developing an abstract model, this is really just thinking, I want to build something. I know what I want to build in human language. But I have to turn that into a model. I have to have states in my model that can be eventually represented with bits. I need to know what desired behavior I want. So when I talked about the keyless entry, we talked about, well, my car's locked. I walk up to it. I push a button a couple of times. It unlocks a certain number of doors. Then when I leave, I want to push another button to lock it back up. Maybe I get a little scared sometimes, so I want an alarm to sound. So you think about the different things you want your finite state machine to be able to do. You think about the behavior, how you want the inputs to affect that internal state. And you just make some notes about that and list the states. So list the states of the system. Maybe write abstract next state tables to talk about how you move from one state to the next. But pretty abstract process at this point. The next step, then, is to start to formalize by thinking about I-O as bits. So what are the inputs? What are the outputs? Those need to be bits, and you need to think about what representations you're going to use for your finite state machine. Sometimes your finite state machine will be getting inputs from other systems, from other parts of your bigger design. Might also be controlling other parts of your design. So for example, when we talked about logic, combinational logic for an ice cream dispenser, we said, well, we have to produce two bits that control how much ice cream is going to come out. Now, actually, that would have been a timed process, so an FSM would be a little better for that purpose. What we did was just give two bits more or less constantly based on the button. But we have to use whatever spec is there. Usually, we're not in charge of all of the other parts of the system, so we have to agree, well, what bits will our finite state machine produce? What bits will it receive? So we have to interact with other systems for that purpose. Once we've done that, then we can go back and say, well, let's now think about all the corner cases. So we know what we wanted to do, but what about all the things that might happen? So go through and complete the spec. Think about, well, what are all the combinations of inputs, make design decisions. So in the keyless entry example, we said, well, we're going to prioritize the buttons. We could have also done what we did with the ice cream dispenser and say, well, now, only one button at a time. If you push more than one, we'll just ignore it. You can make any design decision, but we're going to prioritize the buttons. And you can make any design decisions you want, but you should make them. And try to complete the spec. Make sure you've handled all of the cases. Any implicit assumptions you made should be written down. We could leave some behavior at this point as don't care, but do that carefully. And then at the end, come back and check that it was, in fact, something that was acceptable. Once you've completed the spec, then it's time to pick a representation. So you can implement with flip-flops. They store bits. Later, maybe you can implement with registers or things like that. Actually, we'll do that next week or so. But for now, think of it as just flip-flops store the bits. There's some ways to choose. So sometimes the output patterns will be unique. In that case, well, the stored bits can also just be the output bits. And you don't need any output logic. You've just simplified half the problem. So that's one way to choose. You can map states to a hypercube such that your transitions are just along edges of the hypercube. That will tend to simplify your logic. But one of the best ways for bigger designs is just group your state into meaning for a human. What that does is it separates your bits into groups such that most of your logic will only depend on one of those groups. And so you can ignore the rest of the variables. So I'll show you several examples of this. But in fact, when you get to the design of the LC3 processor in the book, you'll see that a lot of the design of the LC3 processor was done with this in mind, using human meanings for the different parts of bits that flow into the finite state machine which controls the computer. So step five, this one's relatively easy. It's something you've been doing for several weeks now. So once you've completed your spec, you've got next state tables that tell you your next state in terms of your input and your current state. You've got outputs in terms of your current state. And all you need to do is build combinational logic. So if you have lots of variables, you might want to break up your truth table, use a mux, some of the tricks we've looked at. You can use components as well if you find it helpful. You can build it any way you want. All you need to do is build combinational logic to implement those equations or those sets of those tables, basically. State bits that have human meaning will also help here. Because again, if there's some bits that have, well, so let's think about some kind of ice cream dispenser. Bits that specify flavor don't have anything to do with how long we output the ice cream. We can have a counter that controls how long we output the ice cream. Separate bits that specify which flavor of ice cream. So now, when I decide whether I want to keep outputting ice cream, I don't need to know which flavor. I just need to know if the counter had to reach zero. Whereas when I want to know, well, which flavor should I dispense, I don't need to know how much more time. I just need to take those maybe two or three flavor bits, put them into a decoder, and then one of those lines will tell me, well, yeah, it was strawberry or mango or lychee or something. Each of the decoder lines would give me one output for a different flavor. All right, so the last step then is implementing with flip-flops and logic. So state bits are then going to be stored in flip-flops. And your logic is just built as combinational logic. There's nothing really special. It's just the same thing we've been doing. So do it the same way. This next state logic then feeds into the D inputs of the flip-flops, and the output bits are functions of the flip-flop state, the stored state. So let's go. We actually only got a couple of minutes. So maybe I'll save this one. This is the example. It's already posted. So if you want to read through it now for continuity, you can find it on the web. But I will go through it on Friday first thing, and then I'll stop one minute early. OK, thanks. Yeah. I don't know if it was easy to keep the loop running for a couple of minutes. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK.\"},\n",
       " {'ECE120-2016-08-24-LEC-02-slides.mp4': \" Cover for the day and kind of let it sit there before we start. So these are the things we'll cover today We're gonna finish up abstraction layers and digital systems Talk about representations and bits and maybe get through some of energy representation One thing I didn't mention last time But I wanted to make sure you understood just because I tend to talk a lot and talk quickly And I'll tell you stories things like that if it's important, I'll write it down Okay, so if I just tell you something or answer, I mean sometimes you might ask a good question in which case the answer is important But if it's something I'm planning to say and it's important, I'll write it down Okay, if I'm just telling you a story it won't appear and it's okay It's not going to be test material or anything like that It'll just be for your interest or to help you better absorb the material but important stuff will be written down either here in the notes One other thing I wanted to mention There's a rule that I wanted to explain why this rule is there. So tomorrow you have your discussion section I remember those will be working groups So you need to arrive on time because if you show up late then you kind of disrupt your group and delay the start And so people will be unhappy with you. So as a result, you lose a few points. Okay, so that's the rationale It's not my favorite rule either, but but please show up on time All right, so a couple of review slides We started talking on Monday about abstractions about abstraction layers Each one provides some functionality to layers above it and then is implemented on layers below it. And we looked at digital systems as Seven layers we didn't get through this whole diagram But we had gone through Problems and tasks and I pointed out that there was ambiguity, right? Probably no one in the room realized that when I say time flies like an arrow what I meant by that But now, you know, you might have thought it meant something else So there's ambiguity in human language So, how do we implement our problems and tasks in digital systems? Well, there each problem or task will map down to what we call an algorithm and for any problem or task There are many algorithms we can choose from Okay, what is an algorithm? It's a step-by-step process. Okay, so it's a step-by-step process that has three characteristics One is definiteness. So we got to get rid of the ambiguity when we talk about human tasks Like what the number what's the sum of numbers between one and three? There's ambiguity What do I mean by between? Do I mean integers real numbers? What am I what am I trying to ask you? With an algorithm all of those questions have to be answered. We have to be specific and definite in terms of what we mean We also have to have effective computability. Computers are not smart, right? They can only do very simple things add two numbers move move some value from here over to there And we need to express our algorithm in terms of very simple steps. So that's called effective computability And they also need finiteness. So how many of you how many of you know how to count? Good, you know, I've been I was teaching in vietnam a few weeks ago whenever i'd ask them a question like that No one would raise their hand. So i'm glad that all of you know that how many of you finished counting? Really? Okay, I need to I need some people are saying they finished counting. I always thought it was impossible But I guess maybe i'm just not smart enough. I don't know Yeah, so it needs to be finite right the task the algorithm needs to be finite needs to finish in a finite amount of time Maybe you mean you finished because it's you don't really need to do it, but you'll find later in our class. We're going to use counting So each of our algorithms, uh, we can implement on many different computer languages, right so some examples there are actually thousands to choose from so Thousands in the research literature thousands of prototypes Actually probably hundreds of commercially available languages that you could go write an algorithm in Some examples you may have heard of c c++ java python some you may have used javascript We're going to use c in this class in the second class 220 Why do we do that one is there's an easy mapping to low level so by the time you're done with this two sequence course When you write c statements, you'll understand exactly how those are turned into instructions when you're doing the math You write c statements. You'll understand exactly how those are turned into instructions, which is going to be the next layer down in the hierarchy The instructions are what the computer actually executes. Okay, what a computer actually executes so you'll understand that mapping to lower levels C is also a subset of some of these other languages So once you know c you can learn more about those languages, but you can already do everything with those languages Okay, it's just there there's extra syntax and things like java and c++ But the mappings are not as simple Yeah question So c and java They're fairly similar in terms of syntax in terms of what the code looks like Um, but java has java the way you write java Is more object oriented and so you build things around data structures and so The way you approach problems is slightly different and so that's why people like bjarne struestrup who invented c++ believe that that's Fundamentally, you should start with something like his language c++ because it's object oriented whereas c doesn't force you down that paradigm so I think by learning the basic syntax at the end of the day most c++ most java code will have will have to be written In small procedures and those you will know how to write after learning c So so I feel that this is the right way to do it, but not everyone in in the world agrees with me. Yeah I know that there's a assembly simulator You can run off your laptop Yeah, i'm wondering is there any physical chipset Like in class Okay, so the question is, um, is there an actual chip that implements lc3? Uh, so I I don't remember whether anyone actually ever did it in 385 There's no commercial lc3 lc3 is an educational architecture but um Some of our students have been so excited about having fun with lc3 that I think they may have done it in an fpga So and if not, you can do it. You can be the first so Yeah, okay. So Next level down we take our computer languages and those get mapped into computer instructions So there's a layer that we call the instruction set architecture which specifies what are the things that can be done by the computer? Okay, so that's the interface between software and hardware. The software has to be expressed in instructions We can have things like c things like java But at the end of the day, the only thing the computer knows how to do are instructions add two numbers Put the result somewhere put the sum somewhere for example, it would be a typical instruction examples here x86 Most of your laptops most of your desktops have probably have an x86 based processor in them Um arm most of your cell phones if you have a smartphone probably have an arm processor in them Power pc is another embedded processor. Your car may have a power pc in it for example Below that. Oh, and of course, uh computer languages can be implemented by many instructions at architectures We can map computer languages to many isas We can also map isas to many micro architectures So once you have the instructions you can build something to execute those instructions in many ways the way you build it is called the micro architecture, okay, so for example Uh the x86 there are i5 i7 From from intel optron and phenom from amd for arm. You've got cortex a15 cortex a9 Kinetis k so there's there's many different implementations. We call those the micro architecture Micro architecture So, what does our class cover we're going to build from the ground up through the isa level that's where our class will go We're also going to dally briefly, uh in week three at the c level doing a little bit of c introduction So we put that into this class Because our students in the predecessor classes had trouble picking up programming In the space of two-thirds of a semester now when we first taught this class Because there's there's going to be just a little bit on every homework to try to keep keep your Keep you absorbing the C syntax so that you can learn programming more slowly Some people might be tempted to say I'm not having fun with that part. Let me just ignore it That will be at your expense right the expense will not be a few points It means you will have to learn to program more quickly later So please do the little parts of the homework that are you know go into the lab and play around with C Write a couple lines of C that was deliberate so that you can absorb that more slowly and being kind of more level playing field With people in the room who have been programming for a while, okay? So we'll do that briefly in week three Future classes like CS 374 for the copies will teach you algorithms I think it's worthwhile for everyone to take that but as an EE you have to choose among many options For copy you're required to take 374 the algorithms class. So that's kind of where things fit in with this diagram now We've been working on trying to figure out how to get human tasks into digital systems more effectively for something somewhere between 50 and 200 years So in a few years, it's your turn. We be with that But before we start the next section I gotta say, you know, I'm disappointed with Illinois students because MIT students What was it? 1967 did I put it on there? I think it was 1967. They came up with this idea of the Big Screw Award Okay, so what where who gets the Big Screw Award? It's whomever screws over the students the best during one year, right? I'm a little disappointed So one student the one professor there actually taught the class in French in order to win the Big Screw Award But this is Illinois. So here people might actually speak French Not like MIT. No one there. So I don't want to waste my effort. So instead I'm gonna use this code Okay, anyone here know this code? Perfect All right, so the rest of my lectures will be in this code I Hope you're ready So what's a representation? Often we need to represent one kind of information with another inside a computer You'll see we don't have many ways to represent things, but we'll get to that in a few minutes But we need to represent one kind of information with another kind So maybe physical quantities patterns like the drawings I just showed you and so forth So English letters represented by by some drawing right or that's what you just saw Colors represented by variations in radio amplitude some people call that television The mapping from one form to another we call a representation I Think my day here is done. I'm gonna watch a video while you do that. Okay I'll give you a little hint You you Give up no, that's not give up bingo on word one Oh, I hear someone clapping good job. All right All right. So representation when I was a kid, we used to send secret notes in this code So I I'm a little surprised surely you had some code to use to keep the teachers from knowing what you were writing to your friends Right, you don't want to just pass it in normal writing because then they can read it you get in trouble All right, so we have a representation what makes it a useful representation Was it useful when I just showed you the code? I mean, it seems no one got it before I showed you the how I mapped letters into patterns, right? So For it to be useful, especially for computer computers are not smart for it to be useful We need to agree on this mapping the translation Before we try to use it, right? So our purpose here with representations particularly in this class is not obfuscation, right? So we're not trying to hide things what we're trying to do is communicate But we need to express the the form of information that we want to use into some other form in order to do that communication Okay, so we need to have this translation in advance and it needs to be well-defined So that's one property. So what about this one? Here's a here's a here's another representation. So I take the English letters and I represent them with digits Okay, so the letter P Think I have a laser on this not a very good one the letter P. I represent with the number five So what does one four three mean? Okay, so I heard bed let's see yeah, I got that one what else I Hear box Oh really LEDs up there. Oh, I should have picked that one. Darn it. Good call Why does it have to be some acronym you recognize couldn't be VIN? What's wrong with VIN? So computers are dumb. They can't guess. Okay, so it has to be well-defined unambiguous When we use representations with computers every given pattern whatever that pattern is can only represent one thing So over here on the left, you see I've got green represented by four blue represented by one. That's good on the right I've got a representation where green and blue are both represented by four. That's not so good in that case a computer Or digital system is not going to know when you put four Did you mean green or blue just like in the previous slide when we put one four three? Did we mean bed box LED VIN? What did we mean computers are not going to be able to just guess like we could Now some patterns may not represent anything we'll use this in the end of the semester But I just want to make sure you understand what the rules are for representations Okay, so for example here I have a representation where each of these five colors has its own digit But there are five other digits we could use if what we're using our digits to represent the colors and those those digits Just don't mean anything. That's okay. That's a valid representation So those are the two things we need with our representations we need them to be well-defined and unambiguous Inside digital systems inside computers computers are based on electrons The only thing we have to represent anything whether you want to represent ice cream flavors Or you want to represent makes and models of cars or student ID number, whatever. The only thing we have Electrons, that's it. So what can we ask about electrons? Well, we can say okay at this point here How many electrons are there? It's closely related to voltage I think I think people have probably in maybe high school physics seen seen voltage with electrons and things like that so We can look at a particular place and we can ask what's the voltage there? So we'll pick some some ground and that'll be zero volts by definition. We'll pick some higher voltage. We'll call it VDD and I'll push the wrong button. Sorry So at a physical location we can say what's the voltage and if the answer is well, it's close to VDD We'll call that a one and if the answer is well, it's close to ground zero volts. We'll call that a zero So that location thus gives us a binary digit. It's either a zero or one which we call a bit Bit, okay Now each bit is in some particular place So it's pretty easy pretty natural then to use what we do as humans with our with our number system to use positional value or place value So in in decimal we have the ones place. We have the tens place. We have the hundreds place Thousands place so forth and so on In binary, we've got the ones place the twos place fours place eights place sixteens place Powers of two those are powers of ten for decimal. These are powers of two So keep in mind as we go forward the only thing we have inside computers inside digital systems is bits, that's it There's nothing else we're using to represent information. So as humans we talk about abstractions. We talk about using Hexadecimal or something like base 16. That's not what's in the computer Only thing in the computer bits zeros and ones and no blanks. No Multiplication signs nothing else no colors All computer representations are based on bits Okay, so now some questions for you so if I have numbers in the range 0 to 31 integers I'll tell you that so otherwise you'll tell me infinite So if I have the numbers 0 through 31 whole numbers, how many bits do I need to represent one of those numbers? Five I'm hearing so why is that? So we have 30 32 different integers, right 0 through 31 is 32 different integers and Remember representation has to be unambiguous. So for each of those I need at least one bit pattern So that means I need 32 bit patterns If I have five bits that gives me two to the five different bit patterns It's 0 1 1 1 1 1 0 1 1 1 1 1 and so forth and so on right there 32 of them Those 32 I can uniquely assign to the 32 numbers and that would give me a representation And so I need five bits. What about the number 0 to 100? 7 right so again 101 different integers in this case 7 bits gives me 128 patterns 27 of those won't be used but that's okay It's okay to not use patterns. It's not okay to assign one pattern to two numbers. So I have to round up So seven bits for those good All right. So here's a trick question for you. See I'm nice to you. I tell you what I'm gonna ask you a trick question So two books here The collected works of E.E. Cummings my anachronistic dorm mate who you should read because he's a good poet and Our textbook Pat and Patel. Oh great books. You should read both of these How many bits do I need to tell you which of those books you should read tonight Good answer. Wow, you're good at these trick questions. I left my controller over there. I'm so excited All right. So yes, that's right one bit right two books one bit What matters is not what those things are what matters is how many things we want to represent in this case? There are two so we need one bit. That's it Okay So whenever you're thinking about how am I going to represent this set of things? All you need to do is count count how many there are that'll tell you how many bits you need so let's go through and do a few more examples, so Let's see number from 1100 whole number from sorry thousand to eleven hundred Seven right same as before it doesn't matter what the numbers are. There are hundred hundred and one of them. So seven bits good 199 flavors of ice cream. Sorry, I clicked ahead, but I think sounds like people are getting the answers, right? So What about the next one living person? Zero So what is it? Okay, I guess it depends how you interpret that I guess the way I thought of it is someone someone living means a person living on earth, right? I don't think there are too many. Well, there aren't people we know of off of earth So at least I don't know anyone off of earth. So how many people how many living people are there roughly? Seven billion right? So we got to round up a little bit. So seven eight billion people. So 33 bits 33 bits is just over eight billion Okay. What about the last answer if I don't tell you the number I just call it n Okay, I'm hearing good answers so log base 2 of n rounded up so the ceiling notation means the integer that's at least as big as what's inside Okay, so let's go on and talk about what we can use to represent integers So we've been thinking about different numbers we'll need but what if we want to make a representation how should we go about doing it? So we can represent anything with bits. So using zeros and ones we can represent anything integers real numbers human language characters I want to make sure before we go forward to emphasize and I think you'll get tired of hearing me do this by the end of the semester But computers do not understand the bits. Okay from a computer point of view. There are some zeros and ones So when there's some zeros and ones, what do they mean? Well, it depends how we interpret them as people. So you can tell the computer Interpret this as an unsigned number or as a signed integer or as a real number or as a color or an ice cream flavor But unless you do that or someone else another programmer or a hardware designer Someone does that and says these bits mean this kind of thing and build that into the system The computer will have no idea. So if you tell your computer Here's a representation from ice cream flavor to bits and then you tell the computer Please add mango to strawberry. It will simply add the bits and you'll get something strange So it'll it'll just do what you tell it. It's not smart So what number should we represent if we want to represent whole numbers greater than greater equal to zero What should we represent? About we can go around the room that I don't know 150 people some odd each one can pick our favorite number My favorite number is 42. You know why I hope Because I can ask you what is 6 times 7 And I can ask you what is 33 plus 5 I'm hearing some 42s, but I'm hearing some wrong answers So what you need to know is you can need to tell the professor what they want to hear which is 42 because 33 plus 5 in base 6 is 42 All right, so contiguous set of integers maybe instead of just picking our favorite numbers might be better. Maybe we should start with 0 So let's think about what are we trying to do with this stuff, right? Maybe we want our computer to do arithmetic. A lot of people use computers to do arithmetic So what does that mean? Let's say we just pick a range. Let's say okay I'm gonna represent the numbers 100 to 131 with 5 bits. Will someone pick a number from there? Shout it out. Okay, 42 is not in there. Good choice though. I like that. I like that 100 and 120. Okay, good choices. So if I add 100 and 120 we get 220 It's not there So if we add two numbers, it's never there. So maybe we should pick our numbers in such a way that at least sometimes when we add them or when we multiply them the result we get, product, sum, whatever, is also in the range so that we can represent it. Because if I add two numbers from here I can never represent the sum. If I multiply two numbers from this range, it can never represent the sum It's not so useful for arithmetic So maybe we'll pick a contiguous range including zero So at that point I want to say in general, you know, when we have human representations for the same thing Usually those are a pretty good starting point. So as humans when we want to write down a number Well, we use decimal but probably in high school you might have seen base 2, right? So there's base 2 from mathematics. We could use that as a starting point. Remember in base 2 We just write ones and zeros, right? So here are some examples 17 in base 2 is 1 0 0 0 1 42 in base 2 is 1 0 1 0 1 0 and 1,000 is those numbers there In human representations we use these subscripts to tell you which base we're in So when I said 33 plus 5, I really should have said 33 6 plus 5 6 equals 42 6 but here Here are three different numbers. Is this okay? Can we use this in a digital system? Why not? They don't have the same number of bits. So in particular we've got this blank space here, right? There's no blank bit. 0 or 1. That's it. There's no blank. You can't say well, you know This is a this is a small number. So I'll have some blanks. There's no such thing 0 or 1 So that's that's not such a tough problem, right? We'll put the leading zeros So we'll put leading zeros on our numbers That'll fix the number of bits to some n and we'll get this we'll get what's called the n bit unsigned representation So if I take my previous examples and I write them as 8 bit unsigned what I get is what you see here So if I take 17 then instead of just the 1 0 0 0 1 I get three leading zeros and I get 0 0 0 1 0 0 0 1 42 I just need two leading zeros How can I represent a thousand in 8 bit unsigned? I can't right? I needed more bits so I can't do it 8 bit unsigned does not represent 1,000 So then you can ask yourself, okay Well, if I have say 8 bit or 10 bit or whatever what values can I represent, right? So if I want to use this unsigned representation, what's the range of numbers that I can represent? The smallest number of course is going to be all zeros. So that'll be 0 and we kind of chose that already What about the biggest number? Yeah, so I'm hearing some 2 to the n minus 1s It helps me to remember that if I put 1 followed by n zeros Well, that's 2 to the n right by place value. And then if I subtract 1 from that that's n bits This is actually n plus 1 bits here 1 1 1 digit and then n 0 digits And so then I have n bits left all of them ones. That's the biggest value. So as people said 0 up to 2 to the n minus 1 so that's the range of an n bit unsigned representation This is one of the common representations in almost every computer you want. So this is a real computer representation So let's think about As humans sometimes we'll need to go back and forth from decimal into Into unsigned so just think for a minute about how we do that And I want to actually show you the tool if you want to if you want to practice So you can think of the you can calculate a decimal number from a bit pattern Using this idea of a polynomial. So your decimal number I'm sorry, your bit pattern will be some set of bits here. I've drawn six, right? So you can think of those as coefficients on a polynomial. Remember they have place value So the rightmost which I called a zero that has place value 1 a 1 has place value 2 A2 has place value 4 and these are powers of 2 so you can write it out this way You can write it out with the powers of 2 written out a 5 times 32 a 4 times 16 and so forth Or you can just remember they're the powers of 2 So that's how you can translate from bit pattern into decimal So let me go over here And remind you I thought I left my Google open, but I didn't Okay Remind you how to get to this page Sorry, I turned off my wi-fi that was foolish because I knew I wanted to do this All right, so we'll come back to that while it brings my wi-fi up Hopefully it won't Will not make me Log in Okay So what about going the other way? I'll show you the tool in a second. Sorry about that. I turned off my wi-fi not thinking um What about going the other way? So if I give you a a decimal number Um, can you tell me the bit pattern? So if I say hey, I want the 8-bit unsigned bit pattern for the number 193 That seem harder Than going the other way. I mean the other way you need to look at the powers of 2 add them up, right? All right. So it turns out it's actually not that hard. There's a pretty systematic way to do it. So remember that Every bit pattern represents a different number, right? So the the bits we use the a sub i as I called them. Those are unique right So if you write that down You say okay. Well, my my decimal value is equal to this polynomial All of those terms on the right side are even right because the powers of 2 All the way down to 2 to the 1 those are even numbers So if I multiply whatever the coefficient is times that those powers of 2 I get even numbers The only odd number is maybe this one Right if a 0 is 1 this one is odd. It's 1 So if d is odd Then a 0 is 1 If d is even Then a 0 is 0 Then a 0 is 0, right? So I can just look at d and say well, is it even or odd? And if it's if it's even again a 0 0 if it's odd a 0 is 1 so then I can subtract a 0 from both sides Divide it by 2 and use the same reasoning until we run out of digits Okay, so let's do that just for a quick example So if I start with 37 for example, that's odd, right? Okay, so a 0 is 1 Subtract out the 1 divide by 2 On this side subtract out the 1 you can see the a 0 has gone away divide by 2 What's left is this new polynomial and on the left side 18 You can see again. We have 2 to the 0 now attached to the a1 term So all I need to say is well, it's 18 even or odd It's even so a 1 Zero Do the same thing subtract 0 divide by 2 i'll get 9 Subtract the polynomial i'll get the the new polynomial now the 2 to the 0 terms on a2 So that's where I was 9 is odd so a2 is 1 I can roll forward on this Do all the math And if I put them back in order that's what I get right Of course depending on what size how many bits you want in your unsigned representation you may have to add some leading zeros, right? But your bits will come out from from low to high in this process Okay And you don't really need to write down the polynomial, right? That's just for uh, that's just for make sure you understand why it works So for example, if I ask you well, what about 137? How can I get the the unsigned pattern for 137? Well, that's odd, right? So gives me a 1 Subtract 1 divide by 2 I get 68 gives me a 0 it's even so subtract 0 divide by 2 34 Blah blah blah go on go on go on Okay It took me longer to write the slide than it so don't worry if the So now which direction should I read those? Well, remember we get the small bit first So I'm going to read from the bottom to the top, right? So those are my bits so if you want to know what's the unsigned bit pattern for 137 it's 1 0 0 0 1 0 0 1 So not as hard as one might have originally thought The systematic way to do it Let me see if my wi-fi came up because I do want to show you this tool So if you feel like you want to spend time, um Making sure you understood that then Ah, there we go. Okay. So remember Type my name into google that'll give you my home page And then go to the oh This one doesn't uh, shoot. There we go Go to the f16 link there for fall 16 and that will give you this page Now what I want to show you is down here We have these javascript exercises. So the first one is representations and logics So if you click on that you can do this on your mobile, too um You will have a little tool that will let you Do translations and will give you Check answers for you. So here for example, um, we have the number 70 and we're supposed to convert that to the unsigned representation on 8 bits You can see up there. You can go up to 16 bits if you'd like to um You know, you'll want to use maybe a piece of paper for that But uh, if you want different examples, you can click this new example. It'll give you as many examples as you'd like to play with So it'll just keep changing the number. So let's get a nice number So how about 113? That sounds good So then we can go over to uh go over to here So is that even or odd odd good, okay, and then I take 113 minus 1 divided by 2. What does that give me? 156. Okay, so that gives me a zero, right? Okay, and then 56 minus 0 divided by 2 28 And then 28 divided 28 minus 0 divided by 2 14 14 divided by 2 7 so that's a that's odd 7 minus 1 is 6 divided by 2 That's 3. That's odd Uh 3 minus 1 is 2 divided by 2 1 that's odd and then we get 0 so we're done. So it looks like 1110001 and then I'll have to put the leading zeros So, let's see. So go here I think that was it, right? Okay So let me make something wrong just so I can show you this. So if you push enter if you go push this Check answer button it will highlight the bits you got right and and put The bits you got wrong in this darker color to tell you you got that one wrong Okay, so it'll give you feedback instantly on your answer and then you can go and correct it And it will tell you they're all right. And if you push enter again, it'll give you a new problem Okay, so feel free to play with those tools There's actually quite a few choices in terms of different representations different exercises, but that will help you hopefully Make sure that you know how these things work so Let's move forward Okay So that's the unsigned representation so what about negative numbers? As humans we write minus sign, right? So if I want to say minus 24 I'll put a minus sign and I can do that in base 2 just as well as I can in base 10 So I can put a minus sign, but there's no minus in a bit zero or one You might think well That's okay. I can say, you know, there's actually implicitly if I write 24, there's implicitly a plus right? So how many choices of sign do I have? Two right I could have minus I could have plus I could use a bit for that, right? So we just say okay zero means plus one means minus i'll have a special sign bit That's called the n bit signed magnitude representation And that'll give me numbers from this blue part will give me remember 2 to the n minus 1 I'm, sorry. Yeah 2 to the n minus 1 minus 1 And then the sign will let me make that negative or positive So my whole range is from negative 2 to the n minus 1 up to 2 to the n minus 1 So that's sign magnitude That actually was used in some computers a long time ago like the ibm 754 Wait a minute if that's the range If that's the range And I calculate well, how many numbers are there? There's only 2 to the n minus 1 what happened to our other bit pattern? Yeah Um, so this is a bit pattern as opposed to the bit right so we got one leftover bit pattern somehow, yeah Ah positive and negative zero good answer. There are two bit patterns for zero. That's okay, right? Right. Remember we said it's okay. As long as every bit pattern means something unique It doesn't matter that you have multiple bit patterns for the same number again There were computers built using sign magnitude representation. They work just fine It does make the hardware a little more complicated which is why today none of the computers use sign magnitude in practice Okay, but people use this for a while because it's a natural human representation that you can easily turn into bits, right? Right So then that begs the question of well So, how do you know you make up a representation? Is it a good one or not? Right. Now this is a little unfair because some of these questions This question you can't really answer. So i'll give you the answers. Um In particular the second one, right? How do you how do you know? What's easy and fast hardware implementation when this class is supposed to teach you how to design hardware, right? So so that's not a fair question. So i'll just give you the answers this time One is efficiency. So unary right where we make these hash marks That's not efficient because if I want to represent the number a million I have to make a million hash marks Right, and you know if you go take log base two of a million You don't need a million bits to store a million, right? You need far fewer about 20 so So you don't want your representations to be inefficient You want them to store store numbers effectively and basically use all of the patterns or at least most of the patterns most of the bit patterns You do want them to be easy and fast implementation. So we'll come back to that later One thing that I think is fair is well What if I told you I can come up with a representation for signed numbers? Where I can use the same hardware as I do for the unsigned representation, right? So I get it for free Right clearly that's better than another representation where I don't get it for free where I have to have another piece of hardware to do addition say of of signed integers That would be separate from my uh from my unsigned integer adder So here's an unsigned adder. So imagine we've built something, right? It adds two bit patterns of an unsigned representation So if I feed in the number two zero one zero and I feed in the number three zero one one Then out comes one zero one how it works for now. It doesn't doesn't really matter. I build this thing And I ask well Can I actually use this same thing? To add sign to numbers if I pick the right representation the answer is yes Okay So how can we pick the right representation? So first let's think about addition, right what does it mean to do addition on unsigned bit patterns? Well, since we drew the unsigned representation from the base two Representation for humans and math we can use the same sort of arithmetic, right? So if I asked you okay write down some base two numbers and add them up You'd line them up just like you do in decimal and then you add them so you can start though with a single digit addition Right. So if I say okay, what's zero plus zero? Zero good zero plus one One good one plus zero One good one plus one Ten There there are ten kinds of people in the world those who understand binary those who don't Okay, that was a bad joke, but it's an ece joke you have to laugh all right um so Yeah, so this is the whole table, right? I mean you remember in elementary school you had to memorize that big 10 by 10 table It's a lot easier in binary, right? You don't have to memorize a big table. You just have to memorize four things and probably you can rederive them All right, so it's pretty small And then from there, well, you do need to know what's one plus one plus one We'll see why in a little while, right which is one one All right So here's what we do. We line up our numbers and we we just add them up column by column with carries So here's two numbers. The top one is uh 14 and the bottom one is four So we start on the right we say zero plus zero is Zero, you told me right one plus zero One plus one zero carry the one right so put the one on top one plus one plus zero Zero carry the one good and one plus zero plus zero One so we add those up. We get this number at the bottom that represents 18 and lo and behold we got the right answer So we're happy, right? Everyone happy Yeah Ah good point so We only got this answer because we chose our representation in a way that we can use this arithmetic process to get To to do arithmetic and that's absolutely right So because we decided to use the human representation to design our unsigned representation We're allowed to use the human arithmetic process To to add unsigned numbers. Okay, so we'll build hardware that simulates this human arithmetic And that will add unsigned numbers for us, but that's a good point If we had chosen some other representation, we would have to design a more complex piece of hardware likely good point All right now there's a problem though Even if we follow the human rules the unsigned representation we have to pick n bits, right? We have to say what n is It doesn't just grow So sometimes we'll add two numbers and we can't represent the sum So what is that condition? So I claim that that only happens when the most significant bits generate a carry So if a carry comes out of the left side of our addition Then we'll have an overflow and we can't represent the answer If a carry doesn't come out as it didn't in the previous example Then we get the right answer Then we represent our answer with the bits So let me show you an example So let's do this example So on top now we have 14 On the bottom we have 21 So if you remember 5 bit unsigned we can represent up to 31 You add those two numbers together it's bigger than 31 You should expect this not to work Because we're going to have to try to represent 35 So let's take a look So 0 plus 1 on the right is 1 1 plus 0 is 1 1 plus 1 is 1 1 plus 1 is 1 0 carry the 1 1 plus 1 plus 0 0 carry the 1 1 plus 0 plus 1 0 carry the 1 So we have no place to put that 1 So we have overflow Exactly We don't have any place to put that bit If we want to use 5 bits to represent our numbers We're out of luck We can't represent the sum So instead we get 3 So remember for your exams 14 plus 21 is 3 I don't think it will help you You should remember So the carry out tells us that we have an overflow What we added together we can't represent with those 5 bits With that 5 bit unsigned representation So we have a way to decide By looking at the carry out Is the answer right or is it wrong? So it turns out that unsigned arithmetic corresponds to Something we call modular arithmetic in math Or unsigned addition So it's related to the idea of remainders and division And it's defined mathematically as I've shown here So if I take 3 numbers A, B and M Integers A and B are said to be equal mod M If and only if A equals B plus some K Another integer Times the sum of the integers K, another integer Times M So we can also K can be negative or zero So two numbers are certainly equal If they are the same number But A and B will be It's a symmetric relationship Because the two K's would be negative of one another We can also write A equals B mod M That's how we say that this relationship holds So that's the definition of modulus It's like remainder So you can think of it as If they have the same remainder If A and B have the same remainder When you divide them by M Then they're equal mod M You can think of it that way I should have written that down, it's an easy way to remember it So Let's think about what we get When we add two unsigned bit patterns So if we add two unsigned bit patterns If there's no overflow Then this thing we get, we'll call it sum So if there's no overflow Then the sum is just equal to A plus B So without overflow, we get the right answer On the other hand If we get an overflow The problem is that there's that carry out That carry out, it should have gone In the 2 to the N place But we threw it away, so it went from 1 to 0 So if we take what we get The sum, and we subtract off What we should have gotten, A plus B We subtract off 2 to the N Then we get what we actually got For the sum, so if you think back to our example Was it 14 plus 21 Should get 35 Subtract off 2 to the N, 2 to the 5th Is 32, 35 Minus 32 is 3 And that's what we got So in both cases You'll notice that whether we Overflowed or not, the sum Is equal to A plus B mod 2 to the N In the upper case The multiplier is 0, they're actually equal And in the lower case, the modifier Is minus 1 Minus 1 times 2 to the N Added to B I'm sorry, added to A plus B Gives us the sum So they're equal So whatever we use to produce our answer Is going to give us the right answer Mod 2 to the N So we can use that idea To produce a signed representation A representation for signed integers So including negative numbers That uses modular arithmetic If we do that, we can use The same hardware to add Unsigned numbers and to add signed numbers That representation Is going to be called 2's complement So, whoops, wrong button Oh, really, did I finish it all? Okay, well let me open Another one then I didn't think I'd get this far I don't know if that's the right one Okay Push this one Okay Okay, so here's our strategy So we want to use Modular arithmetic to define a representation We're not going to be able to finish this one today But we'll think about it a little bit So we're going to use Modular arithmetic to define a representation For signed integers And by doing so We know that we'll be able to use The same piece of hardware to do addition On unsigned as well as signed integers The computer's not going to know which one It's just going to blindly put bits together And add them, but because the answer Will be correct, mod 2 to the n The answer will be correct regardless Of which way we interpret those bits So, what about the name later? So here's an illustration Of 3-bit unsigned So on the outside Are the decimal numbers And the inside are the bit patterns And I claim that adding a number Corresponds to going clockwise around the circle So for example, if I start with 4 And I want to add 3 Then 4 plus 3 is 7 And the answer Is always correct, mod 8 So if I say, well what's 6 plus 3? Well, 6, 7, 0, 1 So 6 plus 3 is 1 Which is equal to 9, mod 8 So it's always correct Mod 8 For 3-bit unsigned So that's one way to think about it Is the circle You can also realize That this is a quality mod 8 So, if I do addition I go clockwise, if I do subtraction I go counterclockwise And we can also I'm sorry, we can extend our numbers So what I've done is I've added labels Let me go through that again, sorry We can extend our numbers in a clockwise direction So in addition to 0 We can write 8, we can write 9, 10, 11 All of those groups Are equal mod 8 We can also go in the negative direction So by 7 We can write minus 1, by 6 we can write Minus 2, and so forth So we can add labels All of the groups, each group Is all numbers that are equal mod 8 Overflow happens because When we pick a representation We have to pick one of these labels for each bit pattern Remember, we can't have ambiguous Representation So any representation we define We can only pick one meaning So we have to pick one of these outside numbers For unsigned, we pick 0, 1, 2, 3 All the way up to 7 But we don't have to pick those We can pick any set we want And we'll get something that works mod 8 For addition and subtraction So what if we pick a different set of labels The arithmetic doesn't change Let's pick positive and negative And try some addition So here's a set of positive and negative numbers If I take minus 2 and I add 3 I get 1 So before when I picked 6 And I added 3, I got overflow But if instead I pick Negative 3 up through 3 Then I can add 3 to Negative 2 and get the right answer If I could pick differently That gives us 2's complement So if I choose my labels that way By picking An equal number of negative numbers Positive numbers And the 0 as the labels For my representation Then I get 2's complement Now again, because fundamentally The arithmetic we do on that circle Is correct mod 2 to the n Sorry, I'll stop in a second Because it's correct mod 2 to the n That means I can add numbers in 2's complement In unsigned and I'll get the correct answer Using the same piece of hardware So I'll stop there and we'll go over it again on Friday Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Now I have the highlighted you\"},\n",
       " {'ECE120-2016-09-02-LEC-06-slides.mp4': \" It'll go till the end of next week, because we have Monday off for Labor Day. So we'll start talking about the C programming language. I'll tell you why in a few slides. But I'll give you an introduction today, maybe start talking about expressions and operators. We might get through all of that, or we might not. If we don't, we'll pick it up on Wednesday. After that, we're going to start looking at C programs in class. So I have a bunch of those. I've already actually put them up on the links page for you. So let me just flip over there briefly for you so you can see it. So if you go down to the bottom, so this is the one linked off my home page. If you go down to the bottom, PowerPoint likes to take control of my laptop and forbid me from letting you see anything else. So these links way down at the bottom are links to programs. You can also get a handout, which I plan to give you copies next Wednesday once I think we're going to actually start doing them in class. So this is a PDF handout with all the codes printed out. So if you want to look at them, you can use that. If you want to compile them, you can use the links directly to the programs and download them and compile them wherever you'd like. They should be reasonably portable C code. So I meant to ask this question last time. So this will apply before we have another lecture because my office hours, remember, Tuesdays 1 to 3. So historically, I've held them in Zah's. Now that we have the new building, we could have them closer. So here are some photos that I got off the web. So this one by Bill Sanders is the Daily Byte. So that one I think maybe it's OK for me to use. There was one from Pinterest of Zah's. So this is the place I've been going for a long time. It's a cafe down on Wright Street just west. I'm sorry, it's on Green Street just west of Wright. This is the Caribou Coffee at 4th and Springfield. And I used to hold them there until ECE students said, why are you so far away? Why don't you go back to Zah's? Because it used to be near our department building. So I moved back to Zah's. And this is not the lab in the basement of DCL, but it looks a lot like it. It is one of our labs somewhere. So it's cold and lonely. And if you want, you can sentence me there. Somewhat seriously, your labs are due the next day. So if you want me to be in the lab, I can be. So let's just go through them. How many people would prefer Zah's? Oh, but now let me tell you something before you vote. So Zah's and Daily Byte, I never asked Caribou, but I think they'd be OK with it. Certainly these two, I've asked them. And you don't need to feel obliged to eat there, or drink there, or do anything. If you want something, great. But I asked Daily Byte the other day. And I've asked the owner of Zah's, who's told me in the past he doesn't care if people don't buy anything. So don't feel obliged to buy anything if you come. OK, so sorry, Zah's? OK, so maybe 10 to 12. How about Daily Byte? OK, it might be hard to find seating there, but it's looking like 20. OK, how about the basement? OK, it's looking smaller than Daily Byte. OK, and Caribou Coffee? OK, all right, that's the smallest. So I think we're going for Daily Byte. So we'll see how it goes, because quite honestly, I mean, any time you put any flat surface out there, there's an ECE student on it within a matter of seconds. So if we're too crowded, then I think we might have to not do it there. But we'll see how it goes. I will go there next week and try to keep them there. So I'll change it on the wiki. All right, so so far, you learned to represent information with bits. For the last couple of weeks, we've been talking about different ways to represent information, manipulate some of that information, arithmetic, things like that. Now our class as a whole is going to teach you how to design a computer. So we're going to teach you everything you need to know to build a computer, design a computer, a fairly simple one, but a computer. So computer instructions are pretty simple. So once we get there, you'll see computer instructions can do things like add two numbers together, copy some bits from one place on the chip to another. Not many programmers are writing those kind of instructions. So if you look at all the people writing programs, very few of them these days, according to my colleagues, still DSP people, but signal processing people, that is, are writing instructions. But for the most part, not very many people are writing instructions. Most people are writing high-level languages. So since about 1954, when scientists came up with this idea of a formula translator, people have been trying to bridge this semantic gap between human problems, like how to make a peanut butter sandwich, and instruction set architectures. So how do you get a computer to do something that you sort of think you know how to do as a human? And how do you make that an easy process? So as a result, there are now thousands of computer languages. And most of the programs in the world, of course, are written, most of the programs that run, most of the programs written. I think whatever metric you choose, most programs are written in these languages, meaning that the people writing the programs are not using instructions. They're writing in some higher-level language, like C, or like Java, or C++. So before we move on and start talking about how to go from bits and transistors up into gates, we're going to take a week and talk about the language C. So what's the point of that? Why go all the way up there and then come back down? So I mentioned at the start of class, in the predecessor classes, we found that a lot of the students, about 20%, it was going too fast. So students especially felt, and honestly, I measured it many times, and it wasn't quite true, but students really felt that they were at a big disadvantage if they hadn't programmed before. So it took them time to get used to programming, and people would feel like, well, this is not fair. I need to quit and start over because I don't like where I'm going with this grade in this class. And so we had about 20% of the people who would drop out of the class and take it again later. So that was not a very satisfying feeling. So we thought, well, let's switch the material around. So the class you're in now, we're doing mostly digital design, but we wanted to give people more time to absorb programming, more time to absorb just the mechanics of programming languages. So honestly, this part of the class, I think I did mention earlier, is not as integrated into the point system as maybe it should be. So you might notice, well, OK, we've got some stuff on the first midterm. After that, we'll have a homework problem a week using C. And you think, well, one part of one homework problem every week, homework's only worth 15%. You might feel like, I don't need to do that. I can safely skip that part. We discourage you from doing that, because the whole point was to help people that haven't programmed before just kind of absorb this idea slowly. So if you haven't programmed before, please make sure you do all of these, even though it might seem like work per point is not quite as much as it could be, because there's a lot of other material that is also important. So that's why it's in there. So what are we going to do? Start simple. So we'll have you making some small modifications to programs, and we will have you reading examples of programs so that you can see what programs look like, get a feeling for how they're written, before you go and write anything bigger, which you'll do in 220. We'll actually do some programming at the end of this class. So to be clear, in this coming week, today, and the next two lectures, we're not going to teach you how to program. So programming means taking some human task and expressing it in something like assembly code or computer language like C or something like that. And we're not teaching you that yet, later. So what are we teaching you? So right now, we're trying to teach you how to express certain types of tasks, usually things like mathematical formulas, some of the digital design ideas we'll talk about in the lecture, formally enough that you can get a computer to do them. So we won't show you how to teach a computer to make a peanut butter sandwich. I'm not sure they know how to do that yet. But we will teach you how to do things like print a truth table and some other concepts that will become more familiar in the next couple of months. So we'll also teach you how to read and interpret simple formal expressions of computation in C, so to look at simple programs and understand what they're doing, and also how to use a compiler. So we'll connect these skills to the material that we're learning. And also, we think that this will help you learn the skills, because you'll have to learn how to express them formally enough that a computer can do them, which is pretty formal, pretty rigid. Computers are not smart. And also, to just help you realize that computers can help you. So in most of your careers, you're going to be using computers on a daily basis. Most EE careers, as well as almost all computer engineering careers, you're going to be using computers on a daily basis. And you, as an Illinois graduate, will have the skill to get the computer to help you. So you'll know how to say, well, this thing I'm doing is really systematic. Let me get my computer to do it for me. That's what programming is, basically. All right, so computers don't know how to program. You'll start learning that skill in part four of the class. I did want to mention, by the way, in the old class, and ideally in 220, this compiler idea, the idea of translating something in a language like C into instructions is easy enough that, in fact, in our old class, 190, the students wrote most of a compiler as part of that class. Or they could. There was one machine problem one time where they ended up writing a compiler. They had also written an assembler that semester. So they could take a subset of C and go all the way to binary instructions and run those in the simulator for the LC3 processor. So it's easy enough that students could do it in one semester. So they're not very hard things. Of course, that's not to say they were outwriting, say, Visual Studio or something. It was a fairly simple form of a compiler. But we'd like you to learn that and be kind of that level in a year. But that's after 220. OK, so let's talk a little bit about C. So the C programming language was invented by Dennis Ritchie when he was at Bell Labs in 1972 to simplify the task of writing the Unix operating system. So how many of you use Unix? OK, so you know you use Unix. OK, so for those of you who didn't raise your hands, how many of you use Windows? Windows is based on Unix. How many of you use Mac OS? Mac OS is based on Unix. How many of you use, what's the other popular? How many of you have a phone with Android? Yeah, Unix. How about iOS? Unix. Linux? Unix. OK. If you don't have any of those five, maybe you don't use Unix. All of those are based on Unix originally. So they're all derivations of Unix. The original Windows was not, but as of Windows NT, everything after that is based on a variant of Unix originally. All right, so that's how important Unix is. But when he was writing this language, the whole idea was he wanted to write something that would allow him to take advantage of the hardware. So C is a fairly transparent mapping from the C language down to typical ISA. So easy enough, as I said, that 220 students, at least in the former class, could write a compiler for it. So the C compiler converts a C program into instructions. And this was around for 17 years before it was standardized. So there are lots of different variations. It became standard. As you'll see, there's still some machine-dependent parts of the C language. So we'll talk about those as we go through. OK, so here's the program. Let's take a look at a little program. So first thing I want you to notice, up here, we have a definition for a function main. The int means it returns an integer to its complement number. So when your program runs, what it does is it just executes this one little piece of code called main. Now, you can write other things. We're not going to tell you much more than main. All the programs here in 120, you'll just write main. So your program will execute main. And when it's done, it'll terminate by returning a number, an integer. So that's the first thing to notice. The next thing I want you to notice is you can break this main into two parts. The first part are called variable declarations. So when you want to use bits for something, you say, hey, I need to have a set of bits. And it's going to have this type integer. We'll go over this in more detail through the rest of the lecture. But it'll have a type. That's a two's complement number. And I want to name it answer. And I want to set it equal to 42. So you'll have some variable declarations. And then down here, you'll have a sequence of statements. So all the program does, when you start it, and you start it by typing a command like you did in the lab or if you're on a GUI like Windows or Mac OS, you double click something. That starts a program. If you're on Android or iOS, you click something. That starts a program. So whenever you start the program, it runs through main, executes statements in order. And then that's it. It's done. So pretty simple. If you've programmed before, maybe this is really dull. Sorry for that. But if not, maybe it's too fast. I don't know. All right. So what does the program do? Again, it executes these statements in order. So let's take a look at the two here. So the first one is going to send to the monitor this string. We'll talk about how it gets that string later. But it'll basically say the answer is 42, followed by an ASCII newline character such that later printing, if there were any, would occur on a newline. And then that's it. The second statement terminates the program. So there are two statements. You do them in order that they appear in the program. Bigger programs will have many statements. Again, just execute them one at a time until you get to the end. Good programs also have a lot of comments. Even though people try to make computer languages expressive and easy to read and understand, it's very easy to write programs that are not very easy to read and understand. So we strongly encourage you to put lots and lots of comments. So what's a comment in C? It starts with a slash followed by a star, an asterisk. And it ends with a star followed by a slash. Yeah, question? Yes. Yeah, so the question is, does %d stand for decimal? The answer is yes, d stands for decimal. There's also i for integer. I don't think I mentioned that in my slides. We will go through this in much more detail. And it's going to be probably a later lecture. But we will go through printf and scanf in a lot of detail. Good question. OK, any other questions? Yeah. Yeah. There is. And we're trying to minimize the amount of syntax we make you learn in 120. So there are single line comments. They're adopted from C++ and the current C standards. And they're slash slash. So we'll try not to give you those, because we don't want you to have to learn everything all at once. But I think it should be OK to use them. Although sometimes we're asking you to compile with older standards. So I'm not positive about that. I think it's OK, though. So if you know some of these things, it's OK. Sometimes we'll ask you to use a specific set of operators for certain programs, because we want you to learn how to use them. So hopefully it'll be clear in the assignment what you're allowed to do or not do. OK, so comments can span more than one line. So you can write as many lines of comments as you want with this style of comment. The other style that someone just asked about, what's your name? I should start learning more. Sasha. The style Sasha just asked about, if you do learn it, those are single line comments. They end at the end of the line. But the C comments I'm introducing here, these continue until the compiler sees a star followed by a slash. So you can put as many lines as you want. So so far, just looking at that little program, we looked at four different elements of C syntax. So we saw the main function, which is the function that executes when your program starts. We saw the variable declarations, which specify symbolic names and data types. We looked at statements, which tell the computer what to do. And then we looked at comments, which just help us, humans, understand the program. Let's go through those and think about some of the things that tend to confuse people. So first of all, I'm calling main a function, but that doesn't mean it's a function in the mathematical sense. So you learned about mathematical functions probably in junior high or high school. And they said, OK, well, at every point, the function will have one value. And that value, it doesn't change. If you evaluate the function at the same point twice, you get the same answer. That's not necessarily true for a C function. A C function is only a function in the syntactic sense of the C language. So it's a set of variable declarations and a sequence of statements ending in a return statement. Doesn't necessarily mean it's a math function. So for example, we can write a program that returns a random number between 0 and 255. So that program does not return a unique answer. And that program does not even return a reproducible answer. So if I run it twice, I get two different random numbers. So it's not a mathematical function. Both of those properties would be needed to make it a mathematical function. So when we say function, don't try to infer things from math, because these are not math functions. They're also not algorithms. So on the first day, I think we talked about algorithms. Algorithm cannot run forever. They have to be finite. A program can run forever. Very simple, very easy to make a program that just runs forever if it doesn't do anything. That would be a very simple program that's not an algorithm. OK, let's look at variable declarations in a little more detail. So a variable declaration lets you name sets of bits. So we've been talking about sets of bits. We've been using variable names as if they were algebraic variable names. They're going to be different in a programming language. So that's going to be one thing we talk about carefully in a minute. This declaration from the sample program I showed you, int answer equals 42, says, OK, I want the compiler to make space on the chip in memory for a 32-bit 2's complement number. The shorthand for that in C is int. And I want to initialize the bits of those 32 bits to the bit pattern for 42 using 32-bit 2's complement as the data type. And I want to make use of those bits any time one of my statements in my program uses the symbolic name answer. So any time I use the name answer, I want the computer to go get those bits and use them for that number, whatever I've stored. Yeah, Eric. How do you know that it's going to be a 32-bit? So the question is, how do I know it's 32 bits? The answer is that I don't, given that it's a C variable. But the lab machines are, I'll come back to this. I actually have a slide on it. The lab machines int is 32 bits. Some older machines, it might be 16 bits. So unfortunately, C types do depend, as we'll talk about later. Yeah, William. I have a follow-up on that question. Do we assume that in our architecture, it's always been? So the question is, should you make assumptions? In this class, it's probably not going to hurt you if you're making assumptions. There might be cases where you need to know occasionally. But generally, as I'll show you in a later slide, I would recommend that you be specific in your code. Yeah. So variables in C are not algebra variables. So if I tell you in algebra, well, A equals 42, then you would say, well, OK, A is 42. Five minutes from now, A will still be 42. As long as we talk about the same problem, A is 42. A doesn't suddenly become 25. That's not true in C. Every statement in C can change the value of really any number of variables. So your variables just represent sets of bits. Those bits can be changed by the statements. So you should not think of them as something that, like a variable in algebra, continues to hold its value forever. Yeah. Can you declare constant? Can you declare constant variables? Yes, you can. And in that case, if you declare it constant, the compiler will try to keep you from changing the values. Now, in C, the C language allows the programmer to do pretty much whatever they want. So even if it's constant, sometimes the programmer can change it. Obviously, the programmer should not change it. So you can declare constants. And there are other things you can do to try to have something that people can know is not changeable. So yes, you can do that. But in general, most of your variables will not be constants. There are also, just on that topic, there are high-level languages that use what are called immutable types. And in that case, your variables don't change value. They're assigned once, and then they hold their value. The cost of using those languages performance-wise is often a factor of 1,000 to 10,000 times in speed. So if you can afford it, if your program doesn't need to do much, big deal, right? Go use one of those. Maybe it's easier to understand. If you need that 1,000-fold performance, then you need to use something that's closer to the hardware. OK, so variables in C are sets of bits. So they're not algebraic variables. I think that's a source of confusion for people when they first learn how to program, a potential source of confusion. So your bits are always going to be 0s and 1s. But you can't necessarily make other assumptions about them unless you look at the code. So by looking at the code, it might be true that, for example, something is constant. If you look back at the little example program, the variable answer is always 42. None of the statements change answer. So it is, in fact, constant. But you can't make that assumption without looking at what the code does. OK, now the other thing about variables in C, in addition to just being a set of bits, is you tell the compiler what is the data type. So C requires that you say a specific data type for each variable. Not all programming languages require that. But C does. So you need to specify a data type. And then the compiler will use that data type to interpret the statements that use that variable. So for example, if you say that you want to add answer plus some other thing, maybe you want to take two times answer. So you say answer plus answer. What instructions should the compiler generate? Well, it depends on the data type of answer. If answer were unsigned, then it would generate instructions to do an unsigned add. If it were a 2s complement, it would generate instructions to do a 2s complement addition. If it's floating point, it will generate instructions to do floating point addition. How does the compiler know what to do? It looks at the data type that you've assigned by writing the variable declaration with the type int. So given the int, it will choose 2s complement. Now, there are a few data types that are always available in C. They're part of the C language. So they correspond to the representations that we've been talking about for the last couple of weeks. So you've got unsigned representations. You've got 2s complement representations. And you've got IEEE floating point representations. So the same ones you just learned, those are available to you in actually most high level languages, but certainly in C. There are also 8-bit primitive data types that can be used to store ASCII characters. Technically, they're also 2s complement, but you can store ASCII characters in them. Now, here's the question that Eric and Raoul were asking earlier. So unfortunately, C was designed to be fast. And so C is still the case in C that if you use the primitive data types, those are tuned to your system. And so the number of bits in an int depends on your system. The number of bits in a long int depends on your system. So when you write those types, you want to be a little careful about what you assume. You probably should assume the smallest one so that if overflow is going to happen on a different system, you handle it properly. But for example, a long int could be 32-bit 2s complement, or it could be 64. And which one you get depends on what compiler you use, what system you're running on. So to be specific, there's a more modern little library where you use int32, int64, underscore t. The t stands for type. So if you look in the notes, there's a more complete list. But the ones that we'll use in class for our example codes are a small subset. So I just wanted to show you those and tell you what they mean on the lab machines. So we have character, which holds an ASCII character, or it's interpreted also as an 8-bit 2s complement number. We call it character. Write it char. There's int, which on the lab machines are 32-bit 2s complement numbers. I won't use long int. I think on the lab machines, those are 64-bit. But on other machines, they'd be 32 also. There's float, which is the IEEE 754 single precision format that you learned in class. And then there's also double, which is the double precision format, which is 64-bits, which I think I saw the other day as 11-bit of mantissa and 53-bit. I'm sorry, 11-bit of exponent and 53-bit mantissa. But you don't need to know that. It's just a bigger representation, so you have more significant figures of accuracy. Yeah? Is there anything that they've done? There is. And you know what? In fact, I don't think I use it in the examples in the slide, but we do use it in some of the assignments. Basically, if you put the word unsigned in front of character or integer, you will get unsigned instead of 2s complement. Yeah, and that is in the notes. So take a look at the notes, and it'll show you a much more complete set of types, including these types down here, int32, int64, uint for unsigned. Yeah, good question. Anything else? No? Share pointers. Yeah, we will not require pointers in 120. You'll learn those in 220. Yeah, so sorry. Let's skip that for now. Yeah. OK, so the answer is yes. So each variable also has a name, which we call an identifier. So what is an identifier? So it's a set of letters and numbers. You can actually use underscore 2, but I didn't put it in the slide. It starts with a letter, so you can't start with a number. Any length. Some compilers may limit you, so don't make it 100 characters or something like that, but it's supposed to be any length. Use words. You can have any length, and so don't put one-lettered variable names if you can avoid it, because then people will not know what you mean. If you can describe what you want in the variable name, then whenever people use it, they know what it's supposed to represent. Variables are case sensitive, so all four of these could be different variables. You could have four different variables named in this way, and the C compiler would not complain. But your professors may be upset. So please don't do that. It'll make your colleagues looking at your code crazy, too. You can do that because the difference between a couple other systems that are going. Yeah, so the compiler can tell the difference because the ASCII characters are different, and the rule in C is that they are case sensitive identifiers. So that means if there's any difference in case, those are separate identifiers. Yes? What are those now? That's an interesting question. You mean as opposed to Unicode? I am not sure what the latest C standard says. I'll try to look that up. That's a good question. Certainly for many years, they were only ASCII, but if you want to write international identifiers, I'm not sure if you're allowed to. I'm not sure. Another question? Only by name. So you can't use reserved keywords. So you can't name a variable int. I think if that's true. There's certain contextual identifiers that can help. But for the most part, you shouldn't name variables keywords. But other than that, variables are identified just by the symbolic name you choose for them. Yeah? Will? You have to start a variable name. Yeah, I think I said that. Start with a letter. Oh. Yeah, sorry. OK. So what do these look like? So let's put these together. Variable declaration is a data type. So when I put these brackets, you would replace that thing with an instance of a particular data type, and you wouldn't write the brackets. So you could put int or char or float or double. Then you put your identifier. Then you can assign an initial value to the variable by saying equals some value. So for example, here are a few examples down here. I can have an integer and choose complement. That'll have data type int, and I'll assign the value 42, for example. I can have an unsigned integer. So this kind of answers your question, even though I guess I didn't put that in my list. But an unsigned integer, so this up here is a two's complement representation. This one down here is an unsigned representation. Here I've assigned the value of 100 to that. I can have a floating point number, name it IEEE 754, so the underscore is in there is cool, and assign it the value of Avogadro's number, because I can do that with a float. Yeah. AUDIENCE MEMBER 2 If you have the unsigned, like, for one data type? Yes, so together, these two on the lab machines would be a 32-bit unsigned. Yeah, good question. Yeah. AUDIENCE MEMBER 2 What's the lower case? Does this need to be capital? I think it can also be lower case, yeah. Don't need to be capital. Yeah. Special characters. You mean the underscore? No, you can use underscore. That's the only one, yeah. Except maybe the new standards might allow Unicode, in which case I'll look it up. We'll find out. Yeah. Good question. Yeah. Yes. AUDIENCE MEMBER 3 No. Not that you can use that space. You cannot use space in identifiers. No. Yeah, you certainly cannot use space. Anything else? Yeah, other than letters, numbers, and underscores, at least the older standards will not allow anything. Yeah. No, not in C. Yeah, there are a lot of programming languages where dollar sign means evaluate or variable, and so evaluate variable. But C, no, you can't use it as part of an identifier. Yeah. AUDIENCE MEMBER 4 How about in a number? Unfortunately, no. So even if you want to type in billions or something, usually when we type such numbers, it would be either a real number in scientific notation, or it would be something that maybe we could put in hex. It's kind of rare that you would type or something with a lot of zeros. I haven't seen too many numbers like 3,879,000,000 where putting commas would be nice, but it's not allowed. Yeah, so the question is, can you add different types together? The answer is yes, but that's a little bit beyond the scope of what I want to talk about in the lectures. There's a starred section in the notes that talks about that. So take a look at that, and if you have more questions about it, come talk to me in office hours. It's a good question, but we're trying to contain the things everyone has to think about here. So the initialization is actually optional. So the following is acceptable, just data type identifier, for example, int i. So if I write that code, what's an i? i is a set of bits. What's there? It's just bits, right? Good. I'll ask you lots of questions where the answer is bits. They may be zero bits, but don't count on it. And unfortunately, if you just write a little program and you look at those bits, often they will be zero bits. But again, don't count on it. It's because of the way the operating systems work. Yeah? Will a compiler complain if you do? Sometimes. So the question is, will a compiler complain if you declare something without initializing it to a specific bit pattern and then try to make use of that unknown bit pattern? And unfortunately, the answer is sometimes. So maybe even most of the time, but not always. So if the compiler can figure it out and you tell the compiler, as you always should, that if the compiler thinks there's anything wrong it should tell you, then it will tell you. But there are some corner cases where compilers won't figure it out. And the default with a lot of compilers is that they don't warn you about everything anyway. So as a programmer, you should just always turn on all warnings. And hopefully, the compiler will help you whenever it can. All right, so statements tell the computer what to do. So in C, a statement specifies a complete operation. So it tells the computer to do something. And the function main, again, is a sequence of statements. So we have a bunch of different metaphors for executing, running, starting the program. So I might use those words interchangeably. When that happens, your computer executes the statements in main in the order that they appear. So that's the intro. Any more questions before we start talking? AUDIENCE 1 One on the bit still looking. Allocate. Well, I guess knowledge bits is regularly in, but. Nope. No pointers. Yeah. AUDIENCE 2 Can you put more than one variable in a single line? Yeah, so there is a way to do it. And I deliberately didn't show you because I want you to put a comment on every variable. So the question is, can you declare more than one variable in a single line? And you might see it. So you can. You separate them with commas. The other reason I don't tell you is because in C, when you learn new types like pointers, the declaration is a little bit strange. And so until you get used to it, it's kind of error prone. Whereas if you declare only one variable per line, you kind of make it easier to understand. So I'm trying to encourage you not to do that. But you can do that, and it'll be fine. Yes. AUDIENCE 3 Does it? It doesn't give you some one? Yeah, so the question is, does the compiler read languages line by line? To some extent, yes. I mean, there has to be a way to get through the program. But C does not have the constraints of some other programming languages where, for example, a function. We're not going to talk about functions. But there are languages where you can't make use of things that weren't above that thing you're trying to use in the file. That's not true in C. Variable declarations still do have to be above. But I would like to have you put all of those at the top of your blocks of code, even though now modern standards allow you to intersperse them. Anything else before we go on? Yeah. AUDIENCE 4 How would null be represented by bits? That's kind of beyond, did I say null? Null is a pointer value. It's all zeros. It's the all zero bits. And there's a reason for that, historically. But it's beyond the scope of the class. So ask me after class. I'll tell you. Yeah. AUDIENCE 5 Is it a semicolon? Yeah, we'll look at statements in more detail later. But essentially, after every statement, every simple statement, you would put a semicolon. So a simple statement is a type of statement. AUDIENCE 5 Is it a null? Oh, absolutely. If you leave out semicolons, the compiler will complain. Yeah. It's not optional. The compiler will not let you compile your code. Or worse, it will let you compile your code. And it'll have a completely different meaning. So you want to be careful. All right, so let's talk now, before we get into statements again and look through those in more detail, I want to spend some time talking about another syntax concept in C, which is the expression. So an expression is a calculation consisting of variables and operators. So let me give you some examples. Let's say A plus 42. A is a variable. 42 is a number. I add them together. That's an expression. I can say A divided by B. I can say deposits minus withdrawals. So all of these are fine, good expressions. The C language has a lot of operators. So we're going to focus on four types, four types of operators that you need to learn for 120. And then there's another type called logical operators that we'll introduce. But you're not required to learn them. We're not going to introduce the subtleties of logical operators. We'll leave those for 220. So we're going to look at arithmetic operators, bitwise Boolean operators, like we talked about when we introduced Boolean expressions, relational and comparison operators, and then the assignment operator. The first arithmetic, we've got addition, which is a plus, subtraction minus. Multiplication is an asterisk. So you need to use an asterisk for multiplication. Divide is a slash. Modulus, which only works for integers, is a percent sign. There are lots of other functions in the C library. So lots of other mathematical functions, sine, cosine, et cetera, square root. Those we're going to leave for 220. So you shouldn't have to use those here. If we have one occasionally, we will tell you how to use it, and what it is, and what it means, and things like that. But for the most part, you won't need to use any of those. So let's take a look at this. So let's say I declare two variables, a and b, both ints. And I set a to 120. And I set b to 42. Now, when I say evaluates to, the C compiler is going to write a set of instructions that takes the variables a and b and adds them together. So evaluates to means, well, what's the answer, what's the value of this expression after it's been computed? So what's a plus b? Yeah, 162. Good. a minus b? 78. Good. a times b? A big number. Very good. a mod b? 36. Good. I think that's right. So we've got a mod b. So there's two b's make 84. And I've got 36 left, right? OK. What about a divided by b? Oh, I'm hearing lots of twos. OK. So a lot of people have played with this stuff before. Why two? Why not 2.36 over 42 is 7 something, right? Yeah, it's an int, right? So it's going to return us an int. So some of the pitfalls of division, actually, let me start at the bottom. Dividing by an int, dividing one int by another returns an integer. So if you take 120 divided by 42, you get 2. If you take 100 divided by 8, you get some integer. It's going to be either 12 or 13. You multiply 12 or 13 by 8, you don't get 100. So when you do integer arithmetic, don't expect basic mathematical equivalences like this to work, because this one is going to give you 12 or 13. It's going to round. If you divide by 0, your program will crash. If you do an integer divide by 0, your program will crash. If you do that with floating point, you'll get an infinity. Yeah? Yeah. AUDIENCE MEMBER 2 I guess by adding a long before. By adding a what before? By adding a long, and then it's like. A long? Adding a long to the long before, it's going to get. So can you change the type? And yes, so there are type conversions. And again, that's in the starred part of the note. So take a look at that if you want to know how to do it. But we won't do it in this class. So you don't need to understand it yet. For 220, you'll need to understand it. The other thing is there are no checks for overflow in C. So if you tell the C compiler, hey, I want to set my unsigned int to 0 minus 1, it will do that for you. It's a very big number. 0 minus 1 unsigned will overflow. So you'll get for 32 bits, 4 billion whatever minus 1. 2 to the 32 minus 1. And if you did a long unsigned long int, you'd get a 2 to the 64 minus 1. Unfortunately, C behavior with arithmetic also sometimes depends on the processor. So in particular, the rounding direction for integers depends on the processor. Whatever the processor says, most modern processors round towards 0. So it's not really as bad as it sounds, because you'll be hard pressed to find a processor that doesn't round towards 0 these days. So what does round towards 0 mean? If you take 11, divide it by 3, you should get, what, 3 and 2 thirds? Instead, you get 3. So it goes downwards towards 0. If you take negative 11 and divide it by 3, you should get negative 3 and 2 thirds. It doesn't go downwards. It goes towards 0, so negative 3. So it's not rounding off. And in both of those cases, if you round it off, you would get 4 and negative 4. Round towards the closest integer. Yeah? AUDIENCE 2. Is it a finite number? Yes. AUDIENCE 2. Is it a floating point number? So floating point will produce a floating point number. And so there is rounding, because it's a finite mantissa. And so sometimes, actually in your homework, you'll need to think about that. But you will need to round. IEEE floating point has four rounding modes, down, up, towards 0, and what is the last one? Oh, round to nearest. So those are the four modes. So the default mode is round to nearest. But you can change the mode. No, it will not. It will return a floating point number that's the most accurate representation it can, modular rounding, at the 2 to the minus 23rd level for the exponent. Yeah? AUDIENCE 3. What is the percent sign? The percent sign is modulus. So it's similar to remainder, but not quite the same. I mean, when you learned remainder, it was probably elementary school. And so you probably didn't. I think we teach it in the US, at least, before you learn negative numbers. And so no one talked about, well, what is remainder when you work with negative numbers in division? But modulus is defined. But it's not quite defined the way it is mathematically. So this is not mathematical modulus. So it's defined in this way in C. So it's defined such that this expression is equal to A. So in particular, if, for example, you said, well, what's negative 11 mod 3? Then negative 11 divided by 3 gives you minus 3. Multiply that by 3, you get minus 9. So to get negative 11 back, the mod has to be minus 2. So this expression defines modulus in C. So in practice, what this means is don't use negative modulus. You'll have plenty of codes where, for building things like cyclic buffers, you want to use modulus. But if you ever need to go in the negative direction, then you want to add e plus 1 if your number is negative. Because this negative modulus will screw your code up. But this is how it's defined. So if you want to work with the definition, that's the definition. And again, it's machine dependent, right? Because the divide part depends on the machine, depends on the processor. So that's another aspect of modulus is it's not even well-defined in the language. So that was it for arithmetic, those five operators. I don't know if we'll finish these, but let me introduce the bitwise operators. So we have six of them. And four of them you know, or at least you know the Boolean operators. So AND, OR, NOT, and XOR. And then we have left shift and right shift. So in some languages, some of you may know languages where the caret sign means exponentiation, not in C. It means bitwise XOR. So if you write it, the compiler will not complain. It will also not exponentiate. It will do a bitwise XOR. So they treat numbers as bits. So here I've defined a couple of hex values. You'll notice that in C, when we write hex numbers, we put a 0 in front of the X. So this is hex notation for a 32-bit value. These are the two 32-bit values. Otherwise, they're the same numbers. So if I take A bitwise ANDed with B, then what should that give me? OK. This is why I said hex is maybe not as easy with bitwise. So you have to translate in your head to bits. Let me just tell you. So the 7 is 0111. The 2 is 0010. So if you AND those together, you just get the 2 back. So you get the 2. And then the 8 is 1000. And the A is 1010. So you just get the 8 back with bitwise AND. And you can maybe write these out in bits. It'll be a little easier. If you OR them together, you get this pattern. The hex will be much easier to calculate. So usually, if we are doing bitwise operators, it's because we care about bits. And so thinking of it in hexes is maybe the natural thing. If you get this one, maybe we can figure out easily. So not A bitwise. Well, remember, how do we negate in 2's complement? Not A plus 1, right? So if I just take not A, it should be negative A minus 1, right? So negative 121. Notice that the bit pattern, it is a bitwise NOT on all of the bits. So all the high bits became 1s, which in hex are Fs. And then if I XOR them together, I get 52. So let me stop there. And then on Wednesday, we will cover shifts. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\"},\n",
       " {'ECE120-2016-09-16-LEC-11-slides-varodayan.mp4': \" I'm covering for Professor Lumetta today. I don't know where he is, but I think he's not in the country. So some of you may know me. I teach the 1 PM lecture of this class. So you might have seen me in office hours. You might know me as an academic advisor as well. So anyway, I'll try to do my best to cover what he wanted me to cover. And so these are the topics for today. So as I understand it, you did a little bit on KMAPs last time. But we'll do a few more examples and then move to the connection between the SOPs and POS to two-level logic. We'll do a kind of digression on optimization of different circuits and what that actually means. And I don't know how far we'll get into this stuff. But before we begin, let me see. I'm a little bit disoriented with these slides. Let's see. Before we begin or after we begin? OK, yes. Reminders about the exam next week. So the exam's 7 to 8.30 PM, unless you're taking the conflict. Unless you're taking the conflict, the specific time and the location of your exam have been uploaded into Compass. I believe it's where you check your grades. You'll be able to check the location and time of your exam. We'll be doing a review in class. Professor Lumetta will be back here on Monday doing a review in this class for the exam. Each of the instructors will do a review. But this weekend, on Saturday, 2 to 4 PM, there is an Eta Kappa Nu review, which is done by students as a service to other students. As such, we in the class do not endorse it, because it's whatever they decide to present. And if they are wrong, it's on them. But on Sunday, our undergraduate assistants in this class, hired by us, will also be doing a review session 2 to 4 PM, again, in this building. So all the details about that are posted on the course web page under exams. And actually, Professor Lumetta did want me to point this page out to you again. So all the details for the review sessions, the exam time itself, the contents of the exam, and practice problems, as well as links to old exams, some of which have solutions. OK. There's also the page above it, exams. So he told me that someone asked the question, what can you bring into the exam? Is that right? So it's all specified on this page. But in particular, it's a closed book exam. No calculators or other electronic devices. What you can bring is one letter-sized sheet of paper with handwritten notes on both sides. And so there are a number of things that you might want to jot down on those two sides that you can bring to the exam. Yes, Rahul. Has there been a requirement for the writing? Well, you can not bring a piece of paper as well. And you will not be forced to have a piece of paper. So yes. OK. Any other questions, though, about the logistics of the exam? Yes. No calculators? Yeah, no calculators on this test. So for the homework, there were definitely some questions that required a calculator. You can expect that similar questions on the exam will be set up so that you don't need to raise 2 to the 10th power is fine. 2 to the 16th power or something like that. Yes. The exam will be printed with one-sided. So we encourage you to use the back sides of exams. And as general advice, if you have scratch work, you can note it down in the sections where it is so that the grader can find it. Otherwise, it's lost and we cannot grade it. There should be enough space on that to do your work. All right, yes. The ASCII table will be provided to you if necessary. So you don't need to. That's one thing you don't need to put on your age sheet. That would be a waste of space and a waste of time to handwrite it. Thank you for asking that. Yes. How many questions? Can I answer that question? OK, I can ask that question. There are six problems on the test. And you have 1 and 1 half hours. Maybe the last question. Yes. How about the hexadecimal values? Hexadecimal values are pretty easy to remember. But that's certainly a good thing to put on your age sheet, because it's also something easy to get wrong. All right, very last question. OK, so back on that ASCII table, how many questions? I think we gave both, both characters. And the ASCII table includes both characters and hexadecimal. Yeah, yeah, it does. You will be given a table that you can use in the way that a question would want you to use it. So that sort of thing is pointless to memorize and also pointless to write down on an age sheet. We'll provide it to you. OK, so good, good. I hope that clarifies what you need to prepare for the exam. OK, so back to slides. Let's see what's up next. OK, so you did cover KMAPs. At least, you had an introduction to KMAPs. And the goal of a KMAP, a KMAP is just a tool. KanoMap is just a tool to basically minimize Boolean functions. A Boolean function is just another way of expressing a logic circuit made of AND, OR, and NOT gates. And so the way this tool works is that given a KMAP, you're trying to look at the ones in the grid and group them together in a minimal number of loops. And each loop should be as big as it possibly can so that you cover all ones. And the result will be an optimal sum of products expression according to, in some sense, the area that such a circuit would occupy. So let's do a few examples. That's what Professor Lumetta wanted me to do. He actually pointed me towards his tool. But the tool is good because it generates random examples. But I also don't like making mistakes. So I've prepared examples that I know exactly how to do ahead of time so that I won't be caught by surprise. And these are actually the examples that I present in my section. So I just pulled up an example here. So let me just make sure. And I guess I'm going to have you propose how to do this. Not Rahul, because he was at my lecture. And he saw this exact example. Just to make sure that you are where I think you are. So here is a four variable function. And this is the K-map for it. So I hope you understand that a K-map is no different from a truth table. A four variable truth table has 16 rows. And those rows are represented as 16 cells here. So remember, I'm trying to cover all the ones using loops of allowable size, loops that have dimension of powers of two. I cover all the ones with as large loops as possible, using as few loops as possible. So what's a loop I could draw? Could someone describe that? Yes. AUDIENCE 1 Right. These middle two columns. So that is an allowable loop, because it's 4 by 2. So that 4 by 2 dimension means that it can be represented by a product term, a product of literals term. And so any loop that covers ones is called an implicant. And this one is a prime implicant, because it doesn't get any bigger than this. If you make it any bigger, you start to include zeros. So for example, this little guy here, these two together, that's also an implicant. But it's not a prime implicant, because it can grow to this big one. It can be totally covered by the bigger one. So is there another implicant that I should identify here, right up here in front? AUDIENCE 2 That top left corner you have there. ARIJIT SINGH Right. The two ones in the top left corner. All right. So that's definitely an implicant, because it covers one. But is it a prime implicant? No, this one can grow. You can grow it to the square, which is an allowable size. So you can grow it to the square. Can we grow the square any bigger? So it's not right to grow the square to a 2 by 3 rectangle. That's not an allowable size. Yes, question? Right, OK. So this is great. So these are my notes. So this is new stuff for you guys. I mean, you probably saw this in a different form with hypercubes and stuff. But basically, so I did this example in my section where if you start out with the function, you guys probably already know how to fill out a truth table. Row by row, you figure out where the 0s and 1s goes. So to fill out the corresponding k-map is no different from filling out a truth table. But there are shortcuts with the k-map. So if we're looking at, say, this term, imagine this was empty. In my class, this would have started out empty, an empty grid. Not b, not d. This term turns to 1 if b is 0 and d is 0. That's exactly when this turns to 1. So b is 0 corresponds to the two, to the, so this is a, b over here. This is a equals 0, b equals 0, a equals 0, b equals 1, and so on. So this row has b equals 0. And this row has b equals 0. So that's the b equals 0 case. But I also need d to be 0. And it turns out d equals 0 is this column corresponding to that 0 and this column corresponding to that 0. So the overlap of those two is this 2 by 2 here, the four corners, which is if you wrap it around, it's a 2 by 2 square. So in this four variable grid, if you have a product term of two elements, you're going to get four 1's. That corresponds to four 1's, either in a 2 by 2 grid or a 1 by 4, like an entire row or an entire column, four by 1. And so for similar reasons, every kind of product term that you get is going to end up with a shape that has, that's one of these sizes. So no 3's, basically, when you, so. So that's why, when we're going the other way, we have to make sure we draw loops that correspond to these sizes so that we get terms like this. And that example should show you that wrapping around works too. And so why do we want, we want the biggest ones, we want the biggest loops that we can make, because the biggest loops use the fewest literals. You can see this big loop here is just one literal, whereas the small loop, which is just two 1's, uses the most literals in the end. And you want the fewest loops altogether, because each loop corresponds to a term. So you want to minimize the number of terms and the number of literals within each term to make a simplified expression. OK, so back to the example. So yeah, what remains now is to, so both of these are prime implicants, right, because they cannot grow any bigger. We also check whether they're essential. I don't know if this was brought up, but an essential prime implicant is a prime implicant that has certain cells in it, certain 1's in it, that are not covered by anything else, right? So this one is essential, because it has these two 1's, which are not covered by the other prime implicant, right? So this one is needed, and this one is needed too, because this covers a bunch of 1's as well. So now it's a matter of me writing down the terms that go with this. So how about we start with the biggest one? Can anyone tell me what term I should write down that corresponds to making all these 8 1's? OK, a few people called it out. It's z, right? So if you're not catching on, let me tell you why, right? So the 1's in here, they don't depend on w and x, because you can see w and x can take all different values in here. And it doesn't depend on y, because y is 0 or 1. But what it does depend on is z. z equals 1 for this entire column and this entire column, right? So this is represented by z. Now, this one is a different shape. It's 2 by 2. And if we look at this, these ones belong to the w being 0, right, these two rows, intersected with the y's being 0, so these two columns. Gives you those four 1's over there. So let me come back to your question. So I'm going to say, or w equals 0 is not w and not y. So not w, not y gives you this square. And now, if you all them together, you get all these 1's, right? Because either this is true, either z is true, giving you all these 1's, or not w, not y is true, giving you these 1's. So you still have your question? No, no. So in strange situations, I have an example about that one, and I'll show you that. So I had this example, the same grid on the left and the right. And it turns out that there are several prime implicants here, right? So this cannot grow any bigger. This cannot grow any bigger. But nor can this one, or this one, or this one. So those are the five prime implicants that can be drawn in this pattern. But to identify the essential ones, only this one and this one are essential, because this one has these three 1's uncovered by anything else. This guy has this one uncovered by anything else. The others are not essential, because the green one in the middle is covered by, you know, the one on the left in the green one is covered by that one. The one on the right is covered by that one, right? So if I only take the essential prime implicants, I just get this and this, I still have some 1's uncovered. So I have to look at my other prime implicants and try to cover those two 1's as efficiently as possible. As you can see, I would just use the green one. Yes, question? Yeah, I don't. Yes, I mean, yes, you are looking for. No, no, that's also wrong. Kind of hard to put into words. And to even think about implicants, essential implicants, prime implicants, blah, blah, blah, it's a little bit overkill. If you do enough examples, you'll get a hunch. I think my next example, so maybe I'll make this my last example, shows you that overlap is actually good sometimes. You want overlap sometimes. And other times, overlap is wasteful. So that's probably not a good way to think about it. All right, so here's another example. Again, four variables. Can anyone tell me one of the prime implicants? All right, I think you answered the question before, but I'll let you do it again. OK, good. Four corners is a favorite, right? Because it's one that favorite, and when I say favorite, when exam questions are made, it's a favorite. So four corners is a two by two pattern. And this one cannot grow any bigger. And then another, I mean, clearly, these ones need to be dealt with somehow. How should I group those ones together? Yes. The entire row. So let me come back to this overlap question, right? I could just do these two, no overlaps. But this can grow bigger. And if I grow it bigger, it does overlap with the other one. But bigger is better in this case, because when you have a larger loop, you express it with fewer literals in the and expression, right? So we're about to write down what this is, right? So what is, this is true if w equals 0 and x equals 0, right? So actually, that's not w, not x to make these row of ones. If I just wanted to specify this to these two, I'd say not w, not x, z, right? Because z equals 1. But I don't need that z there. So in this case, I want to make it bigger. So looking at overlaps is not really helpful. So that gives me that row. And then the four corners, if I look in terms of rows, that's when x equals 0, right? So not x. But I also have to intersect that with the first row and the first, and the last, sorry, first column and last column. So z equals 0, not z. So there's a lot more to say about k-maps. But I think that will come later. We'll talk about don't cares. Actually, I think that's on the schedule for Wednesday after the exam. So you'll get a lot more practice with k-maps. So hopefully, you understood what I'm talking about today. You'll get much more practice with this. So don't stress out too much. Yes? Could that be a not w or not a w? There's definitely other ways to write this. So let me emphasize that this is the minimal SOP expression. There are POS expressions. There's a way of doing minimal POS expressions by looping the zeros. I'm not sure if that was covered in this class. I haven't covered it in my class yet. So by looping the zeros, you can think about things in exactly the dual way, like a complementary way, and get a minimal POS. And sometimes, a minimal POS will be more efficient than the minimal SOP. And sometimes, there'll be a minimal way, which is neither POS or SOP. And k-maps are not going to help you find that. So yeah, there's a lot more subtlety to this than even what I'm showing you. But this is a handy tool to get a minimal SOP or a minimal POS. OK, yeah, I don't want to do the next example. Oh, I should point out that our notation is slightly different. So I noticed this with Professor Lumetta. So what I would write here in this example is, what would I write? I'll write BD here and AC up here. But Professor Lumetta does, like he indicates that the B is 1 in these two rows. So that's why I know the B comes first. And the D is 1 in these two rows. So the D comes second, and likewise for the C and the A. So just a difference of notation. The industry doesn't do k-maps. K-maps are a teaching tool. And they're really fun to make questions about. They're really fun to solve, too. But k-maps don't really extend well to more than four variables. And if you were designing something in industry with four variables, you probably need to find another job. That's not interesting. What are the programs that you can do? There are. So the way to do it in industry is to use software. And you'll learn a lot about that in EC 385. Like, you'll be designing more complex stuff. I don't actually know a lot about what it's. They don't do it optimally. They use heuristics, because it's a really hard optimization problem. So they do good enough instead of perfect. And they may use the hypercube as some kind of data structure underlying all of that. OK, so where are we? Did we cover this? We covered this. No? Where are we? Oh, OK. So SOPs, so k-maps, what I just showed you, gets you a minimal form, which is an optimal SOP expression where we care about the area. We're trying to minimize the area. But minimizing the area of the circuit is not the only possible metric. We could also minimize for the speed of the circuit. So the speed of the circuit, let me see if that comes next. So apparently, you've already learned that the speed of a circuit has to do with the number of gates between any of the inputs and the outputs, so the maximum number of gates along the chain from input to output is a rough approximation for the delay. And actually, we're going to assume that the complement operation does not require a delay. There's a reason for that, which you'll see in a few weeks. But we usually get, if we have x, we usually have not x somewhere else in the circuit. So we don't need to create it with a gate. It's already there somewhere. So if you only have only allowed one gate delay, what functions can you implement? I guess this is a question for you. So you're only allowed to use one gate, basically. What can you implement? NAND and NOR, actually, that's right. So you can implement NAND and NOR, because those are the basic gates. A NOT is kind of, you can make a NOT out of a NAND and a NOR. So that's what's being said here. A one-input NAND is a NOT. A one-input NOR is a NOT. So very simple, very simple functions. So a single NAND is a kind of a trivial SOP expression, because a single NAND, does that make sense? A single NAND is an SOP expression and a POS expression. What's meant by that? Let me write that down somewhere so I can make sense of this. I just noticed that that's kind of a weird thing to say. A NAND, what is a NAND? That's a NAND. I kind of disagree that this is SOP or POS. Anyway, not. I'm not sure what he means by that. OK, perhaps I'll skip over this slide. I'm not really sure what the message is. All right, all right, but most functions, I think this is it, this I believe. Most functions cannot be expressed as a single NAND or NOR gate. OK, so I think we dealt with a very simple case and made some claims about it, which I wasn't sure about. But how fast is an SOP expression? How many gate delays in an SOP expression? Because remember, if you think about the expression itself, it's a sum of product terms. Each of the product terms is an AND gate. So you have a whole array of AND gates for each of the product terms. And then you OR them together. So it's actually only two delays, a bank of AND gates, all connected to an OR gate. So it's two gate delays, an AND followed by an OR. And any NOT gates, we just ignore, because we assume we have the complemented inputs for free. So it's just two gate delays. But if you remember, when we talked about CMOS, AND and OR were not fundamental. The fundamental gates that we had were NAND and NOR. So is it right to say that they're two gate delays? Because it might be a little bit more than that. So let's explore that question. If we have an SOP expression and we can only implement it with NAND and NOR, how many gate delays does it take? So two gate delays with AND and OR. How many gate delays with NAND and NOR? Well, it turns out that we're going to have to do a little bit of math here. You're going to have to use a formula called De Morgan's law. And we'll see this a lot in this class, which says that NAND is actually, so AB, the NAND of A and B is actually the OR of NOT A and NOT B. So you can replace the NAND operation with an OR operation as long as you invert or complement the inputs before you use them. Conversely, a NOR operation, which is OR followed by a NOT, is the same as using AND with complemented inputs. So you first complement A, complement B, AND them together. This is the same thing as NOR. So if you want to prove this, it's pretty easy. Why don't I actually do that? So let's prove one version of De Morgan's law. OK, so I'll make a truth table out of this. So what I want to do is prove that A NAND B is the same as NOT A OR'd with NOT B. And all I have to do is, by brute force, look at every single case. There's only four cases here, because A and B can only take four different combinations of values. So we know that the meaning of NAND is you take A and B and complement it. So A and B would be all 0's with a 1 here. So NAND would be all 1's with a 0. What I want to show is that you get the same pattern in this column over here. So I'm going to do some intermediate steps here. NOT A is just the opposite of the A column. NOT B is the opposite of the B column. And now I'm ORing these together. So an OR is equal to 1 if either or both of the inputs is equal to 1. So you can see that the first three are 1 here, because we've got 1 OR 1, 1 OR 0, 0 OR 1. And it's only here that you get a 0. So this is a proof that A NAND B is the same as this. This is a proof of De Morgan's law. We just checked every single case. So that's what he's talking about here. You can do the other proof. You can do the other De Morgan's law proof. And you can actually do this for more than two variables as well. So the NAND of three inputs is just the OR of the complemented inputs. All right, so why are we doing this? We're trying to compare ANDs and ORs to NANDs and NORs. We're trying to establish a relationship. And so this math tells us that there is a relationship. And this is just what I just said. Actually, I should be doing this. This is what I just said. NAND is the same as OR on the complement of inputs. NOR is the same as AND on the complement of inputs. So what's neat is that we can express this graphically. This is a little complicated. But AND can be turned into NOR. This part is NOR if we complement the input. And OR can be converted into NAND if we complement the inputs. These bubbles kind of mean complement. So these are not real symbols. You wouldn't see them in a circuit diagram. Just for convenience, we're just putting little bubbles on the input right there. If we have an SOP expression, it can be written as a bunch of ANDs, a bank of ANDs, remember, all connected to an OR gate. And we said there are two gate delays, right? With two gate delays in this one gate here, one gate here. But we want to turn all of these into NANDs or NORs because NANDs and NORs are fundamental in terms of the underlying transistors. So what can we do? Is this animated? Right, we're going to use De Morgan's law. And what we can do is we'll look at the OR gate. And we know that OR gates can be replaced by a NAND as long as we invert the inputs. So we've got these little bubbles here into a NAND gate. So we've got a bank of AND gates, some extra inverters, and a NAND gate. But what is an AND gate followed by an inverter? That's a NAND itself. So you can basically slide these bubbles over to here, that one there, that one there. And what you end up with, I think this is an animation as well, is a bank of NAND gates followed by a NAND gate. So what you have is you've converted the AND OR structure into a NAND NAND structure. And this is still two gate delays. And this is two gate delays based on NANDs. And NANDs are simpler than ANDs and ORs in terms of underlying transistors. So that's a neat thing. And you'll be expected to really understand that. Right, right, so this was the punchline. We can build any SOP function. Instead of using ANDs and ORs, we just use only NANDs. We use only NANDs to build the entire structure. And it's still two gate delays of NAND. Yes? AUDIENCE MEMBER 2 We don't need NORs. We don't need NORs to. We just use NANDs. Yeah, it turns out that our construction didn't use NORs. Now, if you start with a POS instead of an SOP, so I don't know if this is off topic now. But if you start with a POS, then you start with OR gates here and an AND gate there. And then you would convert the AND gate here into a NOR. And then you would get NORs. So a POS becomes NOR logic. An SOP becomes NAND logic. I'm sure you'll explore this, if not in class, in your homework. You'll be doing these conversions. Right, and that's exactly what comes next. So great question. So you can use two levels of NAND to build an SOP expression. You can do exactly the same thing for a POS expression, two levels of NOR. And so any POS expression also requires two gate delays, NOR and NOR, assuming that the complemented inputs are free. They don't cost any gate delays. And as I said, later in the class, you'll see why they're considered free, because we'll get them for free. OK, so how do you make a POS expression using a minimal POS expression? We've talked about using k-maps to find minimal SOP expressions. So what we did before was we tried to make big loops with ones in them, and that led to a minimal SOP expression. If you start with the same k-map, you can look for zeros and try to make big loops out of the zeros, just the same operation. And each of those loops will correspond to a max term. A single zero corresponds to a max term, but a loop will correspond to a sum term. So do we have examples of that? OK, maybe I should do an example here. Agree? I don't see an example coming up. So let's go back to this and see if I can do a good example here. So let's look at this picture again. So suppose I want to loop the zeros together optimally. I'll do this a bit quick. Here's one loop that we could do of zeros to cover zeros, and here's another loop to cover zeros. So I think this is the optimal way to cover the zeros with two loops. So the question will be, if I want to write f of x, y, z as a product of sums, what is the sum that goes with this loop? Well, it's actually a pretty trivial sum. This becomes 0 when x becomes 1. This becomes 0 when x becomes 1. I have to get this right. Sometimes I get confused. So I think that's a sum term x. Or is it not x? I'm confused. I haven't prepared this. I'm going on the fly. AUDIENCE MEMBER 2 Yeah, and then x plus a sum can be a rule. Right, x equals 1 makes this 0. And so I should do not x to make it 1. I'm a little confused. Let me see whether this gets to the right answer. So if x is equal to 0, this becomes 0. And it makes the whole thing 0, because I'm going to multiply it with other stuff. So actually, you have to go and find the value of x and then invert the term. When you find the sum terms, there's like one more step of thinking than finding the product terms. You've got to invert a little bit. So this one, for instance, is 0 when w is equal to 1. So I need a not w in there, not a w, but a not w. Or when z is equal to 1. So that's not z. And so this is the product of sums expression. So it's a little bit harder to think about. I think you'll get practice with it on the homework, and you should also reason about it. But actually, we haven't learned Boolean expressions yet. But if you could factor this expression, you would get this expression. Turns out that you can. You'll see that soon. So they're actually the same. It turns out to be really easy to see that this is the same as this, as long as you can factor out not x. OK, so that was an example. I'm sorry that I didn't prepare that one, so I wasn't that clear about it. Let's see. But this warning here is exactly what was tripping me up. The max term has all variables complemented relative to the min term. And so the same, in other words, the sum term has all variables complemented relative to the product term as well. So if you have a box corresponding to min term ab not c, that's equal to 1 when a equals 1, b equals 1, and c equals 0. If you take the or of those same variables, but each complemented, that is equal to 0 in the same place. So the same cells correspond to min terms like this, but max terms with the complemented inputs. That's the tricky part and the part I was tripping on. OK, how am I doing? I'm actually really slow, but that's OK because Professor Lumetta is ahead of everyone else. So to find the POS form, create loops, find the prime implicants and essential prime implicants. It's just around the 0s instead of the 1s. And then build up your POS expression by multiplying those sums together. Make sure that you don't forget to complement the literals because of the duality between SOP and POS. And then each loop is a sum, and you multiply them together. Again, examples are the best way to understand this. So what gives a better area? SOP or POS? Well, it depends on the function. So if we go back to the example that I had, which one is better? I guess I would say this one is better. This one requires an AND gate, an AND gate, and an OR gate. But this one requires just an OR gate and one AND gate. So this one is slightly better than that. But in general, it totally depends. There's no general rule. It depends on the situation as to which one is better. And in fact, neither may be the best. Neither of them may be the best. There may be an entirely different solution that is better than the SOP, the minimal SOP, and the minimal POS. So this brings us to this topic of Pareto optimization. And as you can see with the star here, it's not actually going to be tested in this class. This is just additional information. So it's kind of good that in the last seven minutes, I can kind of basically describe the idea quickly. So what happens in this situation when you have a task to do and you come up with a bunch of different solutions? How do you decide which ones are better than the other ones? So in this scenario here, you're an intern. You're designing some hardware to execute dense neural networks, whatever they are. So you're trying to optimize your design. And you have two metrics. Let's say your boss says, it's got to be small. And so you have a score for size, 1 to 100, where 1 is the smallest, 100 is a large size. And you have a delay as well. And so the delay can have a score from 1 to 100. Smaller numbers are better. In both metrics, smaller is better. So if you have a design called x, let a of x be the area and d of x be the delay. So if you have two designs, how do you choose between them? What's more important, area or delay? Well, yeah, it depends. I don't know which one is better. So it depends on the context, whether area is more important or delay is more important. So one way to handle this, and I'm just going to kind of skip through most of this, is to create a weighting factor to weight whether area is more important than delay or not. So make a function like this and try to optimize this function. But that's going to depend on the context. It's going to depend on your engineering judgment. But how do you pick the weighting? So it depends on judgment. And you may not be, even if you are the engineer working on this, you may not be the one to have the judgment. That might be like a more of a managerial call than like an intern's job. So what do you do if you don't know what's better? So if you only have two options, just tell your manager both of them and let your manager decide. But what if you have like 10,000 different options? You've created them algorithmically. You have different parameters that you can change. And it just becomes a huge number of possibilities. Do you report all of them to your manager? No, you're going to have a pretty annoyed manager. So what can you do? So I think some of them you can rule out immediately. So suppose you have a design x and y where the area of a is better than the area of y. And the delay of, sorry, the area of x is better than the area of y. And the delay of x is better than the delay of y. So what does that tell you? y is out of contention. So x is better. And so in this context, what we say is that design y is dominated by design x. In particular, it's Pareto dominated by design x. So this is just an example with two metrics. If there are n metrics, then y must be worse than x in all dimensions to be Pareto dominated. So yeah, as we said, anything that is Pareto dominated by another solution can be discarded. And only the designs that are not Pareto dominated by other designs need to be retained and presented to your manager. The remaining designs form what's called a Pareto curve. And if you take some econ classes, you'll also learn about this concept of Pareto. So if this is the space of all designs, and I guess, let's say, this is the area score and this is the delay score, the ones towards the origin are better than the ones away from the origin. But in particular, if we look at solution p, we can see that p dominates all these points. So if you found a solution p, those can be discarded. And so if you do that with all the points, what you'll find out is that you get left with these several possibilities that are not dominated by each other. You can see this is the Pareto curve that you get. So they all represent different trade-offs between minimizing area and minimizing delay. And so these are the ones which need further consideration. So the point is, in many design environments, whether it's hardware design or any kind of design problem, the designer undertakes this exploration task. So there are a bunch of parameters, area, speed, for example. You generate a bunch of solutions. And then you trim your solutions by using Pareto dominance. You throw away the ones that are definitely worse than some solution. And then you show your boss the surface, the Pareto. If you have three dimensions, like area, delay, and power consumption, instead of having a single curve in two dimensions, you'll have a surface in three dimensions, a surface of possible good solutions. OK, so I think the next topic is Boolean properties. I'll let Professor Lumetta take it from there. Are there any questions in the last couple of minutes about the exam or about what we talked about today? Yes, Rahul. So architecture design today always goes to a smaller area and has more or less decreased Boolean, right? Are tools not equal? How can they get smaller and smaller? OK, so you're asking how do things get minimized? I mean, there are a lot of different ways and a lot of different, like, the transistors can get better, the designs can get better, and so on. But I think we shouldn't just restrict ourselves to area and delay. There are questions of reliability or verifiability, like does this thing actually work? So the cost, right? How much money you want to pay your engineers to make sure they do a good job? How many engineers do you want to hire? So there are a lot of considerations. It's very complicated out there in the real world. All right. When is the undergraduate advising for the test? Oh, the review sessions are, there is one tomorrow at, there's one tomorrow at 2 to 4 PM in 1013 ECEB. And that is done by Eta Kappa Nu, so it's not official. And then there is the official undergraduate session on Sunday, same time, same place, 2 to 4 PM, 1013 ECEB. And then, of course, on Monday, you have your lecture again for review. So there's plenty of review sessions. And down the bottom, it actually says that for the Sunday session, the UAs will be talking about the fall 2013 exam. So you can practice that exam. After you practice the exam, you can look at the solutions, and then you can come and ask questions about it in the review session as well. Can I be recorded? So if you want to. Sure. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.\"},\n",
       " {'ECE120-2016-09-26-LEC-14-slides.mp4': \" the comparator design, and then we'll go through that design and analyze it in terms of area and delay and think about optimizing it. We'll do a little bit of algebra, come up with a better design. Then I want to take that design and think about what we can do. So the design we're working on is an unsigned comparator, right? So we put in two unsigned numbers and it tells us A and B, tells us whether A is less than B, equal to B, or greater than B. So then I want to think about, well, how would we build a two's complement comparator? And so the answer we don't want is we'll start over, do a bunch more K-maps, and so we'll see what we can do. That's probably about as far as we'll get today, hopefully. But one thing, the midterm grades are posted, so we finished grading them on Saturday. The standard plan, by the way, is the Saturday after the midterm, we're going to all sit down and grade. So it's kind of a standard process, so you can expect your midterm grades to be done by that Saturday and up, usually by the afternoon, if not by the evening. So those have been up a couple days now. I will send a few emails related to that. I mean, generally people did well. I want to maybe talk with a few people, make sure people feel like they're on track for getting a grade they're happy with in the class. But feel free to talk to me about the same during office hours, tomorrow 1 to 3. I may extend them a little bit, but I'm not quite sure which direction yet. I think my next meeting's at 4, so maybe at least I'll stick around a little longer if people have questions tomorrow afternoon and over in Daily Byte. All right, so I wanted to review, since we had the whole weekend to do other things, so I wanted to review the design we were working on. So remember, when we compare as humans, we write the numbers down, line them up, and then start on the left because the left side's the bigger side, and so as soon as we find a difference, we're done. But of course, when we're designing a digital system, it's not so easy to just have the wires suddenly give us an answer, so the information will flow all the way to the end, and then we'll look at the wires at the end, and that'll tell us the answer with what's A related to B. So it doesn't matter for the digital system which way we go, right, because the amount of time it takes, the logic is going to be the same. So I thought, well, let's just design the other direction. Our choice will actually affect our logic, so you can do different approaches, and sometimes that'll affect your logic. Sometimes it might be easier, other times it might be harder. But our comparator here in class will go from least significant to most significant bit. So this was our bit-slice abstract model. So we have two bits coming in. Remember, there are two bits because there are three possible answers, right? So for all of the less significant bits, we can say, well, A was less than B, is equal to B, or A is greater than B. So in order to encode three different answers, we need at least two bits. So we've got two bits coming in. Similarly, our answer of whether with this extra bit in the front, A is less than, equal, or greater, we need two bits to encode that answer, pass those usually to the next bit-slice, but at the end, we'll have our answer. And then we get one bit of A and one bit of B into this bit-slice for bit number M. And then we talked about, well, how do we actually choose the representation? There is no natural representation, right? If I said, OK, everyone pick their favorite, or pick what you think is best, and then we looked at them all, there are 24 different ways to assign these three different messages to these four different bit codings, right? And I'm sure that none of them would have a better, a bigger distribution or bigger number of students than other ones, right? Well, maybe you'd pick this one, because you've seen it already. But other than that, there's no real reason to choose one over the other inherently, except a little bit. So if you look at this, there is some symmetry here, right? So the equals case, I chose a pattern where the bits are equal. The less than and greater than case, I chose a pattern where the bits are different, right? So there is actually a little bit better advantage. If you look at symmetries and try to reflect those symmetries of the answer in the bits, often your logic will end up being a little simpler. Because we did this, you'll see that the one-bit solution that we calculated initially will also show up in the full solution. So I'll call that out for you as we look at the designs. But you'll see the one-bit solution, the circuit for that one-bit solution, appearing in the general solution as we solve the problem more generally. All right, so this was our single-bit solution. So I said, well, for the end bit, we don't have any extra bits to look at. And so those are implicitly equal. So let's start with this easy problem, or easier problem, of saying, well, what happens when we have one bit of A and one bit of B? What is the meaning of the answer for that? So of course, if we have 0 and 0, those are equal. We'll have 1 and 1. A is equal to B still. Here, A is 0, B is 1. These are unsigned, again. So A is less than B. And then 1, 0, A is greater than B. We code that with our representation. And those are the bits that get passed out for the first bit slice. Now, of course, the real bit slice we're going to build for the first bit slice will look like this. And so we'll feed in zeros to that bit slice in the real design. But we just wanted to calculate this answer. And that gave us this circuit diagram, where the minterms here, these are, sorry, let me go back to that. Each of these functions, remember, Z1 and Z0 is a minterm, meaning that it has 1, 1 in its whole truth table, one output of 1. And the minterms are A, not B, for Z1, and A prime B for Z0. Sorry, I should say that as AB prime for this one, and A prime B for that one. Now again, those two are the ones that say that A and B are not equal. Those are the minterms that say A and B are not equal. So for example, if you wanted to build a simpler comparator that simply told you whether the two values were equal or not, then you could OR these two together, and it turns out that would just be an XOR gate. And so an XOR also tells you, well, are the two input bits equal or not? Not equal, you get a 1, equal, you get a 0. Okay, so now we're ready, hopefully, to solve the more general problem. I won't flip back to the representation because it's actually here for you. Okay, so we've got the, on the left side are inputs. We have A and B, one bit of the current number. Remember, this is the most significant bit, right? So we're getting input from the less significant bits. So A and B are the most important bits to look at at this point in the number. C1 and C0 encode the answer for all of the lower bits. And so when I say the representations reproduced here, 00 means A equals B for the less significant bits. 01 means A less than B. 10 means A greater than B. And 11 should never happen. All right, so let's go through these. So this is one quarter of the truth table we have to write out in order to understand the design. So I want you to kind of get a feeling for what's going on here. So in order to find the answers, we have to look at the meaning. So we have to use the representation that we chose to decode C1 and C0 into a human meaning. We have to then calculate the right meaning for the output. So given this meaning and these bits A and B, what should we tell the next bit slice, A relative to B? And then we have to use the representation a second time to encode the answer. So when you're picking a representation, the relationship between that representation and the resulting truth table in KMAPs is not going to just be trivial. You're not going to be able to say, oh, well, if I change it a little bit, that'll make my KMAP easier to solve. It's not, unfortunately, quite that easy. You have to go through it twice in order to get the truth table, and then you have to take the truth table, put it into the KMAP. So it's often not easy to see. So that's why with something like 24 different choices, often it's better to say, hey, computer, go look at all the answers and find the best one for me. So for something this small, 24 is a tiny number. Even thousands or millions are usually pretty tiny for a computer. So they can solve those kind of problems. If you get a much bigger design, something like you'll see with the LC3 microarchitecture, we have many, many bits. A computer can't solve it. And that's where you really need human intuition about symmetries, different kinds of information that don't have to be related, where as a human, you break those into pieces. You give the pieces to the computer to solve the small problems, and the computer can do a good job with the small problems. But you can imagine if you had, instead of four rows of your truth table, if you had 32, sorry, not on this one, but on the representation, if instead you had 32, well, then you have 32 factorial different ways to assign your representation. Even a computer is not going to explore 32 factorial ways for you, not in your lifetime. So the human intuition helps you in real designs. In this kind of design, we could just hand it to the computer. But I want you to understand how it's done. So remember, in our bit slice, we have four inputs. We have to look at one bit of A and one bit of B. And we also have input from all of the rest of the lower, less significant bits, telling us the relationship of A and B for those bits. Now, any time you have input bits, you have to consider all possible patterns. So with our truth table, all I've done here, sorry, wrong way. All I've done here with our truth table is say, well, I can only fit a quarter of it on a slide. So the quarter I'm going to fit is the quarter where A and B are both zero. And we'll have three other slides. I don't want to show you the answers. We'll have three other slides where A and B are zero, one, one, zero, and one, one. And then we'll go through all possible values of C1 and C0. Yeah. Yes, yes, that's right. So remember the information flow. I don't think I have the big picture in front, but we'll look at it later. There will be n copies of this bit slice. So all of the copies down here, or at least less significant bits, will do all of their computation. We'll decide whether for all of those less significant bits, A is less than, equal, or greater to B. And we'll tell this bit slice through these two wires. Yeah. Yes. And that's part of filling in the truth tables. So hold on to that thought. Any other questions before we go forward? Okay. All right. So Mohamed points out that C1 and C0 we probably only care about when A and B are equal, right? Because A and B are the most significant bits in our design. So since we're passing from least significant to most significant, the only time we should care about the inputs are when A and B are equal. I'm sorry, the inputs C1 and C0, when A and B are equal. There's one caveat to that, which let me get to the non-equal slide before we look at what it is. All right. So help me out here. So if I get A and B are zero, and C1, C0 tell me A equals B to the right of me, what message should I pass? Zero, zero. So actually, I just want you to tell me meaning first, and then we'll encode it. But yeah, A equals B, which is going to be zero, zero. So what if I get zero, zero for A and B, and then I have A less than B for the less significant bits, what message should I pass? A less than B. Good. How about this next line? A greater than B. And so you see, basically what A and B are, since they're equal, I have to rely on what's what the less significant, the relationship between the less significant bits, which is encoded in C1 and C0 for me. So I want to pass the same meaning then because my bits, A and B, were equal, didn't change the answer. So I'm going to pass the same meaning. How about this last one? It never happened, right? This is not a human pushing buttons for us, right? This is not our hand-held computer, hand-controlled computer, thumb switches, right? This is a bit slice. It never produces one, one. So we don't have to worry about this case. So we don't care. All right. So then we can code it. Over here, we already have the encodings, right? So this one, A equals B is going to be what? 0, 0, right? Good. What about this one? 0, 1, 1, 0, XX. Good. All right. So this is a quarter of our truth table. We've got three more slides to go. So this is the A equals 0, B equals 0 case. So let's then do the A equals 1, B equals 1 case. Is there any difference? There's not, right? A and B are the same. So we have to take the answer that our less significant bits gave us as encoded in the C1 and C0 inputs and just pass that along to Z1 and Z0 using the same representation. And so we just forward those bits. So A equals B, A equals B. A less than B, A less than B. Good. A greater than B, A greater than B. What's this one again? I don't care. Good. And then the bits are the same. It looks exactly the same, right? Outputs are exactly the same as the last case. All right. So now what about this case? A equals 0 and B equals 1. So when A equals 0 and B equals 1 and the less significant bits are all equal, what relationship do these have? A less than B, right? Because this is the most significant bit, B starts with a 1, unsigned number, remember. B starts with a 1, B's bigger. Doesn't matter what the rest of the bits are. B's bigger. And that's where you'd stop comparing as a human. So A less than B. So if it doesn't matter what the rest of the bits are, well, A less than B will also send A less than B, right? Not because of this, but because B is 1 and A is 0. And even though these bits, A is greater than B, well, this is the leading bit. So A less than B. What about down here? Don't care. We could say A less than B, but we don't need to, right? If we put out a different answer here, it doesn't matter because this case won't happen. So somehow this answer enables us to get a simpler logic. Let's take advantage of it, right? So this is the caveat that I mentioned in answer to your question, Mohamed, that even though we know the most important bit tells us A less than B, we also know that this should never have happened, so I don't care what answer I put out. And so this is the one that overrides because it doesn't matter in this case. It should never happen. So I can take advantage of the flexibility. Now I don't actually even know if putting x's here gave me a better function, but I want to make sure if it can that it does. xx. Yeah, don't care. Yeah. I mean, we could put 0, 1 here, but that just means there are three functions. Well, 3 times 3 is 9 functions, so we're not considering for A that was 9. OK. So always output A less than B for valid inputs. And so the valid inputs is the caveat. All right, good. And what about A equals 1, B equals 0? A greater than B, right? So A greater than B, A greater than B, A greater than B. Don't care. Good. And those are all coded the same. All right, so now we have our truth table. I'm not going to walk through copying the k-maps. I'm just going to pop up the k-maps with all the values. Is that OK? All right. Oops. I mean, we can go through and copy it, but this is what you should get. So what I've done here is I've put A and B on the top. I put C1 and C0 on the side. And so these are essentially the same as our truth tables, except that the bottom two rows, of course, are flipped. And then the order we did the truth tables was 0, 0, 1, 1, 0, 1, 1, 0 on the slides. Where are the loops? Right side. That's what I picked first, too. What is that one? A, B0. Good. AB prime. OK, so AB prime. What else? Bottom right corner. Hey, look, that's what I picked, too. OK, what is that one? I'm hearing different answers. So OK, right side is A, right? And then bottom is C1. So AC1. OK, good. And then what else? So bottom left two, except you can go this way, too. Wrap around. OK, so we're going to wrap around. Good. A little messy looking, I guess, unless drawn by hand. Tell our students at Microsoft that we need wrapping default arc things. All right, so what is that one? B0, C1. Good. So this is sort of a majority function. I hesitated to call it this, but it's a majority function if you count B prime as a valid input. So if two of these three are equal to 1, then Z1 is also equal to 1. So if we write that out, AB prime plus AC1 plus B prime C1. If any two of those are 1, then Z1 is 1. Yeah, so the question Mohammed's asking is, should you make the loops as big as possible? So in the presence of X's, you need to change the original rules for finding prime implicants. You do need to find prime implicants, right? So you need to make them as big as you can. Circling X's is OK. Circling 0 is still not OK. So make them as big as you can, choose as few as you can, and always cover all of the 1's. You do not have to cover X's. So the changes, I put them on a previous slide when we introduced X's, but make the loops as big as you can, cover all the 1's, and don't need to cover X's. So that's the rules we've applied here, and that gives us this minimal SOP form. Yeah. Is this one unique? OK, so that's a good question. Did I make any choices? So when I went up here, I could not go left. Left. I could not go right. I could go down. I could go up, and I did go in both directions, so I didn't make a choice. For this one here, I could not go left. I could not go down. I could go these two directions and I went in both, so I did not make a choice. And then I had this one left. I could not go this way. I could not go that way. I could go this way and that way. I went involved, so I made no no choice. So since I made no choice in any of these and I'm done, then yes, it's unique. Any other questions? Yeah. It's not that they're unknowns, it's that we don't care. And so we're allowed to leave them as zeros. So in particular, we do not need to circle this x, right? And so in this case, we have a good answer without circling that x. Circling the x would not have bought us anything, right? Adding this row here of four x's would not have gotten us anything because we wouldn't include any ones, right? So including the ones is the important part. You're allowed to include x's, but you don't need to. Anything else? No? Okay. All right, good. So we got another function to do, z0. So what are the loops? Vertical one? Okay, good. What is that? a0b? Okay. And what else? Two squares. Which one did I pick first? There's one. What is that? a0c0. Okay. And then the other squares where? In the middle. That's bc0, people are saying. Okay. So same kind of thing, right? Three values, one of which is a prime, but if two of those three values are one, then z0 is one. So you notice these are symmetric, hopefully. Actually, let me put them side by side. So notice the symmetry both in the circuit diagram, but also in the algebra. That symmetry is there partially from the problem, right? That a and b, we're just comparing them, so there's no reason to think that a is any different than b. If I swap them, I'd still get an answer. It would be the opposite sense. But also because of the way we chose our representation. If you chose an asymmetric representation, the symmetry would be broken and you wouldn't see it in your design. But here we chose a symmetric representation where when the two are equal, we have the 0, 0 pattern, and when they're not equal, if a is bigger than b, we have one of the non-equal bit patterns, and when a is less than b, we have the other non-equal bit pattern. So the symmetry shows up in our answer. So that's a nice design. A lot of gates, but this is what we get out of our computation. We could stop here. If we were to give you something like this on a homework or exam, this would be a fine answer. I'm going to take it further and do some analysis because I want you to understand how you do trade-offs and how you think about these things, but this would be a fine answer. You can go implement it this way and this would work just fine. Any questions on this? OK. So hopefully people feel like they followed along and could do this themselves. All right. So, oh, yeah, yeah. So I did want to call this piece out for you. Notice this thing in the middle. Because we're doing information flow from less significant to most significant bits, the most significant bit, of course, is the most important, as we talked about when we did the truth tables, right? So if you look at this, this is the same functionality that I got when I did one bit without considering what was happening with the, you know, when there were no lower bits. So this is my circuit diagram for one bit, and it produces the same answers and those answers, if this AND gate produces a one, Z1 is one. If this AND gate produces a one, Z0 is one, right? So that single bit core is still there. It's just that in order to handle the other cases when we have less significant bits giving us information, we need this extra logic. But the single bit core of just comparing A and B is still there. One bit of A and B, I mean. Yeah. How would I represent them, sir? Symmetry? So the symmetry will actually come out in the form. So you can see that here, the A's and B's have opposite complementation. So if you look at this term, A and B prime, this term is A prime B, right? And then the C1 and C0 are also symmetric in the sense this one has C1s and this one has C0s. So the symmetry comes out in the algebra as that. But just like we talked about duality where you replace AND and OR, you replace 0 and 1 with each other, here you replace, if you replace A and B with one another and you replace C1 and C0 with one another, and you get the other expression. So that's where it comes out algebraically. Yeah. So that's a good question. So the question is that Daniel's asking, is it possible that an asymmetric representation gives you a more efficient design, whether better area or better delay? It's certainly possible. I think if you have to pick and you don't want to explore both, I would tend to favor the symmetry. I think it's reasonably good intuition. I think it's possible, but I think of just sort of geometric arguments, like if you have a fixed perimeter and you want to make optimal size area, you end up with a square. So making things asymmetric usually ends up making half of it more complicated and not simplifying the other half as much. So the balance tends to be not as good. But it's certainly worth exploring, certainly in simple designs like this, where it takes you a few minutes to go do it. Yeah. It's a good question. Yeah. So I just wanted to call it out so that you see that once we've decided on the symmetric representation and the use of the least significant bits passing information to the most significant bits, that this logic for calculating the single bit solution is still part of our answer. That it's sitting there because the single bit solution is the thing that dominates the answer. So when we filled in the truth table, we said, well, if A is 1 and B is 0, then the rest of the bits just don't matter. Because clearly if the leading bit of A is 1, the answer is A is bigger than B, if B is 0. So that single bit answer here is also logically dominating this bigger system in the sense that if this output's a 1, z1 is 1 regardless of what these gates do, because it's an OR gate. And if this one down here says B is bigger than A, A is less than B, z0 is 1 because this is an OR gate. So that's how that human meaning gets interpreted in the logic. Easier in the area delay power sense or easier in the human? Yeah, so I think you get benefits both directions, right? Yeah, you can't stop. Yeah, that's right. Yeah, so there's no, you can't look at one bit and then suddenly give the answer out of two different wires, right? Someone has to know which wires to look at. So you have to flow the information to the end. So you'll have to carry it forward. So the truth table calculations will be different ones, but more or less the same. Okay, good. So here's what we've got. So let's go through and use our heuristics to analyze area delay. So how many literals do I have here? All right, so remember literals. So it's a little tricky because when we talked about literals before, we only had one output. So the way I want to count literals is just to look at this diagram and say, well, whatever's going into the first level of gates is a literal. So here's a copy of A, here's a copy of C1, here's a copy of C1 and so forth. So how many inputs do I have on my first level of gates? I have six gates, but how many inputs total? 12, right? Two input gates everywhere. So 12 inputs, so 12 literals. And if you look at the equations here, it's going to match, but later it won't quite match. Let me flip back to the equations. So if I asked you to count literals here, you'd also get 12, right? You'd say, okay, count literals A, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12. Later, we're going to reuse some of our expressions, so it won't be quite the same. But here, 12 inputs to our gates from the inputs, right, directly from the inputs. So those are the literals. How many gates do we have, not counting these inverters? Eight, right? So eight operations. And so that gives us an area of 20 from our heuristic. So keep that in mind. Every bit slice costs us 20 area, because later we're going to do a different design we're going to want to compare. Add 12 to 8. Remember, our area heuristic was literals plus operators. And when we do that graphically, it's number of connections from the inputs, possibly through inverters, through the first level of gates, plus the total number of gates. All right. Yeah, Eric? Yeah. So the question is, if we were able to find things like XORs, would that decrease speed or area, and possibly mean decreased delay and increased speed or something? So it may in some cases. And so the thing is, you have to go through the different representations and work it out and figure out the balance, right? Figure out which answer looks best. And that's why I said for 24 solutions, just have a computer calculate them all and find the best one for you. I actually did this all on paper after I picked my representation based on symmetry the first time. So I think the representation I gave you is one of the optimal ones in that sense. But in general, it's worth exploring a few different options that you think might be promising if you're doing it by hand. That's a good question. All right. So let's analyze delay. So to do this, I want to start with Z1. And then maybe I'll tell you now, I'm going to remind you this is symmetric. So if we do for Z1, you're going to get the same answers for Z0, right? So let's just do Z1. So what's the number of gate delays? Again, we decided not to count inverters. So we're just going to go from A to Z1. Two, right? So there's a path that takes two. And I think probably all the paths take two. So two gate delays from A to Z1. What about C1 to Z1? Also two, right? There's another there's a path from C1 to Z1 with two. Good. What about C0 to Z1? Yeah, zero would actually be a little misleading. It doesn't matter, right? It doesn't have any impact on Z1. So let's just say it's not relevant. Zero, we could get confused later. We could think that until I have C0, I can't calculate Z1, which is not true. So in this case, it wouldn't have any effect. But you don't want to have that constraint when later you're trying to glue pieces together and figure out delays. So it's not relevant. What about B up to Z1? Two also, right? So this one does go through an inverter. So if we're going to count that, it might be a little slower. But we'll count it as two. We're going to ignore the inverter. Same way we talked about when we introduced the ideas. All right. And again, the delays to Z0 are symmetric. So if you went and did the same exercise, you would get A to Z0 is two, ignoring the inverter. C1, not relevant. C0, two. And B, two. So here, this is what the comparator is going to look like when we glue it together at the low end. So we're putting zero and zero to say that these are equal. Initially, A and B are equal. And we're going to say A and B are available at time zero. So if at time zero, zero gate delays, I put A and B on my inputs, then when can I expect to see my outputs? So we'll use the calculations we just made to figure out for the bigger system when the answer will become available. So A and B are available at time zero. I'll just mark those as zero. So those meet available at time zero. What about these zeros on the right? What time are those available? Yeah. Those are just constants. So those are just wired to ground. Yeah, negative infinity, effectively. So these are always available. From the point of view of the system, these are available when I turn the power on. So we'll just call it negative infinity. So forever. So that's what we have so far. Now what we need to do is use the timings we just calculated to let this information flow through the system and figure out when are these intermediate values going to become available? Yeah. This one? Why is what? Why is C zero? So C zero, let's look at where it goes. So it goes into this gate. Let me delete that. It goes into this gate and into this gate. These gates go both into this gate, and that gate changes Z zero. None of that information affects Z one. I'm sorry? I'm sorry, I still can't hear you. Yes, yes. None of the changes affected by C zero make their way up to Z one. The other way to do this is to go backwards from Z one and to look at the gates that affect it. So the gate, the OR gate that produces Z one is only affected by the top three AND gates. And those top three AND gates are fed by A, C one, B, and I think that's it. So those three variables are the ones that affect it. In fact, most tools would define what's called a cone of logic. So they'd start at the output and they'd go backwards and they'd figure out what variables affect that output. And that backwards cone is called a cone of logic. You don't need to know that. Okay. All right, let's roll forward. All right, so we need to use those delays we found for one bit slice to calculate the times for these intermediate C values between the slices. So remember that all the A and B bits are available at time zero. So what matters most in that input to output analysis is going to be C getting to Z. All of the A's and B's are available at time zero, even if it's bit number N minus one, those come in at time zero. So the thing that's going to be slowest, and we care about the slowest thing, is C to Z. So we found, just to remind you, we just looked at it, but C one to Z one was two gate delays, C zero to Z zero, two gate delays. So when is this first set available? So this is bit slice zero. Now these are available at negative infinity. So that's probably not the thing we care about for this first bit slice. So when will these be available? I'm sorry, these are not input values, these are timings now. So these are available at zero gate delays, at time zero. Yeah, so that's the question, is how long does it take for this comparator bit slice logic to process A and B starting at time zero, and these arbitrarily far back in time? Two, right? So if you remember, the A input going to C one, and also A to C zero, B to C one, B to C zero, those are all two. And so both of these outputs will be available after two gate delays. So I'm going to draw an arrow saying, well, the information is flowing from here, that's one of the longest paths, and that'll take two gate delays. Two gate delays for each of those. But what about the next one? What about these variables on the left coming out of bit slice one? When do those become available? Four, why? Yeah. So even though A and B are available at time zero, so if we think about the paths from A and B over to here, that only takes two gate delays, that would make these available at two. But from here, these answers are not here until time two. So these answers are two plus two is four. Good. Okay, so let's generalize that. So the C upper script zeros out of bit slice zero are available at time two, which means two gate delays. The C ones are available at time four. So what do you think about C n minus one? Two n, good. Okay, so our whole system takes two n gate delays. If you build a 32 bit comparator, it'll take 64 gate delays. Can we do better? Probably. But you should ask that. So we have two metrics, right? So can we do better in area? Can we do better in delay? And maybe we can do better in both. Can we reduce delay? Maybe. Actually, without not using a bit, we can go to bigger bit slices, right? Do two bits at a time from A and B or more. That could make things faster. But if we keep a bit slice design, it's actually pretty hard. Bit slice with one bit is actually what I mean. Why is that? Because if you want to reduce from two gate delays to something less than two, how do you implement a function with fewer than two? You've got to implement the function with one gate. So unless you get really lucky and your representation lets you implement both of your functions with one gate, then you're not going to have one gate delay per bit slice. You're going to have two, two level logic. So it's actually pretty hard to beat two. Again, if you do two bits at a time, you might be able to do that with two level logic. And that really means you're going to get down to n, right? Because you've only got half as many bit slices as you do bits. So you can do two for each, and then you've got overall n gate delays. But using the bit sliced approach, dealing with one bit at a time, which is much simpler, it's difficult to beat the delay. ARIA, on the other hand, that I'll go with your maybe answer. So let's do some algebra. That looks fun. I know you all love it. So here's what I want you to do. Here are our equations from before. So all I did is copy these. I'm sorry, copy this one. So first, I want to pull out C1 using distributivity. So I've got the AC1, B prime C1. So instead, I'm going to write A or B prime times C1. So that's our first step. And then I want to say, well, you know this A plus B prime factor, I could use a NAND gate for that. In particular, I could write A prime B complement it. So all I've done is I've applied De Morgan's law. So I said, I want to complement this thing. So complement the A, get A prime. Complement the B prime, get B. And then complement that AND. So now I have Z1 is AB prime plus A prime B quantity primed ANDed with C1. And then I gave you the same equation, same manipulations for Z0 right down here. So why did I do that? So here, you see AB prime. Here, you see AB prime. If I calculate AB prime with a gate, I can now reuse that gate's output in two different equations. Similarly, here I have A prime B. Here I have A prime B. If I calculate that expression with a gate, I can then use that gate's output in two different places. So I can reuse my gates to calculate these two output variables by manipulating the algebra a little bit. So maybe I can reduce the number of gates I need. So someone had a question? Yeah, De Morgan, generalized De Morgan's and applying duality and then swapping all the complements are the same thing. This is just one application of De Morgan's laws. This is just applying it once. So you don't need the full power of duality. Any questions? All right. Here's what that looks like, except I made it into NANDs. So I turned it all into NANDs. Why did I do that? Because if you use AND or OR, you actually get extra inverters that are not really there. And so I didn't want you to count the wrong sort of diagram that had gates that didn't exist in the real implementation. So this is how you would implement those equations using NAND and NOR, which is what we have to do in CMOS. Now probably you look at this and you say, I don't know that this represents those equations. I certainly do. In fact, every time I come back to it, I confuse myself before I get it. So I wrote it up for you. So first of all, I wanted to point out, though, here's your single bit core again. So those two factors we pulled out, those are actually the two min terms we produced for a single bit. So all we need to do is produce those two answers. Is A bigger than B or is B bigger than A from that one bit? If so, that's going to basically drive all of our answers, just like in our last solution. I did a funny thing, which I clipped it before the inverter on the NAND gate. So the single bit core had AND gates in it. These are NAND gates. So we're actually inverting our terms before we use them in the rest of the circuit. That's not a big deal. So here, let me try to convince you. So this thing down here now forms A prime B. So A comes through this inverter, goes in there. B is here. So A prime B. And then it's a NAND gate, so A prime B inverted. We're going to take that and put that in this NAND gate up here. That's also going to have C1 coming in. So out of that NAND gate, we're going to have A prime B prime ANDed with C1 and then primed again. Happy? This one on the middle left, this is producing A with B prime. And it's a NAND gate, so we'll complement it after that comes out, after it's ANDed. We're going to feed that one into this NAND gate along with this expression. So what we'll get is this thing ANDed with that thing and then complemented yet again, which looks like that. So there's our AB prime primed there, ANDed with this thing there, and then the whole thing complemented. So I'll apply DeMorgan's one time. So I'll take this prime here, and I'll change this AND into an OR. And then I'll complement this one, which will just take that prime away, and complement this one, which will take that prime away. I'll get that. But that's what we wanted to implement, right? So fortunately, this diagram is symmetric, so I don't have to show you that nasty algebra again. So you should convince yourself that you think this is right, because obviously, if you get the circuit wrong, it doesn't really work. It's just some random circuit. All right, so let's analyze this new design. So you can already see, geez, got a lot of gates there, a lot of maybe delays worse. On the other hand, it has fewer gates than the other one, so maybe area is better. So let's think about it. So how many literals? So here, I want to be careful. Literals, again, anywhere where one of these or its complement goes directly into a gate, I want to count as a literal. So how many literals do I have? Six. Good. There they are. So this NAND gate has one literal coming in. This one has one literal, and these have two each. So six literals total. How many operators? Also six, all NAND gates. Good. So my area is 12. Area is 12, right? Six plus six is 12. So smaller area. Last time was 20. Smaller area. How about delay? A to Z1? Two? Is it really? You sure? How about that path? Three, ignoring the knot. What about C1 to Z1? Two. Yeah, let me make a comment here. So be sure on A, be sure that you're looking at the longest path. What matters is the slowest path. So there are paths that are only two. If I go this way, it's only two. But what matters is going to be the longest one. So I'm drawing you examples, but the examples are always one of the longest paths. I'm not just picking a path randomly and measuring it. So two for C1. Good. And what about B? Is it three? Did I mess it up? I think it's two. Oh, three. Sorry. Yeah, it's three. I messed up my memory. All right. So three also. There's no inverter on that path. The reason I keep pointing out the inverter is if you go and read the notes, the notes count the inverters. So they're going to be off by one relative to the slides in class. All right. So you might think, well, gee, is that 50% true? Three instead of two? Well, let's go here again. So actually, let me go here and make sure. So A to Z1 is three. B to Z1 is three. C1 to Z1, only two. Okay. And it's symmetric. So the Cs to Zs are two. The As and Bs to the Cs are three. So what about this first set of outputs? When does this come available? So same path from zero, add three, we get three. What about this set? As and Bs are done here at zero. So you add zero to three, you get three. So certainly no earlier than three. These are available at three. The delay is not three to get to here. The delay is two. Three plus two is five. So you take the bigger of three and five, you get five. These are there at five. Same slide with numbers change slightly. Three, five. So when will these become available? Two and plus one. So all we did for the overall design, even though the A to B paths, I'm sorry, the A and B to Z paths got 50% longer, the C to Z paths stay the same. And those are the ones that add up as we go through bit slice to bit slice. Those are the ones that add up to this two number here is the C to Z paths. The extra one, three minus two, is here. So if we did a different design where A to Zs became 10, this would just become plus eight. As long as the C to Z paths are fast. So the full calculation is for every input that matters, you add the delay. So A to C1 is plus three. So zero plus three is three. Zero plus three is three. And three plus two is five. And then you take the biggest. So three, three, and five, the biggest is five. We're actually at the end of the hour. So I don't want to keep people over time. We'll look at this briefly again and then finish up the discussion on Wednesday. But we can talk more offline if you want to be satisfied today. Thanks. Transcribed by https://otter.ai Edited by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai\"},\n",
       " {'ECE120-2016-10-07-LEC-19-slides.mp4': \" So we will include, I wanted to go over, there's a homework 7 has a problem on it where you need to have some notation. I wasn't going to introduce, actually the notation on the homework is wrong too, but it'll tell you the right stuff and how to do it. So, and then use the wrong notation that they use in the question. Then we'll talk about serialization. So this will move into part 3 of the class. So midterm 2 material ends up here and then we'll look at serialization and do a couple of examples. We may finish these, they may go into next Monday. There's a feedback survey online. I know a lot of people have taken it. I haven't announced it yet, so I don't know what fraction of you have taken it, but it's open until Monday night at midnight, so please do take it. Basically just feedback on various resources in the class and what you find useful and what you think could be improved and things like that. And I'll read all your long answers. Short number stuff we'll just summarize, but I'll tell you what we find from that survey once we've done the stats on it and stuff. All right, so here's the midterm reminder. So Tuesday, 18 October, the conflict exam. If you need a conflict, please let us know through the wiki by Monday. And otherwise, it's the same. Coverage is up through, is basically part 2 of the notes, plus since we didn't do reading, writing, truth tables from part 1 of the class, that's on part 2. So that's the topic coverage. We'll do a review session just like we did last time, so not the Monday next after this weekend, but the one after it, the 17th of October. We'll have a review session in the same style, so come prepared with questions. So I wanted to spend a little time going into more detail. So what we did on Monday was we built what are called sequential feedback circuits, where the output of some gate goes back directly to the input. So instead of having pure combinational logic, you have a feedback loop, and this one in particular is a gated D-latch. It's one of the ones we did, and we just look for stable states, right? So I think that's pretty much all you need to know, but there's some notation that helps you do a little more. So let me walk you through that and kind of show you how it works. And you'll need to do this approach on homework 7, problem 1. So I want to start by just imagining the feedback loop here. There's actually only one we need to cut, so it looks kind of like two, but if you cut this one, then rename this output from Q to Q+. It's usually Q star, but in the homework problem it's Q+, so leave it there. And then Q is still an input, and at that point what you have is combinational logic, right? So you have inputs over here, D and right enable, the data input and the right enable input, and then you have Q as an input, and everything else is combinational logic to produce Q+. P is actually just an intermediate value of your combinational logic. So that is now combinational logic after cutting one loop, so combinational logic circuit. So after I actually erase it, maybe it'll be a little easier to see. I mean, imagine that bottom right NAND gate is shifted to the left. Now it's just a combinational logic circuit to produce Q+. So let's write a truth table for that. So we've got D, right enable, and Q coming in. We've got Q+, and P coming out, and we've got a bunch of NAND gates that are kind of a pain to analyze. So let's start from P, the intermediate point, and calculate this one. So P is NAND of Q and R bar, so that's Q, R bar, handed together and then inverted for the NAND gate. So if we then apply De Morgan's Law, we have Q prime plus R bar inverted again, and then R bar is coming out of this NAND gate, so we can just invert the inversion again, and write that as D prime, this input up here, handed with right enable. So P is Q prime plus D prime times right enable. The reason I wrote it that way is so that we can then fill in the truth table easily, and you can see there are two colors. So the Q prime, all the zeros in Q imply ones in P. So first we can write those in, and then anywhere we still have a D prime and right enable. So let's see, D prime is up here, right enable is down here. So these two lines here, the third and fourth lines, will be ones also. This one's already a one, but the D prime right enable also makes this P output a one. So everything that's not a one is then a zero. So just read off the equation, it's SOP form, so we'll just fill it in one term at a time with ones, and then fill in the rest with zeros when we're done. So now we have P, then we can go back and fill in Q plus. So Q plus is S bar handed with P, and then inverted, just like that. And we apply De Morgan's, we get S bar complemented again, or with P prime, and then if we have this complemented, that just cancels that inverter there, so we have D handed with right enable, or with P prime, is Q plus. So first term there, D and right enable is down here, that gives us these two ones. The P prime, where is it? So this zero, this zero, and this zero, but this zero is already covered, so we get two more ones from the other zeros of P, and then the rest is zero. All I'm doing is filling in the truth table, it's just this circuit's a little bit nasty, so I wanted to walk you through the process once of analyzing it. All right, so now we have this truth table that gives us Q plus and P in terms of D, right enable, and Q. Sometimes we call this kind of thing a next state table, because it tells you what's going to happen within a gate delay or two for the sequential feedback circuit. So let's take a look at this. Now what we did is we analyzed stable states, right? So we actually just went through the feedback loop until it's stabilized. You can do that pretty easily with this table by simply comparing Q with Q plus. If they're the same, that's a stable state. The system won't change anymore. So if you go look for those states, you get these six. So 0, 0, 1, 1, 0, 0, these are different, so it's not a stable state. 0, 0, 1, 1, 0, 1, not a stable state, 1, 1. So you got six stable states. And then we could use those stable states to come up with the truth table that we wrote down on Monday for the gated D latch. So if you take these, you get this truth table where I've condensed two groups of two into a single row of the truth table by saying, well, I don't care what D is. This line here, for example, could be D of 0, which is up here, 0, 0, 0, 1, or down here, 1, 0, 0, 1. So Q plus has gone away in this table. So these are just the stable states, the summary of stable states of the system. And that's what we had on Monday. With this bigger table, you can also then make a more compact truth table. So, for example, if you look at the rows where right enable is 1, so these two and these two, you might notice, then, well, what is Q plus, or compact next state table, I should have said. So Q plus is 0, 0, just like D. Down here, Q plus is 1, 1, also just like D. So in this case, Q plus is just D. So whenever right enable is 1, Q plus is D. So what about right enable equals 0? What's Q plus? Just Q? Let's see. These are the purple ones, so 0, Q is here, and Q plus is the same. And Q is here, and Q plus is the same. So yeah, that's right. So Q plus equals Q. So we could write this short table here where we say, well, the only dependence is actually right enable. And then we write Q plus in terms of the other input variables. So you saw something like that on Monday also, but we could write it this way, having derived it from our next state table here. So this is another next state table because we're again writing Q plus in terms of inputs. Now, you might have noticed, if you look carefully, that in these unstable states, not this one, but this one, we don't always have that P is Q prime. They're not always complements of each other. And of course, they should be for this particular design. The reason is that these unstable states actually are just transient. So once you go into these unstable states, by changing the input, actually you then move into another state. In some systems, they may oscillate forever. So we might give you something where some of these systems, they just go from one state to another and they go on forever. But in some cases, they might actually stabilize by moving from an unstable state, these uncolored ones here, into a stable state. So let's take a look at what happens with these two. So for this first one, we start at 0, 1, 1 for Q, but we're going to go to 0, 1, 0. And 0, 1, 0 is just above it right here. So we can draw that that way. So if we start in this state where Q was initially a 1, then by setting D and right-navel to 0 and 1, we'll force Q to 0. Once Q goes to 0, it's stable. And similarly down here, if we start with this input combination where Q plus is then going to change to a 1, that will move to the 1, 1, 1 state after Q is changed and will then be in this stable state. And you'll notice in those states, P is always Q complement. So in the gated D-latch, the two outputs are always Q and Q bar. You could imagine a system where that wasn't true. And if you look at this next state table with all of the logic, it might be a little confusing, so I wanted to explain that also. It's only the stable states that matter in terms of what you'll see coming out of the first one. Eric? Yes. Yeah, so they could oscillate between multiple states. I mean, if it goes to the same state, that's a stable state. So if it goes to another state and then that second state comes back to the first state, that would be oscillation. I'm not sure I understand the questions. Toggle between Q and D. So this is the same circuit we looked at before. This is a gated D-latch. So I can store a bit in it. I can build flip-flops out of it. It's the same circuit. I didn't change a circuit. I just changed how carefully I analyzed it. Yeah, so all we did on Monday was we simply looked for stable states. We didn't do all this detail. But when you have a different design, and in particular, the homework asks you for the next state table. So I didn't show you how to do that. Either one of these is fine. If you want to condense it like this, this is also a next state table. The idea is to map inputs, maybe some of the inputs, if that's possible, or all of the inputs into Q+. So the thing that tells you Q plus is a function of inputs is your next state table. Yeah, not really. Unfortunately, that's why the notation here should be Q star. Sequential feedback circuits are not clock synchronous. These are the latches and flip-flops that we're building clock synchronous designs from. So the plus notation usually means the discrete time. But in the homework, it uses Q plus to mean next state of a sequential feedback circuit. So you need to use the notation in the homework. Yeah, the only reason I showed you this was the homework. I mean, you need to know how to do this for the homework. You need to know how to find the stable states generally for the class. But analyzing sequential feedback circuits gets a lot more complicated, too, if you have more than one feedback loop, because then more than one bit can change, and actually either of them could change first if you think about all of the paths. Yeah. Yes, that's right. So if Q and Q plus are the same, that means it's stable. It's not going to move. You could certainly create such a circuit, not in this circuit. Yeah, that's a good question. So P, remember, in the way we broke this up, P is an intermediate variable, and Q is actually the feedback loop. There's only one feedback loop. So if the value of the feedback loop doesn't change, no input to the circuit changes. P was just an intermediate value. Yeah, so again, if you go, let me go back to the drawing. So there's actually only one loop in the circuit. So once we break that loop, if Q plus gives us the same original value that we assumed as an input, there's no change to any of the inputs. And so since there's no change to the inputs, there's no change to the outputs, and that means it's stable. Yeah, that's why. And P is just a side effect. P is just one of the variables you calculate in the middle of that combinational logic. And that has to do with the fact that if you look for cycles in the original design, there's one. And if you break that, there are none. In some designs, you could have more than one. And if you have more than one, you've got multiple bits to look at that might change. And if any of them change, you have to look at actually all possible paths, because any of them could change first. That's why we don't go very deeply into this. Most people, honestly, are not going to use this in their careers, I mean, not use sequential feedback circuit analysis. Unless you're designing the standard gate libraries or working in a company that does custom logic, you're very unlikely to design this kind of stuff. We just want to make sure you understand the ones that you will use every day, which are latches and flip-flops. Okay, so hopefully that won't pose a problem on the home page. Okay, so let's talk then about serialization of bit-slice designs. So if you think back to our bit-slice, we could generalize it a little bit with an abstract model. So bit-slice, it computes something based on p-input bits. So we had a bunch of different examples. We had a ripple-carry adder, where each of the bit-slices took one bit from A and B. So it might be p equals 2, or a comparator was the same thing, or if the one you did in the homework was an even-odd checker, you took one bit. So some number of bits from an operand or multiple operands, and produces some number of outputs. Each of the bit-slices might produce one output, might produce two, might produce zero. So there's some number of output bits per bit-slice. And then there are n bits passed from bit-slice to bit-slice. So in the ripple-carry adder, it's just one bit, the carry information. In the comparator, it was two bits. In the power-of-two checker we did, it was two bits. In the even-odd, I think, in the one you did in your homework, it was one bit. So you can generalize and just give those names. And then to handle n bits, we previously said, okay, let's just take n copies. Or if we had a – in the power-of-two checker we did in class, we took two bits for each of the bit-slices. So then n over 2. But now we know how to store bits. So instead, we can go back to – I think Sasha asked this question a week or two ago. Well, couldn't we store some bits in flip-flops and then use the same piece of physical hardware to compute the next slice? So we're going to go to the other extreme. So in this case, we're going to have one copy of the bit-slice. So this is a serial design. We'll copy the bit-slice, and we'll use flip-flops to store those n bits coming out. And then we'll just feed them right back into the bit-slice and use the next bit. And we'll keep doing that for n cycles, and that will give us the answer for an n-bit operand, or a set of n-bit operands. We'll call that a serial design. So it's not quite that simple because, well, what about the first bit-slice? So if all I do is I wire my flip-flops back up to the inputs, well, what's in the flip-flops when I turn the machine on? Bits? Probably bits. And actually, I know I told you it could be metastable, right? So it might not even be bits in this case. But let's just say bits. So there are bits, and that's not what we want, right? So when we designed our bit-slice designs, we said, well, we're going to put some fixed representation. So the adder, we usually feed a carry-in zero. So we want to use a subtractor, then we'll feed carry-in one. But we know there's some bits, particular bits, not just random bits, that we want to feed into the first bit-slice. And also, what about the last bit-slice? So in the Power of 2 checker, the bit-slice didn't actually produce the answer. It produced three different messages. And we had to use extra logic. It's simple, just an XOR gate. But we needed extra logic to calculate the answer. So we might need output logic. So here's a picture putting it all together. So there's our bit-slice. Here's the M flip-flops. We'll also latch the output bits. So every time, say, this is an adder, it computes one bit output, we'll put in a flip-flop. So some other logic can look at it in the flip-flop. And we'll bring these back over here, but we'll run it through some selection logic that allows us to say, well, this is the first bit, so we'll take our initial values and feed that into the bit-slice. Or we'll take the flip-flop values and feed those into the bit-slice. Once we're all done, the last bits out of the bit-slice, we can put through some output logic and compute the answer. So this is the general model of a serial design. So, okay, I guess I walked through it. So this output logic, then, is the same as the bit-slice design. So we already designed that for the bit-slice design. We just take it from the side of the bit-slice design, we just copy it into this design. Not very hard. F equals 1 means first bit. So usually these things will be 0s and 1s. Usually we don't need to allow them to be real inputs, they're just 0s and 1s. What do we need here for selection? Yeah. So, I mean, we need to choose between the initial values and the flip-flop values, right? So what components should we put there? Yeah, we could put muxes there. Muxes would do just fine. I'm actually going to optimize it a little more than that, but muxes would be a great answer. They would do just fine. So we could do muxes. We can optimize because it will be 0s and 1s. So let's optimize a little bit. The m flip-flops are going to store their bits into the selection logic, or feedback into the selection logic. So let me call those b sub i, and let's call the m bits produced for the first bit slice c sub i. So then we can say, let's assume a 0 in place of b i for the first bit. So let's say we have some b i, and we want to put a 0 in for the first bit. So when f equals 1, we want a 0, and then we can write a truth table. So when f equals 1, we get a 0. When f equals 0, we want to feed in the b sub i from the flip-flop. Yeah. Yeah, so b sub i is the bit coming back from the flip-flop. So between bit slices, we'll be feeding the flip-flop bit b sub i, and that's when it's not the first bit. So this truth table says, well, when it's not the first bit, take the flip-flop bit. When it is the first bit, let's say there's a constant 0. Yeah. So if we write this out, we can say, OK, well, the only non-zero term here is the f equals 0, so f prime times b sub i, and I could write that as a NOR gate, and then we just have one NOR gate. So pretty easy logic. Again, if you just put down a MUX, that's fine, but you can optimize your MUX away for one gate in this case. Similarly, if we say, well, when the first bit comes in, what if we assume a 1 bit instead? We can write that same truth table. So now for 1, we get 1. For 0, we still get b sub i. Now we'll actually use a POS form, so the only place we get a 0 is the f equals 0. So this is POS form for that, and of course, that comes out to be a NAND gate. So we still need that extra inverter, but one inverter and one gate. So we can optimize our MUXes down a little bit. So let me then walk you through an example. So we have this general model, and we have four parameters. We've got, I guess, five parameters, n bit operands, p bits of input from operands, q bits of output produced, m bits between slices, and at the end, we've got r bits of final output that are not on this diagram but produced by the output logic. So I wanted to see what the real size would be as opposed to abstract size. Yeah, it would be the same, right? A register is built out of flip-flops. It would be fine. I use an m bit register that's m flip-flops. Okay, so I mean, the other thing about the register is in this design, in the serial design, we want it to load every cycle. So having that extra load capability is a little bit of overkill. We don't need it. All right, so here's the parameters for the comparator. So this is just bringing up the old diagram of the comparator bit slice. So we had two bits coming in. So p equals 2. We have zero bits going out, so q equals 0. We've got n bits between bit slices. So m equals 2. Sorry, this is overloaded m. This was bit slice number m. But the number of bits between bit slices is 2. And then the number of bits for the final output was also 2. We needed to know, well, is a greater than, equal, or less than b. So we needed two bits of final output, too, so r equals 2. So this was then the representation we picked for those bits passed between bit slices. So which value should I be passing into the least significant bit for the comparator? Which assumption should I make going into the starting point, the first bit slice? 0, 0, right? We just assume a equals b when I haven't looked at any bits. So we'll pass in 0, 0. That'll be our initial values. So when we put this together, this is what we get. So I took just the general model. I plopped down the comparator bit slice here. We said m equals 2. So here are two flip-flops. We'll call them b1 and b0. The output logic was a no-op. Actually, I can walk through this. So input-output, there were two of them, a and b, right, one bit of each of the values being compared. No output flip-flops since q equals 0. So there's no extra flip-flops down under the bit slice. We had m equals 2. So those are those two flip-flops. z1 and z0 outputs are just latched into b1 and b0 flip-flops. This is initialized to 0 when f equals 1. Remember, that was a single NOR gate. So if f equals 1, both of these NOR gates output are 0, and we get c1, c0 equals 0, 0, just like you said we should. If the f equals 0, then we get the b1 complemented output, and we take that into the c1 input, because it's complemented here, and then the NOR gate complements it again. And then down here, we get b0 inverted coming out, going through the NOR gate gets inverted again, so b0 goes into c0. And then the last thing, this output logic does nothing. It's just empty box, because we didn't need to do anything extra in the case of the comparator. So that's our comparator design. So then let's think about, well, how does this compare? Actually, let's walk through and make sure we understand how it works. So what I've done here is just written down discrete time, right? So cycle count. So in cycle 0, these are inputs, f, a, and b. These are the bits of our numbers. Remember, we start with the least significant bit. So these are the least significant bits of a and b. And what's going to happen then is those will produce, let's go back and look at the diagram for a second. So we'll put f, a, and b, and then from those, we need to be able to calculate c1 and c0. And then we've also got b1 and b0 coming back into these gates over here. So maybe we need to know what those are first. And then we'll produce z1 and z0, which will go into b1 and b0 in the next cycle. So what's in b1 and b0 in cycle 0? Why should there be 0? Bits. Good answer. There are bits. We don't know what's in there. There's just some bits. We just started using this thing. There's going to be 0s or 1s in our flip-flops, but we don't know what they are. We don't know whether it's 0 or 1. We can, but you don't want to assume that this thing has never been used before. It should continue to work no matter how many times we use it. So whatever's left in there, you'll see at the end, we don't leave 0s in there. That's a good question. So that's my next question. What are c1 and c0? So your claim is they're both 0? So we can look back. So f equals 1, and we don't know what b1 and b0 are. So if f equals 1, what is c1? Can we know? So f is 1, and so what's c1? 0, right? So yes, in that case, it's not f. Not true if it's f equals 0, though. All right, so f equals 1 forces c1 to be 0 and c0 also to be 0. They're both NOR gates. So we don't need to know what was in b1 and b0. If we set f equal to 1, we're guaranteed c1 and c0 are both 0. So we don't care what was in those flip-flops the first cycle. And we shouldn't have to care. Otherwise, we would need to take another cycle to force them to 0. And that would take an extra cycle to do the computation. All right, so now we have all of our inputs to our bit slice. So now we do what the comparator does to calculate z1 and z0. So which one of these is bigger, a or b? b. OK, so you may or may not remember. The representation for that is z1 equals 0, z0 is 1. That says a less than b. That was our representation. Those two then get latched into b1, b0 in the next cycle. So only in cycle 1 do these values appear in the flip-flops. So that'll be important when we get down to the end. Because only after four cycles in the fourth cycle, starting counting from 0, will we be able to see our answer. So the answer is delayed until all of those four cycles have completely passed. It's discrete time, means a little bit of delay before you get your answer. Yeah. That's right. That's right. Yeah, OK, so we've done that copying. So now we need to decide, well, what inputs do we want to put into the comparator in cycle number 1, which is the second cycle? So as Rahul just said, f should now be 0 for the rest of our computation. There's only one first bit. We can do as many bits as we want. The way we do it, we put f equals 1 one cycle, and f equals 0 for as many as we want. You can do a 1,000-bit comparison with this thing if you'd like. We're only going to do four in class. All right, so here's some numbers. So f equals 0. Let's say the next two bits are 1 and 1. So what, in this case, will c1 and c0 be? 0, 1, right? Because since f is 0, basically b1 and b0 just get copied to c1 and c0. That's how the NOR gates work, the selection model. And so let's see. So this one says a less than b. a and b are equal here. So what should the answer be? I think 0, 1, right? So a is less than b. And then you've got bigger bits that are equal. So a is still less than b. OK. Yeah, this is a little tricky, because it implies actually doing the representation mapping twice in your head. So if you don't remember the representation, don't worry too much. We'd normally give it to you on a piece of paper. OK. So those then, 0, 1, get latched again into b1 and b0 flip-flops. OK. They're already there, but now they're copied again from the z1, z0 outputs into b1 and b0 in cycle 2. So here's cycle 2 inputs. Now we've got 1 for a, 0 for b. c1 and c0 are what? 0, 1, right? Those are just the same as b1, b0 when f is 0. OK. So in this case, remember the smaller bits come in first with our comparator design. So now the biggest bits, a is 1, b is 0. So which is bigger? a is bigger now. So 1, 0 means a is bigger than b. OK. Those get copied down. Yeah. Yeah, that's right. That's right. Yeah. Yeah. So the question is, will we ever be able to get z1, z0 both 0 again? And no, of course, once they're not equal, they can never be equal again. And so once you've got 0, 1, or 1, 0, you will continue to have 0, 1, or 1, 0 until you build up to 0, 1, or 1, 0. And that's the question. So what's the question? What's the answer? So the answer is, yes, you can. 0, 1, or 1, 0, you will continue to have 0, 1, or 1, 0 until you're done with your computation and start the next one, only when they match in all the bits. OK. So we'll copy those down for cycle 3. Put our inputs. In this case, I wanted to make it flip again. So now b is bigger. All right. So these get copied again because f is still 0. So b1, b0 go straight to c1, c0. And then what should z1, z0 be? 1 again. Good. Those two bits now get copied for cycle 4 into the flip-flops. Those are now our answer. So if you have a 4-bit, two 4-bit numbers you're comparing, after four cycles, you'll be able to see your answer on the outputs of the flip-flop. But you have to wait four full cycles because these flip-flops don't latch these values until the fourth cycle starts. Remember, they latch on the rising edge. That's why we can just write cycle 0, 1, 2, 3, 4. Yes. You mean to reduce it? You have to compare. Yeah. So in a serial design, we could do what we do as humans if we were going the other way. Right. If we were going the other direction, starting from the most significant bit, then in the cycle that we saw a difference, we could stop comparing. Yeah, so that's a good point. So in a bit-sliced design, we couldn't do that. And so the direction didn't make a difference. Yeah, but in this design, we can. As soon as we see a, we could put an OR gate on these two. And as soon as we see the OR gate produce non-zero, that means we know there's a difference. We know what the difference is. We can stop and see which direction this is. Yeah, that is one advantage of doing this serially. You could stop early, which I didn't actually point out in the slide. Good question. OK. Yeah, so remember that the flip-flops take the value on their D input at the rising edge of the clock and then store that new bit. Right. And so even though these outputs might be ready in the middle of one of these cycles, they only appear on the outputs of the flip-flop at the start of the next cycle after the rising clock edge. So that's why we have discrete time. You can assume that the outputs of the flip-flops hold that value for one complete clock cycle and that they don't change. But that implies you have to wait for the fourth clock cycle if you're doing 4-bit operands. And similarly, if you're doing 100-bit operands, you have to wait for the 100th clock cycle after the start of the next cycle. Absolutely. We'll go through in detail. So the question is, is this slower than the bit-sliced comparator I think you meant, right? And yes, it will be much slower. Yeah, it's a good question. It will be smaller but slower. Yeah, so you might be able to shortcut it in some cases. So the analysis is going to be a little harder. It'll depend on what data you put in. Right. Yeah, in this case, it's definitely slower. It depends what you want, right? Yeah, so it is a trade-off. And as always, when you have more than one metric, it depends on the context. If you're trying to put many, many of these on a chip, then you probably need them to be small. If, on the other hand, you want speed, you probably don't care as much about area. And so you probably try to use the faster design. And the context will tell you which one is a better choice for you. All right, so let me fill in some of these. So we don't know what comes in in the fourth cycle. We assume we're done with our computation. So let's say, well, I don't care about those. I put a 0 here because actually the b equals 0, b1 equals 0 implies that c1 equals 0, regardless of f. But these are actually unknown bits. So we don't know what's there. We could, in fact, start in cycle 4 a new comparison. So we can do back-to-back comparisons without having any extra time in between. We could put f equals 1 in initially and put a and b values for a next comparison. So we can use the comparator without an extra spare cycle in the middle. But from the point of view of our computation up here, we don't care what those values are. And we don't know what these values are. So put question marks around those. Well, they will if you put f equals 1. f equals 1, just like up here, f equals 1 forces those two to be 0. We didn't care what the bits were. Here, they're not 0. Here, they might not have been 0. f equals 1 forces c1 and c0 to be 0. That's why we're allowed to start a new comparison. All right, so let's take a look then at area first. And then we'll do delay. So what do we have? We've got one bit slice. We have two flip-flops. And then we have two NOR gates for the selection logic. So here's our bit slice design. We had two input NAND gates and two inverters. So six two-input NAND and two inverters for the bit slice. What about the flip-flops? So here's a flip-flop. We had two latches. And inside those latches, we had four two-input gates and an inverter. But actually, we can flip the sense of the inverter. If we instead use NOR gates instead of NAND gates in this latch, we don't need this inverter. So that one is actually, we can get rid of it. In fact, commercial designs will actually be smaller. So we'll assume the design we looked at. But if you really went and looked out at what people use in standard gate libraries, they're not as big as the design we did in class. You can do this kind of thing at the transistor level with fewer transistors. So here it would, because we've got a common clock. And so we would need to actually have the inverse clock to make sure the two were different. We wouldn't normally ship around both the clock and the inverse clock. If they're coming out of flip-flops. Yeah. Yeah. So now that we've seen where things come from, why they're free, we might start counting when we know they're not going to be free, when we'll need it. But in this case, we can absorb the inverter into the latch by using NOR gates and latch. Yeah. Oh, that's fine. Yeah. It would cause skew, and it would also just cost area. So the real counting, you want to just count anything that you would physically need to use. And so here, you don't need it because you can change the design of the latch to be an SR latch with NOR gates. Yeah. Well, I mean, it goes away, so it doesn't. Yeah. But that would be another issue if we're really adding logic. It would potentially introduce skew. Yeah. OK. So yeah, it's a good set of questions. I mean, real flip-flop design, people actually do add timing sometimes to give the illusion that you don't have to do it. They add timing sometimes to give the illusion that you don't have to wait for the signal to be latched. So we're going to assume that it takes four gate delays of stability before we can copy when we do the delay analysis. I'll explain that when we get there. But people usually shift that by adding delay inside the flip-flop. All right, so here's our count. So six two-input NAND, two inverters, 16 two-input gates, and four inverters. And so if we add that up, we've got 24 two-input gates and six inverters. So that's our serial design. So here it is down here, independent of N. It doesn't matter how many bits we're going to use. We've got the same number of gates there. Whereas if we do a bit-slice design, every bit-slice had six two-input gates and two inverters. So those are multiplied by the number of bit-slices. So those are about equal when N equals 4. And for N bigger than 4, the serial design is still there. For N smaller than 4, the serial design is small. So for any reasonable N, if you wanted to compare 16- or 32-bit numbers or 64-bit numbers, the serial design will be substantially smaller. But the serial design is also going to be a lot slower. So why? We just saw it's fewer, right? More gate delays. Yeah, you're also going to wait for the clock cycle, right? So this may not be the thing that determines the clock cycle, right? It might be some other logic. So this might be very fast compared to the clock cycle. But that doesn't matter. You still have to wait for N clock cycles. So let me put all the reasons. So one reason is all of the paths matter. So when we talked about the bit-slices, we said, well, only the slice-to-slice paths matter because all of the A and B bits come at time 0. That's no longer true. Those A and B bits are fed in one per cycle. They probably come out of flip-flops. So they're not coming at time negative infinity or time 0. They're coming at the start of the cycle. So the paths from A and B out to the Z1, Z0 outputs, now those matter more. That's one issue. Second issue, selection logic and flip-flops, those are not free either. There are gate delays inside those. And those count too. And we have to pay for those. And then the last one is, again, this may not be the slowest component in the system. The clock can't go faster than your longest combinational logic. So if this one happens to be the longest one, well, that's fine. Then only factors 1 and 2 will matter. If there's something else that's slower, your clock will run even more slowly. And as a result, your serial comparator will have to be slower because it has to go clock cycle by clock cycle. So let's look at each of these in a little more detail. So I guess I kind of said all of this. The paths, other than the slice-to-slice paths in our bit-slice design, only added constant time because all the A and B bits arrived at time 0. And so we looked at that in the first bit slice. And then even by the second bit slice in this design, they were not relevant anymore. Whereas the slice-to-slice paths, every time we went Z1, Z0 to C1, C0, we had to pay that for each bit slice. So that was the thing we multiplied by n. Now in the serial design, again, A and B are coming at the start of the cycle. So we have to make sure we pay for them to get all the way to the flip-flops. We have to wait for them to get to the flip-flops. The flip-flops and the selection logic take time to store values and to produce values. There are gate delays on both latches. And the selection logic sits between the flip-flops and the bit slices. So the clock cycle has to be long enough to account for all of those. And then finally, the longest path, I said this a couple times now, longest path through combinational logic will determine your clock speed. There's just one clock. So whatever that longest path is is how fast you can drive your clock. In practice, what engineers are going to be doing is going and identifying the complex or important parts of the circuit. Often in a computer, it might be the adder, because you do a lot of arithmetic. But they're going to figure out what those are and try hard to make them fast or split them up into several cycles. So if you look at floating point units, for example, they'll be fully pipelined, meaning that you can put a new set of operands every cycle. And then they'll go through and take many cycles, say eight cycles or more, to compute the answer for one set of operands. So engineers will work hard making sure those things work well and making sure they're not limiting the clock cycle, although at the end of the day, they may still be the things that limit the clock cycle. So even if a serial logic design only needs a tenth of a clock cycle, it doesn't matter. You still have to use n clock cycles to compute n bit operands. You can't make the clock go faster for this. Well, you could have separate clock domains, but typically people don't want to pay for that. Yeah. People have tried that off and on for a long time and have asynchronous circuits, and it's fairly difficult to get them to scale in any useful way. People are starting now to do separate clock domains for different parts of the design, partly because they can then turn them off independently, more than that they can necessarily change the clock speed independently. Although in the multiprocessor chips, having your processors run at different speeds is also useful, because the slower clock speed will still get some work done, but will be low of power consumption. Yes. Yes. Good question. So let me come back to that in a future slide. The question is, can't you put more than one bit slice and do a serial-like design, or maybe put two, three, four, et cetera? And yes, of course you can. So that will, let me come back to that. These are two extrema. Good question. My feeling is it's more the complexity is unmanageable than that it's, I mean, I've seen it in the research literature at least two or three times in the last couple of decades, and never did industry take off with it and do anything really exciting. I mean, there are a handful of academics that get really excited about it and do some interesting stuff, but you've got to be able to manage the complexity to the point that engineers can use it in a big design process, which is difficult. OK. So all right. So let's go through and analyze this delay. So we can count gate delays or bit slice for the selection logic. So what about the flip-flop? So let's just assume that it takes four gate delays of stable D input before the rising edge. So let's say we need that D input to be stable for four gate delays before the rising edge comes in order to guarantee we get the right value latched, and then four delays after the rising edge before the output shows up. So we'll just pick the number four. You could pick different numbers and do the same analysis. So let me show you the picture. So this output here will become available four gate delays after the rising edge. So if we start at the beginning of a cycle, this B1 will not be available until four gate delays later. That's what I mean. And similarly, if the D input arrives at time N, then we have to hold that for four more gate delays until N plus 4 before the next rising edge. So those are the two folds. Are we able to measure gate delays much? In terms of clock cycles, usually gate delays are much shorter than clock cycles. Usually not, because gate delays are an abstraction. The process variations will give you huge swings on how long things really take. Yeah, I mean, the accurate time measurements, the first thing to do would actually be go down to the transistor circuit level and do SPICE simulations. But that's beyond our class two. All right, so let's assume rising edge arrives at t equals 0. So now we're using time and gate delays again. So we're going to calculate gate delays for the minimum number of gate delays for one clock cycle. So these things, the q's and q bars, become available t equals 4. So we said we'll wait four gate delays after the rising edge. So at t equals 4, we get these outputs, b1 and b0. Let's just also assume f, a, and b, those are going to come from somewhere. So let's assume they come from some other flip-flops. So they also become available at four gate delays. So all of these inputs at four gate delays. This thing here, well, you've got f coming in at 4. You've got these coming in at 4. One more gate delay for the NOR gate. So you get the c inputs to the bit slice at five gate delays. So then let's go back to our bit slice. So this is just a slide from when we were analyzing it. So a to z1, we had three gate delays, ignoring this NOT. Remember that the a input is going to come from a flip-flop. We already paid four gate delays for that. So let's assume we already have a prime. b, we've got three gate delays. And c to z1, we've got two gate delays. So when we add that up, these are available at time five, but the path to the z outputs is only two gate delays. So that's 5 plus 2 is 7. a and b are time four. The path to z1 and z0 are three gate delays. 4 plus 3 is also 7. So we get z1 and z0 at time seven, seven gate delays. And then we have to wait four more gate delays before the flip-flops will actually latch those. We assume we need four gate delays of stable input before they can latch the value. So that means we've got 11 gate delays. So if you think back to our analysis of the bit slice design, we needed 2n plus 1 gate delays for n-bit operands. For a serial design, we've got our clock cycle has to be at least 11. And then we need n clock cycles. So we have at least 11 n gate delays for the serial design. And that means we're at least 5.5 times slower. And we may be even slower if some other part of the system sets the clock speed. So this was Sasha's question. So let me go through this briefly, and then we'll end. So these are simple designs, meaning the complexity is low. We said, look, let's just focus on a bit slice. So we're in this space of pretty easy-to-do designs, but we're still at two extrema. One is small but slow. That's the serial design. The other is fast but large. That's the bit slice design. You can build anything in between. Put two bit slices per cycle. It's very easy to do. Just put two side by side. And then n is probably easier if it's even then. If you put three, it's easier if it's a multiple of three. Probably you're going to want 16, 32 bits anyway. So putting four 8-bit slices, that's not hard to do. You'll get a smaller than fully bit slice design. You'll get a bigger than fully serial design. And it'll be basically points in that trade-off space as you use more bit slices, it'll get bigger but faster. So we can also optimize more than one bit slice. We can take two bit slices and just think of it as one function and maybe even get it into two-level logic, and then that'll also be a faster and smaller design. So you can optimize in that sense too. Yes, that's why it'll be a bigger design than serial, but it'll be faster than serial also. And it'll still be smaller unless you add n, for whatever n you want, it'll still be smaller than bit size. Yeah, you can optimize that function. So instead of saying, well, how do I do one bit, you could say, how do I do five bits or 10 bits? And I can solve that as one problem. And that'll be a better design. Yes, to some extent, the tools will help with that. OK, so let's stop there. And if you want to ask more, we can just come down afterwards. Because it's over time. I want to keep everyone. OK. OK. OK. OK. OK. OK. OK.\"},\n",
       " {'ECE120-2016-08-26-LEC-03-slides.mp4': \" Okay, I think it's actually three o'clock now, so let's go ahead and start. So today, I want to review a little bit, I think maybe I kind of sped through the first derivation of two's complement, so I'll back up and start that again, and then also do, in addition to the graphical derivation, we'll do an algebraic derivation. So I'll explain why we're doing two when we get there. Then we're going to talk about overflow for two's complement. So you've seen unsigned addition, you know that a carry out means overflow, meaning that the answer we get is wrong. That's what we mean by overflow. We may get to Boolean logic and go through a little bit of that today, otherwise we'll continue that next week. I had a post-lecture thought on Wednesday, someone had suggested that in the range, I think it was 100 to 131, that we should say 42, and I just completely failed to realize that 42 is 100 base square root 42, so that was good. So these things, oh, I meant to take it out of my bag. They're not connected. Oh, shoot. No. Ah, technology. I have to follow the rules. Let me use this opportunity to take this from my bag and show you. Here we go. So you can buy this thing for $18 if you'd like. It'd be working now. Still not working, huh? Okay. Sorry, I may end up wandering back and forth. You can buy this thing now for $18 in the ECE supply center, which is, you know, walk over to that side, turn left, go down to the end of the hall. Remember this is free online, so if you're happy looking at it on a computer screen somewhere or on your mobile or something, if that's comfortable for you, you don't need to pay for it. If you do want a hard copy, you can get it for $18, or you can print it yourself, too. It's always hard to gauge whether you will save or spend more money if you use your print quota to print class notes, but you have your options. I want to try one more time. Yeah, there we go. Okay. So remember, we decided we were going to try to use the same piece of hardware. So we've got a piece of hardware. Someone's designed to add unsigned numbers, just like base 2 arithmetic, right, adding two base 2 numbers. But this piece of hardware adds two numbers, and what it produces is the correct answer, mod 2 to the n. So we saw that the sum that comes out, the bit pattern that comes out, will be the correct answer, mod 2 to the n, and we wanted to develop a representation for signed integers that also allows us to use that same piece of hardware, and then we'll be able to use that one piece of hardware to add both signed and unsigned numbers, and that will be the 2's complement representation. So you might wonder, well, what is 2's complement? Where does that come from? We'll get there. So here's a circle. What you see around the circle inside are bit patterns, and outside you see decimal values. So this is a way to represent the, or to show, to illustrate the 3-bit unsigned representation. So the bit patterns are inside, the numbers they represent are outside. And if I use this circle idea, then I can think about addition as simply starting somewhere, and if I want to add, I'll count around clockwise. If I want to subtract, I'll count around counterclockwise. So for example, if I start at 4 and I add 3, I'll count around 3 spaces around the circle, and I'll get 7. So that's addition using this circle abstraction. And the answer is always correct, mod 8. So if we had started at 7 and added 4, we would go around 1, 2, 3, 4 spaces, and we'd get 3, which is not correct, but it's correct, mod 8, because 3 equals 11, mod 8. So if we want to subtract, we'd go the other way. And I said, well, OK, the circle, because arithmetic with unsigned addition is simply arithmetic mod 8, or 3-bit unsigned, rather, we can also use this as a way to illustrate modulus. So we'd go around the circle, we'd write down the numbers, just like we did, but we could keep going. So we could keep writing 8, 9, 10, 11. And if we did that, what you'd see is that each of these groups around the outside of the circle are just a bunch of numbers that are all equal mod 8. So you pick one, 2 and 10, 2 equals 10 mod 8. Remember being equal mod 8 means that I can add or subtract some number of 8s and get the other number. So I can also go in the counterclockwise direction. So I'm basically mapping the whole integer line onto the circle. And so I'll get 8 different groups, and each one will have an infinite number of integers. The overflow then happens because we can't have a representation where one bit pattern means all of these things. And the representation, remember, can't be ambiguous. Computers are not going to be able to guess which one was the right answer. So we have to pick one label. And when we pick a label, if it doesn't correspond to the correct answer, well, then that's where the overflow comes from. But we don't have to pick the labels we picked for unsigned. We don't have to pick 0 to 7 in this case. So we could pick some numbers in the positive direction, so say 1, 2, 3. And we could pick some numbers in the negative direction, say negative 1, negative 2, negative 3. And then we could try some addition. So we could go from negative 2, add 3. Again, corresponds to just going around the circle. So three steps. So negative 1, 0, 1. And you'd see that negative 2 plus 3 is, in fact, 1. Now, of course, we're going to get overflows, and the overflows will be different. So if, for example, we said, well, what's 2 plus 3? So we'd start at 2, and we'd go 1 space, 2 space, 3 spaces. And we'd say, oh, 2 plus 3 is negative 3. Well, that's not right. So we still have overflow problems. It's just that now we have a representation for signed integers. And we can use that using the same approach to arithmetic, in particular, the same hardware device to do the addition. So this is one way to derive 2's complement. So you want to know, well, what's the bit pattern for negative 3 in 3-bit 2's complement? Well, there it is. So you can get all of the bit patterns for 2's complement by doing it that way. So the general scheme, if you want to do it graphically, is outlined here. So you draw your circle, and there's a bigger circle in the notes, but you don't really want to draw the circle. But it's a good way to understand it. You draw your circle for n bits, 2 to the n points. You start at 0 at the top. You write your unsigned bit patterns clockwise around the circle down to the bottom. Those are your positive. Well, you write the bit patterns all the way around. You write the positive numbers around the right half of the circle, negative numbers around the left half of the circle. There's your 2's complement representation. So, yeah, question? So what is this 1, 0, 0 going to mean? Let me come back to that later. Good question. So the question is, well, I didn't label this thing. So what should we label it? Let me come back to that at the end. Good question. OK. So that's our approach. We can also do it algebraically. So why do I want to show you both ways? So it turns out that most students will understand the graphical approach or they'll understand the algebraic approach. They'll feel more comfortable with one or the other. They're completely mathematically equivalent, I assure you, 100%. If you understand one, it's good. You're done. You understand why we do 2's complement the way we do. So don't worry if you don't understand both. If you understand both, that's great. But I do want to show you the other one because some students will understand this one better than the graphical one. Let's do some algebra and see if we can find a way to get the same answer by doing algebra. So in algebra, remember that the adder is going to produce some bit pattern, which we're going to call sum. So if I add two bit patterns, A and B, then I get the answer sum. And that sum will represent the value A plus B, but only mod 2 to the n. So it might not be exactly the right pattern because I might not be able to fit the pattern A plus B into n bits. But it'll be equal mod 2 to the n. So when we define n bit 2's complement, the first step is, well, let's define the positive numbers. So we'll define 0 up to 2 to the n minus 1 minus 1. And those will look exactly like unsigned. So half of our bit patterns will turn into positive numbers. And those will be exactly the same representation as they were for unsigned. And then the problem is, how do we find the bit patterns for the negative numbers? So let's see what we can do. What do we need? What problem do we need to solve? So for every number that we have, let's call it a number k. So k is in this positive range I just talked about, from 0 up to 2 to the n minus 1 minus 1. So for every positive number, we have to find a bit pattern that's going to represent negative k. That way, we can represent for every positive number we have, we can represent its negative value also. So somehow we have to find that bit pattern. The bit pattern has to have n bits. So if we look at that bit pattern as a base 2 number, it has to be from 0 up to 2 to the n minus 1. And if it's bigger, it won't fit in n bits. So it's no good. And then we have to pick the pattern in such a way that if we take any integer m, and we add m to negative k, then that's the same as adding this bit pattern we're going to pick to represent negative k, p sub k. So if those two are equal, mod 2 to the n, then the bit pattern k will give us the right answer when we plug that bit pattern into this piece of hardware that someone built for us, that does unsigned addition. The other constraint, so let's say we find a good bit pattern. If that bit pattern is the same bit pattern as a positive number, then we have ambiguity. So the bit patterns we find, they can't be the same bit patterns we've already used to represent positive numbers. So remember, we used all of the bit patterns starting with a 0. We used all 0s means 0, 0 followed by anything else means a positive number. So whatever bit patterns we pick, they better start with 1. So now to solve this problem, we'll do some algebra. So we've got a property up there, I just copied it. So that's what we need to solve. So let's subtract m from both sides. And remember that addition and multiplication distribute across the modulus operation. So we can just say, OK, subtract m from both sides. I can subtract m from both sides of the equation inside, and this will continue to hold. So subtract m from this side, I get minus k. Subtract m from this side, I get p sub k. And negative k equals p sub k mod 2 to the n. So then I want you to remember that, well, 2 to the n equals 0 mod 2 to the n. If I add 1 2 to the n to 0, I get 2 to the n. So those two are equal. And then I can add those two equations. So on the left, I'll get minus k plus 2 to the n, or 2 to the n minus k. And on the right, I'll get pk plus 0, which is pk. So 2 to the n minus k equals pk mod 2 to the n. That's what we need to solve. Turns out there's one easy solution to that, which is just to say, well, why don't I just pick the p sub k, where p sub k is actually equal to 2 to the n minus k. It just has to be equal mod 2 to the n. But let's just pick the one where it's actually equal, period, not mod 2 to the n. Now in that case, we have k running from 0 up to 2 to the n minus 1 minus 1. So if you plug that in, you'll see that that means the patterns we have are at least as big as 2 to the n minus 1 plus 1, and no bigger than 2 to the n minus 1. In other words, they're all n-bit patterns, and they all start with 1. But those are all the patterns, the bit patterns, we didn't use for the positive numbers, and we didn't use for 0. So those are all free patterns. So now we have an algebraic definition. We're done. Negative k is represented by this pattern 2 to the n minus k. So that's an algebraic definition for 2's complement. It's fully equivalent to the graphical derivation. If you do it one way, the other way, you'll get exactly the same answers, and you'll have the 2's complement representation. Having done it this way, you can then use the same piece of hardware to do addition, subtraction, et cetera, for 2's complement and unsigned values. Oops. All right. Ready for the name? You can tell. OK. So let's do some sanity checks. So if I take negative k and I negate it, negative negative k, I better get back the same answer, right? I want to make sure, in fact, I do. So what's the bit pattern for negative negative k? So we said, well, negative k is given by 2 to the n minus k. So we can substitute once. We can replace negative k with 2 to the n minus k, and that gives us this expression here, negative quantity 2 to the n minus k. And then we can substitute again, because we should just be able to negate that parenthesized value. And what we'll get is 2 to the n minus the quantity 2 to the n minus k, which then we can just cancel the 2 to the n's, and we'll get k. So that gives us the right answer. So that's good. I mean, if it didn't give us the right answer, that would be kind of disturbing. That would mean something's wrong with the representation mathematically. OK. So let's do that. So when I want to calculate negative k, how do I do it? Well, I go calculate the bit pattern, 2 to the n minus k. So one way to do that is you line them up and you subtract. You can do it that way if you want. I don't like doing it that way. It's painful. It involves a lot of borrowing. You've got a bunch of zeros there. You've got to do all these borrows. So instead, remember that I can write 2 to the n as 2 to the n minus 1 plus 1. So how does that help? Let's write that down. So we're going to calculate 2 to the n minus 1 and then subtract k and then add the 1 back in. So for n equals 5, what is 2 to the n minus 1? Well, it's 1, 1, 1, 1, 1, 5 ones. For n equals 20, it's 20 ones. For n equals 100, it's 100 ones. So now the subtraction is a heck of a lot easier. It's easier to subtract in decimal from 9, 9, 9, 9, 9 because you never have to borrow. So here in binary, we subtract from 1, 1, 1, 1, 1. We never have to borrow. All I have to do is say, well, if I have a 0, I put a 1. If I have a 1, I put a 0. It's called the ones complement. Adding one more gives you the twos complement. Engineers are so funny. Yeah, it's not a funny joke, I know. But that's where twos complement comes from, at least in my urban legend version. So if you want to remember, it's the ones complement plus 1. Wow, no one laughed. I'm sad. Even at my funny laughing. All right, now you're laughing. Good. So I want to just mention this because you will hear a lot of terminology. In engineering, engineers try to be precise. We try to say exactly what we mean. We define things mathematically. We mean precise things about what we're working with. Unfortunately, once those terms get out into sales and marketing and just general use, they tend to get abused and misused. And so this term, it comes from different places. But we'll try to be consistent in the stuff we give you, assignments, exams, things like that. You will hear the phrase, take the twos complement. And by that, people mean negate a bit pattern. We'll try not to say it that way because people do get confused, especially when they're just learning between the twos complement representation and negation. So taking the twos complement as a negation operation, you can take any bunch of bits and you can apply this negation operation we just talked about. Now whether or not the bits should be interpreted as a twos complement number or not, that's up to a human. Bits are bits. The computer doesn't know what the bits are. So it's up to you as the human to say, well, these bits are twos complement number. And so it's OK to negate them using twos complement representation. So we'll talk about when we want you to do something like calculate the ones complement and add one, we'll say negation instead of take the twos complement. And for clarity, I suggest you try to do the same. Otherwise we might have some confusion when we talk. Is that what? Will the two add up to zero? So if you add k to negative k, will the two add to zero? Yes, they absolutely will. So if you add ones complement, then they will add up to 1, 1, 1, 1, 1, however many ones in your representation. Because everywhere you have a 1, you have a 0 and the other and the negative. So ones complement actually was a computer representation. And you have to go back and replace the 1, 1, 1 pattern with 0 because that's 0. So it makes, again, the hardware more complicated. We don't really talk about it in the class, but it is another way to do negative numbers. Good question. Yes, Eric. Yeah, so, OK, so the question, I want to repeat it so it's on the video. The question is, you know, am I saying it's different because there are many ways to negate but twos complement is a particular style? Yes and no. Twos complement is a representation. It's a way of saying, for some decimal value, how do I come up with a bit pattern? And so I want to keep that away from operations like negation using that particular representation. So yes, what you said is correct, that negation on a different representation is done differently. So if we just sit down and randomly assign numbers to bit patterns, negation would involve looking at whatever table we drew. Here it's more systematic because it's designed to be simple so that the negation process is systematic. And negation only applies for twos complement, the way we've defined it. But I'd like to use twos complement only to describe the representation for signed integers that we've just talked about. So that's why I just find it confusing to use it as a verb, say, take the twos complement, because I found students have gotten themselves kind of tangled up in differentiating between operations on bits and the representations, which is just a question of how you represent using a bit pattern a particular decimal number. Any other questions? Okay, good. Okay, so let's do an example. So as you know, I like 42. You may remember that 42 in 8-bit twos complement, as well as unsigned, is represented by this bit pattern 00101010. And so to negate that number, to calculate negative 42, first we'll complement the bits. So I will take 0 and replace it with 1, 0 with 1, so forth. So this is the ones complement of that bit pattern. And then I'll add 1 to that, and that will give me this answer here, where I've negated the bit pattern and gotten the twos complement representation for negative 42. So there's an example. And if you wanted to, you could add these two up. I don't have it drawn for you. But if you wanted to add these two up, then what you'll see is that you get zeros in every position and that the 1 carries out. So and that high 1, of course, will be thrown away from the n-bit representation. So you get all zeros with a carry out if you add k to negative k for any k, except 0. But negative 0 is the same. So how do we convert between twos complement and decimal? For any non-negative number, it's the same. The representation is the same. The bit pattern is the same in unsigned twos complement for all of our non-negative values. And so converting from decimal to twos complement for those numbers is identical. You can go either direction, do the same process we talked about earlier in the week. What about negative numbers? So one way to do it is if you've got some decimal d less than 0 that you want to find the bit pattern in twos complement, first convert negative d. So that'll be a non-negative number. It'll actually be a positive number. And then negate the resulting bit pattern. So take the answer you get and just negate it. And that'll give you the bit pattern for d, which is, again, negative. If you want to go the other direction to convert a twos complement bit pattern into decimal, well you can start by negating the bit pattern. That'll give you a positive number. And then you can convert that to decimal using the unsigned approach. And then the answer is minus d. So if you calculate decimal d, the answer is minus d. So that's one way you can do it. Students usually find this way easier. And you can see the polynomial up here. And you might think, I don't want to write polynomials. But let me just walk you through it. And then you'll see the answer at the end. I just want you to understand why the approach works. So let's say we have some negative number, negative k. And we want to calculate the bit pattern. I'm sorry, we've got the bit pattern. We want to calculate the value negative k. We know it's negative because the first bit is a 1. So how will we do that? Well, the bit pattern is going to have the value 2 to the n minus k, as we talked about. So we can write our polynomial, which you might remember from a couple days ago. And we know that a sub n minus 1 equals 1, right? Because that's how we know it's a negative number. So if we plug that in, we've got a 2 to the n minus 1 over here. And we could subtract this 2 to the n from both sides. That'll give us this equation down here. This part of the polynomial is identical. The only thing that's changed, so on the left, we no longer have our 2 to the n. And then on the right, we have 2 to the n minus 1 minus 2 to the n, right? In other words, this thing is minus 2 to the n minus 1. So I can replace that then. I know, again, a sub n minus 1 is 1. So I can say minus a sub n minus 1 2 to the n minus 1. So now if you look at this polynomial, it looks exactly the same as the one we used with place value for unsigned, except that we put a negative sign on this leading bit. That's the only difference. So if you want to calculate the value of a 2's complement number, you can use this equation. Instead of counting the first bit as 2 to the n minus 1, count it as negative 2 to the n minus 1. And that'll give you the right decimal answer. So that's the way people mostly prefer, it seems, rather than doing it as I explained on the last slide. I do want to point out, this way also works when a sub n minus 1 equals 0, right? So for non-negative numbers, this thing is 0. And so this term just goes away. And then what you're left with is identical to the unsigned equation. So either way, you can use this approach, where all you do is negate the first bit's value to calculate the value of a 2's complement bit pattern, whether it's positive or negative, doesn't matter. That make sense? Kind of, yeah. And if you want to go through the algebra, make sure you understand it. It's fine. But this approach definitely works. I just wanted to illustrate why. Yeah. Yeah, sure. Let's go over to Notepad then. Good idea. So the question is, can I show an example? So let's write up a random, somewhat random. There's 8 bits, huh? OK, so our place values then are 128, so rather negative 128. That's 2 to the 7th. And that didn't work. Sorry. See what I'm doing. Oh, wow. I think it's because I'm on HDMI. OK, so I will then turn that on. And this will not work well on the little grim. Sorry about this. This is not the best. We'll try to make it big enough for you. Let's just do 6-bit. It's kind of the same. And I think it'll save me space on the board. So hopefully, everyone can see it. Can you see it on the right side? You can see it? OK. So we've got 111001. So the place values here are 1, 2, 4, 8, 16, and instead of 32, negative 32. So we've got negative 32 plus 16 plus 8. The 4 in the 2 places are 0, so we don't add those. So we've got negative 32 plus 16 plus 8 plus 1. So let's just add up the positive parts. So 16 plus 8 is 24 plus 1 is 25. 25 minus 32 is negative 7. Question. So again, that was, I guess I didn't need to turn this off in that case. Ah, OK. It comes back only when I do PowerPoint. That was what we derived as this equation for interpreting two's complement bit patterns as decimal. So by this derivation, we showed that we can plug in this equation. Then that'll give us the value negative k of a particular pattern. The negative k on the left, if it's positive, is just the positive part. We don't actually negate it or anything. This equation on the right will give you the right answer for both non-negative and negative two's complement bit patterns. But here's an example. This is negative 7. And had we gone the other way, so maybe I'll try to do it on the right. So 111001. You can see this over there? So let's take one's complement, so I get 000110. And then I'll add 1 to that. And I'll get 000111. And then if you look at this pattern, this is the 4's place. That's too small. This is the 4's place, the 2's place, and the 1's place. So you add those up, you get 7. So again, negative 7. So regardless of which way we do it, we get the same answer. I think most people find this way simpler, in my experience. So it's OK if you didn't follow the algebra. I'd encourage you to go back and understand it. So the question is, are we going to ask you to prove this, or do we just want you to know why it works? I just want you to know why it works. So let me come back to you in a second. So there's a guy named George Polia who used to teach at Stanford, who has a math dictionary, really. And he thought that the way you learn math and the way you become good at math is to see different mathematical techniques, and then to pull those out of your toolbox and use them. So I will try to expose you to different approaches, different proof styles, different ideas in mathematics that underlie what we're doing in digital design and digital systems. We won't, for the most part in this class, ask you to do a lot of proofs. Honestly, a lot of the optimization and things like that will be automatically done for you these days by computer-aided design tools. But we want you to understand how they work. So there's a certain amount of things that you'll see in the next few weeks, but not proofs. So this one, we just want you to know why this particular equation works. OK, and sorry, someone here. Yeah. So first of all, if I just draw some bits for you, you have no idea what it means, which is something that hopefully came up in discussion section yesterday. But if I tell you it's 2's complement, then you can look at this bit and say, oh, it's negative. So 1 means negative. 0 means non-negative. Yes, yes. So if we go back, I put down my little clicker, sorry. If we go back a slide or two. So negate the bit pattern. We did that. Convert to decimal, we got 7. Answer is negative 7. Yeah. Yes. Yes. That's right. First bit will tell you whether it's actually negative or non-negative. 0 starts with a 0 also. Good question. OK. Anything else? Yeah. Yeah. So if the number starts with 1, that means it's negative, then you can do it either way. You can negate the bit pattern, convert to decimal d. That's what we did over here. So the number started with a 1. So we took the 1's complement, added 1. That gave us the negated bit pattern. Calculated the value of this negated bit pattern is 7. And the answer is negative 7. Or we can simply plug into the place values with the first place value negated over here and add up these numbers. Instead, we'll get the same answer. So either approach works. Next slide. Oh, the top part? OK. So if you have a number, so let's say that we wanted to do negative 42. Actually, I did it already. Where did I do it? Let's go backwards. I did it here. So if you want to know what negative 42 is, you start by calculating 42. And then you negate it. And that gives you the answer. That was all. That make sense? OK. I'm sorry, I can't hear you very well. Yeah. So the question is, is there a reason that the process works this way in base 2? This is not human base 2. I mean, in human base 2, we write a negative sign. This is a particular representation that we chose to use the mathematical idea of modulus to define. And because of the way we defined it algebraically or graphically, you get the same answer. That's why this process works for negation, basically. If you look at the algebra, well, because we defined it to work for negation, mod 2 to the n. By definition, that's why it works. OK, yeah. There is not. There is not. So no negative 0. Yeah. OK, yeah. So there are resources available online. Also, the lectures are being videotaped, and the slides are online. So all of those resources, thanks for pointing that out. I mean calculating the bit pattern for the negative value of what's being represented. So here, this bit pattern represents 42. So if you want to calculate the bit pattern for negative 42, you would take the ones complement and then add 1. And that would negate the value of the bit pattern and give you a different bit pattern. All right. Let's move forward. What did we see? That one worked. OK, so now back to your question. So you said, well, what about that last bit pattern? What is that? So what should it be? Should it be 2 to the n minus 1? We could make it be 4, the 3 bit, 2's complement. Maybe negative 2 to the n minus 1. Could be negative 4. We could just say, just leave it undefined. So what do you think it should be? Yeah, negative 4. Why? Starts with a 1. Good answer. So that's why. So it's a little imbalanced. But in 2's complement, the 1 leftover bit pattern is always negative 2 to the n minus 1, because that way, this simple approach of, well, just look at the first bit, and that'll tell you non-negative or negative still works. If you chose another answer, it wouldn't work. If you chose to make it 4, you would have to look at all of the bits to tell, well, is it positive or negative? So instead of doing that, we always choose, or rather, 2's complement is defined for that to be negative 2 and 2 to the n minus 1. So I added a couple of these in today. And I guess I can't flip and show you the tools, because I'm on the wrong interface here. So sorry about that. If you want to practice conversion, there is the online tool that will give you instant feedback. It will let you do as many examples as you want in 2's complement as well. It will also let you do this extension I'm about to show you. And so all of these things, you can go play with the tool, get experience, get feedback on whether your answers are right or wrong. So sometimes we might need to take one bit pattern in a certain size representation, say n bits, and extend it to an n plus k bit representation. So we might have, for example, 5 bit unsigned, and we want to create 10 bit unsigned. So how do we do that? So if I have a 5 bit unsigned number, and I tell you I want the same number, but I want the 10 bit unsigned representation for that number, how would you find that? Yeah. Yeah, exactly. So add some leading zeros. We based it on base 2. We based the whole representation for unsigned on base 2. And we had to add leading zeros already. So if you want a bigger set of bits, we'll add some more zeros. Not so hard, right? OK, good. Good answer. Zero extension. We have a name for it. What about 2's complement? Ah, good. So Eric says it depends on the leading number. So for non-negative values, that's the right answer. Let's do it one case at a time. So non-negative values, 2's complement is the same as unsigned. All the non-negative numbers are the same. So we just add k more leading zeros, just like we did with unsigned. So that's easy. What about negative values? What do we do there? OK, let's do some examples. So I was going to do these on Notepad, so sorry, that's not going to work. So negative 5 has this bit pattern, 1, 1, 0, 0, 1, 1. We'll do something concrete. So we have these two 5-bit patterns. So let's see, 1, 1, 0, 0, 1. Is that right? 0, 1, 1. OK, so this is negative 5. So how about the 8-bit 2's complement representation of minus 5? OK, so let's do that. So to get 5, I'll go to this 1's complement, and then I'll add 1. So this is 5. And then you just told me I can convert positive values by adding zeros, right? And then I'll convert back. And I have to add 1 again, right? So this is negative 5 in 8-bit 2's complement. Anyone notice anything? I just added some 1's. You understand why that's going to be the same every time? Yeah. Yeah, so basically, going around the top of the circle into the negative part, negative 1 is always going to be the all 1's pattern, right? And so forth and so on. They're always going to have the same ending bits. Here, the other way to think about it is when I go back and I add my leading 0's, those just become leading 1's when I negate again. My leading 0's become leading 1's. So negative 5 is 1, 1, 1, 1, 1, 1, 0, 1, 1, just as we just derived. And negative 10, what do you think? Good. 1, 1, 1, 1, 0. So what about this space? It's just for us. Computers don't have those spaces. All right, so that was just to make it obvious on the slide. So how do we convert? We take the sine bit and we copy it. It's called sine extension. So if you want to extend from a smaller representation, smaller 2's complement representation, to a bigger one, you take the sine bit and you copy it. If you want a bigger one, you take the sine bit and you make k extra copies of it. You want to go from n to n plus k. All righty, so now we need to start thinking about arithmetic again. We know how to do overflow checking for unsigned. We decided, well, we do the operation. We add two numbers together. We get a carry out. That's going to be an overflow, because we have to throw that carry away. We don't have space for it. So what about 2's complement? When I add two 2's complement numbers with n bits each, how do I know if it's right or wrong? Let's go look. Supposed to be base 2 addition, supposed to work exactly the same way. Let's take a look. So here's the first example we did with unsigned. So let's do it again. So I have 14 on top. I've got 4 on the bottom. Those are also the representations in 2's complement. So let's add them up. So 0 plus 0 on the right. Good. 1 plus 0, 1. 1 plus 1, 0 carry the 1. It'd be really embarrassing if I made a mistake. All right. 1 plus 1 plus 0, carry the 1. OK, 1 plus 0 plus 0. Good. OK. So when we did our unsigned, this gave us the right answer. And if you look at that as unsigned, you say, OK, well, that's 18. And then you're happy. So what is this in 2's complement? It's not 18. 18 you can't represent. So it's negative 14. So something went wrong. So we had an overflow, even though we didn't have a carry out. So carry out is not going to tell us quite overflow with 2's complement. Now I want you to notice something. The arithmetic is exactly the same. We didn't do anything different than when we added these bit patterns. And of course, that has to be true, because we defined this representation so that we could use the same process to add numbers. So if someone asks you, well, can you add this in 2's complement? Now can you add it in unsigned? Well, you probably don't need to do it twice. It's the same. How you interpret the answer, though, is different. So here, if we interpret the answer as 2's complement, the answer is wrong. So this is an overflow. All right, let's do another example. So this was the second example we did. This one overflowed for unsigned. So in unsigned, this was 14 plus 21. And I said, oh, you should remember that that equals 3. So I've kind of given away what we're going to get. But let's go ahead and do it. So 0 plus 1 is what? 1. 1 plus 0? 1. 1 plus 1? 0 to the 1. 1 plus 1 plus 0? 1 plus 0 plus 1? 0 to the 1. And yeah, that one's a carry out. But we've got to throw it away. No space. So what we get is 0, 0, 0, 1, 1. And when we interpret that as 2's complement, what was on top was 14. What's on the bottom is minus 11. 14 plus minus 11 is 3. So it was right. So no overflow. So we had a carry out, but we didn't get an overflow. So carry out is not overflow for 2's complement. How do we tell? How do we know when something's gone wrong? So I claim that if I add 2's complement numbers, and one of them is negative, and one of them is non-negative, that never overflows. That's my claim. Ready for the proof? Good, get to work. Yeah, Eric. Yes, that's a very good way to prove it. So Eric suggests that one way to prove it is that if you look at the range, and you then contain one number to be in the positive range, and the other number to be in the non-negative, and the other number to be in the negative range, and then you look at the possible range for the sum, those will always be representable answers. And yeah, that would be enough proof for this claim. That's right. Good, quick answer. So once you do it, you can go see if my answer in the notes is correct. So everyone else should prove it to themselves, and then go read it. So, very good answer. So let me give you a long definition, again without a proof. So if I add these two numbers where the sign bit is A and the sign bit is B, and I get the answer sign bit is S, I claim the following. And so let's make sure you believe me, at least in these two cases. So if the two add ends, A and B, well, A and B are the sign bits. But if these two things I'm trying to add are both non-negative, and then the answer I get is negative, that's wrong. You believe that, right? If I add two non-negative numbers, I get a negative answer, that can't be right. What if I go the other way? So this second case down here, the two add ends are negative. I add two negative numbers, and I get a non-negative answer. Also wrong. So I think people agree with those. The hard part of this proof is actually the other direction, showing that if my answer is wrong, it has to be one of these two cases. So again, proof's in the notes. You should figure it out, and then go read that proof, and check that I got it right. That's a lot of words. Engineers hate words. I was going to joke you should say this five times quickly for me so you remember it. I won't put you through that. All right, so there's a more concise way to write that using Boolean algebra. So I'll explain what Boolean algebra is in a minute, but this is how we would write overflow. So overflow is equal to not A and not B and C, or A and B and not C. So A, B, and C were the sign bits. So what do these ands and ors and stuff mean? So they're Boolean operators. So what is Boolean algebra? So these Boolean operators were invented by a guy named George Boole to reason about logical propositions about 150 years ago, a little more. Originally, they were operating on true and false, but we're digital system designers. So what are we going to operate on? Bits. Good. Everything is bits. Zero is false. One is true. Be careful not to confuse these operators with English words. They don't mean the same thing, and it's easy to do. So do not confuse them. The meanings are not the same. They happen to be English words, but the meanings are not the same. And I don't think we're going to get through them all today, but I'll emphasize that as we go through them. So I think we can go through this brief. Actually, maybe I'll give you examples here. So there are four that I'm going to tell you about. So the first one is AND. AND is the all function. So you can have any number of inputs for an AND, and the output is a 1 if all of the inputs are equal to 1. Otherwise, the output is 0. So that's how we define the AND function as the all function. Yeah, so let's say you're operating on four different operands. If any of the, I'm sorry, if all of those operands are 1, then the output of the AND function is also a 1. And otherwise, it's a 0. So it only gives a 1 if all of its inputs are 1, if all of the operands are 1. The OR function, that's similar to how we usually use AND in English. That's one reason it's confusing. OR is going to be different. So OR, you should think of as the any function. So we'll have some number of inputs, some number of input operands. And if any of them is equal to a 1, the output will be a 1. So that's the OR function. So this is very different from English. If I invite you to my house and I say, oh, would you like some coffee, tea, milk, or orange juice? And you say, yeah, all of them. I might think you're a little rude. Usually, people mean, yeah, would you like to pick something to drink? Not, hey, why don't you just take all the liquids in my house? So in English, sometimes people say that English is exclusive OR. And by that, they mean, well, you should pick one of. But we have an exclusive OR in Boolean logic, and it doesn't mean one of. So exclusive OR, let me jump down here. Exclusive OR is the odd function. So exclusive OR, XOR, as we usually call it, returns a 1 if an odd number of the inputs are 1. So when you have two inputs, that's sort of similar to English OR. But for more inputs, it's not the same. So XOR is the odd function. And then finally, we have the NOT function. And NOT is simply the logical complement. So if you say NOT of 0, that's a 1. If you say NOT of 1, that's a 0. So I want to show you the truth table. So this thing is going to help us understand different Boolean operations. There's another tool that you can use to familiarize yourself with truth tables if you want. You can go play with them. But this is truth table. This is what it looks like. So you can see on the left, we have the inputs, A and B. And underneath those, we have all the possible combinations of those inputs. So for two inputs, we have four different combinations, four bit patterns. And on the right, we have space to write the output for a particular expression, for a particular Boolean expression operating on A and B. So usually, we list these in binary order. So we'll start with 0 and then 0, 1, 1, 0, 1, 1. So what we'll do, I think, starting on Monday, is go through each of those four Boolean functions and build up the truth table for them. So quick question? OK, I'll leave this up. So thanks. I'll let everyone go. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\"},\n",
       " {'ECE120-2016-10-10-LEC-20-slides.mp4': \" Okay, so let's go ahead and get started. A couple of administrivial things to start. So we will, so there's this feedback survey. So if you haven't done that already, please try to do it before midnight. Today we will finish off our serial comparator. I have a few more comments to make. I'll do another example, somewhat faster for Power2Checker, and then start in on finite state machines. So most of today will be an example to introduce the tools that we use to design finite state machines. And then we'll do counters and things like that on Wednesday. So I know there's some FSM problems on the homework. So sorry for being a little late in that regard, but I like this ordering better. I think it's better to understand the serial stuff because it's a little simpler. So that's the plan for today. I wanted to remind you we have a midterm. Today's the last day to sign up for conflict on the wiki. So if you haven't done that, you have a conflict with this time and date, please do that. There's also, so section 2.8 of the notes plus reading, writing, truth tables from last time, since the other lecturers haven't done that yet. There are the notes on the wiki, they have a lot of extra content. So things like T flip-flops are not part of the class. So if you're looking at those, do ignore that extra content. And if you need to know if something's included, look at note section 2.8. That'll give you all of the learning objectives for this part of the class. So in the notes, every part of the class has basically two pages of learning objectives for that quarter of the class. We'll have a review section next Monday. So a week from today, we'll do what we did for the first midterm, go through topics of your choice and review. So come prepared with your choice of topics, and we'll vote on them. Okay, so I wanted to take a little bit of a review. So this was our serial comparator. We adapted from the general model, so we initialized it to 0, 0 when f equals 1. And then we had our single bit slice here. The outputs of the bit slice got stored in the two flip-flops, and then those are cycled back to execute on the comparator in the next cycle. And you've got one bit of A and B operands coming in each cycle as well. And then we just look at those two outputs from the bit slice as our answer, A less than, equal, or greater than B. Yes, so the serialization, it just means that it's operating over time, rather than simultaneously in parallel. So the bit slice design, everything happens, and then there is gate delay, but it's logically inside of, say, a clock cycle, whereas this design is operating over many clock cycles, using the same hardware. So something in between, where, say, you had two bit slices, would be a mixture of the two. Okay, so then we compared area and delay. And so the area gave us that the serial design was smaller for four or more bits, and that was because it was constant size, kind of the flip-flop, so you needed to have a few bit slices in the bit slice design before they were equivalent. But n equals four is pretty small, so generally the serial design will be smaller. On the other hand, the serial designs are slower for several reasons. One is that all of the paths matter, right? So when we look at the A and B paths to the inter-slice outputs, usually we can ignore those in a bit slice design, because all of the bits from A and B show up at time zero, whereas in a serial design, every clock cycle we get a new bit of A and B, so we have to count those. The flip-flop and selection logic, of course, have gate delays inside those, and then whatever is setting the clock speed for the system might be slower than our serial comparator or serial anything, so that's another aspect there. So when we did the side-by-side comparison, we found that the serial design was going to be at least five and a half times slower, maybe even worse, depending on what sets the clock speed. Okay, so this is kind of where we left off on Friday. We said, well, those are two extrema points, right? You can do one bit slice and use that fully serial. You can do n bit slices and use that effectively fully within a clock cycle, but you can do anything in between two. You can do two bit slices, three bit slices, whatever, and you can also optimize, right? So you can say, well, let me go do a single function that compares two bits at once. So if you look in the notes, there's actually one of those designs. We did a design in class, actually, where we looked for powers of two, two bits at a time. So the more bits you look at, the better your design will be, both in area and delay, but the trade-off there is complexity. If you try to look at a two 32-bit numbers and write down the Boolean expression for which one is bigger than the other, it's going to take you a little bit of time. So higher complexity, more likely to make a mistake when you try to build it, but in return, you get better area and better delay. So I wanted to give you one practical example where people have done this kind of trade-off in practice. So there was a generation of Intel processors, I think around the turn of the millennium, around P4 generation, that actually internally, it was still a 32-bit machine. So the processor word size, most of the operations were 32-bit operations, but they actually made the adders 16-bit adders, and they made them clocked twice as fast as the rest of the processor. So typically, that was around 3 gigahertz. So the adders would then go 6 gigahertz. And the reason they did that is they were starting to include these multimedia operations in the design of the processor, and the multimedia operations needed smaller word sizes. And so you could actually use these adders to do two different 16-bit adds at a rate of 6 gigahertz, or you could take two 16-bit adders or even one 16-bit adder and run it for two cycles to do back-to-back adds, bring the carry back around just like we did in our serial comparator with the output of the bit slice. And you could actually do a single 32-bit add in one clock cycle at 3 gigahertz. So people do play these games in practice in real systems where they trade the speed versus the size and do things in between. Now, those 16-bit adders were not your ripple carry adder. They were tree adders just as the 32 and 64-bit adders are today. But same sort of idea, that you can break the big adder into little adders and use them serially. So I wanted to do a second example of serialization. So this was our generic bit slice model. So just to remind you quickly, we're working on some n-bit operands. We've got p bits of input into our bit slice from the operands, and we produce q bits of output. And we've got n bits in between slices. And then at the end, we have some answer that takes r bits. That's not shown in the slide. But we have some output logic that takes the last n bits out of the last bit slice and produces our r bits of answer. So in class, we did this power of two checker where we looked at two different bits of the operand a in one bit slice. So we've got two bits of a coming in here. We've got two bits between the bit slices. Remember those. I'll show you the representation in a minute. But we needed to keep track of whether we'd seen zero ones, one one, or more than one one, because a power of two has exactly one one bit, as you may remember. I think you played with that in discussion too. So p equals two here. Output bits down here is zero. All we want to know is the answer, to the power of two or not. So we don't produce any output operand with bits coming out of the bit slice. And then m is two from bit slice to bit slice. But at the end, we just want to know yes or no. Power of two, not power of two. So we just need one bit for that. So we used an XOR gate in our design to get that final answer. So this was our representation. We said, OK, zero zero means no one bits. Zero one is one one bit. One one is more than one one bit. And one zero was not used. So when I initialize my bit slice design, what should I pass in as constant values to the first bit? Zero zero, right? I don't have any one bits yet. I just started looking. Good. So we want to initialize to zero zero. So actually, the design is going to be similar to the serial comparator in the sense that our initialization values are both zero zero again. So we're going to just use two NOR gates again for our selection logic. Here's the power of two checker bit slice that I showed you a minute ago. Since m equals two, we have two flip flops here. I guess I can actually go through it. So two input operands, p equals two, zero output flip flops since q is zero. Two flip flops to store the bits of m as they come out, the m bits of output. These again are initialized to zero and f equals one. And then finally, the output logic to get the answer was to take these two outputs from the power of two checker, XOR those together. If that's a one, then we have a power of two. And if it's not, we've got no power of two. Just to flip back a second to the encoding, the representation. So if you take XOR of these two bits, if you don't have any one bits, then that's not a power of two. If you've got one one bit, that is. And then if you've got more than one bit, one one bit, XOR of one and one is zero. So that's also not a power of two. So that's why we're able to use this XOR gate over here at the end. So let's just do a quick answer. This looks more or less the same because I'm doing another four cycle input. Here n equals eight because in each cycle we'll take two bits of the number. So in cycle zero, we start by marking the F input as one and then A and B equal to zero for the first bits of the number. What are these? What should these values be? Bits, good answer. Yeah. So we don't know what those are. And we don't care. Why don't we care? Won't they affect our other logic? So if F equals one, what are C1 and C0? Zero. It doesn't matter what these are. And that's important. So when F equals one, C1 and C0 are both zero. So now we can calculate what Z1 and Z0 should be. So this says, OK, we've got A and B are both zero. We didn't see any one bits before. So how many one bits have we seen? Zero still. All right. So those Z1 and Z0 then in the second, I'm sorry, clock cycle number one get latched into the flip flops. And so those will appear in B1 and B0 in clock cycle number one. So again, I want to emphasize discrete time. So we only think about clock cycles. So once we're in this realm of serialization and finite state machines, we're doing fully clock synchronous sequential circuits. So we have discrete time measured only in cycles. Things change cycle by cycle on the rising edge. So cycle number one, we have zero, zero. Let's say we put in zero, zero, one. So F is zero. And now we have two more bits of the number zero and one. So what are C1 and C0? Zero, zero. When F equals zero, the NOR gates just copy these two outputs into C1 and C0. And so what should Z1, Z0 be? One, zero. I thought it was zero, one. But yeah, so this is the representation for having seen one, one. OK, you don't really need to memorize that, except you do, sort of do to answer the question. So sorry about that. So the zero, one then gets latched into the flip flops in the next cycle. So in cycle two, the flip flops will have zero, one. So they'll have that for the entire cycle. So let's say that we put zero, zero, zero during that cycle. So C1, C0 will be what? Zero, one. Good. And Z1, Z0? Zero, one. Again, same thing, because we get no more zeros. So the representation is basically counting the number of one bits. No more ones, I should have said. So the Z1, Z0 values get latched into the flip flops. And then in cycle number three, those will have zero and one in them again. Put in zero, one, zero. C1, C0 is what? Zero, one. Good. And Z1, Z0? One, one at this point, because we saw another one. Now we have more than one, one. So our Z1, Z0 output is one, one. That gets latched into the flip flops. And now in cycle four, we don't know, we don't care what F, A, and B are. We might start doing another power of two check, but it doesn't matter. We don't care because we're going to look at these two values through the output logic and get our answer. So we don't know what these values are either. It depends whether we're actually trying to start a second power of two check. So we don't know these values and we don't care about those. So in order to use this, you have to create a system that delivers the bits at one cycle at a time. So yes, from the point of view of designing it, yes, you assume that they're serialized. Good question. So if I take XOR of B1 and B0 at the output, what I get is zero. So these eight bits do not form a power of two. And I can put them in any order, but these were, actually it doesn't matter whether they're low or high. Yeah. Yeah so that's a good question. The XOR is just wired up to these two outputs, right? So at every cycle, we're going to get an answer. So we could actually just check and see, you know, do we see a power of two? In fact, if we wanted to, we could look for this one, one pattern and say, well, at that point, we know it's not a power of two, right? So yes, we will get the XOR every cycle. And if we wanted to, we could make the thing stop early, right? We could look for saying, well, when have we seen more than one one bit? At that point, we know the answer, so we could just stop. So I'll do the timing analysis, assuming we don't do that stopping early. But you could do it with this kind of design. Yes, yes, that's right. So the A and B inputs actually represent two bits from a single operand of n bits. So this takes only n over two bit slices. That's why n is eight, but we've taken only four cycles. Yes. Yeah, absolutely. So the question is, could I have done a three, four, 10 bit, single bit slice? Yes, it would be more complicated this way. And I think in discussion section, you did a one bit checker, whereas in class, we did a two bit checker. So you can go the other way too, in this case. Okay, so let's analyze our area. So we've got a bit slice, two flip-flops, two two-input NOR gates for selection logic, and a one two-input XOR. So flip-flops, same size as before, so we won't go count them again. This was our design. So just pull up the bit slice design. So you can see we have three two-input gates, one, two, three of them. And we have two three-input gates. So I'll count them as number of inputs. So that's our total. So if we add those up, we have three, let's see, three two-inputs in the bit slice, 16 two-inputs in the flip-flops, and then two more in the selection logic. So that gives us 21 two-input gates, two three-input gates, four inverters, and a two-input XOR. So that's our area. I'm being a little more detailed now. We're actually changing it into transistors to do the comparison. So two input gates have four transistors, right? So that's 84 transistors, 12 transistors, eight transistors. And this one is even, so we'll just ignore that one. In the bit slice itself, we only need N over two bit slices, right? So we need three N over two, two input gates, that means six N transistors, and three input gates, another six N transistors, and this XOR. So if you do it, it actually is equal at N of nine, but we have to do two bits at a time. So the serial design is smaller for N, 10 more. Yeah, Mohamed? So if you remember, three or four weeks ago, we looked at how you actually build Vanden Oor gates. There are two transistors per input, one P-type, one N-type. So a two-input gate will have four transistors, an inverter will have two transistors. So if you want to go more detail like this, you can count transistors instead of using our heuristic, which was an estimate of transistor count anyway. So either way is pretty accurate. All right, so let's see. So let's look at timing then. So a rising edge arrives at T equals zero gate delays, and then we said we're going to wait four gate delays after the rising edge before we assume the output is ready to look at from these things. We'll assume the same up here, just as we did before. So assume these inputs up here come somewhere from flip-flop. So those are all available at time four gate delays. This thing here then has to go through selection logic. That's one extra gate delay. So that's now available at time five. Now, to know how long the paths through this power of two checker are, go back to our design, and basically everything was two. Everything's two gate delays from the input side to the output side. So if we go back here, so these things up here, these are available at four. So the A and B paths to the Z outputs, well, that's going to be four plus two is six. But the Cs are only available at five gate delays. So five plus two is seven. That'll be the time at which our Zs become available. You have to look at the longest path, as always. And then finally, we decided we're going to wait four more gate delays before the next rising edge to make sure we've got enough time to get the value through the first latch. So we said four before and four after the rising clock edge in the flip-flop. So if we use that timing, we've got at least 11 cycles between the rising edges. And then we've also, for whatever we're using this answer for, we need to realize that it's actually five gate delays before we get the answer. The answer comes at 12 gate delays after the rising edge of the last cycle. So let's see. So the serial design, then, we've got n plus one gate delays in our bit-slice design. That's just pulling that out of the notes. For the serial design, we have at least 11 gate delays for the clock. We have to have n over two cycles. Remember that we're processing two bits per cycle. Yeah, that's just a number we chose. We chose the same number as we did for the serial comparator. There is some amount of delay implied. A real flip-flop might be a little smaller, but you need something to compare. So I wanted to quantify, so I just picked four. That's a good question. All right. So we need 11 gate delays, n over two cycles. So we've got at least 11 n over two gate delays. So it's at least 5 and 1⁄2 times slower, maybe even slower if this is not the thing that sets the clock speed, which is probably the case. So that was it for our second example session. So you can design them different ways. We assumed that the input to the flip-flop had to be steady for four gate delays before the rising edge, and that the output would appear four gate delays after the rising edge. Yeah. Oh, yeah. You know what? I'm sorry. That actually should be 16. That's a good point. Yeah, that's a typo, because until this output becomes visible, it can't go into this. That's right. That's a good point. Yeah, so this would be actually five gate delays into the next clock cycle before the output could be used. Yeah, thank you for pointing that out. That's good. Yeah, Eric? It doesn't. What it means, so the rising edge can happen when this input to the flip-flop has been stable long enough, which is 11 gate delays. But whatever is using this answer has to be aware that it takes four gate delays before these are visible, which we assumed also. We assumed these inputs were only available at t equals 4, that they came from flip-flops. But this one is actually not available to t equals 5, because after the flip-flops, we've got some extra logic. Five into the next cycle. So four for this part, and one for that part. Yeah, that's right. That's right. So the next power of two check could be starting, and these outputs at the same time are being fed to the output logic, which is then consuming the answer for the last one. In parallel, in clock cycle four, where the M was. All right, so let's talk about finite state machines. So a finite state machine is just a model of a system, and it assumes that the system moves amongst this finite set of states based on some external inputs, and then it produces some external outputs. So we'll do a concrete example shortly, but typical examples would be things like, you know, bill coin operated vending machines, vehicle control systems that are looking at, say, road conditions, or watching how fast your tires spin to decide whether to turn on your anti-lock braking system, computers executing programs, things like that. Actually, the computer, the heart is a finite state machine, as you'll see. So what is it in terms of math? Well, it has five pieces. So we have a finite set of states. We have a set of inputs. We have a set of outputs. We have a set of transition rules that tell us, given any state in any set of in any given input, where do we go next? Right? What's the next state? And then finally, we have expressions or methods for calculating our outputs. Now we're going to, of course, build finite state machines as digital systems. So everything we do has to be mapped to bits. Thank you. Everything's bits, right? So states, bits, inputs, bits, outputs, bits. This is tricky. Ready? Transition rules. Boolean expressions. Thank you. Outputs, calculating outputs, I should say. More Boolean expressions, right? The rules take your current state ID, which is some bits. Those are input bits. And your, sorry, more input bits to these Boolean expressions, which are the inputs to the system, and create a next state ID, which is the outputs of these Boolean expressions. And so it says, well, what state do I go into, given my current state and my input bits? And then the outputs, of course, are Boolean expressions. We're going to assume, and I'll tell you this several times, but we're going to assume that the outputs are only a function of our current state. Now, in general, they could also be a function of our current inputs, but in our class, we'll assume they're not. So we implement finite state machine as clock synchronous sequential circuits. So that means discrete time, right? So cycle by cycle, things will change. So in each cycle, the finite state machine will look at its current state, look at its inputs, and move to a next state. Every cycle, regardless of anything else in the world, it'll just keep going, chugging along state to state. So given any state and any combination of inputs, a transition rule from the given state to a next state has to be defined. A digital system, it's going to go somewhere. Next cycle, there are going to be some bits in the state. So that has to be completely defined. Self loops, which means transitions from a state back to itself, that's okay. A state can stay in itself, but we need to say explicitly, under these inputs, the state stays put. It doesn't go to a new state. So we have to completely define it. Regardless, what we build will go somewhere, right? There will always be bits. So even if you say, oh, I don't know, I don't care, whatever you build will have some, will have bits there. And so it will pick an answer for you. So let's do an example. So here's my example. You've probably seen one of these. How many of you have seen one of these? Most of you? Okay. I don't mean a key. Yeah. So Yale Pat, one of the authors of your textbook has a great, has a great joke that he plays on a lot of people. So he pulls out an Intel processor in a block of plastic. And he says, you know what that is? And everyone looks at it. I don't know, is that a P4? He's like, no, that's a key chain. So yeah, so this is a key, but it's also a keyless entry system, right? So it has some buttons on it. And when I walk up to my car, I don't have to put the key in the lock. It has a little protocol for me with these buttons here, which hopefully will help me figure out today so I can use my car. So what I want to do is start with a list of states. So when I walk up to my car, probably the car is locked. At least I hope my car is locked now. So, you know, we can make this list of states. I'll call this an abstract list of states. The meaning of my first state is, well, the car is locked and I'll give it a name. I'll call it locked. So in that case, the driver's door will be locked and the other doors will also be locked and the alarm hopefully is off. So alarm is not on. So now maybe I'll do something and my door, the driver's door will unlock. So we'll have another state. So this means a new state in the system. So when I walk up and I unlock the driver's door, then I'll make another state. Driver's door unlocked is the meaning. I'll call that driver. And in this case, driver's door will be unlocked. The other doors still locked and the alarm is not on. And then, so you've played with these? Who's played with these? What happens if I keep pushing unlock? All of them will open, right? Okay, good. So I have a third state. All of the doors are unlocked. I'll call it the unlocked state. Driver's door still unlocked. Other doors also unlocked. Alarm not on. And then we need one more state, which is if I get scared, someone walks up with a big stick or something, there's a little red button there. And if I get scared, I'm scared to push it because someone will get mad at my car and hurt it. So if I push this button in theory, I'll move into this state, which is the alarm is going off. And that's supposed to scare away an attacker or something. So we'll call that the alarm state. Oh, so now I don't know what to do. What should I do? Should I lock the doors or unlock them? Really? I mean, is that better? So what if I'm running? I mean, the only place to hide is my car. Oh, I can't get in. So I mean, it's not really clear, right? Well, you can't leave it. Well, if you leave it as a don't care, whatever you build is going to make a decision. Could be the worst case. Driver's door is locked. The rest are unlocked. So you don't want to do that. All right. So I'm going to go with the unlocked answer. I'm sorry, with the locked answer. I tend to think that's a better answer. But my point is, this is a design decision. So you as the engineer, you have to make a choice. Your choice might actually make a difference, right? And in some cases, I think in this case, it's unclear enough that both answers might be the right answer in certain conditions, but you've got to pick one. So as an engineer, there are going to be a lot of design decisions. You can build anything you want, but realize when you're making a decision, because maybe later you'll say, well, I made this decision, we could change it, right? And go back and change the system. Okay, so we'll make those locked. And now the alarm, of course, is going to be sounding. So those are our four states. So this is a list of abstract states. This is what we get when we sit down and think, you know, I could probably build a finite state machine to control this thing. Let me start thinking about the states I want. So this is just an informal list, right? We call it an abstract list. So in particular, we could just list the states, right? We could just write down state names. The human meaning is useful if your state names are too generic. It's useful to make sure you know what you're talking about in those states. Outputs is also optional. But if you map each state to an output, that means your output only depends on the state. Now in this class, we'll always assume that. In general, it's not going to be true. In industry, people won't necessarily just make that assumption. But in our class, outputs will depend only on the states, not on the inputs. So it doesn't matter what buttons I'm pushing, what matters is just the state. The buttons will change the state, which can then affect the outputs. Okay, so we specify transitions using something called an X state table. So let's do an abstract one first. So usually in this part of the design, we just go through and figure out, well, what do we want to be able to do? What's a normal operation? So here's my keyless entry system. And let's just kind of think about it. So normally, I walk up to my car, and I want to open it, right? So I push the unlock button. So that'll tell me, well, if I'm in the locked state, and I push unlock, where should I go? I should go to driver, right? Okay, so that's one of my transitions. And so there's an abstract X state table. It says, well, if I'm in the locked state, and I push the unlock button, I go to the driver state. So what if I'm in the driver state, and I push the unlock button? I go to unlock. Okay, well, that's now my car is all open. So I'll get in, I'll drive somewhere, then I'll get out, and I want to lock it up. So whatever state I'm in, if I push the lock button, what should happen? Go to lock. Okay. And then last, if I get scared, doesn't matter what state I'm in, if I push the panic button, what should happen? The alarm goes off, right? Good. So that's my abstract next state table, right? So what's the problem with this? Yeah. I don't know. My table doesn't tell me. So it's incomplete, Daniel was saying, right? It doesn't tell me everything, right? So some of the transitions that I might want to know about are not defined by that table. And that's okay right now. Eventually, the system that we're going to build is going to be a digital system, and it's going to answer all the questions. So we should be careful. But this table is incomplete, meaning it doesn't specify transitions like the one Daniel asked about. It's ambiguous, right? So what happens if I push lock and panic? Which one do I go to? I can only go to one, right? And it's actually, I mean, that part is actually inconsistent, right? Because I can't go to both. So but it says I go to both. So it doesn't make any sense. Right now, it's just an abstract next state table. What we need to do next is make it complete, make it a real design for a digital system. So we're going to have to specify those things and answer all of the design questions. So we need to make design decisions. It's good to do those early if we know about the decisions we need to make, right? So don't put it off. If you know you're going to need to make a decision, do it early, because your digital logic will define answers for you. So do them early. And then when you're done making decisions, when you're done implementing, go back and see, well, what actually happened if you did leave any don't cares? Make sure that any don't cares you left are actually acceptable decisions. Because if they're not, you can fix it. Whereas if you just assume they were, it might lead to problems. So we can represent the same information as that next state table using an abstract state transition diagram. So let me show you that. So here are four states. We draw them as circles. We put their names inside. And then we start drawing arrows between them. So our first entry in the table was, well, if I'm in locked and I push unlock, I'll draw an arrow, take me over to driver. So in this graph, I represent that as an arc labeled with the input. So similarly, if I'm in driver and I push unlock, I go down to unlocked. I said from any state, if I push lock, I go to locked. So you can see here is our first self loop. So the black lines are the third element. This was the first, the second line of the table. This is the third lines, all four of these arcs. And then the last line of our abstract state table, our next state table, was the panic button. That in any state, I go from along the red arrows into the alarm state, including another self loop down here. Same information, also incomplete, ambiguous to some extent, and inconsistent. I actually broke some of the inconsistencies, I guess, because I made these self loops instead of just leaving them open. Oh, no, it doesn't, because it doesn't say what happens if you push both lock and panic at the same time. Yeah, so that's a good question. So Mohammed's question is, well, why don't we just do what we've done before with the glue logic and prohibit more than one input? That's one answer. I'll use actually a prioritization scheme, but we do need to do something to make this a real system. We could leave it open, probably not the safest thing. We can make decisions like one button at a time, or we'll ignore your buttons, or we can make a decision like prioritization. We will need to do something. Good question. Yeah. I'm sorry. Yeah. So that's a design decision that we haven't answered yet. So the question is, wouldn't pushing lock and panic lead to the alarm state only if we choose to make it so, or we happen to have it be so? There's nothing in this diagram that says if you push two buttons, what happens? So panic is a button. So if we push lock while we're in the alarm state, according to this diagram, we turn the alarm off. Yeah, and that's already a design decision too, right? That we'll come back to briefly later because one other question is what happens if you push unlock while you're in the alarm state, which is not answered here. Yeah. Okay. Yeah. So this diagram, just like the previous one, is the same information, right? It leaves the same questions unanswered and leaves the same ambiguities and inconsistencies. There's no difference. Just this is a graph that was a table. Same information. Okay. So exactly the same information. Neither is complete. So now what do we need to turn this into? Bits. I love bits. I'm sorry. All right. Time for bits. So how many bits do we need for the state? Two. Good. Four states. Log, brace, two or four, rounded up is two. Okay. So we'll call them S1 and S0. S stands for state. So we've got two bits of state. We'll call them S1, S0. What about outputs? There are three of them, I think. So we've got driver's door. We'll say one means unlocked. So zero means locked. Remaining doors, which will be R, and alarm, where one means your alarm is sounding. What about inputs? Three? Do you have a question? Okay. So unlock button, one means you pushed it. Some human pushed it. L, lock button, one is pushed. And P for panic button. So three bits of input. Okay. So now we can pick a representation and rewrite our list. So here's a representation. The order in this list doesn't matter. So all I've done is I've rewritten my list of states with the representation and with the output bits mapped into the correct meanings of the output bits themselves. Okay. So I have the lock state, which I'll represent as 00. S1 is zero. S0 is also zero. DR and A, both of these are locked and the alarm is off. In the driver state, I'll pick 10 as my representation. The driver's door is unlocked. The rest of the doors are locked and the alarm is off. Same things down here. Just transcribing into bits according to the meanings that we decided on the last slide. So the order doesn't matter. This is sort of a KMAP order, right? So it'll make life a little easier if we copy these things into KMAPs. So you may realize, of course, that the representation itself does matter, right? So your representation will affect the logic that you need. So for example, if you go to try to map these three functions from S1 and S0, then depending on how you pick your representation, you'll have more logic or less logic. So there is something in that. And also the next state tables, we'll have to calculate the next state from the current state and the inputs. There again, the logic will matter. The representation will matter to the logic. Okay. We'll talk more in maybe the end of the week or even next Monday about how to pick. So we're going to introduce a little more notation. So we're going to put pluses after S1 and S0. What that means is the value in the next clock cycle. So remember, we're feeding logic into the flip-flops, into the D inputs. Those we're going to call S1 plus and S0 plus. Those will be the value of the state in the next clock cycle. So most of the design work is then, after we've gone through all of this process and made the system fully digital, is then just going to be solving for S1 plus, S0 plus in the outputs, building that logic and plugging it together. So those are the examples you've seen in the homework. In the homework, you're just asked to analyze them. But it's basically just some finite state machines where you're calculating the next state as a function of the current state and the inputs, and then the outputs as a function just of the state. So we will typically use binary order in the tables I'm going to show you next. We're going to use gray code order on our axes just for ease in copying the K-maps. So here's a table. Where should we start? Didn't answer some design decisions, right? Okay. So back up for a minute. Let's go answer some design decisions. So let's do these early. I mentioned this before, but we've got a bunch of decisions that we haven't answered yet for our system. So before we start filling in tables, we should answer those questions. So for example, what happens when the user presses more than one button? That we kind of hinted at. This actually, someone asked as well, or asked a similar question, what happens when the user presses unlock in the unlock state? So sometimes you'll be able to list most of these questions. Sometimes you might miss some. Things may come up later. Design decisions are going to shape your design. So you should try to make them early. They can actually conflict with one another. You might make one decision, write it down, come back later and say, well, I can't make both of these decisions the way I want to. I have to pick one or the other. So it's good to resolve that kind of stuff early and not leave things until you forget about them. So let's go through and answer all the questions we can. So we're going to start by prioritizing the buttons. So we know there's three buttons. We know we haven't thought about what happens when more than one of them is pushed. So now we're just going to answer. So we're going to say panic has priority. So if you push the panic button, you're done. Whatever happens when you push the panic button is going to happen. The other buttons are ignored. If you didn't push panic, but you push lock, then we're going to do what happens when lock happens. So we're just going to second priority on lock. And then unlock is only going to matter when you don't push the other two buttons. So that's our priority scheme. So now we can go fill in our table. So here are the panic states. So let me look at this table. This is the next state table. You can see that on the left, I have the current state, which is my two bit S1, S0. And then across the horizontal axis, I have eight columns, one for each possible combination of the unlock, lock, and panic button inputs. And so these four columns here, these two and these two, are all with the panic button pushed. So where should I go if the panic button is pushed? To alarm state, which is 01. So I just fill those in. So now I'm half done with my table. Make sense? Okay. So that's that. Let's go for lock button. So lock button, see all of the ones ending with one are the panic button. So these, I didn't push the panic button, but I pushed lock. Over here, I didn't push either one. Over here, I didn't push either one. So what should happen if I push the lock button? Go to 00, the lock state. So then I can fill in those. So that's good. That was easy. So what if the user doesn't push anything? Yeah, it would probably stay in the current state. We didn't actually specify that, did we? We never said, well, if they don't push anything, we're just going to stay put. We probably all kind of thought about it, but we didn't say it. So it's really kind of a design decision. Probably most of us would have all agreed on, but it's worthwhile making it clear too. So let's all agree, if you don't push any buttons, stays in the same state. Actually, later in the semester, we'll say maybe after five minutes, we should turn the alarm off. And we'll talk about extending this design to do that kind of thing automatically. Question? Okay. All right. So what transitions did we define for unlock? Well, there was one up here, right? So if it's locked, you said we should go where? Driver. Okay, that was, I think, one, zero, right? What about from driver? Unlocked. That was one, one. What about these two? More design decisions? Okay. So what should happen? Maybe just stay unlocked if it's already unlocked, right? So here's a slightly more important one. What happens if you push unlock when the alarm is sounding? Oh, sorry. This is our earlier design decision. Sorry, a little typo in the notes. We still have a design decision to make, but it's not this one. So the question is, should we unlock the car or should we assume that people are still panicking and maybe they hit the wrong button? I mean, they need to be able to turn the alarm off, but do we want them to do that automatically for any button or do we want them to push the lock button only? And so I kind of felt like, well, why don't we make them push the lock button? At least then they're cool and collected, right? If they're just hitting buttons, maybe unlock should not also turn the alarm off. So another design decision, but what it results in is from alarm, we stay in alarm. So if you push unlock, it doesn't turn the alarm off. And then similarly from unlocked, we stay in unlocked. Do you have a question? No. Okay. Sorry. All right. So now we're done. We've got our table. So you know how to fill it in from here, right? The rest is KMAPs, expression, and logic. So just to walk through it a little bit. So we would start by expressing S1 plus and S0 plus in terms of our five variables. So you can go look in Wikipedia, do five variable KMAPs if you want to, or you can play the trick we played with our letter checker. And you can say, well, let me just pick one of these variables and split this up into two four variable KMAPs, right? And then I can put those together with AND gates, or I can put them together with a MOX, right? There are lots of ways to build it. But basically need to build those five, two, five variable functions. Then I'll go express DRNA, the output bits, in terms of my current state. Those will be substantially simpler. So I'll build all of those combinational logic functions, take the S1 plus and S0 plus expressions from this table back here, and feed those into my flip-flops, right, to the D inputs of my flip-flops. And then I'm done. That's it. So you should do that as an exercise. We used to make that a homework problem. I don't think it'll be a homework problem this time. But you should be able to do that, right? It's basically combinational logic at that point. You've been doing that for several weeks now. And this will be a little bit more of a challenge, but it should be doable. So this is the last step in all of our finite state machine designs, doing things you already know how to do. All right. So I want to show you a couple more things before we end for the day. So we can also redraw our state transition diagram. So a complete state transition diagram has the same information that we just put into the complete next state table. So it's defined in terms of bits. So what it's going to look like is this. So we'll have our states annotated with both the state ID as well as the outputs. So we've got the state ID in front of the slash and the output bits after the slash. So often, we'll just put 0s and 1s. So it'll be implicit that the bits before the slash are the state bits, and the bits after the slash are the output bits. And the order of outputs has to somehow be known. So there has to be some order you've decided on, or maybe you write it on the side of your graph or something, so that everyone knows the first bit is D, second bit is R, third bit is A in our case. The arcs then are going to be annotated with input combinations. So for us, that's the unlock button, the lock button, and the P button. Sometimes people will write those in some order. Sometimes people will just mark them with the bits. And then again, you need to realize you should put them all in the same order, and you should say what the order is somewhere. So let's actually do that. So here are four states. So you can see now, instead of just having the name of the state, we actually have the state ID bits, and then the three output bits for all four of the states. And then we can start to annotate our arcs. So remember we said, well, when you push unlocked, this was our first rule, transition rule, in the abstract next state table. When I push unlock, and I don't push lock or panic, so now it's explicit. When I push unlock but not lock or panic, I go from locked to driver. Similarly, when I push unlock but not lock or panic, then I go from driver to unlocked. When I push unlock but not locked or panic, or I don't push anything, then I'll stay here. Now in order to save ourselves a little time, often we will shortcut this kind of notation. So I could write this input bit here as x00. So in this case, I've got a don't care for my u input. So what that means, I could have the 000 pattern or the 100 pattern, and both of those will come back to the unlocked state. So I'll mention in a minute or two, you have to be a little careful with that notation. But you can shorten the number of bit patterns you have to list. Turns out when we get over here, we're actually going to have six different patterns. So I'm going to start using the shortcut notation on this diagram. In the notes, it's got all the patterns listed for you. So if you want to see it in the notes with all the patterns instead of the shortcutting, that's fine. Okay, so look at the notation on all of these locking arcs. So you can see that I don't actually care about the unlock bit on any of them. So unlock doesn't matter on these three. Also for this one, unlock doesn't matter so long as I'm pushing lock. So if I'm pushing lock but not panic, I'll go to the locked state from any state. Similarly, I've got 000 listed up here. That was the self loop when I don't push anything in the lock state. So in this full complete state transition diagram, you need to have all possible arcs. But you can use the shortcut notation, as I'm showing you, to reduce the number of arcs you really have to draw. Otherwise, you'd have eight times four, 32 different arrows, which is a little hard to follow. So these things can get messy if you're not careful. All right, so this is the last one here. Most of these are XX1, which means I don't care about unlock, I don't care about lock, as long as panic is one, I'm going to go down into the alarm state. So XX1 here, XX1 here, XX1 here. Here on the left, it's actually six different states, XX1 and X0X. So if I'm pushing panic, it doesn't matter, I stay in the alarm state. Similarly, if I'm not pushing locked, I'll stay in the alarm state. Not pushing lock, I'll stay in the alarm state. So that's actually six different states. Each of these is, I'm sorry, six different input combinations. Each of these is four. So we have to be a little careful, right? Because there's actually, in that notation, there's actually overlap between these two patterns. But that's okay, because they're going to the same place. So if we're not careful with the input abbreviations, we might end up with a diagram that's still incomplete, we haven't covered everything, or even inconsistent, meaning we've got arcs going in different directions with the same input combination. So be careful how you use these abbreviations. The example I wanted to show you, the last one we looked at, was this labeling, and the patterns X01, 001, and 101 both match each of these patterns. And so that's okay in this case because they both go to the same next state. If they're going in two different directions, that would not be okay. That would be inconsistent. We wouldn't know where to go in our state of the world. So that's it for today. Thank you, and I'll see you on Wednesday.\"},\n",
       " {'ECE120-2016-09-28-LEC-15-slides.mp4': \" logic. And now it's 3 o'clock. So I'm going to get my magic device out. So what we're going to do today is wrap up the new comparator design, and then do a two's complement comparator, and then do another bit slice design to check whether a number is a power of two, an unsigned number is a power of two. And we'll do two bits at a time with that one. We may or may not get into talking about building with abstraction. So the first thing there will be a subtractor, and then doing something to check whether an ASCII character is an uppercase letter, and then looking at multiplexers. So that'll carry us basically through the end of the day on Friday, and then next week we'll start doing sequential logic. All of this is what's called combinatoric logic, combinatoric design. So far, through the end of this week, we haven't talked about how you store bits. So next week we'll talk about how you actually store bits on the chip. So on Monday, we'd looked at this, and there were a few people that asked me afterwards. So I wanted to just make sure everyone understood what we were doing. So we did path to path, input to output for each of the inputs here that matter. So remember, C0 doesn't affect Z1. But for each of the inputs that affect Z1, we calculate the gate delays from input to output. And then we went to this diagram, and I just showed you the answers. So let me also show you a table. So what we're really doing at each of the steps in this slide is this whole table. So the inputs for bit slice 0, the one on the right, are available at time 0 for A and B, and at time negative infinity for C1 and C0. To calculate when we get Z1, we then have to go through each of the inputs, add the delay from input A to Z1, which is plus 3 for A, plus 3 for B, plus 2 for C1, and not relevant for C0. Add those to the time A, B, and C1 become available to get the minimum time that Z1 will be available. So then we take the max over these three, and that tells us when we'll get Z1 out of bit slice 0. Similarly, for Z0, we add the delay from A to Z0, B to Z0. Each of those is also 3. We get 3 and 3. C1 is not relevant to Z0. C0 is plus 2, but negative infinity plus 2 is negative infinity. So the maximum here are also 3. And so that's where we got these numbers, the 3 and the 3 for the first bit slice. And then similarly, there's another table for bit slice 1 where you say, well, A and B are both still available at time 0. C1 and C0 are now available at time 3 for bit slice 1. So 0 plus 3 is 3. 0 plus 3 is 3. 3 plus 2 is 5. So now that's where we get Z1 coming out of bit slice 1 at time 5. Same reasoning for bit slice 1, Z0. So that's where these numbers in the blue circles came from. So I know at least a couple of people were confused about that. So I wanted to go through the detailed process and make sure you understand how we get those. We do have to think about all the paths and take the longest one across all of the possible paths. Make sense? All right, so that's just a little bit of review and a couple of new slides. I put those back into the ones I posted, too. So I think those are up if you look on the video lecture now and today's lecture, but also in the slides you can grab online. So overall, we found that compared to the original design, we reduced our area by about 40%. Each of the bit slices was area 12 as opposed to area 20. And we increased delay overall by one gate delay. So it took us 2n plus 1 instead of 2n. So a pretty good trade off. But you might wonder, well, can we do better than that? So we played with algebra for a couple minutes. We got a better design by 40% area, about the same delay. It's not quite as easy. So for example, you can design a slice that looks at two bits at a time of A and B. So I actually did that in the notes for you. So if you want to look at that, you can go look at section 246. That'll give you better delay, because generally you can reduce things to two-level logic. Now at some point, you'll have too many inputs, and you'll have to go beyond two-level logic. Too many inputs to a gate, I mean. But you can do two. And so you can get basically delay two for two bits instead of delay two for one bit. So overall, you'll cut your delay in half for the whole design. And it doesn't get too much bigger. And you're handling two bits, so you only need half as many bit slices. But of course, it's a much more complicated problem. So then you can go all the way to the extreme and say, well, I want to do a 32-bit comparator. Let me just write down the Boolean expressions. I've got 64 bits of input. I'll go solve a 64-input KMAP. Maybe not. You'll do a lot of algebra, and then you'll get answers. Those answers will give you a better design. It'll probably be smaller and faster, but it'll be a heck of a lot of work. So there's a trade-off between human work and complexity of the design, which you're probably going to make some mistakes if you really try to do that for 32 bits. And then you'll have to go figure out where you made mistakes, versus better area and delay. So those are the trade-offs. So let's do a 2's complement comparator. So is this the same as unsigned? So for unsigned, for example, we have this 4-bit unsigned number 1, 0, 0, 1 is greater than this 4-bit unsigned number 0, 1, 0, 1. Is the same true if it's 2's complement? No, why? So 1, 0, 0, 1 is negative. This is non-negative, so this one has to be less. So should we just start over? Throw it out, start over. I like doing K-maps anyway. It'll be more K-map fun. Let's try a little harder. So what if the 2's complement numbers we compare are non-negative? Can I just stick them in an unsigned comparator and get the right answer? I can, because they both have a leading 0. That'll get equal. And then the rest is just like the unsigned representation. So maybe we can just look at the sign bits and figure something out. So let's make a table of sign bits. So here's the four possible combinations. I put a sub s for a sign bit, b sub s for b sign bit. I interpreted those meanings for you here. And then I put in the solution you already found, which is, well, if they're both non-negative, just put it into the unsigned comparator. You're done. All right, so how about this line? So if a sign is 0, b sign is 1, which one's bigger? a, right? Good. And if a sign is 1, b sign is 0, which one's bigger? b, good. And if both of them have sign 1, which one's bigger? Really? I don't know. It's too hard for me to figure out in my head. All right, so maybe you guys figured this out in your head already. But for people like me, they're a little slower. I've got some more slides. So to me, maybe that works. But are the rest of the bits you can just compare? Let's make sure. So remember our simple rule for translating 2's complement numbers into decimal. We said, well, the value of a negative 2's complement number, actually this works for all 2's complement numbers, is this place value here for the leading bit is negative. So negative first bit times 2 to the n minus 1. So if a is negative, then a n minus 1 equals 1. And if we interpret those same numbers as unsigned, those same bits as unsigned, what we'll get is the 2's complement value plus 2 to the n. So for an unsigned number, this is plus a n minus 1. So we'll have 2 times this difference between the 2's complement value v sub a and the unsigned value v sub a plus 2 to the n. That's actually by definition of 2's complement. So either way, you want to remember that. So if we do what people suggested and we just feed those two negative numbers in, well, what happens? So we end up comparing v a plus 2 to the n with v b plus 2 to the n, and we get an answer. So let's say that answer, for example, is less than. Well, we can just subtract 2 to the n for both sides here. So if this is true, so is that. And it didn't matter whether the operator in the middle was equal or greater than or less than. Same operator, we can subtract 2 to the n for both sides. So whatever our unsigned comparator says, that's actually the right answer also for the 2's complement. So some people already saw that, but I wanted to work through it to make sure it was clear. So we have the right answer for 2's complement, and the same result holds for equal and greater than. We'll fill that into our table. So are we done? Can we just put these two unsigned number, I'm sorry, 2's complement numbers into the table? Yeah. Yeah. Yeah, so these middle ones, are these right for unsigned? Is this what we get out? No, if I put these unsigned leading bits, do I get a greater than b? I get a less than b, right? But for unsigned, this is a leading 1, the leading 0, well, that one's bigger. b is bigger. For 2's complement, a is bigger. So it's the wrong answer. So how about we just flip those two bits? Why don't we just cross the wires? So on the sign bits, just flip them. Is that going to work? So if we do that for these middle cases, for a is 0 and b is 1, the sign bits, we feed in 1 for a and minus 1, and 0 for b. So we just cross the wires. And our unsigned comparator, of course, is going to produce a greater than b. You look back here, you say, well, that's what I wanted. And for this case, a is 1 and b is 0. We flip the wires. So we get a is 0, b is 1. And that'll give us, for unsigned comparison, well, b is bigger. So a less than b. And that's what we wanted. So what about the other two cases? So when you design it, if you want to build a 2's complement comparator, you simply put the a bit into the b input and the b bit into the a input. It's just wires. Just like you want on your protoboard. You just say, OK, swap them. No, just for the sign bit. Only for the sign bit. Yeah, the rest we're going to compare as is. What about a equals as equals bs? Did we just break those? Why not? They're the same. Either they're both 0, and you put this 0 in over here and this 0 in over here. They're both still 0. Or they're both 1, you put a 1, this 1 over here, this 1 over there. They're both still 1. So it doesn't make any difference. So that's it. So in other words, if you want to choose complement comparator instead of an unsigned comparator, you take the unsigned comparator design and you put the b sign bit into the first bit slice, the highest, most significant bit slice in the a input, and vice versa. And that's it. That's now a choose complement comparator. Yeah, Nathan? What would be the point of that? So probably it would be implemented in the library. Actually, you would write a comparison operator in system barrel log, which is somewhat like C. And so the comparator that got instantiated would be the unsigned one if the things you were comparing were unsigned, and choose complement if it were choose complement. And so the difference would simply be those two wires would be swapped in the choose complement. So in terms of our original diagrams, it depends whether it's visible to someone doing programming. So if you had a compare instruction, for example, and you had two different compare instructions, you could implement that with two different comparators. You would probably do something more like what's on this slide, which I haven't described yet. So what about just using one comparator to do both kinds? What do we actually have to do in order to make that work? Well, so in order to tell the comparator what kind we want, we need some kind of signal. So let's make up a signal. We'll call it s. And that'll let us select between choose complement, which will be s equals 1, and unsigned, which will be s equals 0 comparison. So in that case, I claim that all you need to do is XOR s with the most significant bits, the sign bits of a and b, and that'll give you the right answer. So if you tell it, OK, I want unsigned comparison, and the sign bit you XOR with s, well, s is 0. So then it'll go in unchanged. So clearly, that one works. And then I claim if you XOR for choose complement comparison, you XOR both of the sign bits with 1, you also get the right answer. So I'll let you figure out why. It leverages the flexibility in the design. So if you solve this with a truth table, and you don't put any don't cares, which you kind of have to do because you actually do care about every answer, then you'll get a more complicated design than this. So you might want to just work through it and see why it works and what we're taking advantage of. All right, so power of 2. So I wanted to do one more bit slice design for you. So let's think about how we do a power of 2 checker. So how can we check whether an unsigned number is a power of 2? What is a power of 2? Yeah, Mohamed? What does it look like? Yeah. Yeah, only one bit is on. Power of 2, 2 to the n, then that's a place value in binary, in base 2. So one of our bits will be a 1. So here, for example, for 5 bit unsigned, these are the five powers of 2 you can write in 5 bit unsigned. So you can see there's 1, 2, 4, 8, and 16. And all of them have 1, 1 bit, which is 2 to the n for some n. In order to check whether an unsigned bit pattern is a power of 2, we need to know, well, is there 1, 1 bit in that number? So I claim we can do this as a bit slice design. So if I ask this question, so is A, which is all of these bits, a power of 2, how many answers can you give? Two, right? It would be yes or no. So here's a trick question. How many bits do you need to pass between slices? I'm hearing 1s and 2s. 2 is right. Why? Answer only takes 1. Is this a power of 2? You can't say, well, maybe. Say yes or no. So the question you need to ask, though, is if you look at the rest of the bits, so if I have a number that has n bits in it, so this is n minus 1 bits here. So if, for example, these bits are a power of 2, can the whole number be a power of 2? Actually, I put the wrong answer. It says no. It could be a power of 2. This would have to be a 0. So if this were a 0 and this is a power of 2, the answer is yes. So sorry, my slide's wrong. But you could tell. So if I told you this is a power of 2, then by looking at this bit, you could say yes or no. If it's another 1, the answer is no, because that'll mean there's a 1 here and a 1 somewhere in here. And you know that's not a power of 2. Whereas if you get a 0 here and this is a power of 2, the answer is yes. So you know the answer. So what about this case? So if I tell you these lower bits are not a power of 2, can you tell me whether with the extra bit it is a power of 2 or not? You can't, right? Because you don't know what these bits are. You just know they're not a power of 2. So it's impossible for you to answer that question. So you need more information. So let's figure out what else do we need to know. So imagine we just finished n minus 1 bits. So the answer's coming out of a bit slice. So under what conditions can our number a be a power of 2? So I claim there are two cases. So one case is for our bit slice is a 1. And in that case, what do we need for the rest of the bits? They need to be 0s, right? Because a power of 2 has 1, 1. So if we've got the 1, everything else had to be 0. And if we've got a 0, the rest has to be a power of 2. So we need answers to both of those questions in order to be able to pass the next answer out of our bit slice. So we need to know whether the rest of the bits form a power of 2, this question. But we also need to know, so that was our original answer. But we also need to know the answer to this question down here for number 1. Is the rest all 0s or not? If I tell you the answers to both of those questions, then you can tell me for the 1 bit you get in this bit slice, 1 or 0, whether the answer is a power of 2 or not. Yeah, Eric? AUDIENCE 1 5, 8. Yeah, so remember, we're trying to build a bit slice design. So we have to make a decision based on 1 bit and the rest. So we want to ask, how do we actually prove an inductive step? So remember, when we do bit slice designs, this is proof by induction. So we need to be able to look at 1 bit and then the rest. And so the question is, well, what possible answers do we need summarized out of the rest in order to make our decision and do that inductive step? And so there are two possible cases for a 1 bit. And for this case, we need the answer to this question. Are the rest of the bits all equal to 0? And for this case, we need the answer to this question. Are all of the rest of the bits a power of 2? So if you tell me both of those answers, then I can design the bit slice that answers the question. Yeah? It is. And that's our inductive step. If we assume that we can answer this question, then we can answer this question. Wow. So yes. And I will not fall into the trap of going down to n minus 1 and proving it. We'll assume it works. Yeah? About the bit top, does it have a power of 3? Yes. The remaining bits form a power of 2, which means there's exactly one 1. Any other questions before we? Good. OK. So the yes cases actually don't overlap. So the yes cases are everything's 0, and everything else is a power of 2. There's no overlap there. Everything being a power of 2 means there's one 1, and all 0s means 0 1s. So those two don't overlap. The no cases, we actually don't have to do anything else to further separate them. So all 0s, again, means no 1 bits. Power of 2 means one 1 bit. And the other possible case is there's more than one 1, which means no to both of those questions. If there's more than one 1 in the rest of the bits, it's not a power of 2, and they're not all 0. So we're done. So those are the three cases we need. We need to convey one of these three answers. In all of my bits, there's 0 1 bits, one 1 bit, or more than one 1 bit. And if I convey that information as input to my bit slice, my bit slice then can convey the same information to the next bit slice. So three possible answers or messages. So we need two bits. Make sense? All right. So here's a representation. Is this the best one? I'm not really sure. I didn't compare them all by hand. So others may be better. It's a pretty good one. So what is it? So no 1 bits, we're going to call 0 0. One 1 bit, we're going to call 0 1. More than one 1 bit, we're going to call 1 1. And I'm not going to use this 1 0 pattern. I mean that if you pick a different way of putting these messages into these 4-bit patterns, you might get a better, smaller, faster design. Probably not faster, but maybe smaller. All right. So let's think about the bit slice that we're going to build. So we're going to actually look at two bits at a time. So let's call those A and B. These are bits of our number A, but I'll just call them A and B inside the bit slice. The inputs from the previous bit slice, we're going to call C1 and C0, just like we did in the comparator. And then just like we did in the comparator, we'll call the output Z1 and Z0, just to distinguish our inputs from the outputs. Both will use the same representation. So the input meaning and the output meaning will use the same representation. The direction for this doesn't actually matter. We just need to know, is there a 1 bit, 1 1 bit somewhere in there? So it doesn't matter whether we start at the big end or the little end and go either direction. It's OK. So let's fill in a truth table. So we'll start with a case of the two bits from the number being 0. And we've got four possible cases. So if we see C1, C0 is 0, 0, that means there are no 1's in the rest. 0, 1 means there's 1, 1. 1, 1 means there's greater than 1, 1. And 1, 0 should never happen. So in the case of A, B equals 0, 0 and no 1's, what message should I pass? No 1's, right? Because there are no 1's that I see. And before me, there were no 1's. So there's still no 1's. What about if there was 1, 1 in the rest? Also 1, 1. The 0, 0 adds no new 1's. So we just copy the message over. What about this one? Also more than 1, 1. Oops, sorry, wrong order. More than 1, 1. And this, of course, is don't care. We should never see that input pattern. So we don't care about the outputs in that case. So we can then fill those back in. And of course, we're just copying the bits, since the meanings are the same, from C1, C0 to Z1, Z0, except for here, where we don't care what the outputs are. So we'll get a little bit of flexibility in designing our bit slice. All right. So then the next quarter of the truth table. So if we've got a 0 on A and a 1 on B, and the meaning is no 1's, what message should I pass? 1, 1. I've now seen 1, 1. What if I saw 1, 1 before, and I got a new 1 in B? More than 1, 1. Good. Hopefully, I got the right order, but I feel like I didn't. I didn't. OK, sorry. What about this last one? Still more than 1, 1. No matter how many 1's we see, there's just more than 1. That's all we care about. So we don't keep track of whether it's 2, or 5, or 100 1 bits. It's not a power of 2. It never will be. So more than 1, 1. So we can fill in the bits. So 0, 1 for 1, 1. 1, 1 for that. XX, 1, 1. Is this case any different than the last one? It's not, right? A and B are just two bits out of the number. It doesn't matter which one is a 1. So if I flip through these, I've got exactly the same truth table as I did for the previous slide. Exactly the same message is out. What if I see A and B both equal to 1? They're all greater than 1. All this message out, except for don't care. All right, so that's the design. We can copy that into KMAP. So here's the first one. I liked POS for this. So let's do a POS solution. So where are the loops? Yeah, we're going to do the 0's for POS. So let's see. So how about this one? Where should I? Just up, right? I can't go down, can't go right, can't go left. So I'll just go up. I can do a square. Oh, the next one you want to do is square, yeah. OK, so what is this factor here first? OK, so remember when you read POS factors, you want to complement, right? So this would have been C1 prime in an implicant, but in a POS factor, it's going to be C1. And then that would have been A prime B prime, but here it's going to be plus A plus B, because we want to complement the literals in the POS factor. So C1 plus A plus B. What about this one? I guess I should have let you say what that was, but someone already said it in front. So there is another POS factor, right? We need to cover this 0, and so we can go left and we can go up. So we'll go both directions at once and get this purple square that wraps around. OK, so I hear a few people saying C0 plus A. And what other? Four corners. Let's see. So I've got one more 0 to cover. I can go right and wrap around. I can go up, get this x. You can actually do both at the same time, right? So good, four corners. What is that one? OK, so I'm hearing some C0 or Bs, right? Good. All right, so we got those three POS factors. So there's Z1. Those three POS factors. Yeah, so I wanted to mention, I didn't mention this before, and I didn't put it in the slides, but when we're solving POS, you can also think of this as Kyle somewhere, probably. There he is. As Kyle reminded me in office hours, you can think of this, if it makes it easier for you, think of this as F complement. What is this one? Z1 complement. So imagine replacing all the 0s with 1s and all the 1s with 0s, and then solving that as SOP. If you do it that way, you get Z1 complement, which you can then apply generalized DeMorgan's and get the POS form. So that's actually fully mathematically equivalent. So if it makes more sense to you, by all means do it that way. So in other words, replace 0s and 1s, then these 0s become 1s. Circle the 1s with the same rules, and then just apply generalized DeMorgan's to complement what you get. Yes? Except if you circle 0s, do remember to change it into this form. The generalized DeMorgan's will change it into this form. So you can either do it by hand after circling 0s, or you can solve the complement function and then do it with generalized DeMorgan's. That's why I say it's mathematically equivalent. But I think sometimes it might make more sense one way than the other to some people. So I think it's equally valid to understand it either way. Equivalent. That's why I wanted to mention it. All right. Here is z0, k-map. So this one looks remarkably attractive for POS, right? But we'll do SOP. So what are the loops for SOP? Yeah, so we got that 8 in the middle. Good. What else? Yeah, the other middle. Sorry, that was c0. Oh, I didn't do them in the right order. Sorry. OK, we got that one. What is that one? A. And what is this one? B. Good. Actually, if you solve this min term and extend it up to here, you'll get exactly the same form for POS. So in this case, you'll get the same answer, regardless of whether you solve POS or SOP. So this is z0, c0 plus a plus b. And notice that if you write those down side by side, this thing here, you can actually get by adding these two factors together. So you can say, well, z0 is c0 plus a or c0 plus b. So we can reuse those gates. That's kind of nice, a little simpler. So here's the design. It has something new. So the new part is not NOR NOR. You should hopefully remember that when I have a POS, I can just write this as NOR NOR. So that's all these NOR gates are up here, is a NOR NOR design for z1. But this NAND gate down here, if you think about, well, what is that? These are the two factors I called out. If you do DeMorgans on this one, you push the inverter through, you get an OR gate. And that then cancels these two inverters here. So you've got OR followed by OR. But that was what we wanted. So if you do NOR followed by NAND, it's just like an OR gate. So all right, so let's analyze this. So how many literals do we have? Seven, right? Coming in there. OK, and then how many gates? Five. So good. So then we've got a total area of 12. And so remember, though, we're handling two bits of the number. So since we're handling two bits of the number, for an n-bit number, we only need n over 2 bit slices. So the total area is going to be just half of 12 times n, so 6n. What about delay? So two gate delays on all paths. So the total delay through our system, again, we only have n over 2 bit slices for n bits. So the total delay is what? Is just n. So up here in the title, I put the overall total. Yeah, exactly. We're handling two bits per slice. So we only need n over 2 slices. Yeah. So you mean this? Sorry, let me go back. You mean this part down here? OK, so if you look at this structure, so just ignore the upper two gates. If you just look at these three gates down here, this NAND gate by DeMorgan's is equivalent to an OR gate with complemented inputs. So imagine you replace it. You've got an OR here, and you have inverters here and here. Slide those inverters down, they cancel the inverters there and there. So now you have OR gate followed by OR gate. It's just an OR gate. So now you have C0 OR A ORed with C0 OR B, which was this expression here, which then is equivalent to what we wanted. Anything else on this? Yeah. Why I can split the bits apart. I don't understand what you mean by split the bits apart. Sorry. So remember when we did our design, don't remember how far back, I said that I would take two bits out of the number. So I'm building a bit slice that handles two bits. And so that's why if I have n bits, I only need n over 2 bit slices to handle all n of them, because each of the slices handles two. Yeah. So how do you split them? A OR gate? It's algebraic. So you look at the design, and you try to spot common factors. So that's all I did. I mean, I didn't really even have to manipulate it. When we solve the k-maps that way, it's almost obvious. I didn't know you could do that. But and and OR. Yes. Yeah, I mean, you can start by drawing this design in just and and OR. And then when you change it to and and OR, I just cut to the chase and showed it to you. Yes. Is it n plus 1 over 2? Sort of. OK, so the question is, well, what if n is odd? Then you need n plus 1 over 2 slices. So if you had 5, n equals 5, you would need three slices. But what can you do with the extra slice? So you can simply, knowing how this works, you can set one of the bits to 0. And that will give you the right answers. Good question. Yeah. What if you have 5, 0, and then you have n over 2? Mm-hmm. That's what you would do. Yes. Yeah, so again, both area and delay, we only have n over 2 slices because we have n bits. Each one handles 2. So you would keep your n over 2. Mm-hmm. And you keep n. Yes. Yeah, that's right. So you would take your n bits. You would feed 2 into the first bit slice, feed 2 into the second bit slice. Yeah. Yeah. So remember that if I just pick one of these a and b inputs and I put a 0 in, that doesn't affect my answer. Right? Yeah, so I just take the bit slice where I don't have another bit of n to feed it and I put a 0. Then I still get the right answer. Yeah, that's very much dependent on what we're trying to do. So if you had something, a design that didn't allow you that kind of simple answer, you would have to also design something to handle one bit. And you'd have to use that one to handle the odd. And yes. All of them? Typically, yeah. Typically. But usually, it's not a big deal to try to handle two bits at a time. Trying to do three is a little weird, because then you probably also have to do another design in most applications. All right, so we don't get an answer. We said we're going to build a power of 2 checker. Out comes this two bit thing. It has some representation. And we say, well, wait a minute. We want to know is it a power of 2 or not. We don't want to know are there zeros, are there more zeros, are there ones. We want to know is it a power of 2 or not. So we just produce this count. It's 0, 1, or many. We want yes. So I'm going to call that p equals 1, or no, p equals 0, power of 2. So if you look at the representation, which I guess I didn't copy up here for you, but if you look at the representation, from that representation, the two bits coming out of the last bit slice, you can simply connect z1 and z0 with an XOR gate. And that'll be p. So if z1 XOR z0 is equal to 1, that means it's a power of 2. And if it's not, if it's 0, that means it's not a power of 2. Where's my last representation? Maybe here. All right, there. So 0, 0, look on the input side. It gives a full representation. 0, 0 XORed together is 0. That means no ones. That's not a power of 2. 0 XOR 1, that gives 1. That's because there's 1, 1. That is a power of 2. And 1, 1 XORed together gives 0, also not a power of 2. We never see this one. This one would also say power of 2, but it's never generated. OK, so let me skip ahead to the slide. Sorry, pulled that up before. All right, so that adds one extra gate delay. So the real design, including getting the answer out at the end, is n plus 1 gate delays. All right, so let's think a little bit about building using some of the components we've already designed. So you can always go down to the expression level, down to the KMAP level. Maybe you can't always use KMAPs if you have a lot of variables. But you know what? You know the underlying algebra. So if you have to, you can do that. You can get your computer to do that. But it takes a lot of time. And it's not very robust. So if you make a change to what you want to do, then you have to redesign the whole thing and do all that work again, as opposed to making some high-level change. And maybe that's a little easier. So you know how to do that process. But you rarely actually need to do that level to get a satisfactory solution. So a lot of the time, the things we're working on, you don't need to get the optimal answer. You just need to get an answer that works, because other parts of the system are going to be slower, are going to take most of the area anyway. And so you just need an answer that works. Get it very simple, get it correct, get it designed, and put it in. So instead, we can take an approach where we say, well, let's use abstraction. We know how to build things like adders, comparators. Let's just put some things down and get the answer out. And then if our part is the thing that needs to be optimized, we can go back and optimize. So we can use extra level of logic to describe our functions intuitively also. There are also CAD tools. So the tools you'll use once you get into 385, to some extent, the ones you're already using, the mentor graphics tools, can also help you with your designs. So they can do low-level optimizations for you. Often, they can do it better than you can, not because they're smarter than you. It was just some engineer, probably not even an Illinois engineer. So probably you could do a better job. But it'll take you a lot of time, whereas a computer can go look at a whole bunch of stuff really, really quickly and find the best answer out of all the things it looks at. So it might take less than a second, whereas you could spend a month looking at all the possible ways to do it. You'd find a better answer, but it still took you a month. It took the computer a few seconds. So it's probably not worth your time in most cases. So context is important. So if you go talk to your mechanical engineering friends and they say, oh, I just got a 0.5% boost in internal combustion engine efficiency, they're probably going to win some major awards for that. That means that everyone in the room's gas consumption just went down by 0.5%. That's actually a big deal, because that's a fairly established field, and that's a big number for them. They don't get that every year. They don't get that every decade. So in our field, engineers spend a lot of time doing things like improving the designs of arithmetic units and memory, because those are the things we use a lot of, and we use them very fast. And so if you can improve those designs a little bit, it'll matter. Or doing things like improving CAD tools' ability to optimize. So now all engineers who use the CAD tools get that benefit. So it depends on context. Oops, sorry. There's a famous computer scientist, Tony Horae, or Hoar, I guess. I'm not quite sure, actually. Never met him. But he said premature optimization is the root of all evil. So sometimes this gets over-interpreted. So the interpretation that you'll see a lot is don't spend optimizing something that's likely to change. So if you're doing a prototype, don't go optimize as much as you can, because then, well, gee, we need something slightly different. Well, throw away all your work and start over. So don't spend time on that. Or something that really doesn't contribute much to the overall system goodness. So if you optimize something that contributes 1% of the time, no matter, even if you make it go infinitely fast, you still have 99% of the time. So be careful about spending your time on stuff that just doesn't matter overall. The flip side of this is don't ignore scaling issues when you're choosing algorithms. So for example, let's say I decided, hey, I want to return your midterms to you. So one algorithm I could use is, well, I've got 95 people in the room. So I'll start over here. And I'll say, here's test number one. Is this your test? No. Sorry. Is this your test? No. Is this your test? No. And if I do that, then I've got roughly 95 squared questions to ask. Instead, I could alphabetize them and have you line up in alphabetical order. And that's actually easier than it sounds, because you can compare it locally. So there are better algorithms. So don't ignore scaling issues. And then also, don't design in a way that prohibits or inhibits optimization. So usually, what that means is you think of things and you build abstraction boundaries. What I'm building is an adder or a comparator. How I then implement it, it doesn't matter. If I need my adder to go faster, instead of a ripple carry adder, I can go do a tree-based adder. So if you define clean abstraction boundaries, then that enables later optimization. If you mix everything together, it makes it very hard to go figure out how to optimize it later. All right. So let's do a little example. So let's start with a subtractor. So how do we subtract as humans? So let's say I ask you to do this subtraction. What would you do? Well, you take the 10's complement, right? The 9's complement and add 1. So the 9's complement would be 8, 9, 9, 9. 8, 2, 1, 9, 9. That one plus 1. 8 plus 1. OK, help me out here. Let's add it up. 5 plus 9 is what? 4 carry the 1. 1 plus 4 plus 2? 7. 3 plus 1? 4. 2 plus 9? 1 carry the 1. 1 plus 1 plus 9? 1 carry the 1. We don't have room for that digit, right? That's the right answer. Yeah? OK. I don't know. Maybe your elementary school didn't teach you that way. It's not my fault. But you probably did that in your homework, right? You probably said, oh, I got to subtract. You can use that from now on for your decimal subtraction if you want to. Actually, one day, I mean, maybe some of you have children now. But one day when you have children, I actually suggest you not teach them that way. Because they're going to confuse a lot of people. All right, so you probably did that approach in your homework, right? Where you said, OK, well, I'm going to take the ones complement of that number I'm supposed to subtract, add 1 to it. I'll add that together. And that'll give me the a minus b that I want to look for. Because somehow, taking the subtraction process we did learn in elementary school and mapping that to base 2 is just kind of a pain. And this is easy. So instead of mimicking human subtraction, let's use an adder, right? We have an adder. We know how to build it. Let's just use one. So here's an adder. And I made some changes. And I think we still have time to finish this in a few minutes. So here's our design. So we have our adder in the middle. That's the core. And we want to calculate a minus b. So we want our adder to produce a minus b. So we're going to modify the inputs to perform the subtraction. So let's take a look at how we modified them. So first one is a. So a is not changed at all. a just comes straight into the adder. b goes through this box I've called ones complement here. So what is that? It's a bunch of inverters, right? Good. So there's n inverters in there. For each bit, so remember this is n wires. So for each wire, I put it through an inverter. And then I put it into b. Yeah, so that's the third change. So the third change is cn, you may notice here, is a 1. When I change the carry in to a 1, all that does is add 1 overall. So now what is this adder computing? Well, a added to the ones complement, so not b bitwise, plus 1, which is a minus b. Yeah. Mm-hmm. So what happens if the user does a minus a negative number in 2's complement? Remember that negating in 2's complement works for both positive and negative numbers. So not b plus 1 is negative b in 2's complement regardless. Regardless of whether b was negative or positive or 0. Yeah. Good question. What about the carry out? Let's think about this for unsigned. So remember that our 1's complement, you can think of the value as 2 to the n minus 1 minus b. Remember when we first talked about negation, I said, well, when you want to negate something, you can think of this 1's complement as 2 to the n minus 1 and then subtracting b. So we obtain d, this thing down here. You can say, well, what I did was I added a to the 1's complement, which is 2 to the n minus 1 minus b plus 1. So the minus 1 there and the plus 1 there cancel. So d comes out as a minus b plus 2 to the n. But what is the carry out? Well, the carry out is the 2 to the n. So if I see a 2 to the n coming out, that means that this number, a minus b plus 2 to the n, was at least as big as 2 to the n. So in other words, if I get the carry out, c out equals 1, then that means this number here, a minus b, was at least 0. So in other words, a was at least b. a is greater or equal to b. Whereas if I don't see the carry out, so c out equals 0, that means this number d is less than 2 to the n, which means that a minus b is less than 0, or a is less than b. So in other words, if these are unsigned, if I subtract b from a, and b is bigger than a, then I get some unrepresentable number. It's a negative number. So I can't represent it with an unsigned bit pattern. So this is an overflow down here. And this one, if I subtract unsigned b, which is less than a, then I get some non-negative number, which I can represent, because it can't be bigger than the numbers I can represent since I did a subtraction. So this means no overflow. So in other words, the carry out here is an overflow indicator in the opposite sense for subtraction as it is for addition. Remember, for addition, if we got a carry out for unsigned addition, that meant overflow. Now if we get 0 carry out for subtraction, that means overflow. Carry out of 1 means no overflow. Yeah. Yeah, there's a similar set of equations you can use. And in some sense, it's opposite. It's in the notes explicitly, but I didn't do it in the slides. So you can flip to this section of the notes, and it's there for you. And the derivation is there. Yeah. Good question. Yeah, for choose complement, just like unsigned was relatively easy. We just look at the carry out. Here, we also just look at the carry out. Choose complement, you have to do more work. So we looked at the sign bits. It's the same sort of thing. Good question. All right, I think that's it for our first. Well, OK. I wanted to also give you the control signal thing. So if we want to build one that does both, then we need to have some way to choose, do you want to add or do you want to subtract? So we can, again, add this control signal s. Maybe s is 0 for addition, 1 for subtraction. So then we need to modify our adder inputs with s. What should I do for a? Just a, right? Don't need to do anything for a. What about b? b. So remember, I want to do one's complement for subtraction, but not for addition. If I do complement, then I'll be adding. When I say add, I'll get a plus b prime. I don't want to do, not quite that simple. Has to depend on s. XOR. So if I XOR all of the bits of b with s, when I do addition, I'll get b unmodified. When I do subtraction, I get not b. Good. What about cn? Just s. When s is 0, I get a plus, this one is just b, plus 0. a plus b. When I do s equals 1, I get a plus not b plus 1. a minus b. Good. OK, that's it. Thank you. See you Friday.\"},\n",
       " {'ECE120-2016-09-14-LEC-10-slides.mp4': \" end of the class. Yeah. OK, so let me go ahead and start. So today we're going to, I wanted to cover a little bit again the use of the heuristics, because I know it was a little confusing with the complemented literal. So I'll clarify that, and then also show you circuits implementing the three functions, which I think will help make it a little easier to do the counting. It's really pretty easy to use the heuristics, but I think maybe the first few times you do it, it's easier to look at the circuits. So I'll just put those up. Then we're going to spend some time on Boolean terminology, and that will help us understand the question that someone asked, how did I get from the big long construction of f to the shorter construction? But I'll do that algebraically, which is really not very fun. So that'll be the first step. And then I'll show you Karnaugh maps, which are a graphical tool that'll make it a lot easier. So that's probably where we'll get to today. I don't know if we'll finish Karnaugh maps, but maybe. Two-level logic, most likely Friday. Professor Vardain will give that lecture. Remember, none of this material this week's on the midterm. So midterm material ended last week, so just so you know what's on the midterm. Another reminder, next Tuesday, you had to have signed up already for the conflict. So hopefully, if you need the conflict, you already did that. The coverage, same as before. One thing I do want to point out, so I know some of you will go and look at the wiki and read the notes that are connected to the lectures there. There's unmarked content. So there's extra content there, but it's not marked. So in the notes you can get from the store or online for free, all the extra stuff is marked with stars. And there's a summary, section 1.6, that tells you exactly what you're supposed to know. In those notes, they're not marked. So use section 1.6 to help you if you need. So based on what you said, previous lectures I know all have Hamming codes. So I think after two years ago, I think we moved it to, so two years ago, we taught Hamming codes now. And that's what I was joking about a little bit two weeks ago when I said they took a lecture out. But we moved it to the back. Midterm, how did that happen? September 15. OK, so maybe they waited another semester to move it then. I wasn't teaching that semester, so I'm not quite sure. And they moved it. I thought they were supposed to move it in the fall. Actually, spring 15. But yeah, question? Yeah, so the rules for what you get to bring to the midterm, I think, are posted. They should be posted on the midterm page. But are they not there? Well, let's go take a look. Let's see, how about this one? Go to Wiki. Go, probably under Syllabus, right? Should be here. Well, this is where I would look for it. All right, let me ask them to post rules. Because we haven't actually talked about that. When I've been teaching the class, generally there has been one single page, handwritten notes, both sides. And I presume they kept that policy. But let me check, because we want to have the policy be consistent in the classroom semester to semester. And I'll ask them to put that up on the Wiki. Oh, OK. Sorry, I forgot to tell PowerPoint. I wanted you to see the Wiki. There's nothing there, so at least I didn't spot anything where I would have looked for it. So let me ask them this afternoon. Oh, it doesn't want me to go forward, OK. All right, so let's go back a step, just to review the area heuristic quickly. So the idea was you count literals. Whether or not they're complemented doesn't matter. And the idea was to get an estimate of transistor count. And then for the delay heuristic, I just want to be clear this time. So for now, just ignore complemented literals. Don't count them as delays. That'll be easier. And in a few weeks, you'll understand. Sometimes you might want to actually count them. But for now, just ignore them. Make it easier. So here was our first function drawn out as a circuit. So you have the three AND gates and the OR gate there at the end. And then you can see I've labeled them all. And there's two complements going in. So I put inverters, but just ignore those in our counts. So to count area, first we'll count literals. So the number of literals is just the number of inputs to the AND gates. So you can just count them up and see there are nine. And then actually, the number of operators here is also quite easy when you draw it this way. It's basically just the number of gates. So how many gates are there? Four, right? Good. So that's the number of operators, three ANDs and an OR. So that's what we get. What about delay? So now, remember, the delay is the longest path, again, not counting the inverters, from the left side over to the right side. So all the paths go through two. So the gate delay is two gate delays through any path on this one. Good. Whoa. That was impressive. I can't even click that fast. Maybe I've been practicing with my handheld computer. All right, there we go. So this is the second expression. So this one takes a couple of AND gates and an OR gate. And if I ask you to count literals, what do you get? Four, right? Good. What about operators? Three, good. OK, and what about gate delays? Two also, right? All paths. All right, and then this was the third form. So here you've got just two gates. How many literals? Three, right? And I guess I gave the answer to the gate, so I'll just click through that. What about gate delays? Yeah, so remember, it's the longest path that matters. So there might be different length paths. The one that matters is the longest one, because you're going to have to wait for all of the different paths to finish changing. So in here, there's a couple of paths of two and one path of one. So we look at the two. OK, so I tweaked this slide a little bit. So now they all have the same gate delays. Otherwise, everything's the same. So ignore the input inverters. All the designs are the same for delay. So just try to simplify that. All right, so now I want to spend a little time just going through and introducing some terminology that we'll use to help us understand how to optimize Boolean expressions, and then also how the KMAP actually works to allow us to just do a graphical approach. So one thing is a literal, which I've already used. So hopefully you remember, it just means a variable or its complement. So maybe we've got three variables. Maybe we have 10. A literal is just any of those variables or its complement. A sum uses our notation, our plus in place of or. It just means a bunch of things or together. So it doesn't matter what those things are. Anything we want, or together. So the final operation is an or. A product, similarly, we use multiplication to represent and. So a product is just a bunch of things anded together. So again, it doesn't matter what they are. A bunch of things, last function is an and. So a midterm, hopefully you'll remember this idea from the logical completeness construction. We constructed a function with 1, 1 in the truth table. And I said, well, that expression of the product of all of the literals, each variable or its complement appears once, exactly once. We call that a midterm. It produces exactly 1, 1 in the truth table. So that's a midterm. There's a corresponding idea called a max term. So a max term produces exactly 1, 0 in the truth table. So instead of a product, it's a sum. And then each of the variables or its complement appears exactly once. So for example, if you had inputs a and b, you could have a plus b prime, or a prime plus b, or a plus b. If you have three variables, all of the variables have to appear exactly once. So you could have these examples down here. And if you think about what this looks like in a truth table, and you go right down a truth table for any of these with the appropriate number of variables, you'll see there's exactly 1, 0. So those are max terms. Sum of products form, we call this SOP usually. And it has a specific meaning. So it's not just a sum of products. It's a sum of products of literals. So it's an or of a bunch of and terms of literals. So down here are some examples. So the function of f we had before, a b plus b c, that is an SOP form. This is also an SOP form. Each of the things in the sum is simply a product of literals. This one down here is not, because it's a sum. But then if you look at this one, it's not a product of literals. It's a product of a, which is a literal, and also this thing. This is not a literal. So this bottom one is not an SOP form. And then there's the opposite, which is POS, product of sum form. Again, the little catch there is, remember, it has to be of literals. So it's just a product of sums of literals. So here are a few examples. Here you've got a plus b. That's a sum multiplied by another sum. So it's a product of those two sums. Each of those sums, just literals. Same thing down here. Each sum is just literals. This is a sum of one. So it's OK to have a sum of one literal in a POS form. Similarly, I think I, yeah, if we go back here, this is a product of one literal. So that's OK too. But this kind of thing is not OK. This is a product. The last function is d times this thing here. And this is a sum. But this thing here is not a literal. The bc is not a literal. So the last one there is not a POS form. The reason I want to spend some time on SOP and POS is, really, the thing we'll use to optimize our expressions will be k-maps. And the forms that are produced by using a k-map are going to be SOP and POS. So these are the forms you're going to use most of the time in the class. There's also something called a canonical SOP form, and of course, canonical POS on the next slide. Or I guess I put it right there, which is a sum of minterms. So it's not just a sum of products of literals, but it's the sum of products of minterms, or a sum of minterms, where every variable appears exactly once. So this is the form we get out of the logical completeness construction, the thing we did yesterday to come up with f originally. Do you know what canonical means? No. It's a math term. It means unique. So the value of canonical forms, so often you'll see in different areas of mathematics, you'll see canonical forms. The point is, if I have things that I can write in lots of different ways, like the expression f, you saw three different ways. If you think about it, you'll realize, well, I can construct an infinite number of ways. I can always add extra terms that don't change the expression, and I can add an infinite number of those. So there are an infinite number of ways to write it. Wouldn't it be nice if there were some way that we could write it down, I could write it down, you could write it down, we could put them side by side, and if we just glance at them, see that they're exactly the same? So a canonical form is a unique form that allows us to do that sort of thing. Now, honestly, with Boolean expressions for 10 variables or something, you might have 400 or 500 different minterms or maxterms. So they're too big. And even inside computers, there are things called binary decision diagrams, which outside the scope of our class, but computers don't use canonical forms internally either. They're just too big. They're too bulky, and people try to find more efficient ways to represent the functions, and yet be able to compare them easily. But it's a useful idea to have an approach that's unique, and a way to write it in a way that's guaranteed to be unique. We do have to pick an ordering on the variables. And so if you change the ordering on the variables, then you move your terms around. It's not exactly the same. So those are canonical forms. You won't use them very much. What does a arrow b mean? You know this from math? a implies b. So a implies b. So if a is true, b is also true. That's what implies means. So what if a is false? Is the implication true or false? So my mathematician friends tell me if a is false, a implies b is always true. So that's just the definition of implication. So the only time you care about b is when a is true. If a is false, the implication is true. So that's the mathematical definition, and that's how we'll use it, as you'll see in a second. But it also means that these kind of funny statements are true. So don't score above 125%. So if the premise is false for all of the x, then the implications are true. So that's the definition of mathematical implication. So I just wanted to make sure that if you didn't know that, now you know it. And otherwise, if you knew it, now you remember it. The way we're going to use it is on functions. So I'm going to say a function g is an implicant of another function f on the same set of input variables, if and only if g implies f. In other words, every output of 1 in g's truth table has to also have an output of 1 in f's truth table for the same input combination. Now, if g has a 0, f doesn't matter. It's only when g has a 1, f also has to have a 1. So that's what I mean by the g implies f. And we'll do a couple examples in a second. So this is a notion of implicants. Now, in digital design, we actually only talk about products of literals as implicants. So there are lots of possible functions. Remember, maybe 2 to the 2 to the n on n input variables. That's a lot. We're only going to look at products of literals. So it would be far fewer functions. But the implicants we care about are just products of literals. So any time I say implicant, you should assume I mean product of literals. So how do we simplify functions? So here's an idea. So as a first step, we can say, well, if I can find an implicant of g, then maybe I can take out one of the literals. And if I still have an implicant of g, my function will have fewer literals, but it'll still be correct. It'll still be the same function. So here's our original form of f that we got out of the logical completeness construction. And you can see that this term here by itself is an implicant. So if I say, well, if this equals 1, is f 1? So if a b prime c is equal to 1, then f is also 1, right? Because the way we get f is we OR that value together with some other values. If you OR 1 together with some other values, what do you get? 1, right? So good. So this is an implicant. Can I cross out any literals and still have an implicant? Maybe not so easy to see, right? OK, so let's do a truth table. So here's a truth table. We've got a, b, and c, all eight combinations on the left. We have f in this column. And we have the a b prime c with each of the literals removed and the functions written out in these three columns. So take a look and tell me, is b prime c an implicant of f or not? Why not? Yeah, there's that 1 there in b prime c. And if you look over in f, it's a 0, right? So b prime c does not imply f. So that we can't do. We can't cross out the a. What about a c? It is, right? It has two 1's. So here's a 1 1. You look over in f, and there's a 1. Here's another 1. There's a 1 also. So a c is, in fact, an implicant. So b prime c is not. a c is an implicant of f. What about a b prime? Also not. Why? There's this one here. OK, good. So because there's a 1 somewhere in the truth table of a b prime, and there's not a 1 in f, it's also not an implicant. So in this case, we did find that we can cross out the b prime. So we can cross out the b prime, and we're left with a c. And so we can rewrite f as a c plus a b c prime plus a b c. That's a little better, right? We got rid of one literal. And then you can go do the same thing. I won't force you to look at all the truth tables. But if you look at the second one, you'll find you can cross out the c prime. And if you look at the third one, you'll find you can cross out b, or you can cross out c. You can't cross out both. But let's say we pick b. Then we'll get this function down here, a c plus a b plus a c. You say, well, the two a c's are the same, so let me just cross one of those out. And that gets me to what we had before, a b plus a c, or a c plus a b. If you then ask the same question, you go write all the truth tables, and you say, well, can I cross any of those literals out, the answer will be no. So for a c, you can't cross out either. For a b, you can't cross out either literal. So let me give you one more definition, which is if I have an implicant g of f, and I can't cross out any of the literals, I'm going to call that a prime implicant. And it means I can't cross out any literals and still have an implicant. So in this case, a c and a b are prime implicants of f. So that's pretty easy, right? This has a lot of algebra. So you just write your function as the sum of prime implicants. That's SOP form. Want to do one of those? Good luck. Yeah, so that's not really that pleasant, right? You don't want to have to write a whole bunch of truth tables and go poking around, trying to see if one thing is an implicant of another. So instead, what we're going to do is actually develop a graphical tool that will make our lives much, much easier. So all you have to do is look at a bunch of squares and draw circles around them. And that will help you identify those prime implicants without ever having to write down a truth table. So it's actually one that was designed almost 70 years ago. So Karno maps. So we have this approach that we just looked at. But it wasn't very fun. At least, I didn't think it was very fun. Anyone here think it was fun? You can still do it that way. You liked it? OK. You can do it algebraically. Everyone else would do this, I think. So it's not so easy. Easy to make mistakes, too. So let's try a different approach. Let's start with functions of one variable. And let me ask you, so how many implicants are possible? I mean, if I just have a function of one variable, how many different implicants might I have for that function? Remember, there's only four functions, right? And we only want products of literals. So someone name an implicant? A. Good answer. Hey, that's the one I chose first, too. What else? Not A. Good. What else? 1. There it is. OK. 1 is the product of zero literals. So we count it. So we've got three. OK, that's not so bad. If you think about a function on one variable, we can represent the domain of that function as an n-dimensional hypercube. So in this case, it's a one-dimensional hypercube. And each of the vertices in the hypercube will correspond to one combination of the inputs. So I'll draw this for you in a second. But the function f will have one value for each vertex. So if you take your truth table, you write it out. n variables input, you've got 2 to the n rows. Your hypercube has 2 to the n vertices. There's a one-to-one correspondence between your vertices in your hypercube and the outputs of f. The rows in the truth table. So here's a one-dimensional hypercube, a line segment with two vertices. So we can split it in half and say, OK, on the left, we'll have a equals 0. On the right, we'll have a equals 1. And the three implicants then correspond to the two vertices and the edge. So on the right side, we've got the a implicant corresponding to that vertex. On the left side, we have the a prime implicant. And then the edge corresponds to the implicant 1. So there's a one-to-one connection between the features of the hypercube, very simple hypercube right now, but the features of the hypercube and the implicants that are possible on that one variable. So if we write the values of f next to the vertices, we can see which implicants of these three possible implicants are covered with 1's. So which implicants actually imply our function f. So instead of drawing the hypercube, we'll draw two boxes. So you can think of those boxes as representing the vertices of the hypercube. And the left box will be a equals 0. The right box will be a equals 1. And each of those boxes corresponds to a vertex of the hypercube. But they also correspond to a minterm. Remember, a minterm is what gives you 1, 1 in the truth table. And each of these boxes is a vertex or an input combination. And so when you write f into those boxes, they correspond to minterms. So what do we do with that? So then we can mark implicants. So we can say, well, let me take a 1, and I'm going to draw a loop around it. And that means that implicant is an implicant of f. Because here, this implicant corresponds to a, but the function f has a 1 there. So a actually implies f. So it is an implicant of f. But it's not prime. So to know whether it's prime or not, I want to think about making that loop bigger. In other words, can I grow it outwards so that it holds more 1's inside? So the answer is yes. And if the answer is no, that means it's prime. So you'll see this a few times. But we can grow this one to contain the other 1 that's next to it. So let me grow that. So once we have the loop that covers both of these, now it's the whole K-map. So it has to be prime. We can't make it any bigger. We can't circle any more of the boxes inside of our loop, because there are no more boxes to circle. So this is a prime implicant of f. And in this case, we can just say, oh, OK, so now f is 1. That's the function that we wrote into our K-map. So you might think, well, that's a function on one variable. I actually know all those functions. The K-map thing maybe is not so helpful. I don't know. Maybe you'll feel excited. All right, let's look at two variables. So if we do two variables, how many implicants? How many minterms? Four, right? Rows of the truth table. So let's put those down. So we've got ab, ab prime, a prime b, and a prime b prime. Those are the four minterms. What about on one variable, one literal? How many? So there's a, a and a prime, b and b prime. So four more. And then, of course, we've got 1. So it seems we have nine. If you think about the hypercube, so first let's split it up. So we'll split a again horizontally. So a equals 0 will be on the left again, equals 1 will be on the right. And we'll split b vertically. b equals 0 will be on the top. b equals 1 will be on the bottom. And then we've got four vertices, four edges, and a face. So those are going to correspond to our nine implicants. So let me draw those for you. So the upper left, a equals 0, b equals 0, well that corresponds to a prime b prime. Then there's ab prime, a prime b, and ab down on the lower right. So those are the implicants. I'm sorry, the minterms, those correspond to the vertices. The implicants with a single variable correspond to the edges. So there's a prime, there's a, there's b prime, there's b. So those four correspond to circling two of our vertices or correspond to an edge, if you rather think of it that way. And then there's one face, which corresponds to the implicant 1. So if you've got all of the vertices filled with 1's, then you have the implicant 1. Of course, we're going to draw this as boxes again. So in our Karnaugh map, we have four boxes now. Each of the boxes, again, corresponds to a minterm, one input combination, and corresponds to a vertex of a hypercube. So it's a one to one mapping between the hypercube and these boxes. Question? Yeah. That's a very. Yes. Beyond, you can use K-maps easily up to four variables, so it's not going to go that far. With a little moderate pain up to about six variables. I mean, I've done them, I think, on six variables before myself in certain cases. Beyond that, you really want to fall back on algebra. So if you want to use the algebraic approach, it's the same math underlying it. So hopefully, once you understand this, you could go off and do the algebra. There's a theorem called Quine-McCluskey, but really, 462 is the place to learn much more about it. Yeah. So this is just some function that we're trying to represent. So whatever the function is, remember that each of the boxes corresponds to one input combination. So often, what we'll do is just, if you can fill it from an expression, you can do it that way. Otherwise, you can take a truth table and simply say, well, for a equals 0, b equals 0, here's the output value of my function. For a equals 1, b equals 0, here's the value for my function, and so forth, and fill it in. Yeah. There is not. No. Yeah, so 0 is not considered to be an implicant. Yeah. Yeah, it's, I mean, the function 0 should automatically be an implicant. Mathematically. But as I said, in digital design, we only consider products of literals to be implicants. And so you can't multiply any literals. Even 0 literals is considered to be 1. Good question, though. Because mathematically, the answer should be yes, but not for us. All right, so the problem's a little more interesting now. What we want to do is find the biggest loop. So why do we want the biggest loops? Well, remember, if the loop can't grow, that means it's a prime implicant. So we want to make our loops as big as we can make them. So make the loops as big as we can. They have to have power of two edge lengths. Now here, it's either 1 or 2. When we get to more variables, we'll see that there are certain sizes we can't have. The reason has to be 1 or 2. 1 corresponds to a vertex, or a vertical, if you think horizontally, a vertical slice, which would be an edge going vertically. And 2 would correspond to a bigger feature of the hypercube. And together, those loops have to cover all the 1's. So we want to take those different prime implicants, OR them together, and get our function. So if we get loops that cover all the 1's, then that will allow us to get our function back in a fairly simple form. So this is our strategy. So let's try it out. So we're going to start by picking a loop and circling it. So let's just pick this one up here. And as soon as we circle it, we know, OK, well, that minterm, because we circled a 1, is an implicant of G. Is it a prime implicant? Not. Why? Yeah, so I can grow this loop. If I look down, I say, well, I can't include this 0, so I can't grow downward. But if I look to the right, I can make the loop bigger by growing it out to the right. So let me do that. So it's not a prime implicant, because we can grow it. So let's grow it. So that loop now represents B prime. So one thing you'll want to be able to do is learn to read these loops off. So I've annotated the KMAP in the most helpful way. But in some of our notes and other homework problems and stuff, we may not draw these extra markings for A. We may just give you the numbers. But here, you can see this one down here is B. So the implication is this one is the B prime implicant. The B prime is also an implicant of our function G. Is it a prime implicant? So remember, if we're going to grow it, we have to grow the whole thing. There's only one direction left. So if we grew it downwards, that would include the 0. We're not allowed to include a 0. So in this case, we can't grow this loop anymore. You can never cover a 0, because then the function you would get out of that loop would not be G. It would have more 1's. All right, so the answer is no, we can't grow it. Eric? I had to start somewhere. Oh, I had to start somewhere. I will tell you how to choose later. But for now, you've just got to start somewhere. I'll come back to that later, because sometimes it matters. But here, it doesn't matter much. What's the next one? Well, we'll do that one next. OK, we've got this one left. So we have to cover that one. Otherwise, our function from this loop will not have this particular 1. All this implicant will generate are these two 1's. So we need a second loop. So let's circle that bottom 1 now. So that's the midterm AB, which is also an implicant of G. But is it a prime implicant? Why not? You can grow it up, right? We can't go left, but we can grow up. OK, so let's grow up. What we have now is the implicant A in that second loop. And that one is a prime implicant of G, because we can't grow it to the left. So we now have two loops, each of which is a prime implicant. And so we can write down those two together with an or in between them and get G out. So these two loops cover all of the 1's. So we can write G equals B prime plus A. Are you excited? OK, you're not excited. So we'll have to keep going. We're going to go to 10 variables. No, I'm kidding. All right, so guess what's next? Three variables. So how many implicants? Yeah, here's some big numbers, but yeah, that's right, lots. OK, so let's do it a different way. So I said that there's a one-to-one mapping between these implicants and features of the hypercube, right? 3D hypercube's a cube. Let's count features. So here's the cube. Let me split it up. Same way for A, same way for B. C, the bigger square, is going to be the outside. It's going to be C equals 0. And then the inner square is going to be C equals 1. So there's our square. So now let's count. So how many vertices? Eight? Eight corners of the cube. How many edges? 12, good. How many faces? How many cubes? Good. So that adds up to 27, right? OK, so now I think some of you said that already, I know. But I had to figure it out. So you notice a pattern? When we had one, we got three implicants. When we had two, we had nine implicants. When we had three, we had 27 implicants. Sounds like 3 to the n. Why should it be 3 to the n? So if you think about, well, what are we calling an implicant? It's a product of literals, right? So if I'm going to say, hey, there's a product of literals, I can then ask, well, what about the variable A? What are my choices for A? Yeah, so A, A complement, or not there. Three choices, right? So three choices. Include it, include the complement, don't include it at all. So for every variable, we have three choices. If we have n variables, 3 times 3 times 3, n 3s multiplied together gives us 3 to the n. So if you have n variables, you have 3 to the n literals, and 3 to the n features of your hypercube. So that's why, once you get to 4, it's actually a pretty complicated problem. Even three variables, it's sometimes difficult to look at an expression and just say, ah, I know how to simplify that one. If you spend a lot of time practicing Boolean algebra, maybe you can do it. But probably a little easier to use the K-map. But how are we going to map this cube thing into squares? So let's see. So look at the top half up here, and let's try to put that in some order. Let me do that by just drawing lines straight down, and I'm going to write the values of a and c down here on the bottom. So the upper left one is 0, 0. The next one, going to the right and ignoring the vertical dimension, is this one. a is 0, still c is 1. So ac is 0, 1 there. How about this one here? 1, 1. And how about this last one? 1, 0. Good. OK, so we have this order down here. This is called a gray code order. A gray code means one bit flips at a time. It actually wraps around. So you can see if you look here, 1, 0, and then around on the other side, 0, 0, one bit has changed at every step. So those connections represent the edges of the hypercube. So each adjacent ac pair shares an edge, and then the last edge wraps around in this horizontal mapping. So there's four edges. The top face is all four of those. So if you then use that to map into boxes, what you get is this gray code. And your loops can be one box wide. That means they're a vertex. It could be two boxes wide. That means they're an edge. Or they could be four boxes wide. That means it's a whole face. It can't be three boxes wide. Three boxes do not correspond to any feature of the hypercube. So when you look at your K-map, and you've got two variables in one dimension, first of all, you're going to use gray code order. So here's a picture. So you can see on the top, we've got the variables A. A is on the right, C is not A is on the left. And then C is inside is 1, and outside is 0. But you can see there's gray code order across the top for A and C. And if you think about what these mean, any adjacent boxes will map into an edge of the hypercube, including adjacency of wrapping around. And then if you pick all four, that's the face of the hypercube. So let's find a way to solve this particular H. So again, we're going to start by circling a 1. So we'll solve this K-map by doing the same process as we did before. So there's our first 1. So that's the minterm A prime, B prime, C. So is that a prime implicant? So with three variables, there are three ways we can grow. So you've got to look in all three directions. Here to the left, there's a 0. Can't go that way. Here to the right, there's a 0. Can't go that way. Here below it, a 0. Can't go that way. So we can't grow it. So this one is prime. But we've got more 1's. So let's pick another 1. Let's say I pick this one here. So that one is A prime, B prime. I'm sorry, A prime, B, C prime. So you can read the variables off, just like you do in the truth table. So A is the left one in those two. So A prime, B is a 1, and C is 0. So C prime. Is that one prime? Why not? Yeah, so remember it wraps around. So I can grow to the left here and wrap around. Let's grow that. So now it wraps around. So that new loop is the implicant B, C prime. It's an edge of our hypercube. So is that one prime? Yes. But can't I pull this one in? Yeah, that would be 3 wide, right? And 3 is not allowed. That does not correspond to an implicant. So you can do it in a, if you get confused, you might circle 3. But then when you try to figure out, well, what's the implicant? There's no answer. There's no implicant for that. So this one's prime. So that one we'll leave alone now. But we still have one more 1. We've got to circle it. That one's A, B, C. Is that prime? Why? Grow it to the right. OK, good. Let's grow it. We go. So that's A, B. Is that prime? OK, so I think we've got all the 1's covered. So that's a prime implicant. So the 1's are all covered. So then our function is just the sum of those three loops. So we had the first one we wrote was A prime, B prime. I'm sorry. Yeah, A prime, B prime. I copied that wrong, didn't I? No, no, no, I got it right. B prime, C. Yeah. OK, yeah, this one is A. So it's A prime. B is 0. So it's B prime. And C is 1. So it's C. That was right. This one that spanned around, that wrapped around, was B, C prime. And then the one we just circled was AB. So together, those three give us our function H. Now hopefully you're excited, because that was probably a lot easier than playing with the algebra. OK, so let's go on to four variables. It's a little hard to draw the hypercube. Not impossible, but probably not worth the time. The K-map's not so bad. Basically, we do the two variables in each of the two dimensions now. And we'll use gray code order in both dimensions. So we'll have, again, no three box loops. So in both dimensions, you can circle 1. You can circle 2. You can circle 4, but you can't circle 3. So in both dimensions, any of those combinations is fine. Your goal is to come up with a minimal number of loops of maximal size. So if you succeed, it turns out that, oh, and they cover all 1's. You have to cover all the 1's. And of course, your loops can't cover 0's, as you know. If you do, that result will be optimal amongst SOP expressions by our area heuristic. So the same area heuristic that we said, we're going to use this to measure the area of your circuit, this will give you the best answer for that heuristic. Now, POS expression might be better. K-maps don't really help you spot XORs. So you might be able to use XORs and come up with an even more efficient circuit. But this will give you a pretty good answer. So this kind of comes back to your question, Eric. So sometimes you'll go through this process. And you might find, well, after I've filled all the loops in, I've got a loop that I don't really need. It's actually everything inside of it is covered by other loops already. You can get rid of that loop. As you get more experience with this stuff, you'll actually start to look around for the loops that you know you're going to have to have. And the way you do that is when you pick a 1 to start a new loop, if you've got choices, if you have something actually like the, I don't want to go all the way back there, but if we had started with the corner in the example, what I'll do is draw it on the board. So if we start here in the corner, that means we could grow in either direction, but we can't grow in both. And so I have to make a choice. So choices are bad. Pick the ones where you don't have any choice first. If you pick the ones where you don't have any choice, those you're going to have to include. So as long as you start by doing those, you'll find yourself less often in the end having to go back and take away some of your loops. So the final thing I wanted to say there is sometimes there's more than one optimal form. So don't worry too much if your answer is different, because for some functions, there's more than one right answer in terms of optimal SOP forms or optimal POS forms. So here's a four-variable K-map. I'm not going to solve this one now, but let's see. What's time? Yeah, let's go play with one in the tool. So I will switch over and tell my laptop to let you see what I'm doing. Get out of the wiki. So down here, there's this Karno Maps tool. And so we want to be excited. So let's do four variables, solving K-maps. So here's a random K-map that it just came up with. So help me out. What should I circle? Circle. Yeah, let's start with the top left. That's a good idea. So if I start with the top left, then which way should I grow that? Grow that to the right? So I can grow it once to the right. Can I grow it again? So let me erase this one, and I'll put the whole one there. Can I grow it up or down? No, that one's prime now. So then let me go find another one to cover. How about this one here? I'm going to do that one next. Can I grow it? Which way? Some people said down, some people said up. OK, so down would be here. OK, so let me grow that up. Is that fully grown now, or can I make it bigger? OK, good. And maybe you want me to do that square there next? OK, now we can do that. So this one I can grow in two directions, that way or that way, and I can actually do it both at the same time. So let me pull that one. What about this one here? To the left, OK. So I'll pick that. How about this one? Yeah, I can go right. I can actually go down also, right? Yeah, so either one of those will be OK. So let me pick the less obvious one. Maybe what I'll do is pick both of them for you. So I can go down, and I can say check answer. Oh, it doesn't like me to pick that one. Hmm. What did I do? Oh, yeah, I can make a square. Good point. There we go. Yeah, that's much better looking. That has one fewer literal, right? Because every time you grow it, you're getting rid of a literal. It's the same thing you're doing algebraically, except it's a heck of a lot easier. At least do this for me. I assume it will be for you, too. OK, so there's a good answer. How do you read this? So there's a good question. So for each of these loops, you would then need to read off the literal, right? So let's take this last one that we did. So because it's all outside the b equals 1 region, that means there's a b prime in it. So these two rows are b equals 1, and the other two rows are b equals 0. So since it's spanning those two rows, we have b prime. h varies, because h is equal to 1 here and 0 up there. So h does not appear in this particular loop. m also does not appear, because it's 0 here and 1 here. And d is equal to 0. d is 1 on that side and 0 on this side. So this is d prime b prime. And if you want practice reading literals, there's actually a couple ways to do it. But you can go back to KMAP Implicants and say you want to identify literals. So here, it's just pulled up an example. So d g prime n. So where is that? So every time you have a literal, it's going to cut the size in half. So the literal 1 would be all 16 boxes. If you had one variable, that would be eight boxes. Two will be four boxes. Three will be two boxes. So that's the first step, is just to realize, OK, this is two boxes somewhere. It's inside of d, so down here on the bottom. It's inside of g, so on the right. And it's g prime. So d g prime and then n prime. So n is here. So n prime is these two. So let me go mark those. And if you get it right, it'll say green. And if you get it wrong, say I say, oh, I like this one, it'll say, no, you're wrong. So it'll say green or black, depending on whether you get it right or wrong. There. So you can practice your implicants with this tool. There's a bunch of different ones. You can do expressing, too. So with this one, what you have to do is check whether these implicants appear are circled over here. So there's always something extra. So and then you just say yes or no, if it appears or not. So you can practice your mapping from the K-map to the algebraic form. And then if you really want to do the whole thing, you can also, you don't necessarily need to use this tool yet. But if you go to here, this tool is actually doing combinational logic design. So it allows you to copy, although it has x's in it, which we haven't talked about. That'll be next week. It allows you to copy the truth table into the K-map. But because the tool's exercise is logic design, you can also just go over here and say, no, do that for me. And then it allows you to solve the K-map. Because again, it's a logic tool. So you can say, no, I know how to do that. Do that for me. And it'll just solve it for you. And then the next thing is you should write down the expression. And so you can figure out what you think the expression is and then tell it, OK, what should the expression be? And it'll tell you. So if you want to double check, you can do it as in the other tool I showed you earlier, where you're answering is this implicant there or not. Or you can do it this way, write down your answer and then have the tool automatically generate the answer so that you get the same answer. So a bunch of tools you can use to help you learn how to solve K-maps. Thanks. I'll see you Monday for a review session. Oh, Verdin is teaching on Friday.\"},\n",
       " {'ECE120-2016-09-21-LEC-12-slides.mp4': \" comment on that briefly before we talk about material. So we are splitting up the midterms to come up with rubrics. We're gonna grade Saturday the 24th, so you should see your grade on campus hopefully that evening. But I looked through about 20 exams on my problems, which were two of the six, and people were doing pretty well. So I think overall we were pleased, or at least I'm pleased so far. So I think people did well. I was a little surprised other people's rooms I think left a little earlier than mine. So that I was worried about that, it seemed like maybe it was too long if we designed it for 45 minutes. And we hit the 50% mark at about 827, which seemed a little too late. That 50% of the people had left my room by about 827. So, but other rooms they said were leaving earlier, so maybe it's okay. But I think that a lot of people were probably just... Yeah, yeah. No, so the comment is that a lot of people were probably just hanging out and checking work. So yeah, I understand that. But on the other hand, when I've done two hour exams designed for one hour in the past, usually they're not staying to the very end. They're staying a little extra and then moving. But we'll see. I think people did well is the main message. All right, so today we're gonna go over Boolean properties. I'm gonna start with duality and use that to kind of look at a few things. So we'll go through several results of the duality property of Boolean algebra. Then we'll take a look at what we call don't care outputs, which are outputs of functions where we don't care what the answer is for various reasons. So I'll give you examples of those. And then I'll actually do an example using don't cares and seeing that we need to be careful about when we say we don't care. So, yeah, I know that's great. Okay, we'll come back to that in real detail later. All right, so I wanted to just review and then maybe ask you a question. Professor Veridan said that he wasn't quite sure that you got one point in the notes. So I'll ask you after I kind of get you back into the speed of things with these couple of slides. So hopefully you remember and you've done several K-maps by now, or maybe you just put off K-maps and studied for the exam. But if you remember K-maps, your goal is to pick a minimum number of loops of maximum size that together cover all ones, that'll give you an optimal SOP form for amongst SOP expressions by our area heuristic for four or fewer variables. Sorry for all the caveats, but if you really go to bigger variables, then these two metrics are not quite equivalent. So it's not really optimal. But for the K-maps, it will have you solve their optimal in the area heuristic. So what you won't see is you won't be able to compare directly with POS or XOR. So XORs will not come out of K-maps directly. You'll have to identify them yourself. And POS to do that, hopefully you remember you draw loops around zeros instead of drawing ones, you make them as big as you can, you cover all the zeros. And then when you calculate the POS factors for the loops, don't forget that the variables, the literals are all complimented relative to the implicants you would get for an SOP form. So hopefully that made some sense. Unfortunately in the tools, it's sort of when I wrote the K-map tool, I deliberately left out POS thinking, well, the goal is not to have you do tons of exercises with both just to understand that you can do both. And SOP is kind of the main one just to get some experience with optimization. But then on the midterm, sometimes we'll ask about POS and sometimes we'll ask about SOP and we tend to go back and forth. So if you want more experience, you can actually go to the layout tool, the logic design tool, and that will give you K-maps where you can do POS solutions and the K-maps will be marked properly. So use that tool instead. And you can also say skip step and it'll show you how it'll be marked, but you can do it and then check the answer and they'll tell you whether you got it right. So use that tool if you want experience with POS. So one question, Professor Verdean said he wasn't sure that people understood why a single, if you have a function, which is a single NAND gate or a single NOR gate, do you understand why that's both POS and SOP form? Yeah, more or less. Okay, good. I mean, we can draw it and then the trick is to just use DeMorgan's to move the inverter across the gate and then it's either a single product of several sums or it's a single sum of several products of single literals. So one gate is basically both POS and SOP, one CMOS gate. All right, so Boolean algebra has this kind of cool property called duality. So the dual of an expression we can find as follows. We can go take the expression and look for zeros and ones and swap them. So if you see a zero, you replace it with a one, you see a one, you replace it with a zero and then look for ANDs and ORs, swap AND with OR, swap OR with AND and that gives you what we call the dual. All right, let me give you an example. So up on top is an expression. So to find the dual, you just do the swapping. So replace one zero with one, one with zero, OR the pluses with multiply AND with OR, vice versa. And what we get is this thing down on the bottom. All right, so the dual of the top is down here on the bottom and then if you say, well, what's the dual of the dual? Well, of course, if you swap again, you get back the original expression. And all we're doing is swapping zero and one, swapping AND and OR. So the dual of the dual is the original expression and that's where the term duality comes from. All right, so there's two aspects of the same thing. Mohammed, come here. Yeah, that's a good question. Let me answer that on an upcoming slide. Why do you care about this, right? It's kind of, hey, that's cool, but who cares? Yeah, Eric. Yeah, so literally, if you look at these two, right, the AND here becomes an OR, the OR becomes an AND, the one becomes a zero, the zero becomes a one, the AND becomes an OR. Everywhere you see an OR, you write an AND, everywhere you see an AND, you write an OR, zero becomes one, one becomes zero. Make sense? We're good, except why do we care? Okay, so before we get to why do we care, one or two more slides. So be careful, don't change the order of operations. So I picked that previous expression kind of carefully and put lots of parentheses in it. But if you write something like this, do not just replace AND and OR, do not just swap those two. You need to add the parentheses so that the BC operation happens first. Okay, if you change the order of operations, that is no longer the dual. So be careful with that when you're taking a dual. So why do you care? So three reasons. Well, let me explain them briefly, and then we'll go back to each of them in more detail. So first of all, when you look at a CMOS gate, actually the network on top of p-type MOSFETs and the network on the bottom, those are actually dual Boolean expressions. Okay, so when you build a gate, you're using dual Boolean expressions, and I'll show you a non-NAND-NOR gate a little later by simply taking the dual. So that's kind of useful if you wanna build a more general gate structure out of MOSFETs. It's also a quick way to complement any expression. So I'll show you a complicated expression, and then simply use duality to find the complement instead of recursively applying De Morgan's rule, which is both error prone and painful. And then finally, this principle of duality. So let's start with that one. The principle of duality says that if I write down an identity or a property of Boolean algebra, then the dual of that identity or property is also true. Well, if it's false, it's also false. If it's true, it's also true. So it has the same logic value. So we're gonna use that in a little while to basically expand all of the different Boolean properties by simply taking their duals to find new properties. And you'll see a lot of the ones that you've already know intuitively are actually duals of one another. So we'll use that in a few minutes. Okay, so the second one on that list, generalized De Morgan's. So let's say we have this expression F, and I wanna find F prime. And so I wanna find the complement of my expression F. So one way to do that is we'll say, okay, so I put the prime on the outside of F, and then I apply De Morgan's, and then maybe I have to keep applying De Morgan's over and over again until I get rid of all of the different steps inside of F. So that's kind of painful. Or we can use the generalized version based on duality. So write the dual form, swap the variables and the complemented variables, and that's it. So that's it. So if you can write the dual, and then you can go through and, if there's a variable, you can add a prime to it. And if there's a variable complement, you can cross out the complement, then you're done. So a little easier than rewriting each step through De Morgan's laws. So here's an example. That's a nasty looking one, right? If you want, you can do this by hand to verify that I got the right answer. So what's F prime? Anyone? Yeah, it's not that fun looking, is it? Okay, so first we'll write the dual. So here's the dual. All I did is I took the ands, I replaced them with ors. I color coded the parentheses so you can kind of line them up visually, but it's all the same, right? Ands become ors, ors become ands. There are no zeros and ones. And then I go through and A becomes A prime, B becomes B prime, L prime over here becomes L, right? So the second step is to just complement all the literals, either from uncomplemented to complemented or vice versa. So then we're done. That's F prime in a fairly nice form, right? Without lots of extra complements on anything. Yeah. Yeah, so remember the variables or the complements are the literals. Did you mean there are no zeros and ones? Okay. It's okay, it's not a bad question. Anyone else have a question on this? So at least I think this is relatively easy compared to going step by step, right? So if you go step by step, then first you would, let me make sure I can parse this. You've got this big expression here. So you'd apply DeMorgan's to this big and, and you'd get A prime or B prime for complement of this thing, right? Which then if you kept going, you'd eventually get this, right, but you'd have to go step by step. But you can do all the steps at once using the dual form. Yes, yes. So when you take the dual form, you do have to swap zeros and ones. So normally we very rarely write equations with zeros and ones. We'll do that in a few minutes for our properties, but most of the expressions you care about don't have zeros and ones. No, you'd change the variable. That's a good question. Yeah, only the variable. Yeah, so if you think about, if you said F prime, you'd have to swap the variables. Yeah, so if you think about, if you said F equals zero, and then you take the dual, you'd get the dual equals one. And then if you complement it again, you'd get F prime equals zero, which is wrong. Yeah, so zeros and ones, you complement when you do the dual. So you don't complement them again, which may be what you were thinking about before. I'm not sure. Okay, so once you get familiar with this, you can just skip the middle step and just write it out. And as you go, change the variables to the complements or vice versa, and change and more. Be careful again about the parentheses. Don't let the order of operations change. All right, so this then, I kind of find the coolest part. So if you look at the CMOS gate structures, the type of the network of MOSFETs on the top, the P types on top, the N types on the bottom, those two are actually duals of one another. So let's think about the N type, and let's assume that we've got a gate where we've got four N type arranged in parallel. So the output is connected through four parallel N type MOSFETs down to ground. So in that case, if any of those four transistors is on, then the output is zero. So those transistors, let's say, are controlled by inputs A, B, C, and D. So Q, the output is zero if any of the transistors is on. In other words, if A or B or C or D, then Q is zero. So Q then, of course, is that value complimented, right? So Q is zero when any of those is true. That's a NOR gate, a four input NOR gate. So think about the, sorry, think about the P type on the same gate. So if you've got them in parallel on the bottom, they're in series on the top, right? So those connect Q up to VDD, but in order for the connection to be made, all four of those transistors have to be on, right? So when are they on? Well, they're on when each of the inputs, A, B, C, and D are equal to zero, right? Having those equal to zero is what turns a P type on. So in other words, we have to have A prime, B prime, C prime, D prime, and that's Q. But those two are the same, both in NOR gate. So you can actually derive the output for a properly formed gate by looking at either of the two. And what I want you to notice then is that A, B, C, D form, looking at it this way, here I have A, B, C, D prime, A, B, A, or B, or C, or D complemented. And if I were to then take the dual of A, B, C, and D, and I get A, B, C, D, and if I were to switch those, I get A prime, B prime, C prime, D prime, which is the same expression I get if I derive Q from the P type transistors instead of the N type transistors. So we can get this equivalence two ways. One is by just deriving from the forms, but the reason that works is because the networks of transistors are actually the duals. So in this case, the duality comes from the structure of the networks and the complements come from the use of P types versus N types, right? That the P type transistors turn on when we put the opposite value in from the N types, right? P types turn on with a one, N types turn on with a zero. So that's where those two come from. So we can make use of that. So this, sorry, this is the explanation I was just giving. So the dual form is actually built into the gate design, right? So the upper and lower networks around the output are actually duals of one another. And the flipping of the complements comes from the use of P type versus N type. So let me give you an example of that. So here's kind of a strange looking gate, right? You look at that and you say, wow, what does that do? So you can, again, derive it from either expression. If you look at the bottom, for example, then Q goes down to ground if A or B is on and C, right? So A plus B and it together with C and then complemented because going down to ground means Q equals zero. You can get the same expression by going upwards and saying, well, Q is equal to one if A prime, B prime or C prime, right? And you'll find, of course, those are the same, but the dual, if you were to instead say, well, what's the dual of this expression, not with a complement, but what's the dual of this expression? Well, it's A and B or with C, this one down here. And if you look at the P types up here, you've got A and B over here or with C over here. And so that's the structure of the P type network. So you've got the duality between the P type network and the N type network. And that ensures that you don't have a short, right? So if you think about, well, what happens if I don't make them duals, right? I can put transistors wherever I want. Generally, if you're not careful, if they're not duals, you have a pretty good chance that there's some input combination that will give you a path from VDD down to ground, right? Which will destroy your chip. All right, so that was the third use of duality. You have a question? Yeah. Yeah, that's where I got this one here from the N type network down on the bottom half. So the parallel construct is an or, right? Because Q is connected to this dot here, if A or B. Right, so if A or B, then one of these transistors will be on and Q connects electrically down to this point here. Now to get to ground, this transistor also has to be on. So we end the A or B with C. And that says this transistor is also on. So if we have A or B ended with C, then Q is connected to zero. And so in order to get the actual value of Q, we have the complement. Yeah. Okay. Forward or backward? Okay, this one? So remember that the, so the dual structure comes out of the networks. Okay, so this one is parallel, right? And this one is serial, okay? The complements come out of the N and P types. So in order to turn a transistor on for an N type, you put the value equal to one. For a P type, you put it equal to zero. And so for all of these four transistors to turn on, A prime has to be true, B prime has to be true, C prime has to be true, and D prime has to be true. Because these were derived from the P type transistors. I didn't draw this one, so let's look at this gate. So here, for example, if you look up at the P types, I have chalk, okay. If you look up at the P types, then what you have is A prime and B prime, right? Because in order for this connection on the left from Q up to VDD to be electrically connected, these two transistors have to turn on. To turn on, A has to be zero and B has to be zero. So this is A prime, B prime. And this path here is C prime. So if either of those two paths is on, I get an electrical connection. Sorry, I think I cut off from the left. So this is what I get if I write the value of Q from the P type network. And this one here that I've written is from the N type network. But you can see if I apply De Morgan's to Q equals A plus B, and it was C, was it? So remember, I would take the dual, so I would get A, B, or C, and then complement all the variables. That's the same thing. Well, I applied generalized De Morgan's. We could also apply it one step at a time, if you'd rather, which would give you an intermediate step of A plus B prime, or with C prime. And then when you apply De Morgan's again, you'd get this one. Yeah. You mean if you wanted to produce a gate that had the complemented output? Yeah, so you could imagine, if I have to write Q in a form that has only uncomplemented literals, because those are N type MOSFETs, and then with a complement at the end, I can't express any arbitrary Boolean function that way. So I don't have complete freedom, actually. So what you would typically do is, if you really needed, say, this function here without the complement, we'll put an inverter after it. So you could build it by playing the trick of swapping N type and P type, but that would give you problems because of the way they work, as we talked about when we first discussed MOSFETs. Well, so the things you can build with MOSFETs are the ones where you have a complement outside an expression formed of uncomplemented variables. So those are the things that you can build directly. You can build all functions, of course. It's, I mean, NAND and OR are both logically complete, and so I can build anything with MOSFETs. But to build a gate directly, the expression I get has to be of this form. Does that make sense? Okay. Okay. All right, so this was just an example of the kind of thing you could do. So one question you might wonder is, well, why don't we do more of this, right? If you want to build an adder or some other circuit, why don't we go down all the way to that level? Now, let's take a look at the area and speed. So the function here that we just derived requires six transistors and one gate delay. You saw the diagram. There are six transistors, and it's one gate delay, because it's basically a gate, a gate-like structure. So six transistors and one gate delay. Now, if instead I said, oh, I want to build this out of NAND and OR, well, then I would have to do this. I could write Q equals A prime B prime complemented ANDed with C complemented. That would be a two-input NAND to produce this value, and another two-input NAND to produce Q. So I could use two two-input NANDs. So each of those two-input NANDs is four transistors, and it's two gate delays. So eight transistors and two gate delays. So it's bigger and slower. Well, gee, why don't I just go down and optimize? Most of the time, people are not going to do that. They're just going to use NAND and NOR or even higher level. When you get into a class like 385, you're going to find you're actually writing something like C. You use a language called system Verilog to describe your hardware. You'll say, hey, I want to add some numbers together. Go produce an adder for me. So in fact, people aren't even getting down to the level of gates much anymore. So why not? Why not go optimize? Well, the problem is the more time you spend optimizing, breaking that abstraction boundary, the more likely you are to make a mistake. The more likely, when you make any change, that you've got to then go redo a lot of your work. So it's a big cost of human productivity and often a small advantage in size and area. To the extent you can get your tools to do it, your computer tools, then the computer tools will do some of this kind of optimization for you. But in general, that abstraction boundary, saying, well, I know how to build gates like NAND and NOR. Give me a library of those gates. Let me plug them together. Or give me a library that includes an adder. And I just want to be able to put an adder or some of the other components you'll see in a few weeks. People are usually working at the higher level in order to be more productive. You have a question? So that's the reason. Generally speaking, if you're willing to go down and optimize by hand, you're going to get some benefit. But remember, a typical processor has billions of transistors. So if you look at every transistor for five seconds, you're not going to finish in a useful product time. Yeah, so certain companies do do custom logic. So companies like Intel, Apple, and Samsung together do custom logic. For the most part, almost no one else does. A couple of networking companies. But for the most part, other people use standard libraries in designing their hardware. Yeah. Not terribly a lot. System Verilog has a little more object-oriented capability. Also what's known as high-level synthesis. So the ability to describe things in a more flexible way at the possible expense of not being able to synthesize them. So I'm sure people who use them every day would argue vehemently that one is just nicer than the other. But practically speaking, you can do pretty much anything in either. System Verilog is a newer language. And also it gives you this high-level synthesis benefit, which has some advantages and some disadvantages. Kind of similar to this, actually. I'll share it. That I'm not sure. Let's take it offline. And I'll see if I can find ways to get you something to play with. OK. Anything else? No? Yes? All right. Oh, we have plenty of time. Good. OK. So let's take a look at some Boolean properties. So these are the easy ones. You probably already know them intuitively. But they're kind of useful to commit to memory if you haven't. Because when you take a look at a circuit, as you'll end up doing several times in our class, many times in our class, being able to analyze it quickly is useful. So we'll ask you to look at something and tell us what it does, and being able to just go through. So for example, you probably remember that if you OR one with some variable, out comes a one. So any time you have an OR gate and you put a one in, you get a one out. Similarly, this is the dual over here. So if I take the dual, I get 0, 0. And I get OR replaced by AND. So it says, well, if you take AND, and you AND something with 0, you get 0. So those two properties are actually duals of one another. Similarly, if you AND something with 1, you get that something. If you OR something with 0, you get that something. Those are also duals. If you OR something with itself, you get it back. If you AND something with itself, you also get it back. If you AND something with its complement, you get 0. If you OR something with its complement, you get 1. So all of those properties, relatively simple properties. But if you memorize them enough that you can spot them quickly, then you can start crossing out pieces of circuit and thinking about what happens in partial cases. So they're kind of useful properties to memorize, and they're pretty simple. De Morgan's laws are also dual forms. So there are two De Morgan's laws. So if you write one of them, you get A or B complemented equals A prime B prime. And if you then take the dual of that, you'll get the other De Morgan's law. And so they're just duals of one another. So I won't walk through that one. So what about distributivity? You probably remember this from algebra. So if I say, well, if I take some number A and I multiply it by a sum, B plus C, well, I can distribute the multiplication over the addition. So I get A times B plus A times C. That also works as Boolean algebra. So and distributes over or. So here's kind of a weird thing. So what if you take the dual? What happens if you take the dual of this distributivity law? Or distributes over and. So that's kind of weird. It's not intuitive. So if you're trying to manipulate Boolean algebra, you'll want to remember this. I don't think you have to manipulate Boolean algebra much, but this is what it would look like in our usual algebra. This is just wrong. But in Boolean algebra, it's right. So because of duality and because of the way Boolean algebra works, you can actually take this or and say, OK, A, B plus A, C. I'm sorry, A plus B times A plus C is the same as this expression here. You distribute the or over the and. All right, so one more property called consensus, which is just kind of non-intuitive. If you have intuition looking at this, good for you. I'll show you graphical reason to try to give you some intuition. But I find it a little bit difficult to understand. But basically, the way it works is if you have two terms where you've got two variables and then the other variable is a complemented variable, and then you've got a third term, which is those two variables added together, you can just throw that one away. You can just cross it out, and you get the same expression. So on the right, all I've done is I've taken the two left terms and then dropped the right term. So this is called consensus because when these terms are true together, this one is implied. That's where the term consensus comes from. The consensus of these two terms implies this term. So I find it non-intuitive algebraically, so I'll show you KMAP. So the green ones are the two terms that we're using on the left. So AB is the vertical green loop here. A prime C is this loop, the green loop down here. And BC is the black loop. So you can see, well, if I put ones for those two loops, then this loop is also true. It's also an implicant. So that's consensus visually. Using it algebraically, you've got to spot the matching between the variables and their complements. But at least, hopefully, after this, you understand why it works in the algebra. I don't. But you've got some expression. In general, it could be more than a variable, but it's B here. It could be an arbitrary expression, another arbitrary expression, C. And then ANDed with those two, you've got a variable and its complement. And then the third thing that you need, the thing that you're going to cross out, is the two expressions B and C ANDed together. Yeah, B and C can be expressions. And I think A and A complement could also be expressions. A could be an expression and complement. Anything? Yeah. OR distributes over AND. So you know the principle of duality. And you take this one, and you get the dual. How it actually works is here you've got an OR that you would normally apply after the AND. And instead, you take the OR across each of the factors in the product, and then you multiply those ORs together, which is what you get on the right. So you take A ORed with B, A ORed with C, and multiply those two together. If you had BCD here, there would be A plus D. Make sense? Yeah, it's somewhat non-intuitive, of course, because you would never do that in our normal algebra. Yes, yes, yes. The principle of duality says that if you have an identity, which means an equation, or a property, and you take the dual of that, it has the same truth value. Yeah. Yeah. Yeah. So the A's have to match, except this one is complemented. And then this B and this C have to show up here. So you can have variables. You can replace A, B, and C with arbitrary expressions, but those will be harder to spot. We're not going to have you do a lot of hand-based Boolean algebra optimization. These days, the CAD tools will do it for you. But if you write the next generation of those tools, you need to understand this stuff, because you're going to have to write programs that use these optimizations to manipulate the expressions internally to the program. Yeah. I mean, the underlying math is, yes. So what's done these days is there's something called binary decision diagrams that try to split the space somewhat optimally. So you look at your function. You try to pick something that will divide it well, evenly. So you pick one of your variables, and then you say, well, this is the best variable to look at first. And then you do the same thing recursively. So those are what's used in modern commercial tools to talk about functions and to compare functions. And it's well beyond the scope of the class, so don't worry if you don't. OK. So this was the consensus illustration. And consensus, of course, has two forms. You can take the dual. So if you take the dual, you'll get this one down here, which I won't show you a K-map. But you can do that one, too. So that's it for Boolean properties. Yeah, I think the main ones to learn, duality is useful in the practical sense of designing gates and also taking the complement of arbitrary expressions, generalized DeMorgans. But I think the short identities for analyzing circuits, just knowing that if you put things together, you've got a 1 with an and. Well, you can ignore that input. 0 with an and, a 0 comes out, those kind of things. Those will help you analyze circuits quickly. Some of the others are just useful for doing algebraic optimization or equivalence. All right, so let's talk about don't-care outputs. 15 minutes or so, a little more. So sometimes we don't care. So we've got a function. We don't care whether a particular input combination generates a 0 or a 1. So when would that be the case? So in some cases, we may say, well, that input combination can't happen. So for whatever reason, it's just impossible to get that input combination. So the output doesn't matter because we're never going to generate it. Our system will never generate that output. So who cares what it is in the equation? Sometimes also you'll get designs where your hardware is part of a bigger system. And you know that if you get that particular input combination, whatever your system outputs is ignored. So who cares what you output? It doesn't matter. So there's a couple of common cases where we don't care what the output is. So what good is that? In such a case, we can mark the output as an x, which means don't care. So instead of writing a truth table with 0's and 1's on the outputs, we can put x's. And that says, well, either 0 or 1 is OK. Now be careful because whatever you actually build will not generate an x. Hardware does not generate x. It generates 0 or 1. So whatever your design ends up being, it will generate 0's or 1's. So you need to make sure before you go putting x's that it's OK to have any combination of 0's and 1's for those outputs. Because if some combinations are not OK, you actually do care. So why is this useful? So more choices means a better answer for pretty much any choice of metric. So say you optimize a KMAP for some function f. And then you say, well, maybe I don't have to use f. I could use g or h or j. So the best answer amongst those four is always at least as good as the answer for f. Because you could always just say, OK, I'll pick f after all. So you're never going to get worse. You might not get better. But in general, you can get better. And you can never get worse if you look at more functions. So using an x actually means that you're looking at many functions. Each of those x's gives you two choices of functions. You could pick the function that has a 0 in place of the x or the function that has a 1 in place of the x. So if you have n x's, that means you're picking from 2 to the n possible functions. So if I put 4 x's in, I've got 16 functions I'm picking from. And I'm going to pick the best of those 16. So often, that's going to make my logic simpler. So that's why instead of saying, well, I don't care. Let me just put a 0 or let me just put a 1, instead by putting an x, I can get better answers. Let me show you how that works. So here's an example of a function. And what I've done is I've filled in the answers I care about. So I filled it. I've partially specified my function. I put some 0's and 1's in. I say, I need to generate this function. And I don't care what the outputs are here. So let me put in x's there. So actually, let me show you what happens if I do something different. So if I put in 0's, say, OK, I don't care, but I'll just put 0's. Then let's solve this K-map. So what do I get for this K-map? What loop should I circle? The 1, 1 loop? Let's see if I did that one first. Yeah, 1, 1. I thought I understood, but maybe I didn't. I circled that one first. 1, 1 at the top. Yeah, bottom left wrapping around is the other one, right? Good. So we've got those two. And I think we're done. OK. So that gives us a b forward with b prime c. Yeah, that's not too bad. You might say, OK, that's a nice function. It's too challenging, a few gates. But we didn't have to pick 0's. We could have picked other values. So what if we pick a 0 and a 1? Let's put a 0 and a 1 there. So now what do we get? Let's solve. So we still get that one. We still get that loop. And then the one on the bottom goes all the way across now. So now our function f is just a b plus c. So we got rid of a literal. So if instead, I mean, again, I didn't care about these two outputs. So if I picked a 1 here instead, well, then I'd have 1 fewer literal. I saved myself a couple of transistors. Better answer. Well, so instead of going through all four possibilities, here there's only four. If you had more unknowns, I'm sorry, more don't cares, then you'd have to go through lots of functions. Instead, let's write x's into our K-map. So now we're going to have slightly different rules. So the rules are going to be I want to still grow my loops as big as I can. But instead of only covering 1's, I can also cover x's. x's can be 1's. So I can also grow a loop to cover x's if I want to. And I still have to only cover all the 1's. I don't have to cover x's, because x's could be 0's. So that's the modification to our rule. Grow loops as big as we can, possibly including x's. Just still cover all the 1's. And the same thing if you wanted to do a POS solution. Grow loops as big as you want around the 0's. You're allowed to include x's, but you don't need to cover the x's. You only need to cover the 0's for POS. So same set of rules. So now if we solve this function, now we're actually able to grow out to the left for this loop. So instead of just this loop here, now we can include these two x's. So it's gotten bigger. And then on the bottom, we can also include this whole row. So what's the answer? Well, b plus c. And that's the best of those four. So instead of drawing four different k-maps, solving them all, and then comparing, I can just write x's into my k-maps, modify my rules for solving it slightly. And then I'll get the best answer amongst 2 to the n. And here is 2, 2 x's. Yeah. Yeah. So that's a good question. So what actually happens to the x's? Because as we talked about earlier, whatever you implement will generate 0's and 1's. It will not generate x's. So the x's, if they're inside a loop, those will become 1's with the function. If they're outside all of the loops, they'll become 0's. Yeah. Yeah. So if you solve the k-map optimally according to these rules, and technically, you'd have to look both for POS and SOP forms, because those are not necessarily optimal relative to one another. But if you simply solve it following these modified rules, you will get the optimal SOP form. And if you solve it following the modified rules for 0, you get the optimal POS form. Yes, but you're doing it in a way that you make your loops as big as possible without adding extra loops. Yes, yes, yes, yes. So the modification is grow the loops as big as you can. You're allowed to include x's. So it's the same rules. You're allowed to include x's, but you don't need to cover them. So hopefully, that's clear. The tool does allow you to practice and check your answers. If you feel like you're not sure, go play with it. Do a couple examples. Any other questions? And we'll actually do a couple more examples in class. OK, so yeah, so you'd ask, well, are they 0's or 1's? It's a good habit to put the 0's and 1's in place of what you got, and make sure that that answer is, in fact, OK. So these two become 1's, because they're inside of a loop. We didn't have any x's that are outside of all of our loops, so none of the x's in this solution become 0. And we also don't have any context for this example. I just said, here's a function I want. Now, if you have a bigger context, you should evaluate this full solution in that context and make sure that it's actually OK. So let's do an example. I'm getting hungry. Let's have some ice cream. The example in the notes has lychee, but I couldn't find lychee. I was a little disappointed, but pistachio's pretty good. So you guys like ice cream? OK. We'll do an ice cream dispenser. I expect this to work by EOH, by the way, so I can eat ice cream at EOH. All right, so three buttons, inputs. So we're going to have mango. We're going to have three kinds. You can pick mango. You can pick pistachio. Or you can pick a blend. And there'll be three buttons for you to push. You pick which kind you want. And then out will come the control outputs for the actual mechanical dispenser, which will be two bit unsigned numbers that say the number of 1 1 cups of mango. So it could be 0, 1, 2, or 3 1 1 cups. And the number of 1 1 cups of pistachio. So we'll design using this set of inputs and outputs. And we'll build the logic in between those two. So let's write a truth table. So help me out here. So what happens if I push M, I want to get 1 cup of mango. So what should I write for CM and CP? Remember, it's the number of 1 1 cups as an unsigned number. So what should CM be? Yeah, so when M is 1, so down here, 1 0 0, CM should be 1 0, I think. We want two 1 1 cups, so 1 cup of mango. What about pistachio? How much pistachio should come out when I pick mango? 0. OK. So second case, I push B, the blend. I want to get 1 1 cup of each. So where's blend? So blend, there. 0 1 0. So I push the blend button. How much mango should I get? 0 1. How much pistachio? Good. All right. And then the third option, I push P, the pistachio button. I want to get 1 cup of pistachio. So let's see, that one's here, right? 0 0 1. So how much mango? 0. How much pistachio? 1 0. Good. And then the fourth one I have to worry about, well, if I don't push any buttons, no ice cream should come out, right? OK. So that's the 0 0 0. So what mango I should get? 0 0. And pistachio? Good. And what about the rest? Hmm. Tough. You know, I just don't care. All right, I don't care. Who cares? Fill in with x's. I don't care. Yeah. Oh, very good question. Let me come back to that. All right. Yeah, see, this is the problem with trusting the human, isn't it? All right, so we can copy these to KMAP. So let's start with CM. So to copy to KMAP, I put these in an order where the last two variables are across the top, and then the first variable's there. So we're going to copy. Well, let me just show you the order. So we're copying these blue ones, the high bit of CM. So the first row is a 0, so that goes in the upper left. And then we're going to copy to the right. Now, this one's gray-coded. So instead of going here, which is 0 1 1, we're in binary order over here. So 0 1 0 is actually on the far right. So we'll say 1, 2, over to here, and then back. So 0 0, 0 goes there. The x goes in the 1 1 slot. So you want to get used to this so you can do it quickly, copying from truth table to KMAP. Remember that your truth table's typically in binary order. Your KMAP's in gray-code order. So you've got to make sure to switch them, otherwise you get the wrong answer. All right, so for the bottom, we've got 1 xxx, the 1, and then the x's are just filling the rest. So what's the answer there? Solve that one for me. Yeah, let's do SOP. Good question. In this case, it's actually the same, I think. Yeah, OK. So M, right? But my loop is SOP. OK, so the high bit of the mango output is just the mango button. Good. Not even a gate. Sorry. I'm so excited about my ice cream. All right, so let's do another one. So what about the low bit? So now I've highlighted the low bits there. So if I just copy this over, here I've got 001x. So I'll fill that in, 001 on the right side, x in the 1 1 slot, and then 0xxx, 0xxx. So what's the solution? B, like that? OK, good. OK, so the low bit is just the blend button. Hey, I don't even have a gate yet, just some wires. That's nice. We can do pistachio, high bit, 010x, 0xxx. Answer? B. OK, and then the low bit of pistachio, 001 on the right side, x, 0xxx. Solution? B again, huh? Good. So there's our design. Very easy design. The x's made our life so easy, we don't even have to have a gate. Just take the wires, connect M to CM1, connect B to both of the 0 output bits, and P to CP1. We're done. Very nice, very cheap. So what happens? Mohamed, you asked this question. What happens if a user presses M and B at the same time? Bad human. Who cares? The janitors care. You're going to find out. So we'll put that in. Let's say we put that in. What comes out? Well, a 1, a 1, a 0, and a 1. So we're actually getting a 1, 1 in our mango control. So ideally, what that means is, well, 3 halves of mango and 1 half of pistachio. So maybe it overflows the cup. That's a good case. We hope that what happens is it overflows the cup. Now, unfortunately, the person who designed the mechanical dispenser may have assumed, well, they shouldn't be giving me a 1, 1. So something bad actually could happen if you give them a control that they don't expect. Mechanical systems may not be that flexible. So if you send the 1, 1, ideally, yeah, it just spits out too much ice cream, and someone has to get a mop. But worse things could happen. So we do care. Using don't cares when some human's driving is just not a good idea. You've got to be careful. Don't assume that they're going to follow rules. So how can we fix this? So one choice is we could pick specific outputs. So we said, well, let's just pick 0's. You push two buttons, you get nothing. You push three buttons, you get nothing. So instead of saying x, we'll say 0's everywhere and just fill in all of our k maps. And then we can solve that. We'll have a bunch more gates. And that'll give us one answer. Another way we can do this is to actually add some logic in between the inputs and the outputs to do what Mohammed suggested initially, which was keep the humans from pressing more than one button. So actually a few choices there. Here's one of them. So what this one does is any time the human presses more than one button, it forces all the outputs to 0. So this dotted box is just some extra logic between our inputs on the left and our outputs on the right. So nothing has changed except I put a little logic device here. And you can see that this AND gate up here produces a 1 only when the human pushes mango, but does not push blend, and does not push pistachio. And similarly, these two produce 1 only when the human doesn't push another button at the same time. So that's one choice is to add what we'll call glue logic. But we're running out of time. So let me come back and go through this in more detail on Friday. But the main point is make sure that you don't care. Don't assume humans will do things. If you're working with another piece of logic, make assumptions. If you're working with another piece of logic, you You You you you\"},\n",
       " {'ECE120-2016-10-14-LEC-22-slides.mp4': \" I've got some examples. OK, so let's get started. So today we're going to spend the whole day doing examples of finite state machines. So we'll do one quick one, which is a two-bit grade code counter just to familiarize you with this process we talked about at the end of the day on Wednesday for designing finite state machines. Then we'll do a slightly more complicated one. Color sequencer has some don't cares in it, so we'll look at that one. And then I think maybe about half or maybe even more, we'll talk about the finite state machine that you're going to be building in the lab. So you've already been kind of playing with that for a couple of weeks, several weeks now. And you'll be building it in the next week and a half to two weeks. More examples of finite state machines, section 3.3 of the notes has examples. Probably we won't cover most of those. There's actually more examples in 3.2 also. So if you're looking for examples, you want to make sure you understand it, look at those. Also under midterm 3, review materials, there's a whole bunch of old test questions for which I wrote answers. So I think it's kind of down. Scroll down a little bit, and it says old EC 190 exam questions on finite state machines mostly. So you can get lots of examples there with solutions. Of course, I recommend you solve them and then look at solutions instead of doing it the other way. All right, so another reminder. Here's the midterm. You've seen this slide many times now. The review session we'll do on Monday in class, so come prepared with questions or topics anyway and questions. So I just wanted to then remind you of other resources. So there are still online tools for this part of the class. You can practice your skills, watch the review video, or also Professor Jaramillo's. Attend any of the three lecture times, assuming the fire marshal doesn't get mad. Go to office hours, and there is this Eta Kappa Nu review session, which is Saturday 2 to 4 PM in 1013 in this building. Same caveat as yesterday, so I will go over that. Same as last time, too. All right, so this was the six-step process that we talked about using for designing finite state machines. So we start out by developing the abstract model, spec the IL, input and output, complete the specifications since we're building with digital systems, any input combination, any state will go to a next state. There will always be outputs. There's never any blanks or anything like that. Everything's built out of bits and Boolean expressions. Once we finish completing the representation, making whatever design decisions we need, we'll pick a state representation. I gave you some ideas of how to do that. Now you'll see some examples. And then we'll calculate logic expressions and then implement with flip-flops and gates. So those were the six steps. So let's go ahead and use that approach to design a fairly simple counter, a two-bit gray code counter, using this methodology. So what's our abstract model? Well, it's just a counter that goes through four states. So start in one state, go to the next state, go to the next state, go to the next state. And it's a counter, so go back. So that's good enough for an abstract model. We've got four states. The inputs, then, well, it's a counter. There are no inputs, so we're done. The outputs, well, we said it's a gray code counter. So let's go through a little gray code. So we'll start at 0, 0, then 0, 1, then 1, 1, then 1, 0. Then we'll start over. So a two-bit gray code counter. Completing the specification, well, there's no inputs. So every state here has one outgoing arc labeled with nothing because there are no inputs. And the spec's actually already complete. So there's nothing to do, no design decisions to make, or anything like that. We know the outputs. I didn't write them in here yet, but basically, this is count A, count B, count C, count D. So next step, then, is, well, what do we want for a representation? So any time our output bits are unique, that is, every state has a unique pattern of output bits, one choice is, well, let's just use the outputs as the state ID. Now, sometimes that's maybe not the right thing to do. If you have 500 outputs, but you only have 10 states, well, you only need a few flip-flops, right? So to say, well, I'm going to have 500, that's kind of silly. But usually, it's not going to give you such a bad answer. In this case, it's actually optimal. We've got four states. We need two flip-flops for the state. And we've got two outputs. So we can use the same two bits that we have for output as we use for our internal state. What that implies is we have no output logic. So for each of these states, remember, the state's on the left. The outputs are on the right. So you can see they're always the same by design, by choice. And so the outputs are simply S1 and S0. So that's why this is a useful approach. When you need to generate output bits, you do it without output logic. Now, all we have to worry about is the next state logic. So from this design, this is a complete state diagram, complete state transition diagram. So we can just go ahead and write a truth table from this. So let's write our truth table. So from 0, 0, where do we go? 0, 1. And then 0, 1, we go 1, 1. And then from 1, 0, where do we go? 0, 0. Good. And 1, 1 to 1, 0. Good. So now we have our truth table. And you can see, sorry, I put this one up. You can just basically read these off. I'm not going to bother with k-maps for this example. So S1 plus is here's a 1 and here's a 1. You can see it matches S0. So it's just S0. And S0 plus is what? Not S1. OK. So those are our next state equations. They tell us the state of the system in the next clock cycle. Remember, that's what the plus means. So discrete time, next clock cycle. If the system state is currently these values, in the next clock cycle, it will have these values. So we can design it by just implementing the next state logic, which is just wires. So S1 plus is S0. Here's S1 on top. So the D input comes from here, which is the S0 output. So next state will be S0 for S1. And the next state for S0 is S1 prime. So here's S1 prime coming out, going into the D input of S0. So just hook two flip-flops together with a couple of wires and you have your two-bit gray-proof counter. So that was a fairly simple, easy example just to get us started. So now I want to do another example, same process. So I put a review slide in here, but I mean you saw it a couple of minutes ago, so I won't spend much time on it. So what's a color sequencer? So imagine that you have this LED that will be one of eight colors. So you get a three-bit input, red, green, and blue. And based on your three-bit input to your LED, it produces one of these eight colors over here. This is actually what old computers used to use about 25 or 30 years ago for their color displays, was eight different colors. That was a long time ago, before you were born. So let's build it. Now you can get an LED that does that instead of a computer. Let's build a color sequencer that cycles through a set of these colors. So imagine we've got this light, and our FSM will basically drive these output bits, R, G, and B, to produce the colors on the LED. So what's our abstract model? Well, again, it's a counter that's going to go through five colors, in this case. So like this, say we start in red. I get to pick the color, sorry. We go to green, we go to cyan, we go to white, we go to blue, and then we're done. So that's our color sequencer. So we want to design a finite state machine that just goes over and over through these five colors. So you can imagine you put it out in front of the building. Oh, wait, someone beat us. OK, so they did something like that. You can do this in the lab if you want. You can put it inside that thing. All right, so what are the inputs? Well, it's a counter. So we're staying with simple examples. So outputs, we're just going to use the RGB code. So we're actually told what we need to do to produce these colors. So the outputs we need, say for the blue state, will be 001. So we'll just inherit those bits for output. So let's add those. So red was red, green, blue, 100. Good. Green's in the middle, right? 010. Cyan is green and blue, so 011. White is all three, so 111. And blue, red, green, blue, 001. OK. All right, so now we have our outfits labeled on our states. So what's next? There's no inputs. So when we say, well, let's complete our specification, there's nothing to add. Every state has already all of the arcs leaving that state. There's no decisions to make or anything. They've already been made, rather. So our spec is complete. Now we can pick a state representation. What do you think we should use? Maybe the same thing, right? We've got unique output patterns here. You know, if I picked green down here, if it went twice through green, then we couldn't make this choice. Because then our outputs are not unique. And of course, the next state from green would have to be one next state. So if we had two similar colors, or identical colors, rather, on our loop, we could still build that finite state machine. But we couldn't make the choice of having the outputs also be our state IDs. But it didn't do that. So let's go ahead and make that choice. So the outputs are unique. So we'll use them for our state IDs. So we'll add them in. So red, we'll add that in. Green, add that in. Cyan, white, and blue. So now this is a fully specified finite state machine state transition diagram. It's got all the bits on it. And we can map it again to a truth table. Question? Yeah. Do you need to pick up the output patterns? Yeah. So remember, in the machines we're going to look at, it's always state bits followed by outputs. And I probably should have put it somewhere near this diagram. But the outputs in this case are red, green, and blue. And the state bits are always going to be largest bit. So it'd be S2, S1, S0. But that's a good question. Yeah, there's no implicit order necessarily for the outputs. So make sure that you label your diagram somewhere. I know I left it out here. It was kind of in the previous one. Yes? How are we going to do this? How are we going to change it? You'd have to have two states with separate state IDs. So the question is, what if I did make, let's say I change this to green. I can no longer, the output bits have to be 010 to drive our RGB for both of those green states. So I can't have 010 for two different states. I would have to actually pick a different state ID for one of those two green states. So it's only the fact that these are unique that allows us to do this. So time to fill in our truth table, or next state table in this case. So let's see. Let's do it the easy way this time. So from 100, we're going to go to 010. So 100 go to 010. Where do I go from 010? 011. So I'll fill that in up here. And then where do I go? 111. So where was 011? Here, right? OK, good. And from 111? 001 down to here. And then from 001, I go to 100. What about 000? We don't care. Good. I don't care either. What about 101? OK, me too. 110? I care about that. No, I'm kidding. All right, so we don't care. Good. OK, so we'll fill those in. And now we can copy to KMAPs. So we'll start with S0. So here's a KMAP for us. So the same order as always. So I put S1, S0 on the upper one so that I can copy horizontally. But remember, grade code order in the KMAP is binary order in the truth table. So we're going to go first, second, hop over here for third, and then go back for the fourth. So X011, X0, hop over one, and put the other one there. And then 0XX1, so 0X, hop over X, and put the one there. What loops? A square over this one, right? OK, good. What is that? S1? OK, good. So S0 plus is just S1. That's easy enough. Good, I like that. All right, let's go on to S1. So fill in our KMAP again. So read them off for me. X0, hop over, 1, 1. OK, and the next four? 1XX0. OK, good. Loops? Hmm, is there a square? Oh, there is, yeah. Oh, that's better than my answer, sort of. All right, that's not my answer. You get another answer? Ha ha ha. Let me show you my answer, and then we'll. I like that one. You're right, the square is sort of better than that one. But I can add this one. And then I get this thing. The square is better, but that's an X0. So the square might be better. Yeah, the square might be better. Yeah, the square could be better. All right, so we'll have this one for the S1 plus, S2X or S1. What about S2 plus? So do the same old thing, copy KMAP. So read them off. X1, 1, 0. X1, 0, yeah. Sorry, don't switch them, because I put them in the hopping order here. And then 1. OK, and the next row? 0, X, X, 0. Good. OK, what do we have there? Just the two on top, right? I actually, yeah, I think you, sorry, I wanted to go back and look if it were unique. So do keep in mind if we're making choices. I kind of made a weird choice last time with the XOR. But I think actually that one might be unique if you want the way you were going. But I'd have to look at it again to verify that. OK, so here we have, sorry, I should have let you read this one off. It's S2 prime, S0, right? So S2 prime on top, and then S0 to isolate these two from the outer ones. I'm going to rewrite that as a NOR gate, because I'm going to map this into CMOS. So this is one NOR gate where I take S2, OR it with S0 prime, and then take the complement of that. So that's a NOR gate, right? So if I draw this thing, I have one NOR gate for S2. Remember, it took S2 here and S0 prime down here. And it NOR'd those together. And that's S2 plus. S1 plus was S2 XOR'd with this one here, which is S1. And then S0 plus was just S1. So it comes down this way. So that's our implementation, three flip-flops, two gates. Yeah? How do you get from 5 to 20? So not one that I know off the top of my head, because I think I have extremely limited Arduino programming experience. In general, you can, as I put this, so with hardware or software, generally speaking, most of the programming languages are what we call Turing-complete, which means that you can express any computation. So if you think back to the first day of class, we said that computers are all the same. What that really means is that a computer that's able to, if we can map it systematically from one computer to another in terms of its capabilities, which is generally true of all the computers we build, but not necessarily all of the programming languages, we say that computer is Turing-complete. Most programming languages are Turing-complete. So you can define your language any way you want, and then figure out how to map it. Now, hardware is actually a little more difficult than that, because you have lots of space and speed constraints. So it's very easy to write a language that is hard to map to hardware. And so, for example, most high-level languages, it's very difficult to build hardware from those. So I think the Arduino language is more constrained, but I couldn't tell you the exact mapping off the top of my head. I'd have to look it up. OK, so this is an implementation. So excited? You probably want to go to the lab, get your protoboard out, right? Takes a while. Being a surveyor? Yeah, good. You know what to do, right? Going on. Don't care. Bits? Yeah, they're bits. They're bits. Good answer. What did happen to those don't care states? We left those don't care states lying around, and we didn't check what happened. So let's take a look. You can just plug into equations. If they find that easier, it's fine. It's the same. I'm going to plop up our K-maps. There was our K-map for S2 plus. What do those x's become? All zeros, right? Because the only loop is this one up here. The x's are outside all of the loops. That means they're all zero. Good. So the x's become zeros for S2. So let me write that as this. So we've got these three unknown states. So one of them is 0, 0, 0. And that's going to go to 0 something something. We've got 1, 0, 1. That's going to go to 0 something something. We have 1, 1, 0. That's going to go to 0 something something also. Good. So we figure that one out. What about S1 plus? Where are those x's going to go? This one is what? This is 0. What's this one? 1. And what's this one? 0. Good. So we've got one of them going to a 1. The 1, 0, 1 state goes to a 1. So now we can plop up these three again. We've got 0, 0, 0 goes to 0, 0 something. 1, 0, 1 goes to 0, 1 something. And 1, 1, 0 goes to 0, 0 something. So let's take a look at S0. Where are those x's going? How about this one, this one, and this one? Good. So we again have one x, different x this time, going to a 1. So if we fit those into our final next state equation, we've got 0, 0, 0 goes to 0, 0, 0. 1, 0, 1 goes to 0, 1, 0. And 1, 1, 0 goes to 0, 0, 1. So what comes after 0, 0, 0? And what comes after 0, 0, 0? When you were kids, did you ever play that game where you write I shouldn't say that. You write something mean, and you say, but if you're not that thing, then read the other side. And then you write the same thing on the other side. And you see how many times your friends flip it over. Yeah, so OK. So let's add those states. So there's black. It has a self loop. There's violet. It goes to green. There's yellow. It goes to blue. So violet and yellow, maybe we don't care so much. We turn it on. If the flip-flops start in that state, in one cycle, it's just going to fall into our state. And it's just a light. So then OK, fine. But if it starts in black, it's going to stay in black. If we turn it on and the light is black, light's going to stay black. And it's not ever going to change because of our finite state machine design. So what can we do? So we're going to have to add some way to initialize. We can pick some specific hardwired initial state. Picking zero maybe is not the best choice here, because that's black. Stay black. There's an easier way to design that FSM. We can use muxes. So we can say, OK, let me put a mux in front of every flip-flop. And then I can put an initialization bit in. And then I can choose, using one input to control all three muxes, do I want to force my finite state machine to display a specific color in any cycle? So I can always put it in whatever state I want, using those muxes. Or I could just pick one signal and force the system into the loop. So for example, I could add a NAND gate to the S0 flip-flop input so that it was S1 prime init prime NANDed. So this would be an active low init signal. And that would, let's see, when that's 0, a NAND gate would force that to 1. So that would force S0 to 1, which I think would push us back into the loop. So we'd go here, here, here, or there. And all four of those, cyan, white, violet, and blue, all of those fall into the loop. So if we were to add that initialization gate, one gate, then we could force the system eventually into the states that are valid. So the other thing we could do is just go back and say, well, now, let's go back to our k-maps. And let's pick specific ways to fix this problem. So go to 0, 0, 0, and change one of them to something that isn't 0, and then solve again. That may take a couple of iterations, because you're going to change the loops, and you may just create new problems with new loops. You can also just choose specific next states for all of them. So you say, well, let me just design the complete system. Both of those approaches are going to add logic. So regardless of whether you just try to think it through of, well, could I limit it to one gate somehow, or could I just go back to the drawing board with my k-maps and play around with it till I get it right, doesn't really matter. At some point, you have to go back and add some way to push it into a valid state. So just be careful with the don't cares, because if you end up in a state that goes in a loop outside of the loop you want, you may never get back into the loop you want, depending on the design. Any questions on this one? Seemed pretty straightforward and understandable. I expect you all to go build this in the lab. Yeah, so in this case, I picked a specific solution. So knowing the design, I looked at the design. I said, well, if I can push it into one of the states that ends in s0 equals 1, then from those four states, let's see, cyan, white, and blue are already in the loop. Violet, we know, once I turn initialization off, will go to green. And so it'll also be in the loop. So if I can force s0 to be a 1, then I can push it into the states that I know work. So what I did is I said, well, how do I force s0 to be a 1? Originally, I had s0 plus equals s1. So now this is init low, active low. So if you put a 1 here, then you get s1 prime prime. So it's still the same thing. I didn't change the actual functionality of the finite state machine by adding this NAND gate, because I switched s1 to s1 prime. So now that flows through. It gives me the same answer before when init is 1. When init is 0, this and in here is 0. Complemented, I get a 1, s0 plus is always 1. So it's an active low initialization signal. So this one is custom tailored to our design, which enables me to use just one extra gate. Anything else? Where we are in time. OK. Still enough time. All right. So let's look at the lab machine. I want to tell you a little bit about it first. So your task is to control this coin-operated vending machine. We'll have inputs produced by coins. So as you put coins into the physical machine, which will be about yay big on the table, then it will produce inputs for your finite state machine. The outputs then specify, well, should the machine accept your coin or send it back to you? And then also, should a product be released? Unfortunately, we couldn't get the products into the lab, so you can't buy anything. But there is a signal that you have to generate. So the design is pretty simple, right? Because you're going to be building this out of TTL chips. So we didn't want you using 20 or 30 or 100 chips. We wanted to limit it to a few chips. So that's why it's a fairly simple design. What's the point of this? So Doug Jones and I designed the class. So Doug's view was that he wanted everyone here to understand the connection between the real world of building stuff with wires and chips and the paper world of lines and boxes. So he wanted to make sure all of you understood that connection and the way to do that is get your hands onto something real and build it to represent, or rather, build the thing that you've represented on paper as a finite state machine. My point of view is I want to make sure that you understand that the knowledge you're getting in this class actually will enable you to go out and do real world stuff like sensors and actuators, right? So finite state machine, you can go build a vending machine, like a real one for ELH for fun. Or you can build a robot. You can do lots of stuff with sensors and actuators. So Doug Jones designed the original finite state machine. The derivation in this in the slide is a little different from the ones in section 3.4 of the notes. So read both. And if you understand one better than the other, that's OK. They both end up with the same design. So that's what you have to implement in the next couple of weeks. Chris Schmitz, who you may know from 110 or something else, he did the original prototype hardware. So he did that for us. He worked for a first few semesters. Vlad Kendutenko, who's also taught this class many times, helped the design as it scaled. So he redid some of the design. As we had more and more students, we had fewer people to help with issues in the lab. And Professor Jaramillo and Casey Smith, who's the instructional person in ECE, did the current design to eliminate basically all of the issues. Actually, one remaining issue, which is these are optical sensors. And I'll try to remind you later. But please keep the shades down, because otherwise, the people with benches near the window will get light coming into the optical sensors from the sunshine. And that can make noise. And so it might not work for them because of the sunshine. So just be careful working near the window and try to keep the blinds down. But that's the only remaining issue that we know about. So here's the physical system. So you can see there is the coin slope. So you put the coin in. And it rolls down. And there's a gate here that your finite state machine controls. So it can either drop down. And then the coin comes down here and is accepted. Or it can stay up. And then the coin rolls through and falls out the other side. That means the coin was rejected. So those are your two choices. Here's the interface ribbon cable to your protoboard. The optical sensors are here. But let me zoom in in a second. So these will produce your clock signal and your T input, which is which type of coin. This gate is controlled by your A output. So let's zoom in a little bit. So you've got two optical sensors. One is for the clock, which is here. And one is for the type of coin. We're only going to put two types of coins. So one is a dime. For those of you who might not be familiar with US currency yet, the dime is a very small one. It's worth $0.10. And a quarter is very big. That's the other coin. So when the dime rolls through, it will hit the clock. But it will not hit this T. The optical sensors generate a 1 when they're blocked. So when the dime rolls through, it will generate a clock high and then low. So will the quarter. But the T signal will only be generated by the quarter. So in order to know whether you have a dime or quarter, you look at the T signal when the clock edge goes up. So I'll show you that in a second. We've also got LEDs on there. So when clock T and your accept input are high, or output are high, LEDs will light up on this board here. And this is the place that the coin rolls by. So here's a dime in action. So you can see the dime rolling there. So dime rolling into the machine, you can see that it's hitting the clock signal there. So the clock is high and that LED is lit up. On the other hand, T is low. So the T sensor is up here, remember. So it's still optically stable, connected to the other side. And here is the dime's timing. So what I want you to notice here is the T signal just stays low. The dime doesn't hit it at all. The dime's too small to block that sensor up there. So T stays low. The clock signal, on the other hand, goes up for a little bit. And then once the dime passes this optical sensor, it drops back down. So we'll talk a little more about the clock in a couple of slides. So here's a quarter. So a quarter is going by now. And you can see that clock is high again. But in this case, T is also high because the quarter is blocking this upper optical sensor. So down here is a quarter's timing. So you can see that the T signal goes up first. So T is going to be stable on the rising edge of your clock, which is important because, of course, you're going to use positive edge triggered D flip-flops. And so you will sample T on the rising edge of the clock. You can see here for the quarter, it's a 1. And over here for the dime, it's a 0. So that's the T input to your finite state machine. So the clock's a little weird. So the clock is not a square wave. It's generated by an optical sensor only when the coin rolls in front of it. So how big is that pulse? Well, it depends. If you shoot the coin in, it'll be narrower. If you let it roll slowly, it'll be wider. Humans can't make the coins go fast enough to matter. So don't worry about that. But it's not periodic. The cycles in our clock are defined by when you put the coins in. They're not periodic. It's not a square wave. Yeah. So asynchronous is always with respect to something. So this is a clock signal. And your finite state machine is synchronous with respect to this clock signal. It's just your clock signal's kind of strange. Most clock signals, they're periodic. They're square waves even. This one is aperiodic. I mean, you get a cycle every time you put a coin in. Yeah. And it will change synchronously with respect to your coin insertion. So coin insertion will give a rising edge. And your finite state machine will take one transition. So it's exactly the same from the point of view of everything we've talked about with clock synchronous sequential circuits. Nothing to worry about there. Good question, though. All right. So yeah, I was just kind of going through this. It's sufficient for our needs. You work with these positive edge trigonometry flip-flops. And so because the way their optical sensors are positioned, t is stable. It'll be 0 for a dime, 1 for a quarter when the clock edge rises. So you get the right input. I should mention, by the way, I meant to say it, but all the work that Professor Jaramillo and Casey did also means you can more or less get this entire thing working at home and then bring it in and just test it in the lab. We do recommend that you test it in the lab. There shouldn't be any issues. So if you have it working at home, it should work in the lab as well, unless you're sitting in the sunshine. So be careful about that one. But all right. So let's talk then about the finite state machine. So what's a sequence recognizer? We actually built one already or designed one already. It was even just Wednesday. I think it was Monday. We developed a 0-1 sequence recognizer. It looks for a pattern of bits in a serial input. So remember, we talked about machine models. It was Wednesday. And we looked for a 0 and a 1. So we can think of the vending machine that way as well. So for the lab, we can treat the sequence of coins as a serial input. We get 0 for dime, 1 for quarter. So 0's and 1's come in. And then the sequences that we want are 0-1 and 1-0, because in the machine, we're looking for totals of $0.35. So part of making it simple was to use this combination of coins, only two types of coins, total of $0.35. So you always have to have one dime and one quarter. So you can put the quarter in first or you can put the dime in first. But you're going to get either a 0-1 or a 1-0. So if t is our serial input, we have to produce a product release output, p equals 1, whenever we see 0-1 or 1-0. Actually, it's a little bit, it's not quite the same. But if we use this process, we'll get the right answer. Because if you, actually, no, maybe it is. Yeah, I take it back. It is correct. If you put a bunch of quarters in, then after the first quarter, it'll reject those. And then you eventually have to put a dime in, in order to get the product, because it has to be $0.35. So at the end of a bunch of quarters, you put a dime, then you've got a bunch of 1s and a 0. So that 1-0 at the end will be recognized and produce a product. All right, so we're going to use this following process to build a sequence recognizer. So we're going to start from a start state. And we're going to then build out the sequence for each of the sequences we care about by just adding one state per bit. Then we're going to complete it by saying, well, for each of the states, what do we want to happen if the other type of coin is put in? And for the end states, well, what if we put any coin after the end state? And then finally, we'll take a look and try to get rid of states, try to make it a little narrower. And then after we've designed that abstract model, we'll come back and assign state IDs. And that'll complete the lab, or rather, that'll get the lab to the point that you have to do the rest of the design, as you know. All right, so I wanted to make this a little clearer in the slide. So what I'm going to do is I'm going to use 0, I'm sorry, a black arc for the dime, and a red arc for the quarter. So that's the T input. And then for the outputs, which will mark states with slash AP, A is accept. So if you have an output of 1, that means the last coin that came in is accepted by the machine. It's kept by the machine. And if you have a 0, that means the coin gets sent back and the machine doesn't hold it anymore. P releases the product. And so if you send an output of P, that means you've collected $0.35 and you should give them whatever you're selling. I know what you can buy for $0.35. All right, so in the beginning, there's a start state. So then we're going to go through the dime sequence first. So if we send a dime and then a quarter, well, in our state diagram, we're going to add a state for that dime. So this black arc, again, means I put a dime in. And then I'll be in this dime state. So this one, I left the outputs unknown. This one, I need to accept that dime, but I'm not ready to output a product. I've only taken $0.10. So then when the quarter comes in, well, that'll be a red arc. So this means quarter. And that'll go to a state I'll call paid one. And there, I need to accept the quarter and then also output a product because I've gotten the dime and the quarter. So the other way this can happen is I put a quarter followed by a dime. So I'm also going to add states for that sequence. So those will be going down. So here's a quarter state. So first, I put the quarter in. It's a 1, 0 sequence. So here's the quarter. And again, accept, yes, and then put a product out, no. So the next state, then, I'm going to call paid two. I'll accept the coin, and I'll put a product out because I've gotten first a quarter, then a dime, $0.35. Now, remember, this is noted as AP. So A is accept. So you want to accept the dime but not put out a product. So all of these are AP. So these two, you accept the coin, but you don't have enough money yet. The paid one and paid two means they've paid fully. So you still have to accept the coin in order to have the money, but then you also give them the product. Yeah, so that's a good question. So eventually, we will merge those because we don't care. We don't need them to be separated. So you've already noticed that. And once you get experience with this process, you could do that too. The basic process is for every sequence, you just write down a string of states, and then you worry about merging them back together. So right now, we're just following this fairly simple process of every sequence I want to recognize, make a separate state for it. That doesn't always work because you may have sequences that share subsequence. And then, of course, they have to share states from the start state. So for example, if we said 001 and 0001, those two start with 00. So we can't split on one common input. We'd have to go to the same state for the first 0 and the second 0. So here we are. So what's next? So now we need to complete our specification, our transitions. So what happens when someone puts in two dimes? What should we do? 00, right? So reject it. And don't put out a product, obviously. You didn't get any more money for rejecting the coin. OK, so where did we go? So we've had one dime. We should accept the first dime, right? So we've got the first dime. And then from dime, right now we have a quarter arc. So now we need a black arc out of dime. And it should go to a new state that has AP equals 00. So like that, right? So reject D for dime. Yeah, rejected. All right, so what about three dimes? What about four dimes? Five dimes? Keep looping, right? We just keep sending the dime back. The user keeps putting it in. We keep sending it back. The user enjoys that. They can do it all day. Good design. All right, so eventually, so why don't we just finish this one up? What happens if we're sitting in that reject D state and someone puts a quarter in? What should we do? Go up to paid, right? So that kind of finishes the sequence. So let's do that. OK, good. So we've now got, the way to look at this is every state should have a red arc and a black arc coming out of it, right? Because every state, you could put a dime or a quarter next. So this one's done. This one's done. Let's see. Those are the only two that are done, right? OK, so let's do the same thing next for quarters. So if we put two quarters in, we want to reject the second one, right? So we'll have reject Q. I don't know how to pronounce that one. But again, it's reject the coin, and we don't have enough money, so we're not going to give them a product, right? And then if we give us more quarters, again, keep sending them back. And what happens when we get a dime? Go over to paid two. That finishes our quarter, then dime sequence. OK, good. So let's see. So these three are now done. So now we need to finish up these other four. This one doesn't have any arcs going out. So what's left to specify? The paid? OK, so how about that one, right? So from paid, I shouldn't have told you what I did. If I put in a dime from paid, I'm sort of just starting over, right? I've already just given out a product. I just got a new dime. That's now $0.10 I'm storing. So I just go to the dime state. So draw a black arc over there. Oh, what if I put a quarter in paid? Go to quarter. Good, OK. What about, let's see, what about down here? Where should I go for a dime? OK, and what about quarter? Quarter, OK, good. I think we're done now, actually, because I realize these also were finished already. So that's it, huh? So there, OK, yeah, there's our complete step two. All of the states have two arcs coming out of them. So now we can take a look and merge things. It suffices when you want to merge to find a couple of states with identical outputs and identical next states. Sometimes you can merge more, but it's harder to verify. So let's take a look. So what do you think I can merge? OK, you guys are too fast for me. But dime and quarter have the same outputs, right? It only matters next state, actually. Outputs and next state. So they have the same outputs, but the next states go different places, right? So they can't merge those. Let's see, similarly, let's see. Something has the same outputs. That's OK. Oh, paid and start have the same outputs. All right, paid one and paid two, good. So there's paid one and paid two together. What about merging and start? Because you can see now they have the same. This one's unknown. Paid goes here and here, but start also goes to the same places. Can I merge those? You don't want me to, OK. So I'm going to merge them anyway. The issue is when you turn it on, if you force it into this start state, then p equals 1, you might think, well, so when I turn it on, I get a free candy bar? That's something you should know about. You should try that. That never works. But in our design, it made it a little simpler to do that. So we're going to just merge start and paid together. It does have this strange side effect, but it made the lab machine a little easier. So for an educational thing, we just decided to go ahead and do that. So there's the five-state abstract model. So now we need to assign states. So what we're going to do is instead of the output approach, which actually you can see doesn't work here, because we have our two reject states that are different, and we've got our two dime and quarter states that are also different, but the same outputs. So clearly, we can't just label things with outputs. Aside from the fact we've only had two outputs, so we have five states. So let's instead use human information. So what I want you to think about, you've got the sequence of coins. And let's call the last coin we put in t0. So t is either a 0 for a dime or 1 for a quarter. And t minus 1 is the one before that. t minus 2 is the one before that, and so forth. So I want to define the state bits as follows. So s2 is just t0, whatever I put in last. s1 is going to be a 1 if out of the coins I put in before the last coin and since the last time I paid, I released a product rather, there is at least one quarter. And similarly, I should say dimes. Sorry about that. If one or more dimes are inserted before the last coin and then after the last product release, then I'm going to have s0 equal to 1. So this will record earlier quarters. This will record earlier dimes. And s2 will record the last coin. So let's fill this stuff out. So for a dime, if I'm in the dime state, that means since the last time I sold something, I've gotten exactly one dime. So what was the last coin I got? A dime, right? 0, good. Did I receive any quarters? No, so no quarters. What about dimes other than the last dime? There's only one, right? So the dimes you need. So the dime state needs to be 0, 0, 0. So here's a little state table or state ID table over here. So dime will be 0, 0, 0. What about quarter? What's the last? So if I'm in the quarter state, that means what have I received? One quarter. Anything else? I can't have received anything else. So what's the last coin I received? Quarter. So what about any extra quarters? No, so 0. What about dimes? OK, so 1, 0, 0. Fill that in over there. So now we have two state numbers. So this is a fine strategy, but if we end up with the same state IDs, we're going to have to change something. We can't have the same state IDs. But let's see what we get. So for a reject dime, what does that mean? We've seen at least two dimes to be in reject dime. And we haven't seen any quarters, because as soon as we see a quarter, we'll go let them get a product. So we've got two or more dimes. So what's the last coin we've seen? 0, a dime. What about have we seen any quarters? No, so this one should be a 0. And have we seen extra dimes? Yes. OK, so we got 0, 0, 1 for reject d. So those are still unique, so that's good. What about reject Q? Last one's a quarter, right? And what about the next bit? Extra quarters, right? And what about the next bit? 0, good. No dimes at all for a reject Q. All right, so 1, 1, 0 is our state, state ID for reject Q. Now paid is a little trickier, because what's the last thing? Since we merged these states, now what's the last coin? Let's just pick one. Let's say it's a quarter. So what's the last coin in that case? Well, it's a quarter. We just made that assumption. So what about S1? Extra quarters, 0. We don't have extra quarters. Oh, I'm sorry. 0, yeah, yeah, 0. What about dimes? 1. We might have even extra dimes, right? It might be they put a dime in six times and then put a quarter in, but that's OK. That means the same thing there. So we could use 1, 0, 1 for paid, but what if we did the other assumption? What if we had a last dime? Then what's S1? So S1 is extra quarters, right? So had at least one quarter. And what about S0? 0. So 0, 1, 0 could also be paid. That's OK. We can have two bit patterns if we want to. Turns out it's convenient in this case to use both bit patterns. It doesn't matter. It is two states in the finite state machine. So in our abstract model, we were able to reduce it to 1, but we've got to use three bits. So we've got eight possible bit patterns, eight possible states. There's not really any value other than simplifying logic to making those kind of things don't care. So if it simplifies the logic to make both of these states mean paid, that's equally useful. So in the lab design, both of these are going to be paid states. So I ended a little early. So the rest of the design is up to you. So you remember, I'm sure, having to go through and actually draw k-maps and solve this, and then you'll be building it. I think there's a spread out due date from the 25th through the 28th or something, so a couple of weeks. So enjoy your weekend, and do bring questions on Monday so we can have a fun review session. Thank you. Yeah, this is for lab 9. Yes, thanks. I mean, it's really all the labs, but in the sense you'd be doing metrographic stuff in A10.\"},\n",
       " {'ECE120-2016-10-24-LEC-25-slides.mp4': \" Hello. Lab 9, I think, what is it, due by Thursday or something? Friday. So today we're going to just pick up where we left off with memory and look at bit slices, how they work, look at coincident selection, which will help us reduce the amount of logic we need for decoders and other things like that. Talk a little bit about tri-state buffers, which we'll use to allow ourselves to have multiple outputs connected to the same wires and then choose which output drives those wires. Obviously, we can't create short, so we only have to have one at a time. And that's what the tri-state buffer will let us do. Look at how we do bigger and wider memories. So take multiple memories and put them together to build memories with more bits, either more bits per address, wider addressability, or more addresses, a larger address space. Then we'll start talking about how we can implement something like a C program using a finite state machine. So we'll walk through an example of that. And it'll illustrate how we actually build a computer. So that'll take us through. I don't think we're going to get done with this today, so I think it'll be at least halfway through Wednesday, if not all of today and Wednesday for those two topics. So just to get back up to speed after the weekend, just do a little review. So remember, with the memory, we wanted to do two different operations. So one is read. So we tell the memory, here's the address we want. We had, in our original design, we had 2 to the 16th name. So we give it 16 bits and say, here's what I want, this address. And out come the bits on these data outlines. And then we can also do a write, where we say, here's the address I want, and here are the new bits. So we said it was 32 bits wide in the original design. And then, of course, we have to tell the memory, do we want to read or write in a certain operation. So this is what the symbol looks like. You can see the things I just talked about. Data comes in here for a write, comes out here for a read. Read or write, write enable is here. This was the address lines. And then we also had this chip select. And we said, well, if chip select is high, that means the memory is going to do something. And if chip select is zero, that means it's basically just turned off, doesn't do anything. So that was chip select. This is a static RAM cell, so double inverter loop to store a bit with active logic. When we turn on the select line, then these n-type MOSFETs connect the bit and allow the bit stored here in the double inverter loop to drive these bit lines. And then when we want to do a write, we force these bit lines to take on the values we want to store. And we turn the select line on. And then we wait for that double inverter loop to switch over and store the bit we're trying to push in. They would, and that's, I think, just a balancing act to make sure that it's a little easier and the shorts are even shorter loop. So yeah, good question. And then this was the last one we looked at last time and went kind of quickly through it. So what I've done here is taken the cell from the previous slides and turned it sideways. So now the select lines run vertically. There's cell 0 select line here, cell 1 select line here. There's 16 different cells, each with its own select line. But you can see the bit lines now run horizontally. And all of the 16 cells share the same bit lines. So we're only going to look at one bit at a time, read one bit at a time, or write one bit at a time out of this bit slice. We only have one pair of bit and bit inverse wires, the bit lines for those. So just to give you a little bit of annotation, so the cells are rotated, I just said. All of the cells are sharing these two bit lines, B down here, B prime up here. And analog logic, like the sense amps and things like that, to drive the bit lines and read the bit lines are down here in this little box. That's analog, so look at how it's actually built. So I also want you to notice that now we're going to use this decoder here to control the select lines. So four bits of the address, the address might be bigger, and we'll see how we can do that shortly. But four bits of the address would go into this 4 to 16 decoder, and the cell that we want out of these 16 would have its select line activated. All the others would not be. So only one of these select lines will be active at any time. And this decoder's enable input is how we'll use the chip select. So if chip select is turned off, the decoder's enable is turned off, and that means none of the cells are turned on. If chip select is 1, then the address chooses which of these 16 cells is activated by activating its select line. All right, so let's look at how a read would happen in the bit slice model. So remember, for a read, we set chip select to 1, we set write enable to 0, set the address bits, and then we'll wait for the data to come out. So we set chip select to 1, so now our decoder's enabled. We put the write enable equal to 0 over here on the read write logic. We put the address in on the address port here, and then one of the select lines becomes active. I just picked one of the cells. Let's pretend address is 0. So now this cell select line is activated by the decoder. Now, that means that since we're doing a read, the cell's double inverter loop inside will drive these bit lines, and the stored bit changes will go down the wires towards this analog logic, at which point this logic down here will read the bit off of the bit lines and send it out to data out. So that's a read. So in this logic, remember that reads and writes act differently. And so the write enable semantically means if we want to do a write, we set write enable to 1. If we want to do a read, we set it to 0. So when we tell this logic down here, write enable is 0, that's telling it, OK, don't do anything to the bit lines. Just wait until the logic comes down from the cell, as opposed to writing to the bit lines. So that's a read. And so we're going to do a read. And we're going to do a write. And we're going to do a read. And we're going to do a write. And the logic comes down from the cell, as opposed to a write, where you'll see in a second, we're going to push the bit lines to whatever logic we want, whatever value we want to store. Yeah, so for each operation, you can read one bit or write one bit. And you can't do both at the same time. And you can't read or write more than one at a time either. Yeah, Eric? Yeah? The dual inverter loop? Uh-huh. So this double inverter loop is exactly the same thing we used in a latch. So it's bistable. You can store a 0 on the left and a 1 on the right, or a 1 on the left and a 0 on the right. Yes, that's right. Yeah. Yeah, so when you connect these two, if you're doing a read, then whatever this inverter drives, whether it's 0 or 1, will go down this bit wire. Whatever this inverter drives, which will be the complement of this inverter, goes down the bit prime wire. So we must have a 0 on the left and a 1 on the right. But it's not a 0 on the right. Yeah, this double inverter loop is bistable. There are two stable states, just like when we looked at the latch. It's exactly the same. Make sense? OK. Why do they need to be in one? Let me come back to that. Someone had asked earlier about timing last week. And it's a similar answer. So I'll talk about it in a little while. For now, think about it as we just have to wait long enough. OK, so let me skip through the read. Is that the read? OK, so that's the read. All right, so actually here. So memory is not clocked. There's no clock in this system. It operates asynchronously with respect to other logic. So basically, it takes some amount of time. And the person who designs the memory needs to figure out, well, how long is that? And then in the data sheet, it'll say, you must wait this long. And then the system that you build to use memory has to wait at least that amount of time. So you can translate that to your system's clock cycles and round up. And that'll work. But it's not synchronous. It's not a clock system. So a couple of different approaches. So the designer specifies a minimum wait time in the data sheet for a read to happen. Or the way it's done in Patent Patel is the memory can also have another output, say, a ready signal that says, OK, I'm done now. Now internally, this option is still done this way. The designer has to know how long it takes. And then they'll just generate the ready signal when the bit is there. But that ready signal is another way it can be done. This is a little bit of an aside. You may hear about SD-RAM. So you may go say, hey, I want to buy some RAM for my computer. Oh, I can get SD-RAM. And oh, what does that mean? No matter, told me it's all asynchronous. It's still true. What SD-RAM is is the interface between memory and your computer is clocked. And that allows us to transfer bits back and forth between memory and the computer faster than with an asynchronous interface. The internal cells are still not clocked. So the cells inside an SD-RAM chip are not clocked. Yeah. To some extent, yes. The asynchronous interface, you always end up kind of waiting for the next cycle. And so if instead you pick a cycle time that's a multiple or a fraction of your chip speed, then overall you can transfer data back and forth faster. So the interface is clocked. The chip itself is, I'm sorry, the memory cells themselves are not. Again, you don't need to know this. I just worry that you'll go out and see it and then you'll feel confused about synchronicity around this. All right, so this is a write. So we've got our bit slice. We set chip select again to 1. We set write enable now to 1. So we're going to do a write from this read and write logic. And that means it's going to force the bits down those two bit lines. So set the address. There we go. Set the address. So the bit to write comes in here on data in. And the address cell select line is going to be activated again. So this one will be activated just like last time. But now instead of reading the bits out of that cell, the read write logic, knowing this is a write, is going to hold these bit lines at fixed values. And that will force the inverters inside here to flip to the state that matches the bit lines. So now they're going to store that bit. And that's the end of the write. So once again, we have to know how long that takes. And we have to wait long enough. So the designer has to figure it out, specify, here's how long you wait for a write to finish. And then when you use it, you have to wait the appropriate amount of time. It's not clocked. So the activated cell will store that bit in cell 3. Good question. So does data in matter when write enable is 0? It doesn't. It doesn't get used for anything. And we'll talk about it later. We can actually reuse it. So real chips will reuse it and match safe pins. But let's save that topic for 10 or 15 slides. Logically, yes. Logically, yeah. And you can think of it that way for our class. It's kind of similar to the gated D-latch, but it forces it over. Right. No. It does briefly, but it's an analog design problem. So we talked about that a little bit last time. It's outside the scope of our class to do analog design. And even when we look at it, you really have to understand transistor sizing and timing and transistor-level circuit simulation. So it's well beyond anything we have to worry about here. You should just know they're analog circuits. And so at some point, you'll learn how to do those. But it'll be probably junior year, at least, before you know how to design it. What do you get out? Nothing. Yeah. So that's a good question. So what comes on data out for write? Nothing. And again, I'll come back to that later. But we're going to figure out, well, could we actually just share those sets of lines? Because for read, we're using one set. For write, we're using the other set. Why do we have two sets? Yeah. Yeah. Let me leave that till we come back. Because in practice, I mean it's disconnected electrically. But I need to show you how. So yeah. OK. That's handled by read-write logic. You simply put the bit in. Mm-hmm. Yes. No, it actually does use two wires in practice, the way I showed you the SRM cell looks. Yeah. It could. I mean, that was the question that was asked at the start of today. Could we just use one bit line? You could. But then electrically, you'd end up probably burning more energy. It gets back into the analog design question. So you'd save a transistor, but you would end up being less efficient and slower. So all right. So again, two approaches for writes. Remember, designer says how long. Or similar to Pat and Patel, you have a ready signal. Your write finishes. It says, OK, r equals 1. No. No, this is all the analog logic we talked about in my little box. Yeah. All right. OK. So here's our bit slice. So this is 16 by 1 memory. Number of bits is larger. And this balances speed against size. So you can have 1,000 cells in a bit slice. And it'll be slower because you have very long bit lines. And when you read, that little double inverter loop has to drive that long wire. And so it takes longer. On the other hand, if you have 1,000 instead of 16, that means, well, you've got this one copy of this logic over here shared across 1,000 bits instead of shared across 16 bits. And so the longer you make them, the slower they are. But the more efficient they are in terms of space. And so smaller, but slower. So the other cost is this decoder. I mean, it looks like a small box here. But how many gates are there in an end-to-2-to-end decoder? Roughly 2 to the n, right? Because you've got one AND gate to drive each of these wires. And they're 2 to the n wires. Remember, it's minterms. So if you have n inputs, 2 to the n outputs, you've got roughly 2 to the n gates, plus some more. But roughly 2 to the n. So that's a lot. So let's think about that. So if we have more than one bit slice, let's say we stacked a few of these. And I'll do that in a diagram in a second. We could have, let's say, a bit slice of a bit that's a little bit larger than the other. I'll do that in a diagram in a second. We could share those select lines. But then how would we decide which bit slice is active? Put another of these, right? Put another decoder. But what does that mean in terms of our decoder area? Well, so let's say you've got a million cells, 2 to the 20 cells. So 2 to the 20 cells, one big decoder, that's 2 to the 20 gates. If instead, I did it in two dimensions, and I said, OK, in one dimension, I'll use 2 to the 10 gates, sorry, 2 to the 10 decoder. In the other dimension, I'll use 2 to the 10 decoder. And then where those wires cross, that'll be one cell. Well, that'll give me two decoders with about 1,000 gates each, so about 2,000 gates, compared to a million gates. So much, much smaller decoders if I use two dimensions. Well, so the problem is the cell really only has a couple of things that can be shared that way, right? So there is actually more hierarchy in real chips than two levels. But in order to generate the signals to those little pieces, you end up putting more gates down here and there anyway. So you can spread your gates out, but you end up using about the same. Yes. I told you I'd show it in a second. All right, so here's 4-bit slices, right? So let's just take a look. I mean, the savings on the decoder is not going to be very dramatic, because this is only 6 bits of address. But here are 64 cells split up into 4-bit slices. Each bit slice has 16 cells in it, just like they had before. We now have a 6-bit address, right? So 2 bits of our address will decide which bit slice. And 4 bits of our address will decide which of the cells in one of the bit slices. So we can take a look at how that works. So here's our 6-bit address. 2 bits over here, 4 bits down here. So let's look first at a write. So chip select is 1. Write enable is 1. So just like before. So set the address bits. So some of our address bits will go up here, right? And so what that means is now, let's see. So write enable is going to go into this decoder as our enable signal. And so one of the 4 outputs based on these 2 bits of the address, the upper 2 bits in this case, will go out and feed the write enable signal on one of the bit slices read-write logic. So all of the other bit slices will think they're doing a read in this design. But we don't really care that much. So they're going to all do reads. But this one here will do a write. So this one will do a write. The other 4 address bits go down here. This line is then activated. So 3 of these bit slices in this design will do reads. This one that I've highlighted here will do a write. So the bit to write comes in. The bits are held at a fixed value. And that cell there then stores the data in there, but only that cell. All of the other cells, there might be some bits coming down these wires. Those basically will just get ignored. Yeah. Oh, I mean, typically in a CAD tool, you'll say I want a memory. And someone will actually have optimized memory variants for you. Yeah, memory optimization, there are tools that will do it for you. If you really need to go and do it yourself, there's several academic papers and things like that that you can do. Oh, yeah, yeah. Intel does their own by hand. And so does IBM to some extent. Maybe not anymore, but it's a long time. OK. So let's take a look now at a read on our 4 by 16 design. So this is really a 64 by 1 memory. 64 addresses, 1 bit each. But we've split it into two dimensions. So chip select is 1. Write enable is 0. Part of the address, again, goes down here. So one of the select lines is activated. Let's say we know, I haven't highlighted it yet here because it doesn't actually use this decoder. It uses this MUX down here. So this cell, again, is activated. Its bit will flow down these bit wires. And then the output will come out of the Q output and go down to the MUX. Now, these other bit slices are also going to produce a bit, but we're going to ignore them. So using this MUX, we'll look at the other addresses, pick out the bit that we wanted, and that will come out to data out. So the MUX will handle the output side for us. You might think, well, wait, there's a little triangle thing. What is that? OK, so what's the triangle thing? It's called a tri-state buffer. So why? There are three rows in the truth table. So the only thing that you might not understand about this truth table is it's called a tri-state buffer because there are three rows in the truth table. What does Z mean? Any idea? Means high impedance. So it means, in other words, it's electrically disconnected. So the input and the output are electrically disconnected when the enable input is 0. And what that means is we can have this connection between in and out. And if enable is 0, this outside can be actually driven by some other gate, by some other logic, and it won't create a short. So it's electrically disconnected when enable equals 0. So how can that happen? So here's a diagram. This is not going to look like one of the other gates because this is not always producing 0 or 1. Before, when we built gates out of transistors, we always wanted to produce 0 or 1. We never wanted to have it just be left floating for the output. This one is going to be left floating. So let's take a look at how that happens. So what happens when enable equals 0? So you put a 0 there. Yeah, cool. High impedance means electrically disconnected. So it just means it's turned off. The transistor is turned off. It's like an open switch. Let me show you in this diagram, and then maybe I think that might clear it up. All right, so enable is 0. So what's the voltage here? What's the 1, right, after the inverter? So is this on or off? Good. And then down here is a 0, right? This is just the wire. How about this one, on or off? Good. So you see what happens when we set enable to 0, right? Basically, out is disconnected from ground. Out is disconnected from high voltage. Out is just floating, not connected to anything. That's what I mean by the Z, high impedance. So you can't cross either of these two transistors easily. OK, what about when enable equals 1? So that's 1. What's here? 0, right? OK, so on or off? How about, let's see, down here is a 1, on or off? OK, so what does that look like now? Is it a short? You still have two transistors, right? So this is an inverter, right, with these two transistors. That's an inverter. There's another inverter, inverter, inverter. So after this inverter is in prime, after that inverter is in again, right? So copied into out. Make sense? Yeah, sometimes people get confused, and they think a tri-state buffer is just like a 1n-type MOSFET or something, but that's not true. So it takes a bunch of transistors to make this work. It has to be active logic. You want to drive out using either high voltage or ground. Right? All right, so tri-state buffers, what do they let us do? It means we can actually wire outputs together. So that means we can have one set of outputs and have something like what I'll call the distributed MUX. So say we've got four groups of n signals. So there's something producing n signals over on the left side of the chip, another thing producing n signals at the top, another on the right side, another on the bottom. We could use a MUX. That'd mean we have to take n wires from each of those, bring them all into the same place, so 4n wires. And then we'd have to decide which of the four we wanted. And then we could take the answer and send it everywhere with n more wires. So 5n wires, a lot of wires if n is big. So instead, what we can do with tri-state buffers is send four control signals. Now, those will be one hot. Obviously, we can only pick one of the four sources. So one of those will be a 1. The other three will be 0. But any of them could be a 1. So those will go to the tri-state buffers. That's four wires that go everywhere. And then we'll have n wires that send the answer out still. But instead, those n wires just circle around the chip. So it's n wires going to all four of the things. We'll call those n wires a bus. So now we have n plus 4 instead of 5n wires going everywhere. So those enable wires mean that only one of the four values actually gets written to the wires that go everywhere, the bus. So in some sense, they're acting like a distributed MUX. So these four control wires go to the tri-state buffers. And only one group of n signals gets written to the bus at a time. So if you look at the LC3 computer data path in Pat and Patel, first shows up in chapter 4, you'll see that it actually uses a bus. And it uses tri-state buffers to decide what gets put onto the bus at any point in time. So that's one use of tri-state buffers. Now, for our memory design, the other thing we can do, to generalize this a little bit, data out is gated with tri-state buffers. So whenever you have a memory in our class, then the output is only going to appear on the output when you're doing a read. So if you're not doing a read, those output wires are floating. So that means any time your chip select is 0 or your write enable is 1, in either case, you're not doing a read. So your output will float. Now, technically, that means your input and your output wires can be the same wire. You're only looking at the inputs when you're doing a write. You're only using the outputs, connecting them to some ground or high voltage, when you're doing a read. So why not just use the same wires? In fact, most chips did that. Most chips would have a data bus, basically a bunch of pins going into them. And you would use the same pins on the chip for reading and writing. It's actually a lot of bits. A lot of pins. So it was important to do this. So we use the same bits, same pins. When we do a write, the pins are accepting bits to store. When we do a read, the tri-state buffers write the bits from the memory cells onto those pins. Why don't we just use separate wires? So the reason is because pins are a very limited resource compared to transistors on a chip. So in the last 30 or so years, the number of transistors on the chip has gone up by a million fold or something like that, maybe more. The number of pins has gone up by about a factor of 10 or 20. And then the number of pins you can fit, physical pins, onto a chip is tiny compared to the amount of data you can pump in and out of the chip. And so if you're not using your pins efficiently, if you just say, well, I don't really need to use these sets of pins at the same time, you might say, heck, I've got lots of pins. You don't have lots of pins. So that's why. And you didn't have lots of pins 20 years ago either. All right, so building a memory of more addresses. So let me give you this thought problem, and then I'll show you how it's done. So let's say we've got two memories, and each of them is 2 to the k, so k-bit address to the k addresses by n, n-bit addressability, so n bits at each address. How can we put those together to have a bigger memory with more addresses, so 2 to the k plus 1 address? So first, just verify, well, if I've got 2 to the k by n-bit memory, that's 2 to the k by n memory cells, the little double inverter loops. And so I have enough, because if I have twice that many, I can treat that as 2 to the k plus 1 times n, which is what I need for this memory. So we have the right number of memory cells. How do we wire it up? It's actually pretty easy. So the one thing that's a little tricky over here, we're going to need a little decoder to handle the chip select signal. So we're going to put chip select into the enable. So if chip select is 0, the decoder will output all 0's. So you see that 0 goes to chip 0's chip select. 1, I'm sorry, I'm giving them names. This will be 0 on the left, 1 on the right. 0 goes to this one's chip select. 1 goes to this one's chip select. So if the external chip select is 0, both chips are not selected. On the other hand, if external chip select is 1, then one bit of the address is used to decide which of these two chips is going to do something. Only one of them is going to do something at a time. So only one of these two memories is active at a time. So what that means is we can just say, well, we'll take the data in and just copy it to both. We'll take the right enable and just copy it to both. We'll take the data out and just merge them. Remember, they're tri-state buffered, so that's safe. So we don't have to worry about that. We'll take the address bits, all but the one k that we used for this decoder here. The rest of the address bits we'll also copy to both chips, and we're done. One of them will do a read, one of them will do a write. Which one? Well, it depends on the high bit of the address. You'd have to put muxes down here, right? Yeah. Yeah. I mean, yeah, n 2 to 1 muxes. Yeah, that's right. And some extra delay there, too. Yeah. It's controlled by chip select and right enable, right? Yeah. Inside those memories, yeah. Yeah, which in the bigger diagram, there was a tri-state buffer already in there, right? Sure, yeah. Yeah, that's not a bad way to view it, because it is like a switch. It's electrically disconnected when you turn it off. Yeah, although you can also have switch styles. Like the one in the lab is a 0, 1 switch, the way we've wired it up. So just be a little careful how you think of a switch, yeah. The way we drew it with transistors, where it's open or closed. Yes. OK, one more question. So what if we wanted instead to take two memories and make something with more bits for each address? So again, two memories, same size, but instead of twice as many addresses, I want twice as many bits at each address. So same argument down here. Well, I've got the right number of memory cells, so should be doable. It's actually a little easier. We don't need any extra logic. So we can just hook them up like this. So the address goes to both. So both of them are going to be active at the same time. You can see chip select is going to both of them also. Write enable also. Data in, we've actually split up into two groups of bits. We now have 2n data inputs, and we have 2n data outputs. So the top half of those will go to one chip. The bottom half will go to another chip. Down here, half will come from one chip. Half will come from the other chip for the data outputs. Now, you can mix and match these bits any way you please. If we ask you this problem on an exam, and we'll probably ask you, please don't make complicated patterns. But as long as the pattern you use up here matches the pattern down here, it doesn't matter. So when you write bits, you use the same way of taking those bits here and putting them into the chips as you do when you get bits back out of the chip. It doesn't matter what mapping you use. In practice, people do look at more complicated mappings for performance reasons. But that's something you'll learn maybe in 4.11. So if you go out to Micron's site, I think the biggest one you'll get for a chip is about 8. Last time I looked, it was about 8, so 1 to 8. And then you build. So there are different questions. So that's the memory perspective is at most 8, and typically 2 or 4. But from the processor's perspective, most instructions in architectures, which we'll start talking about next week, will be byte addressable. So any individual byte in memory has a name for it. There were processors people tried to build in the 90s where you could only talk about 8 bytes of memory. And pretty soon, they figured out that there was far too much software that wanted to do byte addressable memory. And so they had to add that as an extension. Anything else? All right, so I just want to make sure you understand. So write, then you'll take the bits, split them up. Both of these chips will write at the same time because write enable will be 1, chip select will be 1. So both of them will write half of the bits into their cells. When you want to read it back out, chip select will be 1, write enable will be 0. The address will be the same. So we'll collect the two sets of bits from those two chips and then put them together on wires. And those will be the bigger answer. Yes, to some extent, in the coming weeks. The question is LC3 instructions, probably, mapping to logic. Yeah, we'll look at that. So that's it for memory. What I want to spend the rest of today and probably all of Wednesday on is developing a finite state machine that will implement a little piece of code. So you can do pretty much anything with a finite state machine. So let's take a piece of C code. And we'll use components to store the variables. So by store, I mean probably registers, flip-flops, things like that. So the variables in the C code will become registers, counters. We'll also execute the statements. So any time we're moving bits around, that'll be something we do based on the finite state machine. We do comparisons. We'll use a comparator, things like that. But we use other components to execute the statements. And the finite state machine is going to use those components by having the outputs of the finite state machine act as control signals for the components. So we'll have a bunch of components. We'll put them together. We'll call it a data path. And then we'll have the finite state machine state say, well, what should the components do in every cycle in order to basically execute this little piece of C code? Yeah, right? Oh, it was the other way, right? You were given the C code. And you were asked to draw transitions. This is a little more direct in the sense that a lot of software basically is a finite state machine. And so you can do that exercise for almost any piece of software. It's just that the state in software can be arbitrarily complicated. The state of this code is pretty small. So it'll be a little easier in that sense and a little harder in the sense we're building hardware from software, going the other direction. All right, so here's the piece of code I want to do. So what this is going to do is find the smallest integer amongst 10 integers. So if you look at this code, you should know how to read everything except that. So what does that mean? Some of you might know. But there's no reason from our class you should know what this means. So let me explain it. So this variable declaration creates 10 32-bit choose-complement numbers. So it's a variable declaration. It says, I want 10 of them. And so they are then named. It's called an array. They're then named values 0 through values 9. It's a software analog of a memory. So we said, oh, we're going to have a bunch of values. We need names for them. Let's name them 0 through 65,535 as bits. In C, we can name them as decimal, value 0 through value 9. But that's all it's doing. It's saying, OK, I want 10. So we get those 10. The first array element is used here. So we'll take the first one and copy that into min. We have to assume that this was filled up by someone else. So assume someone's written 10 numbers into those. Whatever element is accessed here depends on index, the variable index. So again, values goes from 0 to 9. So the variable index will have values somewhere between 0 or 9. And which of the elements in values, the array of values gets accessed, depends on the value of index. So it can be read. It can be written. So let's assume, before we execute our code, that somehow these 10 numbers get filled in. So something's going to provide our finite state machine with 10 numbers. Our finite state machine then will go through and find the smallest of those 10 numbers. So the first step then is to copy the first array element, value sub 0, into min. So we'll start by saying, well, if we just look at one of them, it's obviously the smallest one. So I'm not going to answer that now, because building that into the finite state machine would mean that we have to then build all I-O and things like that. So we'll just assume that someone's going to put these into something the finite state machine can access. And in the next couple of weeks, maybe three weeks or so, you'll see how the LC3 is built. And then you'll know how to answer your question. All right. So here's a loop. So if you look at this loop, you should know how this works. You start at 1. You check if index is less than 10. And then you increment index for the update. So the values in that loop, index will start at 1. And the last iteration, index will be 9. So it's going to run from 1 to 9. And then inside here, in the loop, we're checking whether the entry indexed by the IDX variable is less than the current minimum, and then replacing it if it is. So we go one by one through the 10 values, through the second through 10th, and check if it's smaller than our current minimum. And if it is, we copy it into our current minimum. So at the end, the variable min holds the smallest of the 10. Make sense? Someone? Yeah. Sorry, Kyle. Yeah, IDX++ is equivalent. We just didn't teach it in our class. So I just wanted to keep the syntax we taught. Min and the value IDX are equal. I'm sorry. I don't understand the question. Oh, yeah. If they're equal, then they're equal. It doesn't matter whether you replace it or not. So in software, you want to minimize the number of instructions that need to be executed. And so executing instructions that have no effect on the value IDX, that's not a good idea. So you want to minimize the number of instructions that need to be executed. And so executing instructions that have no effect, you try to reduce that. So software-wise, it's slightly better performance. In terms of what we're going to get, it's not going to make any difference. It does nothing. Yeah. This is the array element numbered by index. Remember, they're numbered 0 through 9. And index holds a value from 1 to 9. So min starts out as the first value, meaning value sub 0. And then you compare it with the other values. And if one of the other values is smaller, you replace min with that particular number. Yes, and we'll do that. The index variable, yes. So let's draw a flowchart. So we start down here. First thing we did was initialize min to value 0. I'm using colors for the statements here. So this was gray was our initialization. The green is our for loop. So the first initialization in the for loop was index set to 1. And then check if 10 is greater than index. And then if that's false, we're done. Of course, it's not false the first time. It's true. So again, those green things are part of the for loop. The blue is part of the if statement, and then the body of the if statement, the then case. So ifs checked whether min was greater than value sub index. And if that was true, it copied value sub index into min. Once that was done, it went to the update of the for loop. If the if condition was false, we also came down to the update of the for loop, after which we went back up to the test. So there's a flowchart for that code, color coded with statements. So this is just a step towards figuring out how we'll actually organize our finite state machine states. So before we go there, though, let's think about how we're going to turn that flowchart into a finite state machine. What component should we use? So we need an array. I said that an array is the software analog of a memory. So what do you think we'll use? We need 10 different values. We could use registers. We need 10 registers, and we need to be able to name them. Let's use a memory. So then we can use a memory, and we can name them 0 through 9, just like we did in the code. We can name the 10 values 0 through 9. What about the other variables? Registers, counters, stuff like that. What about the if statement? Sorry. So we have to do this comparison. Let's use a comparator. In fact, I'm going to use the serial comparator, not because it's better or anything, but just because I want to remind you that we can build these state machines where one state is actually representing a bunch of states, like we did with keyless entry, where the alarm state became a bunch of states counting the timeout. So here, the state that uses the comparator is actually going to be a bunch of states. It's executing a serial comparator for 32 bits. So just show you the hierarchy of an FSM again. So in order to execute a serial comparator, we have to feed it one bit at a time. So I have shift registers for that and a counter to count 32 bits as they go into the comparator. All right. So what are the rules about implementing state machines? So if I'm going to implement a state machine, well, my states have to be executable in some fixed number of cycles. So I have to figure out how to take this flow chart and break it apart so that I can execute the pieces in one cycle or 10 cycles or at least some predictable number of cycles. I can't just say, ah, just put all the flow chart in one state and I'm done. I could, but it wouldn't be very effective. So that's related to how many components and what kinds of components I use. So if I use very simple components, it's going to take me several cycles to do anything. If I use very complicated components, it'll take me more area, but things might be faster. So for example, I could say to you, well, I need to compare 10 numbers. So go build a 10 operand comparator. It's doable. You can sit down. You can write the equations out. You can solve the k-maps. Well, maybe not k-maps. But you can do a 10-input comparator. And it just spits out the biggest number. It's one big combinational logic. Then it's a very easy finite state machine. One state. Execute comparator. Done. So probably we're not going to do that. We could do that. Different design point. How we pick our components. What we did when we said, OK, we want a memory, registers, counters. How we actually pick them will affect how we design our state. So in practice, we'll go back and forth. When I actually designed this, I went back and forth. I said, well, what if I put these down? Then here's my states. Oh, but that's kind of annoying. So let me go add some more components. Now that's too complicated. So you go back and forth. But this design is all done. So I'll present it as if it were easy, but it's not. You often have to go back and forth as you see how things work. All right, so how do we pick states? So we're going to break the flowchart into pieces. Not every flowchart box is going to become a state. So I'll give you an example in a second. Well, actually, example's here. So in our flowchart, the first few steps were to initialize min. We said, OK, let's set min by copying the first value from the memory into min. We also need to initialize index to 1. And then we do the first comparison. Well, we don't really need to do that in our finite state machine. We know 10 is greater than 1. We're done. So we can do all three of those in the same cycle. So in other words, this part, this part, and this part, we're going to make into one finite state machine state. So now the colors indicate the state. So this is something we'll call the init state. And it'll perform these three boxes the first time. All right, so we can also join some other states. And we can do that by leveraging what we call predication. So what does predication mean? That's actually just an English word. We use it in the same sense when we design things as engineers. So predication means that something only happens under certain conditions. So the English sentence, well, if you give me an apple, I'll give you a peach. You only get the peach if you give me an apple. That's the predicate, if you give me an apple. And if you satisfy that predicate, then you get the peach. We can use that in a logical sense, for example, by saying, well, we get the output from a comparator. And then we can use that output from the comparator to decide, should a register load a new value or not? The way we change the register min is to load a new value into it. So we can use that comparator output to decide, should min load a new value or not? That means we can perform that action in the same cycle that we increment index. So what does that look like in a flowchart? Well, we have these two pieces down here. We had copy values of index into min. That'll now be predicated by the output of the comparator. And then increment index will put both of those into one finite state machine state that I'll call copy. Now we have two states. So now let's step back for a minute and say, well, we've got this finite state machine. How's it actually going to get used? It's going to go in and find the minimum of 10 numbers. But we said, well, something has to fill up those 10 numbers. So something's going to fill up those 10 numbers. And then it's going to execute our finite state machine. And then the finite state machine needs to just kind of wait around again while that thing, whatever it is, reads out the answer. And then maybe later it'll put 10 more numbers in and execute our finite state machine again. But we need some kind of wait state. So let's create a wait state. So during steps 1 and 3, our finite state machine is just waiting there. And then we'll have a start signal that says go to start step 2. So that'll be an external input, start, for our finite state machine to go actually do its thing, run through the flowchart. So where are those? So this was the done, the finish. So start will now be this wait state. And done also, whenever the finite state machine is not executing the code, it'll be sitting in this wait state. And that'll give the external logic time to fill the memory, read the answer out of the min register, and so forth. The last piece then is the if statement. So sometimes, even though it looks easy in a flowchart, it's not so easy to do on the data path. So in our data path, we said, well, we don't have a serial comparator. It has to be fed by shift registers. We need to put values into those shift registers first. So it takes time, takes a cycle, to put a value into a shift register, even if you do parallel load. We also need a counter that's going to measure 32 cycles. So we need a preparation stage. So we'll go and create a prep state in which the finite state machine copies min into the shift register A, copies values of index into shift register B, and resets the counter, all of that in one cycle. And then we're going to have a compare state that will execute for 32 cycles where we run the serial comparator. And then when the counter counts up to 31, we'll have some counter. It'll count up to 31. And the finite state machine will move to the copy state that we already showed. So here's that last bit of the flowchart. You notice I've broken it up into two colors because we're going to have a prep state, and then we're going to have a compare state. All right, so let me finish by just showing you this abstract state diagram. I'll just flip through it, and then I'll walk through it. So this is now what we have. We have a wait state. The finite state machine sits around there until it sees the start signal. When you see the start signal, you go to init. That takes one cycle. Then it goes to prep, where it actually prepares to do a comparison with the second element of the array. Comes down to do the comparison, runs this thing for 32 cycles, and then goes to copy, where it might actually copy the second value into min. That would not be the end of the loop. So it would go around this loop here, the yellow, blue, green, yellow, blue, green. It would do that nine times to compare the other nine elements. And then when it's finished, the smallest number is in min, the register min. So it would go up to wait and finish. And then some other logic could come out and read the smallest number. So we'll go over this again and then finish up the design on Wednesday. Thanks.\"},\n",
       " {'ECE120-2016-09-23-LEC-13-slides.mp4': \" Went through it quickly, so I want to make sure you understand the idea of sticking some glue logic in to clean up the inputs. Then we're going to start talking about using an approach to design in which we break off one piece at a time. And we'll start with a ripple carrier and just use the human intuition of how we do base-2 addition to design the hardware. And then we'll generalize that and think about how we can approach these problems by basically using induction to prove that the answers are correct. So we'll talk generally about bit-sliced designs. After this, we'll start working on a comparator. I don't think we'll get there today. I think it'll be not till Monday. Couple comments before we start. I mentioned last time, midterm one, we're going to sit down and grade it tomorrow. After lecture on Wednesday, I took my, we're doing a rubric generation. So I had 20 exams. So I graded 20 exams. I think it was Wednesday night. Might have been Thursday. The average, maybe I should let you guess. So I didn't pick this. But somehow, my responsibility for creating problems on the exam totaled a certain number of points. Yeah, 42. I was surprised. I didn't pick it. Anyway, so from 42% of the exam, about 5% of the students, so not great statistics, I'd estimate kind of 80% to 90% average. So the big swing there is that other people's problems may be easier or harder than mine. But mine on average were about 80% to 90% given only 5% sample. So there's a little bit of swing there too. So overall, you did quite well. So ice cream. So remember, we started thinking about how we build an ice cream dispenser on Wednesday. And I said, well, we have three input buttons, MB and P for mango, blend of mango and pistachio. It doesn't sound that appetizing on a Friday afternoon. And pistachio. And then each of the two outputs, two unsigned numbers, two bit unsigned numbers for a number of half cups of each type of ice cream. And we realized by putting in a bunch of don't cares, we could just design it with wires. But the problem with that was humans are not nice about following rules. So if they come up and push two buttons, then our ice cream dispenser would at best spit out two cups of ice cream instead of one. And at worst, actually might destroy something. Because some other engineer might have assumed that, well, we agreed you wouldn't send one one. Only 0, 0, 0, 1, and 1, 0 were supposed to be meaningful patterns. So I shouldn't have to deal with 1, 1. So we did actually care in that case. So the solution was, so now I'm going to slow down a little bit because I think I went through this too quickly last time. So the question is, well, how do we fix that problem? And one answer was, well, don't put in don't cares. So pick some bit values that you know are not going to affect anything. For example, pick all 0's. So you push two buttons, you get no ice cream. You push three buttons, you get no ice cream. That's one answer. You'll get some more complicated k-maps, and you could build your logic. And then you're guaranteed that regardless of what the user does, nothing bad happens. So don't use don't cares is one answer. Another approach, and this is the one that I wanted to show you, they're actually kind of equivalent in this case at the end of the day. But you can think of it differently. Well, let's take the inputs, and let's put some logic there to guarantee that the assumptions we made that the user will only push one button or zero buttons are actually true. So how can we do that? So that basically prevents the humans from ever putting a bad combination of buttons, from ever producing a bad combination of inputs. So how can we do that? Here's one way. So we could say, well, any time a user presses more than one button, the outputs we'll generate for them will actually just be all 0's. So let's create a little piece of logic that takes the three button inputs and produces three output bits that look like the buttons, except that if the user presses two or three buttons, they all become 0's. So how do we do that? Well, for the case of the mango button, you can see the yellow and blue networks are B prime and P prime. B prime is the blue one here, and P prime is the yellow one. And you can see those both go into the AND gate along with M. So the output of this AND gate says that the user pushed mango, and they did not push blend, and they did not push pistachio. So if this output here for the mango is 1, that means they only pushed mango. And so the only way you can get a mango output is by only pushing that button. Similarly, if you look at the second AND gate here, it's taking the yellow input, which is P prime, and the green input, which is M prime, along with B. And so that output of that AND gate says, well, they pushed the blend button, and they did not push the mango button, and they did not push the pistachio button. So again, the blend output now, after this dotted box, they could have only pushed blend by itself, no other combination. And then finally, for the pistachio AND gate down here, you can see pistachio is going in there, but we also have M prime in the green network and B prime from the blue network. And so this AND gate says that the user pushed pistachio, they did not push mango, and they did not push blend. And so the only way you get a 1 out of that AND gate is if the user only pushed pistachio. So by adding these three AND gates and a few inverters, we can clean up our inputs and guarantee that, in fact, a human, even if they push a bunch of buttons, they can't affect the system. The inputs that we see coming out of the dashed box are always, at most, one button at a time. So this is one choice. And we can think of this as some glue logic in between our inputs and the way we process those inputs, which is just with some wires. So these wires over here are equivalent to the previous design here. And so I just kind of smashed them together to fit it all in the diagram. But they're fully equivalent to the previous design. And so you can think of this as, well, all we did was add a little logic in between our inputs and how we use those inputs. So that's one strategy. Another common strategy would be to choose a priority. So there's six different ways to do that. I think there's one in the notes, so you can take a look at that. But what does it mean by priority? Well, you simply say, well, one button is more important than the others. So for example, if you push pistachio, just ignore the other buttons. You're going to get pistachio. So you push pistachio with blend, you get pistachio. Push pistachio with mango, you get pistachio. Push it together with both other buttons, you still get pistachio. That'll be the high priority. I think I'd rather do mango. And then second priority would be mango, for example. Again, you can pick any order you want. You can design the logic any way you want. But you just guarantee that what your logic sees is always at most one button is kind of the point. So any of these approaches is fine. In this case, mango might override blend, but it would be less important than pistachio. So you pick a strategy. You can also combine these approaches. So there are many ways to solve the problem. All of them are fine. All of them involve kind of design decisions. So you as the engineer have to decide what's going to be the most sensible thing for some human who pushes these buttons. Maybe it's better to just not give them anything and make them figure out that they should only push one at a time. Maybe it's better to just give them some ice cream and send them away. That's up to you as the engineer. But it's bad to let the system do something unexpected or unknown. So in the case of our ice cream dispenser, if you work it through, you'll probably get about the same answer, if not exactly the same answer. Solving it with a priority from the original KMAPs or solving it with forcing things to zero from the original KMAPs versus thinking of it as glue logic. And in general, you will get variations in area, speed, power. Right here, we only had wires. But if you put extra levels of logic, it will be slower. Whereas if you solve the KMAPs directly, you'll get SOP or POS. You'll get two-level logic. It'll be faster. So in general, you'll get variations. But maybe cleaning up your inputs is a little easier to understand. So you get an abstraction benefit, possibly at the expense of speed or area. So they are conceptually different approaches to the problem. All right. So that was it for the ice cream example. Anyone want to ask anything about that before we start adding? All right. So finally, weeks ago, I said, well, what if you had some hardware device to do addition? And in the meantime, since that first discussion, we've actually gone and filled in. I know the truth tables for adding. I'll walk through it again in a minute. So I think you know mostly how to do this. And probably, you could do it without my showing you. But let's walk through and do it. So we're going to do it based on the human approach. So remember, we write down numbers as binary numbers. And we add them just like we do in base 10, except it's binary. So 1 plus 1 is 10, and you have to carry. But in general, this approach of, well, let's start with a human design will often give you a pretty good design. So you can start that way. It's usually pretty easy, because if you know what you're doing as a human, turning that into logic should be pretty straightforward compared with making up something abstract and trying to figure out the details. And it often does lead to a good design, because humans are pretty smart. The way we do addition was the result of thousands of years of thinking about, well, what's the best way to teach kids how to do this efficiently kind of thing? So usually, the way we do things is not a bad way to do it. So you may remember this slide. This is just an example slide from the first time we talked about binary addition. So we did it before. 0 plus 0 is 0. 1 plus 0 is 1. 1 plus 1 is 0. Carry the 1. 1 plus 1 plus 0. 0. Carry the 1, and so forth. So we got that. We got the right answer. We were happy. And now, we need to put some labels. So in order to build a system that'll do, say, 5-bit addition, we're going to need labels. So I've already called this number A, called this number B. This will be our sum S. And then up here are going to be our carry bits. Now, this is a digital system. So when I was doing base 2 addition by hand, I was kind of lazy. When the carry was 0, I didn't go right to 0. But there's no blank bit. So those things, there's no blank bit. Those carry bits are going to be 0s, not blanks. And so just fill that in. Make sure we know that. There's also this carry bit here. So if we're going to design one piece of logic that adds one column, well, that piece of logic also needs a carry. And it can't be a blank. So we're just going to assume that we're going to put a 0 into the lowest, least significant bit carry. So just flesh out our human approach with the details that we usually just don't bother to write down. I mean, if I'd asked you, oh, what's the carry here? You'd say, well, it's 0, right? Obviously, I left it blank. But there's nothing obvious to a computer. All right, so two extra assumptions. For the least significant bits, we're going to set c to 0. And for the other bits, the carry input is going to come from the next least significant bit. So this is just adapting our human approach to digital systems. So let's spell that out. So we've got inputs and outputs for this full adder. So a full adder is going to add one bit. The name is historical. There was a half adder that added two bits. And then if you put two of those together, you could add three bits. But a full adder will have three inputs. So there's going to be one bit of the number A, which we'll also call A, one bit of the number B, which we'll also call B, a carry input from the next least significant bit, or 0 for bit 0, which we'll call C in. And a full adder will then produce two outputs. So one is the carry out, which will go to the next most significant bit, or if this is the most significant bit, that'll be the carry out that tells us overflow for unsigned or just carry out for just complement. And then one bit of the sum S. So those are the inputs and outputs for our full adder. So here's our full adder the way we might draw it. So you can think of it as a bit slice. You can think of it as a full adder. But here's a picture of it. So it's got two inputs coming in. Those will be the m-th bit of A and B. So this will be one bit slice for the m-th column of our addition. We'll get the carry. I put it as a superscript here to differentiate it from the in and the out. But otherwise, putting it a superscript doesn't really mean anything. It's just the m-th bit of the carry. The m plus 1-th bit of the carry is an output. And some bit m is also an output. Yeah. So the question is, do you have to pass the carry? It gets passed from the left. So the one coming in is from the one less significant digit. And the one going out is to the next most significant digit. But if you're all the way at the end, then I can go back to the yeah, here. So if you're this last bit here, so in a five-bit addition, we would have five of these full adders. So the last one will produce the carry out of the whole adder. That make sense? OK. Anything else? Yeah. Yeah, so for unsigned, the carry out is the overflow, as you might remember. In order to calculate the overflow for 2's complement, we would need to add some additional logic to our adder. And in practice, most adders in real processors would have that extra logic, and it will give you an overflow bit as well. In the LC3 design in the textbook, they didn't bother to add it. So you can calculate it other ways. It's just a little more onerous. We won't add it to our design. It's one extra XOR gate. All right, so here's our design. So now in order to implement this bit, we're going to use a KMAP, of course. And first, we'll fill in our truth table. But we need to add A, B, and C in, and then produce S and C out. So let's go ahead and do that. So let's calculate our outputs. Again, the inputs are A, B, and C in. The outputs are C out and S. I've written these so that we can just add the two numbers and then get a 2-bit sum. And then the high bit will be the carry, and the low bit will be the sum output bit. So we solved this a few weeks ago. Let's go ahead and do it again. So if I do 0 plus 0 plus 0, what do I get? 0, 0. Yeah, 0, 0, 1. 1. 0, 1, 0. Good. 0, 1, 1. Yeah, 0 carry the 1, right? 1, 0, 0. 1 and 0. 1, 0, 1. Yeah, 1, 0. So carry is 1. 1, 1, 0. Sorry, I jumped ahead. And then 1, 1, 1. 1, 1. Good. So everyone remembers how to do this, hopefully. So then we can copy over to the KMAP. I don't remember if we've done this before in class, so let me just remind you. In our truth table, we're generally going to write binary order. In our KMAPs, we're going to write grade code order. And so the order of filling things in, if you're copying, here I put the two ladder variables there on the top. So B and C go this way. So reading downwards, we're first going to go across the KMAP. If you write the variables in different order, you would go down first. But in this KMAP ordering, we'll go B and C first, and then we'll do the second row as the second half of the truth table. And then the binary to grade code, since only this direction has two variables, we're going to go here, here, and then jump over to this one, which is the 1, 0 case of BC, and then fill this one last. So that said, we can just read them off. So 0, 0, 0, 1, and then fill them in. So 0 goes there, 0, and then we'll skip over, put the third 0 there, and then the 1 goes in the 1, 1 position. So make sure you get this, because every time you create something, if you make a mistake copying from your truth table to your KMAP, you're only going to catch it after you've solved the whole KMAP. You go back and you say, is my logic right? Did I get the right expression? Does it work? And the answer is no. And so then you'll go back and realize, oh, shoot, I forgot to flip these. I'll have to start over, basically. So just be careful when you're copying. So C out on the bottom is 0, 1, 1, 1. So we'll fill it in the same order. Even though the 1s, you could swap them. It doesn't make any difference. But just do things in the right order. Make sense? Question? Yeah. So remember, in a truth table, we're just listing all possible input combinations. C in is an input. Yeah. Yeah, yeah, we have to consider all possible combinations of inputs. And the A, B, and C in are inputs. And so we've got, in binary order, 0, 0, 0, 0, 0, 1, all the way through 1, 1, 1. Yeah, remember, in the truth table, to the left of the line, typically, is our inputs. And to the right of the line are the outputs. All right, so there came up a question. All right, so there came out, so we can go ahead and solve this one. So let's find loops. So where do we have loops? 1, 1. Good answer. All right, there's a 1, 1. So which one is that? B, C, N. Yeah, OK, here's another loop. Which one is that? A, C, N. And which one is this? A, B. So you can write that down. That's called a majority function, by the way, because we've got three inputs. And whenever two of them are 1, then the output is 1. Check that. It's not terribly important you know that. But if you're interested, it's called a majority function. So that's our carry out. For the sum, we're not going to do a KMAP, because it's not so easy. I'll show you in a second. But it's not easy to just immediately know you've got an XOR coming out. So I wanted to remind you that when you do the sum, the output bit, the low bit, is the odd function of the number of inputs. So if you're adding 0's and 1's, it doesn't matter how many you add. The answer you get for the low digit depends on whether they're an odd number of 1's in your sum or not. Here we've got three. So whenever there's an odd number in those three, we'll get a 1. So you can check that assertion. So here it's even. You get a 0. Here it's odd. You get a 1. Odd, 1, even, 0, so forth. But we write that as A XOR B XOR C. That doesn't come so easily out of a KMAP. So here's the KMAP. Just for your own benefit, I mean, we're not going to really expect you to do this. But if you ever notice it, you can write it, which is if you see this kind of checkerboard pattern, and they'll vary depending on what particular XOR combination. But the full checkerboard means XOR of all the variables. So here you see a checkerboard. And the answer is A XOR B XOR C. Checkerboard of 0's and 1's. OK, so we can design our full adder. So what I've done is just done the majority function up top with the C out coming out of that. So you've got the A ended with B on top, A ended with C in here, and B ended with C in from this one, or those three AND gates together. We create C out. And then S is just one XOR gate with A, B, and C coming into it. Yeah. Yeah, so for example, if you flip the 0's and 1's, that would be XNOR. So it would be an XOR gate followed by an inverter, for example. You could also have a partial checkerboard where you had 1 1 0 0 0 0 1 1. And that would be an XOR of not all of the variables. And again, you don't have to recognize those. That's why I put the stars up here. If you're interested or you want to be able to pull the XORs out. OK, so I wanted to also, so this was our circuit. I wanted to show you in CMOS what this looks like. So typically in CMOS, we will build the XOR gate. And make that kind of a primitive, just because it takes a handful fewer transistors. So typically, those would be available as gates built out of transistors, kind of like we did the strange gate yesterday. If you want to see how that works, you can go to the tool and build it yourself. I would suggest doing the two input, because the three input is kind of a pain. But the two input's not so bad. And then you can check that you got the right answer. But again, it's not something you need to do. But if you're interested in seeing why you get fewer transistors, you can do that. So all we need to do for the top part, remember that any AND OR circuit, any SOP circuit, we can just replace the ANDs and the OR with NAND gates. And we get the same circuit. So that's all I've done here. So this is the CMOS implementation of the full ladder. Yeah. Yes. What? So OR AND becomes NOR NOR. So remember, yeah, I could pull up this other slide deck. But remember that the first step is to replace this OR gate with DeMorgan equivalent, which is complemented inputs and outputs of an AND gate. So you have an AND gate here with a complement on the output. That's an AND gate. And all the inputs are complemented. You then slide those inverters down to the other AND gates. And those become NAND also. So it's because DeMorgan's law is this OR gate is complemented inputs AND followed by inverter, if that makes sense. And if you look back, I think, to last Friday's lecture that Professor Verdaen gave, those slides will illustrate that for you. Any other questions? Yeah. So again, it just takes a few fewer transistors in CMOS to do an XOR out of transistors. And so typically, because of that savings, people will make the XOR gate available built out of transistors as opposed to built out of NAND NOR. So that's the answer. I didn't want to illustrate that for you. I mean, it's going a little too far into the details of how gates are built. But you can do it in the online tool if you're interested. And again, I would do the two-input version. I myself did not bother with the three-input version. I did do the two-input. It's fine. All right, so we have this one-bit adder that we just designed using what we learned in the last week or two. So then how do we actually build an adder for n bits? So when we add stuff, we add one column at a time. And one of these adders, these full adders, is going to add one column for us. So all we need to do is then hook them together. So we'll feed 0 into the carry input for the least significant bit. The carry out of the most significant bit is the adder's carry out. And then for the other signals, we'll connect C out to C in for adjacent bits. Then we'll take A and B and divide them up. And then feed one bit of each into each of the full adders and collect the bits of S from the full adders. So let me show you that. So here is a chain of n full adders with a dot, dot, dot in the middle, since we don't know what n is. But you can see we're feeding a 0. Is this big enough to see in the back? Can you see this? OK. You're feeding a 0 into the carry in of the first one, the 0-th bit. And then between them, we're taking carry out, feeding it to carry in, all the way down the chain. And then the output here is the carry out. You can see A of n minus 1 and B of n minus 1 going to the bit slice and so forth, all the way down to A sub 0, B sub 0. Those are the least significant bits of A and B. And then down here, S sub 0 comes out, S sub 1, all the way up to S sub n minus 1. So this is the most significant bit on the left, least significant bit on the right. So all we have to do is take n copies of our full adder, wire them together, and now we have an ended adder. So this is a ripple carry adder. Why is it called that? The word ripple is referring to something like a ripple on a pond. So you throw a rock into a pond, and you see these ripples spreading out from where the rock hit the water. And they move kind of slowly. So the carry information is moving kind of slowly between bit slice to bit slice, until finally it gets over here. So the speed of this ripple carry adder is not great. It's a simple design. It's an easy to build design. In practice, we use actually tree adders that are significantly faster than a carry adder for when you get to 32 bits or 64 bits. So we may get to look at that at the end of the class. But for now, it's a perfectly good way to build an adder. You can also think of it as a bit sliced adder, because for each of the bits, we have just the same piece of logic. And we just copy it. You want a 10-bit adder, just make 10 copies. You want a 20-bit adder, 32-bit adder, 100-bit adder. Make the appropriate number of copies, wire them together, and you're done. So fairly simple design. Loop, you mean to speed up the carry? Yeah, so let me move forward a couple of slides. So let me move forward a couple of slides. Let me show you first what an n-bit adder would look like in a circuit diagram. So once you build the n-bit adder, doesn't actually matter how you build it. You can represent it this way. So you've got this sort of funny-looking B thing. Typically, you've got to label it as an adder. The n bits, you see the input with a crosshatch n. That means n bits wide. So n bits of A, n bits of B, they're added together. Sometimes people just put a plus. The sum is n bits wide. The carry in is one bit, no crosshatch. Carry out is one bit also. So there's a shape. You can also then, sorry, illustration of the crosshatching. You can also then hook them together. If you have an n-bit adder and you want a two-n-bit adder, you can simply put them side by side. Again, the implementation doesn't matter. Once you've got the adder implemented, you can put two of them together pretty easily. You can also, as Sasha mentioned, do this virtually in software. So if you take the carry out bit of one physical adder and then somehow manage to put it back as the carry in, so instead of putting the carry in as a zero for the second part, you can add the next higher sets of bits and then continue that as often as you want. So in a typical processor, you might have a 32- or 64-bit adder. But you can use that to add arbitrarily large numbers. So you can write software libraries that will do arbitrarily large or even quasi-infinite arithmetic by simply dynamically using the adder to keep adding the bits until you finish for as much as you need. So usually, in practice, you would use that to check whether there was overflow. And that would go into a carry register. So I mean, at this point, we haven't seen how to store bits or anything. That's another week, week and a half out. So at the end, right now, all we know how to do is build combinational logic. So there's a signal coming out, and we can look at it as humans. But in a real design, you would end up storing that somewhere. And then, for example, software could look at it and see if there was a carry out. Did that answer your question earlier? OK, good. Yeah. OK. AUDIENCE MEMBER 2 Yeah, you're getting the right guy. You're getting the right guy. Yeah. Yeah, so the question is, well, wouldn't it be better if we had a smaller adder and reused it over and over again? It's smaller, but slower. So actually, this trade-off is something we'll spend a fair bit of time on in about a week and a half to two weeks. So we will look at it in detail at the circuit design level. But you can then do the same thing at a broader level. Yeah. Happened if you start with 1 instead of 0. That's a good question. What does happen? So what difference would it make if you put a 1 in? So you would still get a plus b plus 1, right? Well, the answer would be a plus b plus 1. So I mean, if what you want is a plus b, then it's 1 too high. But what if you wanted a plus b plus 1? Then it's the right answer. There's a reason I mentioned that, but I won't tell you why now. The crosshatch, I'm sorry. Yeah, this thing? So this means that there are actually n bits of signal coming in from that wire. So b is actually n bits wide. a is n bits wide. The sum is n bits wide. Yeah. Yeah, so your typical processor will have either 32 or 64-bit adders in it. But they will not be implemented as ripple carry. They'll be implemented as tree-based adders. Yeah, yeah, yeah. So what I showed you is not really the way you build an adder. It's a simple way to build an adder. Not in practice, really, anymore. OK, so now that we have an adder, I want you to think about what we did. So how many of you can add two-digit numbers? OK, come on, raise your hands. I know you can do it. What about five-digit numbers? What about 5,000-digit numbers? Yeah. Does it matter? Does it mean that? It doesn't matter, right? Does it matter if I just say some finite number of digits? You can do it, right? You think you can do it? OK. Yeah, I mean, I can make it arbitrary, right? So I can make it infinite. You wouldn't want to do it, but you can do it. Have you ever seen a proof you're correct? How do you know you can do it? What kind of proof? Proof by induction, maybe? So I think when you learned to add, probably you hadn't seen proof by induction, right? You were probably in elementary school, and probably no one said, let me show you the proof by induction so you don't get worried about digits, right? They probably just said, look, it works. You can tell. You can keep adding digits. It's OK. But if you really wanted to prove it, well, what do you need? You need to know how to some base case, right? So hey, I've memorized an addition table, and I verified it for one-digit numbers, and it works. So I'm good. That's my base case. And I know that if I can add n-digit numbers, then I can show based, for example, in place value that I can do one more column, and then I can add n plus one-digit numbers. And I'll get the right answers. And so you could prove both of those, and then you'd have a proof by induction that, in fact, addition works for arbitrary finite number of digits. Turns out it doesn't work so well for infinite digits, but that's a different story. So when we designed a ripple caryata, we kind of also assumed proof by induction. I didn't prove it to you. I just said, well, we'll just base it on the human approach, and you think the human approach works, so should this thing that we're doing, right? Well, you could prove it by induction. We know how to add a bit. We made a truth table, binary addition table. It's very simple, just four cases or eight cases if you want to do three bits. And we went through that a couple of times. Given that we can build an n-bit adder, we then have to show we can build an n plus one-bit adder by attaching one more full adder, a one-bit adder, to our n-bit adder. So those two steps are also something that I think if I put it on your homework, you would come back having done it and say, OK, great, I've proven that I can do arbitrarily large adder design using ripple carry approach. So in 220, so one reason I want to mention this, one is to get you understanding that for these bit slice design, we're basically just doing proof by induction. So any time you have a problem where you can prove it works by induction, you can do a bit slice design and design a small piece of logic for one or two bits or four bits or whatever, and then put a bunch of copies down, and that'll work. You need to make sure that that's an applicable approach or a useful approach for your problem. But when you can do that, it's a simple approach. The other reason I mention it is in 220, you're going to write software that does what's called recursion. So the recursive functions are going to call themselves. A lot of people end up finding this confusing. So it's the same thing. So you say, well, there's some base case. We call them stopping conditions in software, for which you know the answer. And so you need to have that base case. And then you say, well, given that you can write a function that works for input of size n, you have to prove that you can write a function that works for input of size n plus 1 by handling whatever the extra 1 is and then calling the function recursively for the n. So it's exactly the same thing mathematically, but it tends to confuse people. And I think the reason that it tends to confuse people is there's this assumption in the inductive step. So when you write the inductive step, you say, if you assume that I can do this for n pieces of something, n bits, n's, problem size, and software, whatever n is in your proof by induction, you have to assume that it works. And it's kind of weird when you say, well, I'm trying to design something. Well, just assume it works. But I haven't designed it yet. But you have to assume it works. So I think that throws people sometimes, especially when they get into software, everything's a little more abstract. Sometimes also in the bit-sliced design. The proof works if you assume it works and you show that you can add one more step. You don't have to solve the problem for n. All you have to solve it for is if n works, n plus 1 also works. Yeah. Yeah. No? How would you actually apply this for the ripple carry adder? So I mean, you would have to do, I think, the actual proof would be based on something like place value. So you'd talk about the value of an n-bit number. And then you would say, well, n-bit numbers have this range. And I know that the addition works. That's the assumption, is that I can add any n-bit numbers and get the right answer. Then I can say, well, if I put one more bit on front of my two numbers, can I prove that given this worked, that I get the right answer with a full adder? And that's the thing. You have to assume that n works. You don't have to make n work. You just have to assume it works. And then if you do the inductive step, it will work. Everything will work. So that's sort of this strange leap of faith you have to make that your answer works before you actually design it. So you have to sort of mentally get comfortable with that in order to finish your design. Because if you can't get yourself started, well, of course it doesn't work. If you don't design it, it doesn't work. But you do have to, as part of your design, assume that it will work for a smaller number of bits. And of course, don't forget the base case. If you leave the base case out, it's not going to work. All right, so I wanted to just mention that, because you will do some bit slice designs, and you will do recursive software designs in 220. So remember this. So what is bit slicing? So bit slicing is a hardware approach that is basically like induction. So it means we're going to break off a small part of the problem, say one bit, like we did for the adder, one bit of each input, or a few bits is fine. And then we're going to solve the whole problem by using the solution for the remaining part. So we'll take one little piece and solve it, and then use the solution for the remaining part. And that's essentially a proof by induction. So if you can prove that given only a small part of the input along with the answer for the rest, but you can get the full answer, then you're done. So in hardware, there's a little bit of a complication in the sense that we need to be able to express that answer for the rest concisely. So if we can't express it in a small fixed number of bits, then the number of wires we need from bit slice to bit slice will grow. And if the answer somehow takes n over 2 bits, well, then we can't design one piece of logic, because as we add more bit slices, n over 2 gets bigger. So sometimes we might be able to do it logically, because we just know the answer. We might be able to do it mathematically. But in a hardware design, we need to be able to do it by expressing the answer using a small number of bits. In the adder, it's just the carry bit. The only thing you need to know about the solution for less bits is the carry. And that will give you enough information to calculate your sum. So what kind of problems can we do? Addition, subtraction, comparison, we'll do next. Check for a power of 2, check for multiples, do pattern matching in inputs, bitwise logic operation. So a bunch of different things we can use this kind of approach. There's probably more, but these are the ones I could think of and that I've worked on before. When can't we use it? So any time the answer depends on all of the other bits. So for example, if I say, oh, do a prime number recognizer. Well, nothing you can tell me about these last five, well, at least I don't know how to do it. Nothing I can tell me about these last five bits will tell me whether with some extra bits on the front, this is a prime number. And you need to be able to do that. You need to be able to say, well, given the other bits, is my number a prime number looking at only one bit? If you wanted to do a bit slice design for a prime number checker, for example. So that's an example of where I don't think you can use a bit slice design. So what do you want to generate? So I mean, if you're just adding two numbers, you can use an adder, right? And then get the next one out. Yeah, so that would be fine for bit slicing. I mean, you can use an adder to generate that as long as you're doing the feedback logic to get back the two in the sequence and generating the next one in the sequence. Yeah. Anything else? Yeah. So remember that when we designed two's complement, we designed it deliberately to use addition mod 2 to the n, which was what we got out of unsigned. So the adder and subtractor are basically identical for two's complement and unsigned. And in fact, in order to do the subtractor, and this comes back to what we were talking about with a carry-in of 1, if you think about, well, is there a way I could trick my adder into doing subtraction? I think you've already done it by hand. A lot of you have done it by hand. But think about how you can use your adder to do subtraction. Yes, negate it. But you don't have to add 1. You can put a 1 on the carry-in. Yeah. Anything else? Might be the end. Where am I? No, I still have more slides. Killed my PowerPoint. Sorry. Oh, darn it. Oh, darn it. Oh. OK. Maybe we'll talk about the comparator today. All right. So let's spend a few minutes getting started on a comparator. And then we'll finish this up Monday. So next thing we'll do is compare two unsigned numbers. Now, here it's going to make a difference. And we'll figure out how later, whether it's unsigned or choose complement. But for now, let's just start with unsigned. So which one's bigger, top one or bottom one? Top. Top. How'd you know? Ah, OK. So you started which side? You started on the left. OK, so humans go that way. Why? Yeah, so once you get to, say, 0, 0, say that's the same, one line. Ah, so you can just stop. You don't even need to look. You're done. Yeah, so when we build hardware, they can't just stop. I mean, you've got wires. The wires don't just say, hey, I'm going to turn now because I know the answer. So they can't just stop in the middle. The information is going to flow from one end to the other. And the output wires on the end are going to give us the answer. So it doesn't actually matter for the hardware design if we go the human way or we're going to go the other way. So in our design, we're going to go the other way. It doesn't matter which way we go because we're going to have to go through all the bits in the hardware. We can't stop early, at least not in this kind of design. Once we talk about sequential state and things like that, you'll see there are ways for bigger designs to stop early in some cases, but not in wires. So we're going to design from right to left. We'll look at the least significant bit first. So how many answers are there? So there are three, three possible answers. So if we have numbers a and b, we've got three outcomes. We can say a is less than b, a is equal to b, or a is greater than b. So in order to decide the answer for n plus 1 bits, what do I need to know? Well, I need to know what's the answer for n bits. And then I need to know one bit of a and one bit of b. So here's an example where we can use bit slice. Because if you tell me for one fewer bit, for the less significant bits, which of those sets of bits is bigger and which is smaller, and then you tell me one bit of a and b, then I can tell you with that extra bit which one is bigger, or are they equal. Everyone agree with that? So we should be able to build a bit slice design. So what do we need to do? So how many bits do I need to pass from slice to slice? Yeah, right, because there are three possible messages. You need to know a greater than b, a equal to b, or a less than b. I can't condense that into two answers. Because if your bits are equal, well, then you need to know what the answer used to be because it's the same. So if your a and b for one bit are 0, 0, for example, then the answer depends on the lower bits. And you need to pass along any of those three answers. And how many bits do we need to encode three answers? Two, right? So you need two bits. So here's a figure showing an abstract slice model of our bit slice. So we're going to have two bits coming in from a less significant bit. We'll call them c1 and c0 m minus 1 bits. This will be the mth bit slice. So they'll get a sub m and b sub m for the numbers a and b. And then they'll produce outputs c1 m and c0 m, which internally, just to differentiate these two, we're going to call z1 and z0. So the inputs of what's happening from the less significant bits, we'll call c1 and c0 internally. And then we'll produce z1 and z0 to tell the next bit or to give the final answer, well, is a less than, equal, or greater than b. Well, so if the only thing we need to know is a less than, equal, or greater, we don't need n bits of output for anything, right? We just need one of those three answers. So in this case, yeah, it's a good question. In general, for something, your bit slice design may or may need some kind of outputs at the bottom. For a comparator, you don't need anything. For an adder, you need one bit for the sum. If, for example, as we sometimes do on homework or as we might sometimes do on even exams, we can say, well, out of the bottom, we want you to produce the minimum or maximum of a and b. So if we say minimum only, then you need one output wire. If we say minimum and maximum, you need two separate output wires. Ah, very good question. Good question. I thought of that, too. How do we represent the answers? Got three answers, right? a less than b, a equal to b, a greater than b. They're a natural representation? They're not, right? It's just three answers. Pick any representation we want. So our choice will affect the amount of logic we need. So here is a pretty good choice. Actually, after I designed the one, this is from the notes. After I designed this, I realized, well, I probably should have thought of this beforehand. But I went back and considered all the different choices I could have made and made sure I wasn't somehow doing something that was bigger than it should have been. So there's a pretty good representation. If you're doing the extra C exercises, the optional ones, you'll get to design your own with your own representation and your own direction in software. But software is not so bad, because even if your logic is a little bigger, it's a few extra characters of typing, as opposed to working out lots of area and things like that. But here's a pretty good representation. So we just say, well, OK, the a equals b, we'll call 0, 0. a less than b, we'll call 0, 1. a greater than b, we'll call 1, 0. And then the last pattern, we've only got three messages. So we're not going to use it. So you have actually a fair number of choices. You have these three messages, and you have four different bit patterns. So how you assign them is completely up to you. Yeah, exactly. So as Mohamed points out, now that I've said not used here, I can assume safely this is not a human. They're not going to go pushing lots of buttons or anything like that. The lower bit slice will never generate this pattern. So I can put don't cares whenever I see 1, 1 coming in from the lower bit slice. Good point. OK, so let's see. I'm not sure we'll get through this one. Let's see if we can do one bit. So let's solve one bit. So in this case, there are no less significant bits. So let's just think about A and B. So if A and B are the same, then what's the answer? You already know the, you already know the. All right, fine, I'll just skip ahead. You know the representation. So the meaning, though, are A equals B for 0, 0 and 1, 1. And then if 0 and 1 for A, B, then A is less than B. And 1, 0 is A greater than B, because these are unsigned. So the encoding is 0, 0. What about the 0, what about this row? 0, 1, good. What about the next one? 1, 0. And the last one? 0, 0, good. So this is one bit. So then we can go solve that. I want you to notice that these are minterms. So if you look at Z1, this is a minterm, just a 1 in one row. Z0 is also a minterm. So if I draw a circuit for that, all I need to do is generate a minterm. I don't need to go do k-maps or stuff like that. This structure is going to be kind of the core of our comparator logic. So here we're generating A0B for Z1 and A0, I'm sorry, AB prime, you said that way, and A prime B for Z0. If all you wanted to do was compare A and B and say equal or not equal, you could OR these two together. That would be an XOR. And so these are the two minterms that you need for XOR. And if you XOR A and B, or one bit of A and B, that'll say equal if the XOR gives you a 0, and not equal if the XOR gives you a 1. So if you OR these two outputs together, it's just like an XOR. But this will be the thing that lets us know is A greater than B or A less than B on a one-bit basis in the full design. So let me stop there, and I'll finish it up on Monday. Have a good weekend. Yeah, let's just, yeah. Oh my god. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK.\"},\n",
       " {'ECE120-2016-09-07-LEC-07-slides.mp4': \" So we're going to pick up where we left off, talking about expressions and operators in C, talk about basic IOs, so printf, scanf, and then talk about statements. Hopefully, you had a chance to take a look at the email that I sent out, I think it was yesterday. So we have an online automatic feedback tool for programming. And what we're hoping is people will play with it. It's used in 220, so if you get familiar with it, it'll help you in 220 also. But it's basically a computer tool that will help you find the bugs in your code. So I can tell you more about it if you're interested in office hours. But we have an undergrad who's doing his thesis, creating exercises for 120. And so those are available to you. Has nothing whatsoever to do with your grade. If you don't want to do it, don't do it. Signing up doesn't commit you to anything. So if you think you might want to play with it, sign up. We encourage you to do it because it's supposed to help you. But if you don't want to, that's OK too. But I do encourage you to try. All right, so let's see. Daniel was somewhere here usually. There you are. You asked this question about Unicode in C identifiers. So I went and looked it up. Apparently, it's been in the standard since 1999, but compilers still aren't really quite well supported. So if you use these flags in the lab, standard C99 and F extended identifiers, you can use this type of code. So this one everyone understands. How many Spanish speakers are there? OK, do you know this word? Manana, yes, I think I guess. And how about Chinese speakers? Anyone speak Mandarin? OK, can you read this identifier? Yeah, it's ming tian. So not exactly what you might want. So if you want to use it to change regular text like the commented versions into universal character notation, which are the things you can compile, there are tools that can do that. There's some instructions on this web page using Perl. But in 120 assignments, use ASCII. Please don't put UCNs. All right, so do a little bit of a review before we dive in since it's been five days since we talked. So we're going to cover four types of operators in our class. Arithmetic operators, which we already finished, bitwise Boolean operators, relational comparison operators, and the assignment operator. We're also going to take a look at logical operators briefly. A couple of the online exercises that use them. So if you want to do all of the online exercises, you'll need to remember what they mean. But you shouldn't need to use them otherwise in the class. So these are the bitwise operators, bitwise and, or, not, xor, and then the shifts we hadn't talked about yet. So let's go ahead and I wanted to put actually one slide with and to show you these things written out in bits. So we did the and last time, but it's maybe easier if you translate the hex into bits, or maybe harder since you have to write 32 bits down. But essentially all the bitwise and is doing is going one at a time through each of the pairs of bits, taking the and bitwise for each pair, and producing that and, and then that's the answer. So if you expand 120 in bits, that's the top line. 42 in bits is the second line here. If you and those together, you get the bottom line, which evaluates to 40 or 28 hex. So that's what it's doing for you. All right, so left shift. Left shift is basically shifting all of your bits to the left. So what does that mean? It's like multiplying by 2 to the n. So if you shift by n bits, it's like multiplying by 2 to the n. So for example, if you declare a equals 120, and b equals this hex number, and you shift left by 2 for a, then let's see, that would be 2 to the 2 is 4, so you should get 480. And in fact, you get 480. So with this pattern b, if we shift by 4, that will shift 4 bits to the left, so we'll get four 0's on the right side. And then the f on the left will fall off. So the shift will overflow. So it turns out we get kind of what we'd expect. Instead of 6 f's, we have 5 f's. There's an extra 0 on the right. And we've lost the high bits by shifting them off to the left, because we can only have 32 bits in the answer. That number is actually smaller than the original b value. And so that's an overflow. It's not multiplied by 16, as you'd like it to be. So shifts can overflow. Shifts by 32, by the way, are not defined in C, so be careful how you shift things. I forgot to mention that, but it shouldn't come up. So what bits appear on the left when you're shifting right? So shifting right just means take your bits, move them down towards the small end. But what bits should I put in the high part? 0's? Yeah, so in this case, I want to get divide by 2 to the 2, or 4. So I should put 0's in. That'll give me 30 in 2's complement. What if I want to shift this bit pattern 4 to the right? Should I put 1's or 0's on the left? You sure? So which one is it equal to? Is that negative 256, or is it this big number here? I didn't tell you the type, right? I just wrote some bits. So it depends on the type. Well, it's bits. I didn't tell you the type, right? I can make that an unsigned or a 2's complement. So if it's a 2's complement number, it represents negative 256, in which case, if we wanted to divide, we'd like it to divide by 16 and get negative 16. We'd insert 1's for that. If it equals this big 4 billion number, divide by 16, you've got 268 million some odd left. We should insert 0's. So how does the compiler decide what looks at the type? So if this were not just a bit pattern, but were a type, and yeah, it's true. If you type that bit pattern in, the compiler will assume 2's complement. But if you put it in a variable, the compiler will use the type of the variable. So if you have a 2's complement representation, it will do what's called an arithmetic right shift, which means copy the signed bits. If you have an unsigned int, unsigned representation, it will insert 0's when you do a right shift. Yeah, question? AUDIENCE 2. Yes, int is 2's complement. Yeah, if you want unsigned, say unsigned int, as I've written down here. I'm going to do the unsigned int. OK, so right shift then will use the type and end up dividing by 2 to the n. Now, of course, that can overflow or underflow too. It's always going to round down. So if I take a up here, negative 120, and I right shift that by 2, divide by 4, I should get what? Negative 120 over 4? You get negative 30, right? So you can see it's put some extra 1's in up at the top. And if you look at the bit pattern, you'll see that it's basically just shifted it by 2. What if I shifted by 10? It's like dividing by 1,024. So I'll be getting, it's a 2's complement number, and it's a negative 1. So I'll be getting 1's in at the left. So what am I going to end up with? Negative 1, right? So it'll be all 1 bits, which is negative 1. So you can think of that as divide by 1,024. That gives you negative 120 over 1,024. Round that down. That gives you negative 1. So I didn't wait for you to tell me. OK, if I shift this bit pattern 2 to the right, I put 0's in at the left because it's unsigned for b. And I get this bit pattern here, where I've just taken the bits and shifted them 2 to the right. If I shift 10 to the right, I get more 0's on the front. So it's just moving bits left or right in the bit pattern. Yeah, Eric? AUDIENCE 2 When you're getting those, you're looking at the dust, and it's not supposed to be. They're just binary form. Yeah. Yeah, so to know why these are the right answers, you will have to mentally translate from hex to binary, and then do the shift, and then translate back from binary to hex. Yeah, yeah. So I don't expect you to be able to do this in your head. The reason I put the decimal values up here is to make sure you understand it is dividing by 2 to the n. Had I written these as decimal, it would also make sense, except that would be a huge number. So at least I wouldn't be able to do it in my head. Good question. OK. Usually with shifts, we're thinking about bits. We're using our numbers to represent bits. You can use it for multiplication. It's slightly different than right shift. It's slightly different from division, because most division will round towards 0, and right shift will round down. Yeah, question? Yeah. Yeah, that's right. It doesn't matter. So if you think about the representations, it never matters. To multiply by 2, whether you have a positive or negative number for a 2's complement, you put a 0 on the right side. And the same for unsigned. I mean, there's no negative unsigned. OK, so that's it for the shifts. We also have six relational operators. So less than, lesser equal to, equal to, not equal to, greater equal to, greater than. You can't put spaces in these. One thing that's a little strange in C, in order to do a comparison for equality, you have to put two equal signs. So you'll see later, one equal sign means something different. It means the assignment operator in particular. So you need to not put spaces in these, and remember that to compare for equality, you need two equal signs. In C, anything that's 0, 0 bit pattern is false. Anything that is not 0 bit pattern, anything else is true. The relation operators evaluate to 0 if they're false, and 1 if they're true. But in C, anything that's not 0 is considered true. That'll come into play when we look at logical operators. So if I make these declarations, so I make two integers, a negative 120, b 256, and I say, well, is a less than b? So clearly, if I define them this way, yeah, of course, negative 120 is less than 256. But if you were to then put the same bit patterns in using an unsigned representation, then they would look like this in hex. You'd say, well, of course, this one on the left is much bigger than that one on the right. So if I compare less, it should be false. So again, like shifts, a C compiler will take the type that you declare of the variable, and it will use that to make the decision. So even though the bit patterns might be the same, the outcome might be different for a relational operator, depending on whether the type is two's complements or unsigned. OK. OK. So that's it for relational operators. The last operator is the assignment operator. So you can change variable values with the assignment operator. So for example, you could say, well, a equals 42. That's an expression. What that expression does is it takes the bit pattern for 42, and it overwrites whatever bits are currently in the variable a with the bit pattern for 42. So you can write any expression you want on the right-hand side. You could, for example, write a plus 1 on the right-hand side. That'll take the current bit pattern of a, add 1 to it, and write that new bit pattern, the sum, back into a. So it'll increment a by 1. So any expression you want on the right side is fine. On the left side, not so much. The C compiler cannot solve equations for you. So if you say, well, a plus b should be 42. Go figure it out. The compiler will say, I don't know how to figure anything out. I'm a computer. It'll actually say that much more cryptically. But that's what it's really trying to tell you, is I have no idea what you want. Am I supposed to change a, change b? So you can't write things like this in C. So you get a compilation error. So for our purposes in EC120, the left-hand side of the assignment should always be a variable. So just take a variable, put it on the left, right-hand side, any expression you want, including the current value of the variable, like a equals a plus 1 is OK. All right. One pitfall with this, because it looks like algebraic equals, people often accidentally, when they want to do equality comparison, they write 1 equals sign instead of 2. So if you do that by accident, so let's say that you want to compare a to 42, you're supposed to say a equals equals 42 to do that comparison. But let's say you make that mistake and you say a equals 42. Sometimes the compiler can figure out, you probably didn't mean to do that and give you a warning. In which case, go fix it. But it's probably better to get in the habit of not writing your comparisons that way. So if, for example, you write your comparisons with 42 on the left, and you say 42 equals equals a, it's the same comparison. But if you make a mistake, you'll get 42 equals a. The compiler will say, I can't do that assignment. That will always happen. So if you put the expression for an equality comparison on the left, the compiler will always tell you there's a mistake. And you can always fix it. So it's just a good habit. I started doing it relatively recently. But I'd suggest you get in this habit, too. I will try to make all my examples follow this rule. All right, then the last operators I want to show you, and again, you can tell by the stars, it's not something critical to our class. You will use it in 220. There's actually some subtleties we won't talk about here that you'll also learn in 220. So logical operators, so and, or, and not. They're different from bitwise. And I'll explain that in a minute. But they just operate on truth values. So remember, 0 is false. Anything else is true. So the logical operators will look at their arguments. And they'll say, well, is it 0 or not 0? If it's 0, that means it's false. If it's not 0, that means it's true. And they'll return, they evaluate again, either to 0 for false or 1 for true. So for example, if I declare a couple of variables, a and b, 120 and 42, then I can write these logical operators. So 0 is greater than a, or 100 is less than a. True or false? So is 0 greater than a? So 0 is not greater than a, right? a is 120. Is 100 less than a? Yes. So if I or those two together, I get a true, right? OK, good. And what about the next one? So is 120 equal to a? Yes. So does it matter what the other one is? It does, right? It's an and. Good. And is 3 equal to b? No. So what's the answer? Good. So what about this one? Here, it says compare a to b, and then complement the answer, the 1, because a is not equal to b. All right, so is 0 less than a? Yes, is 0 less than b? So is that and true? And then a complement it, so what should I get? 0, good. And then the last one is b plus 78 equal to a? I think so. OK, good. Good. You know how those work. So here's a task for you. Here's a C expression. Think about what the answer is. You ready? It's a tough one, I know. Did you get 7? You didn't get 7? I hope you get 7. So I'm pretty sure everywhere I've talked to people from everywhere around the world, the rule for precedence on multiplication and addition is the same. So hopefully it's the same everywhere. But usually we're told, OK, you do your multiplications, then you do your additions. So this one is relatively clear. It should be, hopefully. If it's not, you can add parentheses and C code too. That'll be fine. So the order of operations is called precedence. Which one comes first is called precedence. So here's another one. Excuse me. Sorry about that. Here's another one for you. You're 1.67? Is it someone's birthday? OK. Maybe it's a divide by 0 error. So if you do the 2 over 3, you get a 0. 10 over 0 is divide by 0. Maybe it's 1. You do the left one first. If you can't tell, and honestly I don't think there's any way, I don't think anyone's ever written this in elementary school or high school or college. No one writes that kind of expression. Don't look it up. Add parentheses. It won't even tell you how to look it up. Seriously, never look it up. You could, but then your code, no one else will understand it either, right? Because they won't know the order either. So if you don't know the order, put parentheses. That way your code is readable. Never go look up precedence orders. If it's not obvious, and I think probably the only one that hopefully is common enough is this multiplication versus addition. Maybe that one is not even obvious. OK, any questions on operators or expressions before we shift gears a little bit and talk about I O? All right, so we're going to look at input and output. Input's going to come from the keyboard. Output's going to go to the monitor, which means basically a terminal, like you've been using in the lab. And so you can send ASCII text out. You can read ASCII text in. Those are the basic I O operations. Later, not in our class, but later you'll learn how to manage graphics and things like that. So to control input and output, we use two functions. When you want to use those functions, you have to put this line at the top of your C program that says, well, I want to use the standard I O functions. So just put that line there. If you want to understand it, there's some starred section in the notes that'll talk a little bit about the preprocessor, but you don't really need to understand it at this point. You'll have plenty of time to play with it in your time here. So this directive tells the C compiler basically, hey, I want to use these standard I O functions, which I'll tell you about shortly. So to write text onto the display, we'll use a function called printf. So the f stands for formatted. So the first thing you have to put is your desired format inside quotation marks. So for example, you've got this function call down here. It says printf, parentheses, close parentheses over here, semicolon. Here is an example inside quotes. What that does is it sends the string or the characters between the quotation marks to the monitor. So it'll print out here is an example. It will not print the quotation marks. If you want special characters, so for example, if you want a line feed, you need to tell, well, it's not easy to put those between quotes because then your code looks funny. And so you need to mark those special characters with this escape character, the backslash. So for example, the line feed. If you want the output to start on a new line, you need to print an ASCII line feed character. In order to do that, inside the quotes, you put this backslash n. And that will tell printf that you want to print an ASCII line feed. So if you want a backslash, well, you have to put two backslashes. Two backslashes will become one. The first backslash says, OK, there's some special ASCII character coming. And then if you put another backslash, that's one backslash printed out. But backslash n will give you a line feed. You can put as many line feeds as you want in your format string. So for example, if I print this format string up here, the output will appear here. I've also stuck a backslash in just to illustrate it. So it comes out on three lines. And it actually has a backslash n at the end. So if you do another printf, that will start on a fourth line. Now, what if you want to actually print some variable values or some expressions? So for that, we use what are called format specifiers. So here, I've included three of them in my format string between the quotes. They're all %d in this example. So all of the format specifiers will start with a percent sign. The d stands for decimal. So it will print an integer, a two's complement number, in decimal for you. So here, I've just written some expressions separated by commas after the format between quotes. And so each of those expressions will be evaluated. So 6 times 7, of course, is 42. That will then be matched up with the first format specifier here. And it will be printed as decimal number 42. Second, %d will match the next expression in the comma-separated list. So 200 plus 17 prints as 217. And then the last one here will match this expression, 32 bitwise anded with 100. And so that will end up being 32. And so what it'll print out is this line down here. And at the end, you can see there's a line feed. All right, so what are the other format specifiers you can use? So if you want to print an ASCII character, you've got %c. The %d is what you just saw. Take an integer, two's complement number, print it as decimal. So ASCII decimal representation of the number will go out to the display. If you want a double, print it as scientific notation. You can print it as a decimal. And then the last one is %d. So you can print it as a decimal. Print it as scientific notation. You use %e. If you want to print it as decimal, use %f. If you want a percent sign, %%. These are all, by the way, in the notes. So I'm going kind of rapidly through the format specifiers. So that's a bitwise and. So if you think about what are the bits in 100, you've got the 64's place, the 32's place, and the 4's place. So this one is a power of 2. So this is just the 32's place. So if you write them as binary and you line them up, there's one bit, which is the 32's place, that's on in both numbers. So the and takes that bit and turns it into 1. Everything else is zeroed out. So the answer is 32. I know that would be a logical. So 1& is bitwise. 2& is logical. So if you were to put a logical operator here, 32 is not 0. So it's true. 100 is not 0, so it's true. True and true would be true, so you get a 1. But bitwise will give you bitwise and. So those are different operators. Good question. That's right. So if you do not include percent d's, some compilers will give you a warning. But the compiler will not prevent you from compiling your code. It'll just warn you that you've got extra expressions. Those expressions will be ignored. I'll mention that a little later. If you were to evaluate these expressions and put the answers in quotes, then yes, whatever string you, whatever material you put there is going to be printed. But if you want the compiler to evaluate expressions, here you could do it in your head in advance and simply write the numbers. But imagine these were the values of variables. Then you can use variables in those expressions, which you won't be able to calculate in advance. Yeah. AUDIENCE MEMBER 2 You don't count h? You're wrong, I think, on both counts. So let me go forward. So x is for hex. I don't think h will do hex. And I'm almost positive that b will not do binary. Printf implementations differ. So I'm not, for example, sure what the Visual Studio printf will do versus GCC. These are all standard. And pretty much any system you use will implement these. But there will be extra ones available on different systems. So as far as I know, there is no binary. You have to write that yourself. At least no standard binary printout. There are standard hex printouts, which are x and uppercase X. Sorry, if you want something printed as unsigned, you can use %u. And then if you want to see more, look at the man pages on a lab machine. And that'll give you the full definition for printf on the lab machine. Any other questions? So let's take a look at a couple of issues. So one pitfall, if you want any spacing, you have to include it in your format. So if you print %d%d%d, and then these three expressions, they just happen to be numbers this time, what will print is shown down here. There's no spaces. You didn't tell it to print spaces. It didn't print spaces. So your numbers are all jammed together. If you want spaces, you have to include them in the format string. So be careful about that. Anything that isn't a special ASCII character or a format specifier will print exactly as it appears between the quotation marks. So whatever you want, you can put there, and it'll just come out as part of your output. But you can put a dash in your format string. That's fine. You mean backslash? Yeah. OK, so backslash is two backslashes. So you can see up here, we have two backslashes between text and has. And when it prints, it comes out as one. So if you want a backslash, it's two backslashes. If you want a percent sign, put two percent signs. Out will come one. Sense? That's right. That's right. So if you write %%f, that will print as %f. It will not be interpreted as a format specifier. Yes, so if you don't end your format with a %end, then the next time you print something, it will come on the same line immediately after it was printed by the first printout. And that's useful sometimes. So you'll see a lot of programs in our class where you print a prompt. Please enter some numbers. So if you don't want the numbers that they typed to appear on the next line, you don't put the backslash n. And then it will appear on the same line when they type it. So it's a useful thing to be able to do. Yes, float is a single precision. Yeah, so I didn't mention it here. Actually, when you use a floating point expression in a printout, the compiler will implicitly convert it to double. And then the printout will treat it as a double. You don't really need to worry about it too much. It'll be automatically done transparently for you. And that conversion, there aren't too many ways it can confuse you, so I didn't mention it. But yeah, observation. When we see scanf, you have to explicitly tell it whether you want float or double, because there it matters. All right. So that's one pitfall. Another pitfall is passing the wrong kind of expression. So here, what I've done is I've said in my format, well, I want to print an integer and a floating point number. And then I passed a double and an integer. So I passed them in the wrong order. Now, the output is actually system dependent. But it's generally not going to be what you want. So my laptop, I think it was printed both as zeros. And clearly, that's not what whoever wrote this code wanted. Compiler may be able to warn you, but be careful about it, because sometimes it won't. If you pass too few or many expressions, if you pass too many, again, compiler may be able to warn you, it's not so bad, because it'll just ignore them. And then if you look at what's printed, you'll say, well, where'd my expressions go? And then you'll realize you didn't have enough format specifiers. If you pass too few, it will print bits. It will go find whatever should have been there to print. And it will take them. They will be bits. And it will convert them. So the behavior is unspecified. May be able to warn you, may not be able to warn you. So again, be careful. So that's it for printf. When we want to read input, we're going to use a function called scanf. So this will let you type things into the keyboard. The way it works is it won't actually read anything until you push the Enter key. So you can type as much as you want. You push Backspace. And then eventually, push the Enter key. And then scanf will get some things to look at. The f, again, stands for formatted. scanf also takes a format in quotation marks and a comma-separated list, this time of variable addresses. So you can put as many variables as you want separated by commas. All of them you need to put this ampersand in front of the variable name. So this operator, we're not going to talk about other than to tell you to use it in scanf. What it means is here's the address of the variable. That's where scanf has to put the bits that it gets by converting whatever you type into, say, a choose-complement number. So it has to put those bits somewhere in memory. The address of A is the memory location where it stores those bits. Yes, you need to put ampersand in front of every variable name. So if you had two or three of them, you would put ampersand A, ampersand B, ampersand C, separated by commas. Yes. So the %d means decimal interpreted as choose-complement. So you type in some decimal number in ASCII, and it translates it to choose-complement and stores it in whatever address you've given it here, which here is the address of the variable A. So A will now equal whatever number you typed in decimal. There is no scan function, so it'll simply give you a compiler error. Yeah, scanf is. There are other functions, but scan is not one of them. So you need to use printf. scanf reads from the, yeah. So you would first call printf, and that would give the prompt. And then you would call scanf, and that would allow the computer to read from the keyboard. Yes. Yeah, good question. So what happens if the human does something wrong? So let me come back to that, because I have a slide on what the return values are. So when you make a function call, it's like an expression that evaluates to something. So I'll tell you what they evaluate to when you call printf and scanf. Good question. All right. So scanf is going to ignore the whitespace that you type. So for example, if I ask for two integers here, A and B, and the user could type 5 space 42, and that would be fine. And A would become 5, and B would be 42. Or they could type 5, Enter, 42, Enter, and the same thing would happen. So scanf will ignore extra spaces, extra tabs, and so forth and so on. If you put other characters in your format string, the user has to type them exactly. So this is rarely useful. I mean, maybe if you want them to enter a time and you want to insist that they type a colon, maybe that's OK. But if you put something like this, where I've put these brackets in here, then the user actually has to type those brackets exactly like this. So they can put some spaces. Actually, if they put a space using this format, scanf will ignore those characters, because the space does not match that less than sign. And so then B will be unchanged. So it actually will not process the input as you would like. So it's rarely useful to put extra characters in. So this is a list of conversions. They're very similar to printf. The difference is that if you want to convert to a float, you use %f. If you want to convert to a double, you use %lf for long float. So that's the major difference here. You can use unsigned. You can use hex. Yeah, Rahul? AUDIENCE MEMBER 2. Ld is a long int. Yes, ld is a long int. And lld is long, long int. You mean if you did not put the ampersand on? Yes, then it would take the value of a as the memory address, which means it will write to some random memory address, which is kind of outside the scope of our class. But writing bits to random memory addresses, you can tell is probably not a good thing. Yeah. That's right. That's right. Yes. So for every format specifier you put in your format, you want to have one expression in the comma-separated list of expressions. Just like on the printf, when you told it you wanted to print an expression, you have to give exactly the same number as you have in your format. Now, these are simply variable names. I just decided to make them capitals because I thought it was easier to see on the slides. They can be any variable name. Yes. They have to put a space anyway to separate numbers. But putting a space between the format specifiers makes it actually a little more flexible. So it's probably a good habit to put spaces between your format specifiers in scanf. The resulting input will be a little more flexible. But for example, you can't type 542 with no spaces and expect the computer to understand that you meant 5 and 42 as opposed to 54 and 2, or 542 and I'll type something else later. So you do have to separate them with spaces already, even if there were no spaces in the format. Yeah. No. And so that's one case where you might want to put that literally in the string, that if you want them to type 0x or to be able to type 0x, you'd have to have that explicitly in your format. This will simply take the ASCII characters and treat them as hexadecimal if you put percent in. So it's %s for a string, but that's outside the scope of our class because you need to understand pointers and memory. And so you'll learn that in 220. Actually, you'll learn about it at the end of our class, but you'll learn about it in C in 220. So yeah. All right, so let's see. Same pitfalls as printf, match format specifiers and ordering to variable types, match number of specifiers to the number of addresses, and don't forget to write the ampersand. Because otherwise what will happen is, as Daniel said, it will interpret your variable value as an address, and then it'll write to some random memory location, which is not a good thing. So what do these things return? So this is what Sasha had asked about earlier. So when you call printf, it returns the number of characters printed. So whatever output it translates to, it will count the number of ASCII characters it sends to the display, and it will return that number of characters for you. So it'll tell you how many characters are printed. It has uses, but probably not so much with this particular call. So rarely will you see someone actually using it in code. With scanf, on the other hand, you should always check the return value. So scanf returns the number of conversions that were made. So for example, if you ask for two things and the user says hello, you ask for two integers, the user says hello, it can't figure out how to convert hello to a two's complement number. And so scanf will fail, and it will return minus one. If you type something like 42 space hello, it will convert the 42, and then again, it will fail trying to convert hello to the second number. And in that case, having converted one number, it will return the value one. So if you want to check that the user typed the right thing, you can simply compare, and we haven't talked about this if statement yet, but this is something we'll talk about hopefully before the end of the day. If scanf does not evaluate to the number two, so if two is not the answer returned by scanf, then something went wrong. So scanf should return the number of format specifiers that you asked for. If it returns something else, the human did something wrong. There are more graceful ways to help the human fix that, but the easy way for our purposes for 120 is to say, well, if they do something wrong, end the program. Tell them to run it again. So most of the code you'll see will be this simple in terms of how we handle errors. Does that answer your question? All right. OK, so I want to try to cover statements, and then on Friday, we'll look at code examples. So I'll mention I do have handouts. Feel free to take one if you want to look at the code in advance. It's on the links page, too, if you'd rather look at it just online. I do want you to have a handout in class on Friday. So if you take one, please bring it back so that we have enough. I think there should be enough, as long as people aren't taking two or three or something. And it is online, too. And the codes are online if you want to compile them, so you can play with them as much as you want. So remember, I said last week, a statement tells a computer what to do. So let's look at the kinds of statements. We've got three kinds in C. So a statement can actually consist of other statements, which can consist of other statements. So a big C program will have many very deep, recursively nested statements. But for the little ones we'll look at, they'll be fairly simple. So the three types of statements, you have what's called a null statement, which does nothing. So it's just a semicolon all by itself. A simple statement, I'll show you some more kinds in a few slides. But one kind is just use an expression, follow it with a semicolon. So for example, A equals B. It's an expression. But I want to do an assignment, put a semicolon after it that says, OK, my statement is done. Go do the assignment for me. Printf, it's a function call. It's also an expression. So expression followed by a semicolon makes a statement, simple statement. You need to have a semicolon. I think someone asked on last week, what if I leave the semicolon out, the compiler will complain. Compiler will say, I can't compile this for you. All right, and the third type of statement is a compound statement. And this is a sequence of statements. So you might think, oh, that looks a lot like my main function. In fact, it is. The body of main is simply a compound statement. So you have a list of statements, a sequence of statements that execute in order. So you can put whatever you want. So here I said, OK, radius will be 42. My variable c, which is maybe circumference, I'll calculate as the 2 times pi times the radius. And then I'll print that out. Inside a compound statement, you can actually have additional variable declarations. If you want to, you'd put those above the statements. So you can have variable declarations at the start and then statements inside. But we won't use that often in our class. So didn't want to put too much detail. So how do these execute? So there are three things to think about. One is a sequential execution. So the function body of main is a compound statement. And they execute in order. So if you have three statements, the first one executes first in the order of appearance in the file. The second one executes second. And the third one executes third. And when the program is started, all the program does is execute the statements in main in order, in the order they appear. And then the program is done. So here's another one. You actually saw this one already. But I want to make sure you understand it. So you can also introduce what's called conditional execution. So this illustration is a flow chart. The way it works is you're going to execute the statement. The first thing you do is you evaluate an expression. So there's some expression you evaluate. And that will either be true or false. Remember, true is anything that isn't 0. False is 0. If it's true, you'll have what's called a then statement, which is a block of code corresponding to when this expression is true. And you'll execute that statement. If the expression evaluates to 0, it will instead execute what's called the else statement. So I'll show you how this looks in C. But basically, it's just a choice. Do you do the then or do the else? So here's how it looks in C. So you use what's called an if statement. You put if. You put the expression you want to evaluate here. And then if that expression is not 0, the code that you execute will be between these braces. And you put the else keyword. And you put another pair of braces. And if the expression is false, then this code down here will execute. You can put any expression you want. And you can also leave off this else if you'd like to. So you can't leave off the first block, but you can leave off the second block and the else keyword. So how do you do that? That's a comment. That's a comment. Yeah. So how do you know that? So that's just how the C language is defined. So the C language is defined to follow what we call this. This is called a flow chart. So what the C compiler does is it translates this piece of C code into instructions that execute this flow. So it says, OK, first calculate the value of the expression. And if the value is 0, go down to the else statement. If the value is non-zero, go to the then statement. And so those statements are arbitrary code. They're compound statements. So you can put whatever code you want there. Does that make sense? Yeah. So you don't always have to put the else. You can say if expression, do something. And if the expression is false, don't do it. Don't do anything. Just fall out of the bottom and keep going with the next statement. So here's an example. So I could say, well, I want to calculate the inverse of a number. But if that number is 0, I don't want to divide by 0. So first I'll check. Well, is my number not 0? And if it is, I will say inverse equals 1 divided by number. Otherwise, I'm going to print an error message. So that's what this little if statement will do. The test is up at the top here. 0 is not number. If that's true, in other words, number is not equal to 0, then I calculate inverse. Otherwise, I say, oh, something went wrong. Yeah. Well. Is that part of the question? It doesn't really matter. If they're ints, it's not terribly interesting. Yeah, so if they're ints, this will generally come out with inverse equal to 0, right? So if they're floats, they wouldn't cause divide by 0. But you would get an infinity, which maybe is also not what you want. So you can maybe think of them as floats. Yeah. Yeah, so the thought was to set the variable value and then to use it later. So we'd also, I mean, I'm showing this one statement in isolation. You'd have inverse equal to something else later. You could add the printf inside, as you said. So there are lots of things you could do with it. I just wanted to show you how we use if. Good question. Yeah. Yes. Yeah, so this is a style thing. So any time you have a compound statement, you should increase your level of indentation by whatever your standard is. I usually use 4. A lot of people use 4. Some people use 2, 2 spaces. Some people use 8. And it doesn't really matter what you pick, but everyone on whatever team is working on a program should use the same style. The compiler will not give you an error, but we will mark off points. It makes it really hard to read your code. It makes it very difficult. There are actually tools that will automatically indent it for you. So if you're worrying about it, you can run it through an auto-indent tool. But they'll also do things like decide whether to put braces on or things like that, rewrite your C code for you to make it look nice. OK, any other questions? All right, so here's another example. So let's say I've got a variable size. This is an integer, let's say. And I want to make sure size is not bigger than 42. So here I don't have an else. If 42 is less than size, I'm going to change size, and I'm going to tell the user, hey, I changed size. So I'll print out size set to 42, and I'll assign 42 to size. If size was already less than 42 or equal to 42, I don't need to make any change. Another way we could use an if statement. Yeah, so in this case, there is no else block. So if this condition is false, it simply comes down to whatever is the next statement after the if. I wanted to give you an example with and without an else. OK, then the last statement I want to look at is this iterative statement. So if I want to do something more than once, and the number of times doesn't have to be defined. The way I'll decide to stop is I'll have an expression. So if I want to do something more than once, I can have this structure here. So first I'll have an initialization expression. Then I'll have a test expression. The computer will produce instructions that evaluate the test expression. And if it's false, I'm done. If it's true, I'll evaluate what's called the loop body, then execute an update expression, and then go back up and do the test again. So I'll go around this loop as many times as is necessary until this test expression becomes false. Now, that can be infinite. So if you write a loop badly, it just will never finish. Sometimes that's what you want. You might want a program that never stops. So for example, you probably don't want your operating system to say, you know what? My loop finished, and I'm just going to do nothing now. I'm moving on. So an operating system or an online service or something, you would have an infinite loop as the main construct. Just say, OK, keep paying attention to people and doing what they ask. So you can do that easily with a loop. You just make sure the test expression never becomes false. Here's what it looks like in C. We're only teaching you one, but I'll show you another one. So this is the for loop. So you've got your initialization on the left. So you have four open parentheses, initialization expression, semicolon, test expression, semicolon, update expression, close parentheses, and then a compound statement for your loop body. So just to make sure you understand how the flowchart works, I wrote it out as just a list. So what happens is first, the computer evaluates init. After it evaluates init, it evaluates the test expression. And if that test expression evaluates to 0, then it's done. It skips to the end of this list, and it moves on to the next statement. Otherwise, if the test is non-zero, that means true, then it evaluates the loop body. It executes the loop body. It's a compound statement, so it'll do a bunch of statements if you put a bunch of statements in there. Then it will evaluate the update expression after it finishes the loop body. And then it will go back to step 2 and evaluate test again. And go around 2, 3, 4, 2, 3, 4, 2, 3, 4 until test evaluates to false. All right, here's an example. So if I want to print the multiples of 42 from 1 to 1,000, I'll start by setting n equal to 1. Then I'll check that n has not gotten bigger than 1,000, because I only want to go up to 1,000. My update, you'll notice, increments n by 1. So inside this loop, the first time we execute this loop body, n will be 1. And we'll continue to execute this loop body 1,000 times until n is 1,001, at which point this test will be false and we'll finish. So for every value of n from 1 to 1,000, we'll check is n mod 42 equal to 0. That would mean n is a multiple of 42. So if it's true, we print that number n using %d followed by a character term. So this loop will print all the multiples of 42 from 1 to 1,000. Very important set of numbers. Yeah? AUDIENCE MEMBER 2. Do you need to define the number of multiples of 42 for a given test? Yes, but that's beyond the scope of stuff I want to talk about. Yeah, yeah, let me not. Ask me afterwards, and I'll tell you why. OK, so one more loop. We're actually going to do this loop in class on Friday. So a while loop, basically it's the same thing, but we don't specify the init or the update. So we don't want you to have to learn this in EC 120, but you might see it. So maybe just look at these slides. We'll go through the Fibonacci loop as a program on Friday. So this will come back. And feel free to take the handout if you'd like to. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\"},\n",
       " {'ECE120-2016-08-29-LEC-04-slides.mp4': \" We're going to pick up where we left off. We just introduced Boolean functions. So we're going to look at that, go through, make sure you understand them all, do truth tables for them, and then talk about logical completeness. I think we'll get pretty far through fixed and floating-point. Not sure we'll finish that all today. On Wednesday, we'll wrap up representations, and then on Friday, we'll start talking about C programming. So that's kind of the look ahead for the week. You have a lab due Wednesday, shortly after class. So if you haven't looked already, please look soon. I decided because one of my colleagues told me that some of our students, particularly freshmen, kind of got panicky a little bit last year, or last semester rather, and so I will go hang out in the lab tomorrow for office hours. So I know a couple of you asked me, and normally I'm at Mia Zaw's on Green Street, but instead I'll go sit in the lab. So, you know, if you were thinking of coming to office hours, it would be a good chance to do the lab. It's like 12 pages of reading. So, you know, it's a lot of reading. It's not actually that much work, I think. How many of you have done it already? Just out of curiosity. Oh, awesome. Good, good, great. So, you know, if you're one of the people in the room and there's feeling like, wow, I haven't done this and I'm feeling panicky, hopefully you can make it tomorrow to my office hours, sit down, do it, and I can help you out if you're having problems. Otherwise, there are lots of office hours. So look on the schedule on the wiki, and you can find other people. Okay, so a couple reviews. So we talked about four functions on Friday. We talked about the AND, which is the all function. So if all of the inputs are 1, it outputs a 1, otherwise a 0. We talked about OR. If any input is 1, it outputs a 1, otherwise outputs a 0. We talked about NOT, which is just complement. Put in a 1, get out a 0, put in a 0, get out a 1. And we talked about XOR, exclusive OR, and how it expands, which is the ODD function. So if an odd number of inputs are 1, it outputs a 1, otherwise outputs a 0. So those are the four we looked at. And I introduced this idea of a truth table. So again, a truth table is just a way of writing down a Boolean function. So we write down the inputs on the left side of the line. We write all the combinations, usually in binary order, given the order we've listed the variables. And then on the right side, we can put the outputs for each of those lines. Okay. So last time I kind of bungled my my management of my display. So this time, let me just go show you. So again, this is the easiest way I know to find things. It happens to involve going through my website. But there on the F16 link, you can find all of these exercises. And down here, there's lecture videos and lecture slides and stuff like that. But just to remind you, there's these tools here. And so if you want to practice practice unsigned or practice twos complement, you can change the number of bits. If you really want to challenge, you can go to 16. I don't think there's really that much practical utility in doing that kind of long example. But if you really want to make sure that you can do that repetitive translation stuff, you can play with 16 bits or you can do it with as few as four. You can see at the top, there's also a floating point. So when we talk about that today, you can play with that. There's also bits, which are the four functions that I told you about just a second ago, the Boolean functions. And you can make sure you understand applying those to sets of bits. You can also go do things like extend. So if you want to sign extend, twos complement pattern, make sure, you know, just copy the sign bit, right? So it's basically just copying. But just to make sure that you understand all the material, there's a lot of different exercises in here. If you feel uncomfortable with anything, it'll give you instant feedback. Let's see if I can get this one right. Kind of embarrassing, wasn't it? Oops. Okay, looks like I got it all right. So if on your mobile, you can push the button on your, if you're typing on your laptop, you can push the button with the mouse or you can push enter. It'll highlight the ones you got right in green. If you put something wrong, again, it'll show you what you got wrong. So let's just go put a couple wrong. So those will show up in gray and you can go back and check them. So you can do as many exercises you want. Just make sure you understand how things work. So let me switch back to PowerPoint. All righty. So those are the exercise tools. All right. So now let's go through our four functions and I want you to help me kind of fill in these truth tables. So let's start with and. And I'll also give you some more notational knowledge and how to draw gates and stuff like that. So let's start with and. So what's zero and zero? Good. What's zero and one? Good. One and zero? Good. One and one? Good. So with two inputs, they all have to be one, meaning both of them have to be one. All right. So this is the and function. We don't usually write it out with words, right? We'd like to be a little more concise with our Boolean expressions. So usually we'll use this multiplication notation from normal algebra. Okay, so if I write something A times B, it means A and B. Okay, there are other notations people use in mathematics. It's called a conjunction. So if you end up taking a math logic course or something, you'll see that notation. We also use gate diagrams. So this is an and gate here. There are two features that distinguish it from other types of gates. So when you start drawing gates, if you're drawing them by hand, make sure that you try to get a flat input and a rounded output and then people will know you mean an and gate. Okay, so that's that's and. So what about or? Let's go through and do the truth table first. So remember or is the any function. So zero or zero? Good. Zero or one? One or zero? One or one? Good. Okay, so you guys know these pretty well, it seems. So we also use algebraic notation. So for or we use plus. Okay, so multiplication is and, addition is or when we write Boolean expressions. Again, math terminology or math notation, it's called a disjunction. It's written with that little B there. And or gate, again, two distinguishing features, rounded input, pointy output. Okay, so if you draw things, just make sure that you get those two sides right and then people will be able to tell what it is. If you scribble it so quickly that we can't tell if the back of the input side is round or straight and you scribble the front side so we can't tell if it's pointy or round, then we won't know what it is. Just do it carefully enough that you can tell those two things and then people can tell what you're trying to draw. All right, what about not? So not zero? Not one? Good. Okay, so a bunch of ways we write not. We'll stick to usually the first two. So we'll put a prime when we don't have any video graphical writers handy or chalkboard. Often we'll write a bar over it. So the bar or the prime means complement not. There's also mathematical complement, which is this little thing here. So you might see that in some texts. The not gate is a triangle in an inversion bubble. The thing that actually does the not part is the circle. Okay, so if you see it without the circle, that's actually just a buffer. Okay, so it just repeats the signal that's used for performance reasons in circuits. So it's the circle that does the inversion and sometimes people will draw circles all by themselves. So in the book, in the Pat and Patel textbook, you can find still a few diagrams where there are inversion bubbles on the inputs to gates. So those are actually nots and if you built it, you'd have to have a gate for each of those little circles. And they'll fix that in the third version, but the third version, they're trying to save you money because the publisher wants them to produce versions. I really shouldn't say this too much on video. Anyway, so when the third version comes out, those will go away. But for now, if you're looking at the current edition, they still have some of those inversion bubbles on inputs. All right, what about XOR? A, zero XOR zero? Good. Zero XOR one? One XOR zero? One XOR one? Good. All right. So usually we just write that a plus sign with a circle around it and it looks like OR when we draw it as a gate, but it has two lines on the input side. Sometimes the inputs will cross the first line. Sometimes they won't. It doesn't make any difference. Those mean the same thing. So that's an XOR gate. To generalize, use the definitions that I gave you. So AND is the all function, OR is the any function, XOR is the odd function. We just looked at two inputs. If you want to use more inputs in order to make them commutative and associative, they're defined this way. Okay, so let's do an example with three input XOR. So it's the odd function. So what's zero XOR zero XOR zero? Good. Zero zero one? Zero one zero? Zero one one? One zero zero? One zero one? One one zero? And one one one? Good. So again, if you look at these, I mean, I think people are mostly following along, but it is the odd function, right? The number of ones on the left, if it's one or three, you get an output of one. If it's zero or two, you get an output of zero. And you can generalize to four or five, ten input XOR if you'd like. I won't draw the truth table. All right. So there's another way that we generalize these functions, which is by pairing up bits. So a lot of instruction set architectures on computers, and even starting maybe Friday or the day after Labor Day next Wednesday, you'll start to see these operations in the C language where you can take two sets of bits and do a Boolean operation on them. So for example, we might write something like this here, C equals A and B, where A is an n-bit number, bit pattern. B is an n-bit bit pattern. And what we mean by this A and B, where I've written it out with the word, is to take those bits, line them up. So you take A sub n minus 1, B sub n minus 1, you AND those together using a two input AND, that produces C n minus 1. You do that for all of your values of I, and what you get is this number C, where it's a bitwise AND between A and B. So this is what you typically use in a computer where you've got names representing sets of bits, and then you might AND whole sets of bits together. So it's another way to generalize the idea of the Boolean expressions, or the Boolean functions that we've talked about. Be careful not to mix the algebras. So when we talk about bitwise operations, we usually use the words. The reason is that it can get confusing, because when we talk about sets of bits, we can do things like plus. We talked about how we define addition on unsigned and two-complement numbers, and if we use plus to mean addition, then having plus also mean or gets very confusing very quickly. So when we talk about bitwise operations, try just to use the words. When we're talking about Boolean expressions, plus will mean or, and multiplication will mean AND. So try not to mix those, otherwise people will not understand what you're trying to do, or worse, you'll get confused as you try to derive something. I thought about going back and showing you another tool. There's another truth table tool. A lot of that is actually not things you need to know until after the first midterm, but the first tab in there will help you fill in truth tables. So if you feel like, OK, I want to get some exercise looking at Boolean expressions and filling in truth tables, there is a tool that will help you do that, give you the same sort of feedback, same interface, basically. And that's just the next tool down, two tools down. OK, so now I have a question for you. So how many different functions exist on n bits of input? So I only showed you four, right? And after class on Friday, people came up and said, well, what about this function? What about that function? I said, well, those are all nice functions. So how are you going to find that answer? So let's start with n equals one. How many functions are there for, let's say, I have an input a. How many functions can I define on a? I'm hearing a bunch of different numbers. Let's name them. So what can I define on a? So I hear a zero, right? So I don't care what a is, the answer is zero. So that's one function. And one, that's two functions. What else can I do with a? Zero and one don't depend on a. There must be functions that depend on a. Not a, and then just a by itself. So I think that's it. So you've got four functions. OK, I'm running out of fingers, so we're going to have to do this another way. So what about n equals two? How can I figure out how many functions there are? There are four on n equals one. For n equals two, try this. So here's a truth table. Got some function c as a function of f on a and b. I'm sorry, f is the function, a and b are the inputs. So instead of writing values, let me give those outputs names. Let's call them c sub i. C zero, one, two, and three. Now depending on how I pick c zero, one, two, and three, every combination gives me a unique function. So if I were to put four zeros, well that's the zero function on two inputs. If I were to put four ones, that's the one function on two inputs. Every combination I pick gives me a different function. It's a one-to-one mapping between choices and functions. So how many choices do I have? Sixteen, right? So I've got two choices for c zero. The choice of c zero doesn't affect my choice of c one, so I also pick c one. Each of these is just a bit, right? Zero, one. So I get two choices for c zero, two choices for c one, two choices for c two, two choices for c three. I multiply all those choices out. Overall, I have sixteen two-to-the-four different ways I could fill in this truth table. Each truth table is a different function. So there are sixteen functions on two inputs. So what about three? Good. So let's write our truth table, and we'll call the outputs d sub i, and we've got eight of them. For each of them, we have two choices. So two times two times two, I'm going to lose count, eight times. So two to the eighth. I want to point out that's two to the two to the three, right? Eight is two to the three. Four to the n. Maybe. Yes, you can do four to the n. All right. So can we generalize that to n bits? Please don't make me write a truth table. All right. So what do we do? So without drawing the truth table, n bits means two to the n rows, right? If you were to write a truth table on n bits of input, it's got two to the n possible input combinations, right? And so for each of those rows, we have an output variable. We have two choices for that output variable. So you multiply all those twos together, you get two to the two to the n, or four to the n is another way to write that. So two to the two to the n functions on n bits. But I only showed you four, right? Yeah. You have a question? Okay. Eric? So you said that you can have two to the n possibilities of putting those bits together. Two to the n rows, yeah. Two to the n possible ways to have input. But there's only eight outcomes in each of these. Yeah, so here n equals three, right? So what's the total possible outcome? When n equals three, we have eight rows. There are eight different patterns, right? And when n equals four, we would have 16 rows. n equals five, we'd have 32. If we did n equals 10, you'd have 1,000 rows in your truth table. You'd have 1,000 variables to define your function. 1,024. That's just the rows of them, what about the others? So for each row, you have one of these variables, and for each variable, you have two choices. So you multiply all those twos together. There are two to the n of them. So you get this one. That's where that comes from. You're all one. Yes, each output, you choose zero or one, and all of those choices specify a unique function. Yeah? So is this a row, column expression that we did before? No, it might take us a minute to work it out in our head. Yes? So a four to the two? Yes, yeah. Yeah, so you can massage this algebraically as you like, right? So two to the two is four, and you should know that if I have this power to a power, that you can actually do the first one. And then if you plug in a specific value of n, you can also do the other one. They're associative. Do the two to the n one, which we did already on the previous slides. OK. OK, so now the hard part. So I only gave you four functions. Got a lot of paper? I can see the headline now, Illinois professor single-handedly destroys rainforest. All right, I can't have that. So your alternate homework. Instead, you can understand logical completeness. It's your choice, really. But I'm not sure you really want to use that much paper. All right, so I have a claim. If you give me enough two input and, two input or, and not functions, I can compose those mathematically to make any function you want on any number of variables. Do you believe me? Really? Why? Why do you believe me? I'm a professor. The functions, you can set them up back to back where you can keep it. Yes. That's long logic tree. Yes, yes. So the question is, how am I going to do this? We're going to have to be able to put the functions together mathematically. In math, we call that composition. So we put the output of one function into another. I'm actually going to show you the proofs using gates. So we're going to draw it as circuit diagrams, but it's equivalent to mathematical composition of functions. Yeah. So you're saying that those three functions, if, like, let's say I want to do some kind of actually use any of these three functions, and I could get that. Yes. So the question is, I'm saying, regardless of what function you want to implement, no matter what the function is, I claim I can do it with just these three functions. And yes, that's absolutely right. And so I'll come after I show you how. So the proof will be what we call by construction. So in other words, I will show you a way, regardless of what the function you want to implement is, I will show you exactly how to do it using these three kinds of gates. A way to do it. It won't be the best way to do it. This is just proof of concept proof. But it will be a way that you can always build any function. So we'll come back to why that's important after we walk through the details. Let's start the proof. So here's a diagram. So you remember, hopefully, this is the AND gate. So if I hook these together, what do I get out of the right side? So ABC, right? A and B and C. Good. So it's a three input AND, in other words. And if I have three inputs on the left, I put three values into that gate formation, what comes out is the AND of those three variables. So out of those two, two input ANDs, I produce the three input AND. So what about this one? Yeah, four input AND, right? So I've shown you how to build a three input AND. Take one of those three input ANDs, hook it together with one more two input AND, now I have a four input AND. So you probably remember proof by induction from high school or something like that, right? With like AB? Oh, you have to do AB then? Ah. So does it matter what order you do? No, because AND is associative and commutative. So you could reorder these and do the diagrams a different way and you'd get the same answer. OK, so you remember proof by induction? What do I need to prove? OK, so what I'm hearing is if it's true for some N, then I have to prove it's also true for N plus 1. Is there something else I need to prove? Yeah, I better have a base case, right? So I have an example from Yale Pat for showing why if you forget your base case, your proof doesn't work. But I'll skip that one because I think people remember, got to have a base case. So here's our proof by induction. So by induction, we've got base case of N equals 2, for example. You want a two input AND? Well, that you gave me already. So I'll take one off the shelf and I'll put it down. There's your two input AND. That's the base case. You want a bigger, more input AND? We'll do the construct we just did. So we'll start assuming I know how to build an input AND. I'll take one of those. I'll hook together one more two input AND down here. And that will give me my N plus 1 input AND. So that's our proof by induction, that for any finite number of inputs, it can give you that AND gate. Happy? OK. Yeah, you should believe me when I prove things. I don't believe it just because I say it. I occasionally make a mistake. All right. So a couple comments. So first of all, the functional form is here. So if you want to see it algebraically, you can write it that way instead of drawing circuit diagrams. But this is not a practical way to build bigger gates. So don't go back and say, OK, now I know how to build 10 input AND gates. This is not the right way to do it. I just want to show you that it can be done so that later we can talk about, well, once we have this logical completeness idea, now we know what we need to build at the technology layer so that people at higher abstraction layers can make use of any function they want. So I'm kind of giving you a hint at why it's relevant. But it's not practically the right way to approach the problem. It's just a proof right now. OK, so now I can simplify my claim. So before I said I had to use two input AND, two input ORs. But I just showed you how to build those arbitrary input ANDs and ORs. So now I just cross out the two input because all I need to prove is that with arbitrary number of, well, finite number of input AND, finite number of input OR, and not gates, I can build any function. For OR, it's the same idea. Just go through the same proof structure, replace AND with OR. So let's start by thinking about functions that produce 1, 1 in their truth table. So a whole bunch of rows, maybe. I might have 10 inputs, 1,000 rows. One row produces output of 1. So that's a tiny number of functions, a very small number of functions. But let me start with those, and I'll show you how to build those. So each of these functions, exactly one combination of inputs will produce a 1. Any other combination of inputs produces 0. So let me give you an example. So here's Q. Here is one row here. All the other rows produce 0. But tell me, when is Q equal to 1? Yeah, so you just say, well, I mean, the inputs have to be here, right? So A has to be 1, B has to be 0, C has to be 1. So B is 0 when not B is 1. I need that expression to be true. So if I write Q equals A B prime C, then that's the function. That and is equal to 1 whenever A is 1 and B is 0 and C is 1. So any time you have this subset of functions, I can just use one and gate and maybe some not gates and build the function for you. So to build an arbitrary function, we need one more step. So the first step is, well, look at the truth table. And for every row, build the and function that produces the 1 for that row. For every row that produces a 1, I should say. Yeah. AUDIENCE MEMBER 2. What's the problem with the 1? So that's a good question. So if you plug it in, remember this is an and function. So all of them have to be 1. And so A has to be 1. So A can't have any other value. B prime has to be 1, which means B has to be 0. So B can't have any other value. And C has to be 1. So C can't have any other value. So if they have any other values, this combination produces 0. Yeah. So again, it's an and function. So remember, and means all. So all of these have to be true when I use an and. So for each one of them, that constrains that input to one value. And each input appears exactly once. So there's a name for this that you'll learn later. If you want to learn it now, it's fine. It's called a minterm. It's the thing that produces a 1 for exactly one row of the truth table. And it's a product of all of the inputs or their complements. All right, so we'll produce those minterms. So for every combination where we produce a 1 output, we'll produce that and. Then we'll take all those ands, and we'll put them all together into one big or gate. That's our function. That's it. So that gives us what we call a sum of products, because the or is a sum. We use plus notation for the or. And each of the things that we're adding together is a product. It's an and. So we use multiplication notation and algebra for that. That's a really inefficient way to build a real system. We'll talk about that in about a week and a half, how can you do a better job. But it always works. So in other words, if I give you those gates, you can build anything. And that's kind of the point of logical completeness. So we say that the set and or not is logically complete, because as we showed, you can build any function on any number of inputs using only those three. If you want to show that something else is logically complete, you don't have to go to these lengths. If you can show me that given some set of functions, you can build and, you can build or, and you can build not, then you're done. You don't have to show anything else. So for example, when we talk about circuit technology and the CMOS devices that we use today in all digital electronics, not all, but almost all, what they actually produce is the NAND function and the NOR function. So the AND gate followed by a NOT gate is kind of the natural thing to build in those technologies. Turns out that NAND all by itself is logically complete. So it may be something to think about. How can you take NAND, two input NAND, and build and or and not from that? Because that one function all by itself can build anything. Yeah, question? It's NAND. NOR is also logically complete. So this stands for not and. And it's A and B complemented or by DeMorgan's law, that. They're the same. That one function, you can build anything. Yeah? Can't you just plug in the NAND to make it NAND? First, you have to show me how to build an inverter with NAND. Yes, I mean, it's not very hard to build. But that's how you would prove that NAND by itself is logically complete, not to go through the whole constructive thing again, but just to show you can get these three. All right, so why do you care? So imagine you're working on a new device technology. Maybe it's based on DNA. Maybe you're working with Ogitsa Milankovitch. Maybe it's based on new semiconductors with John Dallasassie. Maybe it's based on carbon nanotubes with Joe Leiding. Maybe you're still finishing your degree. That would be really embarrassing for me if you're working on new technologies, like before you finish your Illinois degree. So no, I'm kidding. You have lots of opportunities here, all these technologies. So let's say you're doing that. What do you need to do to make your technology useful? Well, what you need to do is you need to be able to build AND, OR, and NOT. If you can build AND, OR, and NOT, then people who are designing circuits and components and computer architectures, they can take what you've got and build everything on top. If you can't provide those three functions, then how can they use it? So that's the abstraction. If you can provide those three functions, you can build anything, any function. If you can't build those three, then it's going to be a lot harder to use. So that's the abstraction boundary. So the technology has to be able to provide those. Again, lots of opportunities here for new technologies, lots of people working on cool stuff. Think about it in your four years here. OK. So actually, in the notes, if you look online, the slides that I posted, I did three input XOR. But someone asked me after class about this function. So I thought, OK, let's just put this one in the lecture. Like I said, any function is fine. So someone said, well, what if I want a function where I have some number of inputs, and exactly one of those inputs has to be a 1 to produce a 1? So we'll do that on three. So let's write the truth table. So actually, I just make it pop up. So get a feeling for what you think it should be, and I'll make it pop up. So again, if output's a 1, if and only if exactly one input is 1 or true. So here's what I thought was the answer. So if you have c equal to 1, but a and b is 0, you get a 1. If you have b equal 1, but a and c is 0, you get a 1. If you have a equal to 1, but b and c is 0, you get a 1. Anything else, you get a 0. So let's go through and follow our constructive proof. So what is the function that produces that yellow row up there? Yeah, so a prime or a prime b prime c, right? Good. OK. What about this row? a prime b c prime? OK, good. And one more row with 1, right? What about that one? a b prime c prime. OK, good. So those are the only ones with 1, right? So for each of those, we produce this minterm, this product of the literals. We call the individual inputs literals, or they're complement, or also called literals. So we produce these three functions, and then we OR them together. So if we OR them together, we get our function. So you can follow these steps for any function you want, and that will give you the function using only AND, OR, and NOT. So now we're ready to start thinking about, well, how would we actually build that adder we talked about in the first couple days of class? We can do any Boolean function we want. Addition is just a Boolean function. You take some bits, bit pattern representing an unsigned or two's complement number, take another one, and you spit out the sum. It's just Boolean algebra. So now you have a way of thinking about how would you actually build that using just AND, OR, and NOT. Any questions on that before we play the floating point? Yeah. So those plus signs, won't that be the AND? OR. Plus is OR. Yeah. So yes, these are ORs, and the multiplication notation is AND. So this is A prime. So A prime means not A. B prime means not B. C means just C by itself. Those are ANDed together, and then the output of that AND is ORed with the output of these two ANDs. And it has the same precedence as your normal algebra. So the AND happens before the OR, which is also actually important that I should have mentioned. Yes. Yes. So if I were to write this for you in your normal algebra, you would multiply before you'd add, right? So same thing. All right, so let's go forward. All right, so in binary, we have a binary point. I know internationally, people sometimes draw this as a comma. So sorry if this is not the way you'd normally write your decimal point. So if I want to write down pi, for example, I would have that period there. And then after the period, I would have 1 for the tenths and 4 for the hundredths and so forth. So if I write binary base 2 in human terms, well, I can have a binary point. After the binary point, I have the 2 to the minus 1, so the halves place, the quarters place, the eighths place, and so on. So that's pretty straightforward. So let's say that I'm not happy with integers. We've talked a lot about how we represent integers. What if I want fractions? What if I want real numbers? What do I do? Well, one thing I can do is I can use what's called fixed point. So I say, well, in the middle of my representation, I've got a binary point. You can just pick something. It can be supported by software. It can be supported by hardware. It can be supported by both. It doesn't really matter that much. It's relatively easy to do it this way, because everything is still a power of 2. And so it turns out I can use the same adders and multipliers as long as I line things up properly. And sometimes maybe I'll even do that in software. So there have been a lot of generations of processors that just did all of this stuff in software to have fixed point representations. Some signal processing and embedded processors have hardware support for fixed point. So it's a fairly simple extension, again, just based on human notions of representations for binary. So we could do that. So do we need anything else? Or is that good enough? Yeah? Is irrational hard? Yeah, irrational is hard. But the thing is, part of the reason it's hard is there's so many of them. And so we kind of have to make do with an approximation, because to represent irrationals well, one could argue we need infinite number of bits. So that's not quite true. There's some substantially more complicated representations. Actually, I was talking with another professor, John Tallon, about them a few nights ago, because in his mathematical physics class, he's introducing people to them. There's something called continued fraction representations. People have tried to put those in hardware. They're fairly complicated to build hardware. And so what we tend to do is approximate. So what you'll see is an approximation. Good question. Yeah, that's a good point. So we do need negative numbers. So we could probably add a sine bit, kind of the way we did with two's complement. Or we could do sine magnitude fixed point. Yeah, that's a good question, though. Yeah? What about our repeating fractions? Yeah, so repeating fractions, we could try to come up with a representation that handled them well. There's a little bit of that that's natural. If you think about translating just decimal to binary, then some numbers that are finite will become infinite in the other one, because of the primality of the factorization. So people haven't, I think, come up with a representation that focuses on trying to represent repeating fractions. But it would be an interesting thing to do to see if there'd be any leverage. Yeah? That's just not a good idea. Yeah, yeah. So if you mean just having more range, we could throw more bits at it. Or we could think about, well, is there a way with the same number of bits we could get a bigger range of possible numbers? So let's think about all of those. And we'll roll forward and kind of see what floating point gives us. So let me just start by saying, well, what's the range of 32-bit two's complement? You guys know it, right? Everyone knew that? If I say, OK, write down on a piece of paper? OK, good, I'm glad you did. I usually write it this way. I don't remember. I remember 4 billion. The rest is a blur. But I think, I'm sorry, 2 billion. Yeah, 4 billion for unsigned. So let's write some banking software. So forget all this real number stuff. Let's just do banking software. And I say, OK, I'm going to store one 32-bit two's complement number to represent pennies in your account. Anyone have more? No? All right. So we're done. Got our banking software. Let's say you have a friend who has more. Well, OK, 64 bits. There's not that much money in the world. So we're still done. So what about chemistry? Anyone in chemistry? OK, good. So you got chemistry homework, right? You probably want to use a computer instead of going to the lab and being dangerous with chemicals. What's Avogadro's number? 6.0. OK, that's what I had, too. But well, so 10 to the third is 2 to the 10th. So that's about 80 bits. OK, so who's got Avogadro's number to 80 bits? That's 24 significant figures. The ones in chemistry, you know this one, right? No? What are we going to do? What are we going to do? OK, we've got to give you some homework. I should let you go early, because this is going to take you quite some time. Maybe we can just be close. Maybe we can just make up some bits for the other lower bits. Who's going to tell you you're wrong? Not the chemists, right? All right, so what about quantum mechanics? Anyone have quantum mechanics? OK, so some of you do. What about Planck's constant? Anyone have that one yet? OK. You should use Ergs, because Ergs are cool, and all the physicists use them. So yeah, those have to go after the binary point. It's a small number, right? So we'll need 90 bits after the binary point. Oh, that's 24 digits for Avogadro's number. So do we really need 170 bits of precision? Do we need, what is it, 51 significant figures of Avogadro's number to do our chemistry? Probably not, right? But it would be nice if we could represent both of those numbers. So I think people mentioned a bigger range of numbers, maybe with the same number of bits, maybe 32. So small numbers and big numbers. So what can we sacrifice to do that? Well, let's think about what we do as humans. I mean, we've already done it a few times in these slides. We have this notion of scientific notation. So we say, well, what we care about is maybe 5, 6, 7 significant figures. And we have an exponent. But we don't just write all the rest of the digits just because it's a big number. We don't write all the zeros just because it's a small number. We put it in this handy scientific notation, which has three parts. There's a sine. There's these significant figures, which I'll call them antissa. It refers to the precision, right? More digits means we know the answer better. And then we have this exponent. So let's make a representation that has those three pieces. So that's what we call floating point. So Belval Kahan at Berkeley really is the author of this floating point representation. Prior to the standardization, there were lots of different floating point methods in different computers. And they had lots of different numerical problems. So actually, IEEE floating point is really well thought out. And that's mostly due to Kahan. So pretty much every modern computer implements this. Well, any modern computer that supports floating point will implement IEEE 754 standard floating point. So this is what single precision looks like. It's got 32 bits. It has a sine, which of course is one bit. It has an exponent, which it uses eight bits. It has an antissa. Remember, those are the significant figures. You've got 23 bits for that. It's about six digits. So what does a bit value represent? So let me ask you a question first. So what are the values of that digit? Can it be anything? Maybe 0 to 4, 1 to 7? What can that digit be? Remember, canonical form is something it's not supposed to be, right? It's not supposed to be 0, because you can change the exponent. You can change the exponent. You can change the exponent. It's not supposed to be 0, because you can change the exponent. So remember, you're supposed to not have 0. You can have anything 1 to 9. So you can change the exponent if you had a 0 there. Just move it around so that you've got canonical form, unique form. All right, so what about in binary? Same question. Now binary. I'll give you the answer. Not 0 is the answer. But that means it's just a 1. OK, so now how many things do I need to represent one value? How many bits? 0. It's always a 1. I don't need any bits to represent that 1. So the leading one is implicit. So now we can go on and look at how we interpret this number. So if I have these bits, I can plug it into this formula, and that will tell me the number. So negative 1 to the sine. So if sine is a 0, that means it's positive. If sine is a 1, that means it's negative. This implicit 1 here, remember it's implicit. It doesn't take any actual bits in the number, because implicitly there's going to be a 1 in scientific notation in binary. Then the mantissa bits, all 23 of them, multiplied by 2 to the bits of the exponent interpreted as unsigned minus 127. So we can go all the way from about negative 120 to about positive 120. 2 to the negative 120, 2 to the positive. It's about 10 to the 38. Plus or minus. Yeah. Can you explain that again? Sure. Ah, yeah, yeah. So here in decimal, the answer was not 0. So we changed the exponent to make it be not 0. The answer is also not 0 in any other base, because you can always shift the exponent. But in binary, that has a further implication. If it's not 0, it must be 1. And if there's only one thing to choose from, you don't need to store any bits to represent what that leading digit is. It's always 1. There's always a 1 there. Now, there's one caveat that I'll show in the next slide. But the general interpretation is, yes, there's always a 1 there. Yeah. Why is it precocious? It's a biased offset. It's so that you can have big and small exponents. So if you want something like Planck's constant, you need a very small exponent. If you want something like Avogadro's number, you need a big one. So you want to be able to represent big and small. So this just means my 8-bit unsigned value in that exponent field is going to represent big exponents and little ones. And the choice of 127 is to make that balanced. That's why. Yeah. What's the name of that exponent? It's unsigned. It's unsigned. It's actually, there's a different name for it. So if you go read the standard, it's called a biased offset or something. But if you look at it as 8 bits and you translate it into decimal as an unsigned number, then you can subtract 127. And that'll give you the right answer. It's not two's complement. So yeah. Yeah. For doubles versus quotas, what are doubles basically? I know that you have 14 points of precision. I don't remember. I'd have to look it up. So if the double, you have 64 bits in total. One is the signed bit, obviously. And then the exponent and the mantissa split the other 63. I don't remember exactly how. And then there's actually now a standard quad, which is 128 bits. Yeah. Yeah. How would a standard quad work in terms of like? Yeah. So which bit corresponds to a half depends on your exponents. But the first bit of the mantissa in order appears after the implicit one. And so you would just take the bits here and write them out. And that would give you the binary scientific notation form of the number. Yeah. So going back and forth on paper is relatively easy. If you can put something in binary, and we'll do some examples. If you can put it in binary scientific notation, you basically just copy the bits into the 32. Yeah. OK. All right. So the one caveat, well, a couple. IEEE supports infinity, not a number. You don't need to know most of this stuff. The one thing you do need to know, so it's here in the notes if you want to look at it. You don't need to use it, though. The one thing you do need to know is that, of course, we need a 0. And 0 does not start with an implicit 1. So we need to be able to represent the number 0. That's the bit pattern of all 0's. And that was not accidental. So if you have a floating point number that has all 0's in it, it's the same 0 representation as unsigned in 2's complement. It's all 0's. But the denormalization is kind of beyond the scope of the class. So I'll put it in the slides for you. And yeah. It's still the implicit. No, no, no. I mean, 0 can't have an implicit 1. If you write the number 0 in scientific notation, you have to put a 0. So that's the exception to the rule. So the all 0 bit pattern is 0 in floating point. So how do you get the 0? The representation is well-defined. So we've just agreed on it. So now, if you were to go out and build hardware, you know what to do. Yeah, yeah. So that's a good question. But all representations that computers are going to use have to be defined in advance and agreed upon. So this is the one exception. I mean, there's also denormalized numbers. But that's beyond the scope of the class. All right. OK. So conversion. So you can do this in the tool, too, if you want to practice it. But it's not actually too hard. You convert to binary, change to scientific notation, and encode each of the three parts. So we can do an example. The integer part, you know how to do. We've done that already. The fractional part is actually equally easy. So you can write the polynomial in the other direction. So it would be these inverse powers of 2 is our fractional part. And then you think, well, if I multiply f by 2 and I multiply this side by 2, the only way this side can be bigger than 1 is if this term is 1. Because all of these, there's a quarter, there's an eighth, and so forth. So the only way for the right side to be bigger than 1 is for a negative 1 to be 1. So all you have to do is multiply both sides, multiply your number by 2. And every time you get a 1, that's a 1 bit. And every time you have something less than 1, that's a 0 bit. So let me walk you through an example. So let's say this number, it looks intimidating, but I promise we won't have too many bits. So we have that number. First, we write 5 in binary. We get 1, 0, 1. Now we need to convert that fraction. So multiply it by 2. We get something less than 1. So a negative 1 is 0. Subtract 0. Multiply it by 2. Still less than 1. Another 0. Subtract 0. Multiply it by 2. Still less than 1. Same thing. Keep going. Eventually, we will get something bigger than 1. So that tells us a minus 5 is 1. And then we'll subtract the 1 off of both sides. So we'll get half left. And then we'll multiply by 2 and get 1. So a negative 6 is also 1. And then we're done. So that's our fraction in binary. So we would give you shorter problems on exams if we were to give you something like this. And we certainly wouldn't give you something where you had to look at all 23. That would just be mean. All right? You don't want to do that by hand. You want to teach your computer to do that. And I promise the tool is also like 4 or 5 bits. So even if they look intimidating, if you work it out on paper, it's just a few bits. All right. So one last step. So we've got it in binary. So change it to binary scientific notation. And now this 1 here is implicit. These are the bits of the mantissa. Then you've got a bunch of implicit 0's after that. So the other remaining bits are 0's. This is our exponent. So into the field, we have to put 129. So then 129 minus 127 is the 2 that we want. And there's our mantissa with 15 more 0's. So that's it. Yeah. This one I think I'll save, because I want to make sure you understand it. Floating point's a little weird. It's not associative. So we'll talk about that on Wednesday. Thanks. 1 to 3 tomorrow. Oh, I stole my mic live. It doesn't matter. 1 to 3 tomorrow. Oh, I stole my mic live. It doesn't matter. It doesn't matter.\"},\n",
       " {'ECE120-2016-10-17-MT2-review-slides.mp4': \" So we're going to do another review session. Same rules as last time, so hopefully people have thought about what they want to talk about. Anyone want to throw out the first suggestion? Eric? Okay, sure. One comment quickly on that is that essential prime implicants are not, that name is not required knowledge. And I know it showed up on some of the previous midterms, but you don't need to know what that means. We do ask sometimes whether the solution to a particular KMAP is unique or not. And so we can talk about that. But knowing what's an essential prime implicant is not necessary. Mohamed? Okay. Okay. And, yeah, Daniel? I'm sorry? Decoders. Okay. And then? Actually, let me. Adders. Okay. Some of these are pretty specific, so they won't take much time. Anything else people want to throw up there before we vote? See if there's anyone. Okay, we'll give both of you one last chance. Go ahead. Okay, Mohamed, what were you going to add? You mean the canonical ones? Okay. All right, so this is a long list, so let's do voting quickly so we don't spend too much time on that. So you can vote for as many as you want. Essential prime implicants? Two. N-type MOSFETs? About 20. Decoders? Oh, lots. Oh, my goodness. Okay, 50. Timing diagrams? A lot. 40, let's say. DeMorgans law? Maybe about 15. Matters? 15. Functions of MUXes? About 30 to 40. Analyzing sequential feedback circuits? Lots again. 45, I think. Canonical SOP, POS? Three. Okay, so let's start off with decoders then. So, decoder basically gives you minterms of the input. So, the way it works, you would put in some number of wires. Let me draw it the way they've been drawing it in other sections. The way we drew it was like this. These are the same. So, basically, you're taking in some number of select wires, and those select signals you can think about as having some kind of coded value. And you want to know which one of those coded values is held, and so you create an output for each possible bit pattern. So, for two bits, you've got four possible bit patterns. So, each of those wires on the outside, on the right side, carries a one if and only if the bit pattern coming in matches that particular number. So, 0, 1, 2, or 3 are the four possible bit patterns interpreted as unsigned. The enable then just enables the decoder to output a one at all. So, if enable is zero, the decoder outputs all zeros. So, enable equals zero means that all outputs are zero. And enable equals one means exactly one output is a one. Because the bit pattern can only match one of the four possible bit patterns. So, this is a decoder's useful primarily in implementing logic where we need to know which of those four bit patterns was being carried. For a three-day decoder, for example, which of the eight possible bit patterns was being carried by the inputs. So, a lot of things like vending machines or memories will make use of them. We can also use them for implementing arbitrary logic functions by just using OR gates to OR together the minterms. Remember, these are minterms, right? So, matching a particular bit pattern is the same as a minterm. So, each of these outputs correspond to a minterm. If you wanted to know how to build them, then you can just build the AND gates corresponding to the minterms. So, you can say, well, here's an AND gate that takes enable along with S1 prime and S0 prime. And so, this would be the zero output. And then the AND gate that takes, I'll just draw enable linked up. The others I'll leave along with S1 prime and S0. This would be the one and hook up enable to all four of them. This would be S1, S0 prime. That would be the two. And then S1, S0. That would be the three. And so, that's how you would implement a decoder. You would basically generate all the minterms with AND gates. If there were an enable input, AND it together with all of the minterms. And then each of those AND gates would give us one output. Yeah. Yeah, so the outputs, the labeling of outputs on a decoder is usually using the unsigned representation of the input values. So, usually the inputs we would name something like select and it'd be S1, S0. Or for five bits, it would be S4 down through S0. And then the output labels would be the unsigned values. So, if you had a 5 to 32 decoder, they'd be labeled from 0 to 31. And each of those outputs would correspond to the five bit pattern represented by S4 through S0 as an unsigned number. If you then wanted to make different functions, it's not terribly interesting with a 2 to 4 decoder. But if you wanted to make XOR, for example, how would I do that with, say, another OR gate down here? But which minterms does XOR have? Yeah, 1 and 3, right? So, I'd pull off the 1 and 3 outputs and OR those together and that would give me XOR. Yeah, 1, 2, sorry. What about OR? Yeah, so OR should be true for this minterm, this minterm, and this minterm. So, again, 2 to 4 decoder is not terribly interesting. It would be easier to just pull S1 and S0 directly. You can do any function using, by the way, the canonical SOP version, right? Because the canonical SOP is the sum of minterms. So, if you write any function of S1, S0 as a sum of minterms, then you go find those minterms or the outputs of the decoder together that will give you the function. Anything else you want to talk about with decoders? Yeah, this is no longer really used that much in practice. You know, if you were building something out of TTL and you had a decoder and you wanted an arbitrary function, maybe you'd use it. But these days, it's easier to just build a function. Yeah, Mohammed? This is the decoder. Yeah, this is how the decoder is built, these four AND gates. I didn't draw the NOT gates to complement these, but this is the decoder. So, let me put a box around it. Sorry, I added more logic. That's the decoder. I zoom this. So, those AND gates are the decoder. All right, so let me do... It was not on the topic, so let me see what happens timing-wise. Okay, so next up then was supposed to be analyzing sequential feedback circuits, but let me instead, because timing diagrams I think will be brief, just talk a little bit about timing diagrams. I mean, really, I know there have been a couple of questions on timing diagrams. Oops, these are not all... There have been a couple of questions on timing diagrams on some of the previous exams. You need to know what a timing diagram is, so what it's, you know, you should be able to recognize one, for example. Most of the stuff we're going to do, you wouldn't draw any significant timing, certainly in this part of the class, because we're assuming clock synchronous sequential circuits, so everything operates on a clock signal. And I don't think we've ever... I mean, I'd have to go back and look through the old exams, but usually we don't ask you to reason about gate delays and things like that on a timing diagram. So it would really just be mapping out the kind of thing you did in the homework where you would draw the clock cycles, right? And you would represent what's going on in the different signals from clock cycle to clock cycle without more information than that in the timing diagram. So, you know, it's the kind of thing we also did in lecture where, for example, if you had a binary counter... Let's just make it easy, so we'll give Z1 and Z0 outputs. And of course, there's a clock input, so here's the clock. Then the clock should be a square wave, at least as best I can draw a square wave. And so then if your counter is starting at zero, you might say, okay, so, you know, when do the value... You know, draw the rest of Z1 and Z0 for a two-bit binary counter. So when should Z1 and Z0 change? Yeah, the rising edges, right? So the first thing would be to go mark the rising edges. Here's one, here's another one, and so what should change at this first rising edge? Z0, right? Because it's a two-bit binary counter, so it should go from zero to one. So Z1 will stay fixed, Z0 will go up to one. Okay, what happens at the next rising edge? Yeah, so we'll go to the one-zero state, right? So that'll go up, this one will go down. What about here? Z0 goes up, Z1 stays up. And what about... go back to zero. And now we're back in the original state, right? And so this is just going through the four counting states. So this is zero, zero, zero, one, one, zero, one, one, and then we go back to zero, zero. And then we go, I guess, to zero, one, right? Skating flip-flops. You mean of the ripple counter sort? You mean something like that? To D or to clock? Okay, so yes, there's certainly... It's certainly possible because we talked about registers and things like that for you to have flip-flops running on a common clock. So these flip-flops inside of this counter, for example, are running on a common clock, right? So all of these transitions, if I were to draw the inside of that binary counter, those are two flip-flops running off the same clock. And then, of course, the D inputs are going to be expressions of the counter. Now, this is finite state machine design, right? So it's later. But we did do registers, right? So we did shift registers, we did registers with parallel load. So those topics can be on the exam, topics of finite state machines. Was there anything else people want to talk about with timing diagrams or can we move on? Okay. All right. So let's look a little bit at analyzing sequential feedback circuits. So... What is a sequential feedback circuit? So if I have a... If without using a flip-flop, I take the output of one of my circuits, and I link it back and make it into an input as well, we call that a sequential feedback circuit. So, for example, a latch is a sequential feedback circuit. So... If your output's connected back to your input and there's no clock signal in the design, then that's a sequential feedback circuit. So the one we looked at in class, what we started with, was the R-bar S-bar latch, which looked like this. And then we built that up and all the way up through a gated D-latch, and then we went to a D-flip-flop based on this storing a bit design. You can also build SR latches out of NOR gates. These are the common designs in CMOS. Instead of NAND, you use NOR. So this is an SR latch. So if you think about the functionality here... I'll label it Q-bar, although if you turn both of those on, they'll both be zero. So here, these are active high inputs, right? So since it's a NOR gate, if I put a one in on the R input, that will force the NOR gate output to zero, so Q will be zero. So they have the opposite input sense from the R-bar S-bar latch on the left. So this was our Q, and let's see which way did this work. So if I put this as zero... Would both latches give the same outputs? Both of these can store a bit, but the input sense... These are active low inputs, these are active high inputs, and you'll notice they're swapped relative to Q. Active high means that in order to take the human action represented by the name, so if you want to set the output bit, which refers to Q, on the left, you make the S-bar input to zero to set Q to one. On the right, you make the S input equal to one, which means active high, to set Q to one. All right, so really all we want you to be able to do is analyze stable states. So there are a couple ways you can do it. There's the simple way and the harder way. So since we already did the circuit on the left, let's do the one on the right. So you can say, okay, so for R and S, I can look at what is Q. Let's give this name P, actually. So if I set R and S to zero and zero, does that tell me anything about Q or P? No, right, because those are NOR gates. So if I put a zero, I mean, think of it as OR followed by NOT. If I put a zero into an OR gate, I need to know what the other input is, right? Zero or whatever is whatever. So for both of those zero inputs to the NOR gates, I don't change anything in my circuit. So then we could start the way we did in class and say, okay, well, let's just say there's a zero in Q. What does that imply about P? So the bottom gate then would have two zeros going into it. It's a NOR gate, so out will come a one, right? So P is one. In that case, Q, I'll put a little implication arrow here, means P is one. And if P is one, what does that imply about Q? Q is zero, right? So it also goes back. You want to go around the loop because not all of these will be stable. So if we're just looking for stable states, make sure you go all the way around the loop, around the feedback loop, and check. So this state is stable, but what if we had instead guessed Q equals one? What is P then? Zero. So in that case, if Q equals one, then the bottom gate is a NOR gate. It has a one coming in from Q. NOR gate has a one. It gives a zero output, so P is a zero. And then what is Q, given P? It's a one. Top gate now has two zeros going in. So those are stable states. So this thing will store a bit when R and S are both low. What if I set S to one? What can you tell me about Q and P? What's P? It's zero, right? Because that NOR gate on the bottom now has a one coming in from S, so P is zero. So what is Q? And that's why we call this S active high, right? It's setting Q to one when you have S input of one. What if R is equal to one and S is zero? So Q is zero, right? Because the upper NOR gate will output a zero. And then P is what? That's why we name it R, and it's active high. So if I set R to one, Q is reset to zero. And we'd want to avoid this state, just as in the latch on the left. We said, well, we don't want to set them both to zero. Here we don't want to set them both to one. What output do we get if we do that? Zero, zero, right? Q and P are both zero. So we don't want to do that because then the actual value, once we stop trying to force both of them to zero, we can't depend which of these we lower first. And so we don't know what the final answer will be unless we analyze the timing carefully, which is a pain. So we try not to use this one this way. No, it would be, so if you write this as next state table, then Q retains its state, right? It's able to hold a bit. So you put Q plus equals Q in the notation of the homework, yeah. So if you wanted to rewrite this, you could say RS00, Q plus is Q, 01, Q plus is zero, I'm sorry, one, 10, Q plus is zero, and then 11, and then it's zero, but P is not Q bar, so you've got to be careful. Okay. So the more complicated way that I showed you in class will also work. Usually we're asking you, though, for stable states, so you then have to go through your truth table and find the ones that are stable. So remember that when we did it in class with a more complex circuit, we had to look for the rows that were stable by identifying the rows with Q equal to Q plus. One one is a stable state, but the outputs are both zero. So the outputs are both zero, which means that when you let RS go down, the bits that's actually stored depends which one goes down first, right? And so unless you really understand the timing of your RNS signals, you won't know what bit is stored after you've raised both of them. And worse, if you lower both of them at the same time, you can encounter metastable states where the thing actually oscillates after you've lowered RNS. There is no unstable state in this design, but if you, for example, had, I think there was a, let's see, where did I put it? Here's XOR, and let's run that through, I don't know, a NAND gate or something. If I do something like this, so it's unstable if this thing is a single inverter, right? And so since that's an XOR gate, if I put A equals zero, then that's basically a wire from its other input to its output, right? So if I say A equals zero, then that implies, let me call this, oh, this is P, then that implies that Q equals P, right, from that XOR gate. But then looking at the other gate, if, let's see, if I put B equals zero, I'm sorry, B equals one down there, then P equals Q prime. But I can't satisfy both of these at the same time, right? So if I look at A and B and I say zero, one, then this is unstable. Does that make sense? Right, because if you look at these two inputs now, on the top one, that XOR gate is just forwarding its other input to its output, and the bottom one is inverting its input, so you have a loop of one inverter, effectively. If you have a loop of one inverter, it's just an oscillator. Yeah, this just keeps inverting the one value, and it keeps oscillating. Yeah, so that's why that kind of thing is unstable. In the two latch designs, there is no unstable state. There's the possibility for metastable state, but that's not something that our analysis will show you. Yeah, mm-hmm. So we might ask you to identify the stable states, or we might ask you to identify which states oscillate or things like that. Yeah. No, no, no, you won't have to analyze the oscillator, but you might have to identify which states might oscillate. Right, so we don't use SR latches or R bar S bar latches. We don't use the two states where you both try to set and reset at the same time. So we can build extra logic around that so as not to use those states. If you had something that had an oscillating set of inputs, you could build around it so as not to use that particular input combination. And these kind of things are not really that useful in practice, but they let you think about, well, how do these things work and identify oscillation. So we might ask you that kind of question. But we won't ask you to tell us what happens after a certain amount of time with oscillations, for example, because the detailed timing questions are beyond the course. But knowing that it'll oscillate, you should be able to do. Anything else on this one? All right. Okay, so here is our list. So we have decoders, timing diagrams, analyzing sequential feedback circuits. So implementing functions with MUXes. Oh, and so I guess we did have MUXes on there. Okay, so the general question I remember was how to implement a function with a MUX. So let's say that you have some function f of a, b, and c. Okay, so there's the truth table. So f will have some values. If I want to implement this with a 4-to-1 MUX, then, for example, I can put in a and b. So let's call those s1 and s0. And I want this output to be f. So the way I want you to think about this is, well, if a is 0 and b is 0, then I can simplify my truth table, right? So if a is 0 and b is 0, I'm going to pick the 0 input of the MUX, and I'm going to forward that wire to the output f. But if a is 0 and b is 0, the only thing I need to look at is this part of the truth table right here. That needs to go into this input here. And if a is 0 and b is 1, similarly, that needs to go there. And this part, where this is going to maybe get a little messy, needs to go here. And this part needs to go there. But really, all you need to do is figure out, well, for these four little mini truth tables, what functions do I need? Clearly, they're only functions of c. But if I implement those four functions, and I put those four functions in as my four MUX values, that MUX will put together these four pieces of my bigger truth table into one big truth table. Right? So let me fill in some bits, and then we can figure out what functions to put there. Actually, it's only one bit input, right? How many functions are there again? How many different functions do I have to pick from? There are four, right? So let's put them all. Here's one. Here's another. Here's another. Here's another. So what goes into the – what function is this? It's a zero. What's this? What's this? Not c. What's that? Okay. So if I want that particular f, then up here, let's see, you said zero. What is this one again? c. Not c. 1. So I think there was something in the homework about what if I gave you one MUX and one inverter? This input two is where you would use that one inverter. If you have a function of four variables and you want to implement it with a four-to-one MUX, then you also need a little bit of luck. Oh, was it? So I've asked that question on homework, but of the form of can you do it and if not, prove that you can't. And I think XOR is – if I remember correctly, XOR suffices to show that you can't do it, but I'd have to think about it a little more. Yeah, and generally you won't be able to. You have four values left based on two variables, and so generally you won't necessarily be able to do it. You have a little bit of freedom in how you break up this truth table, right? So I just picked B and C. You can pick any two, right? So you've got three different choices here. With four variables, you have six different choices, right? So maybe one of those six choices you could actually implement, whereas the other five choices maybe you can't. So you need to do a fair bit of thinking before you decide it's impossible to do this function. Whereas the reason I'm thinking XOR is because XOR is symmetric under that set of choices, right? So you just show that you can't do one of them and then you're done. Really? Someone asked that on the exam? That's kind of mean. Right? Yeah, so bit-sliced adder, if you know the bits, plug it in. Yeah, wasn't that one on the homework? Okay. So maybe in the interest of time, I'll skip that one because you guys have homework solutions, right? Yeah. Anything else on this? Okay. All right. So let's go back to our list. And we have just done this one. So MOSFETs and networks for gates. So let's take a look. I think Mohamed, you asked this. Did you want to go over n-type, p-type functionality or just the networks? Okay. Yeah, yeah. All right. Okay. So generally, I mentioned this in class, but the n-type and p-type are duals. So we can read these off just as functions. The reason they need to be duals is so that we guarantee there's no shorts. So at least in a gate that will always produce either a 0 or a 1, they will be dual networks. So let's talk about why. So if F is equal to some function of uncomplemented literals, then primed. So why do I say uncomplemented literals? Remember that the n-type MOSFET, what we use it for is to connect to ground. So either it's directly to ground or it's through some other n-type MOSFETs going to ground. The reason is that in order for this thing to turn on, we need a voltage between the input and this side. And so by connecting this side of the circuit to ground, we guarantee that this thing will actually stay on until it brings the other side down to ground. If we try to use this connecting it to VDD, then the transistor will actually turn itself off before it pulls the output up to high voltage. So we only use n-types to connect to ground. What that means is that if we're feeding our input variables into the n-types, well, that means in our function, they will not be complemented. So whatever we built here, unless we've got inverters in front of it, whatever we built here will be our uncomplemented literals. And then if that function holds, output will have a path down to ground, which means that f, the function, is then complemented. So the kind of things we can build would be the ones we looked at. So if you want an inverter, you would just put one of these. So if this is your output, for example, and this was, say, f, then this would be f equals a prime. You could put more than one. So you could say, OK, let me do two of them. And this would be f equals a or b prime. Because here, if I turn on, sorry, I left my connection out there for b. But if I turn on a, well, then f has a path to ground. If I turn on b, f has a path to ground. So either a or b, f has a path to ground. In that case, f equals zero. Did I do that right? Yeah. Yes. So let me get to the p-type. So I just want to make sure people understand the relationship here. So the way we make constructs here is and constructs, down here, which would look like this. So this would be f equals a and b complemented. Because in order to get to ground, we have to turn on a and turn on b. But in all of them, they're uncomplemented literals. So what about the p-type stuff? So the p-type stuff, f is going to be some function of only complemented literals. And why is that? Well, for a p-type, remember that we're connecting it to high voltage. And so if we connect a p-type to high voltage, that means that it can actually, it's looking for a voltage from the side on the right, those two terminals, the source and the drain, to the gate. And so by connecting this to high voltage, that means the transistor will stay on until it pulls the other terminal up to high voltage. And so that transistor will turn on when a equals zero. And so that's why in our function written from the top network, all of our literals will be complemented. So that one I've drawn with just the one p-type is, of course, the inverter. And so in that case, we have f equals a prime, which is the same here and here, these two. And if I want to draw the complement of this one, then I would draw it as this way. And then if I were to derive that, I would get f equals a prime b prime. So if I derive that from the top network, I get f equals a prime and b prime. And that gives me f. If I derive it from the bottom network, I get f equals a or b value complement. And if you look at those two expressions and apply generalized De Morgan's law, you see that they're equal. So this one is equal to that one by De Morgan's law. So I can do the same thing for the other gate. But more generally, these two expressions need to be equal. So the p-type expression and the n-type expression must be equal. So if I write the n-type expression, remember, I get some uncomplemented literals with a prime on the end. If I then apply generalized De Morgan's and I push that prime through all the way down to the literal level, then I've swapped all my ends with ors. And instead of uncomplemented literals, all of my literals will be complemented. So if you remember in class, we did that as a two-step process, which is to apply generalized De Morgan's, you take the dual. And then you apply, you replace, or maybe I should say swap, literals and uncomplemented literals. So in this case, this duality is in the structure of the network. And the swapping comes from the use of n-type and p-type. So the n-type on the bottom turn on when the input variable is high. The p-type on the top turn on when the input variable is low. And so in the gate structures, the dual structure is in the two networks. And so in order for these two equations to be equal, I need this relationship. But I can get that relationship algebraically by applying generalized De Morgan's. And again, the dual structure is inherent in the topology of the network. So parallel and serial are duals of one another. But you can generalize that to any function and use the principle of duality to get the structure. And then the swapping is because the n-type and p-type. Let me do an example. That will be specific to the problem, but I want to stick to this one until we finish it. All right, so let's do an example. So let's say that you have something like this on top, let's say. Sorry, let me start over. Okay, so what is F here? Yeah, so we have to have the top one on, right? So that's A0. And then what about that middle part? Yeah, B0 or C0. And then the bottom, D0, right? Okay, so we can just write it down. Now I claim you can just take the dual. So the dual here, remember how to take the dual? Swap and and or, swap zeros and ones. There's no zeros and ones, right? So we just swap and and or. So I'm going to change the ands to ors and change the or to and. What that'll give me is A. I'm going to leave off the complement. So A or B, C or D, right? And I'll put the complement outside. Okay, so this dual form gives us then the structure of the bottom network. So it says A or B and C or D. So the ors are represented as parallel structures. So there's A. There's B, C. There's D. And I claim that if you go fill in the 16 row truth table that you'll see that this is compatible. There's always exactly one path from out either to high voltage or down to ground. So all I did is I took the dual and then I built the dual structure down below. Yeah. Yes. Yeah, so generalized DeMorgan's, remember, you take the dual and then you flip all the literals and complemented literals, which you can see here at the top. I already did that by hand. Yeah, Daniel? The second expression is the complement of the dual because only because I added the prime at the end. The dual, technically the dual expression has all of the literals the same way. So the actual dual is this. The dual structure down there tells us the network structure. The bottom two expressions are equal. And they're also the two values. So if you read this one off, you'll get the bottom expression. So of course you want those to be equal. Yeah. The bottom two are exactly the same. They're both equal. And if you read the top network, that's where we got the middle one. And the bottom one is what you would get if you read this one off. So the prime comes from using the n-type and the dual nature comes from construction of the dual networks. You get one cheat sheet just like last time. What did the person who wanted to talk about DeMorgan's Law, I mean I would write them down if it's hard to remember them, I guess. Which is those. Yeah, and we also, I'm sorry, we actually do give you the properties list. So these will be there. So you don't even need to read it. Write it on your cheat sheet. Very little. So I mean you need to know how to do K-maps and read SOP, POS, stuff like that. But actually manipulating Boolean algebra is not a skill that's useful these days. Yeah. Yeah. So two things about that. Perfect induction is the fancy name for brute force. So it means write a truth table, fill it in, 0, 0, 0, 0, 1, 1. Good. Yeah, that's perfect induction. Yeah, I don't know who made that name up. Do you need to know how to simplify Boolean expressions with Boolean identities? No, not for our class. Yeah, Mohamed? On the p-types, yeah, because remember that they're always connected to high voltage. The p-types are always used in the upper half of the network. And basically if the input is low, then they'll turn on. So you can always put an inverter, but I mean then logically that's an inverter. Yeah, yeah. So just think of the way the current has to flow. So if you can get a wire, if they're in series, that's an AND. If they're in parallel, that's an OR. Yeah. In this setting. I'm sorry? Sorry, I still can't hear you. Yeah. Taking the dual and then swapping literals and complement is generalized to Morgan's law. So if you want to take the complement of a big nasty expression, you can just take the dual and then swap also literals and complement literals, and that'll be the complement of the whole thing. Okay. Bring any other questions down here. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay.\"},\n",
       " {'ECE120-2016-11-16-LEC-34-slides.mp4': \" Okay. So I think it's three. Hope everyone enjoyed the midterm. Sorry, I didn't ask for your help. Yeah, mine were problems four and five. So you've got fun with multiple choice and fun with LC3. So, all right. So I want to finish up. So we'll do a little more review since it's been, I guess, five days since we looked at this program. So we'll go through the last few slides that we saw and then finish up the coding of the letter frequency code. So that'll be our last program. I'm not even going to change it into bits for you. You can find the bits on the website if you really want to see the bits. But that program technically we sort of did in binary. Then we're going to talk about assembly language and then what you can do in assembly language and things like that. And I'll talk about assemblers and how they work. That may take all of today. I have this think-pair-share exercise. Originally I had it above the assemblers, but then I thought, really, do I want to see binary code? Probably not. I'm tired of it. So I'll put it down here. And if we get to it, we'll do it in assembly and that'll be slightly easier. All right. So this was the problem, just to remind you what we're trying to solve. So we said, OK, what if we have a string? String is a bunch of ASCII characters terminated by a null. This is a zero in ASCII. So we count the occurrences of each letter regardless of case and count the number of alphabetic characters. And then we decided on this high-level algorithm where we go initialize 27 bins to zero for a histogram. And then we go through the string once. We look at each character in the string and figure out, well, is it a letter, uppercase or lowercase, or is it a not letter? And we go find the right bin and increment it. So we did a breakdown. I didn't keep the flowchart around or anything like that. It's available online if you want to see it. So we had decided, well, the string will stick at 4,000 hex. The start of our code will be 3,000 hex. And then the histogram will run from 3,100 hex up to 3,11a. This is 1a is 26. So 1 to 26, a to z. And then the non-alpha bin at 3,100. And then we had these registers assigned during the counting part of the code. So r0 has a pointer to the histogram, meaning this value. r1 is a string pointer that goes from character to character in the string, starts at 4,000, goes until we find the end of the string. And that lets us load individual memory elements, the characters in the string, into r2. r3, r4, and r5, you remember we needed to identify the boundaries in the ASCII table where the letters start and end. And so we had ASCII constants in here that we've mentioned as we went through what they are. And then we had r6 as a temporary register. And so those were our register assignments. Those you would put in comments. So if you look at either of the versions in the website, you'll see this is all listed out in comments. So you don't have to try to remember it. And this is where we had gotten to. We had actually done a little bit more of this. But this was our last comparison to say, well, is the character we're looking at, which we had converted or were about to convert into a number from 1 to 26 for the lowercase letters, is that character greater than capital Z? So is it a letter or not? I guess actually we'd already converted it. So we'd ruled out these three, and we're just trying to do this last separation. So we're trying to compare with lowercase z. So we wanted to subtract lowercase z. We had already subtracted this back quote, so hex 60. And we also had a back quote minus lowercase z in r4 already, because it's the same as at sign minus uppercase Z. Both are negative 26, because there are 26 letters regardless of case, of course. And then we're going to throw away the results stored in r6 so that we can keep the number of 1 through 26 for the lowercase letters, because that was what our increment alphabetic bin assumed we had in r2 to find the right alphabetic bin. So we wrote that instruction. We said, well, take what's in r2, add it to the r4, which was back quote minus little z, add those together, throw away the answer, but set the condition codes. So this is like calculating original character minus little z, throwing that answer into r6. So under what conditions, then, did we have a lowercase letter? So if I subtract little z and my original character value was, say, exactly equal to little z, that'll give me a 0. And if it's anything smaller, what will that give me? Negative, right? And then what if it's over in this green region? Positive. Good. So a lowercase letter, then, would be the negative in the 0 case, right? So then we can branch on negative or 0 to increment the letters histogram bins, but we've already got that code, right? So we're just going to branch to it. Now one thing we talked about, but I want to make sure people all understand, when we write that code, we have to make sure that we write it in a way that it can be used for the uppercase and the lowercase letters independently. And so the assumptions we made with that code were the assumptions of the registries we already had. So we made use of the fact that r0 held the histogram pointer, but we also assumed that r2 had a number from 1 to 26, which corresponded to the letter that was read from the string. So for the uppercase character, uppercase A, capital A was a 1, capital B was a 2, and so forth. For the lowercase character, we've got exactly the same relationship, but with the lowercase characters. So at this point in our code, if we had an uppercase T, sorry, a lowercase T in the string, that happens to be letter number 20. So r2 will have the number 20 coded as 2's complement. So the bits for the number 20 and 2's complement. So then we can just branch to that code, because we designed it to be reused that way. So the branch condition then is what? We just derived it, right? Negative or 0, right? And then we could figure this offset off, because it's up in the code we've already written, but I'm too lazy to put all the code on one slide. So instead, we'll just leave it blank. We could go do our fun counting exercise on paper. All right, so here's what we have left. So if that branch is not taken, we know that this is not a letter. But we've also written that code, right? So what can we do? Just branch to it, right? In this case, we could say BRP. The condition codes are still set, but just for a force of habit, we'll just use an unconditional branch, because we always want to go there. We happen to know what the condition codes are, but it doesn't really matter. We don't need to use them if we don't want to. We know we always want to go. So we'll do an unconditional branch, and again, we could figure out this offset, because it's code we've already written, but I'm going to leave it blank for now. All right, so those were the five regions. So now we're out of our review. So those are the five regions of the ASCII table. We've classified and counted all of the letters, all of the non-letters. Now we just need to go back and incur what? I'm sorry, we finished this box. Now we just need to point to the next character. So remember, the next character is in what register? Remember R1? So how do I point to the next character? Remember, it's just in consecutive memory locations, right? So what LC3 instruction? Just an add, right? And what arguments? I didn't ask this on the midterm, so now no one remembers. R1, R1, 1. OK. I'm tired after the midterm. All right, so now we're done with counting, right? And now we can actually just branch back to the top of the loop and get ready to look at the next character. The pointer to the next character is all ready, so we can just go to the top of the loop, load it into R2, and start again. So in that case, you do another unconditional branch. And again, you could fill that instruction in, but I don't want to. So we do need a halt. So at the end of the program, when we're done, we find the null. We need a halt somewhere in our code, right? Now, we would branch to that from the start of the program where we saw the null character down to here to stop the LC3. We do need to have that. We also need some data. So here was the number of histogram bins, a negative at sign. I just wrote these out as characters. We'd have to, of course, code them as bits. But I just wanted to remind you the values, logically. And then this 4,000 was a place we stored the pointer to the beginning of the string. So we need all those data in memory as part of our program. So again, the full program is available online. We're about to talk about assembly. There's both a binary version and assembly version. It's the same code, but one is in assembly, one is in bits. So please do take a look at those, play with them, make sure you think they're right and that you understand them. And if you use it, actually, the assembly example has an example string coded into it, which is not at 4,000. But it'll work just out of the website. You mean why not put it at the beginning of the code? It doesn't matter that much. Yeah, it really doesn't matter that much. I think a lot of... Doesn't matter that much to me. There are people, including a number of companies, that have a strong dislike for having any kind of terminal flow control hidden in the middle of your code. And that's actually, I have a dislike for that, too, for real terminal flow control. Because then someone who's trying to understand your code might not realize that this thing can stop right in the middle and I have to understand that. So they're trying to look at it as the whole thing. If the thing is very big, it might take them a while to realize, or they might just fail to realize it can stop in the middle. And so people tend to put the end at the end. And some companies will tell you, if you write code that doesn't have that, we're going to get mad at you and tell you to rewrite it. Yeah, no, not so much. It's really just for code clarity, code readability issues. Yeah, yeah, it's not parallel processing issues. Yeah, it's just a question of where you have to look to know which part of your code is going to run. Right? So is the bottom of your code going to run or not? Do I need to read the middle in order to answer that question? That's what the question is. All right, so leave the rest for you, all the counting, all the bits, all the fun, really. Okay, so now we can move on and talk about assembly language. Everyone's really quiet today. Were you happy with the midterm? Yeah, okay. I know, I'm sorry, I didn't ask for help. I'll do it again on the final. All right, so let's review our programming process. So step one, we have to figure out all the instructions, right? You have to sit there and think and think and think, figure out the instruction sequence. Step two, the fun part, map the instructions and the data to memory addresses, right? We started at 3,000, so we go to the top and we write 3,000, 3,001, 3,002. It's really a lot of fun. Step three, take those addresses and calculate the offsets, right? Often by counting. I mean, what more fun could you have with programming? And you fill in the relative offsets as bits, right? You can translate those counts into bits and then fill them in. So step one is hard, right? We're not going to get a computer to help us. So I don't know, maybe some of you get bored. I really enjoy the counting myself. When people get bored, right, they start making stupid mistakes, right? So if I were to tell you, okay, you know, homework 12, let's just change it up. Homework 12 is going to be a go by hand and actually count the letter A's in Pat and Patel. Probably everyone would get it wrong, right? Even if you tried, you would get it wrong, right? You're like, oh, page 300. Okay. So you get bored with that stuff. So instead, since it's so easy, well, we're not going to be able to get computers to do this part for us, right? Computers are dumb. They're not going to be able to do that. But this stuff down here that's basically just counting, I mean, surely a computer can count, right, or subtract or whatever, right? So let's figure out, could we get a computer to do these parts for us and just leave this part for ourselves, for the humans? So here's a typical real programming process. So the programmer actually will write something in a high-level language, right? So something like C or Java, JavaScript, whatever. Well, maybe not whatever, because then I'm going to put a compiler on that. Not all of those are compilable languages. But you would then take that language, that program in that high-level language and feed that into a compiler, and that would actually produce assembly code. Okay. So when you run GCC on your C code, in fact, that produces assembly code internally, and then it runs the assembler on that assembly code. So that's the next step. The compiler will do that for you by default, but the real program, the compiler, is simply calling another program to do that. Yeah, Eric? No, usually it will detect any inability to translate to assembly code and not generate the assembly code. Very rarely, there would be a bug in the compiler if it generated bad assembly. So the compiler is designed to take this program and produce this program. And if it's unable to do that, it should tell you that. It should tell you it's unable to do that translation, not produce broken assembly. So if it produces broken assembly, that's a bug in the compiler, which sometimes they do, right? Compilers are not bug-free any more than any other piece of software is bug-free. So you get your assembly code out of your compiler, and then you feed that into an assembler, and your assembler produces your binary program, which then, in order to get pulled into memory on the computer, usually is pulled in by what's called a loader program, takes your binary off the disk, puts it in memory. Once it's in memory, the operating system can transfer control to your program and let it execute. So this is your typical programming process. Yes, there's also a symbol table, which I didn't draw in this process. I mean, in the starred notes in section one of the class, there's a more complete diagram. This is a simplified diagram. So this is kind of the core that we've looked at so far. All right, so down here, this is where you did labs 10 and 11, right? So you said, OK, I'm going to go write some binary. I'll write zeros and ones. This is today. We're going to talk about what assembly code looks like and how an assembler works. And then labs 12 through 14, one of which I know you're doing tomorrow, but the next few weeks also, you'll be writing bigger chunks of LC3 assembly code. So you'll make use of what we're seeing today and understand how it works to replace you, basically, in steps two and three, right? So you don't have to do the counting anymore. And then in EC220, you'll actually start writing substantially more C code. So you'll actually do a little bit more. I should have said there's some EC220 in here also. So the very first few weeks of the class, you'll do more LC3 assembly programming. But then after that, you'll do purely C programming. If you take 391, you will have to learn x86, because in order to write an operating system, you have to make use of some assembly code. But you won't have to write binary for x86. If you really enjoy pain, you can. I don't recommend it. All right, so here's assembly code. It's a line-by-line format. So the assembler is just going to look at one line at a time. And the line format looks like this. So there's a label, an opcode, operands, a semicolon before a comment. These pieces here, the label and the comment are optional. You can also have blank lines. So you can leave blank lines. You can put a label by itself on a blank line, a comment by itself on a blank line, those two together on a blank line. With any instruction, you will have an opcode and operands. And then you can put these extra optional things as well. So the label is a symbolic name for a memory location. So we'll come back to that a few times. But it's an ability for you to make up a name using letters and underscores and numbers and say, OK, I want to name this particular memory location. And then I want to be able to use that name in order to reference it, say, with a branch or with a load. So instead of having to calculate offsets and know where things are, the assembler can do all those things for you by your being able to give names to memory locations. The opcode, then, is a mnemonic. So instead of writing 0001, now you can write add. So it'll be a lot easier to write your code because you won't have to remember the opcodes. You mean data? Yeah. So normally, because of the LC3 in particular, you would put it at the end because it starts your PC at the start. In other assemblers, you could do it either way. But typically, people will put the code first and then the data down at the bottom. If you look at the output of a compiler, sometimes it will associate some data with functions, and so they'll interleave them. But typically, when it's assembled, those two will be separated into different regions of memory. I see. I see. Yeah. OK. So here are a couple of examples. Do you understand that one? So there's a label over there. There's an opcode. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's an opcode, operand, and there's a comment. So what does that do? Yeah, it's infinite loop. Mohamed? OK. You were just going to answer. OK. OK. Yeah. So this is just an infinite loop, right? So how about this one? What do you think this does? Yeah, it does a load of what? Yeah, whatever bits this branch is, those bits get loaded into R3. This label here references this memory location. So this says, well, take the bits in this memory location and pull them into R3. Now, if you really put it in this order, this one would never run, right? So labels name memory locations. So there's a name of a memory location. It's mentioned over here. This is the one that defines it. These are uses in the operand cases. And so you can use it as a target for your branch. You can use it as the offset of your load instruction or your LEA or whatever. So assembly language also supports a couple of things called directives and pseudo ops. Even in the book, they treat these as the same thing. I treat them slightly differently, but most of the world doesn't. So don't worry too much if you don't learn my meanings. But I'll use them this way. So directives are basically they provide information to the assembler. So we'll look at a bunch of examples. But they tell the assembler, well, here's something that I want you need to know in order to assemble my code. And that's provided by the programmer, of course. And pseudo ops are basically just shortcut notation. So there's something you want to do. And so rather than typing a bunch of bits or whatever, there's a shorter way to do it just to make it easier to write assembly code. So we call those pseudo ops. So let me give you examples. So first, we'll do directives. So the.orig directive, all of the directives in pseudo ops start with a period. So.orig, for origin. This tells the assembler, where do you want to start your program? So instead of putting one address like you do in binary, you put a.orig directive at the start of your file. You can put comments above it, but you can't put any instructions above it. And there can only be one of these. So you say, well, here's the start of my program, for example, 3,000 hex. And you have to do that once, again, before any actual bits, any lines that would generate bits. At the end of your program, you put a.end. So second directive,.end. This one you should be careful with, because the assembler, when it sees it, it says, OK, I'm done. You told me I'm done, so I'm done. You put other stuff after it, it's done. It doesn't read it. So I mean, here's an example where you really wouldn't want to put this in the middle. This is not the same as halt. If you put.end in the middle of your code, half your program simply will not be assembled. And you can look at it as much as you want, but nothing you write there will be flagged as an error. You can put the multiply instruction down there. It won't get it. Nothing will happen. Yeah, so the assembler will stop reading your code. It's not the same as a halt. So if you don't put a halt, you just say.end, the LC3 will keep running through whatever bits are in the memory after your program. It'll keep going. So you have to tell the LC3 to halt by putting a halt trap. Don't expect.end to do that. Yeah. OK, so let me stop you before you finish your question. So if you branch over the end, so the assembler is just taking your assembly code and producing bits. And so you can certainly say branch 100 memory locations forward and not write that part of memory, not write that many more instructions and end your assembly file, at which point that program is going to branch off into some other part of memory. If you put bits there, that's great. Then it'll do that. That would have to be in a separate file that you would load separately into the simulator. But if you put a.end, it just stops reading your file. So if you've only put five more instructions, it will not write anything in that 100th memory location. Even if you put after the.end, even if you put 500 more instruction-like lines, it'll ignore those, even if they're valid. Yeah. Yeah, I mean, this is really just telling the assembler this is the end of the file. And you really shouldn't try to use it in interesting ways. It simply stops reading the file. Yeah. I mean, LC3, because it's an educational architecture, there's really not much support for having different chunks go in different parts of memory. You can do it by hand in the simulator. You can say, oh, load that file. Now load this file. Now load that file. But it changes the PC every time to the start of whichever file was loaded last. So it's really kind of a pain to do things that way. And it's not meant to be used that way. Most real assemblers, you would actually have another step in the process that I didn't show you called linking, where you would take multiple object files and then build them into a binary. That's in the more detailed version if you want to see it. I'm not quite sure what you mean. No. No, the problem is just that the software infrastructure doesn't, we don't have a file format that allows you to specify multiple non-contiguous regions of memory. Yeah, it's purely no one bothered to build it. It's all software. Software support. It's not there. Okay. All right. Third and last directive, blank words. Blank word directive says, okay, skip some memory for me. Leave them blank. Now, you know there are no such things as blanks. They're bits, right? What are those bits? You should think of them as bits. What they really will be will be probably zeros. In fact, they will be zeros because they'll go in the binary file and they'll go as zeros. So that's an unfortunate thing. You should think of them as not being filled with zeros because some assemblers will not put zeros there. And so if you use those other assemblers, you could get burned by this, right, if you assume they're zeros. So when you say something is blank, you should assume that it needs to be initialized if you want it to be zeros. So what can we use that for? Well, remember, for example, when we let a user type a number at the keyboard, we wanted to put that number in memory. We just need a place to put it, right? We don't need that place to be initialized to any value. We're going to overwrite those bits anyway. So for that, we could use one blank word, make that memory location with a blank word instruction or blank word directive rather, and then store the answer that they typed into that memory location. So that's the kind of thing for which we'd use the blank word directive. So some pseudo ops. So what if instead you said, well, sometimes I want to put certain bits, right? So when we did that typing in a number code, we wanted negative ASCII character zero, right? Because we wanted to use that to convert from digit zero to number zero and to complement digit one to number one and so forth. So what we can use in that case is this pseudo op called dot fill. And that'll let us write one specific 16-bit value. So for example, we can write dot fill hex FFD zero, and that'll write these bits FFD zero into the next memory location for us. So if we put that directive in our assembly, we will get one memory location filled with FFD zero. So if you want other numbers, you can put dot fill whatever. Ah, so remember that the assembler is just looking line by line. You tell it where to start, memory location 3000. And as it goes line by line and sees instructions, it just puts them into consecutive memory locations. So we'll look at that process a little later. But whatever the current memory location is, when it sees this pseudo op, it will drop those bits into place. And that's all. Yeah? Did I say, I'm sorry. Okay, I screwed up. Yeah, you see, remember I mentioned cut and paste bugs? It's a cut and paste bug. I cut and paste my slide and forgot to fix it. Sorry. Thank you. I'm sorry. By next, I just mean whatever it's currently writing, right? So the assembler is just going to generate a bunch of bits, right? So whatever place it is, when it sees this pseudo op, it will simply stick those bits in. So that's what I meant by next. Yeah. Yeah, so bear in mind, I'm the only one who uses this as a difference. But pseudo ops are just shortcuts for actually generating bits of some sort, right? Whereas directives just tell the assembler something. They don't generate bits. So the blank word is supposed to just skip some memory locations. It's not technically supposed to generate anything for them. The easy way to do that is to generate zeros, which is why that's what it does in practice. But conceptually, it's just supposed to skip. Yeah. So it doesn't necessarily correspond to an instruction. This for example, these bits are not an instruction, right? This is a trap op code, but a trap instruction has to have zeros here. So it doesn't need to correspond to an instruction. It can be any bits for fill. And so when you have pseudo ops, some of them will correspond one to one with instructions. For example, I already sort of mentioned the halt pseudo op, right? And halt will correspond to trap 25, one trap 25 instruction. So some of them do correspond one to one. They're just shortcut notation, that one in the sense that you no longer need to remember 25 hex when you want to halt, you can just say halt. Okay, so I leave this one too. Look at that. I left them all. Okay, sorry. Cutting case errors. String z pseudo op tells the assembler to write a null terminated ASCII string. So for example, you could write the string hello. And what that would do, you can also include things like backslash n for carriage returns, et cetera, and it will turn those into carriage return characters for you. But it takes these characters one at a time out of the string and store them in consecutive memory locations. So each seven bit ASCII character will get zero extended to 16 bits stored in one consecutive memory location. And then we'll put one more memory location filled with a null, which will be a 16 bit zero after it's zero extended. But ASCII null is seven bits too. All right, so don't forget strings, he always writes the null. So the number of characters is number of characters plus one. So for example, how many memory locations? One, seven. Seven, right? So there's three letters in the word, three periods, and then one more for the null is seven. How about this one? Maybe five, right? Three for the letters, one for the question mark, one for the null. How about this one? Good, okay. Occasionally, we ask you to calculate things like this, so you should know how to do it. So the LC3 assembler also supports pseudo ops, they got it right here, no cut and paste here, for trap instruction. So the three that you know are getC, which is trap 20 hex, out, which is trap 21 hex, and halt, which is trap 25 hex. So you don't need to remember those numbers anymore, you can just use them. Oh, yeah. Of course you can have a computer do that. But that wasn't what I wanted you to do for your homework. So now I can assign it, right? Okay. Yes. Good point. All right. So what's the advantage? Why do you want to use this stuff? So let's pretend that we're going to write our letter frequency program with assembly now. You can actually get this code, but I sort of want to just pretend that we're writing it to sort of highlight how much easier it is as you write it. So let's get started. So the first thing is we'll start our code at 3000. So this is not really that significantly easier, right? Before you just had to write 3000 as binary. Now you can write it as hex, big deal. But you know, maybe I don't know if the initialization stuff, I just haven't wrapped my mind around it yet. Let me just leave some comments in the code. It doesn't matter because the assembler is going to do all the counting of how long that is, right? So I don't care. Even if I have branches that cross over this stuff, for example, from my initialization code, I have to load the number of bins for my data at the end. It doesn't matter how far away that is, the assembler will figure it out for me. And if I change the answer by fixing bugs in the other code, it'll figure it out again. And I don't have to count. I don't have to do anything. So I can just come back later to write this initialization code. Yeah. Yeah. So the question is, are you still limited? Well, there are LC3 instructions, right? So the assembler doesn't change the LC3 ISA. It can only produce LC3 instructions. And so if somehow you get to the point where you tell the assembler, produce something that doesn't work as an LC3 instruction, what do you think it'll do? We'll come back to that one. I'll let you answer it later. Okay. So let's write the counting part. So here's our counting part. Remember the first thing we did is we read the first character, or rather the character pointed to by the string pointer into R2. So it was offset zero. We used an LDR. Remember we need to come back to that eventually. So we can just make up a name. So just make up a name before we write any more code. I'll call it count loop. Okay. So if we find a null, we need to go to the end of the string. So should I leave this blank and come back and count it later? Let's just make up a name. I can just make up names now. It's kind of nice. I can just go down and write that code, in fact. I can just go write that code. It doesn't matter how many instructions it's going to take me to write the rest, because the assembler will figure it out. And if I get it wrong and I have to fix a bug, the assembler will figure it out again. And I just don't even have to care. So as long as I make up a name here and I use the same name down here, it's fine. So much easier. All right. So label represents an address. So I do want to make sure you understand this. So this instruction, this LDR, is at this address. What is this address? The assembler is responsible for figuring that out. We don't need to care. It's an address. It's some address in memory. The assembler will figure it out, and the assembler will make use of it. Same thing here. This label is at some address in memory. When the assembler is going to generate this instruction, it needs to know how far is this away. So it can calculate an offset. But that's its job, not our job. Yeah, it's sort of similar to C identifiers, except it's not case sensitive. So you can, you can, I don't remember if you can start with an underscore. So start with a letter, not a number. I think you can use letters, numbers, and underscores. But I think you probably want to start with the letter. That's right. That's right. Yeah, so done represents an address. But here we need an address to do the offset calculation. So normally if it were us, the humans, calculating it, the way to do that is say, well, what address is BRZ? What will the PC be? Well, it'll be BRZ's address plus one. What address is this at done? Then I would subtract or count one way or the other to get done's address minus PC address, which is branch address plus one. And then get that offset and then put that into the instruction. Okay, yeah. Possibly. I'll show you how. Yeah, the question was, will you ever be asked to make a symbol table? Possibly, yeah. I mean, look, the assembler's not doing anything harder than you've done 20 times in your head as we went through code, right? So it's really not hard. All right, so what's next? We wanted to compare with capital A so we can write some code. This was the code we wrote to do that. Again, we have a branch. This was in the case where it was capital A or bigger. Well, again, just make up a name. And then we can put that code down there, or we can just wait till later to write it. It doesn't matter. As long as before we invoke the assembler, we've written this label somewhere, that's good enough. Okay, so once we find out, once we do the branch, sorry, I probably could have deleted that. Once we do the branch, we're going to reuse this code. We may not realize that. We didn't say that the first time we were writing the code. We could always come back and add this label. But that was our code to increment the non-alpha bin, right? So we had this instruction to read the non-alpha bin, add one to it, write it back. And then we had to branch. And again, just make up a name. Every time we need to go somewhere, we want to just make up a name. It's good enough. We do have to make sure the names match. So when we get around to writing the other piece of code, we have to make sure that the names are identical. Otherwise, the assembler is not going to figure it out for us. But what about data? So after the code, we had to write things like, well, the number of bins was 27. And that sign is this. The string start. Oh, look at this thing. What does that mean? So this thing here that says fill string. Yeah, so this is an address, right? So here's the address down here. I don't want to need to know. I just want the address of this string in memory to be stored here so that I can load it into a register without an LEA, with an LD. So here's my histogram. I made the histogram be just part of my program now, just a bunch of blank words, place to store my histogram. So now that we have an assembler, this kind of stuff is easy. Before if I said, oh, well, I want to put my histogram at 3138. Oops, my program's too long. I clobbered it. Now I've got to go change it. Now I've got to go change a bunch of other stuff. It's such a pain. Right here, I let the assembler figure it out. It doesn't matter. I've got a name for it. Some other piece of code wants to use my histogram, use the name hist. It'll find it. OK. Yeah. A blank word just skips 27 memory locations. Well, whatever you ask. So here we ask for 27. So remember, we needed 27 bins for a histogram. So this says, leave me 27 memory locations. I'm going to do something with them. The first one is named hist. The others are hist plus 1, hist plus 2, hist plus 3. I think it was the limit, hist plus. Yes. A string would be the address hist plus 27. That's right. Yeah. Yeah. And that's something you should know how to do is figure out, well, how many memory locations will each sudo op or instruction take? So this one, for example, would take 1, 2, 3, 4, 5, 6, 7, 8, 9, one for the null. And so if you had another label under this one, it would be string plus 9. Yeah. Yeah. Yeah. So I'm going to do something with this. It is certainly possible. But if you put that, that would be blank words equal to the address here, which would probably be a fairly large number of blank words. I mean, as long as it's, yeah. Oh, you mean a copy of this value? Yeah, no, there's no easy way. Yeah, no easy way in this LC3 assembly. All right. So how do assemblers work? Same way we do for this purpose. We can do other things. The assembler just does this one. Yeah, so you can write code to do it. But I believe Daniel's question was, can you write the code in such a way that they're both initialized to the same value without copying the value in your code? And I don't think there's an easy way to do that. Okay, so step one, figure out the instruction sequence. Step two, map instructions and data. So this will be the first pass of the assembler. The way the assembler is going to work is it's going to look at the program twice. The first time, what it's going to do is just go line by line and say, well, this instruction is at this memory address. Next instruction is at that memory address plus 1, and so forth. Just write the addresses next to it. Then it'll fill in the offsets. How will it do that? Well, it'll look at the addresses it wrote next to the bits, going through the program again, the assembly program again, and calculate all the offsets and write the bits of the instructions. So a two-step process. So here is the first part of the code. I chopped up the comments explaining things, and then there's a lot more code underneath. But this is the first part of the assembly version of the letter frequency code. So you can see we can start counting. This would be the first pass. So you can see up here it says orage.3000, right, dot orage 3000. So we'll start there. And the assembler will say, OK, here's an LEA. Well, that LEA is at 3000. OK, good. Here's the next instruction down here. This is just a comment. Next instruction is at 3001. Here's the next instruction. Guess where? Yeah. You guys are good at the counting. Are you sure you want an assembler? All right, 3003, right? So keep going. When we get down here, we see there's a label. So whatever the current count is, right, the place this instruction would go, that's the value of that label. OK, so hfloop, this was histogram fill loop, is at 3004. So what the assembler is going to do in its first pass, in addition to all this counting, is build a table called a symbol table. So here's the symbol table, I left some of it out because it's a little big for this program. Here's a symbol table for that code, right? So you can see hfloop's at 3004, countloop's at 3000c, non-alpha, 3010, blah, blah, blah, blah, blah. Histogram's down here at 3028. And that should be plus 27 to string, 27 decimal, which is what, 1D? Did I get it wrong? Yeah, yeah, these are in hex. So yeah, 1D maybe. Anyway, OK, so that's our symbol table. So in the second pass, what's the assembler going to do? Well, it's going to start counting again at the beginning, right? So I see the dot origin 3000, say OK, start at 3000. There's LEA, R0, hist. I say, wait a minute, what is hist? Well, let's go look it up. We have the symbol table from the first pass, right? So in the second pass, when it needs to generate the bits for this LEA, it's going to say, well, I've got to go look this symbol up in the symbol table. So where is hist? Ah, so it's down here, right? So 3028. So go back here. Hist is 3028. What's the PC when this LEA executes? 3001, right? So then what's the offset? X27, good. And that's it. Now we have enough. Now we can write the bits. Or rather, the assembler can write the bits, and we don't have to. Yay. OK, so what happens if the assembly file has a mistake? Oh. Yeah. Good luck. Yeah. So, Cassidy, really? I had you going with that one, really? All right, so yeah, you get to fix it, right? I mean, it can tell, yeah, this is not going to work. And it just says, error. And then you go fix it. So what kind of things can it detect? So in the first pass, it can tell if you put bad mnemonics. So if you get excited, and you say, multiply! No, sorry. LC3. Or bad operand. You say, I want to use R42. Or you say, I want to add 1,000. Right? No, out of range, sorry. Not going to work. What about labels? So is this code OK? This code should be OK, right? Just that this label that I want to go to is down here. So what? Right? Oh, it is a memory location. I don't have to have code there. It's OK. It's a memory location. This branch is forward. So in the first pass, when I get to this line, it's not in the symbol table. This label is not in the symbol table, because in the first pass, we haven't seen this line yet. So there's no label in the symbol table. So in the first pass, you can't say, oh, there's no such label, because maybe it's just down further. So you can't have that error. So it reads the file in order. You may not find it when you go look, if you look in the first pass. But that's OK. Right? Yeah, you're going to have a second pass. So in the first pass, you cannot detect undefined labels, because they might just be lower in the file, might be branching forward. What about this code? Ah, so, well, so then you're trying to make it do something smart. So, I mean, maybe these are maybe a little confusing, because I didn't put anything in between. So this probably, this should come up to the same address, right? You might think, oh, that's OK. But it's not OK. The computer's not that smart. Normally, if you have two definitions, those are going to be different addresses, right? Most often, they would be different addresses. And the LC3A and the assembler is not going to make a choice for you. So it'll just say, well, you've got multiply defined labels. So if, when you go to the symbol table, you find the symbol already there in the symbol table, that label appears twice, and it just generates an error. So how do you architect your things to get this? Usually not completely for all label types. There are local label types in some assemblers. Yeah, yeah, but not in LC3 assemblers. OK, so multiply defined labels, the last first pass error. All right, what about the second pass? What can go wrong? We saw one already, right? We decided we couldn't find, so find hist. Where's hist? Oh, it's not there. We had a typo, right? We got down to the bottom and wrote histogram instead of hist. Those are kind of similar, right? Won't the assembler just say, ah, you probably meant this. No. So it'll just make an error, right? So if the label's not defined, it'll find out in the second pass. It'll say, well, where is this label? Look in the symbol table. It's not there. So it's an error. There's nothing it can do. But what else might go wrong? Error. OK. You already asked about this, Emily. We've got offsets. Yeah. So what's wrong with this code? Yeah, this is just taken out of the middle. So imagine I put a.origin and a.end. Not a whole program, just a little piece of snippet of code from the middle. How about this? Bad, bad style. All right. So if I asked you to turn this into bits, what would you get? So yeah, bits. Very good. Good answer. Perhaps even involving 42 in hex. All right. So this LEA should not be a problem, right? Because PC is pointing here. And so the offset will be down to here. What about this stop? So that's 4200 plus 1, 4201 ahead. But PC points here. Only 4200 ahead. So you just put the offset 4200 into the branch. Yeah, you only get 9 bits in a branch, right? So is there such an instruction? There's not, right? So that's bad. So the LEA would need more than a 9-bit offset. Question? Yeah. Yeah. Yeah, so what you have to do is you have to use jump instead. And so you'll have to, I'm not sure I would call it elegant, but that's the only way to do it in LC3, which is to branch over a jump and then use a jump. You may have to load a register first. You might even have to put the data next to it if your data is very far away also. But load the stop address into a register and then jump to that register. So generally, but the assembler is not going to do that, right? That's rewriting your instruction sequence. I think they're in their habit. You could chain branches together to avoid using a jump, but I would recommend that you don't do that, that you use jumps instead. You never have to do that. Jump can go anywhere, sorry. No, this is a label, right? But the assembler can't figure out how to insert an offset that's too big into the instruction. The assembler does, and if the count is too big, too bad, right? It can't fix the problem for you. Here, it can do the counting, but the answer is 4200 hex for this branch. Sorry, this should say the branch, not the LEA. The LEA is fine. Yeah, so the branch offset is broken, right? The branch offset is going down to this stop label, and this is 4200 memory locations. So that would have to be an offset of 4200. You can't fit an offset of 4200 into 9 bits. Yeah? You could put the name like, don't do. I wouldn't be able to do. Or like, not do. Oh, no, there's no local labels in LC3 assembly. Okay, any other questions? I think we're slightly over time, so if you have a quick question. So I think it says label out of range or address out of range or something like that. Yeah, yeah. Okay, there's a summary. I'll leave that up. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay.\"},\n",
       " {'ECE120-2016-09-12-LEC-09-slides.mp4': \" to build logic gates. We may get to optimizing logic expressions. Otherwise, we'll start on Wednesday. I'm pretty sure we're not going to get to Boolean terminology. Someone pointed out that my factorial code also had a bug. So whoops. But also, Professor Verradin will guest lecture on Friday. I won't be here, so he will lecture in my place. I noticed, unfortunately, I didn't notice during the lecture, but the mic cut out very shortly after the start of the lecture on Friday. So unfortunately, there's no sound in the video. So sorry about that. If I find time, I'll try to re-record those in Personify and post them for you. But the slides are there, so you can look at those. So before we get started, I wanted to remind you that our first midterm is coming up real soon now, a week and a day, 7 to 8, 30 PM. Location, check the wiki. If you need to take the conflict, you need to sign up by today. So please do that through the wiki. The coverage is basically everything in part one. So if you look at section 1.6, it gives you a list. The exception is truth tables. You don't need to be able to read them or write them. I know you can all do it, but the other classes didn't do it, didn't cover that in class. So it won't be on the exam. Whoops. Yeah. When I went on, did you get checked in? So it points you to Compass. And I didn't follow it to Compass, because I think it uses your, so you followed it and it didn't go there yet? Yes. I forgot that that's what it's called. OK, so it should be up tomorrow, hopefully. Yeah, sorry it's not up already. We have the rooms. I think Professor Jaramillo will do assignment by name or something to, or maybe by section to room. And so I think he just hasn't posted it yet. It'll certainly be there before Tuesday. OK, so next Monday, we won't have class. So you're not obliged to come. We will have a review session. So here's how it'll work. You suggest topics. I will write down a list of topics on the board, and then I'll have you all vote on the topics. And then I will cover them in decreasing order of popularity until we run out of time. And then it'll be on the video. So if the mic stops working, tell me, because I've actually lectured in this room plenty of times with no mic, and my voice is loud enough. So I just don't even notice. I just talk louder, and everyone can still hear me. I think everyone heard me last time, right? OK. All right, so other resources, practice online tools, watch the videos. There are actually two videos. Attend any of the three lectures, assuming there's space in the room. That is, can't override the fire marshal. Can't be unsafe. Go to office hours. There is an Eta Kappa Nu review session. Eta Kappa Nu is the Electrical Engineering Honor Society. The only problem, we can't vouch for them. So if they make a mistake, I'm not saying they will, but if they do, it's not, sorry, nothing we can do about that. So if we make a mistake, and then that affects your test score, then we'll give you points back. But we can't do that for them. All right, so but usually it's probably worthwhile. So how can we build gates? So the first thing we did is we said, well, we've got electrons. We can measure voltages. Give us a bit, right, binary digit. Then we said, well, let's look at representations based on bits, based on electrons here and there. Then we said, OK, we can do functions on bits with Boolean algebra. But we kind of skipped over the device level. So today we're going to start looking at, well, how do you take devices like CMOS transistors? I'll tell you what CMOS means later. I'm sorry, CMOS gates, MOSFET transistors, and build these Boolean functions out of them. So that's what we're going to start looking at today. But first, I want to run something by you. This is just so exciting. I had a really great idea. They call it a torch. Just point it at you, and it'll light you up. It'll be so nice. You can point it at the podium. It'll light up. No, just it's a light. I mean, you see, it's a lamp. It's not a laser. Actually, Nick Coloniak gave a talk, and he had a visible light LED that was still under the danger level. But you didn't know that when he said, see, look how bright it is. And he said, oh, don't worry. It's safe. Thanks, Nick. So good idea? What do you think? What? But you want me to do what? Like this? But people already make those. I can't patent that. They call it a flashlight. You've never seen this? All right. I don't know. All right, I had another idea. Here's another idea. You like switches? A bunch of switches together. A lot of switches. It'd be good. How many of you play video games? See, this will be great. Good exercise for you. And when you want to change your bid, you just flip a switch. Be the hand-operated computer. Sound good? Good idea? Yeah? OK, we're going to do that? OK, you don't like that. I know some of you didn't like it. Some of you liked it. I got to say, if you want to be a video game champion, it's all in the training. So if you don't want to do the hand-operated computer, I understand. But we do a voltage-controlled switch. Then one switch can control another switch. And that switch can control another switch. So we can put two billion switches all together in one circuit. So that's a really cool idea. I'm getting tired just thinking about that thumb thing. Let's take a little break. So the person who invented that cool idea a long time ago, 70 years ago almost, John Bardeen and Shockley and Bertain. One of them's a manager, but you can read about that if you want. But they invented it at Bell Labs. Four years later, John Bardeen joined our faculty, also the physics faculty here. Got a Nobel Prize a few years later. After that, maybe another 16 years, they got a second Nobel Prize for BCS theory of superconductivity. This is where electrons pair up and act like bosons, allowing them to move without bumping into things. His first PhD student then, Nick Koloniak, invented things like the visible light LED. So all the lighting you see all over the world basically stems back to one of our faculty members, Nick Koloniak, who I mentioned a few minutes ago. He also invented things like laser diodes for CDs and DVDs, if you have ever used those, and dimmer switches and other things like that. Here are some of the things that he was awarded. You can find a much longer list on the web if you want to look. Nick's first student, I think it was his first student, Greg Stillman, also joined the ECE faculty, invented things like avalanche photodiodes, elected to the National Academy of Engineering. This is actually the most prestigious honor for an engineer in the US. It's basically being called to serve the country as an advisor, as an engineer. He founded the MNTL lab, which is just right next to us, and was its first director. His first student, Milton Fang, also joined the ECE faculty and burned the terahertz transistors. So very, very fast, much faster than your typical computer these days. Also the light emitting transistor, both of these were done with Nick Koloniak and the transistor laser. And he just retired actually this fall. So you could have worked with him had you come last year. Actually, he's still around doing research. But not just faculty, so just to mention one of our students, how many of you are going to get a BSEE? The others are BSEE, right? OK, people don't want to raise their hands today. I know we've got more E's than that. Anyway, so but now you're feeling shy because I'm putting Kilby up there. All right, so he got his BSEE in 1947. 10 years or so later, he invented the integrated circuit at Texas Instruments. He also invented things like the thermal printer and the handheld calculator, National Academy of Engineering, and of course, Nobel Prize for physics. So now you know why we expect a lot of you. Yes. Yeah, seriously. I'm not kidding. OK, so all right, so that was just a little bragging break so you know more about Illinois history. So digital electronics today is based on MOSFET. So what's a MOSFET? The material is metal oxide semiconductor and the technology is a field effect transistor. So the voltage basically turns the transistor on and off. It's a voltage controlled switch. So there are two kinds which are named after the charge carrier. So there are electrons. So if the electrons move, it's called a negative type. And if the absence of electrons, which we call holes, move, it's called a positive type. I think not too many of you have taken quantum mechanics, right? So a few of you. So if you think back to, I think probably most of you have high school chemistry. So if you think about what happens when you have valence electrons, you can put two in the same orbital, and one is spin up and one is spin down. And if you have one absence, then it acts kind of like a positive charge. And if you have an extra one in your orbital, it acts like a negative charge. So it's the same sort of idea that in semiconductors, you have energy states. And if some of the energy states are empty, they act like holes. So if the holes are moving around, it's a p-type. If the electrons are moving around, it's an n-type. Just a way to remember p and n, positive or negative charge carrier. So how do these things work? You can learn a lot more in EC 440, I guess 340 now, if you want to take that class later. But I guess all the EEs will probably take it. But CompE is an elective. So an n-type MOSFET turns on when the voltage between the gate on the left here and the other terminals, it's a symmetric device. But between the gate and the other terminals exceeds a threshold. So if the voltage is smaller, the transistor turns off. And then current cannot flow between the other two terminals. Historically, they were called source and drain. But that implies a direction. And this, again, is a symmetric device. So we need two voltages. We're going to do binary digital systems. So we need a ground. And that's our binary 0 value. And we need a VDD, which today is about 1 and 1 half volts. That's our high voltage, our binary 1. It used to be about 5 volts. Actually, the stuff you'll play with in the lab in maybe about five to seven weeks will be 5-volt TTL chips. But on modern processors, it's usually about a volt and a half. So we can use these binary voltages to control, say, an n-type MOSFET. Now, remember, it only will turn on when the gate voltage is high. So the voltage has to exceed a threshold. So if we put 1.5 volts, and then one of the other terminals has 0 volts, as you see on the left here, the current can flow. And then the top terminal can get pulled down to 0 volts. So to turn on an n-type MOSFET, you put high voltage, binary 1 in, on the gate. And then if you have one of these connected to ground, then the other side will come down to ground as well, because the transistor will turn on. This is circuit terminology. You say the circuit's closed or open. I'd prefer to say on and off. I find it less confusing. But either one is fine. So this one, when we put 0 volts on the input, remember that in our binary voltage system, the full range of voltage is only 0 to 1.5. So you can't have anything lower than 0 over here. And so you can't exceed the threshold. So essentially, whenever you put a 0 onto the gate of the n-type MOSFET, it will turn itself off. So p-type MOSFET, the voltage goes the other direction. So if the voltage from these terminals on the right to the gate terminal exceeds a threshold, then the p-type will turn on, which means current can flow between the two terminals on the right. And if the voltage is smaller, it turns off. So the voltage just goes the other direction. So here's the same diagram with the p-type. So in order to turn it on, we need to put our ground voltage in on the gate. You'll notice, by the way, that there's this inverter bubble thing here on the p-type. I'll explain how that will help you. Remember which one is n-type and which one is p-type and how they work in a minute. But if you put 0 volts on the gate and you have high voltage on one of the terminals, the p-type transistor will turn on. And this high voltage can pull this terminal up to high voltage as well. If, on the other hand, you put high voltage on the gate, then you're not going to have any current. Remember that the whole range of voltages here is 0 to 1.5 volts. And so you can't get a higher voltage here to turn the transistor on. And so the p-type will always be off if you put 1.5 or a binary 1 on its gate. Yeah? So that's when? Yeah, so as soon as you get a voltage with the p-type, if the voltage from this point to that point is greater than a threshold, and the threshold is, say, about 70% or 80% of the high voltage, so maybe 1.2, 1.3 volts. So if the voltage difference is sufficient, then this acts like a wire between the two terminals, just like down here. And if the voltage difference is below that threshold, which it always will be if you put high voltage on the gate, then it acts like an open switch. It's turned off. You will not learn. This is the level of detail we'll cover in the class. The question is, will you see PNP junctions? If you want to learn more about transistors, then 340 is the class. So they'll cover semiconductor devices, basically, and give you a lot of detail on this. You'll see a little bit more. You'll see an ID curve, current versus voltage curve, in 110. So you'll see a tiny bit more in 110. OK, so the drawings will actually help you remember how they work. So you notice on the p-type, we have this inverter bubble on the gate. So you should just remember that that means if you put a 0, it turns on, whereas the n-type, you don't have the inverter bubble, the little circle. So n-type turns on if you put a 1 on the gate. P-type turns on if you put a 0 on the gate. Might not be so helpful to remember the names, because at least for me, they're sort of opposite of the binary digits that you'd put onto them to make them work, because they refer to the charge carriers. Yeah? Yes, this is an illustration of the on and off of p-type. And two slides back was on and off of n-type. OK, so how do we actually build gates? So to build gates, we're going to use what are called complementary structures of p-type and n-type MOSFETs. So we'll have an equal number of each type of MOSFET. On the top, we'll put our p-types. The bottom, we'll put our n-types. We say that digital systems are based on CMOS, complementary MOS. So pretty much every digital system you'll see, except for some high-speed networking equipment, will be based on CMOS. So all of your cell phones, all of your computers, most network routers. What does this gate do? So here's the simplest one. We put one p-type on top, one n-type on the bottom. What does it do? So let's go through and analyze it. So let's start. Write a truth table. So first, we'll put in voltages, and then we'll change them later to 0s and 1s. So start with a equals 0 volts. So what about the top transistor, on or off? It'll be on, right? p-type has a 0 volts on the gate, so that'll be on. What about the bottom one? Off. OK, so now we have basically a connection going from Q, the output, up to VDD. So now, remember I said, well, if one of the terminals is at 1.5 volts and the gate's at 0, it can pull the other one up. So this will pull the output up to 1.5 volts. We'll write that in the truth table. What about the other case? So if A is 1.5 volts, we put the labels on. Top transistor? Off. Bottom transistor? On. Good. So now we have a path down to ground. So here, the n-type is pulling Q down to ground, down to 0 volts, by just connecting it through its two terminals, because its gate input is 1.5 volts. So it's 0 volts. So now let's convert those voltages into our binary values. We get those. So it's a NOT gate, right? Yeah. No. I'll just throw it. So you'll see the bottom transistor is on. Top one's off. So the bottom transistor acts as a wire. So now this is ground down here, this little triangle. Sorry. Yeah. So it's changing? Yeah, it's connecting the output Q to ground, when you put A as 1.5 volts under these two transistors. The top one turns off. The bottom one turns on. Creates a wire to ground. Yeah. Yeah, so the p-type MOSFET, so it's not a gate. This whole thing is a gate. But the p-type MOSFET has the circle on the input. MOSFET is metal oxide semiconductor field effect transistor. You don't really need to know. Yeah, transistor. Good answer. Yeah. OK. All right. Yeah, we won't quiz you on that. Although I used to give out candy when teaching the networking classes. There's so many TLAs. Because no TLA, right? Yeah, good. Three letter acronym, exactly. There's so many TLAs that I told my networking class, well, if I give you an acronym and you challenge me and I can't tell you what it means, I'll give everyone in the room candy. And they actually got me a couple of times. It was fairly embarrassing. I'll give you the same deal, because I shouldn't do that to you either. But you have to remember. I won't remind you. Yeah. Yes, yes. So this thing down at the bottom is a general symbol for ground. Yes. And this up here is a general symbol for high voltage. So ground, high voltage. Yeah, this up here is high voltage. And this is ground. Yeah, sorry. Forgot, you might not have seen those. OK. So that's our NOT gate. And of course, we draw it like that. This is how we actually implement an inverter with two MOSFETs, one P-type, one N-type. Let's do a little more complicated gate. So let's go through and analyze this one. So we'll start with A and B equals 0. So there's A. So what about that top transistor, on or off? Off. Good. Bottom one? Off. Off. Good. OK, let's put B's labels. It's also at 0. We're going to do the first row of the truth table first. So what's this upper B transistor? On. And the bottom one? Off. Good. OK, so path then goes from Q where? Yeah, up to VDD, right? OK, so we get a 1. Good. Seem to follow that? Seem like it. OK. Feel free to ask questions. So let's see. Here, the A value is the same, right? We're going to look at the 0, 1 row, the second row. The A value is the same. So it just left the markings on A. You already told me the answer is there. So let's just change B. So B will have 1.5 volts. So what about B's upper transistor? Off. Good. And the bottom one? On. So now where does Q connect? Down to ground, right? Good. OK, so what's the answer? 0. Good. So now I'm going to skip a row of the truth table because I just want to change one bit. So I'm going to go down to the 1, 1 row. So now B is the same, right? B is still 1. So I've left the B markings there. So now let's put A markings for 1. So 1.5 volts. So top transistor? Off. Bottom left? On. OK, so Q still actually now has two paths down to ground, right? So that'll still be ground. And then let's do that last row. Here again, from the bottom row, A is the same. It's still 1. So I'll leave those markings. And we'll put the B markings for 0 back. So you already solved this, but let's just go through it again. The upper B transistor? On. And the bottom one? Off. Good. OK, so we still have a path down to ground. It's still 0. So what is that? Not put together with OR. Yeah, so not put together with OR, right? OR it together, and then invert the output of the OR. That equation. So that we call a NOR gate. It stands for not OR. And it looks like this. So you can see it looks like an OR gate with an inverter bubble on the front. Yeah. Yeah. How? Oh, it doesn't matter. It's just two ways to go down to ground. They're just electrically connected. Yeah, the thing you have to worry about, rather, when you design gates, is you want to make sure you never have a path from high voltage down to ground, at least for any long length of time. Because if you do that, current will flow very quickly, and your chip will melt. So you need to make sure that you never set up your transistors in a way that it's possible for current to flow directly from high voltage to ground. Yeah. But in this case, having two paths to the same voltage, that's OK. It actually will just go down to ground faster. It has less resistance to ground. OK, that's an OR gate. One more. So let's do this a little more easily. So let's just say A equals 0. So I won't even tell you what B is here. So let's just look. What happens if A equals 0? So what's the top transistor going to do? That one's on. The other A transistor? Off. Do I need to look at B? I don't, right? Because I have a path already from Q up to VDD. So any time A is 0, Q is what? A 1, right? Good. Now, what about B equals 0? The same, right? The circuit is symmetric. It has the same behavior for A and B. Let's just walk through it. So we'll put 0's in B, top transistor on, bottom one off. There's a path, right? So also, 1, 0 gives us a 1. So then we have one last case, which is A and B are both equal to 1. So what about A? What about that top transistor? Off. Bottom? On. And then B, also 1.5 volts. Off and on. Good. So we've got a connection down to ground now. All right? What is this gate? An AND. Good. And it looks like that. AND gate with a bubble on the front. So you do the AND, and then you invert the output. I'm sorry? Can you combine it with a NOT gate? Yes, you can combine it with a NOT gate to get an AND gate. So you can take the NAND and put a NOT on front if you want to build an AND. In most of the systems we'll design, actually, you'll see that usually you have more than one level of gate. And so you end up using pure NAND or NOR most of the time, whenever you can. Because otherwise, you're using more transistors than you need to. Yeah, you can make an AND gate by just adding an inverter on the front. OK, so there are some rules. Same number, one side's parallel, at least for NAND and NOR. One side's parallel, the other's serial. I'll explain duals maybe the end of this week or next week. But for now, it's enough to know the parallel versus serial construct. So I'm going to switch over to the tool, and then maybe you can help me out. Let's see. Yeah? I think you had a question earlier that I asked. OK. Do you want to ask now, or I can switch back? Good question, but let me come back to that one, actually. Yeah. I have to convince my laptop. PowerPoint doesn't like you to look at other things. OK, so now we're going to go down to the CMOS gate layout tool. And you'll see that I actually pre-wrote. Wait for that to go away. So why don't we do the NAND? OK. So there's a NAND gate with two inputs. You can check it by saying, hey, I think this is a NAND gate with two inputs, and pushing check answer. And it'll put it all green, meaning it's correct. You can go click on these rows, and it'll put the values at each of the junctions. But let's extend this and make this three inputs. So actually, here is a three input NAND exercise. We can check answer. And so at least one of those is wrong. If I have three inputs, well, it's not even paying attention to C. So what do you suggest I do to make this a three input NAND gate? Yeah, so add one p-type and one n-type controlled by C. So where should I put them? You can put the C. Hm. Up here somewhere. So up here somewhere? Right. Hm. See this thing turned to S? It means short. This is what you don't want to do. I didn't do what Rahul said yet. This is not his fault. But I connected the top through C. And so now, I actually created a path from high voltage down to ground, in this case here, where I've got 1, 1, 0, and A, B, and C. Yeah. Yeah, because I didn't protect the bottom to connect to ground. So now I have to do the other half of what Rahul was saying. And I will snip off this ground, add another n-type down here, connect those up, label that C, connect the other side to ground, and then check answer. So hopefully, you understand this side is in series. If you wanted three, you put three. If you want four, you put four. Four is about where it gets a little too slow. And so typically, gates will scale to about four inputs. And then you'd want to use multiple gates. But you can generalize these if you want to. If you want to play with it, you can go to the tool and make sure you understand it, build whatever you want. You can actually ask the question you asked there, Daniel, also. Maybe what I'll do is just reload it. It's easier than trying to delete everything. But for example, if you put the n-type on top, then you'll get these things, L and H, which if you look down in the legend here, you'll see stand for soft 0 and soft 1. So if you think about the way these things work, usually people ask this question, so it's good you asked it. But if you think about the way these things work, remember, for example, the n-type up there, the voltage has to exceed a threshold for it to turn on. And so if A is at high voltage, then it will turn on so long as the other side is not at high voltage. Once it comes within the threshold of high voltage, it will actually turn itself off. And so the output there, the thing that comes out the other side, is actually a little lower than high voltage. I think I misquoted before. The threshold is usually only about 20% or 30%. And so what comes out here is about 70% or 80%. And we call it a soft 1. And that soft 1 will be then slower in pulling up the next gate up to high voltage. And if you keep building things this way, eventually they just won't work, because they won't be able to exceed the threshold voltage. So because of the way MOSFETs work, typically we're not using this kind of approach often directly. Instead, we build with NAND and NOR. This is how you would build NAND and NOR if you wanted to. But people rarely do this in practice for that reason. Yeah? How many NORs do you want in each? Yes, they're complementary structures. So you've got at least one of each. So there's no gate that has fewer than two. The NOT gate's the simplest. Yeah? OK, yeah, so this was actually a comment also along the lines of your question, Daniel, that if you swap them, you do get these soft 0s and soft 1s. Coming out, they don't quite work properly. Does that answer your question? OK. All right, so what I want to do next is take a look at a function and think about what we can do to get a nice way to express the function. So let's see. Well, kind of hard to understand that probably at this point. So let's start by doing something we know. So when we did the logical completeness proof, we went and we looked at each of the lines with a 1, and we wrote down a Boolean expression for each line. And then we ORed them together to get the function. So let's do that. So here's a row. How do I write a function that gives me that row? Yeah, a b complement c. Remember that we've got each of the variables. So this one is a 1, so we'll have a. 0 will give us b NOT. And c will give us c. So that'll be a b prime c. So what about this row? a b c prime. Good. What about this row? a b c. Good. So if we take those three and we OR them together, we get f. So it turns out I could also write f is a b plus a c. So you can verify that if you want. The ones where a and b are on are these two down here, the bottom two. And of course, you have ones there. And the ones where a and c are on are the bottom one, and then the sixth one down from the top, or the third from the bottom. And of course, those are both 1 also. And together, those two sets give me all three of the rows with 1. So that's the same function. And if you remember distribution, distributivity, well, this, if I have a times b, then that'll give me that term. a times c, that'll give me that term. So all three of those are the same. Which one's the best? Yeah. How did you do that? I just made it up for now. I just said, hey, I just happen to know what this is. I'll show you a way later. Good question, though. Yeah. OK. That's one way to count. Good answer. Yeah. I was about to say, yeah. OK. So you also like the third one. Sorry, but we didn't agree on a metric. If we don't agree how to measure things, then all answers are wrong, right? It's the same sort of game you can play with, add the numbers between 1 and 3 or something. So until you talk about a metric, it doesn't really make sense to say what's best. And there are actually quite a few metrics people care about. So in digital design, usually they care about the first three at least. What's the area? Because that'll be the cost of fabbing the chip. So how big is it? How fast does it go? If it's very slow, maybe it's not worth making. Got to be competitive. Power energy consumption, if your battery on your cell phone is only going to last half an hour, you're probably pretty unhappy. So all three of these are important. Which one's the most important depends on the context, depends what you're trying to do. And as an engineer, you're usually going to have to balance between them. Yeah. Will you give anybody a hint? Not necessarily, no. So in our class, we're only, we'll talk about it more in a few minutes. In our class, we're going to talk mostly about area and performance. And you can trade those off pretty well against each other. And the last one is complexity reliability. So we'll talk about all four of these a little bit. But we need to use heuristics. So why are we using heuristics? And what are heuristics anyway? So in practice, actually making a measurement, saying, well, look, let's just build all the designs. And then we'll go measure them. That's kind of expensive. So in particular, if you were a cell phone manufacturer and you want to create a new cell phone and you need to do some chip fabrication, that process with all the engineering costs is about $50 to $100 million. If you're going to sell 5 million of those cell phones, yeah, big deal. That's OK. A few dollars per phone, yeah, we could cover that. If you're not going to sell a few million of those, you're not going to be able to afford it. Just building it, just the mask cost, the thing that allow you to fabricate the semiconductor chips, will cost you a few million dollars these days on the high-end processes. So instead, we want to make a guess before we go build something. So we'll use something called a heuristic, which allows us to estimate a measure. So what makes a good heuristic? Well, you'd like it to be reasonably accurate. But maybe more importantly, you want it to be monotonic relative to the real measurement. So if I get a bigger number out of the heuristic, I should get a bigger number out of the real measurement. And as long as it had that monotonicity property, probably a reasonably good heuristic. So let's take a look at a couple of heuristics for our class. So here's one for area. So take your expression and count up the number of literals. Literals are variables or they're complements. So count up the number of literals, and then add the number of operations, not including the complemented literals, so just ands and ors, or other operations would be fine, too. So why does that work? Why is that a good heuristic? So if you think about what we just saw with gate design, every time you have an input to a gate, it's going to be two transistors, one n-type, one p-type. So you get kind of a transistor count. Operators and operators, if you have an AND gate feeding into an OR gate, same thing. That output to the input, two transistors in the OR gate. You're basically transistor counting. Wires also take space, so this is not the best heuristic in the world. But it's a pretty good one for just looking at an expression and figuring out how big it should be. So let's go ahead and calculate area heuristic for those three forms of F. So what about the first one? How many literals do I have? So you have to count all of them. So this term alone counts for three. So just having A twice, those are going into different gates. So each of those will cause two transistors, two transistors, two transistors. So just literally count the number of letters. You get nine, right? How many operators? So here, it's a little trickier. Don't worry about the number of inputs. So for example, this OR is one three-input OR. And the ANDs for the minterms, those are one three-input AND each. So you have four, right? Three ANDs and one OR. So total, about 13. What about the second expression? How many literals? Or how many operators? Three, right? Two ORs and one, I'm sorry, two ANDs and one OR. So total, seven. And then the last one? Three literals, two operators. Good, so five. So from area point of view, our heuristic tells us, OK, that last one is probably the best. Fewest transistors. Now, a second metric you might care about is speed. So here's a way you can estimate speed. You look at, here we only have one output. But in a bigger system, you might have many outputs. You look the longest path in terms of how many gates from any input to any output. Don't count complemented literals if they're free. Sometimes they might not be free. So you kind of have to know what you're using the system in. Why does this work? Your gate takes time, right? For currents to flow across wires, they're not instantaneous. It takes time. So the time it takes one gate to change its output, we call a gate delay. It'll change with a semiconductor process. It gets faster over time. But it'll always be finite. It'll always take some amount of time. So we'll call that time a gate delay. And if we count gate delays in our design, we can estimate the speed at which we could use that system. So let's do that again for our functions here. So in the first one, we have maybe these complements. So that could be one. And then going into the ands, and then that goes into the ors. So two or three. Yeah. What's the operation? The operation? You mean the area? Yeah. Correct. Yeah. So basically, an and consisting of any number of terms, of any number of factors, is one. Same thing for an or. So the ors are a little trickier to figure out. But any sequence of terms with pluses between them is one. So that would be a multi-input or gate, basically. Yeah, here we leave out the complements. You'll see in about maybe three weeks that often these are free. So often, if you have a, you'll also have a prime available on a different wire. So that's why. But I know it's not clear now why, but just don't count them because they're usually free in most digital systems. So here in the first one, we had three minterms. Each of those requires an and gate to calculate it. And then we have one or to bring together all three. So three ands and an or. This one is two ands and one or. This one is one or followed by one and. So let's go now count delays. So here we've got, in the first line, again, two or three. So we've got the ands, we have the or, and then we might need to calculate complemented literals. So let's just say two or three. Here, we have just and followed by or. There's no complements, so definitely two, whether they're free or not. And then the last one, we have an or followed by an and, so again, definitely two. No complements either. So here, these last two designs are the best for delay. Yeah, so we're just counting gates. So I thought about drawing them for you, which will make it easier to just point at physical gates. But the B plus C, for example, is one or gate. That output of that or gate goes into an and gate. The output of that and gate is F. We have two gate delays. Similarly for the bigger ones. So the simple heuristic is you simply count the number of gates along the longest path. So you're just counting gates, and you just say it's gate delays. In real systems, if you want more accurate estimates, things with fan in or fan out above four will be slower. But we don't need to worry about that for our class. Yes? AUDIENCE MEMBER 2 So the two and gates can execute in parallel. So it's the longest path from any input to any output. But one path will go through one and gate from A. The other path will go through a different and gate. But both paths will only have two gates on them. So there's the second equation. So for anything on this side, basically, it'll be through two gates to get to F. So in this case, we have a clear winner. Yeah? AUDIENCE MEMBER 3 I mean that one's the first one? Yes. AUDIENCE MEMBER 3 One or? Yes. AUDIENCE MEMBER 3 If they go through the other one? Yes. So three three input and gates, and one three input or gate for the first expression. AUDIENCE MEMBER 4 What are the time delays? For the gate delays, the complements would be the third one. And so if they're free, it's two. And if they're not free, it's three. But these expressions don't have anything complemented. So they're two, regardless of whether or not the complements are free. OK. In this case, we have a clear answer. The answers are not always that simple. If you want a simple expression where you have to choose between speed and area, just look in section 211 of the notes. And there's an example there done out the same way, where one is faster and one is smaller. So you have to pick. We'll see a lot more of that kind of trade-off later in our class, too. And in practice, we're going to be a lot more of that kind of trade-off later in our class, too. And in practice, this is the kind of thing people have to do all the time. So there's a starred section I took from one of our former PhD students' PhD thesis, showing trade-offs for computer processor architecture designs. So you can see the graphs. And you can see the kind of things people do in the research. It's a starred section, right? So don't feel obliged to read it. But if you're interested in thinking about how you do this kind of stuff, there is a little bit in there on that. OK. Another question? Yeah, go with one. Two slides back. OK, so remember when we talked about the complemented literals, I said you should count the complements if they're not free. So if they're not free, you have to use an inverter. An inverter is a gate. So that's a gate delay. So draw this one then. Oh, this one's bigger, huh? OK. OK. So what are they? A, B prime, C, and then A, B, C prime, and then A, B, C, right? And this is F. So this is the first expression. So you can see now the inverters take a gate delay. So if those are free, if the complemented inputs are free, I don't have to pay for the inverter. So that would be two. If the complemented inputs are not free, I have to invert the A and B inputs. I'm sorry, B and C inputs. And that'll take a gate delay. Yeah. Is it a diagram? No, because that's an assumption. So in this diagram, it's not free. In the diagram, I drew them explicitly. If they were free, then I would simply connect C prime to here. So I mean, I can change the diagram to explain it. But that diagram assumes they're not free. Yeah. It's not sure. Yeah, so the question is, can you break your complex circuit into pieces and analyze each of the pieces? Absolutely. Yeah, so as you'll see, even in a week or two, we're going to start to build components. And so often, people will design pieces. In fact, most designers are using a standard gate library. So they're not really going down to transistor level and optimizing. A couple companies, Intel, Samsung, Apple, actually do custom logic these days. But almost no one else does. And even beyond that, when you get into 385, you'll be writing something C code-like to design your hardware. So you'll say plus, and that'll pop down an adder for you. Yeah. Would you like to talk about the C++? In office hours, if you want to. OK, so power and complexity. So I just wanted to talk briefly about these. You'll notice the stars at the top. It's beyond the scope of our class to talk about power consumption. It's too complicated to throw into 120. But if you're interested, when current flows, current flows when you switch your transistors on and off. Current has to flow to bring the voltage at the output down or up. And so that consumes energy. Goes through there, burns heat in the resistance. And you can estimate the number of times that happens in a simulator and use that to estimate your power. So that's what a lot of the design tools do for you. In 385, you'll see that, and you can play with it. Complexity, the fourth measure I mentioned, is kind of hard to measure. No one really has a quantitative way to do that. So it's usually based on experience. It's based on people knowing how hard will it be to make this work. In practice, we just have a couple minutes left. In practice, there's a lot of funny stuff in the industry. So for example, a lot of the Intel processors had what were called chicken switches. So they implemented, for example, multithreading, parallelism in their processors. And then they released them, but they were worried it would break. So they didn't turn it on. So they just left them off. A year or two worth of processors, they just had it turned off. And everything was ready. It had all the logic circuits. It had all the transistors ready to go. Just they were scared that it would break, and then they would lose a lot of money if a customer is getting angry. And so they turned it off. So there's a lot of that, actually, in the real industry. And a lot of that is just based on whether people think it's going to work and whether they think it's going to be viable to actually develop it and test it and make sure it works in the hardware. So I'm sorry? Oh, of course they tested it. And they found that it wasn't reliable enough for them to turn it on in the product. And they wanted to get the product out the door. Yes, of course they tested it. Yeah. Yeah, they always test it. Don't worry. There's actually a lot more testing in hardware because bugs can be in the design, but bugs can also be in the fabrication process. All right, so let me stop there, and we'll pick up on Wednesday. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\"},\n",
       " {'ECE120-2016-11-11-LEC-33-slides-start-at-11.5-min.mp4': \" Iawn, mae'n mynd i'r rhan fwyaf o'r gwrthwyneb hefyd. Mae'r adswyth oliau ac aliadu haethiad chyda dim lle Dewis Aelodau y Gallfrin yma roedd y rhan fwyaf o edrych ond nid yr un topAsiannaf yno. Ond mae'r E illum wrth gwrth gwael ryw fath bach yn y stopash yn y meddwl, yn oerthin i'ra fân yma a meddwl fy mod ynל swyddo at yr gwaith llwyd. 40%, er mwyn ddweud y byddwn yn ddwy munud. Felly, diolch am hynny. Iawn. Felly, byddwn yn gwneud chalk. Felly, rwy'n am gynllunio'r ddau ddau byth o'r cynllun, yr holl slidau Powerpoint ar gael, felly os ydych chi eisiau gweld y rhai hwnnw nesaf, dyna'n iawn. Unwaith ddweud y gwnaethom ychydig o'r hynny, mae'n bwysig iawn, ac mae'r projectorau'n deimlo'n ddod allan, felly, yn hytrach na'n dod ymlaen ar y 20 munud arall, mae'n bwysig iawn uchwichwyl iawn. O ran a ffordd fyddwn i'n gwrthodi'r garch ymgynghoriad, ond mae ddewis g Schulder yn rhan, i chi. Byddwch yn maneiraidd iukiwch ddry KP Southwest wedi'i benodoli a fyddwch yn y phone chwbod ydych chi eisiau ein cwitho ac yn dylunio'r garch. Rynarrator fel sefydleidfa, hyd yn oed ac eisoes. Mae cyllid eu chyfleuwr drwy w Sisters nawr trwy'r syniadau rhandaddau olennol, ac mae dimelyn a gallu'r d WWE ac ymwneud â chynnal yr holl ddifrifnau ar y string hefyd. Felly roeddem yn eisiau mynd drwy'r string. Roeddem yn cael nifer o ddifrifnau gwahanol, felly un o'r ddifrifnau, er enghraifft, oedd i'r un ddifrifnau a'r ddifrifnau ddifrifnau ddim, gan fod y ddifrifnau ddifrifnau yn un categori, i'r un ddifrifnau yn y string. Felly gallwn ni sefydlu rhywfaint o sum i ddifrifnau yma. Os yw'r ddifrifnau'n cyfathrebu â'r llyfr neu'r ddifrifnau ddim, yna sefydlu sum i sum plus un, ac yna pan ydych chi'n gwblhau'r holl string, yna gallwch chi ddifrin neu gosod y sum fel y llyfr yma, neu fel yr holl lyfrau. Felly dyma'r ffordd y gwnaethom ei wneud yn ddiwylliannol fel dynion. Os edrychon ni ar y string gwaith, byddwn yn dweud, wel, os ydw i eisiau edrych ar a, byddwn yn edrych ar y holl string, gweld pa mor a'r ydw i'n ei weld yn adroddio'r nifer honno. Yr ail, os oeddem am wneud Patent Patel, ddewisom ein bod ni'n gobeithio gwneud rhywbeth ychydig wahanol yn ystod, sy'n rhywbeth fel yr ysgafn. Felly dychwelywch 27-byn histogram, ddod â'i gyflwyno gyda ddifrifnau, ac yna mynd drwy'r llyfr unwaith, mynd drwy'r llyfr fawr unwaith, edrychwch ar bob unigol, a ddewis pa ffordd o unigol mae'n ei wneud, os yw'n llyfr yn unigol neu'n llyfr ddim, ac yna addu un i'r bin cywir. Felly ar gyfer pob unigol yn y llyfr, cynyddu'r bin cywir ar gyfer y unigol. Felly dyma'r algorithm 2, dwi ddim yn eisiau ddysgu'r algorithm 3, dyma'r algorithm 1, ac yna sônoddom am y gwahaniaethau rhwng nhw o ran amser, gofyniadau gweithredu, pethau fel hynny. Rydyn ni'n mynd i ddatblygu'r un hwn. Y rheswm yw, yn y blynyddoedd, roeddwn i eisiau ddangos i chi sut mae rhai o'r control yn gweithio, ac wrth i ni wneud y decomposiad systematig, roeddwn i eisiau gallu defnyddio strwythurau ysgrifennol o ran ymwneud â chlasifio'r unigolion hyn. Felly, byddwn yn defnyddio hynny. Rydw i'n mynd i geisio dod yn ôl i hyn a gweld a oes ganddo. Oh, nawr mae'n mynd i ddod o'r amser i mi. Wel, mae hynny'n cymhwysol. Wel, dwi'n mynd i geisio siarad â phan o'r bwrd. Sori am hyn. Mae Phil Crine wedi mynd i China, felly dyma ddim yn gallu ei gysylltu â nhw. Mae Phil Crine wedi dyluni'r adeilad hwn. Na, dydy'r maic ddim yn gweithio er mwyn bod y system yn ei wneud. Felly, os nad ydw i'n siarad yn llawn, dweud wrthym i mi a byddwn yn siarad mwy. Mae'n ei wneud, mewn gwirionedd, ond pan fydd y system yn ei wneud, sy'n cymryd unrhyw 5 munud neu rhywbeth, byddai'n mynd i ddod â'r maic. Iawn. Y rhesymau y gofyn i mi ddod â'r broblem honno oedd, yn unol, roeddwn i am ddangos penderfyniad control cyflawniol trwy gweithio â'r adeiladau. A gadewch i mi weld a fyddai'n... Na, nid ydy'n mynd i'w gwneud. Ond roeddwn i'n ei ddweud yn HDMI, felly dwi'n mynd i ddod â'r un hwn yn ôl i mewn a gweld a fydd yn swycio arno i mi. Iawn, felly... oh, a oedd hwnna'r maic? Rwy'n credu bod hwnna'n maic, o'n i'n ddweud? Felly, mae ein rhaglen cyhoeddus yn rhoi'r rhan gyntaf o'r de-gwneud, o'n i'n dweud, wel, rhaid i ni gyntaf gynhyrchu'r histogram. Rhaid hefyd i ni gynhyrchu rhai rhaglenau. Felly, nid oeddwn yn siarad am defnyddio rhaglenau yn ôl. Fe wna i ddysgu sut y byddwn yn defnyddio'r rhaglenau. Mae'r hyn yn deimlo ei fod yn ail, o'n i? Mae'r peth hon wedi'i ceisio ei ddysgu, nid yma i'r hyn rwy'n gallu ei weld. Felly rwy'n credu fy mod i'n mynd i ddod â'r sgrin, a os gallwch chi ei gael i weithio, yna, yn fawr, a byddwn yn dod â'i gael yn ôl, ond, felly, byddwn yn dal i weithio ar y tro. Rwy'n ar y laptop, ond rwy'n mynd i gael'r sgrin allan. Ie, os gwnaethoch chi'i wneud yn byw, yna byddwn yn mynd i hynny, ond felly, mae'n iawn. Iawn, felly, felly, cofio'r algorithm rydyn ni'n ei ddod â'r hyn o'r decyn o'r cyflawniad cyflawniadol yma, yn y codi, y codi pseudogol rydyn ni'n ei wneud, iawn? Fe dweudwn, wel, yn gyntaf, byddwn yn cyflawni, yna byddwn yn mynd i ddod trwy, oh, mae'n ddiddorol nad wyf yn dda gyda'r technoleg. Beth wnaethoch chi'i wneud? Iawn, dwi'n gwybod. Ie, ie, yna un. Iawn, rydym yn dda yna. Iawn, iawn, iawn, iawn. Iawn, iawn, iawn. Diolch, Sir. Yw hwn yn byw? Gallwch chi fy nghyfres? Neu a allaf, efallai os fyddaf yn gysylltu â hyn, byddai'n well. Iawn, dwi'n gwybod, dwi'n mynd i'r ôl, dwi'n gwybod am y burp mentrol, ond rwy'n eisiau gofio hyn yn ddiweddar. Felly byddwn yn mynd i'r cyfnod arall, i fynd i'r ffwrdd drwy'r adnoddau. Felly, yn ogystal â'r holl rhan tri, eto y rhan o'r ddeg o'r termau, dyma'r bwlltau. Rwy'n eu rhoi ar y wefan hefyd, ond ar ysgrifennu a deall rhaglenau yn binari LC3, ac yna hefyd gallu ysgrifennu sefydliad gwreiddiol, felly ffynoneimau Van Neumann a phethau fel hynny, iawn, a'r strydau gwreiddiol o ddysgwyr. Yn y bôn, fel y dweud, pan ysgrifennwydwn yn y clas, yn y bôn, yn ddysgwyr a'r adnoddau, ond yn cael sylw ar beth yw'r pethau hynny. Yr un hon, rwyf yn gobeithio bod y rhan hwn yn rhedeg. Iawn, yn siŵr. Yn y bôn, y rhan hwn yn y cyfnod tri, y rhan hwn yn y cyfnod tri yw'r ffsm. Felly, iawn, yn y bôn, dyna'r rhan hwn yn y ddeg. Roedd y bwlltau eraill nad oedd yn y rhan tri, oherwydd mae gennym ddydd sy'n mynd o'r rhan tri o'r clas i'r rhan tri. Felly, mae'r topïau ar gyfer y cyfnod tri yn y rhan hwn, sy'n cyd-dod â'r rhan, yn unigol, yn cyd-dod â'r rhan ar y wic. Felly, roeddwn i eisiau ei roi i chi mewn clas, yn unwaith. Iawn, felly, roedd hwn yn y cyfnod tri. Roedd hynny'n algorffem trwy'r cyfrifiadau. Iawn. Iawn, felly, dyna'n ein stryd cyntaf rydyn ni wedi siarad amdano. Felly gallwn hefyd ddysgu'r cyfrifiadau. Dyna hefyd yn y codi pseudogol, iawn. Felly, pan ddysguon ni'r codi pseudogol, roedden ni'n dweud, wel, byddwn yn mynd i ddod o'r holl ffigurau yn y rhan. Felly gallwn ddod o'r holl ffigurau yn y rhan. Pan ydyn ni'n parhau? Wel, ar ddiwedd y rhan, dywedon ni ei fod yn ymdrech ar gyfer ffigur nol, Asky Null, sy'n unig yn 0. Felly, pan ddodon ni'n ddod o'r 0, mae'n golygu ein bod ni'n gwneud gyda'r rhan, ac yna rydyn ni wedi cyfnod yr holl ffigurau y gallwn gweithio. Yn ail, mae angen i ni gyfnod un ffigur o'r rhan, ac yna dal i fynd. Iawn, felly, sut ydyn ni, sut ydyn ni'n cyfnod un ffigur? Wel, mae angen i ni wneud dwy ffyrdd wahanol, iawn. Felly, byddwn ni'n mynd i ddefnyddio un arall o ddysgwyr. Un o'r pethau yw ddod o'r holl ffigur a'i gyfnod, felly, cyfnod un ffigur yn y histograff, ond yna mae angen i ni hefyd cymryd ein pwyntwr i mewn, i gyd. Mae angen i ni gael ein gysylltiad â'r nesaf o'r ffigur yn y histograff pan ydyn ni'n cyfnod y ffigur hon, felly byddwn ni'n mynd i gyfnod y pwyntwr hefyd. Felly, bydd hyn yn edrych fel hyn, dim ond un arall o ddysgwyr cyfnodol. Iawn, byddwn ni'n cael y ddwy ffyrdd hynny, ac yna gallwn ddechrau'n rhannu'r un hwn, iawn. Dyma'r un cyfartal. Sut ydw i'n gwybod os yw rhywbeth yn llyfr neu ddim yn llyfr? Sut ydw i'n gwybod pa ffyrdd i'w rhannu? Wel, rhaid i mi edrych ar y data. Felly sut y gallwn ni ei wneud? Felly, byddwn ni'n rhaid i ni ddefnyddio cyfnodau cyfnodol. Yn aml, ni ddim yn eisiau 128 o ffyrdd gwahanol, iawn. Dydyn ni ddim eisiau dweud, well, os yw'n y rhan gyntaf, byddwn ni'n ei wneud hyn, yn amlwg, byddai hynny'n deimlo. Rydym nhw'n rhannu feilydd, digwydd chi bach o raglen, felly rydym ni'n hyfyr-ifer hyfyrgyll, fel rhaid i chi leoli! Wrth ystryd y rhhaven sy'n ymddangos fel gyda gw olaf, bydd yn rostridig ymladdiadau. Onc needles pwy sydd yn gorfod cael ein groesi yn ddiweddar hyd i greum garaer bobol. Dylai dim byrwodol, treulyn energy meuddio fel gwallt, ond rydym ni'n gfrei i bob lŷ bobl hyd ac yna gwneud 140 o hneppion. Nawr, rydym am ddim lodi phelus. ymdrechion, ac hynny'n gwneud i ni ddiffygu llyfrwyr ddi-llyfr o llyfrwyr, trwy'n brifysgolio'n ffwrdd i'r regynau hwyl a'r hawl. Felly, ar gyfer gweithgaredd, os edrychom ymlaen at y ffigur, a'r ffigur mae'n llai na llyfr A, yn ASCII, nad yw hwnna'n llyfr. Felly gallwn ymdrech ag y llyfr A, capital letter A, ac os ydyn ni'n dod o'r cyfrifiad yw llai na A, gallwn mynd i gyfrifiadu'r bin non-llyfr yn unig. Rydyn ni'n gwybod nad yw'r rhan yma, oherwydd rydyn ni wedi gwneud y cymharas honno, felly beth sydd ar gael, yw'r ystod y chwe ffyrdd. Felly, byddwn yn mynd i gyrraedd llyfrau cyfrifiad nesaf. Felly beth ydyn ni'n ei wneud yw, byddwn yn cymharu gyda Z. Byddwn yn cymharu gyda Z, yn gwneud cyfrifiad o seiliedig ar Z, ac os yw'n llai neu'n unig i Z, yna dyna'r beth yw'r llyfr, oherwydd rydyn ni'n gwybod nad yw'n yma. Rydyn ni wedi cymharu y cas honno. Felly byddwn yn rhannu'r bocs sydd ar y ddra i'r strwythur cyfrifiad hwn, a byddwn yn dweud, mae'r llyfr yn fwy o'r cyfrifiad nesaf. Os yw'n ymwneud â'r llyfr, ni allan gwybod beth yw'r beth, felly byddwn yn rhoi'r bocs sy'n dweud, oh, rydym yn gwybod sut i gyrraedd rhywbeth mwy o'r cyfrifiad nesaf. Ond os yw'n llai neu'n unig, os yw'r cyfrifiad hwn yn ddifrif, os yw'r person yn llai neu'n unig i'r llyfr Z, yna rydym yn gwybod ei fod yn llyfr. Felly yna rydym yn mynd i gyrraedd y llyfr Z yn ymwneud â'r cyfrifiad nesaf. Felly rydyn ni wedi gwneud y cyfrifiad hwn. Rydyn ni'n gwybod bod y person yn y braciau o'r iaith yma. Felly yr hyn sydd ar gael yw'r tri rhegion yma. Felly pan dylem i'r rhaglen? Pan dylem i gydweithio'n ddiogel? Efallai ychydig llyfr A yma, o'r gwrthwyneb. Iawn, dwi'n gwybod. Felly rydyn ni'n gwybod bod y cyfrifiad nesaf yn y llyfr Z yn y tri rhegion. Dwi'n gofyn, a yw'r person yn llawer mwy na'r rhaglen A? Os yw, edrychwch yn ôl ar y diogram hon, os yw'n llawer mwy na'r rhaglen A, ac rwy'n gwybod nad yw'n ymlaen yma, oherwydd rydw i wedi cymryd yr holl rhaglenau hynny i lawr, yna dwi'n gwybod bod y person yn y rhegion hon. Ac os yw'n y rhegion cyntaf, y rhegion cyntaf-ddwyrain, nid yw'n llyfr, ac nid yw'n llyfr. Yn y tri rhegion cyntaf, mae'r cyfrifiadau yn llawer o bethau. Un o'r rhegion cyntaf yw llifr y histogram o 0. Felly dyna oedd y rhan yn ein codi. Ond mae'n rhaid i ni hefyd rhoi unrhyw gwerthoedd y byddwn ni'n eisiau eu rhwng-registr. Felly, gofynnwch, pan roeddwn yn tyfu mewn nifer, roeddwn i eisiau FFD 0, sy'n negatif ASCII 0, er mwyn i ni gynhyrchu'r nifer y dylwn ni ei ddysgu yn ASCII i nifer bynari, neu nifer gwlad 2, er mwyn i ni ddysgu 30 hex, cymryd y digid 0, a chael nifer o 0 i 9. Pan fyddem yn gweithio gyda llyfr, rydym yn eisiau'r un peth yw'r benderfyniadau hynny. Rydyn ni eisiau gael gwerthoedd a rhaglenau a allwm i ni ystyried, a yw hynny'n fwy nag a, a yw hynny'n fwy nag Z, pethau fel hynny. Felly, gallai bod niferau sy'n ddefnyddiol. Byddwn yn ddysgu beth maen nhw'n ymlaen, ond efallai y byddwn yn eisiau rhoi'r rhain i'r rhestrau. Felly, mae hynny'n y pethau y byddwn yn ei wneud. Beth am ddod o'r histogram? Felly, byddai'n mynd i fod yn gweithredu. Rydyn ni'n cael 27 ben, felly 26 llyfr, un ben ddim-alfabetig. Felly, byddwn yn mynd i wneud gweithredu. Felly, eto, byddwn yn eisiau pwyntio i'r histogram. Felly, byddwn yn pwyntio'r rhestr i'r histogram, ac yna'n mynd i ddod o'r benau, 27 arall, a chyflwyno'r un bob un gyda 0. Felly, unwaith y gwnawch chi ei ddod o'r ben, ddim yn mynd i ddod o'r histogram gyda 0 yn ymdrechion, ond dyma'r siart llwyth. Felly, gallwch weld y strwythoedd cyntaf rydyn ni'n ei gael, lle rydyn ni wneud 4 gweithredwyr gwahanol, un yn ddod o'r un o'r diwedd, a'r un o'r ddau. Felly, 4 gweithredwyr gahanol yn order. Dyma'r 5 rhedegau o'r tafel ASCII yma, ac yna dyma'r cyflwyno, y colwm o'r ddod o'r a'r cyfrif gyda'r lwyf yma a'r cynyddu'r pwynt ar y ddau yma. Os ydych chi eisiau edrych ar y siart llwyth hon, mae'n... Wel, rwy'n credu bod wedi'i grinio, ond efallai nad oeddwn i'n ei rhoi ar y ffyrdd erioed, ond mae'n rhaid i ni gwneud y cyflwyno i'r cyfrif. Felly, rydyn ni wedi'i rhoi ar y problem, a gallwn gwneud y cyfrif L3 ar gyfer hynny. Felly, dyma dim ond y cyfrif o'r broblem a'r algorffen rydyn ni'n ei gyrraedd, felly rydyn ni wedi sôn am hynny. Felly, dechreuwn i ddod o'r gwmpasau. Felly, byddwn yn angen strwyng. Bydd yn rhaid i'r strwyng fod yn ymwneud â memoriaeth ymlaen. Rydyn ni'n ddod o'r gwmpasau ar y cyfrifiadau, felly byddwn yn dechrau'r gwmpas ar 3,000 hacs. Pa lle rydyn ni'n eisiau rhoi'r histogram? Dwi'n medru rhoi hi ar 3,100 hacs. Nid yw'r gwmpas yn gyffredinol yn mynd i fod yn ddau'n fawr. Mae'n ymwneud â 30, 40 gwybod, neu rhywbeth fel hynny. Felly, bydd yn dechrau ar 31,000 hacs, ac yna, bydd y pen-iaith yn mewn ordd 31,001. Felly, bydd 31,000 hacs yn ein pen-iaith nid-alfa, a bydd 31,001 yn a, a bydd 31,002 yn b, ac yn y blaen. Felly, bydd hynny'n ein histogram o 31,000 hacs i 31,000 hacs. 1 hacs yw 26 o ddeg. 1 hacs. Yna, mae angen i ni asgrifio'r rhestrau hefyd. Felly, pan ydyn ni'n cyfnod, fe wnawn ni gwneud r0, pwyntor histogram. R0 yw'r pwyntor histogram. R1 yw'r pwyntor strin. Felly, bydd hynny'n mynd drwy'r strin. Byddwn ni'n dechrau ar y dechrau, ac byddwn ni'n gweithio'n rhagor rhagor ar ragor i'r ddod â'r nol. Pan ddod â'r rhestr allan o'r strin a'i roi yn y rhestr i edrych arno, a ddod â'r beth yw'r rhestr, pam ddod â'r rhestr yn r2? Dydyn ni'n dweud ein bod ni eisiau rhestr angen, ond dydyn ni ddim yn gwybod beth mae'r rhestr angen i fod. Felly, byddwn ni'n dweud, ie, r3, r4, r5 gall fod yn rhestr angen a'r r6 bydd yn rhestr amgylcheddol. Felly, pan ddod â'ch gweithio i ddod â'r rhestr, dydych chi wir eisiau gwneud ymddangos ym mhob ffordd ar y pwynt o'r papur, hefyd yn eich cyfnodau a'ch codi, er mwyn i chi ddim angen i chi gofio ym mhob ffordd. Felly, mae'n amser i chi ddod â'ch codi. Felly, mae angen i ni gynhyrchu r0 i 3100. Beth ydych chi'n meddwl y dylem ni ei wneud? Felly, gallwn ddefnyddio Ld, iawn? Gallwn ddod â 3100 mewn cofnodion yng nhw. A oes unrhyw beth y gallwn ei ddefnyddio os yw'r adroddiad hwn? L-E-A, L-E-A, L-E-A, L-E-A, L-E-A, L-E-A, L-E-A, L-E-A, L-E-A. Felly In yr 99. Ff, 100 hex minus 1. So, the PC, when this LEA executes, will be what? 3,001, right? So if we add ff, we'll get 3,100. Okay, so that'll be the instruction. We won't put it into bits. I'll leave that all for you. Actually, it's done for you in the version on the web, so you can actually download that if you want to play with it. So what's next? We need to fill the histogram with zeros. We'll actually need a couple of registers for this, so I'm going to kind of break my rule. And part of that is, well, we need more registers for this program than we have registers in the LC3. And so I need to reuse registers, but do it at a very high level if you need to do something like this. So we'll have a different meaning for the registers during initialization than we have during counting. So the ones I showed you was during the counting. During initialization, we're going to reuse R1, R2, and R6. So R1 we're going to use for a loop counter. It's going to have to do 27 iterations because we have 27 bins in our histogram. R2 will be the current histogram bin to fill, so we're going to scan along in the histogram bin, going bin to bin, putting zeros in them. So that'll be our pointer to what we want to put a zero into. And then R6 will just have a zero in it. I don't have a good way to put a zero in memory unless I have a zero in a register. So put a zero into R6, then we can store R6 to put a zero into a histogram bin. Okay, so time for you to write code again. So we need to initialize R6 to zero, R1 to 27 decimal, and R2 to 3100 hex. So let's do those in order. So how do I put a zero in R6? I can do an AND. Good. Okay, so AND, R6, R6, zero. You've seen stuff like that before, right? All right, so how about R1 to 27? Can I do plus 27? So LC3 immediate for an ADD only goes up to 16. So I could do two ADDs, and I could add 16 or 13 and 14, but instead maybe I'll just do an LD. That'll mean I have to have the number 27 somewhere. So let's just store it in memory somewhere and use an LD. So LD, destination R1. What's the offset? We don't know. So it's going to be down somewhere at the bottom. After all of our code, we can put some data in, but we don't know where that is, so let's just leave it blank for now. How do we get 3100 into R2? Yeah, I could do another LEA. That's a good idea. That's not what I did, but that's equally good. I already have it on R0, right? So how can I get it from R0 to R2? Yeah, good answer. So add R2, R0, number 0. So add R0 to 0, put the answer into R2. So that'll copy R2 into R0 for us. I'm sorry, copy R0 into R2 for us. Good. So now we're ready to actually fill the histogram bin. So we set these up already, these three registers. And what we need to do is write a 0 from the R6 register into the memory location pointed to by R2. R2 is pointing now to our histogram, the start of our histogram. So we need to take R6, write it into that memory location. Then we need to increment to point to the next bin, which means add 1 to R2. And then we need to decrement the loop counter, which is R1, and keep doing that over and over again until the loop counter, R1, gets to 0. So that'll fill all 27 bins for us. Okay, so write one 0 from R0, I should say R6, sorry, to the histogram bin to which R2 points. I'll see if I can structure that. What? STR, right, store register. Good answer. Okay. What's the source register? So you want to store a 0, but R0 doesn't have a 0 in it, right? This was wrong. This was a typo. R6. Good. And the base register? R2? Yeah. So remember, R2 is now pointing to the histogram. It has the address of the first bin in the histogram by design. That's what we loaded into it up here. This put the address of the first bin into R0. This copied the address of the first bin into R2. Each time we come back in this loop, we'll be pointing to a different bin. So R2 is going to point to one of the bins we're going to store from R6 into the address, the memory address pointed to by R2. And the offset then is 0. And so that 0 gets added into R2. R2 already points to the right place, so we don't need to change that. Actually, almost never do you need to write anything other than 0 for your offsets. There's a few times, but pretty much not very often. Okay. So next step, point R2 to the next bin. I'll use the instruction for that. Add what? R2, R2, 1. Good. And then decrement the loop counter. Use the instruction for that? Add. Good. R1, R1, negative 1. Okay. Branch backwards until we've written 27 bins. What's the condition? Branch positive. Good. Okay. Oh, so I wanted you to remember R1 started at 27, so after the 27th time, it gets to 0. Right? So if we branch positive, like you said, where? Hmm. You should be able to answer this one, right? So where's PC? I always have to count. All right. So we're going to start here, right? So here. And then we want to go back to where? 3004. So 1, 2, 3, 4, but going backwards. So negative 4. Yeah. All right. So we're going to go back up here to where we stored. Oops. Sorry about that. Yeah. So the pointer's wrong, too. So another brain-o on my part. Okay. So, yeah, it should not point here. It should point to the STR. Sorry about that. All right. So now our histogram's filled with zeros. We've written eight instructions so far. So I wanted to just make sure you understand when we write this kind of stuff. These memory addresses over here, these are just for us. These do not appear in your code, right? In fact, well, I'll come to the next point. These memory addresses are just for us, just so we have some idea where in memory our code is falling. Just a convenience. You don't actually even write these in your program when you write binary, nor when you write assembly. And so the only time you're going to see these would be in the simulator, really, or on a piece of paper. The other thing I want to make sure you understand is these instructions, well, those are not bits. And at least for now, until next week, you have to write bits. So when you write your programs, these will be bits. Next week, we'll talk about assembly language and talk about assemblers. And then you can start writing code like this and tell the computer to turn it into bits for you. But for now, you still have to think about bits. It's not quite true because I'm not going to turn it into bits for you. But in theory, you should be thinking about how to turn it into bits. All right. So we still have a little bit of work to do for initialization. So we had all these registers, and we needed to set some of them up. So we initialized our histogram. We already initialized R0. It's pointing. Yeah, so it turns out the string is stored one ASCII character per memory location. So it's zero extended up to 16 bits and then stored one character per memory location. Not in binary, so it's a pain to write a file with a string in binary. But in assembly language, there's a directive called.stringz where you just put a string in your assembly file. And then the assembler actually writes one character to memory for you one at a time. So it's actually relatively easy to do so long as you're using the assembler as opposed to writing it out by binary. Yeah, if you looked at the typing in a number code, the messages, the error messages there, you actually did those by hand in binary ASCII in order to make it realistic for what you knew. And it's relatively painful. So if you want to play with this code, figure out how to write a string in ASCII so you can do something interesting with it before you don't do it in binary. All right, so we've got these other registers, right? So we have to initialize the string pointer. We need to point that to, I think it was, 4000 hex. So we'll just take the character from the string. We'll just read that in our loop, right? These ASCII constants we'll have to set up. And then it's temporary. We don't need to initialize. So we need to initialize R1, R3, R4, and R5. Here's some code. What do you think? Is that good? Are those all loading the same value? Why not? It's all PC relative, right? Good. So somewhere in memory, I put in the real offsets for you. Real offsets meaning if you go download the code, these are what they are. But somewhere in memory, I've got four consecutive memory locations that have the initial values for R3, R4, R5, and R1 in that order. And so these four load instructions pull those four sets of 16 bits out of memory, copy them into R3, R4, R5, and R1 in that order. So just want to make sure you understand PC relative does mean something different, does mean a different place depending on where the instruction sits. All right. So finally, we're ready to actually do some counting. So we can do some counting. So let's see, what's the first step? So we said, OK, we need to check if a character is null. So before we can do that, we have to actually get the character out of the string, right? So where was the string pointer again? Remember? Yeah, so I think what we loaded into a register, right? R1. OK. So how do I go get the thing at R1? LDR. OK. So LDR. And I want to put it in R2, right? So LDR, what's the destination register? R2. And the base register? R1. And then the offsets just zero. So this will go to the address R specified by R1. So whatever R1 is pointing to, we started it at the start of the string. Sasha? Because I'll show you, I'm going to play a little trick to use one constant twice. Basically, it's because, you know, there are 26 letters in both sets. So you need one constant for the difference between those two sets. And it's the same. So you can reuse that one. All right. So this is going to go to the memory address specified by R1. We started that at the start of the string. We're going to move it forward. So we'll look at one character at a time. R1 will keep adding one to it. But every time we go get one character out of the next string location, copy that into R2. So then how do I check to see if that's a null character? Do I need to do anything? I just branch, right? Branch on what condition? Oh, sorry. Forgot they're connected. Okay. So if I get a zero, that means I found the end of the string and I can go to the end of the program. But I don't know where that end of the program is, so I'll leave it blank. All right. So now we're ready to classify our character and increment one of the bins. So the first conditional we had was, well, is the character less than capital A? So let's define R3 as negative at sign. Why negative at sign? At sign is down here. So if I subtract at sign from my letter, what that will give me if I have a capital letter is a number from one to 26. So again, if I have a capital letter, one of these, and I subtract 40 hex at sign, then I'll have a number from one to 26 left. And I can use that to tell myself, well, which bin in my histogram do I want to increment? Because remember, those are also in order from one to 26 for A to Z. So we're going to store the difference of our subtraction back into R2. Let's go ahead and do that. So we'll add R3 to R2 and write the sum back into R2. So add R2, R2, R3. So now I can check whether the character was in fact less than capital letter A. So if I subtracted 40 hex and I want to branch forward, if the character was 40 or below, what branch condition should I use? Zero or negative? So branch, ah, that's for letter. I'm sorry, I screwed this up. Oh, I'm sorry. Yeah, yeah. So this is the opposite condition. Yeah. So we're going to handle the case first, which is the non-letter case. My apologies. So your answer was correct, Mohamed, but we're going to do the other case first. Let me go back and be clear on the diagram. So we're going to do this case first. We'll write the code for this first. So we're actually going to branch in the false case. So the condition for this being true was negative or zero. And so to go the other direction, we invert that, just flip all the bits. So instead, we get branch positive to skip ahead to the rest of the calculations. So we'll branch over the code we'll write next with a branch positive. But we don't know yet how long that code is. So if I find a character that's in the left region, the non-alphabetic region, so then I'm over here. So I just need to increment the non-alphabetic bin. And that bin is at 3100 hex. And I have a pointer to that bin in R0. R0 points to the non-alphabetic bin. So I can just increment it. So increment memory location. What's the instruction? Is there one? Yeah, I've got to read it, do a load, add one to it, and then store it back. There's no LC3 instruction that'll do that in one. So I'm going to have to have several. So what's the first one? Load. What kind of load? LDR. Because here's the address. I've got that address in R0. So I can use R0 as my base register. Where should I put it? Where should I put those bits? R6. I said, OK, R6 will be my temporary. I don't want to clobber some useful value, but I need somewhere to put it while I'm adding one to it. So let's put it in R6. That's a good idea. So no instruction. So let's do an LDR, R0, offset zero, and then put the value in R6. And then how do I add one to it? Add R6, R6, one. And how do I put it back? STR. Where? From R6 to R0, base register, offset zero. So these three instructions together will go to the memory location pointed to by R0, which we know is the non-alphabetic bin, add one to it, and put it back. So that will increment our non-alphabetic bin. So now we're ready to... we're finished counting that character. We knew it was a non-alphabetic character because it was less than capital letter A. We're done with it. We just need to go point to the next character. That's some code down below. We haven't written it yet. So we need to branch. So what branch condition should I have? Just always go there, right? So branch NZP, but somewhere. Don't know where yet. So we'll leave that one blank. But one thing we can do, we can actually fill this one in now, right? So what offset should that be? I hope I got it right this time. All right, let's do our counting. So where's PC? So we're going to fill in the offset for this branch. So where's the PC when this branch executes? Sorry, I should be clearer. Yeah, 3010, right? And where do we want to go? 3014, right? Okay, so we'll start here and we'll say 1, 2, 3, 4. It worked. Yeah, so these are, when I'm writing in sort of, this is actually assembly language. So any time we're writing in assembly language, you can use human notation. So the X means base 16, the pound sign means base 10. But you don't have to put leading zeros. Now, they are all two's complement values, so you can put negative signs. You can also just put the one bit. So there are a few ways you can write it. No, this is branching forward. Yeah, this is branching forward. Okay, any other questions or if you like? Okay, all right. So now we just handled the non-alphabetic case on the left of the ASCII table. So now we can take a look and see if our character is greater than capital Z. And if it is, we'll increment the alpha bin. I'm sorry, if it is, we'll go forward and handle this other set of three sets of characters here. If it's not, if it's less or equal to capital Z, we'll handle it as an alphabetic character. And so we want to subtract capital Z, but we already subtracted the at sign. And remember, we subtracted the at sign, we stored our character back. Having subtracted the at sign, we store the result back in R2. So now in order to compare with capital Z, in order to subtract capital Z, what we have to add is at sign minus capital Z. And so this, Sasha, this is where it's going to come in that later we're going to have back quote minus little z, which is the same number because there are 26 letters in both cases. But anyway, that number, let's just put that in R4. And we're going to throw away the result. I just want to know, I want to know, is it a letter? But I want my numbers from 1 to 26 to use to find the right bin if it is a letter. So I'm going to keep the numbers 1 to 26 if it's a capital letter. And so I'll throw away the results of this sum. I'll just use the conditions I get out of it to check whether it's in this blue region or somewhere over here. All right, so we'll compare with capital Z. So we'll add R4, which is at sign minus capital Z to R2 and write the answer, the sum into R6. So add destination is R6. And then the source registers are R2 and R4. So now if the character is not a capital letter, what should my answer be? If it's not a capital letter. So if it is a capital letter, then it should be negative or zero, right? So if it's not a capital letter, it should be positive again. So again, what we just calculated was original character. This add calculates original character minus capital Z. So if that answer is negative or zero, we know it's a letter, a capital letter. If it's positive, it's something else. So branch on positive to somewhere. But we don't know where yet. We've read blank. Okay, so we know, I should have crossed this one out, results not positive, results a capital letter. So what bin should we increment? So we have in R, what is it, R2, we have a number from 1 to 26. In R0, we have the 3100 hex. Yeah, that's right, and you would not have positive. No, remember we threw the answer away. We just used the condition code. Yeah, the number in R2 is still 1 to 26. And that's important, because we want to use R2 as 1 to 26 to get the offset into our histogram. So our histogram pointer, the first bin is 3100, that's in R0. So here's a hint, R2 now holds this. Remember R0 holds 3100. The A bin is 3101. So how would you get 3101 when R2 has a 1, R0 has 3100? Just add them together? Well, what if I had 26? So the Z bin is 3100 hex plus 1A, which is 26 in decimal, so 311A. So could I do the same thing? So all the time, I take R0, I add R2, that now gives me the address of the right bin, that letter's bin to go increment. So 3100, that's an R0, and then plus R2. So R0 plus R2, oh, okay. So you said add, right? So let's add. Where do we put it? I could put it in R6, but then I'd run into problems, because I need some place, when I'm going to go to memory and add a number, I need some place to put that one. So I guess I could use R7, but I told you never to use R7. Yeah, so that's a good question. What about R2? Do I need that anymore? I mean, now I've figured out what it is, right? This is a capital letter. So I know what it is. Can I just overwrite it? I don't need it anymore, right? Once I find the bin, I'm done with that letter. So let's just overwrite it. Let's just throw it away now. We'll put now our histogram pointer, bin pointer, into R2. So now I need to increment the address pointed to by R2. Of course, the answer is no. There's no LC3 instruction for that, but you know what to do, right? So what do we do? LDR, right? Same thing we did before. Before, we wanted to point just to R0. Now we point to R2. So LDR, where should we put the answer? Remember, we need a place. We just want to add 1 to whatever's there, right? So we just need a temporary register to store this value while we're changing it, adding 1 to it. So let's put it in R6. And the pointer is R2, so that's our base register. So this will go to the memory address R2, which remember now is the correct bin for whatever letter we just saw. And it'll pull those bits out of memory, the current count for that letter. So now we want to add 1 to that, which is what? Add R6, R6, and 1, and then put it back. I'm going to put it back. STR, good. So now you can more easily maybe see the reason that I didn't want to put our pointer in R6, right? Because we need another place to keep track of the count when we're adding 1 to it. So if we put that pointer in R6, then we have to put this set of registers somewhere else, right? And we don't have somewhere else. So since we didn't need R2 anymore, we just reused it here instead. All right, good. So we're done with that one. Now we need to jump down to the code to point to the next character. So let's branch always. We don't know where yet, right? But we can fill in that offset. So what is that offset supposed to be? Good. You're getting better than me at counting. Where's the PC? 3016. And where do I want to go? Down here. So let's see. 1, 2, 3, 4, 5. Good. Okay. You were right. All right. So now we can check whether the letter is less than capital A, right? And if it is, we'll increment the non-alpha bin. And if it's not, then we have to go do some more work. So we know it's not in here. We can compare with little a. If it's less than little a, we know it's in this region, right? So how do we compare that? We already subtracted at sign. So we'll add at sign minus the back quote, right? And that will give us the same thing we had before, number 1 to 26, this time if our original character was a lowercase letter. So we'll get the same mapping for our letters as before, but now the lowercase letters will be 1 to 26. Characters down here will be 0 or negative numbers. And then up here, we'll have to figure out later whether we've got one of those. So let's see. So we'll add R5 and store it back into R2. So I'm going to store this value in R5. That was our third constant. So I'll add that offset onto R2, put it back into R2. That'll do our comparison. So under what conditions do we have a character here after that add? Yeah, so negative or 0, right? Because we're subtracting this thing effectively from our original character. So in that case, in the N and Z case, I want to increment the non-alphabet. How do I do that? Yeah, we already wrote that code. So can I just use a branch? Will they? It's a good question. I think the answer is you want to write your code so that they're not. Yeah, so in this case, we're just incrementing the non-alphabet. We don't need to know anything else about the character other than, well, it's not a letter. So this code is relatively easy to get right. For the letter code, we have to make sure that, remember, we assumed that R2 was a number 1 to 26, depending on which letter. So if we're going to reuse that code, we have to make sure the same condition holds. That's a very good question. So in this case, we met your condition, though. We know it's not a letter. And we know that all of the other registers, we never change. Our constants, our pointer to the start of the histogram, stuff like that doesn't change. So let's just branch to it. So we'll branch. What's the branch condition again? Branch NZ, right? And then we actually know where that code is, I think, but it's off the screen. I didn't want to try to cram all the code on the screen, so we'll just save it for later. Besides, I'm getting tired of counting. I'll leave that to you. All right, so one last condition. So I know we're getting very close. All right, one last condition. So these are actually pretty easy, right? So one thing to notice, we want to subtract little z. So basically, we already subtracted back quote, so we need to add this number, back quote, minus little z. But that number is the same as at sign minus big Z. Both of them are just negative 26. So we already have that number in R4. So we'll just add that number in again, throw the answer away. Just use the condition codes. But under what conditions do we have a lowercase letter? So I just calculated original character minus little case, lowercase z. Yeah, so n or z, right? OK, good. So I can, if I want to go increment a letter bin obeying Muhammad's constraint, which is that, well, we better make sure that we have the same rules for the code, which we do. R2 now holds a number from 1 to 26, just like it did before. And so that tells us which bin we want to increment. So then we can just branch to it. So we designed that code to be reusable. So this is what you were asking about. It's important that you do that, that you've got the same set of register value assumptions going into the code, regardless of which way you go into it. Very good. All right, so let's handle the lowercase letters. Branch condition was nz. Go to that. Otherwise, just leave that blank. Otherwise, we know it's not a letter. And so then we can go to the code that handles not a letter, right? Just branch unconditionally. We're done. There we go. OK, so let me stop there. And we'll talk about the rest of it on Wednesday. Sorry for the long break. If you want to just look at the code, it's online. Download it, play with it. And we'll talk about the rest of it on Wednesday. So, again, I'll see you on Wednesday. Thanks. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Byeee. Thank you. Bye bye. Bye. Bye. Bye. See you later. They're leaving me behind. Multiple characters I can't pull out of my own. Terrible. I don't know if I had enough and it went like this. It just goes and it goes. They blew me off, I went to look at the created code. I pulled some data out. There's about 10 bits in it. I figured I had enough and I pulled quite a few. But there are, what about you? We got about ten. Alright. Ok. Do you have any more words in your code? For the maximum number possible?\"},\n",
       " {'ECE120-2016-11-28-LEC-36-slides.mp4': \" So we're going to spend all day talking about control signals. I know you're probably just dying to talk about control signals over break, had no one to talk about control signals with, but yeah, all day. So we'll start by just going through the control signals in the LC3 data path, looking particularly at those that are not involved in interrupt and privilege, neither of which we talked about in our class. So maybe the subset of those that you need to know about and understand. And then we'll look through fetch and decode states and map each of those states to the control signals that need to be generated to execute those on the LC3 data path. And then we'll walk through LDI execution. LDI is one of the longest instructions, so I just figured that's the biggest example. There's another couple examples worked out in the notes, I think add and maybe one state of branch or something. On Wednesday, we'll do control unit design that may go through some of Friday. And then on Friday, we'll start if not finish redundancy and coding, error correction coding, error control coding. So but before we get started, a funny thing happened over break. Go figure. Yeah. All right, so let's go. All right, so that really happened. That was not a fake picture. I don't know why. All right, so remember that the control unit, finite state machine and a processor takes as inputs, the signals coming out of the data paths. Remember, we developed our own little, our own little finite state machine with a data path and a control unit for that to do finding a minimum in an array, right. And so the LC3 is no different. There are signals coming out of the data path that the control unit uses to decide what state to go into next. And then there are also the control signals from the finite state machine or its outputs that go to the data path to execute the RTL using the data path. So let's take a look at these control signals, the LC3 data path. It's in the notes, it's in the back of the book, you can actually get it online pretty easily as well. And we will also of course give you a figure in the test which you've seen before and you can go get it off the wiki if you want to have a copy. We're going to ignore any control signals that are associated with interrupt and privilege. So if you read through the appendix of the book, it will talk about all of the control signals. Many of those you don't need to care about because they're only used for implementing interrupts or implementing privilege in the LC3 processor. If you take 391, so these are probably going to be left out for the most part of even 220. If you take 391 though, you'll make use of both of those ideas in the context of the x86 ISA and you'll see how they're really implemented and used. So let's start by breaking up the control signals in the LC3 into five groups. One group will be the register loads. So a bunch of registers that can be loaded in any given cycle. So each of those will have a load signal and those will be our register load control signals. So we'll go through those first. Then there are bus gating signals. Remember that in the LC3 data path, each of the outputs that can go onto the bus are gated by a set of tri-state buffers. So there are 16 wires on the bus. There will be 16 wires coming out of some given output, 16 tri-state buffers all controlled by one input to decide do those 16 bits go onto the bus or not. And there are actually four sets of those. So we'll have four bus gating control signals. The third set then is MUX selection. So if you remember the data paths, I could have popped up a picture here, but there are lots of MUXs and those are mostly for making decisions about whether to pick a 5-bit 2's complement offset or an 8-bit or a 9-bit or an 11-bit. So all of those MUXs will need configuration when we want to implement some RTL. Often they need configuration, maybe sometimes they need configuration. So those MUX selection bits are also control signals. That's our third group. The ALU, of course, implements add and not. And then there's also a pass mode that some of the RTL needs to just get something out of the register file, put it directly onto the bus. It passes through the ALU using the pass mode. So there are ALU function selection control signals. So that's our fourth group. And then finally, control signals to operate the memory. And so when RTL needs to make use of the memory, we need to tell it do you want to read or write, you need to tell it, okay, enable the memory in the cycle. So there are a couple of control signals for that. So we'll break them into those five groups. So the first group then is register loads. So again, each of the register load signals controls one or more registers. So I say sometimes more. It'll make sense the grouping. So for example, the grouping I had in mind here was the condition codes. NZ and PL have one control signal, you have to load them. They all either load or they don't load. So each of those signals is set, meaning it's one if and only if the RTL for the current finite state machine state changes that register's value. So you look at the RTL and if it changes that value, set it to one, otherwise you set it to zero because you don't want that register to change unless that was part of what you're trying to implement. So let me give you some examples or just actually walk you through each of these. So load signals include the MAR load signal. Do you want to load the memory address registers down here, this next to the MAR of course. The MDR right there. The IR instruction register over here in the control unit side. So the two memory registers, instruction register. This one you haven't seen before. It doesn't actually show up in the main data path diagram. BEN stands for branch enable. So we'll walk through this in detail because we're going to see how the decode state is implemented. But basically in the decode state, the LC3 processor uses these NZNP registers to calculate a branch enable using the IR bits for the little NZNP and then the big NZNP control condition codes here. And it calculates a branch enable bit, should the branch be taken or not. It does that in decode so that in the first state of branch execution it can use that to decide whether or not to change a PC. Yeah, Eric? Yes. Yeah, the state diagram. Yes. Yes. So I'll show it in a minute, but remember that the LC3 has three fetch states and then a fourth one is a decode that then branches out into 16 different states, one for each opcode. So decode is basically looking at the four bits of the opcode and transitioning into one state for each different opcode to execute that particular type of instruction. And I'll show you, again, I'll show you that diagram as we walk through things, pieces of that diagram. Okay, so that's four of them. There are actually three more. So zoom into another part of the data path. So there's LDreg, which is the register file. So only one of the eight registers will change. So which register depends on what input you give on the DR, the destination register input. But if you want any of the registers to change, you need to set LDreg. So there's a load for the register file. There's a load for the condition codes. Typically this thing will be set whenever you're writing, doing an ALU op or a load. Remember that the condition codes are set for the loads and the ALU ops. So here's a load control signal for the condition codes. You'll notice that that's just calculated by whatever value is on the bus. It goes in through this logic and then into the condition codes and is latched there. And then the last is the load PC signal up here on the PC. So there's seven of these different register load control signals. So you might wonder, well, what are these things write? So you can look at the data path for each of the registers and see what they write. MDR's new value either comes from the bus or from memory. A lot of them come directly from the bus. So MAR, IR, the register file and the condition codes, all of their values just come directly from the bus. So whatever's on the bus will get copied into the register. You don't have any choice. If you want to write something into those, you have to put it on the bus first. PC's new value comes from a MUX, PC MUX in particular, with one MUX input from the bus. So that's this one here. So we're going to have to control that to decide what the PC writes when we tell it to write. And then finally, branch enable is just loaded based on CC and IR. Again, it's not in the data path picture, so I won't show you, but it's basically just loaded directly from CC and IR. And so there's nothing to configure. If we tell it to load, it'll look at the current values of the condition codes and the current value of the instruction register. All right. So the second group then is the bus gating signals. So again, you'll see again when I pop up the data path, but a bunch of the outputs are gated to go onto the bus. And so we need to make sure that we only send one one to each of those sets of tri-state buffers. So the tri-state buffers keep those outputs from being written onto the bus. But if we send a one enable signal to a particular set of tri-state buffers, that will put those 16 bits onto the bus. So we need to make sure only one set of 16 bits goes onto the bus. So the register loads, we only set to one, the ones that we want to change. The bus gating, we only set at most one of them to one. If we set more than one to one, we're in trouble. So let's see what they are. So you can just look at the tri-state buffers to see where they're going to be. So there are four sets there. So the first one then is the PC. So we can take the PC register and write its contents onto the bus. So that's gate PC. The MDR, so we can take the memory data register and write its contents onto the bus. So that's down here. The results of the ALU. So if we do an add or an and, or if we pass something from the register file out onto the bus, we turn on gate ALU to do that. And then the last one is gate MARMUX, which is this MUX up here, and its output is gated onto the bus. This is the thing that we use for address generation for memory operations, loads and stores mostly. But sometimes PC relative addressing too, we might make use of MARMUX. All right. So the third group of control signals then is our MUX select signals. So we've got the register loads, the bus gating, and now MUX selection. So we've got a bunch of MUXs, actually six MUXs. So the MUXs are going to be used to control, well, what value do we put in the PC? What's the destination register in the register file? What source register one in the register file? And then what's the memory address that we want to use? There are actually three different MUXs for memory address generation. One controls the source register, one controls the offset size, and then one controls whether we want directly from the IR or we want something out of the adder, out of the memory address adder. So, oh, so the other difference between these and the previous control signals is if MUXs are not used, if the output of the MUX is not used, the input can be don't care. So not the case for bus gating. You can't leave it floating because then if you end up with more than one one, you're going to get shorts. Registers, same thing. You don't want to register to change, so you're not going to leave a register load control signal as a don't care. The MUXs, on the other hand, if the outputs are just discarded, who cares what the outputs are? So we can pick anything. So we can leave their select inputs as don't cares for these MUX controls. All right, Eric. So I mean, the MUXs aren't always even connected to the bus, right? This one just goes into the PC. But this MUX's output never goes anywhere except into the PC. So if you're not changing the PC in a given cycle, this output is ignored. So who cares what it is? Make sense? Yeah. So basically, anytime you have an output that's being ignored, you don't care what the setting on the MUX is because it just pulls some random bits and then it throws whatever the random bits are away. So it's OK. Yeah, and I'll give you details of how you can check to see whether it's used. I mean, this is the example for the PC MUX. The only use is to change the PC. So if you're not changing the PC, if load PC is 0, then PC MUX's setting can be a don't care. And if you are changing the PC, you need to set PC MUX correctly to get the right value. So what can you use for PC MUX? Well, there are only three choices. You can see them there in the diagram. The encoding we're going to give you, right? So don't worry about memorizing it or anything. If you happen to have your sheet later when we figure out bits, then you can look it up. But if we want PC plus 1, this path over here is for fetch, for example, the encoding is 0, 0. If we want to take from the bus, you can see the bus comes down here. You can write that into the PC. That would be 0, 1. And then this line here is coming out of the address generation adder here for branch and jump. That's this path. And that's the 1, 0 input. 1, 1 is not used because we only have three things we need. Okay, so second MUX, the destination register is also MUXed. So there are three choices here as well. Now, if we're not writing to the register file, it doesn't matter what destination register we pick, right? So if we're not writing to the register file, if LDREG is not 1, then DR MUX input can be don't cares. But if we are writing to the register file to get the high bits of IR, the high bits after the opcode, I should say, then we put in 0, 0. If we want R7 or R6, we can put in 0, 1 or 1, 0, respectively. These are actually used for things that we didn't really cover in our class. So the only things that we're going to talk about in our class would use the 0, 0 input for DR MUX. But that MUX is there, so just to explain it. One can also pick different values for source register 1. So source register 1 is the, remember there are two registers you can read from the register file in any given cycle. So this is the left side in the diagram. So source register 1 is then used by both the ALU and the address 1 MUX. So if you are doing an ALU op, right, and then writing that onto the bus, then you need to make sure that this SR MUX setting is valid. Or if you are doing, using the address generation with this as the input, then you need to make sure it's valid. Otherwise, it could be don't cares. So you need to kind of back propagate. If you're using it in any way, then you don't want to leave it as don't care. If you know you're not using it, you can leave it as a don't care. So the choices here, 0, 0, 0 will give you IR 11 through 9. So if you look at the instruction encoding, those are the source register bits for stores. And so this is how you would set up for a store is to pull those bits out as your source register to write those to memory, write that register to memory. For ALU ops, jump, load, LDR and STR's base register, IR 8 to 6, you set 0, 1, and then I'll give you that register. And then finally, the 1, 0 setting will give you R6, which is again, nothing that we've seen. It's actually the changing privilege implementation on the LC3. So you don't need to worry about it. But it's there. Yeah, so these are all clocked. I mean, the entire LC3 data path is on a single common clock, just like all of the other designs in our class. Yeah, yeah, this is still clock synchronous state machine with a common clock, one finite state machine. All right. I mean, the thing to remember, when we talked about the, when we did the example of mapping the code into a finite state machine, I introduced the idea of RTL is that we define the RTL for the state, but the RTL actually happens on the rising clock edge. So the control unit exerts all of these control signals, and then the changes happen on the rising clock edge. So they'll be true in the next cycle. So that's why, for example, this IR somewhere, IR's here. So in the third fetch state, we're writing into IR, but we have to wait until the fourth fetch state to look at the bits in the opcode in the IR, right, the 15 to 12 bits for the opcode, because until the fourth cycle, they're not there. And in the third cycle, we copy them from MDR into IR, but then only in the fourth cycle are they present in the IR to use them. All right, so let's go back. This is the next MUX. This is actually two of the MUXs, two of the three for address generation. The third is the MarMUX, I'll show you in the next slide up there. So the first one here is choosing a source register. So this line comes from SR1, this line comes down from the PC, and address one MUX just chooses between them. So if you configure it to zero, you get PC. If you configure it to one, you get SR1. Now, obviously, if you're not using the output of this adder to write back into the PC or to write onto the bus through the MarMUX, then you don't care what this address generates, right? So you can set it to don't care in those cases. This second one, you can see several sign-extended offsets. So there's a six-bit, that's for base plus offset mode for LDR-STR. There's a nine-bit that's used for branches, and there's an 11-bit that's used for JSR, which you haven't seen. But those three different sign-extended chunks of the IR or a zero, right? And so you can see the four choices and the encodings for address two MUX down over there. Once you've decided those two values, those go into this adder, get added together and go into MarMUX, your other choice is over here for MarMUX. Yes, that should be 10 to zero. Thank you. Yeah, sorry, that's a typo. This one is right. Yeah, thanks. Okay. So on the left here is something we didn't talk about how traps are implemented. If you're interested, it's using this approach to go to this memory address basically. So you take your eight-bit trap vector zero, extend that to 16 bits, and that's your memory address. So that zero mode of this MarMUX is used to execute a trap instruction. All of the things that we know about, we didn't talk about trap implementation. So everything we know about will go through this address adder here and go out through the MarMUX. So that would be setting one in the MarMUX. And that's it for the MUX settings. So those six MUXs. All right. So notice that these two MUXs are used by both the PCMUX, so the output here of the adder gets used by the PCMUX and the MarMUX. I kind of said this already, but if either one of them is used and MarMUX is only used if gate MarMUX is one, PCMUX is only used if load PC is one. So if either of those is turned on, then you have to set these three address generation MUXs. If they're not, you just don't care. You can set them to don't cares. Make sense? Good. Okay. All right. So ALU selection bits. So we have four functions. You know three of them, of course, add, end, and not, we put in as part of the ISA. The fourth one is necessary again, so that we can pass values from the register file out onto the bus to go places like the MAR or the PC for control flow or other operations. So the ALU output is only put on the bus when gate ALU is one. If gate ALU is zero, it's just thrown away. So we can just set the ALU function to don't cares. And then finally, the memory operations. So memory only needs two bits to control it. So it needs to know, well, do you want it to operate? Right? So there's an MIO enable for enable the memory. It's actually memory and IO, which we didn't look at the memory mapped IO implementation, but this is the control signal name. So when that's equal to one, memory does something. When it's equal to zero, memory does nothing. So the read write bit only matters when memory enable is one, right? When memory enable zero, read writes a don't care. When it's a one, it's defined as follows. A one is a write, read write, I'm sorry, read R.W is one means a write, R.W is zero means a read. So that's it for the control signals. So this is just a summary of all the control signals. So we had seven different register loads with four different bus gating signals. The MUXs, there are four two bit signals and two one bit signals. So that gives us a total of 10 bits. So this is number of bits. ALU function selection, we needed two bits and memory, we had two one bit signals. So if you add them all up, you get 25. So every FSM state in the LC3, you have to specify 25 bits to say, well, how do you implement that particular state? Any questions on this before we start looking at examples? Well, you can set them to don't care. But if you're calculating logic to build a finite state machine, you've got to put bits. So just like in any other logic design, it's going to output real bits, however you build it. So in your design, you can put don't cares. The thing you build will make zeros and ones. I don't think so. I compared them before. I compared those sheets with my notes and with this. Yeah. So again, there's six MUXs, four of them are two bits and two of them are one bit. So four times two plus two times one is 10. Okay. Okay, so let's see. So let's do fetch and decode. So this was the top of the finite state machine diagram is figure C2 in the back appendix in Pat and Patel. But this is the fetch part up here, these three states, and then this is decode down here. And then after that, you go into instruction execution. So let's go through these one by one and work out the control signals that we need for each of the fetch states and for the decode state down here. And so hopefully, you remember, you will need to know this on the final, I mean, you'll have the diagram, but you needed to know it on the midterm too. So MAR gets PC, PC gets PC plus one. That's the first fetch state. So let's go think about, well, what do we need to do for the control signals to make that happen? So let's start with the registers. So which of the registers need to change? Which of these values should be one? Yeah, so LD MAR, right? Because we want MAR to change. So make that a one. What else? The PC, right? Good. Okay, what about the rest of them? Zeroes? Not don't care? Yeah, zeroes, right? We don't want the registers to just load random bits, right? So they better all be zeroes. Okay. All right. So now let's take a look at how we would implement this thing. So we want, let's see, MAR gets PC. So PC is up here. So we've got to send it across the bus down here, and then put it in the MAR, right? So it's going to have to go across the bus and go down into MAR. And then the other part was PC gets PC plus one. So here's PC, it goes through this little plus one thing here. We've got to take it through the PC mux and then put it back into PC and do both the blue arrow and the green arrow in the same cycle. So it's worth when you're trying to figure out how to set things up, just looking at the data path and maybe sketching out, well, how are the bits going to move from place to place? Because anytime you go through a mux, you've got to make sure the mux is configured properly, for example. Okay. So we've got these two bits. So what do we put on the bus? PC, right? So you can look back at the picture, right? This gate PC, you got to get the blue line to go through there onto the bus. So that better be a one. So what are the rest need to be? Zeroes. Good. Okay. So those are the bus gating signals. So which muxes matter? Yeah, PC mux. What about Marmux? No. What about this one or this one? No. DR mux and SR mux in there. They matter? You're not writing into register file, you're not using the output, right? So they don't matter. So only the PC mux. So what should PC mux be? The PC plus one, right? Which was zero, zero. So, okay, what about the rest? They're all don't cares, right? Because none of them are used. So we can just fill them all up with don't cares. All right. So what about the ALU and memory? So here's the ALU. Gate ALU is off, right? So it's not used. Memory is down here. We're not doing anything with memory, so it should be turned off. So what should the values be for ALUK, MIO enable, and read write? So let me take them one at a time. ALUK, what should it be? I'm hearing zeroes and don't cares. So remember, the value of ALU is being thrown away. And then gate ALU is off, right? So if it just spits out some random bits, so what? They're just discarded. So it's don't cares. What about MIO enable? It better be zero, right? Because otherwise, we might end up doing a write, right? Especially if we leave read write as a don't care, right? If it's a read, maybe that doesn't matter so much, but then memory won't be ready when we need it. It'll be busy finishing a read we didn't need. So let's just set that one to zero. What about RW? That's a don't care, right? Because we set memory enable to zero. So memory is turned off. No, actually, no. So this is a clock synchronous sequential design, and the clock timing has to be such that the longest combinational logic in the system is slower than the clock speed, than the clock period. And that's the limiting factor, actually, in a lot of high speed processor designs. So in a lot of your desktop or laptop, what sets the clock speed is something like the adder time or the time to do simple arithmetic operations. That's what limits it. So that's, we might, if we have time, I'll show you a tree adder, which is a faster version, it has shorter paths. And those are the those are what people actually use in real processors. Because the ones we looked at things like the ripple carry, they're too slow, right? And they're what set the clock speed. So but in most of these designs, you find your slowest combinational logic, and they don't take more than one clock cycle. If they do, you have to set it up so that it's it's managed across multiple clock cycles. So for example, a floating point unit in a typical modern design might take four or eight, depending on whether you're just adding or multiplying four or eight cycles to complete one operation. But they are usually designed in the high performance systems to accept new operands every cycle. So you can start a new addition or a new multiplication every cycle, but you still have to wait that long to get your answer back. So. Okay, so, all right, so we'd finish this one, right? So we've got we've done fetch one. I just want to make sure people notice this is not a don't care. Right? So don't get confused by that. So now we can go on to fetch stage two, fetch state two, which is this one, right? So now we have the PC and the MAR, we can go get the instruction out of memory, take its bits, put them in the MDR. So this is MDR gets M at MAR, memory at MAR. So which registers are going to change? Just MDR, right? Anything else? That's it. So all zeros, right? Okay, so those are our register load signals. So let's see. So we have MDR gets MAR. So data comes out of the memory and goes through this MUX, which is controlled by MIO enable anyway, so we don't need to do anything there, goes into the MDR. Now, you might actually notice there's this funny path through this other MUX over here. This is part of the memory mapped IO system, and we didn't talk about it. So, so just ignore that part. There's actually simpler diagrams of the data path, but this is the one I had. So I just kept this one. This MUX will be configured to forward this output back. So the path is okay. So what should be put on the bus? Nothing, right? We could technically probably leave one as a don't care, but let's not do that kind of thing. Because then we have to worry about well, so what bits go where? So we'll just set them all to zero. So nothing's on the bus. It's just floating. So what MUXs matter? Yeah, this one is set though, right? This is not in our control. This one does matter, but MIO enable, we're going to have to make sure it's turned on to get the memory output into the MDR. This path is actually what we use for stores. We set up the MDR before we write the bits into memory. But when we're fetching, we need to read memory. So that's coming through here, and it's already going to be controlled by MIO enable signal. So do any of the six MUXs we talked about, PC MUX or address one or two MUX or SR1 MUX, do any of those matter? There's nothing going on in that part of the data path, right? That's all just nothing. It's all turned off. Not turned off, but there's nothing going on. So none of them matter. So what should I do? Just set them all to don't care, right? Put all don't cares there. Good. What about ALU? ALU is not used, right? But memory has to do a read. So what should I put here? So what about ALU? Don't cares. What about memory IO enable? A one. What about read or write? Zero for read. I did them one at a time. Thanks. Okay. So these are then the settings for memory. We want to turn memory on and tell it to do a read. ALU, we don't care. It's being thrown away anyway. So that's it for the second fetch state. So what about the third fetch state? So we finished this one. We finished this one. So now we have to write RTL, well, write control signals to implement this RTL. So we take MDR, copy it to IR. So let's take a look. So what registers are going to change? Just IR, right? Anything else? It's just that it. So a bunch of zeros. So here's the data path. So MDR has got to come out across the bus, go into the IR. There we go. So what should be, which gate bus gating signal do we need to set? MDR, right? Anything else? Better make sure the rest are zero. You can never have more than one bus gating signal turned on. Okay. So which MUXs matter? None of them. Because all the MUXs are up here in this part that I didn't even show. So all don't cares, just like the second state. Okay. What about the ALU and memory? Not used, right? Memory is down here. ALU is over here. Not used. So what should these be? Don't cares here. Zero. And don't care. Same as up here, right? We're using ALU or memory. All right. So that's it for fetch. Fetch is done. And then we have one more state to do, which is decode. So in the decode state, we're calculating branch enable. And branch enable, you might remember the little n bit is IR11, the little z bit is IR10, and the little p bit is IR9. So I just took the same terminology, or rather the same RTL out of the FSM diagram out of Pat and Patel. But when we've written it, it's been little n anded with big N, little z ended with big Z, little p ended with big P. That's our branch condition. So that is calculated by some logic that's not shown in the data path and then copied into branch enable in the decode state. So which registers are going to change? Just branch enable, right? So what do we do with the rest? Zeros. Good. OK. How about, let's see. So I can't show you in the data path because there's nothing there. It doesn't show up. So just calculate directly from the condition codes in the IR. So what should I do with the bus? Just zeros, right? There we go. Zeros. Yeah, there's nothing flowing across the bus. There's some special combinational logic, takes the bits out of NZAP registers, looks at IR, does some combinational logic and writes into branch enable. So there's nothing that's going on the bus. What about mux selection? Do we care about any of them? There's nothing being used, right? So we don't need any of them. So just don't care about any of the selection bits. What about these? Yeah, so. So remember in the branch instruction, so let me get that back up. There it is. In the branch instruction, we've got encoded in the instruction, the parameters for which of the condition codes we want to consider. And we write them as little n, little z, and little p. And so IR11 is little n. IR10 is little z. And IR9 is little p. Yeah. That's part of the instruction. The IR is the instruction. Yes. So no, I take it back. Branch enable, one reason for writing it in decode is it's ready to go when you execute the, when you get into the branch execution. If it's not a branch, you don't need to look at it. So it's just like the mux selection bits. If you can calculate it, then you just ignore it. It doesn't matter. So you're actually, the LC3 is in fact calculating the branch enable for all instructions, but only using it for branch. And it'll just be garbage for the rest of them. It doesn't matter. Yeah. Yeah, it's in the control block. It doesn't appear in the data path. That's why I didn't highlight it for you. It's not there. I think there might be a separate figure in the back of Pat and Patel, but I didn't pull it out. Yeah. IR is the instruction register at 16 bits. IR is not signing. It's a long way back to a full data path. The sign extension is for the two's complement offsets that are fields of certain instructions. The instruction register itself is 16 bits, and it takes all 16 bits to represent an instruction. It's pulled out of memory. Remember, it's pulled directly out of memory through the MDR, from MDR directly into IR. It's never sign extended in the fetch path. Yeah. Okay. That's no problem. Okay. So where were we? I think we've done these, right? We've done these. All right. So what about these? So all we're doing is calculating branch enable and decode. The whole reason for decode is so we can get to, we can look at the opcode and get to the start of the execution state for the correct opcode, right? So do we need to do anything with ALU or memory? No. All right. So what should I set these to? XX0X? They're not doing anything in that state. Okay. Yeah. Yes. Yeah. So that was the question Sasha asked earlier. Yeah. So branch enable is calculated before you've decoded, right? During the decode state. So you don't know what kind of instruction it is. You don't even know if it's a legal instruction, right? Because not all opcodes are legal instructions. So you're going to calculate it every time. But it's a garbage bit. It's a garbage bit. You only use it if it's a branch. You're always going to calculate it and then just ignore it unless it's a branch instruction. Any other questions on this? Okay. So I think that's it, right? That's our four. So these are the whole table with all four fetch state and decode state and all of the signals. So that one's in the slides for you. It's not really something we need to dwell on here. Any more questions before we look at LDI execution? Okay. So let's do LDI execution. All right. So here's execution of LDI. It starts up here. These are other loads. So just ignore these two states. LDI comes down here and then goes all the way down to this, which is one, two, three, four, five states, right? So it takes five states to execute an LDI. So let's work out all the control signals for those five. So we'll start up here in the first execution state. We'll call that LDI one. And what we have to do there is take the nine bit offset. I'm just using the RTL from the FSM diagram. This is sign extended from nine bits in the IR, then added to the PC and then stored in the MAR. So what registers change? Just MAR, right? So the rest should be what? The zeros. So let's look at what happens. So let's see. We have MAR gets PC plus offset nine. So offset nine needs to come out of the IR. I don't know if you can read it, but there's a sign extension of the eight to zero bits here that will go up into address two MUX. So we're going to have to pick that sign extended version out of address two MUX, and that'll go into the address adder. So that's step one. For PC, it's going to have to come down this way and go through address one MUX. So that's this direction. So then those two get added together. PC is green, offset nine, sign extended to 16 bits is blue. Those get added together. That has to then go through the MAR MUX, across the bus, and then down into the MAR. So that's purple. So we need those three parts. We have to configure all of those parts so that this data flow works through the data path. All right. So what do we need gating? The MAR MUX, right? So up here, this thing needs to go out on the bus. So MAR MUX needs to be a one. What about the rest? Zeros, right? Again, only one gate signal should be on. If you write on the final, multiple gate signals turn on. I'm going to cross it out. So don't do that, please. All right. So what about the MUXs? Which ones do we care about? Yeah, the address MUXs, these we better set up. This one we better set up. What about PC MUX? Not used, right? PC is not changing. And that's only used if we're going to change PC. What about DR and SR1? They're not used, right? So we can ignore those MUXs, too. So those three we need to set, and then the other three we don't care about. So let's just fill in the don't cares. So those three we don't care. What should address 1 be? Does anyone remember or have the encoding? I don't even remember it. Okay. Zero. What about address 2 MUX? One, zero. Okay. And then MARMUX? Pretty sure this one's a one. Okay. But again, you know, the right thing to do here would be to look at the table, which would be in the back, right? So you should always keep the table with you. Don't try to memorize this stuff. Okay, so those are MUX selection signals, and that will implement these three lines here to move the data around. The ALU and the memory are both unused, right? So what should these values be again? XX, zero, and X, right? Good. Okay. Second LDI state is this one here. Take memory at MAR, copy the bits from memory into MDR. Does that remind you of anything? Second fetch state, right? Good. Okay. So we don't really need to do the RTL again, right? We did it already. So we know how to do that RTL. We just take the bits we already wrote, copy them into this one for the same control signals. Okay, so the control signals here were MDR changes, so we'll just fill that in. The control signals here, let's see, I think, I think nothing, right? Yeah. For this one, we weren't using any of the MUXs, so they were all don't cares. And then for this one, we have to do a read, so that's a one, read write is a zero for a read, and then ALU is not being used. So all they did was copy the bits out of the fetch to state, basically. Same RTL, same control signals. Okay, so then we're in the third LDI state, which is one, two, three, this one here. So we're going to take MDR and copy it back to MAR. Remember, LDI is the one that says, oh, I got 16 bits out of memory. Oh, that's like an address. Let me go read from that address, right? So you're going to copy MDR over into MAR and then do another read. So let's go figure out how to do that. So MDR goes to MAR. So which registers am I going to change? Just MAR, right? Good. So the rest, zeros. Okay, so here's the data path that would happen. So we're going to take MDR, copy across the bus into MAR, like that. So what needs to be gated onto the bus? The MDR, right? That has to go into the bus so we can copy it into MAR. So the rest are zeros. Which muxes matter? None, right? All the muxes are up in the data path above this little part here, and we're not using any of them. So what should these signals be? All don't care. All right. ALU and memory are not used, right? So here, XX, zero, X. All right, well, we're three-fifths done. So now we have state four. So one, two, three, four. So we're down here. This happens to be used by the other loads. So let's see, this one is LDR, this one is LD. So this is used by all three types of loads, but it's going to take memory at MAR, copy it in MDR. We did that one already, right? Same RTL. So why do we need more than one state? Eric? Yeah. Yeah. So it actually, you can come from different places and go to the same state just like these do, but what matters is actually the output path, right? So remember when we talked about merging states, we said, well, if they're the same outputs and the same next states, right? So these have the same outputs, right? The outputs, remember, are the RTL. The RTL is identical, right? But the next states are not. And that has to do with what you were saying, Eric, about setting things up for the addressing for the different modes. But unless the next states are also the same, we can't merge the states. All right. So we have to go implement this RTL again, or rather, we need to copy the control signal bits because it's the same. So let's just do that. So all we're going to do is copy from LDI2 down to LDI4. So there, that's done. Done again. Done again. Done again. All four are done. All right. So now we have one last LDI state. It's this one here. So copy MDR into the DR. So we finally have the value we've loaded from memory sitting in MDR, 16 bits. We want to copy it into the register file, store it into some destination register specified by the instruction, and set the condition codes based on that value. So what registers are going to change? So the register file, right? So I better put a one there. And what else? The condition codes, right? So I better put a one there. What about the rest? Just all zeros. Okay. All right. So then let's look at the data path. So how do these things work? So we've got a copy from MDR across the bus and store that into the register file. The only way we can write into the register file from the bus, right? So go along that blue path. And then the other half is set CC. So remember, the condition codes are always set by what's written on the bus. So this green arrow is just coming off what we've already written onto the bus, going through this little block of logic here and then being stored in the condition codes. Whatever value was being stored, it would be calculated negative, zero, or positive and latched into the condition code registers. All right, so what do we need to gate onto the bus? MDR? And then the rest better be zeros. Okay. So which of the muxes matter? Yeah, so DR is going to matter, right, because we're writing into the register file. PC mux will not matter. The address generation muxes won't matter. They're all being thrown away. And what about SR1? Are we using it for anything? No. So that's not going to matter either, right? So only DR mux is going to matter. So DR mux needs to be set to take the input from the, I think, 11 to 9 bits for the source register in the store. So that'll come with a zero, zero setting on DR mux. And then the rest of them are don't cares. So you notice we almost never use too many of the muxes in a lot of these things, right? Occasionally we'll have to set some muxes up for address generation or things like that. But often they're all don't cares. All right, ALU and memory are both unused. So same as before, XX0X. So that's it. So there's our whole table. So yeah, in order to implement an LC3 processor, you have to go through the whole state diagram and do this. But as you can see, a lot of it's pretty easy, right? So on Wednesday, what we'll talk about is then taking all of these tables with all of the RTL and thinking about, well, what are the different ways we can take those bits? We won't do them all. But what are the different ways we could take those bits and then actually build the control unit? So we'll look at a few different ways to do that. Any closing questions before I end? Okay, thanks.\"},\n",
       " {'ECE120-2016-11-09-LEC-32-slides.mp4': \" Okay, I think it's three o'clock. So today we're going to start with systematic decomposition. So try to give you a way to think about breaking problems down into pieces and do that until you get to the level of instructions. You've already done a little of that in the lab, I know, but this is supposed to be a little more systematic, hence the name. I'm going to spend some time, probably most of today, just talking about what does it mean to do a good job of designing a piece of software, mostly just to tell you that you'll take classes later, so don't worry too much now. I'll give you a couple hints of things, habits you can start to form now. Then I think either we'll start this or it'll come on Friday. We'll do another big example, calculating letter frequencies in a string. So we'll take a string and count up the number of each kind of letter, independent of case, and also the number of non-letters. So we'll spend some time thinking about how we want to do it, we'll decompose it systematically, and then we'll write the code for that. That'll be our last example, actually, in binary, and then we'll talk about assemblers next week after the review session. So review session's Monday, as you hopefully remember, midterms Tuesday night. I have actually information, so the Beta Kappa Nu review session, they move back an hour relative to last time, so it's 3 to 5 now, same day, Saturday, same place. As always, we can't guarantee that they're going to give you correct answers, but usually they're pretty good, but we can't guarantee it. And then there's other resources up here, so I think you've seen these before. You know this slide. Two more times. Well, one more time, sorry. Deadline's Friday. If you haven't done it, please do it. All right, so how do you write a program? So you've seen a few examples so far, but it'd be nice, given a task, how do you break it down? How do you turn it into a flowchart, turn it into LC3 instructions? It'd be nice if there were some systematic way to do that. How did we do it? Well, systematic decomposition is an approach to trying to program. It's basically saying, well, let's take our task and refine it. In the book, I think they refer to it as stepwise refinement. But basically, take your task and say, OK, let's break that down into simpler things. So let's start, we'll just take the main task, whatever we're trying to do in human terms, and break it apart, and then we'll take those things we broke it into, and if they're still too complicated to do with one, two, three handful of instructions, we'll break it again. We'll keep doing that until the end result is something where every little piece can be implemented with a few instructions, a few LC3 instructions. So it's actually not a bad approach to doing things. You'll see later, it's not actually terribly systematic, but it can help you think about what you can do. So I want to go through the pieces, and then show you how we map those into LC3. You've seen them all before at the start of class. So we'll talk about these pieces, three kinds of simpler tasks, and then look at how we map each one of those pieces into LC3 memory. So before we start that, I want to make a couple comments about programming in general. I talked to people in office hours yesterday. Generally speaking, you really want to get out a pencil and paper before you start sitting in front of a computer and writing code. Sitting there trying to look at bits, especially, is really painful, and you'll get yourself very confused. You really want to go in before you sit down to program, having an idea of how your program will work. And usually what that means is you drew a picture on a piece of paper, you wrote some notes about what each register holds, so you know what's in the registers, instead of just sort of making it up on the fly as you write instructions. If you have your algorithm clear in your head, and when you sit down, you've got your code in the LC3, you can simulate it when it does something wrong. I say when, not if, because everyone writes bugs. Then you can say, well, what was it supposed to be doing here? And then you can figure out why it's not working. Much easier to debug your code. In fact, this is a little bit of a forward illusion, because when you get into writing larger programs, it's very, very easy to have a bug in your code and you can't find it. Because you look at your code, you're not actually reading the code. You're thinking, yeah, this is what I meant to do there. So having someone else come in and look at your code, they look at it and they don't know what you're meant to do. They only know what the code is. So there's a practice called code reading, where you have someone else come and look at your code. And it's much, much easier for them to say, well, this is broken. Because for you, you can sit there for literally hours. And it looks right, because you're just looking at what you had in your head. But if you have nothing in your head, then it's even harder. Make sure you have a model in your head before you go sit down and do it. So draw some pictures, draw some flowcharts, think, then sit down to write your program. So when you do get ready to write your program, I would suggest, especially when you're starting out, that the first thing you do is take all of that model and write it out in English as comments. So say, well, first I'm going to do this. Next, I'm going to do that. You're going to want to put those in anyway. Because when you hand in your code or when you hand it off to someone else, we expect you to write some comments. So put the comments in first, and then write the code around the comments. You'll find it's much easier that way. Don't leave comments as an afterthought. Comments are not something you add so you can get those last five style points or something like that. You should try to do it this way. Actually, so there's a story. And I've forgotten the student's name. But it was one of Wenmei Hu's master students. So they had some tricky code that they needed added to their compiler infrastructure for x86. So the student came in, and he did his master's adding this code. It took him about a half year or a year to add the code. And then maybe about six or eight months later, he started working on his PhD. And it turned out they had to make some changes to another part of the compiler. And that didn't interact correctly with his code, his module of code that he had added. And so they said, well, can you go adjust it, make changes to meet the new interface of the compiler? He said, sure, sure. So he went back, and he looked at his code. He kept looking at his code, and he didn't have any comments. And he realized he couldn't understand his code. So he had to throw it away and start over. So don't do that to yourself. Make sure you can make some notes about what you did so that when you go back and look at your code, you can understand it. So systematic decomposition. So what do these three things we can use look like? You've seen them before, actually. So they're just the same flowchart pieces we looked at with C code. They correspond to C statements. The iterative construct you'll see is a little bit simpler. So here's the first one. So you can say, well, I've got my task. And in order to accomplish this task, I need to do several things. And I can just do them one at a time. So it's just a sequence. So I say, well, first I'll do the first one. Then I'll do the second one. Then I'll do the third one. Maybe there are two. Maybe there are five. Maybe there are 100. It doesn't matter. Just a sequence of things. So I can break the task down into a sequence of smaller tasks, each of which is easier to do. So that's first approach, first pattern. The second pattern is the conditional. So we can ask the question, well, what if in some cases I want to do one thing, and in other cases I want to do another thing? Then I can have a condition. So I can have this test condition, phrase my condition so that it's either true or false, some kind of Boolean expression, not in bits necessarily, but some kind of Boolean expression. And it either is true or false. And if it's true, I'll do this then subtask. And if it's false, I'll do this else subtask. So that's the second pattern. We can take a task and break it down into a conditional. Either of these boxes could be empty. So you could say, well, if the following is true, I want to do something. Otherwise, I don't want to do anything. That's OK. These boxes don't have to both be filled. What if you have more than two cases? You could say, well, sometimes I want to do thing one, other times thing two, other times thing three, other times thing four. Well, you can just keep breaking these things down. So you can take your else subtask, for example, and break it down into another conditional. And now I have three cases. I've got the test condition. One is true over here on the left. One is false, but two is true here. And both one and two are false here. And if I wanted four, I could also break down the then case over here. Or I could break it down, break down this case or that case. So I can just keep breaking things down over and over again and have as many different cases as I want based on these conditions. So the last one, the last approach, or last pattern, rather, is the iterative pattern. So this one you saw is the for loop in C. This one is substantially simpler. So you say, well, I want to do something a bunch of times. I want to do it until this test condition is false. So I'll test. And if it's false, I'm done. And otherwise, I'll do the thing, the subtask. And then I'll go back and do the test again. So this is simpler than the for loop. The for loop, remember, had some initialization and some update. You could add those in. You could break this first down into a sequence where you did your initialization, then add this iteration, and then take the subtask down here and break it up into whatever you wanted to do, and then an update. So you can reconstruct the for loop out of this systematic decomposition process. But your basic iteration is, well, test for something, do a subtask, go back, test it again. Keep doing it until the test becomes false. So those are the three pieces. So flowcharts are nice, but you can't just kind of cram a flowchart into memory. Memory is this linear sequence of addresses. And you know that the LC3 is just going to go address to address and execute instructions, maybe that have some control flow or something like that. But you can't draw diamonds or boxes or start things or things like that. So how do we turn a flowchart into a sequence of instructions? Let's take a look at each of these three constructs, and we'll then show how we turn each one into LC3 instructions. So sequential is pretty easy. The LC3 and fetch, it'll add one to the PC. So if you just lay instructions out in memory, then here's your tasks. If you say, OK, let me write the instructions for this first subtask, and then the instructions for the second subtask, I'll just put after the ones for the first subtask. And then for the third subtask, I'll just put after the instructions for the second subtask. The LC3, if it starts up at the top here, will simply run through first subtask, second subtask, third subtask, and we're done. So this is the simple case. So for the conditional construct, we have to be a little more careful. So of course, there's instructions associated with each of these three pieces. So we might put the test first. So we'll generate the test, and then we can generate the instructions for the subtask, for the then subtask, and put those here. And then for the else subtask, we could put those instructions down here. So what else do we need? Is that OK? Just do it this way? Yeah. So some kind of branch, right? So maybe here, I can branch on false. So I'll set up whatever NZPN bits, NZNP bits, based on my test. I'll set NZNP to the right values. So this is branch is taken, is the branch opcode. This branch will be taken if the test is false. So if the test is false, where do I want to go? I'm going to go to else, right? Good. OK, so now am I done? Why? Because you want the subtask. So if this test is true, then I don't branch, and I execute my then subtask. So that's good. Then, oh, then I'd fall through, right? Then I'd start executing the else subtask. OK, so what should I add here? Another branch. What kind of branch? I'm hearing different answers. So is there any case in which I want to go execute else after that? No. So I always want to jump over the else instructions, right? OK, so let's put 111 for safety. I mean, it might be the case that as the last instruction, you always load a negative number, in which case you could have a different set of bits here. But why bother? Don't make it dependent on this code. Just say, OK, I'm always going to branch. Where do I branch to? Down under here, so out of my instructions for this construct on the left. OK, good. So this is how I would set up a conditional construct in LC3 memory. So I need a couple of branch instructions. And if these pieces of code get too big, I can't use branches, right? I'll have to replace them with jumps. But that's something we'll worry about when you start writing huge amounts of code, which won't be in our class. All right, so then the last one is the iterative construct. And this has two blocks of code. So we can write the instructions for generating the test, write the subtask instructions. And what else do I need to add? What should I put here? So I generate the test. Should I then just go execute the subtask? I should branch. Branch on false or true? On false, OK. So if the branch condition, I'll set this up so that the test is false. If the test is false, where will I go? Down here, underneath, right? OK, good. And so am I done? What else do I need? Ah, so I need to go back from here up to this up here, right? OK, so branch, what conditions? 1, 1, 1 again, right? So always branch back up, do the test again. Only after this test is false do we jump down to the bottom, get out of this block of code. So this is how we linearize our three constructs to put them in memory. All right, so here's the bad news. So systematic, the word in English suggests that you just follow some formula. You apply some rules. You don't have to think too hard. You just methodically go and break down, break down, break down. Unfortunately, that's not the case with this, right? So computers cannot program for us. If this were so systematic, then we could just tell the computer, well, just break it down, right? Take the task, break it down, write the instructions, and we're done. But unfortunately, it's not the case. So usually, you'll have a lot of choices, which means you'll have many different ways to solve a problem, different algorithms. And you have to think about, well, maybe some algorithms are better than others. We haven't even talked about what does it mean to be better, right? What's a better algorithm? So we'll talk a little bit about that in the next couple of days. But don't worry too much. Learning to program all takes a lot of time. So this is a first class. We've seen programming for a lot of you. Don't worry too much if you're not getting the greatest algorithms out when you sit down to write your lab. It's not that big of a deal. We will try to push you to do things like loops instead of making 10 copies of something. But other than that, don't worry too much. All right, so let's talk a little bit more about good design. So a couple of things you should think about just starting off as you start to form habits of writing programs. One is, if something is simpler or feasible, then it's probably better. If you're not sure if something is going to work, don't try to do it that way. Find a way that you're sure it's going to work and write the code that way. Once it's working, then you can go do your improved design after you commit your code to some version and the working version. The other really bad thing is when you get your code working, then you think, well, I can make it better. You make it better, but you break it. And then you don't have a copy and subversion. You no longer have a working program. So always, always commit after you make your first code work. But if you have a simpler approach, it's probably a better approach. It's easier to read. It's easier to write in a way that you know your code works. So simplicity is good. Avoid making things more complicated than they need to be. Try to use clear, obvious techniques. Second bullet, you want your program to be easy to understand as well. So take the time to do things like style, structure, indentation, comments. But also organize your functionality so that it's easy to go test it. Write your code in a way that you can make sure that each piece of your code works and that you can also do system-wide testing. So I'll give you some specific examples maybe at the end of today. But think about how am I going to make sure that what I wrote actually does what I wanted. So think about that as you think about your design. All right. So here's an example just to get you started thinking. So imagine you want to do a survey. So I'm going to do a survey of n people in a room. And I want to ask them 20 questions. And they're all going to answer from 1 to 5 for each question. So then I want to take all those answers. And I want to calculate the average over the n participants. So we're doing some important public opinion poll. So how are we going to do this? So you can do this the usual way. We'll call it method one. So I make a form. And I put all 20 questions on the form with 1 through 5. You can circle. And I hand each of you a piece of paper. And then you circle your numbers. And then we collect them. So then what do we do with that? So we've got a bunch of forms. We've got maybe 80, 90 people in the room. And we've got a bunch of forms of 20 questions on them. And how do I calculate the averages? So do I iterate first over the questions or iterate first over the forms? So for example, here's a couple of ways to do it. So question first is on the top. So I say, well, for every question, I go through all of the forms. And I add up that number from each form for that question, so f of q. And then when I'm done with all the forms, I divide that number by n, the number of forms. And that gives me an average for that question, which I can then print out and then go on to the next question. Or I can do the form first. So I can make an array of all zeros, so 20 zeros. And then I'll take a form. And I'll add for each question, I'll add one number into one of my array elements. And then I'll put the form away. And I'll get the next form. And I'll go iterate over forms first. Then when I'm done, I'll take my array. And I'll divide each entry by n and print it out. And that'll give me the average of all the questions. So which is better? Well, so if I iterate over questions first, I only have to remember one sum at a time. Maybe I even keep the sum in my head. So that's nice, a little easier that way. On the other hand, if you think about just moving paper around, now I have to go through these forms, all of the forms, 20 times. So that's 20 n forms I have to get out to look up, you know, question 15, question 16. I have to look that up every time. That's kind of a pain, a lot of paperwork. But what about this other approach? What if I iterate first over forms? Well, then I have to keep track of 20 sums. I can't keep track of 20 numbers in my head. So I'm going to have to have another piece of paper that has my numbers on it now. On the flip side, I only have one form at a time. And I read the questions in order. So I get a form. I go one, two. Very easy and very fast. So there are pros and cons to both. But well, why did we have to do it that way? So here's another way we could do it. We could have 20 pieces of paper, one for each of the 20 questions. And I could say to everyone in the room, well, make sure that you come up and put a number from 1 to 5 for your vote for each of the 20 pieces of paper. So if we do it that way, then we can do this algorithm. For every form, every question, set a sum to 0. And then for each person on the form, each number written down on the form, we'll just add to our sum. And when we're done, divide by n. And then we get the answer. Then we can go to the next piece of paper. So get kind of the best of both. So one sum at a time. Each paper has one sum. And we only have one form at a time, because you just read all the answers off of one piece of paper. So why don't we do surveys that way? Which one is better? Depends what we say, better, right? So what's better about method one? I mean, why do you think people don't do surveys the second way? Why don't we just say, look, I'll post a piece of paper up here. And everyone come and put a number on there. Right? Yeah, so there's confidentiality issues, sort of. I mean, if all you're going to write is a number from 1 to 5, that's probably as anonymous as giving you a piece of paper where I can maybe even coordinate your answers. Yeah. Yeah, so more typing. OK, but we're doing all this by hand. So yeah. Yeah, yeah, so participation is probably going to drop. And I have no real way to gauge it. I've got a form with a bunch of numbers on it. So I can't say, well, you didn't actually do your form. Whereas if they make you turn in a form, I mean, we didn't say this would be anonymous. I could have even have you put your name on it. So if I don't get an answer sheet from you, I say, ah, you didn't want to participate. So there's a bunch of different things. Good answers. So easier to organize. So I can say, well, I'm going to put my name on it. And I can say, well, I'm going to put my name on it. Good things, good answers, so easier to organize. Because if I really ask everyone to line up and find 20 pieces of paper, it's pretty challenging just to say, well, did I get all of them? Are you going to remember which of the 20 you held? You probably need a piece of paper to keep track of them too. Easier to avoid cheating. So what about the person who comes down? They really think this question is important. So they write 55555. Who stops them? How do we know it was them? Participation too. So how do you know whether someone participated? How do you encourage them to participate? Because the work's all on the people now. So well, you've got to go track down that last sheet of paper. So there's a bunch of reasons that we wouldn't want to do it that way. But just out of this simple question, there are lots of different trade-offs for the different approaches. So that's kind of my point. It's not easy to know, well, what's the right way to do something? There are many, many ways to measure goodness for algorithm design. I hope you're ready. It's been a long lecture so far. Bits. No bits yet. OK, you ready? I need your help. Can someone help me out here? Anyone, just raise your hand. Who wants to help me? Yeah, Daniel. So B to C. Good. I can do that. F, good. G, good. H, like that? Awesome. That is good. That is really good. OK. Thank you. That was helpful. Is that OK? You can be assistant walking director. That's a better idea. Is it good? Can you do this? OK, teach my computer. OK. LC3 instructions, anyone? Do I look like I'm in good shape? Yes, it has to be the shortest path. I don't want to walk all around. I want to go straight to strawberry fields. I'm already hungry. Yeah, but I'm not. I'm in my office. This has to be independent of those kind of things. All right, anyone? Any ideas? Yeah. Oh, that's a good idea. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. That's debatable. Oh, so you want to just give me, for this map, you'll give me all the answers? Because I actually have the Google Maps database. If you could just fill in all the answers for that, then we're good. All right, so I have an idea. Too late. Too late if you know a good answer. So we're going to list all the paths. So this is step one. We'll just list all the paths. Then we'll measure all the paths. Then we'll pick the shortest one. Sound good? Come on. Let's try it. So we need a more complex data structure, which is, yeah, that's beyond what I want to talk about now. Let's just figure out how we do it. We can map it to LC3 later. So list all the paths. So let's see. I'm at B. If I can go to A, I can go back. Good point. And then I'm at B. If I can go to A. And then go to B, A, B, A. How long are you going to let me go here? All right. So that's maybe not that. All right, so that was a little silly of me. OK, so let's do simple paths. A simple path in math is one where you only visit any node once. So we'll only list the simple paths. So OK. Yeah, this one's infinite. The one I was showing you is infinite, right? So that would not be a path that would take us. So I won't list that. That would take me to H. Yes. So you can end up, Benny, right? Yeah, so Benny's pointing out that if I take simple paths, I may run into a dead end. So that's not a path to H. So I won't write that one down. Yeah, yeah. But I want strawberry fields today. You guys think I'm so flexible. All right. All right, so let's try this again. So I'm going to start at B. And then I'll go to, say, C. And then I'll go to F. Oh, this is good. This is good. And I'll go maybe over to E. And then how about down to L? And then M. And then N. And then G. And then H. There's one path. All right, now we've got some more paths. Thank you. OK. So it turns out, yeah, that's some bad news. Turns out that for some graph with p nodes, the number of paths is actually exponential in p. So I had another good idea. Are we good? Maybe not. You didn't seem excited. All right, so here, let's try this. This is my last try. So let's have a queue of nodes. And then we'll keep track of the best previous location. So for every node, we'll say, well, it came from some other node. And then we'll go through the queue one at a time. A queue is just a line. So we'll go through the queue and process the nodes one at a time. And we'll add any unvisited neighbors from that node to the queue. We'll just put them into the queue. So I'll show you what I mean. So here's our queue. And so we haven't put anything in yet. Here's the previous for each element of the queue. So we'll start here at CSL. And we'll put that in the queue. And it didn't come from anywhere. That's where we started. So I'll just put a little dash there. All right, so let's process node B. So where can I go from node B? So A first, right? So I'll put that one in the queue. And then D. All right. And then E. And then one more, so I can go to C. OK, so what we did to process the element is we said, well, for everywhere we can go directly by walking around one edge, we'll add those nodes to the queue, but only if they weren't already there. And so remember this caveat here. Only if it's unvisited, so only if we haven't already put it in the queue. So there was our first exploration. So B was finished. So now that's done. So let's go on. The next element in the queue is A. So let's explore node A. Where can we go from A? We can go down here, right? Yeah, we already saw D. So we're not going to add that to the queue. It's already there. We can also go to B. B is also there. All right, so we're done. Nothing to do for A. OK, so A is done. So what's next? D, good. OK, so we can go to K. So we'll put K. Now, notice that K came from D. We're processing D now. So to get to K, we'll come from D. So we'll put D down there instead of B, like we did for all these others. All right, so let's see. K, what's over here? E. So we've been there, right? Then we can go up this way to B. Been there. And then we've got one more direction, right? Been there too. OK, so I think we're done with D. D is done. And what's next? E? So we can go left to B. Already there. Go down to L. And that one's not there yet. So we'll add that in. And we'll say, well, we came from E. Coming from E to L. We can go over to F. That one's also not in our queue yet. So we'll add it in. So F comes from E also. And then we can also go up to B from E. But B is already in the queue. All right? Then we'll do C next. So from C, we can go to B. But that's there. Go to F. But that's there. So C is done. OK, next is K. Where can we go from K? To J, huh? So we'll put that one in. So J comes from K, because that's a new one. We can also go to L, right? But L's there. It's already here. And then we can also go to D. But of course, D is there. That's where we came from, K. OK, so K is done. Not too much more, but we still haven't gotten to strawberry peels. I'm a little disappointed. All right, so what's next? L? L can come from K, but K is already there. L can come from M. OK, so M comes from L. All right, and then L can also go up to E. But E is already there. All right, so F is next. So F can come from E, but it's already there. M is already there. N we can add in. So N comes from F. We can get there from F. G we can add in from F also. And then C is already there. All right, that one's done. So how about J? Anywhere we can go from J? Just K, right? We've already been there. That's how we got to J. K is already in the queue. So let's skip that one. Or rather, just process it quickly. What about M? So we can go to L. L's there. N's there. And F's also there. So there's nothing to add. So that's processed. Next one is N. Put that down. Where can we go from N? G, M, F. So there's M in the queue already. There's G in the queue already. And there's F in the queue already. So nothing extra. Yeah, Arun? Are you faking it? All right, so let's see. What's next? Process the next node. So here we go. There's F. That's already in the queue. There's N. Hey, there's H. H comes from G. I sort of made this unnaturally long. So we got our goal. So how do we get the path? Go backwards. So here's H. So let's see. So H came from G. Where'd G come from? F. Good. Where'd F come from? E. Good. Where'd E come from? E. Good. And that's our path. So we got B, E, F, G, H. Same path as before, I think. Oh, almost, I think maybe we went to C before. I don't remember. OK, excellent. So now my computer can solve this problem. So that approach is called breadth-first search. So it looks at nodes in order of distance. So it seemed like we put a lot of stuff. That's because the place we were trying to go was the furthest away in the graph. So I just kind of trimmed the graph a little, didn't put anything that was further away. But if you look at the distance in terms of number of streets you have to walk along to get from CSL at B to these other nodes, you'll notice that for each of the elements in the queue, the number of hops, as we say, or the distance to those nodes is strictly increasing. So to get to A, D, E, and C, you just have to walk along one street. To get to K, L, and F, you walk along two streets. To get to J, M, N, and G, you walk along three streets. And then to get to H, you walk along four streets. So in fact, you could take some big map database and you could run exactly the same algorithm, and you'd only look at the nodes that are at the distance you want to go. You actually wouldn't walk around the world trying to find things. You would simply look in the local area, and this would work quite well. So it explores the nodes in order of distance. So you can use it with some commercial map database, and it'll be fine. So BFS was actually invented by EF Moore, who invented also more machines and some other things. And once you've seen it, all of you could probably do this. If I give you another map and I said, well, find the shortest path here, then you could probably do that pretty easily, pretty straightforward. People used to think of it as artificial intelligence. It used to be, well, there's these great AI techniques. You can do breadth-first search. You can do depth-first search. Depth-first search, you just put the things at the front instead of the end when you add them in. But it has different properties. So what's the message? Well, finding the best algorithm for something, probably most of you didn't know how to do this. When I said, oh, teach my computer how to solve this problem, probably most of you said, well, I don't know. I know how to do it. I look at the map, and I said, go this way. But probably most of you didn't just say, ah, just make a queue. I mean, if you've seen it before, probably you did. Experience will help. Classes will help. All of the copies have to take these two classes. I know a lot of EEs also take 225. You may also want to take 374. They're both good classes. Don't worry in our class about finding ideal solutions. You'll have plenty of time to learn. And classes and experience will help you in that regard. So what can you do now? So I mentioned a couple of things earlier. Always start with a mental model. Write lots of comments. Structure your code clearly. When you're writing binary, put the spaces in so it's easy for you and someone else to read. Indentation and alignment for C and assembly code. Really, don't leave your spaces out, because if you're looking at a group of 16 bits, you're going to have a hard time noticing that one of them is wrong. It's hard enough just looking at them with the spaces. But without the spaces, it's almost impossible. Some other tips. So try to avoid repetition. It's really tempting sometimes to say, oh, I've got some other code that almost does the same thing. Let me cut it and paste it into place. You're better off kind of generalizing your code. Often, bugs get copied when you do that. Chances are good the code you're copying has a bug in it. And when you do that, you're copying the bug. And people spend lots and lots of time tracking down bugs they've already solved, because someone cut that bug and put it somewhere else too. And so they find one bug, and then they don't realize it's been cut and pasted somewhere else, and they have to solve it again later. That's also a common thing people end up doing, just because people tend to think the same way and make the same mistakes. So there's something called regression testing we'll talk about in 220 that will help you get rid of common errors. Did a question make it in there? OK. All right, another thing you can do is try to design your code to make it easier to test. I mentioned this earlier. You have finite time. And you're going to spend finite time testing your code, making sure it works before you turn it in, before you ship a product, whatever your deadline is. You don't have forever. You've got a fixed amount of time you're going to spend. So if your program is easier to test, then you'll do more testing. If your program takes a long time just to get it ready to test in a simple way, then you'll do less testing, because it's hard. It's painful. So for example, if you look in the lab, you've been playing with the simulator. There's a graphical simulator. There's a command line simulator. The graphical simulator actually just sends commands to the command line simulator. All the testing is done on the command line simulator to make sure it works. And then the GUI stuff is actually quite difficult to test. So we don't test it that way. Testing something that only has a GUI interface means that there's some human there playing with a mouse, typically. It's really slow compared to having a computer try to test a lot of things at once. So make sure that you have a testing interface that allows you to do testing really quickly. And then your code will be more solid. So we have a few minutes left. Let me get you thinking about this for Friday, because I think we'll spend most of the day developing it and writing code for it and things like that. So let me tell you what the problem is. So let's say that we want to do the following. So I'll give you an ASCII string, which is a bunch of characters in memory, sequentially in memory, terminated by a null, which is a 0 in ASCII. And I want you to go through that string and find all of the occurrences of each letter, so A to Z, regardless of case, and count up. So how many A's, how many B's, so forth. And also count the number of non-alphabetic characters. So I want to count for each letter and account for the number of non-alphabetic characters. Are you ready? We'll do systematic decomposition. There. Build histogram of letters and non-letters. And we're done. That's my part. You do the rest. So sometimes people ask me, well, what's a histogram? So let me make sure everyone knows that. Histogram is a function on a set of categories. There's one way to explain it. So here's a couple of examples. So here are the number of leaves on my favorite tree in September. And this many were green, and this many were yellow, and this many were orange, and red, and brown, and this many had fallen off. And then I measured again in October. I made these data up. These are not real data. But I measured again in October. These are both histograms. So they show you for some categories here, leaf colors, or whether they've fallen off the tree, what's the expected frequency, or what is the measured frequency of those categories. So those are histograms. So what we want in our problem is a count per letter. So for the string, how many A's? Either case. How many B's? Either case. Blah, blah, blah, blah, blah. How many Z's? So how would you do this? Yeah, Nathan? 42. Yeah, so that's one thing we're going to have to do inside. Subtract 40 hex, maybe, right? The below letter A, yeah. All right, so what I meant was, how would you, as a human, solve this problem? So let's do this string as an example. Yeah? I mean, I think whether or not the value is out of text, like, I mean, you could use random letter that has a number of hexes. Yeah, yeah, yeah. So you can, Eric's saying, you can basically check for A, and then maybe check for B, and so forth. I think what Nathan was saying is you can actually subtract and maybe use that difference from 1 to 26 as an index in the memory, for example. So there are a bunch of ways you can do it. So all of those are good answers. What I'm looking for, though, is a higher level process, right? So if I literally said, well, do this example. Give me the histogram for this example. What are you going to do as a human? And maybe we can model our program based on what we do as humans. So how many A's? Three? The string. Try this string as an example as our string. Three A's, right? OK. How many B's? Oh. How many C's? Zero. Good. How many D's? Good. How many E's? Two. Good. All right. That's enough, right? All right. So maybe something like this is probably what you did. So for every letter, set a count to zero, and then go through each character in the string. And if you see that letter, add one to your count, and then store the count for that letter in your histogram. So when I said, oh, how many A's? You probably look through the string. There's an A. There's an A. There's an A3. And I said, how many B's? You went through the string again. You went through the string 26 times or 27 times. That's a lot of times through the string, right? Here's another example. Everyone have their textbook? OK. How many A's in Pat and Patel? Everyone got that number, right? How many B's? 42. Exactly. All right. Oh, yeah. So the real question, if I had asked you to do that, let's say you were getting paid. You're getting paid to count the number of A's and B's and C's in Pat and Patel. How would you do it? Would you do it the way you did it with a little string? Would you say, let me look for A's? OK, I'm done. Let me look for B's. Or would you do it a different way? Yeah, go ahead. Can you repeat the question? Yeah, so you can go through the whole book. And then maybe I don't need to use sophisticated data structures. Maybe I can have a piece of paper with letters A through Z on them. And every time I see the letter A, I'll make a mark on A. When I see the letter C, I'll make a mark on C. But then I just go through the book one time, which is a lot faster than going through Pat and Patel 27 times, I think. Although you should enjoy reading Pat and Patel, but maybe not 27 times. So here's another algorithm. So for a longer string, maybe what we do is we set all our histogram to zeros. And then for every character in our string, we'll go through it once. And then we'll just increment the appropriate histogram bin. So if we see the capital letter T, we'll go to the T and increment it. If we see the number 5, we'll say, well, that's not a letter. We'll go to the non-alpha bin and increment it. So figuring out, well, which bin, that might be a little complicated. So we're going to have to figure that out. There's one more I want to show you. We have a few more minutes. OK, good. So what if instead we did this? What if instead we said, well, let's make the inner part simpler. I don't want to do a lot of calculation. I want to just make it easy. So let's build a bigger histogram. Let's have, let's see, ASCII has 128 characters, right? So I have 128 characters. And then what I'll do is I'll go through the string one time. And every time I read an ASCII character, I'll just say, oh, that's ASCII character number 35 hex. Let me go to entry 35 hex, add 1 to it. And so do no computation at all to figure out what it is. I'll just go add them up, whatever the index is, whatever the character is. I'll use that as an index into my array of 128 things. Add 1 to it. And then when I'm done, well, there's lowercase a and uppercase a. So I'll add those two numbers together. And that'll give me my a. And lowercase a, uppercase a, I'm sorry, lowcase b, uppercase b, add those two numbers together. Done. And then I'll add up the rest of the things that aren't letters. And that'll give me my non-alpha. So now finding the bin is easy, right? It's just, well, whatever the character is, there's 128 of them. Go to the right one. Add 1 to that memory location. But then I have to add some extra initialization. Instead of 27 bins, I have to do 128. I have to do a little extra work down here. So there's some trade-offs. It's a little more work at the beginning and the end, a little easier in the middle. But what's better? So maybe I'll leave you with this. We'll talk about it a little bit. And I'll leave you to think about it. So what is the metric? When you get into later classes, or maybe some of you have seen this, you might talk about things like computational complexity, which usually map to something like, well, how many instructions does it take? Or how much time does it take? How many cycles, clock cycles? How long does it take to run your program? That's going to have a lot of factors that change the answer. But basically, if you're looking at how many things you're doing in your program, then that's a measure of complexity. And you can measure it explicitly with number of instructions. You can measure it explicitly with number of clock cycles, wall clock time. Another way you can measure things is, well, how much memory do I need? Do I need only a few bytes? Do I need a kilobyte? Do I need a megabyte or a gigabyte? Or do I need a terabyte? Do I need to have blue waters to run this thing? Hopefully not, because there's only one of those. So if you need that much memory, maybe it's not your best approach. But those are all trade-offs. These are different ways you can measure things. So what about for our problem? Does it make a difference, do you think, for long or short strings? Certainly, probably you would approach it differently for a long string and a short string. Again, try to think about it seriously. If you wanted to do Pat and Patel, you really don't want to do that first algorithm. But if you're going to do a short string, is it really worth getting a table and saying, oh, this string starts with a T? For the short string, it's probably easy enough to just look at it a whole bunch of times and look for specific letters. So maybe the answer depends on the length of the string. What if your string is sorted? What if all the letters are in order? That's kind of crazy, right? But to make it easier, then you just count As. And when you get to the end of the As, well, then you go to the Bs, and you count all the Bs. Then you count all the Cs. You're still going through the string once, a lot easier. But why would it, you know, the string wasn't sorted, right? Except you can sort it. And you can sort things. And you can do that in linear time for this particular type of problem. So in fact, meaning time proportional to the length of the string is what I mean by linear time. So I could sort it first and then use a different algorithm. So there's always lots of different ways you can solve these problems. So let me leave you with that thought and think about what's good in these things until Friday. Thanks.\"},\n",
       " {'ECE120-2016-09-30-LEC-16-slides.mp4': \" section. Okay, so if anyone wants to chat with me, feel free to stop by. Policy update as of the trouble with the lab, not this week, but last week, your lowest two labs will now be dropped instead of just your lowest lab since AWS, I guess, killed our software right before the deadline. And then I just wanted to do a quick review because a couple of people that asked me about finding all the notes and videos and stuff like that. So if you go to Google, and if you can remember how to spell my name and type it, then you can find my homepage and then you can go down here to classes 120. Oh, sorry, it still says 198 JL. That's the original name. F16, you go there and then on this links page, you have all the online exercises, you have all of the PowerPoint slides, have all of the recorded video lectures from the class, and then the C code examples and then some extra stuff if you want it. There's also a copy of the reading notes here. So if you're looking for those, they're here. Easier to read like this. PowerPoint or PDF viewer doesn't want to do what I want right now. Anyway, so those are there. And then obviously the top thing takes you to the wiki where all the rest of the class resources are. So hopefully everyone knows how to find everything. So just do a quick review. There we go. All right, so today, oh now it's in, I look funny. I don't know why it went to that mode. Anyway, so we're gonna start by doing a checker for uppercase letters, more examples of building with abstraction, then talk about multiplexers or muxes, spend a little time on decoders. We may start sequential logic today or we may not get to it until Monday. I didn't put it on the list, but we may get there. So I want to do another example and show you a few different ways that you can you can break up problems to make them easier than going all the way down to KMAPs. So let's start with one where we say, well let's have an ASCII character, 7-bit code, C, C6, down through C0. And let's make a piece of hardware that will tell us whether that ASCII character is an uppercase letter. So you may or may not remember an ASCII A is this bit pattern which is hex 41, capital Z is this bit pattern which is hex 5A. And so how do we check? If I give you this, these six or seven bits rather, how do you tell me is this a letter or not? Muhammad? Yeah, that's yeah, exactly. That's one answer, right, is we can use some comparators. I'll put that off, I'll do it a slightly different way, but that's a good answer. Yeah, so these numbers here we're gonna have to feed into the comparator somehow, right? Yeah, good point. Okay, so we'll come back to that answer. So here's another way we can do it. Go down to truth table. Can you help me out? Is this one an ASCII character? No. Okay, what about this one? Got a lot of slides here. So let's hurry up. All right, so maybe, maybe, I mean a lot of these are zero, right? Maybe we can just skip to the ones that matter. So what if we just take our truth table and we break it up into pieces? So we got 128 rows, but most of those rows are zero, right? So let's break it up into eight of them. So each of those eight pieces of 16 rows will be one value of C6, C5, and C4, right, the three leading bits. And then we can solve each of the little pieces, the groups of 16 rows, with a kmap on four variables, right? So we could do it that way. So maybe we don't need a kmap for some of those, right? Maybe we don't need to do eight kmaps. So remember, A is this thing, Z is this thing. So what about this truth table? So C6, C5, C4 equals 0, 0, 0. What's the function? Zero, right? So you didn't need a kmap, right? You want to draw a kmap? I know kmaps are fun, so maybe we do it. No, we'll just skip it. By the way, I want to make sure you know when I write something like this, this means C6 equals zero, and C5 equals zero, and C4 equals zero. We'll write that increasingly often. So no ASCII character with those upper three bits is an uppercase letter, right? So that function is just zero. So that was relatively easy. So which of the eight functions are not the zero function? Yeah, so anytime we have C6, C5, C4 is 1, 0, 0, or 1, 0, 1, some of those are letters. All the other possible values of those three bits, those are just the zero function, right? So out of eight different kmaps, six of them are zero. We're done, right? We've got two more. So if we break up the truth table, then we can solve a lot of it pretty quickly. Well, six of them are zero. So let's call that function T4 before I'm getting out of just this number here, right? So 1, 0, 0 is four in decimal. We'll call this one T5, and that's it. So let's just do the kmaps for those two. So here's the kmap for T4. What do you think? SOP or POS? You want POS? Okay, the max term, right? So what is it? Yeah, add them all together, right? That one? Okay, okay, good. We're done with T4. So it gets pretty easy at some point. Okay, so here's T5. I claim POS is slightly better again here. So what are the loops? Yeah, I want to do POS again. Yeah, sorry. So this one here? Okay, good. What is that one? Like that? Okay, and what's the other? The two horizontal zeros? Okay, and that one's this? Good, okay. So that's it, right? Those two factors. All right, so then how do we put them together? So we've got T4, we've got T5 with six zeros. We could write down if we want. I won't write them. So T4 applies when C6, C5, C4 is 1, 0, 0. T5 applies when C6, C5, C4 is 1, 0, 1. So what should I do? All right, so what if I, let's see, so I want this one to apply when this is true. Can I write an expression for this? So I need to AND T4 with C6, C5 prime, C4 prime, right? So if I write C6, C5 prime, C4 prime, that means these three are equal to those three. Is that right? Okay. So AND T4 with C6, C5 prime, C4 prime, AND T5 with what? C6, C5 prime, C4, okay. And then do what with those two results? OR them together, right? Good. Okay. So that's my answer. So it looks nasty, but it's not really that bad, right? It's pretty small, pretty fast. It's not two-level logic. It's a little more, but we still had to do a little bit of work, right? So you already know the easier way. So this is the question we can think of it as, right? We know how to build comparators. So instead of saying, let's go build this expression, we can instead say, well, I know how to build a comparator. I know this is a contiguous range because on homework number one, we asked you some question about why did we put digits in a contiguous range? And you said, well, so you could do translation to binary numbers, right? And well, why do we put letters in a contiguous range? So you could do this kind of thing. So you need to check, well, is C greater or equal than A and less or equal than Z? If it is, well, then it's a letter. And if it's not, it's not an uppercase letter. So here's two comparators. So I built two seven-bit comparators using our bit-slice approach and just plopped them down in my diagram. Into both A inputs, I put the C, the character in ASCII that we're comparing. Into the left comparator, I'm going to put hex 41. That's the letter A, remember? And the right comparator, I'm going to put the letter Z. That's 5A. And then I have to go back and look at my representation, which I didn't rewrite for you guys. But remember that if you've got Z0 on, that implies that C is actually less than 41 hex. That A is less than B. The Z0 output is 1. And if the Z1 output is 1, that implies that the A is greater than B. So C is greater than 5A. So if either of those conditions are true, it's not an uppercase letter. So if C is less than the letter A, then it's not an uppercase letter. Or if it's greater than the letter Z, it's also not an uppercase letter. So I have a NOR gate down here that takes those two NORs them together and gives us our uppercase function. So fairly simple, fairly easy. Probably could write it down in a couple of minutes. The hard part is going back and looking at the representation to figure out what gate to put there. OK. What about this? So you know how to build adders, right? You could do it with adders. So last lecture, we saw how to build subtractors. So these are actually being used as subtractors, right? So this thing here, so what's BE for? Well, that's 41 hex, one's complement form. And so this is one's complement of 41. This is carry in of one. Remember that when we take C, this is 0 extended to be 8 bits. When we take C and we add it to not be plus 1, that gives us C minus 41. So C minus 41, if that overflows, I'm sorry, yeah, if we get the carry out, that means no overflow. If we don't have a carry out, if carry out is 0, that means that C was less than 41 hex. So if we get a 0 carry out that comes down here, goes through an inverter, changes to a 1, forces you to 0. So in other words, if C is less than letter A, capital letter A, we'll get a U of 0. Similarly over here, A4 is one's complement of 5A, I think. I put that wrong, didn't I? It should be A5. Sorry about that. So that should be A5. Yeah. Oh, wait, do we need a, let me think here. So we get this one minus 5A, maybe it's for the greater or equal. So 5A, yeah, it's inverted sense. So this is C minus 5B. And so if we get a carry out of that, it's 5B or more. So that's why it's off by 1 here. So this has to be the greater or equal to 5B. That's what the carry out means. If that's true, it's not an uppercase letter. So we're getting a greater or equal then when we flip the carry sense. And that's why this is one's complement of 5B instead of 5A. Does that make sense? OK. All right. So with these two adders, so basically each adder is checking one bound of the range, same as with the comparators. So we could build it this way too and get the same answer. So what's the trade off? Well, those are kind of large and slow compared to our first solution. If you write it down as gates and you show how many gates you need for that first expression, it's really not very many. It's pretty fast, a few levels of logic. As compared to our 7-bit comparator, where it's going to have maybe order 14, 15, plus the logic at the end, so 16 or so gate delays. So substantially slower, substantially bigger for the comparator approach. Same thing for the adders. You've got to wait for the carries to ripple through if you build them as ripple carry adders. So they're slower and bigger. On the other hand, the CAD tools can optimize a lot of that overhead away. So if you look back at the adders, we're actually throwing away the sums. So we build these adders and then we calculate the sum and then we just ignore it. So the CAD tools can look at that and say, well, you didn't use those. So any gates I use to generate those bits, I don't need those. And so it already start trimming down the design that way. But it can also do a little bit of optimization for you. The other way to look at this is, this is like XML parsing or something. If you're going to do XML parsing in your data center, which lots of data centers are doing 24 hours a day, seven days a week, 365 days a year all the time, what are those doing? Well, they're using software. They're saying, oh, compare this incoming character to capital A, compare it to capital Z, actually probably with 32 or 64 bits at a time instead of eight bits. So we're actually doing that all the time in much less efficient ways in software. So this kind of hardware, if you build something like this and if you can get it sitting and doing XML processing, for example, it's more of a complicated task than just checking characters. But it can actually be a lot faster even with a slower and bigger design than using processors. Yeah. Yeah, possibly. And that would be an argument for doing it in software. The computers you're using in software are part of the processor and you can use them for myriad other purposes. But in reality, even 15, 20 years ago with TCP IP network processing before everything was XML based or HTML based, if you looked at a typical data center, a lot of your processor cycles, so on the order of 10 to 15% of your processor cycles were spent doing this stuff. So there's actually a reasonable amount of research in what people call TCP offloading, try to process networking protocols, TCP IP offloading, networking protocols in hardware off the main processors so that you could have your processors actually run internet services instead and reduce your costs that way. So yes and no. There's benefit to it, but getting the generality you need, especially as the protocols evolve over time is sometimes difficult. So people have tried the TCP IP networking at least three times in the last 30 years. And there's some of it now I think in the industry and in real data centers. But it's hard to get right in a way that can survive for a long time. And that's partly because once you put it in hardware, you can't change it. It has to be the same. Good question. Yeah. I'm not in this class, but you can do it. Good question. Yeah. Yeah. I wouldn't ask you to do something that complicated in our class. But yeah. So we want you to understand how to do it and how to approach these kind of problems, both in the sense of if you want to go down to the level of building out of gates to know how to do those things, but also to know how to use the components that you can pull off the shelf to build things. So right now we're looking at examples of the latter. To solve problems, you can take pieces of known solutions and glue them together and do that very, very quickly and only optimize afterwards. If it's something that is too slow or too big, then you can go make it smaller and faster by spending more time on it. So we want you to understand both strategies. Does that answer the question? Okay. Another question? Okay. Yeah. Can you look ahead in my slides? Yes. Yes, we can. Hold that thought. I won't repeat it for the camera because it'll come up again. Good question. Anything else? Okay. So multiplexers. So here we go. You didn't have to hold it for long. So what if we want to take a lowercase letter? So lowercase letters are 61 hex through 7a hex. Remember that uppercase or 41 through 5a. So can we reuse our solutions? We just do what? What was it you said? That? Right. So you'll notice if you put them side by side that bit c5 is flipped. Right. So I'm sorry. I took down the representations, but they couldn't all fit on the slides. We had this answer before by breaking up the truth table. So I'll go back. The only difference here is bit c5 here is a 1, bit c5 here is a 0, c5 is a 1, c5 is a 0. Right. So flip the c5. So change c5 here, c5 here to c5, sorry, c5 prime, c5 prime to c5 c5. We're done. We've got a lowercase checker. Yeah. Oh, sorry. I thought you were raising your hand. Okay. And if you want to use the comparator for that purpose, right, then all you have to do is change these inputs up here. So change that one from 41 to 61. That means z0 equals 1 now implies c less than 61 hex. Change this one from 5a to 7a. That means that z1 down here equals 1 implies c greater than 7a instead of 5a. And then we have a lowercase checker instead of an uppercase checker. So very, very easy to just go change that answer. So what if we want to design one answer to one piece of hardware that does both? So we did that a couple of times on Wednesday. We did unsigned and choose complement comparator by XORing the sign bits with the signal s. We did that with an adder and subtractor where we put them together by again having control signal s. But what if we want to have just logic that allows us to have some control signal s that just selects between two arbitrary signals? So we'll design this logic and then go apply it to our problem here of designing one piece of hardware that checks both upper and lowercase. So if I want to do that, here's a full truth table. So I have a select bit s. It could be 0 or 1. I have two data inputs. They could be 0 or 1. And those are the eight possible patterns. And so if I have select bit 0, that pulls out d0 and I get a 0, 0, 1, 1, 0, 0, so forth. But I could probably make it a little shorter. So instead of drawing this big truth table, I know that if I select 0, I don't care what d1 is. So here we're putting X on an input, which is different than putting X on an output. This says in this truth table row, d1 doesn't matter. d1 can be 0 or 1, and Q will still be 0. So this row here then represents these top two, I'm sorry, not the top two, this one and this one here, the first and the third. The second row then represents the second and the fourth. It also says, well, if select is 0, d1 doesn't matter. If d0 is 1, Q is also 1. So we can have an abbreviated truth table. I mostly wanted to show you what it means to have a don't care symbol on the inputs. So it means that we're merging multiple lines with the same output. You have to be careful because if you have more than one overlapping set here in your rows with different outputs, then you have an ill-defined truth table. So you've got to be careful how you merge them. We're getting there. Sorry. A multiplexer is what implements this function. So this output Q is the result of a multiplexer. But I'll show you logic diagrams in a bit. We'll derive them. So it's the thing that allows us to answer this question down here. Use one control signal to pick between two arbitrary signals. So the answer, we call a multiplexer. I debated whether I should put it in the titles, but that's what we're building towards. Yes. Although I call them d1 or d0. So here in this abbreviated one, what I was telling you, unselected inputs don't matter. So remember, s is select. So the ones that are not selected, if s is 0, then d1. If s is 1, then d0. We'll mark those with don't cares. And furthermore, I could even, in this case, I could write the truth table in a really compact way. So I could say, well, if s is 0, the output is d0. So whatever, this is now an input. But I'll say, well, that output corresponds to this input. And I just have two rows. So as we go forward in the class, it'll be more and more necessary as we build bigger systems to start writing truth tables where we take advantage of these shortcut notations. So I just wanted to introduce a couple of them. So let's go ahead and solve this problem with the KMAP. So first, we'll copy. So I put d1 and d0 on the top. So we're going to go across. And then we'll just copy from q into this KMAP. So we'll start with this one and then go downwards. So that's 0, 1, another 0. But remember, we need to hop over when we copy. So 0, 1. And then 0, 0, 1, 1. So 0, 0, 1, 1. So what are the loops? So we could do this one. But if we look at this one, for example, we have to have this loop, right? Yeah. So remember, this was the example or similar to the one we used for consensus. So we don't need to have that one. But those two loops were done. So yeah. It doesn't actually matter, right? They're equivalent in this case. So you're right that I probably should take a look at that and make sure that I think that I'm, well, visually solve them and see that I think one is better than the other. If it's close, I may solve them exactly to compare them. In this case, they're symmetric. So it's going to be identical. Yeah. So the question was SOP versus POS. And they're the same here in terms of complexity. So we'll solve this one with SOP. So we'll write it down. It's S prime d0 and SD1. So I could have done that a little differently. I could have started with my small truth table and said, well, when I have S0, I get d0. So S prime, that's the min term for S. S equals 0, sorry. S prime anded with d0 gives me this row. And then S, this min term, anded with d1 gives me this row. And I OR those together. That's my function. And in that form, it's maybe a little easier to see that, well, all this is letting me do is when S is 0, I pick d0. And when S is 1, I pick d1. So this is a device, which we call a multiplexer, that allows us to pick between two signals, whatever they might be. And it will forward one of those signals, depending on our choice, which is S, to the output Q. So here's what it looks like. All I did here is implemented the logic that we had on the last slide. So this is how a 2 to 1 MUX is implemented. This is how we draw it as a trapezoid with data inputs 1 and 0. And then which of those gets forwarded to Q depends on S. Yeah. Yeah. So the question is what are we going to use this for? And the answer is, well, when we want a piece of hardware that does more than one thing, we have to tell it which thing we want to do. And so we can control which inputs it looks at using something like a multiplexer. So I'll come back and actually put that in front of our devices. But yeah. Good question. Like this? Good question. What if we have four expressions, for example? So we have 3, 2, 1, and 0. What should we do? So yeah, one answer is to use hierarchical MUXes, right? So we can start by using one 2 to 1 MUX. We'll control it with a signal. Let's call it S1 for now. And let's decide between D3 or D2 will go into this input. And D1 or D0 will go into this input. No. D3 or D2, the way I've numbered these. Yeah. Eventually. Yeah. So the next question then is, well, how do we get D3 or D2 to go into this input? Well, we're going to use a MUX, right? So how are we going to deliver two expressions? We use a MUX controlled by S0. So here on the top, we pick between D3 or D2 using S0. One of those two will go into the input to this second level of MUXes, which is just one more MUX. And here we're picking between D1 or D0 also based on S0. This choice here is based on S1. So if you think about what ends up happening, I'll look at it in more detail on the next slide, but S1, S0 is basically a two bit unsigned number that chooses between input 3, input 2, input 1, and input 0. Sorry? Yeah. Yeah. I really like it. No, no, no. It's great when you guys are predicting the slides. That means you're really on top of things. I like it. OK. Yes, you can do it with four AND gates. And each of these is a minterm, right? So if you think about what's going on here, each of these four AND gates is producing a minterm ANDed with one of the D inputs. So let's go through those. So this top one is D3 ANDed with S1, S0, which is the minterm which you could think about as number 3. It's the 1, 1 minterm. So those get ANDed together and produced by this AND gate. The next AND gate is D2 with S1, S0 prime. And that's 1, 0. That says, OK, I want input number 2. Down here, D1 ANDed with S1 prime, S0. That's 0, 1. So that gives you the D1 input. And then down here is D0 ANDed with S1 prime, S0 prime. So that gives you the D0 input. The outputs of all four of those, only one of these four minterms can be on. S1, S0 has to have one of those four bit patterns. Only one of these four AND gates will produce a 1 ever. So then you OR them together. That gives you Q. Yeah. I thought it'd be easier for you to understand if I draw it this way. I'm sorry. I forgot to include that slide. Yeah, OK. So I mean, you should know, I know actually a few people had some trouble with this on the homework. So any time you have two-level SOP, you can just literally go replace both levels of gates with NAND and it'll be the same. So I mean, if you want them to be NAND, just draw NANDs in place of these. But I didn't do it. Sorry. Yeah, sorry. So that's an interesting question. So the question is, well, could you just connect these four outputs together? Remember that these are what we call active logic. And so if you think about the way these gates are working, you are actually connecting one of them to high voltage and the other, or maybe to high voltage if it outputs a 1. The other three are connected to ground. So if you connect the outputs, you've created a path from high voltage to ground. I will show you later in the class how to do what you're saying, where you actually electrically disconnect some of the outputs from a wire, and then you can use multiple outputs to drive the same wire. But you have to have electrical disconnection, not connection to ground, which is what you get out of the gates. Good thinking, though. Okay. All right. So here's the symbolic form. Bigger trapezoid labeled with the four different values, two bits of select input, so crosshatch with the two. And of course, we could then further generalize, right? So you can build 8-to-1 MOXs. You could build them out of 4-to-1 and 2-to-1. You could build them out of AND gates. At some point, your OR gate at the end gets too big, so you'd really have to have multiple levels there. But conceptually, it's the same. You can build 16-to-1, 32-to-1, and so forth. So anytime you want to select from 2-to-the-n, where I'll name that p to make the notation down here easier, with dp-1 down to d0 inputs, we need n bits of select. The log of p, log base 2 of p. Yeah. I mean, in theory, it's infinite. In practice, usually at about 4, you'll want to put more than. It depends on the semiconductor process, but usually it's around 4. Yeah. You mean how do the CAD tools do? Yeah, so the CAD tools are actually, so there's a set of engineers who are working on the fabrication and will go and measure the fabrication capabilities and the speeds and the timings of the transistors and things like that, as well as the capacitive load of different wires. And then all of that gets fed into the CAD tools with process, semiconductor process-specific information that the CAD tools then use to optimize. So there's a lot of information that's not even available to the public. So unless you're contracting with that particular fabrication facility, they won't even give you those numbers. Those are proprietary numbers that you would get out of them. So the CAD tools are obviously designed to use that kind of information. And sometimes you'll see some of it if you're working on hardware. The rules of thumb have been sort of similar for a while, but the details are all hidden. All right. So we can use sets of MUXes also. Another way to generalize a multiplexer instead of just thinking, well, we could have bigger sets, we can use multiple, many copies of the same kind of multiplexer using the same select bits to switch between groups of bits. So for example, well, let me generalize it first. We can have an end-to-end multiplexer, which is actually M copies of N over M to 1 MUXes, each with log base 2 of N over M select bits. And typically, N over M is some power of 2. So for example, when we did our subtractor design, we said, well, we want to take B or complement B, one's complement of B. And we did some optimization there. We could have instead just used MUXes and put B into one input of the MUX, B prime into the other input, but we'd have N copies of a 2 to 1 MUX to do that. And they would all be controlled by the same select bit. Either we want all of the bits complemented or none of the bits. None for addition, all for subtraction. Now, when we talked about it, we actually did a little bit of optimization for the MUX implementation. We said, well, because we're putting B and B prime in, we just need an XOR gate. We don't need a MUX. But we could have just put a MUX down. And actually, the CAD tool probably would have figured out to replace that with an XOR gate anyway. It's simple enough logic that the tool could figure it out. All right. So let's then back up a step and think about our ASCII character checker. So let's say now, instead of just upper and lowercase, I want to check for four different kinds of comparison. So I want to say, well, let me check for control characters. Those happen to be the range 0 to 1 f hex. Check for lowercase, so 41 to 5a. 41, not 40, sorry. 41 to 5a hex. Uppercase 61 to 7a hex. And digits, 30 to 39 hex. So I want to check all four types with one piece of logic. So what should I do? Yeah, MUXes, what kind? Yeah, so a set of 4 to 1 MUXes, right? A 28 to 7, where each of the ASCII characters is compared against one of four possible lower range values, 0, 41, 61, or 30. And one upper range, 1f, 5a, 7a, and 39. Which of those four I put in is actually just controlled by the same two bits, for all 14 of those 4 to 1 MUXes. So the same two bits make my choice for me between the four different possibilities. 0 to 1f, which gives me control characters. 41 to 5a, which gives me uppercase letters. 61 through 7a, which gives me lowercase letters. And 30 to 39, which gives me digits. And then I just look down here at the output to see for the range I chose, was the answer yes or no? And I can use the same hardware. Make sense? Yeah. What are you, we're relying to give you what? I'm sorry. Ah, so the S input, right now we've only done combinational logic, right? So this is just like any other input to our logic, right? So somehow we need to tell this piece of hardware which operation we want to do. So later we'll see how we can store state, actually we'll start it shortly. But eventually we'll build full computers, and then it'll be up to us to make sure that the answer to your question gets routed to these two input bits at the right time, so that we perform the correct comparison. At this stage, probably not too much, right? At this stage, we're designing something that is usable, right? That the human can arrange to have the right two input bits. I mean, humans can make mistakes everywhere, right? So you can design an adder and they put the wrong bits into the adder, they get the wrong answer out. So in all stages of all kinds of engineering design, you have to think about, did a human make a mistake somewhere? There's sometimes other sources of error too, but humans are responsible for most mistakes. Yeah, when it seems like a computer is responsible for most mistakes, it's actually the programmer. So yeah, occasionally there are things like cosmic ray strikes, right? That'll cause bit flips that will, so there are hardware, software slash errors that come up because of nature. Most bugs are because of humans at some point. All right. So one more piece, actually, before we start sequential logic, so maybe we won't get to sequential logic today. So decoders, so it's going to be a little bit abstract. This will make more sense when we get to memory. So what if we have designed a representation with n bits? I mean, we did a bunch of them when we did bit slicing, right? But what if we have an n bit representation of something and we want to know, and we have a value in that representation, n bits, we want to know which of the values is it? So I want one signal that tells me, okay, this was the mango ice cream or this was the lychee or this was the pistachio or whatever, one signal each. So what am I going to do with that? Well, naming sets of bits. So again, when you receive memories or register files, probably three to four weeks out, we'll need this, right? This will be one of the primary components in the construction of a computer memory. So we will need to have decoders. Another one is actually generating arbitrary functions, logic functions dynamically. So this was used in old reconfigurable logic, so called programmable logic arrays, basically. So I'll show you how that works. But for many years, that was how we built dynamically reconfigurable hardware and did hardware prototyping quickly. So in other words, given a set of n bits, I want to generate a signal for every possible combination. So those signals then of course, correspond to the min terms. And so for every min term, I'll have a signal and exactly one of those will have the value one. So decoder generates all the min terms, and one of them will be one. So you might remember, we saw that in the mux, right? So there's a similar structure. So here's a decoder, two to four decoder. So it takes two input bits and generates all the min terms. Here I've added an enable signal. So in fact, for this decoder, if enable is zero, enable goes to all four of these AND gates, and so all the outputs are zero, right? If enable is one, each of these becomes a min term of S1, S0, and so one of the outputs will be a one and the others will all be zero. So this is decoder. And if you were then to be mean and ask me, well, this is not NAND and NOR and it's not too level, I'd say, yeah, it's not quite accurate, right? You're going to need extra inverters to make this a real circuit for CMOS. Because if you used a Morgan's law, you'll get extra inverters on this side, which you can easily just swap the inverted and non-inverted lines here, but I guess you'll get a bonus inverter and enable. Yeah. I'm not sure if I understand what you mean. I mean, a one input NAND gate or NOR gate is an inverter, right? If you think about the parallel versus series, they scale it down to one transistor, that's then an inverter. But unless you have two in a row, they don't just cancel. So when... Yeah. Yeah. Yeah. Okay. Yes, but I'm... Yeah, I'm not sure. I'm not sure if I understand. I mean, I can use a two input NAND and connect both inputs to the same thing. I see. But I can do the inverter with one input. I mean, I can also have three inputs or 10 inputs. It's all the same. It's all an inverter if I connect them all to the same input. Yeah. But what I can't do is when I change this to a NOR gate in order to make it CMOS, I get inverters here. So all of these will be inverted. So these two inverters will be flipped. So that's fine. It's the same cost, but I'll still have one inverter that I need for the enable. So I'll have one extra inverter in the NAND NOR design if you work that out. Okay. So this is how we draw a decoder to the trapezoid going the opposite way. So the NBIT signal usually comes in from the smaller side, not the narrow ends, but the smaller side of the trapezoid. And the outputs then come out from the other side. If the decoder has an enable signal, not all of them do, but it's pretty common. It'll come in from the narrow side. So this is a symbolic form of the decoder. I do want you to notice that this structure is very similar to the MUX. So in the MUX, we then ANDed each of these min terms with one of the data inputs, and then we ORed all the results together. But we have the same AND gates to generate all the min terms. So they're very similar in that sense. The decoder allows these min terms to be used separately. So for example, if you were building a vending machine and you wanted a bunch of products coded in some representation and each of these outputs could then control the mechanical release for that product. You'd release exactly one product based on the product that the vending machine said, OK, time to release a product. And you probably want to release one at a time rather than having your vending machine drop a random subset or something. Well so there are no 2 to the n data inputs where n is the number of select bits. So there's nothing actually getting ANDed in with the min terms other than the enable signal. So that's one difference. And the min terms are not being ORed together. So in a practical sense, the way that's used is we can compose arbitrary functions by ORing together the right set of min terms. So it's not very interesting for 2 bits, but if you built a bigger decoder like 3 to 8 or 4 to 16, you could then pick out the right min terms, OR them together, and compose an arbitrary logic function. So that's how the old reconfigurable logic was built, by composing logic functions out of min terms. And you can actually do that. So let me finish this and I'll get to your question. You can actually do that for more than one function, because you have these min term wires. So you can have one function by just ORing the right set together, and then a different function by ORing a different set together, and a third function, and a fourth function, and so forth. Whereas with a MUX, those min terms are all ORed together into one wire. So you can't then use that to construct arbitrary logic. You can use it by putting 0s and 1s to the input, but one MUX will get you one function. Whereas a decoder, you can then add OR gates outside the decoder to get you any number of functions you want. So the primary application, other than memory, was the programmable logic arrays. I'll show you, when we get in about two and a half weeks, I will show you an application which is a vending machine, which is, you pick a product and then there's internal logic that decides, am I going to actually deliver that product to you? Have you put enough money in? And so that goes to the enable of the decoder. So if the answer is no, you didn't give me enough money for that product, then nothing gets released. And if the answer is yes, then we decode the signal, and then we take each of these and send it to a mechanical release. Or you can use it for that kind of application. The primary use, though, outside of memories, which we'll see in a few weeks, was these programmable logic arrays, which have now been superseded by FPGAs. FPGAs use a different mechanism in terms of lookup tables. Oops, really? That was it? OK. We have a few minutes left, so let me give you a little start on any questions on this before I switch slide decks. Yes, so based on S1 and S0, there will be four different minterms, and it will generate exactly one one for one of those minterms. Yeah. Yeah. The enable. Yeah. Yeah, the S1, S2 would be the product choice. That's right. And then each of these lines out would control whether a different one of the four products got dropped out. So a MUX is typically used when you need to choose between different functions. So for example, when we did the add or subtract, or when we did unsigned or two's complement comparator, you can use a MUX. When you want to compare different ranges of ASCII, you can use a set of MUXs to choose which type of character you're looking for. So there will be many, many cases where we want to have the ability to choose between two things or four things, and we'll use MUXs in all of those cases. In fact, we'll see it probably Monday or Wednesday when we design registers. I see. So in a different sense. So this is giving me one signal for each pattern, whereas the MUX is unifying many signals under one wire. Right. So do I want to add or subtract? I want the answer to come out in the same place. Right. So when you want to combine things into one output, use a MUX. When you want to split something that's already been coded into individual wires, use a decoder. Yeah, it's trying to give you the ability to tell which of the patterns here was the one that was actually present on the bits. So that you can then do things with each of those individually. Go ahead. Okay. You mean if you wanted to build a bigger decoder from a smaller one? Yeah, then you have to. So the question is, can you build bigger decoders from smaller ones? You can. You do need to have decoders with enable, because if you think about, well, how could I build something with eight outputs from two of these? Well, you can't if both of these always output one, one. Right. Because in the eight, you want one, one also. If you've got one, one from each of these, then you have two ones and you can't do it. Right. Without adding some extra gates afterwards, which would be a pain. On the other hand, if you have the enable input, you can make one of the two, two to four decoders output all zeros. Right. So if you take two, two to four decoders with enable, you can build a three to eight decoder out of that with a little bit of extra logic. Make sense? Okay. I think that might be in the homework. Yeah. Yeah. So if you were, if you were really designing it in CMOS, then, you know, you need to change these AND gates into NOR. Or, I mean, you could change them into NAND, but your outputs would mean different things. All right. So let's just stop there. We'll start sequential logic on Monday. Thanks.\"}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load josn from file: input_data/audio_transcripts/mit_lectures/mit_lecture_transcripts.json\n",
    "import json\n",
    "with open('../input_data/audio_transcripts/vlad_lectures/lecture_transcripts_large_model.json') as f:\n",
    "    lectures = json.load(f)\n",
    "print(len(lectures))\n",
    "lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas = [dict(textbook_name = list(lecture_dict.keys())[0], page_number = '') for lecture_dict in lectures]\n",
    "# metadatas = [dict(page_number='', textbook_name=page['textbook_name']) for page in textbook]\n",
    "textbook_texts = [list(lecture_dict.values())[0] for lecture_dict in lectures]\n",
    "assert len(textbook_texts) == len(metadatas), 'must be equal sizes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"stuff and a little bit of philosophical prattle to start off. One clarification too that's worthwhile from last lecture. Then we'll dive into von Neumann model and then look at LC3 as a von Neumann machine. And then I think we will manage to get through most, if not all of this instruction format stuff. After that on Monday, we'll start talking about instruction processing. I suppose there's some small chance we may get to that today. So before I do the clarification, do this. So if you're feeling now after having gotten your midterm back, you know, my TA, if I hadn't had this TA, I'd have gotten half the score. Then nominate them. Even if you don't feel that way, nominate them. Because you should be proud to be in 120. Otherwise the 210 TAs will win or the 2310 or some people like that. They just don't deserve it. Our TAs should win. I mean, they're good, but they're not as good as ours. So seriously, I mean, unless you feel strongly and you don't want to do it, at least think about it. Because we have some good TAs and it's nice for them to get the award. The award is something like a couple thousand dollars. Sometimes I don't know if they split it if they give it to two people. They have given it to two people sometimes or if they give them each 2,000. But it's a pretty nice chunk of money for a TA and more importantly, nice recognition for a job well done. So please do consider nominating them. I won't actually start teaching and take Ticto Code, even if you don't. But I may track whether you nominate them. I'm kidding. All right. So I want to make one. Oh, shoot. Sorry, I left this animation in. I wanted to make one clarification about this stuff. So I realized after talking to a couple of people after class that these RTL, these remember are FSM outputs, but they go to the data path. So the data path is basically all clocked logic. It's the components. So these actions happen at the rising edge of the clock. So the actions take effect in the next clock cycle. So there's a little bit of difference from how we wrote the state tables before because there we would have external outputs listed against each state. Whereas these actions are actually not external outputs, but outputs from the FSM to the data path. And so they take effect not in the current cycle. They're not outputs that are visible externally, but they're actually outputs that control the action of the data path. And so they take effect in the next clock cycle. So I know there's a little bit of confusion about that. For example, how when we get into the compare state, how count is equal to zero. Well that's because we set it to zero here and then in the next cycle when we're in the compare state, then count starts at zero and then starts counting. So sorry about that confusion. Just wanted to make sure it was clear for everyone before we move forward. Because we'll use the same kind of notation in the LC3 finite state machine and it'll have the same meaning that in a particular state, when you say the RTL for that state is such and such, that RTL will not actually happen effectively until the rising clock edge at which point you're in the next state. So just bear that in mind in terms of the meaning and the timing. And someone I think asked me, so why would I want to give you a hard problem to do? So I wanted to answer that. So this is just philosophy. So you seem surprised that I'd want to give you a hard problem. Not really on an exam. I mean exams are timed. I don't care if you can do it fast. So here's another problem. So write an assembler in C for the LC3. So take assembly code, which you haven't really seen much of. So I wanted to come up with some problems that maybe you can think about how hard they'd be. So write an assembler. You're seeing it in the lab now if you've played with the lab. And that assembler can take LC3 assembly code and actually do the encoding. So after a few weeks of assembly and a few weeks of C. You think you'd do that? Here's another one. A couple more. So how about a simulator? So how many of you played with LC3 in the lab? OK, so a few of you. So you write that simulator. Same few weeks of C. Seem good? Yeah? OK, good. I hope you think you can do this. Actually, I'm not sure if you think you can do this. You might think it's hard. So what about LC3 code generation? So the back end of a compiler. You do that, right? OK, so here's some quotes for you. So here's someone. This is Pete Sauer. So apparently, we faculty didn't realize that in order to win awards, we had to be nominated. So that was actually quite helpful. So they created this faculty awards committee. Turned out to be true. So it turns out also that if you don't try something, you can't do it. So it's probably not me. I'm sure there's someone more famous. Here's another quote. So this is my colleague, former colleague. Now she's at MIT. But we used to work together. We started here together. So what does she mean by that? So I would contend these things. I agree with her for the most part. So if you've never tried something that you couldn't succeed at, that your teacher or professor or whoever gave you the problem, you didn't know, OK, this is completely doable. I'll be able to do this in a certain amount of time. And it's on my homework. So of course, I'm going to be able to finish it by the end of the week. How are you going to know what you can do if you never try something that you're not sure if you can do it, not even sure if it's possible? No one else has done it before. So these things that I mentioned, those are about 1,000 lines of C code. This one, code generation, it's only a few hundred lines of C code. But it uses recursion. So usually, that's more complicated. So we put that after these. But those are real assignments. So in the old programming class, which is one semester, we give them a few weeks of assembly, a few weeks of C, then they'd have to do those things. And most students did them and did well and felt pretty happy. And they seem really hard at first. And people would be scared of them. And then they do them, and they think, wow, that's really cool. I can go build those tools I used at the beginning of the class to play with the LC3. So it was a sense of accomplishment. So all of you, as I told you at the start of the semester, you're all smart. You can all do incredible things in the world. So I suggest you try to solve hard problems. And sometimes you'll fail. So what? Sometimes you'll succeed. Sometimes you'll find out, oh, those aren't so hard after all. But you'll always learn. So that's why I want to give you that kind of problem. Because it's really not that hard. I thought of a couple of them. I might write one up. And then if you want to challenge yourself, you can. Actually, I'll just tell you, and then you can conceptualize it on your own. And then you can make whatever assumptions you want. There was one I was going to do in the LC3 data path. But you'd actually have to read ahead and learn some other stuff on your own first. But try to do like a microwave controller, right? Just 10 buttons, let's say. Set some time. Push Go. Run the microwave for a few minutes, whatever it says. Count it down. Show the display. Anyway, that's an idea. All right. So that was my philosophical prattling. So let's talk about von Neumann model. Hopefully you remember this diagram. So this is the seven layers, abstraction layers from Pat Patel chapter one. And so far, we've gone up to a few of these. I'll put an arrow on this in a second. But remember, up here is human language. And then we have software in green and hardware in blue. And so, so far, we've kind of worked up to how a computer works. We spent a week number three talking about the C programming language. But basically, now you're ready to see, you know, how does a computer actually work? So to remind you, the microarchitecture, this is the implementation. This is the thing that executes instructions from an ISA. So that's sort of the implementation of the computer. And that's going to look a lot like that finite state machine we designed. So it'll have a data path. It'll have a control unit, which is a finite state machine. And it'll execute instructions. So it'll look exactly like the thing we did on Monday and Wednesday. The core is an FSM. And then we're going to cover it kind of briefly. We'll go over it today and maybe on Monday a little bit more. And then we'll dive into the instructions. And then we'll talk about actually programming. At the start of the semester, when we talked about C, that was just so you could start using C, get familiar with the syntax, but not really how to program, right? Programming is breaking things down to the level that a computer can execute, which is pretty low level, pretty simple things. So we'll start thinking about that in the next few weeks. And above that is the ISA, the machine or instruction set architecture. So that's the interface between the green, the software, and the hardware in blue. Examples are things like x86, ARM, PowerPC. And we're going to follow Pat and Patel and develop this LC3 ISA. I'll tell you what that means in a few minutes. So in 1946, John von Neumann invented this model for computer organization. He said, well, here's how maybe we should be building our computing platforms, long before people had computers in their pockets and their desks and everything. So he said, well, it should have five parts. So one part is memory. So there's a memory. What's that memory look like? It's the same that you saw last week, right? So it's able to read or write every cycle, maybe take several cycles, but it's able to read or write. The computer's instructions on the program the computer is going to run, we're going to put into that memory. So that's part of the model. You could put it in a different memory. There were other models that had the program somewhere else, for example. But in the von Neumann model, the program and the data and everything will go in this one memory. So the memory is going to use two registers. So remember, we've got an address and we've got data. So we're going to use some registers to manage moving data in and out of the memory. And so we're going to have an address, memory address register associated with the memory. And that's just going to hold the address that we want the memory to read from or to write to. So there's what we call MAR, which is memory address register. And there's also what we call the MDR, memory data register. So when we want to do a write to memory, we'll put some bits in the MDR, and then we'll put the address in the MAR, and we'll say go. And the memory will store the bits from the MDR at MAR. And when we want to do a read, we will set the MAR to the address and say go. And the memory will put the bits from that memory location in MDR, and then we'll take them out of the register and do what we want with them. So that's how our memory will work in combination with these two registers just to help things move around in the data path. We're also going to have a processing unit. So the processing unit is going to do all the operations, and it's going to define what we call the word size. So you've probably heard, mostly probably about operating systems these days, but the underlying hardware also has a word size. So your processor might be a 64-bit processor or a 32-bit processor. Usually your laptop, your desktop are probably 64-bit processors. Your phone is probably a 32-bit processor. The processor in your watch might be 8 or 16 bits in terms of the word size. So what does that mean? Well, if it has an adder, if it has a multiplier, those are usually 8 or 16 or 32 bits. It depends on the word size. I'll show you some other pieces that will also usually depend on the word size. So typical word sizes are 32 and 64 bits, but you can go out and get small microcontroller chips that have still 8 and 16-bit word sizes. So inside the processing unit, we're going to again have two things. One will be what we call the arithmetic logic unit, or the ALU, and that'll do the work. It'll handle the operations like addition. If we have multiplication, we'll have that too. That's what operations we want the processor to be able to support. So we'll talk about that for LC3 later. The processing unit also has a register file. So the register file is going to have actually flip-flops, or registers. So it's not SRAM, it's actually registers. And that's basically going to just give us a place to put values temporarily. It'll be faster than the memory, faster even than SRAM, but it'll be smaller. So faster but smaller. So let me give you some details. So as I mentioned, it's going to use flip-flops, so they're actually on the same clock. So typically, you'll be able to read things out of the register file in one cycle. That's not usually going to be true for memory. Even SRAM, sometimes it's going to be slower than a cycle. So it's faster than SRAM, much faster than DRAM, but there's usually only 10 or 100 registers. Not quite. Cache is usually SRAM. And a cache is also not usually visible architecturally, meaning that from the writing of the program point of view, you don't know whether there's a cache or not. It's purely for implementation performance purposes. But let me give you an analogy. So you guys probably have your Pat and Patel sitting on your work desk in your apartment or your dorm or whatever. When you go back, you frequently need to do 120 work, and you probably got your boxed two or you didn't until this week, and it's right there next to you. That's kind of like the register file. You have very few things on your work desk, but those are the things you use a lot. You probably also maybe have a bookshelf. So you got your old calculus book or maybe your current calculus book. But some other things that you might want to look at once in a while, maybe even a dictionary. Well, I guess you do that online now. But you've got some things you don't use that often, but your desk is here and your bookshelf is there. And then probably most of you, I still have this stuff too, back at your parents' house, you probably have a room full of stuff. And that's where everything you've ever collected, you still have there. Takes a while to get there for most of us, but it's big. So that's kind of like the register file is your desk. The cache is sort of, it's not nameable, but it's sort of like your bookshelf. When you need things, things come off the shelf on your desk, you use them there. And then the memory is more like your parents' house. It takes a while to get out there. Actually hundreds of cycles sometimes to get to DRAM memory compared to a processor. So we have a memory hierarchy in most digital systems. And it's made up of the register file, SRAM, and DRAM. So the details of SRAM you'll learn in how it's used in caches, you'll learn in 4.11, if you take 4.11. So all right, so there are usually only tens or a hundred registers, again, for speed reasons. If you build something with a thousand or a million registers, usually that means you can't complete things in a cycle. Or rather, the clock speed of getting something out of that with the big muxes is too big for what you want the clock time to be, the cycle time. All right, so as you might expect, registers in the register file are named with bits. So there's a bunch of them, maybe eight, maybe 128, we name them with bits. So data moves between the memory and the processing unit. We'll do stores to move data into memory, loads to get it out. So these black arcs mean data moving between the pieces of the von Neumann model. So a computer also needs to be able to get input from the external world and also give output to the external world. So for example, keyboard, monitor, mouse, disk, printer, network, so forth. Someone asked me early in the class why I keep talking about the number 42. And in the same set of books, there's a story about people building a computer to answer, what is the meaning of life? And so for the first generation, they built the computer and they ran it and they ran it and they ran it and took several million years. So the people who built it, they didn't get to know the answer. But the people, when the computer was ready to give the answer, they found out that the designers forgot to include output. Start over, second generation. Yeah, so not with von Neumann. With von Neumann, we're going to have input and output. So those are two more of the pieces, some kind of input, some kind of output to make the computer useful. See, if they'd only studied 120, they wouldn't have done that. So what's missing? We're going to have a control unit. So we're going to have two registers in the control unit, in addition to the finite state machine, we're going to have a program counter. So the program counter is going to say, well, where is the next instruction? It's a memory address, right? Where is it? So that way, the control unit can go get that instruction and execute it. So when it gets the instruction, it's going to put it in another register called the instruction register. So you can have some representation for instructions. We'll go get the bits of the instruction out of memory at the address specified by the PC, and we'll put it into the IR, and then the finite state machine will look at the instruction and do whatever it says. But the bits of the instruction will go in the IR. Yeah, but historically, it's been named counter. But it is an address, yes. So you can think of it as pointing to the next instruction. Yeah, so for those of you who don't have much experience in the software world, there's a notion of pointers in languages, and it's one-to-one with addresses in memory. So a pointer is just an address. So when you start, I mean, in 220, you'll make use of that. But it's important to understand that a memory address is a pointer and vice versa. So counter may be not the best name. Instruction register 2, yeah, in fact, the Intel term for PC is IP, instruction pointer. So if you play with x86, you'll see that. OK, so control arc's going from control unit to everything. Control unit's in charge of everything. So that's our von Neumann architecture. So here's just a summary slide. So you've got the five pieces, processing unit, memory, input, output, control unit. So yes, it does, actually. I mean, there are signals, data path outputs that will come from the processing unit. I should have drawn them, but I didn't. They're data path outputs. They're not really control, because the control unit decides what to do with them. So it's kind of data. So I should have drawn a data arc coming from the processing unit to the control unit. And also, the control unit is fetching instructions from memory. So if you wanted to, you can think of it as data coming down here. Good question. Anything else? All right, so let's then go back through this and think about LC3 ISA. And we'll put numbers on each of the pieces and talk about a little more specific detail for the computer that we're going to look at. So what is LC3? So little computer three ISA was developed by Yale Pat and Sanjay Patel basically as an educational tool. So the design is every aspect they thought about, well, how is this going to help people learn? How are we going to avoid putting them off in the wrong direction so that later they can learn more, but make it simple enough that they can do it in one year? The book's meant to be a one year sequence. So as Yale says, it took them three tries to get it right. So they tried three times, and the third time it stuck. So this is LC3 as opposed to LC1 or 2. So that's where the name comes from. In our class, so LC3 is an ISA. It's only instruction set architecture. The book also has a microarchitecture. So you could build it any way you want. The ISA and the microarchitecture are two separate abstraction layers. You can build an LC3 processor any way you want. There's an LC3 processor implementation in the book. So we're going to look at that and build up towards that eventually in our class. There's some alternative strategies outlined in the notes, a little bit simpler maybe. But the one in the book is kind of the one we'll build towards. You can understand how that'll work. I put this slide in here just as review, but we just saw it. So let's start again with the memory. So in the LC3, memory is 2 to the 16 by 16 bits. So part of the ISA says, well, here's how big the memory is. So 2 to the 16 addresses, let's call that number X. X is 16. And 16-bit addressability, meaning every memory location has 16 bits. So let's call that 16Y. Both of them are 16. The reason I want to give them separate names is I want to ask you questions like this. So you want to remember the MAR stands for memory address register. So it's specifying if we want to do a load or a store to memory, it's telling us what's the address. So how many bits do I need, X or Y, for an address? So I have this many addresses. So how many bits do I need here? X. And I have this many bits at an address. So if I want to tell you an address, I'm going to need 16 bits to tell you which of these. So that's what I called X. At each address are 16 bits. So see, that's why I wanted to separate them out, because it's easy to get confused. The answers are going to be 16 all the time. So on an exam, you just write 16 or 42, which I'm sure is the same in some days. Maybe not. All right. So here, though, what matters, if I want to specify an address that I want to do a load or a store, I have to be able to tell you which address. And there are 2 to the 16th of them. So the number I need is this X, right? This 16 here. I have to tell you which address. So I need log base 2 of 2 to the 16, which is 16 bits to specify an address. So same question for the MDR. So MDR, memory data register, when we read memory, the bits from memory come back from one location and then go into the MDR. Similarly, when we write memory, we put the bits into the MDR before we send those bits to one memory location. So how many bits for MDR? 16. Good. X or Y? Y. Y, right? Good. Okay. All right. So I just want to make sure, because you can design an ISA that has, say, byte addressability. In fact, if you take 411, they'll do LC3B, which stands for byte addressable. And the memory there is 8-bit addressable instead of 16. And so then you have to think about, well, it actually still has the 16-bit loads. So you still need an MDR of 16 bits, but you could have an MDR of 8 bits instead, because the memory is 8-bit addressable. All right. So the ALU in the LC3 supports three operations. You can do and. I'm sorry, add. You can do, that's, choose complement add, by the way. You can do and, and you can do not, all on 16-bit numbers. Can I do anything with these? Okay. We had a name for that, right? Logical completeness. Okay. So you know the answer, you just forgot the name. Okay. What about, oh, I don't want to show you that yet. What about or? I thought what we proved was that. I showed you the answer. Darn it. Okay. Well, hopefully you knew this answer too, right? We proved that and, or, and not together were logically complete, right? We also talked about NAND by itself and NOR by itself. So you can kind of get at that here, right? You say, well, I can build NAND, right? I do the and and then I invert it. But and and not also, of course, are logically complete because of De Morgan's law. And if I want or, I do a compliment the not, not b and those together complement it. That gives me a or b. So this was purposely chosen as a set of things from which you could build anything just to make the point of, well, you can build anything out of this. And some mean person, I don't know who's responsible for making the homework, but you can enjoy doing XOR out of these things in an upcoming homework. It wasn't me. Okay. It was me. The register file has eight registers. Okay. So LC3's register file has eight registers. So what do you think we're going to call them? That's probably a good guess, but, oh, no, sorry. Wrong. Sorry, holidays are coming and just getting excited. Yeah, R0 through R7. The R is just for humans. The computer calls them 0 through 7. But we'll refer to them as R0 through R7. You'll see in the instructions, it'll just be three bits, 0 through 7. Yeah, so register renaming is useful for getting rid of false dependences and things like that. And it's way out of the scope of our class. It's 4.11 material. So happy to talk about it later. Okay. So LC3's word size is 16 bits. ALU operates on 16 bits. Registers are all 16 bits. Input and output. So we're going to have one input device. It's a keyboard. We're going to have one output device, which is a monitor. That's it for the LC3. Monitor, display. I always call it monitor. The book always calls it display, so I put both. Little extra information. This is all 220 stuff, so you don't really need to know this. But the way things interact, the keyboard, humans are kind of slow compared to a computer. So there's only a key when a human pushes a key. So there's also a keyboard status register that says, well, the human pushed a key. So that's what this status register is for, KBSR. It says, okay, human pushed a key. So your program can look at that and tell when a key has come in. The programming will do. There are some operating system services that handle dealing with all these registers. So you don't need to know this, really. But if you're interested, the keyboard data register then in the LC3 delivers that key in ASCII. So if you push the letter A, that lowercase, that would be 61 hex. So the keyboard status register would tell the LC3, hey, there's a key ready. And then when your program looked at KBDR, it would get the ASCII character for the letter A. So that's how this works. It's in chapter 8 if you're interested. So, there's also a display status register. Again, the processor is much faster than the display. And if all you do is pump data to the display, the display is going to drop some of it on the floor and it won't show what you want it to show. So you have to ask, are you ready for another character? You use the display status register for that. And then the display data register with the LC3 is set up. So you give it an ASCII character and it prints that ASCII character to the display for you. So that's how the devices work on LC3. But again, you don't need to use that until 220. You'll see it in the first three weeks or so of 220 when you take that class. So remember, the program counter stores the address of the next instruction. And LC3 memory is 2 to the X by Y bit, where X and Y are both 16. So how many bits do I need in my program counter? X, right? It needs to tell me an address. So it doesn't matter how many bits are at that address. What matters is how many addresses are there. So there are 2 to the X addresses. So if I take log base 2 of 2 to the X, I get X. So I need X, which is 16. Everything's 16. All right. So the instruction register then stores the encoded bits of the instruction being executed. How many bits in the IR? Why am I asking you? Because I want you to think. Okay. So why shouldn't you know the answer yet? You're making some assumptions, right? So how do you encode instructions? So you can encode instructions using some variable number of memory locations, right? So in x86, for example, an instruction can be from 1 to 16 bytes. In the LC3 ISA, every instruction is 16 bits. And that was deliberate. It was a deliberate choice to say, well, let's make the instructions all fit in one memory location. So it was a design choice by the authors of the textbook so that each instruction would fit in one memory location, makes the instruction set architecture and the microarchitecture substantially easier to understand for the first one you're looking at. You don't have to do it that way, but those were design decisions by the architects. So yeah, the IR requires 16 bits for those reasons. If you change the addressability of the memory, you could then ask, well, should we change the ISA completely? If we make it 8 bits, should it be an 8-bit instruction set architecture where every instruction takes 8 bits? Should we just keep it at 16? Should we go to 24 or 32? Many, I mean, basically anything you want, right, if you're designing the ISA. So these were just choices they made to decide that every instruction is going to require 16 bits. So here's what the data path looks like for the LC3. So this heavy black line here is a bus. I'll zoom in on a few pieces in a minute, but generally speaking, everything in this diagram you know how to build from transistors. So you can see the bus, if you look at the things going on to the bus, sorry, it's a little hard to see before I zoom in, but you can see there are tri-state buffers gating things going on to the bus. So basically there's a distributed MUX that says, well, which thing do you want to put onto the bus in any given cycle? And of course, the control unit is sending out control signals to decide that, right? So in a given finite state machine state, the control unit will say, well, maybe I want this ALU to put its answer on the bus, and then that answer will go back over here, and I'll store the sum of my addition back into the register file, for example. So this part here is basically the control unit in green circle. This part's the processing unit, the memory is down here, and then this part over here is IO. So you can kind of break the data path up into pieces. So let's take a look at those pieces and make sure we understand them. So here's the control unit part. So let's see. So up here is the program counter. The instruction register's down here. So I think on Monday I will show you how the control unit uses the PC, puts it out on the bus to go down to the memory, reads the instruction out, the bits of the instruction, then go into the IR, and then you can figure out what the instruction is and execute it. What's a bus? Ah, so remember when we talked about tri-state buffers, I said that you could hook all the outputs together, and if you did that, if you just had a bunch of wires with different tri-state buffer outputs onto them, you could call that a bus. So it's basically a bunch of wires with multiple pieces of logic gated with tri-state buffers that you can put their answers on by signaling the tri-state buffers. Does that make sense? So let's take a look here. So for example, I can take the PC and I can write the PC's value onto these wires by having these tri-state buffers copy it. I can also take, let's see if there's another example. Yeah, this is Marmux. This is calculating the memory address. So you can see there's another set of tri-state buffers here. So I can take the value calculated by this Marmux and I can also write that onto the bus. I'll go back a step. You can see the ALU output also has a set of tri-state buffers. So this is basically, these thick black lines are 16 wires that go around the chip. That's it. It's 16 wires. And there's a bunch of things, logic outputs that we decide which of those should we write to those 16 wires using tri-state buffers. And that's what we call a bus. It's not any more complicated than that. I think I mentioned that when we talked about tri-state buffers. That's right. They're just wires. And just like all other things, you can't short them. That's why they have all the tri-state gating in here. So we use the same, maybe I can zoom in on it. So you see there's an LDIR for that register. So just like when we built our data path, we said, well, the register is not going to load every cycle. So when the control unit wants a new value in the IR, it tells the IR to read the value from the bus and store that value. And when it doesn't, it sets LDIR to zero. And so pretty much everything that takes its value off the bus is gated in the same manner, that there'll be a load signal of some sort. Yeah. Sorry, I'm not sure what it is. I mean, that would be a point-to-point network. So I mean, a lot of modern chip designs are moving more towards point-to-point networks on the chip. But a bus is a shared medium. I mean, that's the other aspect to keep aware of a bus, is it is a shared medium. So all of these things can write to it, but if more than one write to it, in the electrical case, that'll be shorts. So it's a bad thing. Yeah. Eric? So, as long as the finite state machine follows the rules that it doesn't try to set gate PC to one at the same time that it sets gate Marmux to one, or any other tri-state buffers gating things onto the bus to one at the same time, then those wires will not create shorts. And so the finite state machine is responsible for guaranteeing that only one of the gating signals is one at a time. And so that's part of the FSM design at that point. Make sense? Yes, yes. So just like when we draw a MUX like this one, this is actually 16 two-to-one MUXes, remember? We said, well, this is not just one two-to-one MUX. We've got 16 here, 16 here, 16 coming out. This is actually 16 two-to-one MUXes controlled by the same signal. When we draw a tri-state buffer across a wire that should have a crosshatch on it, sorry about that, I just took the figure from Pat and Patel, it should be crosshatched with 16. So this is 16 tri-state buffers with the same enable signal. Yeah. I'm sorry? Yes, the bus has 16 wires because the word size is 16. And so everything we do, when we add things together, we're adding two 16-bit values and getting a 16-bit answer. When we move data from memory, it's 16 bits coming out. When we store data to memory, it's 16 bits going in. So that's why there are 16 wires. But everywhere here, there are 16 tri-state buffers because there are 16 wires on the bus. Yes, that's right. That's right. So, and it's up to the finite-state machine to guarantee that all of the tri-state buffers other than one set are in high impedance mode by sending them zero as they're enabled. Yes, the control unit controls every open signal you see here. So the address MUX input, the MARMUX input, the load PC, the load IR, the load condition code down here, every control signal of the data path is up to the control unit to control. Yeah. Yeah. So in that sense, it's identical to the data path that we developed. There are a set of control signals. In this data path, there are a lot more than the six we have. But it's up to the control unit to set those for each of its states. And we'll look at that in more detail later. We'll look on Monday at the process of fetching an instruction and then decoding it and think about how it would be executed. But we'll look in detail in a few weeks after we do some programming at how you would actually execute one or two instructions on this data path. If you want to read ahead, section 4.1 of the notes, we'll talk to you, we'll show you specific control signal implementations on this data path. Okay. So program counter, instruction register. So this is some miscellaneous instruction execution logic. It'll make more sense once you've seen what the LC3 instructions can do. This is our finite state machine generating all the control signals. So there's the state in here. And it basically sends out all the control signals. They're not wired up just to keep the diagram from getting too cluttered. But they drive all the control signals in the data path. Okay. So let's also take a closer look at the processing unit. So this was on the right side of that figure. This is just the bus coming around. You can see that you can take the ALU output and put that on the bus. The register file can read a value from the bus and store it into a register. So here's the ALU. It does these three operations, add, and, did not, all 16-bit, two's complement addition. There's the register file with the eight 16-bit registers. So one thing I want to make sure, because we didn't cover this explicitly in class, but I don't think it's that hard to do. So if I have eight registers and I have a three-bit number telling me which register I want to read, can you build that for me? On the reading side. So you've got eight registers and I want one of those registers to come out, say, on this set of wires. I want to pick one of eight. How do I pick things? A mux, right? If I want to pick things, I use a mux. So I want to pick one of the eight registers to read. I'll have eight to one muxes. I'll have 16 of them. And that'll give me one output. And then I'll have a bunch of other eight to one muxes for this output. On the write side, when I want to write to one of those registers, then I need the decoder. Then I need the decoder to tell that register, you should be storing the value. So I can route the input to all eight registers and then use a decoder to tell one of those registers, well, you should do a store now. You should load a new value from your input. So this register file is capable of doing one write and two reads all in the same cycle. So let's take a little look at the memory here. So here's the memory to the 16 by 16 bits. There's the MAR. There's the MDR. You can see the MDR is gated, but it can also take data off the bus and store in the MDR. So for a load, what we'll do is tell the memory to give us bits. And those bits, there's some address logic associated with the I-O, but they'll come back and go into the MDR. And then from the MDR, we can copy them onto the bus and put them where we want them. For a store, we'll first write the bits to the bus and put those into the MDR. And then from the MDR, we'll put those into memory for the store. So we can do loads and stores with this arrangement, with the MDR, MAR, and the memory down here. And the details of the I-O, I have it in the diagram, but I'll leave it for a 220. So more questions on Datapath? We talk about instruction formats. So how do we represent instructions? Good. Good. Yeah. Okay, so instructions are encoded by some representation. Whoever's going to design the ISA says, well, here it is. Here's the representation we're going to use. Design decision. 16 bits, that's a big representation. Should we get some paper out and start writing all the instructions? I take a while. We've got 65,000 choices more. All right. First, I want to do a little exercise. Yeah, it will be bits. It'll be bits. Yeah. There'll be bits involved, I guarantee it. Seem good? We're on? Okay, good. So since we're all on board, here, let me tell you what I want. You put in a quarter, you pick one of your favorite flavors. I mean, now, there used to be another flavor here. It was a beverage. It looks, yeah, it's not legal for some of you, so it's no longer here. So now we have cola, lemon, orange, and grape. A little dull, but I was a little worried about putting another copyrighted one trademarked one. I'll leave the design to you. I just need a little help. All right. So four flavors, and I want you to dispense one of those four flavors for 10 clock cycles. So let's count states. So let's see. So when you come up to the machine, the machine's off, and then you put a quarter in, and then that'll go to a half coin state. So that's two. Okay. So help me out here. So if you're going to dispense cola for 10 cycles, how many states do you need? 10. 10? All right. 10? Okay. 10. Good. What about lemon? I really like lemon. How many for lemon? 10? But I like lemon. You sure it's not 12? All right. What about orange? I hear 42s. This one takes three. All right. All right. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. So let's see. All right. They're making fun of my slides now. Okay. Okay. So let's make a table. Did you get that? I heard this earlier. Awesome. I'm happy. Can you help me out again? I'm hearing some sixes. Six? Six? Okay. Whatever you guys say. Six is good. I have a suggestion. Instead of six, can we do seven? Because six sounds painful to me. Maybe you can try it, but I like to use seven. I want to have one bit that says, you know, did you put a coin in yet or not? I'm going to have two bits that say, well, we've got four flavors. Which flavor do you pick? I'm going to have four bits that will just be a counter that will count to 10 down or something. So here's how I think it'll work. So you put in your quarter, that turns on the coin bit, and you pick a flavor and that goes into the flavor bits, but you can only do it when the coin bit is on. Otherwise you have to put a coin first. So you pick your flavor, that loads 10 into the counter and it sets the flavor that you picked. And then the counter will start counting down. And then to dispense the soda, we'll have a decoder. We put the flavor into the decoder and then we'll put the counter nonzero signal, which we can just easily, you know, do an OR gate out of the counter bits or something. And we'll put that into the decoder enable so that if the counter is not zero, we'll get soda from one of the four flavors. And if it's zero, we won't get soda. One decoder, handful of gates, and an extra flip-flop over a six-bit solution. Yeah, so you might need a priority encoder. It's true. Good point. Okay. So put priority encoder down here too. Or just keep the humans away from the machine. All right. It's only for me. I promise not to push them off at one. All right. Kids, back away. All right. So why does this work well? So adding these extra bits lets us organize, adding one extra bit in this case, lets us break the bits into meaningful groups. So we can have the coin bit, we can have the two flavor bits, we can have the counter bits. And relevant here, so mathematically that means when we look at, well, what flavor do we want to send out, we don't have to look at the flavor bits and also at some function of the counter bits. We don't have to look at the coin bit at that point. But relevant is based on these meanings. So by making these things meaningful and separating them into groups, we actually not only make it easier for ourselves to understand, but we make the logic easier too. So remember when we talked about how do you pick representations for finite state machines? And I said, well, often you want to try to use human meaning. Now it's going to be much more important. We have a 16-bit representation to deal with for instructions. That's a lot of bits. That's a lot of meanings. So we're going to break things into what we call fields. So this is the real point. So pretty much any ISA you look at, except maybe x86, which is a little funky because it's grown over 30 or 40 years now. But most ISAs, and even there, where they have this simplification. So you'll have a bunch of fields. So separations of those bits and the encoded instruction. And the first one will be your operation code. So it'll be some bits that'll say, well, what do we want to do? What is the operation you want to do with this instruction? And then the other fields will tell you what the operands are. So well, you want to do an add? What do you want to add? Usually you add two things. So what are those two things? Those will be separate fields in the instruction. So we're going to use this idea that we just developed with our soda dispenser of breaking things into groups in order to design our instruction set architecture. So you'll see that when we look at LC3 instructions. So here, for example, is an LC3 instruction. So it's 16 bits. So over here in green is the opcode. So it turns out that's an opcode that's known as LDR for load register base, which you don't need to know yet. I'll just show you some examples. We'll go through the ISA in much more detail next week. So it has three other fields. One is the destination register. So what are the possible values here? 0 through 7, right? One of the registers. Good. So there's another register, base register. Possible values, 0 through 7. Good. And there's a 6-bit offset, which is a 2's complement offset. So what are the possible values there? So it's 2's complement. So the smallest one, the biggest one would be 0 followed by 5 ones. That would be, I think, 31. And so negative 32. Okay. So here's what it does. So it says, okay, take this offset, assign extended to 16 bits, add it to the contents of this register, go to that memory address, load the bits from that address, and copy them into the destination register. So in words, it's kind of long. That's why we write it in RTL. So you want to know what the RTL means, because otherwise, you don't want to have to write this. So again, take the offset, assign extended to 16 bits, add it to the bits stored in this register called base register, named by these three bits, and then go to that memory location, get the 16 bits out of that memory location and copy them into the DR. That's one instruction. So here's another instruction, which is add. So this is the add opcode over here. It also has three fields and then three things that have to be fixed to zero. So there's a destination register. That's where we're going to put our answer, 0 through 7. There's one source register, also 0 through 7. Good. And then there's another source register. So it says take two registers, add them together, put the answer, the sum, into destination register. That's all. What are the zeros for? Ah, so that's a good question. So why not just let those be don't cares? So there was this commercial architecture called the 6502, let those be don't cares. And it turned out that those don't cares produced some bizarre effects when software people used those instructions with different bits, because they just built a finite state machine and they left them as don't cares. And so it did something. And turned out it did something sort of interesting that the software people decided that they really wanted. And so they put those non-existence instructions in their software. And then when the 6502 architects wanted to produce a new generation, they found that in fact people had used bit patterns that didn't exist in the instruction set architecture. So the modern view of that is don't ever make that mistake again. If you ever want to extend your instruction set architecture, it's really useful to have undefined bit patterns. On the other hand, having software that takes advantage of a particular microarchitecture's don't cares mapped into something is not so attractive from a design point of view. So let me stop there and we'll look more at these next week. Have a good weekend.\",\n",
       " \"Okay, wow, I'm loud. Okay, I think it's three, so let's go ahead and start. Hope you had a good weekend. So midterm material three is over. So everything we talked about today is for the final but not for the midterm. Details, I'll go through that in a second, but details, it's probably best you look at the midterm three page because there's a little bit of midterm four, or rather section four, that we covered in the last week that we're going to include on the midterm three, just to kind of make it a little easier than having a full midterm on finite state machines, honestly. So we're going to have the LC3 ISA, so doing things like decoding instructions you'll need to do on midterm three, for example. So today we're going to go through another example, how to type in a number. So we'll say, well, how do we let the user sit down and type in a number? It'll come in in ASCII from traps, one character at a time, and we'll convert it into a two's complement number. So we'll figure out how to do that. That'll be the example. Then I want to spend a little time saying that computers are dumb just because it makes me feel good as a human. I'll give you some examples. We may or may not get to this today. Eventually, by either today or Wednesday, we'll talk about how we break down problems, and we will give some examples of that too. And then we'll do another long example and then go into assemblers. That's kind of the next four or five lectures. I may add some more examples because the programming stuff before we go back and play with control units, we're going to spend another five lectures through all this week. Review session Monday, and then two more lectures next week on assembly or LC3 binary and assembly programming. So third midterm's coming soon, next Tuesday night. I know you're all excited. You've been having so much fun with finite state machines. So same rules as before, same time, places will be up on Compass. If you need a conflict, do make sure to sign up today through the wiki if you didn't already do so. Coverage, section 3.8, and then the left half of the terminology, which is all LC3 ISA, von Neumann, stuff like that. And then a few of the bullets, which I copied into the midterm 3 page. So it's know how to decode LC3 binary instructions like we did last week. But look at those for details. All right, so review session on Monday, just like before. So come prepared with questions, and we'll do the same thing. I'll sit there. You tell me what you want to talk about. We'll vote on it. You'll vote on it. I promise not to vote. And then, well, at least not next week. You should vote this week. But then we'll do that just the same way. So vote tomorrow, and then vote again on Monday. All right, this slide, you know what it is. It's going to be there till Friday. So let's solve a problem. So yeah. I believe so. They usually try to. The question is, is Eta Kappa Nu going to hold another review session for you? They usually try to do that for most of the core classes. So I believe they will. I don't have the time or place. My guess, the first two were exactly the same time and place, relatively speaking, right? So it was Saturday. I think it was 2 to 4 PM, but I'm not positive. If you look back at the lecture slides, I put it in there. I think it's on the Wiki, too. So it's probably going to be Saturday 2 to 4, and I think it was in 1013B. So 1013 ECEB, rather. So probably all the same, but I'll tell you when I know. Yeah. Good question. So let's see. Yeah, I'll do the slide I had on resources again. I mean, it's things like, well, you can watch the video lectures. You can watch Professor Jaramillo's lectures. If you want to, you can go to the other review sessions, too. All of the four lectures will have review sessions. So if you want more review, you can go to those, Eta Kappa News review session. So let's see how we can take a problem in human terms and translate that into LC3 instructions. So for this one, for the most part, I'm going to do it for you. I may ask you to help me out here and there, but for the most part, I'm going to show you how it's done, and then later we'll talk about how we do it. And then on a bigger example, or another big example, I'll ask you to do it for me for the most part. So we're going to start by identifying, well, what do we need to keep track of? So I'll tell you what the task is. That's what we'll actually do first. But then we'll say, well, what do we need to keep track of? Those are things we're going to put in registers. We'll find at state machines, we had registers in a different sense. Now I mean registers in the register file. But when we were designing FSMs, we would identify information and then put it in registers and counters or state bits, and then we would figure out how we move between states. Here we're going to assign registers from the register file to those stored values, draw a flow chart for our code, roughly with one box corresponding to one or two or three instructions, and then write those instructions in some human readable form and then convert them to binary. And so the whole, this program we're about to do is available to you on the web page. I mean, I can bring it up, but it's the links page. So if you've got it bookmarked or something or type my name into Google, it'll take you to my home page and then go to fall 16, 120. At the bottom, there's a bunch of programs in LC3 or several programs in LC3. This is one of them. So you can download it. You can run it in the lab if you want. You can type in a number. One caveat, if you run it in the lab, I forget which way, but I think it's the GUI that actually changes the character that gets pressed when you hit the enter key. So the code may not work in the GUI because we only check for one key, and it may be a different key that comes in from the GUI. I don't remember right now. So here's what we want to do, though, which is let the user type in a number. So someone comes up and they're going to type in a number. Maybe there's a prompt, but we won't even print a prompt. They'll type a number from 0 to 32767 using the keyboard. When they're done typing their number, they'll press the enter key. So you can imagine why I picked 32767 as the upper bound, right? Okay, good. Yeah, I mean, it's the biggest twos complement number we can store in one memory location. So we're going to read in the number, convert it to twos complement, store it in one memory location, and if the user does something crazy like presses the letter L for LaMetta or something, we'll say you're a bad user and go away. Give them an error message. And if they type 100,000, then when they hit that last key, instead of 10,000, it becomes 100,000, we'll say you're a bad user, go away. And that's it. So we'll give them error messages if they break the rules. So what do we need to store? Before we answer that question, I just kind of wanted to point out that, well, this is a lot like when we were developing finite state machines, right? In fact, you can think of a program as a finite state machine. Your state in that case will be your variables in a C program. In LC3, it's going to be the things you put in registers or the bits you put in memory locations. So we need to think about, well, for this one, the keys are the inputs, including the enter key. The error messages are the outputs. The number typed is eventually read out. I mean, we'll put it in memory, but then if this were a bigger program, we'd take it out of memory and use it for something. So our program is kind of like a finite state machine. So what do we need to keep track of, or what other values might we want to keep around in registers to solve this problem? So user's going to be typing in a number. So they're going to press a key, right? So when they press a key, that's some number they're pressing. So maybe we need a place to keep track of that. So they press a key, better put that somewhere. But there's also some number they're typing. And so even when they're pressing, say, the third key, they've already pressed two, so we better know what they typed. So we better keep track of, well, what number did they type from their previous keystrokes? So there's a couple of things. Let's see, what else? How about FFD0? You like that number? I like that number. You know why? Now do you know why? So when we want to convert their ASCII keystrokes into two's complement, how will we do that? So there's a homework problem ages and ages ago, weeks and weeks. In semester time, it's eons. Remember, we can subtract this number, 30, right? So remember, if we type a number, a digit in ASCII, it's from 30 for 0, 31 hex, sorry, 30 hex for 0, 31 hex for 1, and so forth, up to 39 hex for 9. So if we subtract 30 hex, that'll turn it into a two's complement number from 0 to 1. So this is the number we want to subtract. If we negate that number, we get FFD0. So that's why. If we'd done that with ads, we'd need three ad instructions. Remember that the LC3's immediate ad operand only goes to, it's a five bit two's complement number. So the most you can subtract is 16, or 10 hex. So you'd have to have three separate ad instructions. So instead of doing that, we'll put FFD0 in a register, and then we can use one ad instruction to subtract 30 hex, and then we'll want to convert. And then I also want to have a temporary register. You'll see it's useful. Sometimes I just want to do calculations and then throw them away, right? So when I'm doing comparisons, for example, I need to set the condition codes, but I don't need the answer. So I'll have a temporary register. So let's put the things we want to store into registers. So we know when we use the getC trap20 hex to read a character, the keystroke's going to come back in R0. So whenever we call the operating system and say, okay, let the user type something now, the answer is going to come back to us in R0. And we need to store that somewhere, so let's just keep it in R0. Why make trouble so we have to move it somewhere else? We're going to say, yeah, R0 is the key they pressed. So that was pretty easy. R1 could be the current value of the number. R2 can hold this FFD0 constant, and R3 can be our temporary. So it's pretty straightforward. As long as you only have a few values, we have eight registers. Remember not to use R7. It doesn't really matter which ones we pick. So another question before we go on. So this one I need your help with. So when the user presses a key and we're keeping track of the current number that they've typed, how do we update it? So let me give you an example. So let's say that the user has pressed 3, 2, 7, and 6. So the number they've typed so far is 3,276. And then the user, say, types a 5 or something, or 7. So now they've typed 3, 2, 7, 6, 7. So how do we take the 3, 2, 7, 6, and the 7 and combine them? Well, I don't think this is a multiply by a power of 2. Multiply by 10, and then add this one, right? So let's see. So like that. Uh-oh. So we have to multiply by 10 and add the new digit. Is that right? People agree with that? You already know how to multiply by 10. You could, yes? That would be one answer. All right. So let's figure it out later. Let's do this flowchart. So I'll just draw a flowchart for you, but I'll put it together piece by piece. So when we start, the first thing we're going to do is initialize our variables. Generally speaking, any time we start a program, when we have things we're storing, we need to think about all of them and think, well, do I need to put some specific number in that register before I start, or can I just leave it as bits? So we'll go through and do that, but first let me go through the whole flowchart. So the first piece is, well, let's make sure if we need to, we initialize any variables, like r0 through r3. The next step then is, well, let's go to the keyboard, or rather go to the OS, and say, hey, let the user type a character. So once they type a character, then we have to ask, well, did they press the Enter key? And if they press the Enter key, then they're done typing, so we should store the number and finish. So if that answer is true, the key they pressed is Enter, then we're going to store the number, and then we're done. On the other hand, well, what if they didn't press Enter? Well, if they didn't press Enter, we have to ask, well, did they press a digit or not? Did they press something else? And if the answer is no, they didn't press a digit, well, then we should print the error message, and then we're done. We're not going to ask them to start over or anything nice like that. We just quit. All right. Very simple program. All right. If they do type a digit, then we have to do our multiply by 10 thing, add in the new digit, and, oh, check for overflow, right? We said, well, if there was overflow, then we'll print an error message. And if there's no overflow, what's next? Read another one, right? Let them type something else. OK, so that's it. That's our whole flowchart. It's not, it's hard to cram into a PowerPoint slide. It looked a little nicer on paper, but hopefully it's not too hard to follow with the animations. Yeah, Mohamed? If the conversion with the new digit has caused overflow, yeah, yeah, because remember, we can only go up to 32767. If we go beyond that, we're not going to be able to store it in one memory at a time. Anything else? All right. So here, now we're ready to write instructions. So we'll start with this one. So let's step back for a minute. Well, which ones do we need to initialize? So here's our table. So what about R0? Do we need to set that to anything? Why not? It's going to get filled in for us, right? We don't need to put any bits there, because when we call the trap to get a key from the keyboard, that trap's going to overwrite whatever bits we have in R0. So there's no point putting anything in there. So that'll get filled by Gitzee. What about R3? Just a temporary, right? So skip R3. R2, we better set to FFD0, right? Our code's going to assume it's got that in there, so we better set that. Uh-oh, what about this one? What should I set that to? You guys are good. It took me several slides to figure that out. All right. All right, fine. All right, so how do you figure that out? Well, you've got the rule that we developed earlier. And you say, well, when I start, if the first thing the user does is presses a key, like 5, then we want the new value to be 5. So we need to solve this equation, right? 5 is the thing we're going to calculate, the new value. And that'll be 10 times whatever we initialize current value to plus the key we pressed, which was 5. So if you solve this equation, you get current value equal to 0, right? So you want to initialize current value to 0. It has a strange side effect that if they run your code, you immediately push Enter, then you get the number 0, right? Which maybe you want to give them an error message on that, but I'll let you extend that in the code if you want to. So we'll initialize R1 to 0. This code won't do it. The code on the website either won't do it. So now we're actually ready to write some LC3 instructions. So how do I get FFD0 into R2? Well, one way is to use a load instruction, right? I can put FFD0 somewhere in memory, and then I can use an LD instruction to take it out of memory and copy it into R2. So let's use a load instruction. There it is, destination R2. And what's the offset? Yeah, we don't know where it is, right? Because it has to go after our program, but how big is our program? How many instructions is this going to take? We have no idea, right? So we just leave a blank line, and we'll come back to it and fill it in, right? Because we don't know where it's supposed to go right now. So we'll leave a blank line in our code. So for R1, if we want to put 0 in a register, we can use, for example, the AND instruction. Question? Could you build backwards? You could, yeah. That's one idea, but I kind of have the same problem. It's a little easier, so I could build backwards knowing that this is a 3000, and any time I need something, I could put something earlier and go and change the start of my program, make it earlier and earlier. One issue will be that when you load a program into the simulator, at least, the PC will get set to the start of your code. I'm sorry, not the start of your code, to the start of that block of bits. So if you set, for example, if you put it at 2FFF, then when you loaded your program, the PC would be 2FFF, not 3000 hex. So it's a little bit of a hassle with the tools we have. It's a perfectly valid way to do things, but it would be a little bit of a hassle with the tools. Yeah. Good question, though. Yeah. Yeah, so you can do that. We try to discourage you from interleaving code and data just because a human tends to get confused by that sort of thing, right? So it's good habit just to try to separate out your code and your data. And when you're really writing binary, it's a little bit hard, but as we get up into assembly language, it'll be much, much easier. And it's just good practice because when humans look at things, it's easier if you say, well, the data are in one part of my file and the code is in another. It's a little easier for people to read and understand most of the time. Yeah. It's a good question, though. I mean, sometimes that's not true. Sometimes there'll be data that are very tightly associated with a particular piece of code, and so those you might still put next to it. But literally putting, you know, OK, I need to load something. Let me just branch over it. That kind of thing people try not to do. It's also extra instructions, right? It's an instruction you didn't need to execute. So your code will run a little more slowly because you did that. Does that make sense? Yeah. So that is what Sasha was saying is we could, our code is going to go down, right? Because so Sasha was saying we could put it at 2FFF, for example, and we could do that. It's a little bit of a hassle with the tools you're going to use in the lab, so I don't want to just, I don't want to encourage it because it might lead to confusion. So there's a contiguous set of bits, and so they have, the tool has no way of knowing which things are data and which things are instructions. So it sets the PC when you load the contiguous set of bits to point to the first set of, the first word. So when you loaded your code, it would then, the PC would point to your data. You'd have to change the PC before you ran your code. And I think the other thing is we're going to have lots of offsets and not all of them would benefit from this solution of saying, well, OK, let's put it back. We're also going to have branches in the code, right? So we'll have to go to different pieces of code. Those we won't know where they are until we write them. So my point here is just to have these blanks because later, once we've written the code, we're going to have to go do counting and fill in the offsets. So even though, yeah, we could fill this one in, we won't be able to fill them all in. So that's kind of the point. So there's, so for R1, you will use the AND instruction. So AND R1, R1 with number 0. So that'll force a 0 into R1 and satisfy our initialization. So now we've finished initializing the variables. We can move on and read a character. So to read a character, we just use trap 20, so 20 hex, that is. So write trap 20, get C, and that'll get a character and bring it back in R0. It'll actually wait until the user presses a key. So our program will stall until the user's pressed a key. Then when it continues with the next instruction, there'll be a key in ASCII in R0, keystroke in ASCII in R0. So now I want to do this. What is that? Anyone know? And why would I want to do that? Yeah, so this one is the out trap. So that will actually send that key that they pressed back to the monitor and have it show up on the monitor. So when you read a character from the keyboard, it doesn't just echo to the monitor. If you wanted to write a video game or something, you don't want all the keys they're pressing to move whatever echoing back onto the monitor. So it's a separate trap. But when they're typing a number, it's kind of nice if they can see what they type. So we're going to have it echo that key back to them so they can see it as they type it. So it's not necessary. We could make them type their number blind, but it's a nice thing to do to echo it. So all right, so that's reading the character. So now we need to check that character for enter. The enter character is, or the enter key produces ASCII code 10, number 10, decimal 10. So R1 is the key pressed. So we're going to have, I'm sorry, R0 is the key pressed. So we're going to use an add instruction and subtract 10. And where should I put the answer? Maybe R3, right? I don't need the answer for anything. I just need the condition code. So I'm going to throw the answer away. So I'm going to add R0 to negative 10, decimal, and put the answer in R3. So now my condition codes are set, right? If they press the enter key, the zero condition code will be set. Otherwise, some other condition code will be set. So I can branch on negative, I'm sorry, branch on Z. That'll mean go somewhere if they press the enter key. So where should I go? I don't know. We didn't write that code yet. So we have to leave it blank. That code's somewhere in the future. I mean, we could write that code next, but then we'd still have the same problem, right? We'd have to figure it out how to branch around that code. So we'll branch for when they press the enter key, and we'll leave it blank. So remember, this instruction writes to R3. It writes to all of the bits of R3. So nothing reads R3 here. So whatever bits were in R3 get thrown away. Good question, but we never use the bits of R3. First thing we do is throw them away. So there's no point in setting them to anything beforehand. Yeah, yeah, that's next. So I'm just going through the flowchart in some order, but definitely following the arrows. So we did a branch. We got a blank label. So now what's next? We could go either way here, right, because we made a decision. We decided to go this way, to is a digit. This code will have to come back later and write this code and fill in the offset. So let's go up and check if it is a digit. So how do we check if it's a digit? So let's see. So R2 has negative ASCII digit 0, FFT 0 in it. So I could, for example, convert the key to binary, right? So we've got R0. So let's convert that R0 into a binary number. And if it's a digit, it'll be 0 to 9. So how do we convert it? Well, we just add R0 and R2 and store it back in R0. So now R0 will have an, if they type a digit, it'll have a number from 0 to 9. If they didn't type a digit, if, for example, they press something, if the answer is below 0, it wasn't a digit, right? So we can branch negative and we know it's not a digit and we can go somewhere. We don't know where, right, because we didn't write that code yet. So we have a blank. Okay. Now, at this point, R0 holds the original ASCII character minus 30 hex, right? So if that was a digit, it's 0 to 9. If it was less than 0, we already went away. So now it has to be anything from 0 up to 9, but it could be bigger, right? It could be they pressed a letter and now it's bigger than 9. So we need to figure out, well, did they press something like a letter or something beyond the digit 9 in the ASCII sequence or the ASCII code? So to do that, we could say subtract 10 and discard the result. So we'll add R3, we'll throw away the result, destination register R3. So we'll take what's in R0 now, add negative 10 to it. That'll produce a number from negative 10 up to negative 1 for digits, a negative number. And for non-digits, it'll be 0 or positive, right? So we can then say branch on 0 or positive somewhere. Okay. That make sense? I'll have a sip of coffee while you think. It's multiplied by 10. Okay, you want to switch? X86, it would be good for 391. All right. So here's some code. It's good, right? Okay, it all works. All right, let's try again. So let's use V to denote the original value of R1. This thing up here is a comment. So anything with semicolon is a comment. You'll know and love them because they'll explain what's really going on without your having to look at bits, or at least hopefully they'll match. So here's the first instruction. So it says, well, let's take R1, that's our current value, and add it to itself. So we'll call that V. So now after this instruction, I have V plus V, I put that in R3. So now after this instruction executes, R3 has 2V. The next instruction was add R3 to itself, put the answer back in R3. So R3 had 2V before this instruction. So 2V plus 2V is what? 4V. Good. Okay, so then we have this instruction, and that's R3, which is 4V, and R1, which is still V. We didn't change R1. So 5V. And then we have this instruction. What's the end? 10V? Good. So now you're happy? All right. You would have added 10 times, and that would have been a fine answer. Only six more instructions, no big deal. If on the other hand you wanted to add 1,000, then do it my way, please. 1,000 times anyway. Yeah, you can do this generally with any multiplication. It's basically just shifting and adding. Okay. Yeah, the number of lines should be roughly the number of bits in the thing you're multiplying, plus the number of 1 bits, roughly, and then minus 1. All right, so now we need to add the new digit in. So that's pretty easy. The new digit, remember, is in R0, and then our current value times 10 is in R1. So to add the new digit, just write back into R1, R1 plus R0. We already converted it earlier when we were checking the bounds to make sure it was a digit. We also converted it from ASCII into binary, into two's complement, 0 to 9. So we can just add it in from R0 and R1. R1, remember, is 10V at this point. So this is our final equation value. We store it back into R1. Now we've updated current value with a new key. Yeah. No. Ah, okay. Let me go back to where you can see the code. Yeah, we threw that number away. And that was important. We didn't want to have to add 10 back to it. Yeah, so when we checked the upper bound, we did the calculation, but we threw away the answer. We just used the Z and P conditions to check if it was above the digit 9. Yeah. But the answer, this one stayed the same. R0 stayed the same. So it still has our digit, which we know is a digit now, from 0 to 9 in two's complement. Okay. All right. So now we can check for overflow. Well, okay. Sort of. We can't really. So for example, the first thing we did was add. So if we had, let's see, let me think for a second. If we had 10,000 and we multiplied by 10 and added 0, let's say, then we'd have 100,000. And the answer is always correct mod 2 to the 16th, right? So if you subtract 65,536 from 100,000, you get something. Actually, is that? Yeah, maybe that's too big. So 90,000 or so, right? It's still a positive number, unfortunately. So if you wait until the end of the computation, there's no easy way to check for overflow. So what you have to do is you have to check basically after each of the ads. So for some number you're typing, each of those ad instructions, you have to branch if it becomes negative, right? It's overflowed if you add those two positive or non-negative numbers and then they become a negative number. So it's easy to check. We have to check after each of the five ads. So the code online actually does all of those checks for you, but you can't wait till the end. You have to do it in the middle. And so rather than adding all of those instructions, we'll just skip the overflow check here. So in class, we're not going to do it. But the code that I've given you online does all of the checking and error message printing. So if we're going to skip the overflow check, it's time to then just go get another digit, right? So what kind of branch should I use to go get another digit? So in this case, I always want to go get another digit, right? So yeah. Yeah, we did nothing to allow them to type a negative sign. Yeah, and in fact, we said that the range would be limited to 0 to 32767. So they could try to type some, if they were to try to type, for example, 40,000. One could have allowed them to then store that as a negative number, 40,000, whatever that is interpreted as two's complement as a 16th value, right? But we didn't. We decided that would instead print the overflow message. And that's what will happen if you run the code that is online. Okay, so let's just use an unconditional branch, right? We always want to go back. So we'll say, okay, brnzp, and then we'll figure out the offset later. So this part over here, we're going to leave on the web page. We didn't do it. But we need to store the number. So we can use an ST instruction to store it nearby. The numbers in R1, so source registers are one, where to store it again, we don't know the offset yet. So leave it blank. And then we're done, except we have a couple of, well, first a halt trap, right? So we want to stop our program. So trap 25x to halt it. And then we need a couple of things for data, right? So we need FFD zero. So let's just put that in memory here. And then we also need a place to store our number. So let's like a little place there for our number. So that's it. That's our program. And we have all those blank lines. Yeah, you ready? Were you going to say bits? I know, I'm sorry. Don't worry, one day we'll get to bits. All right. So there's that one up there. Where's that going? I wanted to put FFD zero in R2, right? Where's FFD zero? Oh, it's down here. Okay. So there should go from here to there. Where's the PC when I execute this load? 3001. Good. Okay. So there's PC. All right, I got to put my coffee down. This is hard. All right. So starting from here, we got one, two, feel free to count along. Three, four, five, six, seven, eight, don't get too excited. Nine, 10, 11, 12, 13, 14, 15, 16, 17. No, don't try to trick me. All right. So that's 11 hex, right? So 11. Good. We're not done. 17 is 11 hex. So one is 16 and the other one is one. 16 plus one is 17. Instead of writing number 17, I don't know, because we're going to change it to bits. So converting, I mean, at some point, it's much easier for me to convert from hex into binary. So I try to go from decimal through hex into binary. Why is the offset 17? That was the counting part. We counted. Yeah, but the offset, so remember on the load, we're going to do PC relative addressing. So we'll use the PC, which points here, and add 17 to it, 11 hex. So if you add 11 hex, you get 3012. So we could subtract, but it's much more fun to count. And actually, subtracting, I don't know, I always find it hard unless I use the ninth complement. All right. So where is this branch? So this was the case where we didn't get a, no, sorry, this was the enter key, right? So this should store our answer. So where is that? Yeah, this is the code to store the answer, right? So we want this branch to go here. And where's the PC for 3005? 3006. Good. Okay. So we're ready to count. One, so we started, this is zero, right? So if we set it to zero, it would just come to this add instruction. So one, two, three, four, five, six, seven, eight, nine, ten. Okay, and that's XA, right? Yeah. Okay. All right. This one, what is this? This is checking our digit, right? So if this is negative, this is not a digit. So I'm going to make that come down to here. But I'll imagine I wrote my error handling code afterwards. We're not actually going to write it. It's in the code online, but we're not going to write it in this code. So let's see. So PC is where? 3008. Okay. So one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve. That's C, right? You notice I'm getting better at counting already? All right. This one was also error checking. So I'm going to cheat a little bit. Let's see. So this is two down. And so if I subtract two from this offset, I should still get the right answer, right? So 12 minus two is ten, which is AX. So A. Okay. All right. What about this one? Where does this go? So that's our branch to go get another character, right? Up to here, 3002, right? This is reading a character. So it should go up to here. Okay. Good. So PC is there. So starting from here, I've got negative one, negative two, negative three, negative four, negative five, negative six, negative seven, negative eight, negative nine, negative ten, negative eleven, negative twelve, negative thirteen, negative fourteen. Okay. So I would write that this way, X negative E. Unfortunately, the negative XE doesn't actually work in the assembler. So we'll put that there. And then this one is easy, right? So where is this supposed to go? There's a place down here, right? So we want it to go there. And a PC is where? Are you getting tired of counting? I think this is the most fun we've had all semester. Okay. Fine, too. Okay. So we're done. Now we can write some bits, right? Oh, wait, there's a bug. We forgot the overflow. Okay, let's go do the counting again. Sorry. Yeah, now you know how much fun it'll be. Okay. So if you make any, if you have any bugs or anything, like you need, you realize you left out one ad, then you have to go recount and recalibrate, right? So it's really kind of a pain. You'll get tired of it soon if you're not already tired of it. So here's the first instruction. This notation, by the way, is assembly code. I think I mentioned that before. So it's very human friendly. But we need to turn this into bits, right? Because the computer only understands bits. So what is this opcode LD? You know? 0010? Okay. And then that opcode has two fields, right? So the first one, we want it to be R2. So what do I write here? 010. And then what do I write here? Okay, do you get it right? I hope so. All right. Yeah, as I think I said last time, you know, once you type all these in, so a couple notes. So one, when you type them in, include the spaces in your program because you want to make it easy to read, right? For yourself as well as people who are grading it or whatever, right? So just include the spaces and add a comment, the semicolon thing. I'll actually show you an example in a second. You can use the assembly notation. You can use RTL notation, whatever. Just make it clear what those bits were supposed to do. So it'll look something like this, right? And so forth, and just the rest of the code. Your program, by the way, starts with a starting address. So this is 3000 in hex or rather in binary, there's 3000 in hex over there to explain it to the humans. The other comment is even after you've done it this way, you're very prone to typing one instead of zero and vice versa or leaving out a zero or something. The tool will warn you if you don't have 16 bits. But if you manage to transpose digits or something, it doesn't know, right? If you have 16, it just says, okay, great. But what you can do is then once you run it, you can take it into the simulator and you can list it and make sure that the instructions that it shows you are the instructions you meant to happen. So and it'll show you, it'll show you hex, but it'll also show you assembly code. And if it does something strange, like turn one of your instructions into a dot fill, that means it wasn't a valid instruction. So usually it'll show you instructions, but for 16 bit values that don't correspond to real instructions, it'll do dot fill or something else when you list it. Okay, so one more, and then we'll, we'll just let you do the rest. So here's an and instruction. What's the opcode? 0101. And so and has a couple of a few fields always, right? It has a destination register. So what is that one? 001. And then source register one, 001. And then which mode? The one immediate mode, right? So once we have immediate mode, then there's a five bit twos complement field. That's the last field. And what should we put in there? A bunch of zeros. Good. So there's our last or second instruction. And I'll leave the rest for you. So I think you can manage it. Or you can just look it up. We have the code online. If you want, if you want the exercise, though, you know, do go through and change a few of them and you can compare it with the, with the results in the code. So you will have to do this at some point, both in the homework, you have one exercise this week, but you'll, you'll have more in the future, but then also on the final. So in the, in the midterm, it's just decoding, but in the final, it's like that'll be encoding as well. All right. Any questions on the example before we continue? You like the name. I like it too. So the handout I gave you, which I didn't bring with me, but that sheet with the data path and the finite state machine and the encoding diagram with all the RTL, that's exactly what you will get on the midterm three and on the final. So if you want to know, do I have it or not, just look on that sheet. It's also on the, on the wiki. If you lost it, it's under resources, LC3 sheet or something like that. And so that way, if there's anything that's not on there that you want, you can add it to your crib sheet. Okay. So computers are done. So think way, way back to the first day of class, I mentioned Church-Turing hypothesis, which tells us that anything a human can compute, a computer can also compute and vice versa. And so you might think, so what's the difference? What's the difference between humans and computers? They're equivalent. So here's the answer. Humans are smart. Computers are dumb. So what is this? Can you do that one? Anyone? It's 42. Good. All right. Computers can't do that. Seriously, computers can't do that. So it's very difficult to do that, in fact. And what you did is your brain recognizes digits because you think whatever I scribbled up there probably has to make some kind of sense if I'm asking you to think about it, right? And then you say, oh, it kind of looks like digits. And oh, it looks like 19 plus 23. And I know how to do that. Yeah, it's 42. But no one seems to know how to explain that to a computer. I mean, a lot of things our brains can do, we don't know how to systematically solve. And so because no one can get a computer to do things like that quickly, we can put things like that up and call them CAPTCHAs. And then if it happens quickly, if we get an answer quickly to, well, what text is here? Solve some little problem or do something like that in fuzzy, bizarre-looking text, usually that means there's a human doing that, as opposed to a computer robot who just wants to create lots of accounts on your website. So that kind of technique is just an example of many kinds of things that somehow human brains do really well and quickly, but we still don't know how to describe it. And computers can't figure it out themselves. So if a computer is going to do it, some human has to figure out how to do it systematically and break it down to the level that a computer can also do it. So I may have said, and I might say in the future, something like, oh, the LC3 only understands two's complement. So what does that mean? LC3 is not human. LC3 understands nothing. It's a computer. It's just bits. So what am I trying to say if I say something like that? Well, the LC3 hardware and instructions set architecture have a bunch of fields that are two's complement fields, and the hardware has a bunch of sign extensions. So part of the LC3 ISA interprets bits as two's complement values. When we add an immediate value, when we and an immediate value, when we add a PC relative offset, all of those are two's complement values, and they're interpreted as such because of the definition of the ISA and because of the hardware in the data path. On the flip side, when I say it only understands two's complement, what I mean is, well, if you want to do floating point, good luck. You're going to have to write all of that in software. There's nothing in the LC3 instruction set architecture to help you. It is complete. You can do anything. You can do any Boolean expression and so forth, but any other data type, you have to translate operations on those data types into instructions. So you have to write software to do those things. So here's an example of a software representation. So over here in memory, I've shown you three instances. One of them has an ASCII one digit. One of them has an ASCII nine digit. And then the last one has an ASCII null, which is just a zero. This is often how we store strings in memory. So if I want to store the string one nine, then I would put the one, the nine, and the null in consecutive memory locations. And then when I wanted to talk about this string, I would just tell you, OK, my string is at address 4012 hex. And if you wanted to read it, you'd go to 4012, and you'd look at the memory, and it'd say, oh, there's a one. And then you'd look at the next location and say, oh, there's a nine. And then you'd look at the next location and say, oh, OK, there's a null. That's the end. So if I wanted a longer string, I'd use more memory locations and so forth. So that's a string. So here's another string. What is it? 23, right? OK, good. So say that the LC3 does this. So you tell the LC3, OK, this is string one. It's 4012. So put 4012 in R1. And string two is 7196. So put that in R2 and then add them. What's R3? B1A8? If you tell the LC3 to add two 16-bit numbers, it adds the two 16-bit numbers, right? It doesn't know what they're meant to be. So what's stored at B1A8? Bits. Good answer. Bits. So unfortunately, I've actually met quite a few people who have never seen representations and don't know how computers work. And they make this kind of mistake in their programming languages and then they're just baffled. They don't know, well, why doesn't that work? I told it to add my two strings. Oh, I need your help. It pushed go. Which one's the biggest? This one here? This is the biggest of these three? No, it's 41962. I guess you're probably right. OK. What's the smallest? So that's the smallest. And then that one's the middle. You sure? You think that? Are you sure? Maybe double check my... Kind of strange. Really? Because the computer said this is the smallest and this one's the biggest. All right, let's put them side by side. All right. What's bigger, 4 or 9874? Good luck on the midterm. All right. Yeah. So 9874 is the biggest, huh? OK. All right. So computer one, students, how about these two? Let's see. So 4 is equal to 4. 1 is equal to 1. What about comma and 3? So comma. Comma is smaller than 3. So the middle one is 41321. And then the biggest one is... I'm sorry, the smallest one is this one here, 41962. So it seems the computer's right. Yeah. So it turns out if you sort strings in ASCII order, then that's the kind of answer you get. So you might think, well, OK, yeah, that's cute. Kind of silly example, but yeah, whatever. So take a look at the index. You see it here? Yeah..................................................................\",\n",
       " \"example. Just an example of how we how we build a finite state machine with components. And then what I'm going to do is actually we need to do memory before we look at a finite state machine with more components and think about separating how we control those components from our finite state machine design, which will then take us into how we build a computer. But for that design we want to have memory. So I thought maybe I'll move that forward and then if we have extra time relative to the other other lectures maybe we'll just do a finite state machine analysis example in class. But first let's finish the vending machine. Then we'll talk for whatever we can get through out of these memory topics. So first I'll give you an abstract model, talk about SRAM cells. I'll tell you what's in a DRAM cell. There's a picture in the notes if you want to see one. Talk about how we build bit slices and do coincident selection. And then trisate buffers and eventually we'll look at bigger and wider memories. Be sure to start lab 9 early if you haven't started it and when you go in the lab don't let the sunshine in. Because you're engineers not for any other reason. No, remember that the optical sensors if the sunshine hits them might generate noise and then people in the sunshine will have trouble with their lab. So try not to raise the blinds while people are trying to turn in their lab. Alright, so this is just a little review what we were building on Wednesday. So we have this vending machine that we wanted to use components like registers, adders, muxes, decoders. We built a new component called a priority encoder. That's not really one you need to know but it is one that's used for various purposes in practice. And we'll do one module today specific to this design. Basically just to translate our coin representation into a value in nickels. So we can add that number in. I remember we decided to have the the state of the system be some register a six-bit register n which represents the number of nickels held by the machine out of money the users put in so far. Inputs were this coin input which is a representation, three-bit representation, telling us what coin just came into the system. Product selection buttons for the three products that the user might want to buy, one, two, and three. And then the machine generates outputs, one coin except, kind of like the one in the lab, but there's a more complex vending machine saying yes or no, I'll take this new coin or I won't. And if it's rejected the coin mechanism will return the coin to the user. And then if we want to release a product, we've got three product release signals, R1, R2, R3. So we then decided or pointed out that since our finite state machines in our class always have outputs dependent only on state, that we wanted to calculate the outputs based on the current input and the current state, but then we just buffer those in flip-flops or a cycle. Those don't affect our state machine design, but it means they're delayed a little bit. And so we've got four flip-flops that will basically just keep track of the release outputs and the accept output and hold those high or low for a cycle after the state in which they're created. We decided to prioritize our input events. We had 48 arcs we had to think about. We decided, well, let's make it easier on ourselves. So we'll just strictly prioritize the eight different types of input event and the one no input event. So we decided that purchases are the highest priority. So item three, item two, item one, and then coin inputs are all distinct, right? The different patterns on the C input. And so we just prioritize purchases. And then if there are no purchases, we'll do a coin input. And this was a specific example, given three prices that are sitting in registers, a specific example of what our real state diagram next state table should look like. So we said, well, purchase three is the most important. So if I ask for item three by pushing button three, none of the other inputs matter. And in this case, I only had 50 nickels. I needed 60 to buy item three. And so I just sat in state 50. So we went through this table on Wednesday. So I won't go through everything again. But you can actually derive for a given set of prices. You can derive a full next state table at this point. So that's where we were. All right. So now it's time to start thinking about how we're going to implement this. We decided that purchases have priority. So the first thing I want to do is say, well, how are we going to decide which purchase they ask for? Remember, I said, well, if they pick button three, I'm going to ignore everything else. But if they don't pick button three and they pick button two, well, then I'll ignore button one and the coins. And then button one has the lowest priority amongst the purchases. So to put those together, what I'm going to use is something called a priority encoder. So this kind of thing is actually a way to do a priority encoder. So this kind of thing is actually used, for example, in deciding, well, if I have 10 devices that might need attention from my processor and they can give me a one bit signal, hey, I need some attention at the disk drive or I need some attention at the printer or I need some attention for the mouse. Each of them gives me a one bit signal. I'll use a priority encoder to make a decision about which one the processor looks at first. So they're actually used in situations like that. What we'll do is a four input priority encoder. So we only have three inputs we care about, but we'll just use one with four lines. And what it will produce is one signal P that says at least one of the inputs had a one. So whenever someone pushes a button, P will be one. So we'll put the buttons into these priority encoder inputs. And also the two bit signal encoding the highest priority active input. So it has four inputs. We'll call them 0, 1, 2, and 3. Surprise, surprise. And the output S will say 0, 1, 2, or 3 if P equals 1. Otherwise, we don't care what S is. So if they don't push any buttons, if all four inputs are zero, we should just ignore S. So let's write a truth table for that. So here's the truth table. So the first line says, well, if B3 is equal to 1, then I want P to be 1, right, because they pushed a button. And I want S to say, well, button 3 was pushed. And in that case, none of these others matter, right? B3 has the highest priority. The next line says, well, B3 was 0, B2 was pushed, then nothing else matters. I want P to be 1 still, and S should say number 2. Similarly, so forth and so on. So buttons 3 and 2 are not pushed. Button 1 is pushed. Ignore button 0. Say something was pushed. So P output is still 1. And here we say, well, button number 1 was the highest priority. And then this line says, OK, only button 1 was pushed. So we say, yes, I'm sorry, button 0. So a button was pushed, but it's number 0. And then last, if none of the buttons are pushed, P equals 0, and we don't care what S is. S should be ignored. So there's our truth table. We can then copy that into KMAPs. So here's KMAP for P. So what are the loops? It's an easy one, right? There's a midterm there. So here are some loops if you want to do it as SOP. And you get that. So a pretty easy circuit. How about this one? Pretty easy also? OK. So you guys know how to do this. OK, good. I'll skip it then. So this one is B3, B2. S0 is a tiny bit. Where's the other one? Square around here. Wraps around. Good. So if you write that one down, it's B3 ORed with B2 prime B1. Good. So there's an implementation. So not too hard. So this is a four-input priority encoder with priority on the 3. You could build 8. You could build 16. You just figure out the equations, and it's pretty straightforward, as you saw. All right. So we can then plug that in. So with this implementation now, this will only do purchases. So I want to build something that's only going to do purchases. We decided, remember, we're going to use an adder. Hopefully this is legible. Can people in the back read this? Yeah, good. OK. All right. So here's our register N in the middle. So that's our number of nickels. We've then got our priority encoder we just looked at up here. So the buttons are coming into the priority encoder. It's producing the P signal down here and the S signal up here. Remember, this is the register N, the number of nickels. So up here, there are registers storing the prices. Remember we said that instead of hardwiring specific prices, we would put each price into a register. So actually, these registers don't store P1, P2, and P3. What they store is negative P1, P2, and P3, so that we can simply feed them down here into an adder. So when we make a purchase, P will be 1, but S will also decide which of the three registers gets forwarded through this mux. So you see S here is used as the select lines on this 4-to-1 mux, or set of 4-to-1 muxes, which then outputs the price corresponding to the item that was selected by pushing one of the buttons. So the priority encoder, if you push more than one button, will only give 1, and S will say which one. So wait a minute, what happens if I don't push any buttons? What's S? Put a 0 in the equations I gave you? But we said don't care, right? So some bits come out of there, the mux forwards one of these down to here. So we better make sure that if we don't have P equals 1, this output is ignored. Because we don't really... I mean, that was the way we implemented priority encoder, but if we go buy one, who knows what will come out if P equals 0? So this adder then, whatever price comes out of here, will then go into the adder. You can see N is fed into the other part of the adder. So this adder now, for a purchase, will compute current number of nickels minus whatever price was selected. So the carryout then, since we're adding negative P1 to N, the carryout will equal 1 if and only if N is greater or equal to the price. So it's like a subtractor. So to overflow, meaning carryout is 1, these are unsigned values except we negated one of them, if we have enough money. So if we have enough money, carryout will be 1. If we don't have enough money, carryout will be 0. So then if you look over here, we have an AND gate. So it says, well, if the carryout was 1, that means you had enough money to buy the thing you wanted to buy. But you also have to look at, well, did you try to buy something? If you didn't try to buy something, some garbage is coming out of this muck, some bits. So we don't really care what happened in this adder. We want to make sure we ignore it. So unless you tried to buy something, unless you actually pushed a button, P will be 0. This AND gate will produce 0. So if you did try to buy something and you had enough money inserted into the machine, R will be 1. So R means, do we approve the request? Is it allowed? So R means request is approved. P is purchase requested. It says that one of the buttons was pushed. So if R is 1, you'll see that R comes around here and controls this mucks right here. So what does this mucks do? If R is 0, which means either you didn't push a button or you didn't have enough money. So if R is 0, where does that one come from? It comes straight from N. So we stay in the same state. So either of those conditions is true. We stay in the same state. On the other hand, if R is 1, well, that means you did push a button and you had enough money. So now the one input comes from the output of the adder. Well, that was N minus the price of the thing you wanted to buy. So now that's the right state to go into. That's fed back up into the register. So our next state is N minus P of whatever you tried to buy. All right, and then the last piece down here, you can see S, the thing that you picked, the item that you picked, is coming down here to this decoder. The enable is enabled by R. So if R equals 0, right, no purchase made because it was not approved or because you didn't ask, right, then this decoder outputs all zeros. So you don't release anything. These are going into flip-flops, one-bit registers, that will then control the release signals in the next cycle. And so that's where we're storing our output bits. So if the purchase is approved, meaning you tried to buy something and you had enough money and we changed the state to reflect that, then this decoder will have one 1. And the one 1 will correspond to the item that you bought. So one of the release signals will go out as a 1, and the item will drop out of the machine. And that will be selected by S, yes, which is the output of the priority encoder. So if you push B1, B2, and B3, it will say, oh, okay, you get 3. And assuming you have enough money to buy 3, it will take your money away, and it will output a 1 on the 3 output of the decoder. Any other questions? Yeah. Yeah, so remember that we don't want our inputs to directly affect our outputs. But we have to make a decision on the current state as to whether we're going to give them the product or not. So we make that decision, and that's R. But we can't just immediately give the R output. What we need to do is, because we want to build machines that don't have inputs directly as a function of outputs, is we simply add flip-flops after those outputs. So we're storing that output, which could have gone directly, but then it would have been a different kind of a finite-state machine. And in our class, we're always only going to change the outputs and make them dependent on the state. So when a state becomes part of the state, we latch those output values. They're held high or low for a cycle, which sometimes is important. So in the lab machine, for example, if you don't latch the gate output, then it'll just go down and up. And so whether you accept or not won't matter. It'll be too short to actually control the mechanical gate. So here, it might also be important. So we decide that we'll latch them into flip-flops for that reason. Anything else? In real life, of course. In an exam, no, we wouldn't do that. But we have had a fair number of problems where we have to analyze things. Maybe slightly less complex than this. Yeah, designing it, we might ask you to design part of it. The other problem is, honestly, if we did a full design like this, there would be so many different answers, it would be a nightmare to grade. So we might ask you to design part of this on an exam. So under exam three, there's a bunch of old exam problems from on finite state machines. So you can see the kind of things that you'll be expected to do. All right. Yes, I think I went through that one. So now let's think about what can we do to add the ability to put money in the machine. This machine we built, well, it's kind of cool. It handles purchases, but you can't actually put any money into it. So how could you ever buy anything? So let's figure out what do we need to do to handle purchases. Well, the first thing is we've got this coin input. So we've got the adder. So when a coin is coming in, we can use that adder to add the current state to the value of the inserted coin. The adder is already there, so we might as well use it for that too. And then write the sum back to the register if the sum doesn't overflow. Remember that if the sum overflows, we're going to have to either take away their money or not take their coin. So we decide to be nice and not take their coin. But what is the value of an inserted coin? We only have this three-bit representation. So here's our three-bit representation. I showed you the table before, but before this was number of nickels, and now this is a five-bit unsigned number, which is the value of each coin in nickels. So this is the number that we want to add. We've got a six-bit adder, so we're going to have to zero extend this out one extra bit. But let's convert from these three bits into a value. So how do we do that? Well, it's just k-maps. So here's B4. So there's our one loop. And here's the equation. There's B3. There's one loop. There's an equation. There's B2. There's one loop. There's an equation. So this is pretty straightforward. I'm going fast because on the harder k-maps, you told me it was too easy. So there's a big box for this one. So this is just C1 prime. And there's B0. This one could be what? Yeah, it could be XOR. I just did the C2 prime C1. Here's the implementation using those equations. So down here, you could have replaced this with an XOR2 and then not had to use the inverter. So here's our coin value module. So this is specific to RFSM. It takes the representation that we were given of what coin is this and spits out a five-bit coin value in nickels. So this is the kind of thing you did do on the midterm. So yeah, you would have this kind of problem. But until midterm three, we won't put it inside an FSM. All right, so the blue stuff is the new things. So the black stuff is the old purchase-only implementation. And so the blue color shows you what's been added. I know if you got the printed book, by the way, the blue doesn't show up too well. So you can look at the online version and you can see the colors if you want to see them. So what's in this diagram now? So up here is our coin value calculator. And you can see it's been zero extended. So this notation here, you can see this is five bits wide coming out of the coin value calculator. This is six bits wide going into the mux here. The fifth bit five, so these are bits four to zero. Bit five is a zero. So this kind of notation here means put one zero in front of the other five bits. And that'll become the six bits. You can see the bracketed bit indices there as notation. This mux then decides, well, are we going to put in the price or are we going to put in the coin value? Because we're going to use our adder for both adding value as well as subtracting out purchase prices. So how do we decide which one to put in? Well, we have this purchase signal P. Remember, they have priority. So if you push a purchase button, you put a coin in, it just ignores your coin, sends it back to you. The vending machine sends your coin back to you and ignores it. So in this case, we want to just look at the purchase price. So if P is one, we take our price out of this mux over here and forward that to the adder. But if P is zero, that means you didn't try to buy anything. So now we can look at the coin value and forward that to the adder. That gets added again into the current state, the number of nickels. And then it comes down here to this mux. So we have to decide, do we want to accept the coin? So how do we decide whether we accept the coin? We're adding the coin's value to the current state. So if we're going to be able to store the answer back, that sum has to fit in six bits. So how do we know? Well, just look at carry out. And if it overflows, carry out will be one. So if we get a one out of this adder, that will make this NOR gate go to zero. This NOR gate is generating the accept signal A. So if carry out is one, we have to reject the coin. Similarly, if they made a purchase, we always want to reject the coin. So if P equals one, goes to this NOR gate, also outputs a zero. So the only time you accept a coin is you didn't try to buy something and putting the coin in didn't overflow the sum. So if those two conditions are true, the NOR gate will give a one, and that will come down here and get latched into this one-bit register, just a flip-flop, one-bit register A. So same reason as for the R output. We're going to hold it high for a second. All right. So there's a little bit of logic left down here, right? There's this thing. So what is this thing? So whether or not we now stay in the same state or not depends on whether we're trying to make a purchase or trying to insert a coin. So in the case that we are trying to make a purchase, then this R signal might be high, in which case that will go and control our MUX just the way it did before. So remember, in order for R to be high, P has to be one. So the only time this gate matters is when P equals one. And the only time this gate matters is when P equals zero because if P equals one, this gate outputs a zero. So that going into the OR gate won't matter. So if P is zero, that's putting a coin in, right? No purchase. And so this gate then outputs accept. And if we accept the coin, this OR gate outputs a one. So this OR gate is either saying, well, we either decided to allow the user to buy something or we decided to accept their coin. So those are the two cases where this MUX takes its input from the adder and routes that back to be our next state. In the case where either we said, no, you're not allowed to buy that thing, you don't have enough money, or we said, we don't want your coin, this N input goes into zero input of the MUX, right? And we're picking zero, so that goes back and we stay in the same state, same number of nickels. I think that's it. Yeah, Eric. Yeah, so this NOR gate basically is generating the accept signal, right? You can see A is being latched out of this NOR gate. So when do you accept a coin? Well, there are two conditions. First of all, we said purchases have priority. So if they try to make a purchase by pushing a button, then the answer is you never accept it. So you can see priority encoder has the P output that says they pushed a button. That comes down here to the NOR gate. So one input to a NOR gate means a zero output. So in that case, since P was one, if they were allowed to make the purchase, then we'll still change the state to N minus whatever the current – whatever the price of the item they tried to buy. But if that purchase was rejected, we'll stay in state N. And similarly, if they didn't try to make a purchase, then this NOR gate reflects whether this carry out overflowed or not. On an overflow, that means we can't store the current state plus the value of the coin. So we reject it and we stay in state N. Yeah, yeah. So remember we – yeah, exactly. So if we had, for example, 60 nickels already and we tried to put a quarter in, well, we can't store the number 60 plus 5 is 65 in 6 bits. So we'd have to reject that coin. And that would show up as a carry out, right? Because you do a 6-bit add of 60 plus 5, you get a carry out. Yeah. Yes, that's right. So if you don't push anything, what actually goes on? So P is 0, right? So you're picking the coin value calculator. Let me flip – see how quickly I can flip back. So maybe I played a little trick here, which is that when you put nothing in, you get the value 0 out, right? I specified that in my KMAP, so that's definitely true out of our coin value calculator. So then the number 0 comes down to the mux. P was 0, so we pick it. We add N plus 0. That comes down here. And in that case, let's see what will happen. So no overflow and P was 0, so the NOR gate will give us a 1. This will give us a 1. We'll pick N plus 0, go back to there. So yes. So every cycle it will add N to 0 and write it back. A does not affect the coin value calculator at all. The logic is the other way. So you look at the value of the coin. You see if adding the coin makes your amount stored overflow, which is down here, the accept signal, and that is then stored. That is sent back to the coin mechanism, which is responsible for returning the coin if you say you don't want it. Just like in the lab that you're building, there's a gate mechanism that you had nothing to do with. You control it. You didn't build it. So there's some mechanism that some other designer builds that says, I'm going to look at your A signal, and if you say, don't take this coin, I'm going to give them back the coin. If you say, take the coin, I'm going to put it in a money box. Yeah, so that's an output. And this one is an input from probably the same mechanism that says, they just put in this coin. It has this type. This is the analog of the T input. It's more general because we allow many different types of coins, and this is the analog of the A output in the lab. So this is an output back to the mechanism like the gate in the lab. So they're held high for a cycle, high or low for a cycle. Yes. Yeah. Yes, yeah. So A is controlling whether the mechanical system accepts or rejects the coin. And N is the memory in the finite state machine of how many nickels we hold. And these R signals tell the mechanical system, let go of that product so they get it. Go ahead. Any other questions up here? Okay, so yes. So when we talked about MUXs, we talked about generalizing them. So you can see there's actually six inputs into each of these four for this 4-to-1 MUX. So in this diagram, this is actually six copies of a 4-to-1 MUX. And so anytime you see a MUX drawn with crosshatches on its inputs and outputs, that's multiple copies of that kind of MUX. So in particular, that would be six here. And if you wanted to make changes into 8-bit price registers, 8-bit nickel storage or whatever, then you would have eight MUXs. It's not much larger, no. So I think the trick wise, I think it's basically to break it up. So the way to work through these things is to try to figure out the human meanings. So usually there's some documentation on what the meanings are and to logically break it up into pieces. So that's what I tried to do for you walking through it. Yes, this is one 2-to-4 decoder with an enable. This is one 6-bit adder. You can build them any way you want. This is six 2-to-1 MUXs. This is six more 2-to-1 MUXs. I mean, I showed you a good diagram. Usually, something like a priority encoder you can usually pull off the shelf. Same thing for adders, registers. You've seen the implementations, right? You should know how they work. But usually people will provide these elements for you when you're building. In fact, once you even get into 385, I've mentioned this a couple times, but most of the building will be based on writing something similar to C code. So you'll say, oh, add A and B. And the tool will figure out that, well, I need an adder if you want me to add things. And so it'll put an adder down for you and route A and B into the adder. And then wherever you tell it to put the sum, it'll route the output of the adder to that place. So you're saying that this line here is taking its low bits from these five and the high bit from that five. We'll go on to memory. Let's go through this stuff then. All right. So I had a little bit of a memory block trying to get into these slides. So it will help. You're not that tired. I know it's Friday. Any other names? We're going to have a fair number of places. So I got A, B, C, oh, D. Good idea. Anyone else? Come on. I don't like those much. What else? E. Yeah. What else? F. I heard F. Okay. Those are good. Right on. That's six, right? A, B, C, D, E, F. Okay. Yeah. Okay. I think we're good. Okay. This might take you the rest of the hour. Really? A better idea? What? Did someone say bits? I heard bits. I heard someone say bits. Maybe I'm imagining. I don't know. Bits? Really? You want to name things with bits? All right. Really? Don't worry. Our names will be 0, 0, 0, 0, 0. All right. Fine. Do it your way. All right. So we'll use bits for names like you wanted. So we can probably build a circuit for that, right? Now we have bits. Name things with bits. So the circuit will let us read and write the bits stored in each of the 65,536 places. Right? So instead of having registers named A, B, C, we're just going to have a whole bunch of them. 65,000 of them. And they'll have names like, I really don't want to say 0 16 times. Imagine it. So a bunch of 0s or a bunch of 1s or 0, 1, 0, 1. So every combination of bits, let's call it an address. Okay? So you get a 16-bit pattern. We'll call that an address. So we'll have 2 to the 16th different addresses. Right? And that will let us name all of our places. And at every address, we'll have 32 bits. And we'll call that the addressability. So here's how we're going to use it. So if we want to read one of the places, right, each place is 32 bits. So if we want to read those bits and do something with them, then we're going to tell our circuit, well, here's the address of the bits that we want. Right? So we'll give it 16 bits and we'll say, these are the bits that we want. Somewhere there's, you know, that'll name one of those places. Then we'll wait for those 32 bits to come out. That'll be a read. If you want to change the bits in one of those places, then we'll tell the circuit, here's the place. Here's the 16-bit address. And then we'll give it the 32 bits. And it'll go put those 32 bits, store them at that place, the one that we named with the address. Oh, and we also need to tell the circuit, do you want to read or write? You need to say which one you want to do. So let's give these some I.O. names. So we'll say, well, the address will tell the circuit what we want to write to or read from, read or write, with address, ADDR. When the data come out, we'll have some data outlines. When we want to write the bits, we also have to give the address. We can use the same bit, the same input lines. Right? It's just an address, 16 bits, in the case we've been talking about. And then when we want to give the bits, we'll have some data input lines. And then we'll have a write enable signal that says either we want to do a write, in this case write enable will be 1, or we want to do a read, in which case write enable will be 0. All right. So here's a picture. Here's how we might draw it. We'll call it a memory. It has this one I generalized the number of addresses and the number of the addressability of this memory. So this one has 2 to the k addresses. So they're k address bits. So k could be 16, for example. And it has n bits at each address. So n could be 32, like we've been talking about. So that n bits at each place also means data input is n bits wide, and data output is n bits wide. And then it has this CS thing that we didn't talk about. There's write enable. There's CS. What's CS? CS means chip select. So often with memories, we're going to make use of many memories at a time. So we have a special control. It's like enable on some of the other components we've looked at. It's a little stronger than that in the sense that if chip select is 1, the memory is either going to do a read or write as we tell it to do. So we say chip select is 1, write enable is 0, it'll do a read. Chip select is 1, write enable is 1, it'll do a write. Chip select is 0, write enable is a don't care, it won't do anything. So if we turn chip select off, our memory will just not do anything. That's what it's for. That way we can have multiple chips and then decide which one we want to take action based on the chip select signals. No, no. So yeah, so that's a good question. So the question is, you know, if I turn chip select off, does the memory just get erased? No, not at all. It just means that it's not currently active. Its stored bits are still there. Good question. Go ahead. The realistic answer is, actually, I'm not sure. I think a lot of them are initialized to 0. I think when you power them on, they'll do, for the purposes of testing, they'll do some initialization and they'll end up all being 0 bits. There may still be memories that are just random bits when you turn them on. But I think most of them, when you power them on, will be all 0s. Yeah. Were there more? Edwin? Yes, yes. Each memory will have its own chip select. Oh, that's a good question. Let me come back to that one. Yeah, so when does data out become available? So yeah, it's kind of a complicated answer. So let me come back to that. All right, so the memory we're going to use in our class is random access memory, or RAM. So you may have heard of RAM. So what does it mean? It means that you can read and write addresses in any order, and that, more or less, the time to access any address is the same. So this is as opposed to things like tape, where one piece of the tape is next to the read head, and if you want to read other addresses, you have to turn the tape until you get close to that part of the tape. So those are serial memories. Random access memories, it doesn't matter what the address is. You can go read whatever address you want in any order, more or less at the same time to access them. In our class, we're only going to look at volatile forms of memory. So what does volatile mean? That's the part where they lose their bits. So if you turn off the electrical power, all of the memories we talk about, all the bits are going to go away. But turning off chip select will not remove the bits, just turning off the electrical power. Okay, so there's two kinds we're going to care about. One is called static RAM. It uses the two-inverter loop you've seen. So if you remember when we talked about storing a bit, we drew a couple of inverters back-to-back. That stores a bit. That stores a bit in SRAM, too, and I'll show you exactly what that looks like in a minute. So those will keep their bits indefinitely as long as you keep them powered on. So as long as you give them electricity, they'll keep their bits forever. In contrast, there's something called dynamic RAM or DRAM. This has a capacitor to store a bit. So there's a couple of charged plates, really tiny charged plates. There's some electrons on it. Remember, transistors don't really turn off. There's a transistor keeping the charge on those plates. They don't really turn off. So electrons can kind of go through the transistor even when it's supposed to be off. So eventually, those bits on the capacitor will go away. Sorry, the electrons on the capacitor will go away, and you'll lose your bit. So DRAM, the reason it's called dynamic is you have to rewrite it every so often. Every so often is typically tens of milliseconds. So you have to go rewrite every bit every so often. And so that's one issue with DRAM. I'll tell you more about it in a second as to why people use it, because that just seems kind of like a hassle, right? But there are big benefits to DRAM also. Both of these are volatile. So again, you turn them off, turn off the power, all the bits are gone. So SRAM is faster, uses the same semiconductor process as logic, which means you're designing a process or you're designing the logic you've been working on for the last, what, eight or nine weeks. All of those are able to be on the same chip, but it's much less dense than DRAM. DRAM is slower, and the refresh interferes with using it. If you have to refresh it, you might have to wait to be able to access it. But it uses a separate semiconductor process. So they're different chips. They're not on the same chip, usually. But it's much, much more dense. So you have more bits per chip area. So what do they usually use? What do most real systems use? Well, both and other storage types as well. So where is SRAM? SRAM is close to your processor. It's on the same chip. Your caches and things like that, don't worry if you don't know what a cache is. All the memory close to the chip for fast use is SRAM. The main memory of your computer, if you say, hey, my computer has 16 gigabytes, that's DRAM. You don't build, usually, 16 gigabytes of SRAM. That costs a lot of money still. And it wouldn't be on the same chip. It would be a box. So some storage, fast storage companies might use that kind of thing of SRAM. But a desktop or a laptop, this kind of size would be DRAM. So most systems often also have non-volatile memory. Your phone, your laptop, your desktop, servers, they have their own non-volatile memories. So some are flash or solid state disks, magnetic storage or hard drives, optical storage, DVD drives. Often you have all three. So what do you need to know in this memory stuff? So you need to know how to use memory. So the interface we talked about a couple minutes ago. The terms we just talked about. A little bit about how memories are built, which I'll show you shortly. So what SRAM and DRAM cells are inside, a capacitor versus a double inverter loop. Use of decoders to select cells. I'll show you how that works. Coincidence selection. I'll show you how that works also in a few slides. And then how to build bigger memories out of smaller ones. So if I give you a memory chip, can you put them together to build bigger memories? This is a common use. So I'll show you all of those things. What don't you need to know? Memory systems are analog circuits. So you really don't need to understand exactly how they work. I'll tell you a little bit about them, and I'll star them as we talk about them. Star the slides that are extra content. But fundamentally, they're analog designs. So understanding exactly what's going on is beyond 120. And also the details of DRAM operation, even how you interface the DRAM. If you're interested, section 364 will give you a brief introduction. All right, so here, as promised, is the double inverter loop. So this should look familiar, at least the circle part of it. What you won't necessarily understand yet is, well, we're using these n-type MOSFETs to connect these to what we call bit lines. They're bit and bit prime because they're going to be opposite values because of the way the double inverter loop works. So we have those. The MOSFETs are then controlled by select. So when we turn on the select line, these two inverters are connected to the bit lines. And when we turn off select, we set it to zero, these two MOSFETs will turn off. And then this double inverter loop will just store a bit. So to write a bit, what do we do? So we hold these bit lines at opposite values, and then we turn on select, and we force these inverters to accept our new value. So this circuit does something that we've told you never, ever do. Do you notice it? So if I'm going to set bit to one, and this thing is a zero, it's not oscillating. It's just short, right? Because inside those inverters, we are wiring this thing to ground, and this thing we just set is wired to high voltage. So we turn this transistor on, we have a short here and a short over here. I didn't expand those, but at these points, we were actually creating shorts. So that's one of the reasons you've got to design these systems carefully, thinking about, well, exactly what's going on at the transistor level and make sure these short circuits don't last very long because the short is going to generate power or get hot. So people have to think about this as an analog system. You don't just treat it as a digital system. Yes, yes. Inverter, there's nothing mysterious here. This is exactly the way we showed an inverter when we learned it the first time. I can, but I don't have a slide that does it. So, yes, let's do it after class. I'll draw it for you. So it's a major issue, right, because you don't want to generate too much power. So they're designed not to require too much power to store the bit. And you can do that by sizing transistors and using things like resistors in the right places. But it's an analog problem. It's not a digital problem at this point. Why don't they use two different select files? Between here and here? Here and here? I'm not sure I understand. I mean, so the reason we don't add a bunch more transistors in general is because that would be bigger. So the more transistors you add, the bigger this cell is to store one bit. So there are ways, and there are actually, this is the most common commercial cell. It's called a 6T cell. I have it on another slide. You can add more transistors to try to eliminate some of these problems, but in the end, it's still an analog design problem. So there are things you can try to do, but if you do it by making like an 8T or a 12T cell, then you've taken twice as much space for your one bit. And so it becomes less and less efficient. So there are some trade-offs there, but they're kind of outside the scope of 120 also. Yeah. Yeah. Yeah. A latch is much bigger. So a latch was four NAND gates and an inverter. As long as we drive it the right way, we do two NAND gates, so that would be eight transistors there. So, yeah, maybe I shouldn't overemphasize these. It's an analog design problem, so the way they build it, it's not that big of an issue. But you need to understand that you can't approach this as a digital design problem and just expect to put gates down, right, because you won't be able to solve it correctly. So at that point, you need to understand transistor sizing, IV curves as a function of sizing, and it's well beyond the scope of 120. That was kind of my point. So don't worry too much about it. Just realize that it's more complicated than you will see here and certainly more complicated than when you do the discussion section and you'll see a pretend version that you can use, but it's all digital. So it would be huge to do it that way. All right, so in order to read this bit, what ends up happening, again, it's analog, but you can think, well, all I do is I make these connections, I leave these bit lines floating, and then these inverters drive the bit lines either to 01 or to 10, depending what bit is stored. In practice these days, on SRAM or DRAM, always on DRAM, but in the last 10 or 15 years on SRAM also, these lines are actually charged to VDD over 2 and pre-charged before you turn select on. And then there's something called a sense amplifier, which basically watches the voltage from one bit line to the other, and as soon as it starts to drift away from zero, it pushes it all the way so that the voltage is digital 01 in one direction or the other, well, digital 1 in one direction or the other. Yeah, go ahead. No, it's mostly size, and in SRAM size is important. So here's my slide. So how many transistors is this? Six, right? So this is called a 6T cell. So you can add transistors, but if you add two more transistors, then you've got only, let's see, it would add 33% overhead, right? You've got about three quarters as many bits stored for the same area. And if you make it 12 transistors, you've got half as many bits. So two shown, two per inverter, 6T cell. So it's good reliability, small size, and it's one of the most common, and pretty good power too. So here, I think we're going to probably end up stopping soon. Let me talk a little bit about the bit slice. Yeah, I'll get about a minute. So this is a bit slice. So you'll see down here, I've labeled it with our abstract symbolic memory labels. I'll walk through it next time, but this is how you could build, for example, a 16-address, one-bit addressability memory. So you can see there's the analog logic over here. I think I did it in the next slide. Okay, so in this diagram, the select lines are vertical. The bit lines are now horizontal, and all of the cells are sharing one set of bit lines. So we're only going to read and write one cell at a time. And this over here is our sense amps and other analog circuits. So we're going to balance between the length of these bit lines, so usually they'll be bigger. We'll have lots and lots of cells per bit slice. And the reason for that is this logic here is relatively expensive compared to the cells, so we want to drive as many cells as we can with one copy of this logic. So let me stop there, and we'll pick it up on Monday. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\",\n",
       " \"you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you yeah, Eric? like, I forget one more thing you said that you can't represent one by one or you can represent one by one you can't have both you can't have two things which the things here are colors have the same bit pattern representation because then the then the representation is ambiguous right, so this one on the previous screen where these two colors were both represented by the same bit pattern that's not a good representation right okay okay alright, so so it's not it's not symmetric, right it's okay to have more than one pattern for the same color but not okay to have more than one color for the same pattern alright, so here's an example where we could we could do something like that I mean you've seen some already but in this example this is something called binary coded decimal this was used for a long time as the representation behind numbers and banking and things like that and business oriented software in fact the COBOL language would encode a lot of things using this sort of implicitly underneath and then certain ISAs also supported it so for example x86 actually still supports it because it was in the original x86 design so what is binary coded decimal? well you take your 10 decimal digits and for each decimal digit in your number you code it as a 4-bit value just using the binary representation of that digit and then these other 4-bit values well those don't mean anything okay, so you've got 6 4-bit patterns that just don't mean anything and each of your digits is one of the 10 binary values from 0 to 9 so it's not like a a number or a bit that your number is a key and you have to put them all in a sequence of digits? oh no, so this is representing larger numbers as a sequence of digits right, so if you wanted to have a number up to a billion you'd have to have 10 digits and each digit would be 4-bit so you'd end up having 40 bits instead of 32 bits in a more compact binary representation yeah, so it's less efficient but it's easier when you want to when you want for example to translate this to ASCII you don't have to do any conversion digit by digit you just add the 0 ASCII character and then print it out and vice versa so it's easier to use in some sense but it's less efficient all right, so what else can we do with these things? well what happens let's say we have an error so we see one of these six patterns so you have a number stored in your system supposed to be your account balance or whatever you see one of these six meaningless patterns well you know something went wrong so if you have this kind of redundancy in your representations you can say sometimes I'll be able to tell that something happened so can we use this idea to try to fix errors? well so what's an error? so here's an error a meteorite landed on some things here this is the crater in Arizona it's kind of cool to visit it if you've never been there but you know certainly you can't deal with all errors so some errors are going to be catastrophic you can't say oh I built this system it's going to be really reliable if a meteorite lands on ECEB the system is gone you didn't handle that unless you put a copy of your system elsewhere so you can't handle all errors because catastrophes are always possible and hopefully they're not common so let's focus on errors that are more frequent things that will happen a lot instead of things like meteorites hitting so errors are nothing new so when people wrote on stone stone kind of weathered and things started disappearing when people wrote on paper paper could get wet get crumpled and so forth when people write on flash well you know you put electrons here and then they tunnel their way to freedom and then they're gone if you didn't know that about flash don't ever put things you care about on flash they will do that in 20 years your data will be gone don't do that all right so our class is going to use a model that's slightly different that model I just showed you all of those examples are what are called erasures so the data are there you see that there's supposed to be some information there but you can't tell what it is because electrons got away or the paper is smudged or the stone is eroded so those are called erasures we're going to look at a more difficult type of error where things are actually replaced and so everything in our class is bits and so we'll look at bit flips so instead of a one you see a zero instead of a zero you see a one so that's our error model so let me show you the difference using English so this is erasures I put dots in place of the missing characters can you tell me very good very good okay here's errors exactly that goes this way yeah sorry now I kind of cheated if you look really carefully at these you'll notice they're both kind of compatible with one another but in general when you're doing coding and trying to correct this kind of things erasures are a little easier than errors because with errors you don't know what's wrong with erasures you know what's missing so erasures are typically easier than errors, mistakes where you don't know what's missing you don't know what's right or wrong so here is a probabilistic model so it's our bit flip model so a bit can change from a zero or a bit can change from zero I'm sorry one to zero or zero to one right and if we assume that all of the bit flips happen independently of all the others we have a lot of bits in our system at some point each of those bits might flip we have some very small probability that any bit might flip so we'll call that probability P then if we have n bits the probability that one of those bits has changed given the probability P for one bit and having n bits is the probability that we pick one bit which is n times the probability that that one bit flipped times the probability that all the other bits didn't flip so remember P is small right so this one minus P thing is is usually pretty close to one and the chance of getting two errors is this thing where this is the the ways to pick a pair of bits and then this is the chance that any particular pair of bits two of them have flipped so if you if you work out that math and you do the approximations then this one is about n times P times that one and in general we pick nP right if we know the probability then we pick n such that nP is much less than 1 and that means the chance of two errors is much much less than the chance of one error right so when we design our systems you have to kind of guess or know by measuring things well what's the chance of one bit changing and then you use that to decide how many how many bits you could protect right all right so let's look at another code so this is called a two out of five code this was actually used in a variety of telecommunication and computing systems and things like that so this instead of mapping into four bits this maps decimal digits into five bits and so you might notice the pattern each of these bit patterns of five bits has exactly two ones in it okay so each of the decimal digits then is mapped to a pattern of five bits with two ones so it's less efficient it takes more bits than binary coded decimal which is in turn less efficient than binary or choose complement but what's the advantage? so let's think what happens if we take some number coded with a two out of five code and one of the bits flips right so what what bit flips? well we don't know right so let's look at all the possibilities could be this one flips in which case we end up with this number here this bit pattern it could be that the second bit flips in which case we get this bit pattern could be the third bit flips that bit pattern the red in these is just for us to remember which bit flipped right you wouldn't get to know which one you would just see the bits fourth bit this pattern fifth bit that pattern do you notice anything about these five patterns? yeah none of them have two ones right none of them have two ones so as soon as you see any of these five patterns you say hey something went wrong you know something went wrong you detected the error so none of them means anything so we always detect that single bit error it turns out that regardless of which number I picked I just picked six I just picked seven but if you go back and look at this at this list any number you pick here regardless of what the original digit is if there's only one bit that flips you can always tell so with the two out of five code you can always detect one bit flip so that's that's error detection yeah Eric yeah Eric mm-hmm no no let's come back to that because I'll give you an example yeah so if you have two bits flip with the two out of five code you can't necessarily detect it good question but we'll come back to it anything else all right okay so first though I want to try to generalize this idea so let me go through that same exercise but ask you instead a slightly different question so we started with a two out of five code this is just one example the seven right and we said well we're going to flip a bit so let's ask instead how many one bits are there if we flip a bit so there's two choices we could flip a one or we could flip a zero if we flip a one bit how many how many ones are left? one if we flip a zero bit how many ones are left? three so regardless of which one we start with now by this reasoning now you should understand well it doesn't matter which one I started with all ten patterns had two ones and so after I flip a bit all ten patterns will have either one one bit or three one bits so it didn't matter which digit I started with right I can detect an error for any of the ten digits so what about other you know I just showed you decimal digits what about binary numbers, letters, colors is there some general strategy? I mean two out of five code only gives me ten patterns and so it's not what if I want to represent a floating point number? I probably don't want to write it out in decimal digits so is there some way that we could use this idea to have error detection for arbitrary representation? so let's see so we started with bit patterns with two one bits and we said well if you flip a bit flips from one to zero we have one bit and if a bit flips from zero to one we have three one bits so what if instead we started with an odd number of one bits so all of our bit patterns have an odd number of one bits then what happens if say a one flips to a zero? it becomes even right what if a zero flips to a one? also even so in other words if you start only using patterns that have an odd number of one bits then if there's one bit error that one bit error I mean it's either got to flip one to a zero or zero to one right but after that one bit error you always have a pattern with an even number of one bits and then you can look at it and say well that's not a valid pattern so then you know something went wrong right? so any bit flip gives what we call a non-code word the code words are the original valid patterns the ones that have meaning so this is what we call parity so if we add this extra bit a parity bit to each code word and choose that parity bits value right if we're going to add a bit well we can pick zero or one to put on the end and we'll pick it such that the number of one bits is odd just like we talked about and that's called odd parity you can also pick it to be even that would be called even parity you have to agree on which representation you want to use of course so here's three bit unsigned in the black digits with odd parity which is the blue digit I've added onto the end right so three bit unsigned goes from zero to seven and all I've done is add the add the parity bit on the end to make this a representation protected by parity so let's then take a look at well I want to define a distance so if I give you two bit patterns I want to define what I'm going to call hamming distance as the number of bit flips I have to do to move from one pattern to the other so here on the left I have 0101 and 0100 those two are only different in one bit so I'll say well this is distance one apart this top pattern from the bottom pattern this pattern over here 0101 from 0010 I'd have to flip three bits to go from here to there so I'm going to say this is distance three this is what we call hamming distance Richard Hamming was a Illinois alumnus in math he did his PhD here in math and then he ran Bell Labs Computing Center for a long time it's actually quite famous and he has many things named after him in various fields computing signal processing so hamming distance is number of bit flips right so for two patterns the hamming distance between them is the number of bits I have to change from one pattern to get to the other pattern that's the hamming distance so let's also define hamming distance for representation which I'm going to start calling a code so if I give you representation there's some patterns that are valid things right some that aren't but for the patterns that are valid things I want to ask well what's the minimum hamming distance between any two valid bit patterns any any two that mean something so the hamming distance of the code then or the representation is the minimum hamming distance between any two distinct code words so it's the minimum over all possible pairs so it could be hard to compute sometimes it'll be easy we'll do a couple of examples so what's the hamming distance of binary code a decimal one right you choose two code words for example zero and one and here this is distance one so there's an example of a pair at distance one you know that there any different pair is always at least distance one so then you have your answer right the hamming distance is distance one okay so BCD is hamming distance one what about hamming distance of two out of five so with two out of five codes if we have two different patterns a and b each of them have to have at least two one bits and they can't have the same two one bits right so that means a has to have at least one one where b has a zero and because they're different one bits and they only have exactly two and b also has to have a one where a has a zero so those are two bit differences I didn't put any constraints on which patterns I chose we've got two there right so you've got to have at least two hamming distance for the whole code and because of course I can I can easily find a pair that has exactly two the two out of five code has hamming distance two all right so what about parity so what's a what if I have a code with odd parity so like I give you the example of taking three bit unsigned but I can take a bigger representation I can I only protect a few bits with parity what if I had a thousand bit choose comp a thousand bit choose complement yeah could I protect that with one parity bit that seems kind of inexpensive yeah yeah that's right that's right yeah so that's a good analysis so there's two aspects one the single the single odd parity bit will work from a single bit flip but if you make the if you make the representation too big the chance that you actually have two bit flips goes up and with two bit flips we haven't shown it yet but I think maybe we sort of hinted at it with two bit flips of course you you won't necessarily be able to detect the problem so it's not limited from the theoretical sense but from the practical sense of the error probabilities going up too much for two it is limited all right so let's do this little yeah for small enough for a small enough number of bits you would I mean you would not need to do that you would I mean you would not go to a megabit with one parity bit but for for something like a 32 64 128 bit number if all you wanted was air detection a single parity is sufficient again it depends strongly on the error probability so it depends on the context for spacecraft the air probability is much much higher right because they're being bombarded by cosmic rays all the time yes yeah so you can always have you can always break things into into groups that you protect separately with individual parity bits good question another question over here okay all right so let's take a look at this this was just an example of parity and why the hamming distance is two so if you pick two distinct code words a and B we don't know what the bits are but we know that they have to be different right so let's just assume that they're only different one place that would make the hamming distance one so let's just assume that they're only different one place that would make the hamming distance one so let's just assume that they're only different one place that would make the hamming distance one so if we go forward without assumption well if that's true then A has odd parity we know because we said the whole everything has odd parity but then if they're ham if A and B are hamming distance one apart and A has odd parity then B has even parity but that can't be right because we assumed all of our bit patterns had odd parity right so this is a contradiction in our assumption that this location is unique therefore the location is not unique and so for any two bit patterns they have to differ in at least two locations that means hamming distance two so just a quick proof that with any representation one parity bit gives you hamming distance two all right so just this is then just a concrete example so this is three bit twos complement and you can see that I've added an odd parity bit on there and the difference between zero and one is two and so the hamming distance of this representation is exactly two you know from the previous slide that it's at least two for any parity based code but this one is exactly two so what happens if two bit errors occur this was the question you would ask Eric what happens if two bit errors occur when I have something like three bit twos complement with parity so here I have represented a zero and let's say the first bit error comes in and it flips the bit the zero here so now I have zero zero one one and then a second bit flip happens and I get zero zero one zero except that's the pattern for one all right so if I have those two bit flips happen to my original value I won't be able to know oh something went wrong I'll look at that and I'll say oh the parity is right it's correct it's a one right even though what really happened was two bit flips so I won't be able to know it so this is why you do have to worry about the possibility that more bit flips than you expect will happen so no error can be detected in this case all right so more generally if we start with a code of Hamming distance D and then we want to know well given Hamming distance D for my code how many how many errors can I detect remember that Hamming distance D implies that if I pick any two code words those two are at least D bit flips apart okay so if I start with one and I only flip D minus one bits or fewer I can't get to the other one right so if I start with a code word and then I flip one bit or two bits or up to D minus one bits I can't reach another code word and so I always stop at a place that isn't a code word so as long as there are somewhere between one and D minus one assuming that's meaningful if D is one then you can't detect any errors right but at least but between one and D minus one bit errors I can always detect if I have Hamming distance D for my code and so this is the relationship between error detection and Hamming distance this is why Hamming distance is a useful concept and if you know the Hamming distance of the code you know how many bit errors you can detect with that code it's just D minus one yeah no no this is a general code parity Hamming distance is two so it works for parity but this also works for any other code where your Hamming distance might be larger so later I will show you probably on Monday I will show you Hamming code which has Hamming distance three so those can be used for detection two-bit errors you can also build bigger codes I shall show you also Hamming distance four code which you could use to detect three errors if you wanted to up to three errors. It always refers to ones which is equivalent and the odd parity means an odd number of ones you can also have even parity which is an even number of ones and it's there's a one-bit difference. There's a one-to-one mapping right because if your characters are only zeros and ones as there are for all of our systems then the number of zeros is the number of bits minus the number of ones. Yeah, yeah, yeah and that it's a convention and the convention is necessary because otherwise if I say odd parity you wouldn't necessarily know whether it's whether it's odd number ones or zeros and then you wouldn't have a well-defined representation. So it's always the number of ones. Yeah. So these are errors remember so you don't want this to happen but you in order to protect it protect against it you need to make whatever number of bit flips you expect you need to have a Hamming code with a code with large enough Hamming distance that you can't happen as far as you're concerned. Now again you know when you say can't happen it's a probabilistic argument right so typical error rates the optical fiber error rates for example used to be something like one in a billion bits I'm sorry one in a billion flips per bit so if you sent a terabyte of information down you could you could do the math you know figure out how many bits are in a terabyte divide that by I'm sorry it was a trillion it was 10 to the 12th divide that by a trillion you would expect to see at the other side of your optical fiber. Optical fiber is actually quite good I mean copper and things like that much higher two or three orders of magnitude higher error rates and wireless is really bad so which you probably know from having just used it but it's because of the bit error rates and other phenomena. Okay so let's let's take a look then at error correction or at least get the motivation so sometimes that's just not enough. You know sometimes that's just not enough right hey I've got an error right so well what happens if your bank calls you up one day and say hey you know what there was an error it turns out there was an error with your account balance and the account balance now after the errors in there we can tell because the parodies are wrong but the error says you've got $500 so we're thinking we've got two options for you you know one is one is well maybe the parody bit got flipped right so okay that's fine you got $500 but we think probably what happened is the sign bit got flipped so when you can pay us the $500 let us know and I think hopefully all of you as you know ECE majors would go back to no, no, no, no what happened was the big the highest zero bit in the exponent got flipped and this was my balance. I just had a big deposit right so when you get this money let me know. All right so and you know so that's one example. Oh wait there's an alert. What's going on here? Oh good. Yeah. So another thing you never want to see again right so please if you work on we saw in the curriculum committee we were talking about where our students go and a bunch of people said they would go into medical devices right. Please never write this. Use something stronger. All right so error correction. Can we use redundancy to correct errors? Yeah but the overhead is going to be higher so if we want to correct errors we're going to need bigger more Hamming distance basically is the short argument and we can see more detail on that on Monday but let me just show you so here's our odd parity Hamming distance is two. Why can't we correct an error? So one bit flip remember could be from here so we see this pattern. It might have come from here. It might have been that we sent this pattern or we stored this pattern and this bit got flipped and we saw that. On the other hand it might have been that we stored the one and the other and this bit got flipped so if we see this pattern what should we pick? It's the same as the banking problem. We have no idea what we should pick. We don't know which one it came from so we don't have a good answer to that. So for Hamming distance is only two we're not going to be able to correct an error. We'll need a bigger Hamming distance so here's an example, very, very simple example, not a good strategy but here's two copies. So here's two bit unsigned copied three times just for us there's a black copy and a blue copy and a green copy but it's just a six bit pattern so now if we get one bit flip then something changes but only one of the three copies can change so now the other two copies you can look at all three copies and do a little voting exercise and the majority vote correct. So I got two, zero, two. Okay. That was a two. I'm done. So I can actually correct an error. What happens if I get two bit flips? So two bit flips then two things can change in different copies. I can do my little voting exercise. Two, zero, oh, this was a zero. Sorry. So it's important to realize in this case if you do correction you might actually get a good result. So be careful with that. We'll talk more about this on Monday and show you examples of good codes for error display. you you you you you you you you you you you you\",\n",
       " \"Yn ystod yr oergell, mae'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Mae'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Mae'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Yn y gweithlu'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Yn y gweithlu'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Yn ffurfio, mae'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Yn ffurfio, mae'r cyfrifiadau'n cael eu cymryd yn y gweithlu. Beth ydym ni'n ei wneud heddiw? Cofiwch y codi os nad oes un. Byddwn ni'n mynd i ddod yn ymgyrch programau i'w edrych. Cofiwch eu cymryd yn y gweithlu os oes gennych gyfrifiadau gyda chi. Ond, arall, gallwch edrych ar eu cyfrifiadau a dilynu arnynt. Byddwn i'n mynd i ddod yn ymgyrch i Notepad, a'n mynd i ddod i'r gwaith a chyfrifiadau. Mae angen i chi edrych ar y codi. Dw i am ymgyrchu'r lwybrau byw. Cofiwch y codi yn y gweithlu'r ddiweddarau. Yna, byddwn i'n mynd i ddod i'r programau cyfrifiadau. Cofiwch y lwybrau byw, y codi yno. Cofiwch y programau C. Mae un o'r programau yno. Cofiwch eich codi. Efallai na fyddwn i'n mynd i'r gweithlu. Nid wyf yn siŵr pa mor ffordd byddwn i'n mynd i'r gweithlu. Felly, bydd yr holl slaidiau, fel arfer, yn cael eu cyflwyno i chi. Mae'r rhain yn cael eu cyflwyno. Rwy'n cwestiynu am edrych ar y leicwyr, y fideo yn Chrome. Fe wnaethom ystyried hynny yn fy swyddfa, ac mae'n deimlo'n iawn. Rwy'n cysylltu â'r IT. Ond, yn aml, mae Chrome yn gweithio i mi hefyd. Felly, dechreuwch i ni edrych yn gyffredinol ar y llwybr pwll. Mae'r llwybr pwll yn cael 4 rhan. Mae yna ddynion cyfnodol, dynion test, dynion cyfnodol cyfnodol newid, a'r bod lwybr. Y ffordd y mae'n gweithio yw ei ddefnyddio'r adnodd unigol yn gyntaf, ac yna'i ddefnyddio'r adnodd test. Os yw'n ffwrdd, mae'n parhau. Yna, mae'n gweithio'r llwybr pwll, y ddatganiad o'r cyfnod, ac yna mae'n mynd i ddefnyddio'r newid, a'i gyrraedd yn ôl i'r stryd ddwy, a'i gwirio'r test eto. Felly, cofiwch, yn gyntaf, y adnodd unigol, ac yna'r test, y llwybr pwll, y newid, a'i gyrraedd yn ôl i'r stryd ddwy, a'i gyrraedd yn ôl i'r test. Byddai'n gallu bod nad yw'n mynd i'r llwybr pwll. Gall y test fod yn ffwrdd y pryd. Felly, pam y llwybr? Byddwn yn ddangos hyn i chi, ond byddwn yn ceisio'n fawr na'i defnyddio, fel y byddwch yn gael gwybod unig sut mae'r llwybr pwll yn gweithio. Mae'n gwirionedd yn ddim iawn. Felly, mae'r llwybr pwll yn unigol yn cael test, ond mae'r llwybr pwll yn ddim iawn. Felly, mae'n wirioneddol eang i chi, ond meddyliwch nad yw gennych y ddwy ffwrdd, felly nid oes unrhyw beth i'w wneud ar gyfer y rhanau hynny. Felly, yn benodol, os ydyn ni'n cymryd ein broses bwysig, byddwn yn nesu'r bwysig. Nid oes unrhyw beth. Yn gyntaf, byddwn yn cyfrifoldeb y test. Os yw'n ddifrifol, bydd yn parhau. Er allai, byddwn yn gweithio'r llwybr pwll. Felly, mae'r llwybr pwll yn ddifrifol. Gallwch ddod at y llwybr hwn yn 220. Mae'n ddifrifoldeb syntactig pan nad oes gennych test. Ond, dydych chi ddim yn ei gael. Iawn. Felly, dyma beth rwy'n eisiau ei wneud ar gyfer y rhan fwyaf o'r diwrnod. Felly, rwy'n eisiau mynd trwy rhai enghraifftau coed gyda chi, a gwneud yn siŵr bod chi'n dilyn, a'ch bod chi'n teimlo'n deall, a'ch bod chi'n deall sut mae'r coed yn gweithio. Bydd angen i chi ddysgu sut i'w gyrraedd. Rwy'n credu eich bod chi wedi gwneud hynny eisoes yn eich lab. Felly, bydd angen i chi ddysgu hynny yn y lab. Mae yna rhai gyrraeddau style ar y wiki y dylid i chi edrych arno ar unrhyw bwynt. Gallwch hefyd edrych ar y cyfrifau coed rydw i'n eu rhoi i chi i feddwl sut y gallwn fod yn dynnu fy nghwaraethau neu beth bynnag. Cysylltai enwau gwahanol. Byddwn yn ymddangos ar y rhai o'r rhain hefyd. Byddwn yn cyflawni'r pethau sy'n iawn oherwydd roeddwn i'n rhaid eu cyflawni i'r slyd. Byddwch yn gweld hynny'n y ffordd da yn y coed. Y pethau rydw i wedi'u rhoi i chi, byddai'r rhain yn ymgyrchu. Mae'r rhaglenau ar gael i chi ymgyrchu, felly dydynt i chi ddod â'u cysylltu neu rhywbeth. Felly, dyma'r llwybr Fibonacci a dyma'r llwybr y gwnaethom ni ei ddangos yn y diwrnod diwethaf. Felly, byddai'n werthfawr gael ymgyrchu o fapur. Byddwn yn newid i Notepad. Dyma'r rhaglen gyntaf ar y cyfnod. Rwy'n credu mai'r ddau o'r rhan ymlaen yw'r rhan yma. Felly, dyma'r hyn rydyn ni'n ei gael ar gael wrth i ni fynd ymlaen. Felly, byddwn yn gweithredu un peth ar y tro a byddwn yn rhoi coment yn ysgrifennu beth ydym yn ei wneud ac yna byddwn yn newid beth bynnag a bydd yna newid o fawr neu os oes printiaeth a bydd yn gwneud rhywbeth o ddifrif, byddwn yn rhoi yn y colwm beth yw'r ddifrif. Yn y slaidau, os edrychwch arnynt yn ddiweddar, byddwch yn gweld bod yna rhai pethau yno. Byddwn yn datblygu hynny ein hunain. Felly, os edrychwch yn ôl i'r slaidau, gallwch weld yr holl ddatblygiad honno, ond byddwn yn ei wneud yn y clas yn lle'n gwblhau'r slaidau. Felly... Yn y slaidau, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno. Yn y clas, byddwn yn gweld yr holl ddatblygiad honno.\",\n",
       " \"and Hamming codes and then also SECDEAD codes. I should mention, I think it's probably clear from the wiki, but there's a homework 14, but it's not actually due. So we'll give you solutions. I suggest that you do it because those kinds of problems will be on the final. So it'll be the kind of things we've been doing this week and the things we'll do today and Friday. So you won't have to turn it in, but you will get solutions for it and you can check your answers and stuff like that. Okay, so you've seen everything in the data path and how it works and how the control unit drives the data path to execute RTL for all of the states. So today what we're gonna talk about is, well, how do you actually go about building the finite state machine that the control unit is? How do you make it work? So I wanna go back and say, well, what does the control unit actually do? And so you know, it drives RTL with control signals, but well, as you should remember, it goes in, it fetches an instruction and it executes that instruction, goes back, starts over. Very exciting. The control unit. Okay, so how can we actually implement that? So let's start by making a simplifying assumption. Let's assume that we can fetch an instruction in a fixed number of cycles and that we can also execute any instruction in a fixed number of cycles. Not all ISAs, for not all ISAs is that the case unless your fixed number is very, very large. For example, x86 has a string copy instruction that takes a register as the length of the string. So you can copy, you know, a gigabyte of memory from one place to another with one instruction. So that's not the kind of thing we have in mind when we say fixed number of cycles, right? Be, I don't know, five, 10 cycles. Some processors had instructions that were 100, 150 cycles, but you know, some number of cycles that's reasonable. And in that case, sorry, we can use a counter, right? So we can actually build our finite state machine around a counter where we say, well, the first few cycles, whatever it takes are fetch, and then the rest of the cycles are executed and then we'll start the counter over and we'll start the process over and fetch a new instruction. So control unit FSM does the following. So given as inputs, the counter value, right? So we're gonna build it around this counter, the IR, the instruction register, that of course is gonna tell us the instruction. And as you know, those bits are meaningless until we fetch the instruction, right? So we're only using the IR in executing the instruction. During fetch, we're not gonna use it. Signals from the data path. So we'll talk about what those are in the context of LC3, but it could be whatever feedback is coming from the data path, some signals coming out of it. So given those things, then the control unit is gonna generate the data path control signals using combinational logic. So if we use combinational logic, we call that a hardwired control unit design. So hardwired just means somehow we're gonna design combinational logic. Could be with KMAPs, it could be, as you'll see, by figuring out all the bits and putting them in a read-only memory. And it doesn't really matter how we build the combinational logic. What matters is we're gonna use combinational logic and implement this control unit that translates these things into control signals. All right, so for a simple enough ISA and a powerful enough data path, arguably, you can have a single cycle hardwired control. If you can put everything into one cycle and get it all done, probably you need a fairly complicated memory, right? Because you gotta be able to fetch the instruction and execute it. So it's pretty complicated data path and usually a slow clock. So people don't really build things this way, but there is a name for it, single cycle hardwired control. The thing that's more interesting then would be multi-cycle hardwired control. So let's start with Pat and Patel's LC3 data path and their finite state machine state transition diagram, and think about how could we build a hardwired control unit that would actually make use of that design. So as you should remember, the LC3 data path in the book, I mean, it cannot fetch an instruction in a single cycle, it takes three states, and then the memory state might take many cycles, we have to wait for memory to finish. And it certainly can't execute in a cycle either, it's got five states for some of the instructions, like the LDI we looked at is five states long. So we can't fetch nor execute an instruction in a single cycle, but we can still use combinational logic for our design. So this is still a hardwired control unit, but it's gonna be multi-cycle. So how many cycles do we need in that design? So fetch has three states, or how many states, maybe I'll ask. So fetch has three states, remember we went through first you put the PC down into the MAR, increment the PC, then in the second state, you go read memory, and then third state you copy MDR across the bus into the IR. And then the longest instructions, LDI and STI take five states. So we saw one of those on Monday. So the total is eight states, so we can use just a three-bit binary counter to drive the core of our FSM. So here's just an example of what those would mean. So the counter value will run from zero through seven, the first three states will be the first, second and third fetch states. Yeah. Ah, so that's a good question. Let me come back to that in a second. So I didn't put decode up here, and that's a good question as well, where'd the decode go? Because remember in the Pat and Patel state machine, you've got the three fetch, then you have a decode, then you have the different execute states, right? So here in the counter, I've only allocated counter values for the three fetch states and five execute states. So what happened to decode? So, all right, so Pat and Patel have a different strategy, which we'll talk about later, it's called microprogramming. Their strategy, as I've talked about a couple of times, requires an explicit decode state, right? Because what's happening is in the third fetch state, we're actually bringing the bits across the bus from the MDR into the IR. That RTL executes on the rising clock edge, and so not until the fourth cycle are the bits actually in the IR. But you wanna use the bits of the IR then to go to different finite state machine states, okay? Here, our states are kind of implicit and our combinational logic uses these IR bits directly. So in the fourth cycle, once the bits are in the IR, they're going into the combinational logic and we can make use of them to actually execute, because we're also, we're looking at the opcode and we're looking at the counter value that says, okay, this is the first execute cycle. So the combinational logic just handles that directly and we don't need an explicit decode state. Pat and Patel with microprogramming do, because they have to split the state based on the IR and they can't use the IR until the fourth state. Make sense? All right, so what about the shorter instructions? So remember an add only takes one cycle, right? You do your three fetch and then do your add and it only takes one cycle. We allocated five cycles for instruction execution for LDI and STI, because those will take five or five states, I guess. So do we need to sit around and wait? What can we do? So what if I just, I get here and I finish my add and I finish my add, I just push my counter back to zero. What happens? It just goes and does another fetch, right? So what can I do to not wait around for four cycles? Just reset the counter, right? So I'll add a counter reset signal. So this won't just be a binary counter that just wraps around. I mean, that would work, right? But then we would have to wait around for four cycles. So add a reset signal. That'll be another control signal. Whenever we're done with an instruction, whether it's one cycle long or one state long or five states long or three states long, doesn't matter. At the last state, we'll exert counter reset and then we'll go back to fetch. So we'll only spend as much time as we need actually executing the instructions. Memory access can be slow. So do we need our clock speed to be slow enough for the memory? Or is there something else we can do? Yeah. Yeah. Let me. So the, for memory access, you can type in the process you set up and type in the information you need. Okay, so something like a memory ready signal or something? So what do we need to do with our counter? Oh, the counter that's not in the middle. Yeah, well, no, no, no. The counter that we're using to drive this one. Yeah. We better make sure it doesn't keep counting, right? Yeah, so we need to just stall it or pause it, right? So is that a pause signal? So we could call it stall, doesn't matter. Just some kind of signal to the counter that says, don't keep counting right now. We're still waiting for memory. Once memory finishes, which I'll just use in this design, I'll use the same signal that Pat and Patel use, which is the signal R, memory ready, meaning it finished its access. Once that signal is exerted by the memory, that means we can move on, right? So somehow we'll use that to decide how long we have to pause the counter before we can continue. And then our clock can run at the speed of the logic, which is what we want. Okay. So here's the general design. We've got some N-cycle binary counter. So for LC3, that's gonna be eight cycles, so three bits. You've got your IR and your PC feeding into combinational logic, producing control signals that drive the data path. The data path has some status signals that go back also into the combinational logic. We also can have the data path using the IR and the PC directly. But yeah, Mohamed. Yeah. No, because only in the states where you are waiting for memory, do you wait for memory. In the states like add execute, there's no memory operation. And so that takes exactly one clock cycle. And if memory is 50 times slower than their logic, then that's 50 times faster for the add execute state. Good question. All right, so this was, sorry. So this was our general model. I just added these arcs just to make sure you understand. I mean, these IR and PC are sort of sitting in the data path. You know they're being used anyway, but I didn't want you to think from the figure that they weren't being used. Yeah. Only if you try to pipeline and we're not pipelining our designs. Yeah, this is just executing one instruction at a time. Okay, one. Okay, so. All right, so how complex is this combinational logic? So we said, okay, we're just gonna build everything with combinational logic. And we know the inputs. We know we've got 25 data path signals plus our pause and our reset. So we also know for LC3, PC does not directly affect the control. And so if you look at all of the different states, we never use PC to make decisions. We use it as data, right? When you do PC relative addressing, or you change the PC for branches or other control flow instructions, but you don't actually make control decisions based on your PC. So we have as our finite state machine inputs, these three bits of counter state. We have the IR, which is 16 bits. So that's a lot of state. And we have data path status signals. So maybe that's, I don't know, around 24 bits or so, right? It could be around there. So get your KMAP pens ready. Ready for some 24 input KMAPs. So that's a lot, right? I mean, that's pretty nasty sounding functions. So at that point, really good design kind of comes to the rescue. So Pat and Patel spent a lot of time thinking about how can they design the LC3 data path to make control simpler. You've seen a bunch of examples of how that works. Things where, you know, bits in the instruction encoding can be used to specify the source register, for example, and those can then just be fed directly into the register file, rather than having to come up with those bits as part of the control unit. So you've seen a bunch of those examples already. So I won't spend a lot of time explaining it, but it's really through their effort that we can make these simplifications, right? So they design things so that it's easy to move bits around with wires rather than requiring lots of extra logic. So what inputs do we really need for the combinational logic? So if we think more carefully, well, we still need the three bits of counter state, right? As we walk through the different execute states, it's doing different RTL. So we need to know which state we're in. That's clear. We really only need the op code out of the IR. Everything else is kind of wired through muxes and we just need to control those muxes, right? The data path's been designed to let us not have to worry about those in terms of the states of the finite state machine. So we just really need those four bits. There's actually one instruction we didn't look at in our class called JSRR that uses IR11 as an addressing mode. So in fact, if you want to implement the full ISA, even without privilege and interrupt, you need IR11 as well. So we'll just add that in. And there's really only two data path signals we'll care about. One is the memory ready signal, R, that I mentioned a few minutes ago. And the other is the branch enable signal, right? The thing that we were calculating before in decode. So that will still have to be calculated at some point. So branch might get a little longer in this hardwired implementation because we couldn't use it until it's ready. Okay, so those are our signals. So if you add those up, let's see, we had three plus four plus one plus two is 10, right? So 10 bits of input, that's still somewhat complicated. So let's see, so how many control signals? So 10 bits of input. So control signals, 25 that we talked about on Monday, and then we added counter reset and counter pause, right? So we've got 27 total. So we still have 27, 10 input functions. So I think probably if I said, okay, get out your paper and solve all 27, 10 input functions, you'd probably be a little unhappy. So is there an easier way if we have all of those bits? So what if instead of really going and building from gates, we just said, well, let's just put a read only memory down. Right, so let's just figure out the bits and then we'll put them in a read only memory. That way it's also nice, if I figure out all the functions and I build it out of gates, and then I realize I messed something up and I left out a state or I did something wrong, I might have to go recalculate a lot of my functions, basically start from scratch. If I mess up some bits in a read only memory, if it's really read only, well, then I have to get a new read only memory and program it with the new bits, but I just have to change the bits, right? A lot of the, you can often get a programmable read only memories and change them, right? So if you make a little mistake in your design, just fix the bits and you're done. So, the 10 bits, how would we actually use this? The 10 bits of input are gonna act as an address. So we've got these 10 bits, the three bit counter state, five bits of the IR and two bits from the data path. We apply those bits as the address and outcome 27 control signals, right? So we need 27 bit addressability and that gives us this two to the 10 by 27 bit memory and total is over 27,000 bits. So that's not too bad, right? That's only 32K memory or something, less than 32K. I guess exactly 27K, but smaller memories would be faster, right? So if we wanted to make this a better design, we should think about, well, are there ways we can have fewer bits in that memory, right? Are there ways we can trim it down a little bit? So let's think a little bit. The data path in Pat and Patel was designed for their control unit, right? So if we are willing to make a few little changes here and there, we can actually make a better design for hardware control unit. So let's see how we can do that. So one piece is the memory ready signal, what's it used for, right? Anytime we access memory, whether it's instruction fetch or load or LDIs first load or store or any kind of store actually, anytime we use it, we're using the memory ready signal to wait to see, well, did that access finish, right? And we're just staying in that state until it finishes. So the only reason we use that is to generate our pause signal, right? So what's going on in this design as we've said it so far is well, memory ready signal goes in as one of the address bits. And for every one of these states, we actually have two different addresses. One is which memory is ready and one is with memory not ready. And one of them has pause on as one of the bits in that memory location and the other doesn't. So instead, we could just take that logic out of the ROM and put it into the data path. It's pretty simple logic. So for example, let's instead add a control signal called waitmem. So in the states where we have to wait for memory to finish, we'll exert the waitmem signal. And then the finite state machine states that stall, like I said, they'll set waitmem equal to one. And then in the data path, we'll just add this little bit of simple logic. So pause, the input to our counter pause will be R prime and it with waitmem. So the only time you're gonna pause is when memory is not ready and you're told from this control signal, well, you have to wait for memory to be ready. So we cut the control signals by one by removing pause, but we added a new one, waitmem. So the control signal is still 27 of them, but now we don't have to put the R signal as an address bits. We only have nine address bits. So that means now we only have half as many memory locations, so half the size of the memory. So one tiny little bit of logic added to the data path would cut the memory in half. So what about branch enable? So branch enable is used in the branch instruction, and if you see the branch enable is false, you go back to fetch. And if branch enable is true, you change the value of the PC before you go back to fetch. Well, so again, our initial design does that computation implicitly by having different addresses. We're routing branch enable as an address bit. The ones with branch enable turned on will continue and execute the PC change. And the ones with branch enable turned off will go back to fetch by resetting the counter. So instead, what we can do is add two more control signals. One will be branch reset. So the branch instruction will use this control signal, and all of the instructions when they're finished will exert a second control signal, second new control signal called instruction done. So then we can set in the data path, the reset signal will be calculated with this little bit of logic. So we'll say, well, whenever the instruction is done, we'll reset the counter. Or if we have branch reset exerted and branch enable is not true, that means we're doing a branch instruction, but the branch should not be taken. So now we just wanna reset the counter immediately. In either of those two cases, reset will be true. So now we have two more control signals generated. We're no longer generating reset from the control ROM. So we have one extra, so that gives us 28 and one fewer input. So again, cut roughly in half. So now we have one more bit of addressability, but we have half as many addresses. So now we're down to about a quarter, just with a couple, a few gates. So there's one more thing we can do very easily, which is this JSRR problem. IR11 is used only for that particular instruction to decide between JSR and the JSRR instruction. One uses a PC relative offset, the other uses a base register. So decide between those two, what we can do instead is connect the base register, which is an SR1 over to the fourth input of PCMUX, and then use IR11 directly in the data path with another control signal. And so if we add that extra control signal and take IR11 out of the inputs, then we're down to two to the seven addresses, seven bits of address, three for the counter, four for the opcode, and then 29 bits of addressability for control signals. So total is less than a seventh of the original design, so a little more than an eighth. These are some details, I don't think I'll go through these, but eventually these will go in the notes. Yeah, I realized, as you'll see, I realized that without doing the simplification, we can't actually get our hardware control design down to 32 states. So we do have to do the simplification to have only five bit addresses. All right. Any questions on that before we talk about microprogramming? Feel like you understand the hardwired design? Yeah. Mm-hmm. What's the, so the JSRR, what's the one thing, IR, that's what you're looking for? So what we did is we made a more powerful data path, but we didn't have to add much logic, right? So remember PCMUX had only three inputs connected. So there's a free input. So we use that free input to put SR1 onto that input. Yeah, there's actually a long story here that the, I think it was in the early days, but I think it was in the early days of the first PCMUX, and I think it was in the early days of the first PCMUX, and I think it was in the early days of the first PCMUX, and I think it was in the early days of the first PCMUX, but I think pretty much all of the versions you can find in the wiki and the webpage and the notes and so forth of the Pat and Patel data path are the old version, which has a bug in JSRR, which they then fixed in later instances. So those of you that have newer books probably have a slightly different finite state machine implementation of JSR and JSRR. So those can be combined with this little extension so that there's only one state instead of three states. No, LC3B stands for byte addressable. Let's use for 411. Yeah, no, it's not related. Okay, so let's talk a little bit about micro-programming then. So that was hardwired control. So here's the finite state machine, and this is the one, let's see. So in the newer versions, this R7 gets PC, gets copied down into both of these two states. This is the JSR and JSRR implementation here. This one is JSR, this one is JSRR. But that's not kind of the point. I just wanted to show you while we had it up. The point of this slide is, well, this is a pretty sparse, sparse finite state machine diagram, right? I mean, in theory, you can draw finite state machine diagrams, and there's so many bits of input here, you could have hundreds of arcs going out of every state. And we said, well, you have to make it complete. But this looks more like a flow chart or something, right? It's got one arc going out of most states. Sometimes you have two. The only place you've got more than two is decode. And everywhere else, there's only one or two arcs leaving. And so it's a pretty simple thing in terms of finite state machine transition diagrams, relatively simple, very few arcs. Yeah, go ahead. I mean, it has the same utility of jump versus branch, right? It's just longer range, because the PC offset is limited. Okay, so can we treat this as a program? So what if instead of thinking of this as a finite state machine design problem, we thought of this as a programming problem. So think of the control words, right? So each state has some RTL. That's what we looked at on Monday, taking that RTL, turning that into control signals, right? So you can think of those sets of 25 control signals as a control word. So each state has a control word, and maybe instead we'll call those micro instructions, right? So what the control unit is then gonna do is to execute micro instructions. And so the way it'll do that, the program will be this thing, right? And so each of these will be a micro instruction, and we'll go through and execute those one at a time. We'll store micro instructions in a ROM and use the state ID as the address to that ROM. So we'll read the micro instruction for that state and then use that micro instruction to drive the data path and then go on to the next micro instruction. And so this is called micro program control unit design. So if we ignore, again, interrupts and privilege and include that extension that I mentioned with JSRR and PCMUX, then we need fewer than 32 states. So then we can have five bit state IDs, which was kind of nice. And so very tiny state IDs. So our control ROM will be very small also. So control ROM will be only two to the fifth by 26 bits. Remember that extension we added one more control signal. So two to the fifth by 26 bits. So every cycle, this micro program control unit will take the five bit state ID, go to the control ROM, say, well, give me the micro instruction, and it'll get back 26 bits. It'll apply those as control signals to the data path and then go on to the next micro instruction and just execute one instruction at a time. And so the control unit will really look a lot like a processor, right? Except instead of executing instructions, it'll execute micro instructions, which are just the states of the FSM. Now notice that IR is not used as part of this address, right? It's only the states, right? We don't need to know the IR, that's implicit in the state diagram, right? Each op code has its own set of states. So we don't need IR as input to our control ROMs address. And so it's much smaller control ROM. So how do we handle these transitions though? And so we said, we'll go on to the next micro instruction. How do we find it? So that problem is called micro sequencing, or sometimes we just say sequencing. So let's look again at this diagram. So there's a lot of stuff in here that we never talked about. So most of these states, first of all, have a single arc, right? States like memory access actually have two arcs, right? Here's one going back to wait for memory to finish. JSRR had two arcs, although we're combining those. Where's the other one? Oh, here's branch up here. This has two arcs, right? This is the one branch is taken, goes down, branch not taken, goes back to fetch. So let's add a couple of state IDs to each of these micro instructions. So instead of just having the control signals for micro instructions, let's also store the next state ID. And so how do we figure out what's next? Well, we'll just store the next state ID. So here's an example of what that might look like. So we've got our state ID stored at a five bit register. That goes in as the address of this 32, two to the fifth by 36 bit memory. Those 36 bits then are the 26 control signals and then two five bit next state addresses. So those two next state addresses will go up here and then somehow we'll come up with some micro program branch control that will let us pick one of those two addresses and that'll be our next state. So most of the time, we've only got one or two next states. The only exception is decode. So this design will actually suffice for the entire state diagram except for decode. But we do need to figure out, well, what is this? What is this micro program branch control stuff? How complicated is that? So it turns out it doesn't have to be very complicated. In the state diagram, there's only two reasons to branch. Those states that have two outgoing arcs, they have it for two reasons. One is memory is ready or not. And the other is branches enabled or not. Those are the two data path signals we needed. So those are the reasons for branching. So here's a simple example. So here's a simple design. We'll take the state ID, we'll compare it to the branch state, and then we'll use a MUX. If the MUX says it's not the branch state, we'll pass the memory ready signal as a micro program branch control. If the MUX says it is the branch state, we'll pass branch enable as the branch as the micro program branch control. So that's fine for the states that actually branch. What about the states that don't branch? Well, we've got two state IDs, we'll just make them the same. If there's only one next state, we'll make the two possible next states the same. And then regardless of what R happens to be, it'll just go to that next state and we're done. So now we've handled everything except decode. So using one MUX, this little comparator for the branch state, and this memory, this is our control ROM, this is a five bit register, this is another MUX. So we've got, I guess, two MUXs. Yeah, Eric. Yeah, so for example, here in fetch state three, the next state is decode, right? And so here in fetch state three, you would set both next state IDs, both of these values here would be the decode state. And so then regardless of what this MUX does, it gets decode state as the next state. Okay, make sense? For every state that does not have two outgoing arcs, yes. Every state that has a single arc, so this one and this one and this one and this one and this one. So everywhere you see two outgoing arcs, then those would have different addresses, yeah. So the ones with self loops are two outgoing arcs, and then this branch here is two outgoing arcs. And then this one we haven't talked about, it has 16 outgoing arcs. So we need to do something about that, right? So what can we do about that? We'll borrow a trick from Pat and Patel. So let's just say that the first state of execution, we haven't done anything with our state numberings yet, right? So let's just say, well, we've got 16 opcodes, we've got 32 states, we need an opcode to start the execution of each, I'm sorry, we need a state to start the execution of each opcode. So let's take the first 16, zero through 15, and say those are the states where we'll start executing the corresponding opcodes. So add is opcode number one. So state one will be the one add execute state. Zero is branch, right? I can't remember too many opcodes. 10 is LDI. Each of those states from zero to 15 will be the first execute state for that opcode. So then we can do this. So I've added the blue stuff, right? So I've got a comparator, it says, is this the decode state? If it is the decode state, ignore the next states and just put in zero followed by the opcode. Okay? So that will give me the first execute state as this state address, right? Because I just defined them. So then on decode, my next state will be the first execute state for my opcode. For everything else, decode is not, it's not that state. So I'll pick the zero input, which is exactly what we had before. So then we're done. That's our control unit design. So we do actually need to assign the other values, right? So we've got 16 states left and we've got, I think, 15 states we'd have to give numbers to. So it's a somewhat tight fit, but then we can just go calculate the bits. And so once you assign all the states numbers, state IDs, and we've got 15 more to assign, then you can calculate all the bits. Control ROM total was two to the fifth by 36, right? So 1,152 bits, about 30% of what we needed with the hardwired design. And again, most of that is that in the hardware design, you're looking at both the IR, the opcode and the counter. And so you end up having a lot of redundancy, right? So if you think about, you've got a bunch of states that aren't used, which are the trailing execute states when the counter has a high value for opcodes like add and and, but you also have redundancy where all of the fetch states are the same. And so you're ignoring the IR bits, but you don't know what they are. So they have to be multiple addresses in the ROM for that. Yeah. Yeah. Yeah, so to some extent that's true, right? So let's go back. So to some extent, you've got similar, if not identical RTL, all of the memory access states, except for the store, which is this one, right? All of the memory access loads, so there are one, two, three, I guess only four, but the four memory access loads are the same, right? And so you could say, oh gee, can I combine those somehow? The next states are different, right? And so it would not be easy to come up with a control unit that saves you, you're only saving now four times 30, I guess three times 36 bits, right? But I mean, maybe you can find more redundancy in the RTL. So maybe it'd save a couple hundred more bits out of the 1152, but it'd be hard to make that work because you'd have to keep the same next states. Well, you'd have to have some way to make them work properly, right? You can't combine them in the finite state machine design. So you'd have to come up with an implementation that gave you the same answers without using as many bits, which I don't know how to do easily. Yeah. Yeah, they certainly have to be separate states logically. Whether you can come up with an implementation that's smaller easily is a different question, right? Logically, they have to be separate states because they do have different next states. So the behavior of the finite state machine after the memory finishes its access has to be different. I mean, you don't want your fetch suddenly turning into an STI, right? Okay. Let's see. Just finish that design. So any other questions on, yeah? So decode will have to assign some value, right? But it's just some fixed bit pattern. So we haven't assigned a value yet. But let's say we pick 16, right? Then all this thing has to do is compare these five bits to 16 in binary, right? And so logically, it's maybe some inverters and an AND gate. Actually, you can have inverted inputs out of the register, out of the flip-flops, right? So it's really just an AND gate with five inputs. Anything else? And the same is true for this comparator, right? We didn't, at this point, we hadn't even picked the branch state. It'll end up being zero, right? So this is just comparing to see if the state is all zero bits. Eric? Yeah, so this is the state ID after decode, right? So this is the state ID after decode. Yeah, so this is the state ID after decode, right? So this is the numbering of the first execution state for each of the opcodes. So the opcode is 0001, which is add. Then the state is 0 followed by 0001, which is 1 in decimal. So state 1 would be add. State 0 is branch, because the branch opcode is four 0 bits. State 15 would be trap, because the trap opcode is 1111. I don't know if you can see these. I kind of doubt. Sorry, I know it's, can people in the back read these numbers, the one I'm pointing to? Can you see those? It's too fuzzy, right? Well, those are the, so this one and this one, these are the first execute states for each of the opcodes. And if you could see the numbers, you'd see this is LDI, and this is 10. This is STI, this is 11. This is add, this is 1. This is and, this is 5. Those are the opcode values. And those are the state numbers, both in our design that we just finished and in the Pat and Patel design that I'll show you shortly. Except in Pat and Patel, they have one extra leading 0. But the numbers for the first execute states are all the same. Well, they have more than 32 states. So they need 6-bit IDs. All right, so let's go ahead and take a look at this. So with interrupts and privilege, they're going to have these 6-bit state IDs. So that was really the point of this slide. So we're going to have to do a slightly different design. So I want to look at the one in Pat and Patel now. And show you how their micro sequencer works primarily. And then go through and derive sequencing bits for the same states we did on Monday, meaning fetch, decode, and LDI execution. So this one is the arc for outgoing interrupts. That's actually in a completely separate figure in the appendix. So all of the states that are not shown in this diagram. All of these little numbers here, as I mentioned, are the state IDs. So I know you can't read them. But when you look at the figure or you get the figure in your exam, if you need the state IDs, they're all there. So you don't have to memorize them or anything. So interrupts and privilege add another 14 control signals. So the total control signals is 39. Pat and Patel micro instructions also include then 10 bits of sequencing information. So in the design I just showed you, we added 10 bits as two 5-bit state IDs. For their design, they add 10 bits as one 6-bit state ID. A condition for branching, which I'll explain in a minute. And then IRD, which is just a 1 when you're in the decode state and a 0 when you're not. So they add that as a bit in the control word, bit in the micro instruction. So here are the conditions. Only three of these are things that we've talked about in our class. One is unconditional, which means you only have one next state. The other two that we've seen are the memory-ready branch and then the branch-enabled bit branch. And then the three we haven't seen are the JSR or JSRR addressing mode bit, which is IR11. Privilege mode violation, which is PSR15. This is process status register. It's not even a register we've talked about. So you can just think of these as some 1-bit signals. And then interrupt occurred is the int signal. So we didn't talk about these three gray ones, these three at the bottom, but it's in their design. So I wanted to make sure you don't feel confused when you see the design. So here's the design of their micro sequencer. So first of all, it has the same thing that we had for managing decode. So they have the IRD signal coming out of those 10 bits. It says this is the decode state. When you're in the decode state, you get two zeros followed by the opcode as your next state number. So the same state IDs for the first state of any opcode execution as we defined for our machine for our micro program control unit a few minutes ago, but with one leading zero because they have 6-bit state IDs instead of 5. So they have two extra zeros. We had one. But otherwise, it's also the same MUX design. Now, the difference here is this is their micro sequencer for everything else. So what you can see here, this is basically like a decoder exploded for the conditions. So for each of these conditions, these are implicit inverters here. But each of these AND gates would be one minterm on the conditions. And so they're the minterms in this table. So there's no unconditional one, obviously, since you're not going to change anything in that case. But you can see for each of the AND gates, each of the five conditions, and they're not in order. They're kind of scrambled. So you have to kind of look at the thing to decipher it. But for each of the conditions, we change exactly one bit of the, sorry, there's the decode. There's the first states. For each of the conditions, we change exactly one bit of the address j. So the address j, which is stored as part of the micro instruction, that's the next state address. The only kinds of next state addresses we can use are addresses that differ in exactly one bit. The zero bit happens when the condition that we're looking at is false. And the one bit happens when it's true. So we have to pick our state numbering somewhat carefully. So let me explain that a little more. So for example, the memory ready signal or is in the bit number one or value two. You can see that here. Here's memory ready. That gets or'd into j sub one. So that or's in the value two. So if we want to wait for a memory access, we have to pick state numbers that differ in exactly that bit. And we have to have the memory not ready state have the address, the state ID with the zero bit. And then the next state where the memory access is complete has to have the address plus two or two, which is the same in this case because that bit is zero. Those constraints have to be obeyed. So you have to obey those constraints when you pick your state numbers if you want to use their micro sequencer. So of course, they did. And it's reflected in the state diagram. But occasionally, you'll see as you go study old final exams, you'll see things where we ask you to add an instruction and make use of free states in the Patten-Patel design. And you have to look at the micro sequencer and figure out how to make use of them in a way that works. So we'll go through some examples. Here's another example. So branch opcode is zero. So that's the first execute state. So that's the branch execution state is number zero. State zero branches on branch enable. When it's false, the branch is not taken. So the next state is fetch. And when it's true, the next state has to be 18 or four. So the next state has to be 22, which it is. And that's because it's branching on branch enable. And if you look back here, you can see branch enable goes into J sub 2 and puts a 1 into J sub 2 when it happens. So we have a few minutes left. I think we'll probably have time for this. I don't think it should take too much time. But I wanted to go through and take a look at all of the fetch and decode states and ask, well, what are those 10 bits for each of those states? We already did all the control signals on Monday. But let's look at the 10 micro sequencing bits for each of fetch and decode states. So these are the states again. So now, hopefully, these state numbers are visible. But I'll put them in the next slides anyway. So here are the state numbers in binary for fetch 1, fetch 2, fetch 3, and decode. Fetch 1 branches on the interrupt signal. The next states are fetch 2, which is this pattern. You can see it down there. And start of interrupt, which is over here. So the bit that's different then is this bit here, the bit number 4, counting from the right as number 0. So 0, 1, 2, 3, 4. That's what the interrupt signal changes. So what should j be? So remember, in their micro sequencer design, when the condition is true, it's going to change the bit from a 0 to a 1. So if in j, you make it already a 1, it will never branch. Oring in a 1 where something's already a 1 doesn't change it. So you have to pick, out of the two next state addresses, you have to pick the one with more 0's. So you have to pick this one, basically. So that has to be the next state address. If the interrupt signal is on, the micro sequencer will turn on this bit in j, and it will go to this state instead. If interrupt is off, it will go to fetch state 2. So that's how their micro sequencer works. Because as you fill in these bits, for every time you have a branching state, you've got two next states that have to differ in exactly one bit. The bit in which they differ always depends on the condition you're picking. The condition and the bit that differ have to match. And the pattern with the extra 0 in it is the one that has to go into the j value for the micro sequencer bits. So the condition in this case is 1, 0, 1 for the interrupt bit. So is this the decode state? No, so it's a 0. So what about fetch 2? So fetch 2 branches on memory ready. Fetch 2, we're going to memory, and we've put the PC into the MAR, copied the PC into the MAR, incremented the PC in fetch 1. Now we want to read from memory. So the next states are going back to itself, which is fetch 2. So it's that address again, or going on to fetch 3. So you can see the difference here is in bit number 1. And so fetch 2 has the 0, fetch 3 has the 1. So when memory is ready, it'll go to fetch 3. And when memory is not ready, it'll stay in fetch 2. So what should go into j? Fetch 2, the one with the extra 0. And the condition in this case, any time we want to branch on memory ready is 0, 0, 1. And then is this decode? No, that one's easy. Usually you probably want to look these up in the table. So we'll give you all these tables. All right, fetch 3 does not branch. The next state is decode. So what goes in j? Just decode. There's no branching. So what's condition? It's all 0s. That was the unconditional one. And is it decode? No. Next one is decode. All right, so decode goes from some state from 0 up to 15. Decode is where we're branching into one of the 16 different op code states to start execution of those op codes. Based on that op code, it picks one of those 16 states. So let's start over here. Is this decode? Yes, good. What are these things? Do they matter? So if you think back, I mean, I can see how quickly I can flip back to the micro sequencer. There it is. So when this mux goes from here, does this stuff matter? They're don't cares, right? So j is a don't care. And condition is a don't care, because whatever this thing puts out gets thrown away by the mux. That input is discarded. Because right now, we're looking at decode. We're taking this input, forwarding that to the next state. So we'll flip through this. Yeah, yeah. I mean, you could simplify by not muxing those bits, right? Yeah. Yeah, so you could do that. Yeah, you could simplify it a little and have two fewer muxes out of the six. I mean, I think they just wanted to simplify the diagrams in the book. Yeah, when you actually build it, I think you'd probably do that simplification. It's a good idea. All right, so the other set that I thought would be useful was LDI. We're kind of out of time, so maybe I won't walk you through this. But it's in the slides online. So all it is doing is looking, again, at the five LDI states and asking, well, what are the micro-sequencing bits for each of these five states? The one you're going to encounter most of the time is going to be the ready signal. And if we ask you to add an instruction on the exam or something, it's going to be something with a load or a store. You're going to have to do memory ready. You're going to have to have them off by the difference in bit one, so two. And the one where you're reading from memory has to be the one with a zero there. So you can look through those. And I will stop now and leave those to you. And on Friday, we'll do error control, redundancy, things like that. Thanks.\",\n",
       " \"during the break, then you can do Lab 14 early if you want to. It'll go up early. I know all of you are just itching to do more LC3 programming. There's also this sprite ASM file on the wiki, which is what the other lectures are doing. So if you want to see it in action, you can watch Professor Jaramillo's lecture. But you can also just go grab the code and take a look at it if you're interested. What we're going to do today is do some ASCII screen art, because I just like art. And so I'm going to ask you to write a program for me, and I'm just going to type. But it's going to be this program where actually, so I'll reveal who at the end. But someone sent me a file of tuples of positions on a screen and ASCII characters. And so we're going to take that file and figure out how to print it. So that's what we'll do today. I have a think-pair-share too, but I think I'll just skip it, especially because there aren't that many people here. So if you're interested, I might post the slides. Think-pair-share is I ask you to get together in small groups during class and think about things. I used to do a bunch of them in 190, the predecessor to this class. I don't do so many here, because we oriented the entire discussion section around that style of interaction. So we're already doing it every week, so we don't do it in the lecture very often anymore. But I thought it'd be fun, just before break, to go and develop a code together. So let me get my paper out. I told you never to start coding, so even though I have this part ready to go for coding, we're not going to do that first. See, I've got Notepad, my all-purpose programming tool. And I've got CGWIN LC3 tools here. So this file, we will write LC3 code here. So I learned the, I can type pretty quickly now, but when I learned to type, I didn't know enough to do what my department head did to me, which was, he said, oh, I can type now with more than two fingers. And he said, yeah, well, I used the double eagle version of typing. Wow, Dick. This was Dick Blahut. Wow, that sounds really impressive. I'm a faculty, so I don't just say, oh, thank you, double eagle, amazing. So what is the double eagle? The double eagle version. So tell your friends and family, I'm a double eagle typist, actually. All right, so let me see how quickly they can switch. I think it's not too bad. All right, so what I want to do is we're going to get this set of tuples. So it'll be an array of three tuples. So what it'll look like is basically consecutive memory locations like this. There'll be an x location, a y location, and some ASCII character. So for example, it might say, well, at position 5x, at position 10y, we want to draw the letter A, for example. And then after that, it might say, well, at position 5x, position 11y, we want to draw the letter T. So I'm putting them in quotes for the ASCII characters. Of course, they'll be ASCII coded. So what we want to do with that, when we're done with that, the end of the array, so we won't know how big it is, but we'll get an x value of negative x value, which will be the end of the array. So that's how we'll know where the end is. Like when we're looking at a string, we know the end because we see a 0, a null character in ASCII. For this array, it'll end with a negative x position. So if we get a negative x position, that means we're done. So what we need to do is figure out how to take this array and get it onto the LC3 screen. So here's a picture of what I want to draw to the screen. So you remember, with LC3, the only things we have for input and output are basically send a character to the output and read a character from the keyboard, right? So we don't have nice screen art where we can say, well, I want to move over here on the screen and put something there. And then I want to move up there on the screen and put something there. So in order to make this work, we're going to have to play a couple of tricks. In particular, what we're going to do is break this down into a few steps. Let me switch briefly back over to PowerPoint, and I will show you those steps. Oops. Oops, I was going to review this, but I'll just skip that. So this is our array, right? We've got x position, y position, ASCII characters. That's what I was drawing on the paper for you. So here's how we're going to tackle the problem. So instead of just drawing directly to the screen, because we can't control where we draw, we can just draw sequentially, what we're going to do is we're going to build up in memory a picture of a screen. So we're going to do that as a bunch of strings, one string for each row. So we'll start off by just filling that fake screen in memory with a bunch of spaces. And I'll actually use a null at the end of it, because I'm kind of lazy and I want to use putstrap, which I hadn't told you about. But the putstrap will send a whole string to the display. So we put r0 to the first character in the string. We call the putstrap, and that prints the whole string for us. So we'll make a bunch of strings, one per row of the screen. I'll draw that as a picture in a minute. And then we'll parse the array. We'll go through the array and say, well, here's a character at position 5, 3. We'll figure out where that should go in our fake screen, and we'll put that character into our fake screen. And then at the end, we'll dump the screen to the real monitor to see what it looks like. So those are the three steps. So let's go back over here. So here's our fake screen. So the idea is, well, somehow, maybe we've got some width here. We've got some height. So when I see something, so first I'll fill this with spaces, right? So first, fill with spaces. And put a null here that's not part of the screen. So a null here, a null here, a null here. Each row will have its own null. And each row is one set of spaces followed by a null, width spaces followed by a null. So fill it with spaces and write the nulls. And then step two is parse the array. So we'll parse the array. We'll parse the array. We'll parse the array. And then step two is parse the array. So for example, up here, I said, well, x position is 5. y position is 10. So if I were to draw all these positions, then let's see. We'll count this one as 0. This one is 1, 2, 3, 4, 5. And then this one is 0. This is 1, 2, 3, dot, dot, dot. Down to position 10. So here at 5 and 10, I want to plug in an a there. And that would be parsing the first 3-tuple from our array is to go, say, x position 5, y position 10, put the a there in our screen. And then once I've gone through this whole array and put all the characters in, then my screen is ready. And I can just print all the screens. We'll put s one at a time. So I'll go through the array one tuple at a time until I find the end of the array. Step two, parsing the array. And then step three is print the strings of the fake screen using putstrap. So those are our three steps. So let me switch over here. And we can get started just putting a few things in. Let's see. OK, good, it didn't. All right, so we'll do the first part first. But before I can do anything, this is LC3. So let me write my. So you can't actually type now. I brag too much. All right, there we go. So I'll put my dot orange dot in, give myself a little space. And then first step, fill the screen with spaces. So let's see, we want to have width and height parameters. So put those down at the bottom. So for width, why don't we say, I don't know, 40 spaces. For height, why don't we say 26 spaces. We could change those later if we wanted. We'll use them as parameters that we'll store in memory. So how do I write a bunch of, oh, I better make a space for this, huh? So let's put our screen somewhere. So let's put our screen at 4,000 hex. So our code's at 3,000, our screen's at 4,000. Let's say our array's at 5,000. So just put those in at the bottom of our code, and we can make use of them in our code. So the first step is fill the screen with spaces. So right now, there's just a bunch of bits in that memory. So I need to go through and somehow create one row, one string for each row. Yeah, Nathan? Really? Remember, that's 1,000 hex, 4 kilobytes. That's a good check, though. Someone's doing the checks. Because if you make one clobber the other, what happens? LC3 just does what you tell it, which means that you would overwrite the array with your spaces, and then you'd miss part of your array. So good call. But in this case, we're safe. So good check. All right, so yeah, if you make width and height too big, then we're in trouble. But for now, they're OK. Maybe we should put a comment there. OK, now we're safe. No one would ever change those to be more than 4 kilobytes. All right, so let's think about what we need to do to fill the screen with spaces. So I'll switch back over here. So here's my screen. How is this screen going to go into memory? Which way? I mean, this is an array. So let me draw a smaller screen. So let's pretend we've got a screen. And I'm going to draw a screen. And I'm going to draw a screen. And I'm going to draw a screen. And I'm going to draw a smaller screen. So let's pretend we've got 3 by 3. So I want a 0 here. So let me call these A, B, C, D, E, F, G, H, J. I'll skip I. So what should go first in memory? A, right? What's next? B. OK, so we're going to go across the first row. And then we're going to go down after the 0. So if my screen is 3 wide, I'm going to have three locations, one to hold that extra 0. So to linearize this in memory, it's going to look like this. A, B, C, 0, D, E, F, 0, G, H, J, 0. So this one is width plus 1. And this whole thing is width plus 1 times height memory So that's the thing that can't take more than 4K. It is that product there. So how should I break this down, filling A through J with spaces and putting those 0's in? Is that an iteration or a sequence or a conditional? It's a loop, right, an iteration. So loop over what? Rows or columns? Probably good to do rows first, right? Because then, actually, if I do rows first, then I'm just walking through memory, and I can have one pointer that fills things. If I do columns first, my pointer to what I'm writing has to jump around a lot. So maybe let's make our life easier. So we'll do the rows first. So we'll say something like, for every row, for every column, I fill a space and then increment the array pointer. And at the start of that loop, then I can say array pointer initialize to what was it? 4,000? OK, so if I initialize my array pointer to 4,000, and then for every row, for every column, I fill a space and increment my array pointer, that'll write the letters up there. What about the zeros? I'm sorry? You probably shouldn't assume that about LC3 memory. I mean, yes, it's true in the simulator, but yeah. Yeah, well, so for one thing, our program is not going to go up there, right? Our program is down at 3,000. So our program is not going there. And yes, the simulator will fill the rest of memory with zeros, but you're probably safer just not assuming that kind of thing because it'll tend to come by to you later. We're going to end up having to put a carriage return, but I was going to put that in the print loop. We want the zero because we're going to send, we want a null because we're going to send the entire string using put s. So we do need the zero. So we're going to have to write it there. So where should we fit that into our structure here, our loop structure? Yeah, we can put a zero in a register. So where would I put it in the memory? I'm sorry? So I want to put one for each row, right? So after I do my entire column, maybe down here. So after I fill a column, OK, so let's see what this is doing. I should have cut more pins out. So this is one row up here, right? So this loop here will fill that row. So after I do that row, then I want to put one zero. So fill one zero, and also increment the array pointer so that I don't overwrite it. So this is now something I do for every row, right? So if I add that little bit of code down there, that will write my zeros in for me. So these will be my spaces. Whatever my width is, I'll write that many spaces. I'll put the zero at the end of each row. And I'll do that for height number of rows. And then I'll be done. That make sense? OK, so what do we want to use for keeping track of these? OK, so what do we need to keep track of, first of all? So we need a row. We need a column. We need an array pointer. Someone said we should have a zero. That's a good idea. Uh-oh, what's going on with my laptop? Wants to reboot. Maybe not reboot. I think it decided to go to sleep. Hopefully, I can get it to wake up. And oh, what other thing do we need? We need one more thing. What else would be convenient to put in a register here while my laptop comes back? Anything? Sorry? Yeah, so height and width, we can maybe use the pointers and just count down, because we just need counts, right? So we could initialize the count. That's a good idea, but I think we can count the other way and then just use one for the row and column in this case. What about this one? Anything you might find convenient for filling a space? How are you going to write a space into memory? Yeah, you probably want it in a register, right? Because space is 20, so 20 hex. So maybe we'll put 20 hex, which is a space character. This is null. Well, maybe we're not going to be able to write code today. What's going on with my laptop? Oh, I have light. Try to get it to go to sleep and then wake up again. Into another register. Oh, I'm sorry, those A, B, and C initially will be spaces. Yeah, those I just wanted to illustrate the mapping between the screen we're trying to build and the memory organization. Yeah, but initially we'll want to make them all spaces, and then we'll fill them with real characters from the array. So we have to have a drawing canvas, right? So the drawing canvas is a bunch of spaces. So the array is mapped like this. So depending on the width and height, the number of memory locations, one row is mapped, is organized linearly in memory. And you have first row followed by second row, each of them with a zero at the end. So this array is three by three. So the first row is A, B, C. And so in memory, it's the A, B, and C characters. And then there's a null at the end. Yes. AUDIENCE 2 Ah, I'm sorry. I called two different things array, didn't I? I'm sorry. It was at 5,000, the tuples, the three tuples start at 5,000. AUDIENCE 2 So the three tuples are organized sequentially in memory as x, y character. The last one is a negative x position. And then the x and y positions are given according to this mapping. So 0 and 0 is the upper left corner. x positive is that way. y positive is down. Oh, yeah, they're unsorted. Yes, they're not sorted. Yeah. Yeah, and so that's one reason that we have no way to control moving around other than we can only print linearly with LC3. No, no, no, no. We make the blank canvas. And then we put characters in wherever they happen to fall. And then we have a picture. And we dump out the picture. Yes, yeah. So we're going to use the step two. We're going to go calculate the screen position for each array element, put the character there, and then we'll dump the screen in one big operation in part three, basically print a bunch of string. And this is actually technically similar to how real graphics work. Most of the time, the graphics cards are drawing the next frame in the background. They're not drawing it on the screen because it makes it flicker. So yeah. If you want, let's say, rotate the image, you can go ahead and swap them. Oh, yeah, yeah. I mean, all you have to do is treat them as opposite values. Yeah, so if you want to do an image transpose along the diagonal, although the characters are not square. But yeah, you can do that easily. Sorry, my laptop did decide it had to be rebooted. So we're waiting for it to come up. And then we'll type this first code. OK. All right, so. OK. Oh, I didn't save my code. Wow, that's sad. All right, so what did I have? A width, what did we say, 40? OK, so what we decided we needed in memory we need a row. Why don't I use this one for the 0, this one for the space? OK, so R2 can be our row. R3 can be our column. R4 can be our array pointer. I think that was all we needed. So let's first initialize our variables. So how do I get a 0 in R0? And good. And then how do I get a space in R1? Yeah, I could add, right? I'm kind of lazy, though. I think it's less typing for me. But yeah, I could do add 10x. No, I can't add 10x. I'd have to do three adds, wouldn't I? Because it's 20. Yeah. Yeah, I'm just going to fill, because I'm too lazy to type so many adds. All right, so for the row, let's see. So let's start the row at height. So this will be our row loop. And then I'll have to reinitialize the width every time. So let me load that here. And this will be our column loop. So then I need to store a space, right? So where's my array pointer? I better initialize that, too. How do I initialize R4? I want to initialize it to point to the, oh, I'm sorry. I really should call that screen at this point, huh? I want the screen pointer here. I will need an array pointer for the next part. So for now, I'll just leave that blank, though. So how do I initialize R4 to point to the screen? So the screen's at 4,000. I don't think I can get from down around 3,000 to 4,000. I do have it down here in this memory location, though. So is there a way to get it from, how can I get this value that I've stored down here into R4? Just another load, right? OK, good. Yeah, the assembler will take care of the offset. I could try to do an LEA, but I would have to calculate the offset myself, which is a pain. And then it's also probably out of range from this code, which is another pain. Yeah, I wouldn't be able to jump. I won't be able to LEA either. OK, so if I load it from here, then that will give me the value. Oops, but I don't want it there. I want it up here. OK, so that's got those ready. 0 is ready, 1 is ready, 2 is ready. Column was supposed to be 3, not 1. I should leave bugs for you. All right, so now I need to fill a space. How do I fill a space? How do I write a space to my current screen pointer? Yeah, not unless it takes me a lot of code. I mean, the PC offset is 9 bit, right? Yeah, yeah, that's just the value of x4000. No, no, no, no. OK, so someone said store. What kind of store? Really? OK, so st from my space register to where? Yeah, probably store register, right? I could use sti to this, but then I could only fill one space. I'm actually going to change r4. r4 is going to go through the screen and fill each place with a space. So I'm going to change r4. So let me use r4 offset here. And then I can increment r4 to point to the next one. So that'll give me one space for one column. And I just made the advance the screen pointer. So the next time I fill one, there'll be a different place to put a space. So now I need to count down my column loop. So how do I decrement? Ah, yeah, str, good. Thank you. So how do I decrement my column number? Add negative 1 to which register? Or 3, right? OK. Good. And then what? Branch, what condition? So if this were 5, then first time through, it would be 4, then 3, 2, branch positive, right? OK. So as long as we still have a positive number, we're going to go back for more. Where should we go back? Good. OK. So now we have one row done, but we didn't put our null yet. So how do we put the null? From r0, which is a 0, to where? 4. 4, good. Yeah, so we're just writing into this screen that we're creating, right? OK, and then I better advance the pointer. I really should leave bugs for you. I tried to leave one, but you caught it. All right, what do I do next? Just branch back to row loop? OK, branch, what condition? What do you want? So what do you want me to do? Add r2? Minus 1, good. OK, and then branch positive like that. Good. So we should be done. Try that. It worked. At least it compiled, or assembled. Let's see. I can dump 4,000. Hey, look, there's a bunch of spaces. Cool. Did I get it right? A lot of spaces. Think the code works? So when you do this kind of stuff, you probably want to make your life easier. Probably that one's easier to check, right? Let's do that. OK. So now there are a few less. I don't know, can you read this font? There's one, two, three spaces and a zero. One, two, three spaces and a zero. One, two, three spaces and a zero. So it looks pretty good. Actually, it's probably a bad idea to pick three and three. Why is that? Yeah, if I get them mixed up, I won't be able to tell, right? So maybe I'll do it a little bit differently. I'll make it four wide and three high. And then we'll run it one more time, and then we'll go back and do the second part. OK, so we have now one, two, three, four spaces and a zero. One, two, three, four spaces and a zero. One, two, three, four spaces and a zero, and then a bunch more zeros. If we really wanted to be careful, we could write non-zeros into some of these memory locations to make sure this last zero was actually written. But at this point, I think we're pretty good. Yeah, Rahul? Is that summation font the correct summation? How do you get all that? How do you get all the values? No, bang just repeats the last command, starting with whatever prefix you follow it with. So yeah, so bang LC3S means whatever last command issued starting with LC3S, do it again. So I don't have to keep typing it, because I get tired of typing. My fingers get sore. All right, so good. So we're done with the first part. We have a second part to do, right? OK, so let's copy our register table. We don't need all of them anymore. We'll just change the registers, potentially. So we need a row and a column for each of the elements, right? We'll need the array pointer, too, now. So maybe we don't need the space. So let me make this an array pointer. Let's see, what else will we need? Any ideas? Any ideas? We need a screen pointer. We need an array pointer, a row and a column. We need something for the ASCII character. We put that here, the one that we're going to write into the screen. We'll probably need some other temporaries, but maybe we'll come back when we need them. Just to make sure everyone's following, let me switch briefly over here and say, OK, so here's our array, right? So basically, in order to parse this array, what we're going to need to do, I need to pull it down to where I can reach it, what we're going to need to do is walk through these three tuples one at a time, and look at the x position, the y position, use those to calculate a position in our fake screen we just created, and then put this character at that location. So how do I figure out the position given the x and y coordinates in memory? Yeah, but would I multiply the x and y coordinates? Maybe not, right? So let's take a look at this drawing over here. It has the disadvantage, again, of width and height being the same. But where does the second row start? How many memory locations down from the first? So if I look at the difference between a and d, how far ahead is d? Four, right? Or width plus one, right? What about if I go two rows down? Three times that. It would be twice that, right? What about three rows down? Three times that. So if I multiply the vertical position by what? Width plus one. And then I can add the column, right? So let me write that formula down. So if I say my y position times width plus one, plus my x position, and then I add that to my base, so my base is here, the address of the first character, which is just 4,000. So if I calculate this expression here, that will tell me where to put the character, right? And you understand why, given the pictures? Make sense? Yeah? OK. x is, remember, each of our tuples has an x position, a y position, and a character. So the x position, if it's 0, then that would be the first character, the first column. The second column would be 1, and so forth. So if you add that offset, you'll get the position within the column. We're going to assume that the tuples know how big our screen is, that they don't give us bad values. We won't check the values. Yeah. OK, so we'll have to calculate this expression then. And other than that, we just need to go through and look at each of the tuple values. OK, so let's see. So let's make a loop. We'll start. We'll start. It was r4. Oh, we've got to reset r4, right? Because we advanced it as we were writing. We used r4 to write our whole screen. So r4 is no longer equal to 4,000. So let's set it back to 4,000. And then we could add it in later, too. So we'll do a loop. When we're done, we'll come down here. We need to point to the array. So let's see. How do I get my first x out of the array? Where is it? Remember, they are x, y, and character. So if r1 points to my next array element of this 3-tuple, so x is offset 0 relative to r1. So if I go in LDR, so this will give me my column. And then I can do another LDR into r2, offset 1. So this will get my data out of one 3-tuple. The offset 0 is the x position. I'll put that in r3. Offset 1 is the y position. I'll put that in r2. Offset 2 is the ASCII character. I'll put that in r0. And then I'll add 3 to r1 to point to the next tuple for the next iteration of the loop. When is my loop done again? How do I know my loop is done? How do I know when I've reached the end of the array? Sorry? x is a negative number, right? So where should I branch right after I load x? And what branch condition should I have? Branch negative, right? So if I get a negative x position, I shouldn't load the other ones. Where should I go? First done, good. So in other words, if I see a negative x, then I just quit. And I just come down here, I'm out of my loop, I'm done. So if I don't see a negative x, then I will load the y and, I want to give myself more space, load the y in character. And now I need to calculate where that should go in my screen. So let's see, I have to multiply y by width plus 1, right? So maybe I'd better start using some temporaries now. So multiply y by width plus 1. Let's see. Let me put width into r5. And let me put a 0 in r6. And then add, oops. OK, what do you think of that? So what I did is I put a 0 in r6 for my sum. So I'm going to sum, hopefully, width plus 1 times. Or I'm sorry, sum y plus 1 times. So I'm going to put width into r5. Oh, I did that the wrong way, didn't I? No, I did it the right way. I did width plus 1, yeah. OK, so we have to go back to the picture of the, remember these are the tuples. So in memory, each tuple has, in the first memory location, the x position, then the y position, then the ASCII character. x position, y position, ASCII character. So r1 initially points to this one. And so plus 0 is that memory location. Plus 1 is that memory location. Plus 2 is that memory location. Then we add 3 so that next time through the loop, we'll point to these three. So they're just three tuples with x, y, and ASCII character. Yeah. Mm-hmm. AUDIENCE 2. So the x and y coordinates are inside the screen? Yes, yeah, we're not going to check. We will not check that the x and y coordinates are inside our screen. We just assume that they're OK. Which, if they're not, then we'll end up writing outside of our screen, and we won't see those characters, or something worse could happen. So it's not the best way to do it. But just not to have too much to write in the space of an hour. All right. So switch back over here. Hopefully, we can get this part written. All right. So what does this do? So it puts a 0 in r6. And then how many times do I go through this loop? Ask it that way. Width plus 1. And the easy way is, if you start with width 0, then of course, you'll come through this once, because you don't branch before. And then you'll add negative 1 to 0. You get negative 1. You'll stop. So if you have a width of 0, you'll get 1. If you have a width of 1, you add 1 to negative 1. You get 0. But 0 goes back again for a second. So you get width plus 1 times. So if I take width plus 1, adding r2 to r6, then I get width plus 1 times r2. But r2 was the y position, right? Yeah. No? AUDIENCE MEMBER 2 Yes. But given the relative size of your screen, does that mean that you can't do it in the next step? Yes, probably. Depends on the relative size of your screen. But generally speaking, the screen will be wider than it is tall. So yeah, that would be faster. Yeah, so you could do it either way. Your way would be fewer instructions. Good point. So now we have that. So let's add in a couple of other things. So that's in r6, right? So let's add in the x offset. So now I claim r6 points to the place where we should write our ASCII character, because we've included y times width plus 1. Then we added in the x offset. So that's our formula. But we needed the screen base, which we had in r4 up there. So if we add those three pieces together, we get the plus 1. And then we get the minus 1. And then we get the minus 1. And then we get the minus 1. And then we get the minus 1. And then we get the minus 1. And then we get the minus 1. And then we get the minus 1. And there we get the place where we want to put our ASCII character in memory. Our ASCII character is in r0. So how do I put ASCII character in r0 into the memory address of r6? Yeah, did I screw that up? OK. Let's see. X offset. Yep, there it is up there. In r3, not in r1. So good call. Add that in r3. Thank you. OK, everything else work? OK. So how do I get my character from r0 into memory address pointed to by r6? STR again, right? Good. So source register is what? r0? Remember, we put the character in up here. We didn't change it. So it's still there for us. r6 is the pointer. Offset is 0. Good. So I just put one character. Maybe I should go get the next one from the array. So how do I get up there? Branch. What conditions? All, right? Always. Where? That'll go get the next one. We only come down to parse done after we're all done with the loop, which is when we find the negative x position. So this should parse the array. Let's see. So we've got a few minutes left. Not sure if we'll be able to make a fake one, I think. OK, so no errors in the compilation. Oops. Can't type this way now. No, it's OK. I'll do it quickly. OK, so we'll put the letter a at 1, 1. And then maybe at 2, 3, or 2, 2, we'll put the letter b. That should be enough just to sanity check it. We put it at 2, 3. How big did I make x? There we go. OK. Yes, thank you. Sorry, I'm just trying to write one of these little arrays quickly. I'm sorry. Still minus 1? It's OK. Yeah, that's the terminator that gives us negative x position. OK, so let me read in my fake one. And then read in my at 1. And then I can look at 4,000. So where did I put the fake one? So 1, 1. So here's my first row. It has nothing in it. On the second row in position 1, I have the letter a. You can see the a over here maybe. And then my second row in the third position has a letter b. So that worked. Good. OK, so our code worked. All right, so the question is, can we dump all the strings quickly? So our strings are ready. All we need to do is do a loop. Let me get the register table. Keep those. We need a row. We don't actually need a column pointer. We need a screen pointer. And r0 is going to be our string pointer. And actually, we won't need the screen pointer. So let's start by putting screen and r0, and then width plus 1 in r1. And then we can do a putstrap. So we want row. So we want height in r2. So putstrap. Putstrap. What did I do? And I want to add height plus 1 to my string pointer so that I'm pointing to the next row. And then I want to add minus 1 to my loop counter and branch back. Does that look good? OK, sorry. I had to write that pretty quickly if we're going to finish on time. So put a screen pointer in r0. That's a pointer to the first string. Remember, the strings are spaced at width plus 1. So every width plus 1 space is in memory is the start of a new row string. So I'm going to put width plus 1 into r1. And then I'm going to keep adding it in to get to a pointer to the next string in r0. Puts is the trap that prints a string to the screen. Our strings already end with nulls. I'm going to do one row, one string for each of my rows. So I load height into r2, add negative 1 to it, branch until I've printed all the rows. So I think this should work. There's no line feed. Thank you. Good call. OK, so I better put a line feed. So after the put s, I had better, oh, shoot. OK, then I need r0 for a line feed, don't I? So let me put this in r3. And then, sorry, let me copy it over to r0 there for the put s. And then I can get a line feed. Thank you. OK, so print. Oh, no, thank you. OK, so that printed that screen. OK, so now let me, so now I can decode this thing Rahul sent me last night, except for one thing. I better make my screen bigger. OK, so let's change our screen back to something realistic. Ready? What? Oh, I put a tab or something. Ta-da. There you go. Happy holidays. Enjoy your break.\",\n",
       " \"It's midterm review. Everyone ready for the midterm? No. OK. Can we just go home now? All right. So what do you want to review? Oh my gosh. We'll start and go back. Moore versus Mealy. OK. Yeah. And Mohammed, you had your hand up first. Oh, it's up there already. Mm-hmm. LC3 data path. Yeah. So I'm trying to remember the exact boundary. So you need to know control signals. You need to know how fetch works. But you don't need to do things yet like translate RTL into control signals for LC3 data path. And what? Eric? I think the thing that's a problem is that it's not like managing a hard-try method and just when the ISA where you have the MAR and the MBR, your instruction method, just knowing how to increment those and change those based on the instruction. So instruction processing, basically. OK. One, how to make an FSM smaller. OK. So just basically FSM design or? We didn't talk about state minimization. But no. I mean, I did it once, but we didn't talk about it as a subject. When we did the lab machine, I reduced states. But that was not. It's something you can do, but we didn't formally cover it. So we're not going to worry too much about that. Yeah. I'm sorry? FSM design. OK. OK. Anything else not on there? Yeah. I'm sorry. I made a mistake. OK. OK. Yeah. Yeah, I'm sorry. I'm sorry, LC3 what? Operands? Operands. I'm sorry, I made a mistake. OK. You mean in the sense of the different addressing modes? Or? OK. OK. All right. Anyone else want to put something up here before we go down and vote? All right, so Moore versus Mealy, how many people want to see something? What's that about? 35 to 40? Memory and building larger memories from smaller memories? OK, that's more like 50 to 60. LC3 data path? They're all popular topics. I'm going to guesstimate 30-ish. Von Neumann? OK, probably about 25 to 30. Instruction processing? That's probably about 5 to 10. Finance state machine design? About 20 or so. Serialization and trade-offs? OK, maybe 10 to 15. LC3 operands? OK. One. No one else? OK. You can ask me in office hours. All right. OK, so what's a popular topic? So let's start with memories. There are a couple of examples in the notes if you haven't seen those already. So do take a look at those. But remember, a memory model, I don't remember which ones we use where. But generally speaking, there's data input. There's data output. There's some kind of chip select, sometimes inverted, sometimes not. There's some kind of write enable. Sometimes we might write read or write bar. Sometimes we might write write enable. I think the book actually just writes RW, and it just assumes you'll put one bit for one of them and one bit for the other. And then, of course, there's address. So remind me, so let's see. So 2 to the, let's give these names. So what's the size of the address space for this generic thing here? 2 to the n, right? So the address space is this part. And what is it? How many bits do we need for address? n bits. OK, good. So this over here will be n bits wide. So this thing implies n bit addresses, right? And what's the addressability? m, right? So m is the addressability. And so what does that m imply about our box over here? So what's the addressability of this? m. So does it affect chip select? Data in and data out, which are how many bits wide? m, good. OK, so this is our generic design. So this is a 2 to the n by n bit memory. And let's say you wanted to build something with, sorry, I'm going to zoom out a little bit to be able to fit something else. So let's say you wanted to build something twice as wide, wider addressability. So say 2 to the m bit. I'm sorry, 2 m bits. So you'd get, say, two chips. You could also do four chips. Maybe we'll just do four. So this will be 4 m wide. So if I want to build the same size address space, but four times as wide, how many of these chips will operate at one time? Four, or if the other possibility is what? If we're not doing anything, how many chips will be chip selected? Zero, right? So all zero or four. So how should I wire up the chip select? Same chip select, right? So let's see. Let me call this external CS. And so that would go to all of their chip selects. I can spell chip select. All of their chip selects. What about read and write? Write and able, we'll call it. It's all the same, right? So if I'm going to do a read, I'll read from all four. If I do a write, I'll write to all four. In all of the designs we've looked at, but if you look at some of the test problems, it doesn't necessarily have to be identical. So let's say I want to do a read and write. It doesn't have to be identical signal. Usually you wouldn't have some of them reading and some of them writing. That would be strange, right? OK. I'll just label these separately to keep the diagram from getting too messy. What about address? Yeah, I probably could just take the external address. I didn't make the address space any different. But if I just take the external address and put it in, that's fine. So external address to all four also. So it's pretty easy to do the wider one, right? What about data in, data out? Yeah, so I'm going to have four M bits coming in, right? So I can make each one M wide. Really, it's a total of four M. So I'm breaking these out of something much wider. And then each of those M groups can go into one chip. Does it matter which M I put into which chip? Yeah, as long as they come out the same way, it doesn't matter. You can do whatever you want. When you get into later classes, I think I mentioned this. There are some tricks you might want to play that will affect performance. But correctness-wise, it doesn't matter at all, right? So as long as the input and the output have the same pattern of splitting the bits up and bringing them back together, it's fine. I'll ask you something else when we look at the other way for address, too. So let's do the same gathering in our outputs, then. Normally, we'd have to label this somehow. The best way would just be to not gather them and put them side by side like this. So those are the data outs coming out of the bottom. I won't go add all the labels. So it's pretty straightforward to make wider addressability, right? What about more addresses? What if we want to do more addresses? Let's see. You want to do four? Is it four? Yeah, there we go. OK. How many chips are going to be active? So now I'm going to have four times as many addresses with the same addressability. How many chips will be active at once? One or zero, right? So how do I set chip select? Yeah, so I need a decoder, right? So there are four of these. So how big a decoder? How many bits in? Two, good. And where should those come from? Two address bits. OK, good. Yeah. So two address bits. So let's say these are m plus 1 and m. So now I still have m minus 1 down to 0, which is m bits, right? So those I could put into here and here and here and here. Sorry, I think I scrambled my order a little bit. And each of these is m bits wide. OK, oh, but what if I don't want to do anything? What if I don't want to do an operation? This decoder, as I've drawn it, is always going to output a 1. I should use enable? What should I use to drive enable? CS, OK. So external chip select is going to drive this decoder. Does it matter which of these outputs I hook to the chip? What if I cross my wires? Does it matter? Yeah, they're identical chips, right? So if I call the name of the chip, it gets associated with whatever the output of the decoder is. But if I just flip the chips, they're the same chips. It doesn't matter. So that's fine. What about write enable? Yeah, whatever the external one is, only one of these chips is going to be active. So it's the only one that will be looking at write enable externally. So we'll drive all four of the write enables from the same signal. That's OK. Let's see. So then we only have one data in of m bits. So where should it go? All four? Really? Oh, yeah, only one chip's going to be active. So if we're actually doing a write, whatever chip that is, we'll look at the data we put in. The other ones will ignore it. OK, so here's the tricky part. What about data out? Where's it come from? Do I need a MUX? So remember, when we talked about the data chip, we're going to assume these chips are going to be tri-state buffered on the outputs. So if the chip is not chip selected and I look at its outputs, what logic values do they have? Yeah, high z. It's not even bits. It's disconnected. So if I have only one chip out of the four, or even zero chips out of the four, connected to the same set of wires, a bus, basically, only one of those is active. Only one of those is going to put zeros and ones onto those output wires. So that's safe. As long as I only have one chip chip selected, which is always true because of my decoder, most one of them is chip selected, I can take these four and just wire them together, and it'll be safe. Sorry, it's hard to see this. And that'll be m bits of data out. So whichever chip I say I want to read from, whichever chip I say I want to read from will produce my output data on the same m wires. And that'll be fine. What happens if I scramble my wires? I mean, it's kind of complicated. Like if I was building this on a protoboard and I scrambled my wires, would it matter? Doesn't matter, right, as long as they're self-consistent. What if I, here's a different question, what if I put by accident address m plus 1 into one of these bits, would that matter? So well, so be careful. So if I use these two bits for my decoder and then I reuse one of the bits for one of the addresses, maybe on all four chips, does that matter? It does, right? So let me give you a concrete example. Let's make it easy. We'll say that there's only a one bit address going into the chip. So if I use, so I'll have three bits of address in total. If I use address 2 and 1 here and address 1 going into the chips, so if I've done it this way by accident, how many addresses can I access total? How many bits am I using? I get two there, right? But that's not an extra one now. So total number of bits is only two. So I can only access four addresses. So if I make that mistake, I'm going to miss half of my cells in my memory. So it's not going to let me access everything. Does it matter which ones I choose, as long as the other m are over here? So why did I pick the high two bits? I just like the high two bits. It really doesn't matter. Any two bits is fine. Any two bits is fine. You could pick the low two bits. It would work fine. So any two bits to run the decoder, but don't reuse those bits as the address for the chips. Yeah. Yeah. Yeah. No. If your chips don't have it, then you need it. Right? If your chips don't have the tri-state buffering, you would need it, yes. If the chips have it, it's just a waste, and it will slow things down. So it's extra gates, extra chips, and it will slow things down. So if your chips have it, you wouldn't do it. And? Why do you need the mux? You don't. And that was the question. Radvith was asking, do we want to put a mux just in case? And I said, no. If you know you have tri-state buffers, which is our design, you do not need the mux, and you shouldn't put it in. Does that answer your question? So you don't have tri-state buffers? Yes. So if you don't have tri-state buffers on the chips, then these chips are driving active 0s and 1s. In other words, they're connecting the output wires to VDD or to ground. So if you connect those two output wires together, you have a good chance of creating a short. So in order to avoid that, you would need a mux. Good question. Peter, sorry. No? Yeah. The tri-state buffers are inside these chips. So in our abstract model, all of the memory chips we give you will be tri-state buffered. Internally, yeah, it would be driven by chip select. And in fact, it would be driven. There's a diagram in my PowerPoint slides also in the notes. But it's driven by a combination of chip select and write enable. So you only get data output when you are reading and your chip selected. So that's an interesting question. So if I send chip select 0, are my outputs 0s and 1s, or are they high impedance? Yeah, so I don't need any more tri-state buffers. This design is already tri-state buffered by virtue of having all of the chips be tri-state buffered and having the chip selects all be 0 if I didn't select this bigger system. Yeah, a good question. Yeah. So you need to know what it is. And you need to know why it's useful. So yeah, so how to implement it? The only useful way, like there was a homework problem that just made you replicate the logic of the decoder. So that was not a useful way. The useful way is to use the fact that you've got bit lines and you've got select lines. And each of those can be driven by a separate decoder. So yeah. So if you have a label, you add them to some of the lists and that's one address. You're only going to send 5.5 0 higher. And then they have to connect to the bigger abstraction. So you have m plus 2 bits of address coming into the bigger system. So giving them new names is fine. So long as you still connect them to the address bits. Yeah. Yeah, that's the only way you can name 2 times m plus 2 address, 2 to the m plus 2 power address. Yeah, this is four times as many addresses using equal chips. OK. All right, should we move on then? OK. All right, so back to topics briefly. Sure. So more papers on SRAM cells? No. You mean things like SRAM cells? No. No. OK, so let's see. So this one we finished. Thinking more versus Mealy. So you don't really need to know much about more versus Mealy. And really, honestly, the names. So the only thing in our class, we always do these. So these are a limited version of more machines in which inputs do not affect outputs directly. In other words, state is a function. I'm sorry, output is a function of state only. And Mealy is the more general model in which outputs can depend directly on inputs. And this is the one that's always used in practice is the Mealy machine, but not with names. So this is a very simple example of a Mealy machine. But not with names. It's just that if you want a more machine, you simply don't make your outputs depend directly on your inputs. So if you've designed one and the timing doesn't work, you can throw down a flip flop. Yeah. Yes, the next state logic can always depend on the input. On the states. That's right. That's right. Yeah, so the constraint is on the more machine, the output is purely a function of the state, not also of the input. And so that's the extra constraint. It does mean the slight difference in the transition diagrams and the way we draw them, also next state tables. So this is how more looks. So because the outputs are only a function of the state, we can label the outputs in each state. There's no input dependence. So we don't need to know what the inputs are. We can just put the output bits here. And then the input arcs, we have to have one arc per bit combination of inputs. With Mealy, however, the outputs depend on the, or can depend on the inputs as well. So what we have to do is label them this way. So for every state, remember, if there are, say, three inputs, we have two to the three or eight different possible arcs. And each of those arcs will have a different combination of outputs, potentially, because the outputs can depend on the inputs. So in the Mealy design, the transition diagrams, you've got to move the outputs to the transition arcs. Is a synchronous counter an example? A synchronous counter can be either. That's an orthogonal decision. A synchronous counter just means that all of your flip-flops, so synchronous means they all share a common clock. And the counter means that it's mostly, it doesn't have inputs. It's just a loop of a circle of states. So the idea is that you can have a synchronous counter. And the synchronous counter is a function of the inputs, so you can still do these either way. I guess, technically, if we say strictly that a counter has no inputs, then they're the same. So if you do things like reset, you could have a reset that forced the output immediately into whatever state you'd be resetting the counter into, for example. And that would be a Mealy counter versus a Moore counter that waited until the rising clock edge before accepting that reset signal. But it's largely orthogonal, too. Anything else on this topic? All right, let's move on. I think maybe LC3 data path, wow. Let's see. It kind of looks like this. It's a big bus. All right, so LC3 data path. So there are a lot of control signals, but you don't need to know how to use them until the final. The things you need to know are this instruction processing, which no one wanted to hear about, 5 to 10 people. Who asked this question? Just clarify what you wanted to know. And everyone liked it, so anyone can chime in here. Remembering the modified data plan, I'm going to talk a little bit about that. OK. So all right, so first of all, there's the state machine. So the state machine looks roughly like this, and you need to know a tiny bit about it. So this is kind of what you need to know. Just a second, let me finish it. I'm going to zoom out a little. OK, so this is the rough structure of the state machine. So you've got three fetch states, and you should know the RTL for those. You've got a decode state, and I'll explain why that needs to be separate again in a second. And then you've got instruction execution. I've drawn three. Of course, there are 16, right, because we have four bit opcodes. So there's 16 different sequences, each of which is executing one of the different opcodes. So the way the LC3 works is first you do your fetch, and then we'll talk about what RTL goes into those boxes in a second. Then you do your decode. Then you do the instruction execution for whatever that opcode is. So you do need to know at this point roughly how these instructions are processed, what fetch does, what decode does on the LC3 data path. You don't need to know, well, which control signals does that mean? I showed you, but we're not going to ask you to write control signals until the final. I did say until, so you do need to know that eventually, but not tomorrow. Yeah, then? Yeah, so this one, the sheet I gave you is what you'll get, which has this with all the RTL filled in, so you will have that also. You probably want to remember the thing that I've told you 25 times in our class, which is PC gets incremented in the first stage, so when your instruction executes. As long as you remember that, you'll be good. But you should know what the RTL is here. You can always look it up in the diagram. If you lost that page, it's under Resources, LC3 handout or something like that on the wiki, so if you want to look it up. It's also attached to most of the sample exams, and it will be attached to your exam tomorrow night. So you'll have the LC3 encoding with all the fields and the RTL. You have this one. You'll have the data path picture. A lot of this, you won't need much this exam, but you'll have them. You'll need it more on the final. OK, let's just fill these in. So do you remember what's here RTL-wise? No, M-A-R. M-A-R. OK, so the other thing to remember about RTL is these things happen simultaneously. So whichever order I write them doesn't matter. On the right side is the current value of the PC in the cycle, and on the left side is what the values will be in the next cycle. So at the rising clock edge, M-A-R will have the value currently in the PC in this cycle. PC will get incremented by 1. So then whenever our instruction gets executed, the address in the PC will be the instruction address, whatever one we're executing, plus 1. So what's next? So then we read memory. So memory, remember, the way the von Neumann machine is designed, the memory only reads from the M-A-R. So we just tell the memory, well, go do a read. And we wait until the bits are then in the MDR. So that's the second stage. If you look at the diagram, we've talked a couple of times about memory having a ready signal. So that just stays there as long as memory is not ready. So once memory finishes getting the bits, we move on down to here. What happens there? Yeah, so we copy across the bus from MDR to I-R. And that's the point at which we can decode. This actually sets branch enable here, but we didn't even talk about that. It's not that important right now. So the reason we need a decode stage is because the decode is going to make use of the I-R. But remember, we can't make use of the I-R until the instruction bits are in the I-R. And the instruction bits are not in the I-R until the rising edge after that third state. So in the fourth state, the bits are there for us to look at and to branch off into these different sub-sequences for each of the instructions. But before that fourth stage, we don't have the I-R sitting in the, I'm sorry, we don't have the bits of the instruction in the I-R yet. So we can't branch until that fourth cycle. Read or written. Yeah, so for a write, you fill MDR and then fill M-A-R and say, go to a write. And then for read, you fill M-A-R and say, go to a read. And then you pull the bits out of MDR after the memory says they're there. OK, anything else? I was looking on Big Ben. I'm looking on the mirror now. No, you can't ask that in the review session. Sorry, I can answer afterwards. OK, anything else? Yeah, anything else? So whenever we have that table where it says, as we go along through this floating point, we're going to start with an I-R here. And then we start at that point, and then we're going to do a value. And then we do all of that separate stuff. So how do you do that? Yes, yeah, yeah. So yeah, so I won't go through and do a detailed example now. But there are some detailed examples. I won't go through and do a detailed example now, but there are some detailed examples in the PowerPoint notes and in the recorded lectures that will remind you of exactly what values the PCI-R, M-A-R, MDR take as you go through and fetch and execute instructions, including loads and stores. Yeah? So are the coordinates for M-A-R and I-R important? When you start executing an instruction, yes. After that point, for a load or store, you're going to change MDR. For a load or store, right? So are they always the same? No. And after you load or store, are then what happens? How many different I-Rs are we using? During execution, you may need to use MDR. So you asked whether I-R and MDR are always the same. No, they're not. Yeah, that's it. You mean in my slides? Oh, yeah, unfortunately, I'm not sure that I can remember exactly what it looks like in the discussion. Yeah, except that I don't know what the discussion sheet looks like. I looked at it briefly. And then, yeah, if you have it and can show it to me, then I'll explain it. But I mean, we tend to ask you things like the sequences so that you fill them in as they change, right? So you do need to be able to walk through this and understand when a particular register changes and then put them in order, that kind of stuff. But I don't remember how that discussion sheet was organized off the top of my head. No. I mean, T flip-flop is not terribly complicated, but it's outside the scope of the class. People don't really use it anyway. I know, I know, yeah. It was not supposed to. OK, anything else? OK. All right, so which one is that? OK, so von Neumann architecture. All right, so von Neumann, there are five pieces, right? What are they again? Memory, good. As you name them, I can draw them. Control unit. You've got to remember my Tolkien joke. I'm sorry? Input and output, good. And processing unit, right? OK, and then there are a couple of registers here and there, right? So what are the pieces? Let's say we'll start with the order. I put them in the same place as before I did, right? So what do we have associated with the memory again? MAR and MDR, right? So memory, remember, always going to have an address, and we're going to use a register to hold that address when we load or store stuff from the memory. And then MDR we'll use as a register to move the bits in and out since the memory is asynchronous with respect to the processor. Memory is not clocked, remember? In the processing unit, we also had a couple of things. What were they? ALU, right? So arithmetic logic unit is what that stands for. Whatever set of arithmetic logic shift, whatever operations we want to do, we have some function unit that can do them for us. So for the LC3, it's relatively simple. Generally, it could be any set we want to implement. What was the other thing in the processing unit? A register file. So these are actually registers that are synchronous with respect to the processor and substantially faster than the memory. And they allow us to manipulate values quickly by just having a few of them in the processing unit. So it tends to be small and much faster than memory. Input and output, those are just devices. We talked in detail about the LC3, but you don't need to know those details until 220. And then what's in the control unit? So we have a lot of memory. We don't need to know those details until 220. And then what's in the control unit? PC and IR. So program counter, which is what again? The address of the next instruction, right? And what's the IR? Instruction register. And what does it hold? The bits of the current instruction. Right. OK. Anyone want to ask anything else about that? Oh, it captured my pen. I don't know how I froze it. Hopefully I can figure out how to unfreeze it before we run out of time. Ta-da. OK. Anything else you want to know? Can you go to the contact list for people who have lost it? No, you don't need to memorize those. You can always just look them up if you need to use them. I mean, I don't think we hand you anything that has them, but you don't need to know them. So nothing else on von Neumann? OK. All right. Finite state machine design. That's just kind of general, huh? So let's see. Yeah. I mean, those are... Let's see. So I was trying to think of another one we could do quickly. Yeah, we can do a counter quickly. That's a good idea. Or a sequence recognizer. Why don't we do one of both? So just someone make up some bits. Say three bits. 110. Next. 010. Next. Next. OK. There's a counter. That was tough. All right. So then, I mean, seriously, what we would do is write... So those we'll call S2, S1, S0. And we could write those out like this. So 000, we could say, well, I don't care. 001, you didn't give me either, so I don't care. 010. 111. 011. Where's that going? XXX. It's a pretty easy counter so far. 110. I'll eat those words. We'll see. OK. OK. So we can draw K-maps. So let's see. So we've got XX1X. And then 1X01. All right. XXOR? X and OR, huh? Or we could do this. Oh, we need that one. Yeah. We have just this one here, right? We'll go right back. Does that look OK? Simple enough? It could be simpler. Maybe I wouldn't get full points on this problem. All right. So XX1X again. 1X10. That look right? Yeah, that one looks easy, huh? OK. So S1 plus is what is that? S1 bar? Yeah, good. So XX1X and 0X00 and this one. Is that right? Oh, sorry. No, this doesn't look right, does it? I think I screwed something up. This doesn't look right. I think I screwed up on top of the... I know, I just don't know where you're looking. Sorry. All right. So 0X00. Which ones do I care about? Oh, how did I screw this one up? Oh, shoot, I copied it wrong, didn't I? Why didn't you guys tell me? Which way did I copy it wrong? So I went that way. So S2 should be on the left. Thank you. OK. That's what you're saying, on the left of all the K-maps. OK. So then these are all wrong. So this one should be S0 bar. Is that right? That looks right. This one should be S2 bar. And this one should be S2 bar, S1 bar, S0. OK. Does that look better? OK, thank you. So three flip-flops, and this one will be S2 bar, and this one will be S0 bar, and this one will be S2 bar, S1 bar, S0. And I think that's it. So if you wanted to, you could then ask, well, what happens if it starts in one of these four unknown states, and then figure out whether we need to initialize it, or we can just dump it into some random state and expect it to fall into our cycle of four? Oh, no, you can always write it like this. Yeah. Yeah. Yeah, we're not, I don't think we're checking anymore whether you can draw. We used to, right? But let's say not anymore. I think it's OK. All right. Used to a long time ago. All right, so let's do a little sequence recognizer then. Someone pick a sequence. 1, 1, 1? OK. So how many bits do we need to recognize that? Three. OK, so we'll have a start state. So usually, sequence recognizers, we just start by drawing what we want to recognize, right? So start would output a 0. This would output a 0. This would output a 0. This thing would output a 1. And then we can fill in the other arcs. So one question, since that can overlap with itself, what does that mean? So if this were an input sequence, these three should output a 1 in that cycle. But if our input sequence is 1, 1, 1, 1, well, that's going to output a 1 here. But then the question is, what about this one? So if we say, well, it's OK to overlap, then that question mark should be a 1. So the input is the top, the output is the bottom, and they're lined up cycle by cycle. So it takes an extra cycle of delay in order to get the output with a Mohr machine. So the question is, should that question mark be a 0 or a 1? So that output did. If we allow the overlap, then it should be a 1. If we say, no, they need to be separate sequences of 1, 1, 1, then it should be a 0. If we say they have to be separate, we can only get 1, 1 every three cycles at most. Yeah. On that last day, the one output, what changes when it comes back to itself? Does it overlap? Is it going to do that for days after start? Yeah. So if you allow overlap, then you'd put this back to itself, because that would be a continuous sequence of 1's. And if you didn't allow overlap, you should be going up to that one, because that's the new 1 for the next sequence. Yeah. So anyone have a preference? You want overlap or no overlap? Did you have a question? Yeah. So let me draw this more carefully. So this is input. This is output. And so the recognition will always be in the cycle after the sequence. So you won't recognize it until the rising clock edge. You're able to change the output to say, well, yeah, I saw the sequence. And so in terms of cycles, if you count this one on the left as, say, cycle 1, it'll be in cycle 4, three cycles later, that you see the output is equal to 1, the sequence recognition. And remember, then, in a Moore machine, the output is independent of the input. So even though that question mark I just added may affect our state transition, it can't affect the fact that we saw the sequence. OK. So what did we want to do? Overlap or no overlap? Overlap. OK. So if we're going to allow overlap, let's see. We don't have a 0 arc here. Where should that go? To itself? How about a 0 arc here? Back to start. This one's relatively easy. What about a 0 arc here? All right. What about a 0 arc here? Back to start. What about a 1 arc here? OK. I think we're done. Can we finish? OK. There's our sequence recognizer. Yeah, you have to complete it. So remember when we talked about designing finite state machines, you have to make sure that every state has a 0 and a 1 arc. There's one bit of input. If you had two bits of input, you'd need to make sure it has all four arcs. All right. And you can give these names if you wanted to, or say, well, let's recognize one bit, two bits, three bits. All right. We have two minutes. So serialization and tradeoffs. So generally speaking, let's just do it quickly generally. The serial design, if you're talking about a big bit slice design, it can take lots of gates, right? So when you do the serial design, you do have to put a few flip-flops down, but those flip-flops will balance against a few bit slices. And so if you're doing a many bit slice design, the serial one will be smaller. It will take fewer gates. It will also be slower. So you're doing a slower design, but a smaller design. Why is it going to be slower? There are several reasons. But basically, you're doing one bit per clock cycle. And so instead of being limited by the gate delays in your system, you're limited by the clock cycle, and you're doing one bit per clock cycle. The serial design may not be the limiting factor in your system. So the clock cycle may even be longer than the single flip-flop plus one bit slice delay. So that adds up pretty quickly. Numbers-wise, it was something like an order of magnitude slower in the designs we looked at in class. Those are two extrema, right? So you can say, well, instead of having one bit slice for my serial design, let me do two or four or five or eight or whatever. And so you can operate in between those two. You can also optimize. So instead of doing a bit slice design, you can optimize across a couple of bits. So there's one example of that in the notes, where we did the comparator that we did in class. And then it's not something we're going to ask you to do. But if you're interested, I did a two-bit design for the comparator, where you can handle two bits at a time and optimize the logic for that, just so you can see how you get smaller logic when you look at the more general function and optimize it with kmaps. So those are some of the tradeoffs to think about. Yeah, so let me stop there. If you have any real burning questions, you can ask me now. But I'm going to turn off the mic. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.\",\n",
       " \"Okay, so let's go ahead and start. So today we're going to go through an example. We might get into a second example, but I think not. So we're going to try to go through this example of counting to 10. My code is there for you on the page. You also have this handout I gave you last time. Hopefully you brought it back today on your LC3 reference sheet. I meant to bring some of the extras back, but we have a faculty retreat all afternoon, so I was just upstairs and didn't have the chance to run over to my office. So let's just go ahead and get started. Then on Monday, we'll start another lengthy example of typing in a number. And then we're going to work towards looking at how we break problems down. And we'll keep working back down to LC3 code. So just do a few examples. This slide again, sorry, I know you're tired of it now, but I'm going to keep showing it until this day. All right, so what I want to do is look at the infrastructure we need with LC3 to be able to do something 10 times. All right, so you know how to do this in C from, I guess, seven or eight weeks ago, right? But to use the LC3 instructions, there are a bunch of ways we can do it. There are three ways on the sheet I gave you. One, just to show you the different addressing modes. One with PC relative addressing, one with indirect addressing, and one with base plus offset addressing. So just using the different loads and stores to do the same thing. So let's work through the middle one, the second one, which is the indirect addressing using LDI and STI. And then do the others on your own just to practice, make sure you understand things. For some of your labs, notably, it's the last two labs in the class, not next week, but the ones after that. They are sort of substantially more programming, and so you will have opportunity to make use of your programming skills. And students have found them relatively heavy in the past, so do try to spend some time on this and make sure you're understanding it. This is also arguably one of the more important parts of the class, right? To learn how to program, because then at 220, you'll have an entire semester of programming, right? So I told you on the first day, well, we tried to spread this out for you, so make sure you're getting the most out of it. And there will be a fair bit of coverage, a little bit on midterm three of just looking at LC3 instructions, but then also writing programs on the final. All right, so this is the part of the sheet that we're going to solve. So this is the second piece of three, and this is the code for the indirect address loop. So it's got the PC, we're going to start at 3,000 hex by convention. And I don't know why I put zeros there, sorry, that's C notation. You probably know LC3 notation, we usually leave off the initial zero. So this is the first part of the code we'll look at, and then the last part of the code we'll look at down here. And then down here we have some data that I've placed in memory, some other bits that are non-instructions. And then in the middle here, I've left out something, which is whatever that some section of code we want to do ten times. So that would be our loop body. Okay, so our loop initialization would be up at the top there, our loop test actually ends up being down at the bottom here. Our update is also down at the bottom, but you'll see all of this in detail as we decode these instructions. So I'm going to use the same data path image I used before for the most part. So I filled in the values, the data values that I told you about in memory. I've got the eight registers over here in the register file. Not much of memory will we use, just those two locations. I've got four microarchitectural registers down here, but actually we're going to ignore these three. So at this point I think you understand how we go through and do fetch, how we do execution with regard to loads and stores using MAR and MDR. But we're going to ignore those this time and just focus on the register file, the memory on the right, and the PC down here. So where should I go to get my first instruction? 3,000, right? So to answer that question, you should say, well, the next instruction's always in the PC, the address of that instruction. So look down on the PC and say, okay, I should go to 3,000. So we'll go to 3,000, so we'll look at our code page, and 3,000's up there at the top, right? So here's address 3,000, and here are the bits at address 3,000. So let's take these bits and figure out what that's supposed to do. So there's the bits. So what kind of instruction is that? LDI, right? So hopefully, how many of you don't have your sheets? Is there someone you can sit with and look? And if you have your book, it's in the back, the back cover. All right, so LDI, right? And that has two fields. So the first one is, what is it again? Destination, right? So when we do a load, remember, bits are going to come out of memory and go into a register. So this is which register we're going to put it in. What register is that? R3, good. And this is going to be kind of a human-friendly notation I'll write underneath. Turns out later, we're going to call this assembly code, okay? So it'll be sort of like RTL, but this will be what you write after we've put you through enough pain and punishment writing bits, and you get tired of bits. I mean, the computer only understands bits, right? But you really don't want to write too many of those. All right, so there's one other field in LDI, which is the nine bit whose complement offset. And so what is this one in hex? Yeah, so this is the leading bit for the nine, so we'll sign extend to zero, right, so that's zeros. And this one is 1001, so nine. And what's the last one? F, okay, good. All right, so this is the RTL then, so if you look that up on the sheet, remember LDI takes the PC, adds it to this thing, sign extend it to 16 bits, which is 009F in hex, goes to memory, reads that value, then goes to memory a second time, right? Okay, so that's the LDI instruction, so let's see how it works. So let's first write that into our sheet. So we've got, this instruction really means LDI R3 X9F, or you could write that in RTL if you'd rather, either one's fine for now. So then let's go execute it. So we'll go back to our data path picture, and we've got this, I'm sorry, not to the data path yet. We've got this RTL down here, so what is this first memory address? Yeah, so what is PC? So let's see, 3001, why is it 3001? So, okay, so in fetch, it got incremented, right? So when we fetch the instruction, we increment PC, so when we execute it, it's the address of the instruction, which is 3000 plus 1, right? So we've got 3001 in PC, so go back here. So 3001 hex plus 9F hex gives us this number, at least if I did my math correctly. So we'll go to that address, so go back to the data path, so where's the address? So 30A0, and we'll read that address, so this is the first memory read, and what we get out of it really is these bits, right? But for humans, we're gonna call that 4123, right? So we get 4123 back, and then we're gonna read, that'll be the inside memory reference, so that one gives us 4123 hex. So then we're gonna go read memory again, this time from 4123. So where's 4123? It's down there, and that gives us 0, right? So there's our instruction, the second memory reference returns all 0 bits, so we're gonna go to R3 and fill that up with 0 bits. So we go to R3 and overwrite whatever bits were there and put 000. Now of course, that's really 16 0 bits, right, but for human convenience, we're gonna write that this way to the side. Okay, one instruction done, so time for another one. Where do we go? Yeah, we're gonna fetch from what address? Good, yeah, so we just go down and look at the PC, right? LC3 doesn't do anything smart. Okay, where do I go? PC, that's where. Okay, so 3001, the next one on our sheet, so let's go look at it and decode these bits now. So we'll copy them here, and what is that? That's an add, okay, and the first field is destination, and which register is that? R4, okay, and what's the next field? Okay, one of our source registers, okay, and which register is that? R3, good, what's the next field? Yeah, so it's the one, the mode that tells us what the addressing mode for the last operand, right? So what does this one mean? Immediate, right? So then we have this 5 bit 2's complement number as an immediate value in the instruction, and that number is 1, right? Okay, so this again is our assembly language, which is nice for humans. So basically all you do with LC3 is you write the human form of each of the fields, and then you get the assembly language form. You can see there are commas in between, right? So eventually you'll get to write this nice friendly form, but right now you still have to write bits. So, all right, so R3 gets, I'm sorry, R4 gets R3 plus 1, right? That's what our instruction's supposed to do. So we can go back, write that into our, into our, our sheet. So we've decoded the instruction, so that's what the second instruction means. Now let's go ahead and execute that on our data path. So we say, well, let's take R3, add 1 to it, write it into R4. So go to the data path, look for what's in R3. So R3 is here, so that's 0. And we add 1 to that, and we get 1, right? So we're going to write 1 into R4. So, do you have a question, Kyle? You're just stretching, okay. All right, so we wrote 1 into R4, all right? So now, whatever used to be in R4 is gone. Hopefully there was nothing important, right? Same thing for R3. If we started with some important bits there, those are also gone. Now they have 0 and 1, right? And we're done with another instruction. So, where to? 3002, right? Whatever's in the PC, that's where we're going to go. Good. All right, so let's take a look. 3002 is up here. Here are the bits in that memory location. So, same exercise, right? Go get those bits and figure out what they mean. So, here's the bits. What's that opcode? STI, okay. And STI's first field is what? Source register. And what is that one? Okay, so that's R4, right? Okay, and what's the next one? The PC, the 9-bit 2's complement offset, right? And what's this number in hex? So, 09D, right? Okay. All right, so here's RTL for it. Again, this is a store instead of a load, but it's store immediate, I'm sorry, store indirect STI. So, it uses the same address formation as we did with the LDI. So, we're going to go to PC, add this constant sign extended to 16 bits. Going to go to memory and get an address, right? Go to memory, get 16 bits, say, well, 16 bits, that's an address. And then we're going to do the store of R4 at that address that we got back from this memory location we calculated by adding 9D to the PC. All right, so let's write that into our sheet, and then we'll go execute it. So, let's see. So, I guess the first step again is PC plus 9D, right? So, what's that address? What's the PC? Yeah, so good. You remember, we have to increment in fetch, right? So, when this STI executes, the PC will be 3003, right? Because it got incremented from 3002, which is the address of the STI during the fetch part of instruction processing, all right? So, we'll add that again. So, notice that when we add 3003 to this constant, this constant is a little bit different. So, we still end up with the address 30A0, right? That was of course delivered in the code. So, both of the, both the LDI and the STI go indirectly through 30A0. So, here again is 30A0, that hasn't changed, right? Nothing changed those bits. So, when we read that, we again get back 4123, okay? So, the LC3 then says, okay, well, the first read returned 4123. Now in my RTL, I'm going to write to address 4123, write the bits out of R4 into that memory location. So, we'll go look at our data path. So, R4 has the value 1. So, we're going to take that value and copy it over here to memory address 4123. Okay, and then we're done with that instruction. Time for another fetch. Where from? 3003, good. Okay, so where is that? Yeah, it's not there, right? The part we left out. Okay, so now, after the LC3 has done those three instructions, there's going to be some loop body that we didn't write down. We don't know what it does, but we're just going to assume that it does something important that we want to do 10 times. So, whatever it is we want to do, we would write into those instructions that I have left out. And then eventually, the LC3 will hopefully get down here to the end, and PC, let's say, is 3010 in hex. The current value of this is now 0001. This one hasn't changed, so I didn't edit it. But we're going to start executing this instruction, right? So, it's going to do some loop body for us, and we'll get to the end of the loop. And now, we're going to do our loop management code down here, for these last two instructions. All right, so I want to make another little table, just to keep track of what's going on here. So, we just executed the loop body. We just did it the first time, right? So, I'll say, well, that's loop body execution number one. So, what was R4 when that was executing? Go back for a second. Yeah, what was R4? It's one, right? Okay, so put that in the table. And there's this other thing that I'll fill in later. Okay, so R4 was one during the first loop body execution. Okay, so now, here's address 3010. So, we said that after the loop body, eventually the PC's going to get down to 3010, right? So, this will be the next instruction we look at. So, let's go decode it. What kind of instruction is it? It's another add. Okay, good. And destination register, R4. Source register, R4. Immediate or immediate? And what's the number there? Okay, so remember, if we want to negate two's complement, flip all the bits and add one, or we can also, let's see, this would be negative 16, and this would be six, so negative 10, right? You can do it either way, but, and you can do it on paper in practice too, it's fine. All right, so negative 10. So, in LC3 notation, the pound sign means decimal. So, when you're writing in the tools, if you see the pound sign, just means it's a decimal number, or if you write the pound sign, it'll be a decimal number. So, what that means is our RTL, take R4, subtract 10 from it, 10 decimal, and put it back in R4. So, that's the instruction. So, we can go do that in the data path. Well, first let's write our instruction into our sheet. So, we've decoded it, add R4, R4, number negative 10. So, go execute it. So, what is R4? Let's look it up. R4 is one, right? So, go back and subtract 10 from that, and we'll get minus nine, which we're gonna then write back to R4. Question? No, okay. All right, so we'll write minus nine, which I'll just put in decimal, right? I'll write the bits in in a second, but from our point of view, it's just easier to know, well, right now that's minus nine, and we just put minus nine into R4. And it's time for another instruction fetch. So, where from? PC, always PC. It's getting kind of dull. All right, so go look at address 3011 hex. That one is here. So, what are those bits? Let's go decode them. What kind of instruction is that? A branch. Okay, and what is that first grouping there? It's NZ and P, right? When we have a branch, we have to say, well, under what conditions do we wanna change the PC? All right, so remember, these are the NZ and P bits. So, this is saying, well, branch, if the last result was a negative number. So, if the last thing we wrote to the register file was negative, we're gonna change the PC. And what does this part tell us? The offset. So, this part tells us, well, where are we gonna change the PC if we wanna change it? So, there's a nine bit twos complement offset. Oh, sorry. Anyway, you could translate that. One EE, right? So, it's a negative number, okay? So, in other words, if we just sign extend it, that'll be adding FFEE, or it'll be like subtracting something from the PC because there's, you know, the carryout will get discarded, right? The 16 bit adder, the carryout bit will be thrown away, and it'll be effectively like subtracting something from the PC. We'll do that in a second. Yeah, so, no ops are used for various purposes, sometimes for delay, right? So, if you need to wait for a device, like if you look in the old Linux code, often before interacting with devices, they would delay. They're also used for alignment purposes. Some microarchitectures do better if you have instructions aligned to some bigger addressability. So, there are, I know there's a question. So, if you're in the habit of reading through exercises and else in the Pat and Patel book, there's a question about, well, what instructions do no op? And yes, branch is one of them, right? If you set these three to zero, as Rahul points out, then it does nothing. And so, you have an instruction that does nothing. Yeah, Daniel? Yes, effectively. So, what Daniel's asking is, well, how can we make that happen? Do we have to specify in binary? Yes, because if you put BR, as I mentioned two days ago, it will give you BRNZP instead. So, if you write in an assembly, you can't easily make it the no op without just specifying the bits. Yeah, awesome. That's right, that's right. So, this is what we call conditional branch instruction. So, the conditions happen when one of these three bits matches the last thing that was written to the register file. It would not match in this case, yeah. Or if it was a zero value, yeah. So, the only time we're gonna change the PC is when the last thing, which is the big N here, the one bit condition code. And I guess I could have taken this off at that point, but this was the one that was left. So, the full condition, which I wrote up a couple days ago, was little n times big N, and not times, plus little z times big Z, plus little p times big P. Nathan? Yes, you could do it that way too. Yeah, BR with a zero offset, it doesn't matter whether the branch is taken because that would add PC, that would reduce to PC gets PC. So, good point. Yeah, you can write a NOOP and assembly that way also. Without writing bits, yeah, good point. Okay, so let's see. So, let's go do this. So, first we'll write our instruction in. So, we found this was branch negative offset 1EE and hex. So, let's go execute that. So, what was last written to the register file at this point, do you remember? Negative nine, right? Our add wrote a negative nine to the register file, right? So, R4 got negative nine, that's negative, so we're gonna take the branch or not? Yes. So, let's write that in here. So, R4 at this branch instruction was negative nine. Okay, so I'm just building up this table. We'll come back to why we're doing it later, but just have this table. So, for the first loop body execution, R4 in the loop body was one, R4 at the branch was negative nine, okay. So, the branch is taken. What's the current value of PC? So, the branch, remember, was at 3011, right? So, remember, it'll get an incremented and fetched. So, the current value of PC when we execute the branch is 3012 in hex, right? So, what happens when I add 3012? Well, I guess I wrote it up earlier, sorry. So, if you add 3012 to FFEE, you should notice that one, two, and EE, when you add those up, you'll get a round number, right? And so, that'll percolate through, you'll get 3000 back. So, this is effectively negative 12 hex, right? So, we're gonna write 3000 to the PC. So, we'll make that change. Then what happens? Start again, right? Instruction fetch time. So, PC, LC3 will go to PC, okay. So, let's go to 3000 because that's what it says to do. LC3 just does whatever you tell it to do. So, go back up here, but we've seen that code, right? We know that code already. So, we don't have to go through and decode it or anything. We know what it's gonna do. So, let's look at that. So, here's the RTL for the first three instructions. So, I just copied it from our previous pages. Now, the value of the PC for each of those instructions, the instruction didn't move, right? It's in the same place. So, the PC value is always the instruction address plus one. So, when we calculated those addresses before and we found 30A0, that's not gonna be any different the next time we execute them, or if we execute them a third time, or a fourth time, or a hundredth time, right? So, we can simplify our RTL a little bit and just replace these PC plus values with 30A0, right? So, let me do that. So, now I've got going to memory at 30A0, memory at 30A0 instead of depending on the PC, it's a little simpler. But let's also assume that the bits at that address didn't change, right? Now, how could they have changed? Yeah, so, I mean, but we didn't do that store, right? Could they have changed somewhere? Yeah, the loop body, right? I didn't tell you what the loop body did, right? So, we're gonna assume that the loop body didn't do this. Okay, and I might ask you later, well, what if it did? Right, but we'll assume the loop body didn't change this address, right? So, if we assume it didn't change the address, well, then 30A0 still has 4123 hex, right? So, now I can simplify my RTL further and say, well, when you go to memory at 30A0, you're gonna get 4123 back, right? Just like we did before. So, let's do that. So, now we've got much simpler RTL, right? It says, okay, R3 gets the value at memory address 4123, and down here, I'll store R4 to it. So, now let's go execute these three. So, here's R3. So, first one, read memory at 4123, write it to R3. Here's memory at 4123. So, I'm gonna copy that over to R3. Now, R3 has a one in it, and then, okay, so that's change is done, so that's checked off. Then add one to R3, copy it into R4. So, here's R3. So, I'll add one to that and write a two into R4. And then, the last step is take R4 and write it back to memory at 4123. So, here's R4, it's a two, write it over there. Now, we have two in memory address 4123. And so, these three instructions together, they go to memory address 4123, add one to it and write it back. Yeah, Eric? How do you get back to the PC? Remember, when we execute a branch, we are going to add the current value of the PC, which was 3012, to the offset, sign extended, which is FFEE. So, if you add 3012 to FFEE, you'll find that you get 3000. So, it's like a minus 12. Yes, FFEE is equivalent to minus 12. Yeah, that's right. Okay, sure. Yeah, you can put pound negative 12. I'm sorry, then it'd be negative 18, sorry, yeah. Good question, we'll come back to that one. We executed all these, right? Okay, okay. Anything else before we go on? Okay, all right. Okay, so, we're going to do a little bit of a recap. Okay, so, let's see. So, we get down here, we'll assume I finished our loop body a second time now. So, we get down to 3010 hex with our PC. So, let's go fill in our table. So, we have the second loop body execution. What was R4? Two, right? Okay, so we'll fill that in now. And then I want to go back and do the bottom part, right? The subtracting 10 from R4, and then checking that to see how big it is, and maybe doing a branch again. So, these were the two instructions at the end. Subtract 10 from R4, write it back to itself, and then do the branch. So, the PC on the right, again, only depends on the instruction address, right? So, we can just replace that also here. That, again, is going to be 3012 hex. So, when we add it, it's always going to be 3000, right? This branch instruction is never going to go somewhere else. So, we can just replace that with 3000. And so, now let's go execute these two instructions. So, we've got R4 gets R4 minus 10. So, R4 is 2. So, when we subtract 10, what do we get? Negative 8, right? So, we'll go write negative 8. Okay, so that's the first step. Oops. Ah, so let's fill in the table. So, now we're at the branch. So, R4, you said was negative 8, right? We put that in there. And it's negative. So, this branch then, what's going to happen? It's going to change the PC, right? Good. And it changed the PC to 3000. So, that's the second execution of our loop. And we just branched up back to here again. So, let's go back and look at that table now. Okay, so we've gone through the loop two times. So, if you look here, R4, every time the loop body executes, R4 is the number of times we've executed the loop body. So, the first time it was 1. Second time it was 2. Third time it'll probably be 3, right? So, when does R4 at the branch get to 0? When this one is 10, right? Okay, which means what about the loop body execution? It's also 10. So, why did I ask you when this one gets to 0? Yeah, so when it's 0, it's not negative, right? So, when it's 0, this branch will not be taken. In other words, after the 10th time we've done the loop body, we get to the branch, we don't take the branch. We keep going. Okay. So, in other words, after the 10th loop body, it's not taken, and the PC remains at 3012. So, guess what the LC3 does? It does a fetch. Good, good. We're going to stop. Okay. That's what the LC3 would do, right? So, unless you tell it to halt, it would keep going, keep executing. All right. So, some questions for you. So, one of them, Mohammed asked. We'll get there. All right. So, why is there a 0 stored at 4123? What if I just put some bits there? Wouldn't that be just as good? I mean, what, 0s, 1s, they're all the same, right? They're all bits. Yeah. So, what would happen if I just put some other bits there? Almost. Not quite random. So, what would change about what I wanted? Yeah. Or fewer than 10 times, right? Yeah. So, basically, this 0, this is what we used to decide effectively whether we would keep going through a loop or not. It's like saying, well, I want to count to 10. Negative 4000, negative, we just, negative 399, you're not going to let me go, right? You're going to tell me to stop and that you understand. I mean, if I don't start in the right place, if I don't start at 1 when I count to 10, it takes me a heck of a lot longer and I don't count 10 times, right? So, if I don't put that 0 there, whatever I put there, it's going to start that count or iteration in our table. I'm going back here for a second. This 1 was the original value of 4, 1, 2, 3 plus 1, right? So, if you would put negative 3000 there, then instead of 1, you'd have negative 2999. And then this question I asked you, well, when do you get to 0? Well, that would still be 10, but then the relationship between this column and that column would have changed, right? So, you would execute the loop many, many more times. All right? So, another question for you. So, more specific, what if I put 5 at 4, 1, 2, 3 before I ran my code? How many times would it execute? Five, right? Because instead of counting starting from 1, we'd count it starting at 6. So, 5 off. All right. What about if I start at negative 5? Then 15, right? What about 25? Okay. So, this one's tricky. So, can it ever execute less than once the way we wrote this code? It can't, right? It never checks before it executes. So, it's got to execute at least once. So, it gets down to the bottom, and you've taken 25 and added 1 to it. You get 26, you subtract 10, you get 16. Is that negative? So, you're done. So, how many times? One. All right. Good. All right. More questions. So, what if we leave that one? I guess I kind of asked already, right? Okay. Yeah. That's a compiler decision, and it's actually, you can write C code that does it either way. Yeah. I didn't teach you both variants, because you don't need so much C. Yeah. Okay. So, what happens if we change the value at 30A0 to, say, 3141? Because this is, I like this number, because it's sort of part of pi, right? 3141. So, then that'll be a better program, right? What'll happen? Yeah, it'll address a different memory if it's load and store indirect. What's up with that memory? Bits. Bits. So, it'll run some random number of times, and then it'll stop, right? We have no idea how many times, because we don't know what's there. We didn't say anything about what's there, except, well, you add some bits. Good. So, what happens if the loop body sets R4 to zero? I think this is what you asked me, so you can answer. So, your loop body, you know, somehow someone else writes that, and in the middle of the loop body, they set R4 to zero. So, what's going to happen? Yeah. So, you take, I mean, at the end, R4 has zero. Subtract 10 from zero, you get minus 10. And that's negative, right? Yeah, so it'll go forever, right? So, just keep going and going and going. What's in 4, 1, 2, 3 doesn't matter anymore. It'll keep getting incremented, but in the middle of the loop body, we set it to zero, and so you subtract 10 from zero. No matter how many times you do it, you still get negative 10, right? Yeah, that's an unfortunate thing since I wrote it, isn't it? It unfortunately sets them all to zero, and I sort of regretted that in retrospect. I should have set them to random bits, but that might have been more confusing to people. Yeah, so the simulator, this was the question. What is memory set to in the simulator initially? And it's all zeros. Real operating systems do that also for security reasons, right? So, if you run a program, and then I can come look at your program, and your program has your password stored, then it's a bad thing. And so, an operating system, typically, before it runs your program, will zero all the memory it gives you. So, it's not unrealistic. It's just that it does then sometimes confuse people when they're just learning that they see memory always starts at zeros, which isn't necessarily true. Okay. All right. So, there's a reference copy of the code, data down here. And that's it for that one. Yeah, okay. Yeah, I mean, that's, sure, there are insecure OSs, yes. Yeah, so, deallocation is not sufficient, right? So, I mean, you would have to zero things. I mean, it goes, there's a step further, right, which is, you know, when you take your hard drive and you want to get rid of it, it's actually possible, even if you reformat your drive, it's possible, unless you spend a fair bit of time writing random bits on it and deleting them and writing them again, that someone who really cares can come in and read the bits you have there. So, there are lots of security issues like that. But most modern operating systems will, before they give you memory, they will set it all to zeros. So, yeah. Yeah, so, in the LC3 ISA, the real use that's, the most useful thing I've found with those is that there's some I0 registers up in high memory and they're always in the same places. And so, rather than putting those, they're not reachable as PC relative numbers, so they tend to be addresses like FE00. And so, you need to either put them in a register and do an LDR or you can do an LDI directly, right? If you have the number close to you, you can do an LDI. So, it has that value. In terms of practical value as a real ISA or something, they're not quite right. I mean, there are real ISAs that have things like that that are a little bit different. And the little bit of difference makes them much more useful from an idea of like generating code from high-level languages like C. So, they're a little bit strange in that sense. And if you know other assemblies, you might think, well, why did they do it this way? The primary reason, as I mentioned when I introduced them, was that the authors of the textbook wanted to emphasize that if I go to memory and I get 16 bits, that can be a memory address, which is an important lesson because you can. So, they wanted to make sure that everyone realizes 16 bits, it can be a memory address, it can be a two's complement number, it can be an unsigned number, it can be anything you want. And it's up to you, the programmer, to say, well, how should the computer interpret those bits? Did you have a question, Nathan? Okay, Eric? You mean this thing? We did it 10 times. But we do it one time and then we check. So, this is basically equivalent to the for loop. So, we're initializing and then we've initialized by hand down here. So, the initialization is not actually present in our code. The initialization would be to say write a zero here. And then we can leave it as bits but have our code do that writing. Up here, what we're doing is the increment. So, we've actually done the increment of our variable and then we're executing the loop body and then we're checking, sorry, the loop body, and then we're checking whether we've gotten to 10. So, these are pieces of the for loop, if you will. But I mean, like, that's something that a lot of people have tried. That's not the STI. Oh, no, no, no. There's some other code that I have omitted here, right? I've done the adding. That does whatever we want to do 10 times. It doesn't matter. I thought that was the STI or you want to do 10 more times. Oh, no, no, no, no. Oh, sorry. Yeah. The loop body is any code that we want to execute 10 times. So, it doesn't matter what code we write there. It's just this is how we would create a loop to do something 10 times. Yeah. Yeah, yeah. It's the loop part. The loop body I left out. It could be anything. It's the instruction. So, let's see. How many did I... So, that would be 16 minus 3. So, there are 13 instructions that can do anything. But you have to be careful not to write R4. And you have to be careful not to write to 30A0 or 4123. Yeah. So, you can do any loop body you want, basically. As long as you can fit it in 13 instructions. Yeah. Yes. So, in assembly, you can specify any of the operands can be written in decimal or in hex or as labels, which we haven't introduced. But we'll talk about that when we do assembly. Yeah. Can you refer to the PC with decimal values? That part, not quite. Yeah, that part, not quite. So, like the... Well, maybe you can. Now, I take it back. You can. So, the only time you would use that would be... The only time explicitly there's... When you specify where your program starts, if you want, you can say 12288 decimal. But I'm not sure what the value at is, I guess. So, you can use decimal numbers more or less throughout your program if you want to. The tools you're going to use first will be binary. And you have to write everything in bits. Actually, there is a version you can write in hex, too. But I wouldn't suggest doing that. I would write it all in bits. Yeah, so if you wanted, for example, to terminate your loop, you could set R4 to a value that would force it to stop at the end. Yeah, so that's true. It's not necessarily a bug if you're writing that code. That's a complicated answer. I guess I would never write that code that way. But some companies have insisted that all of their employees write code that way. So, it's hard to say no. But I wouldn't advise it. Go back to the first... Yeah, you can make loops within loops. I mean, if you wanted this one to execute again, you would have to reset 4, 1, 2, 3 to 0 if you wanted to execute 10 times. But that was what I was saying. I left off that initialization from this loop. I did it by hand. But yes, you could do that. Okay. Yeah, Rahul? Sorry. I mean, there are only five or six, and they're all on page 543. You won't need any more for a class. The code's in the LC3OS, too, if you want to look at it. Yeah, yeah, you don't have to do this through memory. Part of what I wanted to illustrate with these examples was the use of the load and store instructions. So, yes, you could simply use another register. In fact, you could simply... You don't even need to use R5. You could simply keep it in R4. And you could write the difference to R5 so as not to change R4 when you did the calculation of whether you got to 10. Yeah, yeah. So there are many ways to do this kind of loop structure. And that was also part of what I wanted to illustrate is you have many options when you're writing LC3 code to do the same sort of thing. And any of them is fine. Okay. Yeah. Yeah. So, okay, so that's a tricky question. Is there a better way to write the load? So if you mean, couldn't we have an ISA that didn't have so many PC relative instructions? That would make your life much easier. As you'll see in our next example, we're going to end up spending a fair bit of time doing counting, right, because you have to count, you know, how many instructions do I need? Like this one, right? I didn't make you count this time. But basically, in order to figure out what this offset should be, I could subtract, right? I could take, I could say, okay, well, PC will be 3012, and I want to go to 3000, so I need negative 12, right? I can subtract, but I'll make you count in class. And the problem is, if you change the size of this, of this loop body, then you change the offsets, right? Any offsets that cross-code you've changed, you're going to have to recalculate them and put them back in bits again, which is a giant pain. And so by the time we get done with a couple examples, you'll be ready to have an assembler that will do that for you. And the assembler will make that easier, substantially easier, meaning you don't have to do it anymore. A computer will do it for you. As to whether it's better to have load and store instructions that are PC relative or absolute, there are advantages to both. I mean, if your load and store instructions are PC relative, that means I can take that code and I can put it anywhere in my memory and it'll keep working. Whereas if I have absolute addresses in my instructions, that's not true. I have to rewrite my code to be able to put it in a different set of memory locations. Does that make sense? So if I had, for example, you know, branch to 3000 here, and if 3000 were encoded as an immediate value in my instruction, as is the case in some instruction set architectures, then in order to take these same instructions and do the same kind of thing elsewhere, I would have to change that branch instruction to make it work. But the way it's written here in LC3, that's not the case. I can take exactly these same instructions, put them, shift them to another location, and they'll still work. Yeah. Honestly, the best thing to do is to make the computer work for you, which is an important lesson in our class. So as you're writing, it's a little bit of a pain, the binary part, and we won't ask you to write that much in terms of binary code, probably like 20 instructions or so. And the reason is it just gets painful. But sanity check yourself by taking your code, pushing it through the tool, and looking at it in the simulator. It will tell you the address, right? And you can say, oh, I got it wrong or I got it right. So you can double check it. If you don't double check it, you just expect it to work and run it, then good luck. But I would use that to check it myself rather than trying to just stare at it. It's a lot easier. So when you use the LC3 tools, you are doing cross-architecture compilation, right? So what Raul is asking about is, well, when we compile, when we use the LC3 tools, we're running on an x86 machine, right? We're not actually running on LC3, right? So the code that we're using to assemble code or to change bits in a file as ASCII zeros and ones into actual encoded instructions for a simulator or for a real LC3 processor, if you build one, that's not actually running on an LC3, right? So that's called cross-compilation or cross-generation of code. That's pretty common for microcontrollers and small ISAs. If you get an 8 or 16-bit microcontroller, you're not going to compile code for it on that controller. You'll compile it on your desktop, your laptop, your phone, and then download the code as bits to that microprocessor. So there's not anything particularly mysterious about it, just that the code in the back end, the tools, generate instructions for a different machine, for a different ISA. And then you put those bits in a file and ship them to the machine that should be executing them. How do you write the – Yeah, the compiler actually only generates assembly and then you have an assembler. So – No, it doesn't – no, it doesn't go through a translation process. Yeah, let's take this one offline because – All right, any other questions on the example or – Okay, so maybe we're not going to get far into the typing a number example. So I'll put that one up online if you want to look in advance. The code is actually already there on the webpage, so have a good weekend. Thank you Professor. Sure. Mind if I ask you that question? No, it's fine. So – Okay. Okay. Okay. Okay. Okay. Okay. Okay. You you you you you you\",\n",
       " \"and didn't get around to it. Or maybe I'm dressed as a professor or something like that. So we're going to finish up instruction formats and then start talking about instruction processing, so how the LC3 actually executes instructions, processes them one by one. I'll walk through a detailed example of instruction execution. I realize I turned my mic way up. And then we will, I think probably on Wednesday, go through the entire ISA and look at most of the instructions. Most meaning I'll leave a couple for 220, but for the most part, we'll look at the instructions you'll need in our class. So I wanted to put this up briefly again, and then I'll turn the volume down a little bit since it's not so much feedback. So yeah, again, please do think about nominating your TA for the Olson Award. It's a nice thing. These are for 225, so unless you're really into getting ahead. All right, so last time we saw that in order to simplify logic, we can actually break representations such as instruction encodings into fields. So we looked at that. We looked at a couple instructions, and we saw that there's an opcode, which tells us, well, what is this instruction supposed to do? What kind of instruction is it? And then the other fields will actually specify the operands for that particular opcode. So we looked at a few LC3 instructions. Sorry, I didn't remove the animation from these, I see now, one, two. One of those was LDR. So LDR then had three operands, a destination register, a base register, and a six-bit offset. And we saw that, OK, here's how that particular instruction works in RTL. We'll go through all of these in detail again. So primarily, what I want you to see here is this structure in the instruction encoding. So you've got the opcode, which is always the four high bits in LC3. And then you have the rest of the bits, the other 12, broken up into fields. So there's no overlap here. You don't have to do any complicated math or anything. There are three-bit register fields. There are multi-bit, two's complement numbers. For the add instruction, similarly, we looked at one variant of it. You'll see another one later. And this variant had three registers. So you take source register one, add it to source register two, and write the sum back into the destination register. Again, in fields, four-bit opcode, and then three three-bit register fields. We had some left over. And so we set those all to zero. Rather, Pat and Patel set those all to zero. There was one more I wanted to show you before we started talking about how the LC3 processes these instructions. So this is the STR instruction. So if you look at this opcode, you go look it up in the table. I don't expect you to memorize opcodes, but we'll give you a table for that. If you learn it a little, then you might go faster translating code and things like that. So it might be worthwhile. But I would recommend just getting it by practice, not bothering to try to memorize them or anything like that. So it has a source register. So this is a store. So this will have actually the same fields as the LDR instruction, except that the direction will now be from a register. Take some bits from a register and put those into memory. So remember, the LDR was take some bits from memory, copy them into an instruction. So in this case, you can see the address generation is the same. So we take this base register. We read 16 bits out of it. It's zero to seven. So any of the registers in the register file, read those 16 bits out. Take these six bits from the instruction, sign extend them out to 16 bits. This is a six-bit two's complement number. So we just copy this signed bit 10 more times. Add those two together, and then go to that memory location and store the bits in the source register named by these three bits of the instruction into that memory location. So that's an STR instruction. And then in words, of course, that's much longer than the RTL. It's one reason we like to write RTL. So that's what it does. So I wanted to go over briefly, well, what is it you need to know about this stuff? So one thing is what we saw at the end of the week last week, which is, well, why do we do it this way? Why do we break things up into bits? You'll see there's already a question on the homework that kind of gets at that in an upcoming homework. I guess maybe, I'm not sure if it's the one that's out now or the one that's coming next week. But you'll get a question about this kind of on a homework at some point. Know the terminology, so things like opcode and fields of instructions. And eventually, in the next today and Wednesday, I'll show you how the different kinds of operations work. And you should have some idea of how they work and the kinds of things you can do with instructions, because you will start to have to program in a class at the end of the class in the last few labs. And so you need to know what you're targeting when you're breaking down the tasks down to the instruction level. So the better you understand, well, what can a computer actually do in an instruction, the easier that process will be. And then finally, how those operations can be executed on the data path. So I'll show you that as we go through. So we're not even going to look at return from interrupt. We won't look at interrupts in our class. But if the question is, do you know how to take a finite state machine state in the LC3 and map that to control signals, yeah, for the data path in the book. That is one of the things we'd like you to be able to do. You've already seen that on the previous example in terms of a very simple data path with six control signals and a finite state machine. The LC3 is a bit more complicated. There are a couple of examples you can look ahead to in section 401. Eric, come back in a second. AUDIENCE 5 OK. So I hear two questions. One was, do you need to know where the fields are for each of the opcodes? No, but you need to be able to read the table, which means you need to be able to translate all the things in the table. So if we give you instructions, you need to know how they work. You don't need to memorize that. Then the first question was, well, why are they designed in LC3 the way they're designed? No, we're not going to go much into that, other than to say that they're split into fields to make the logic much simpler. So when you look at the data path, you'll probably notice that things are pretty simple. There isn't much extra logic, aside from a few muxes, sign extension, things like that, because they took the time to do a very careful job designing the ISA with that goal in mind. If you're interested in more general ISA design trade-offs, you can read section 4.3 of the notes, which is a starred section. But it'll talk about instructions that architect your design, but beyond our class. Kyle? So what is the requirement of the class instance? So that's just for this. This is one field for STR and LDR. And it's an offset, because it's being added to the value in this base register. So your memory address is taken by adding these two numbers together. So this is an offset relative to the value stored in the base register. Does that make sense? Yeah, the particular fields will be on a per-opcode basis. Each opcode will have a different set of fields for its operands. Mohamed? Yeah. The source register are the bits being stored to the memory address. So the base register and the offset are used to create the address, to calculate an address. And that address in memory is where we're storing the bits of SR. You're talking about add immediate? We haven't even gotten there yet. Let me come back there. Let me get there first. OK, so all right. So what don't you need to know? We don't care if you learn the LC3 encoding, as long as you can use it. So don't bother trying to memorize it or anything like that. In particular, if you want to know what we'll give you on the exam, under the Wiki, under Resources, LC3 handout, there's, I think, four pages that will attach both to midterm 3 and to the final exam. So you won't need all of it on midterm 3, but it'll all be there if you really want to look at it. It has things like the LC3 instruction encoding with RTL for every instruction. It has the LC3 finite state machine state diagram. It has explanations of the control signals. So that handout will be attached to both of the exams. OK, so let's then think about, well, how does the LC3 actually process these instructions? So you've seen some examples. The LC3 is going to execute those instructions using the data path, but the data path can only do so much. So for example, think about the memory. The memory, the way we designed it, you can either read. Actually, it takes more than a cycle. It says a cycle on the slide. But you can read or you can write. You can't do both. You can't do two. You can't say, hey, I want to do two reads or four reads. And it might take many cycles just for one. In Pat Patel's design, there was an R signal. And until the memory says it's ready for something else, you can't go ahead and do something else. But to do an instruction, well, the instructions are sitting in memory. So how do we know what the instruction is until we do a read? So to get the instruction, I read it from memory. But then what if it's a load? We have to read again. So what should we do? Don't panic. There's nothing new. So all we're doing is breaking things down. So the first day of class, I said, how do you make a peanut butter sandwich? And you helped me break things down step by step to try to help me keep less hungry. When we designed the keyless entry system, if you want to open all the doors in your car, you have to push the button twice. You push it once, your driver's door unlocks. You push it again for the other doors. So we just need to break instruction processing down into steps. And each step then has to execute on the data path that the LC3 has. So we have to simplify to the point that our states, our finite state machine states, can execute on the LC3 data path. So what kind of things do we need to do? So first thing is, well, we need to get the instruction. Computer's just going to execute instructions. Instructions are sitting in memory. Computer doesn't know, oh, that instruction does such and such until it actually goes to get the bits. So it has to fetch the instruction out of memory. Then it has to take a look at it, meaning there's going to be some finite state machine state that looks at the bits of the opcode. So it's, well, what are they? Is it an add? Is it a store? Is it a load? What is it? So that's called decode. Those always have to happen. So those two, every instruction, go get the instruction, look at it to see what it is. It has to happen. Otherwise, you don't even know what it is. For some instructions, then we need to evaluate an address. If you're going to do a load or a store, well, load or store to what memory address? So there might be some computation, as there was in LDR and SDR, to add things together, whatever, calculate the address for memory access. Fetch operands from the register file. If you're going to do an add, well, you need to take the bits out of two registers so you can put them in the ALU to add them. So fetching operands, another kind of thing we need to do. Execute. So when we do an add, we have to use the ALU to add things together. So we've got to do execution. And then storing the result back to the register file or back to memory. Once we get bits out of the memory, want to put it in a register, or we do a sum, we need to put it back in a register. So these are the kinds of things we need to do with instruction processing. Not every instruction needs all of them. So sometimes we'll do some of them, sometimes we won't. We'll always do fetch, and we'll always do decode. The rest of this stuff is just sort of general categories to help you think about the kinds of things you need to do when processing instructions. So don't worry too much about them. The book will mention them. The book will give you definitions. The definitions there are a little fuzzy too. What matters is you understand you have to take the LC3 instruction, the RTL for that, and break that down into steps that are simple enough to execute on the data path. And you'll always have fetch, and you'll always have decode, and then you'll have some more steps. As you'll see, it'll be one to five more steps for each of the instructions in LC3. So let's focus on these two parts that we need to do all the time, fetch and decode. So we'll start with fetch. So here's our data path. Hopefully, this is visible. I thought about giving you a handout. Can people read this in the back? We're getting a little fuzzy. If you've got your LC3, your patent to tell book, it's just taken from that, from figure C3 in the back. So where are the bits of the instruction before I go get them? They're in memory, right? So they're down here in memory. Good. And where do we want them to be? Well, remember, there's a special register as part of the control unit in the von Neumann model that's supposed to hold the instruction bits. Register file is part of processing unit. So control unit's over here. Yeah, instruction register. So in order to execute the instruction, we want to copy the bits out of memory into the instruction register. Then the finite state machine here can look at those instruction bits and do whatever it says. So we need to somehow get these bits out of memory over to the IR. So how are we going to do that? So the last step then is somehow copying bits into the IR. You can see that it copies off the bus. So memory, though, can't write to the bus directly, right? Memory's down here. And it can go to the MDR. OK, so maybe that's what we need to do. Memory can write into the MDR. And then that memory from the MDR, those bits can go over to the IR. And so those will be our last steps. So let's put those in context. So the last step is take MDR, copy it across the bus into IR. And then whatever we do right before this step, we're going to have to fill MDR. So in other words, we'll do a read operation. But when we do a read, whenever we do a read, remember there's also this MAR, memory address register. Whenever we read from the memory, memory reads from the MAR. So that'll copy memory at MAR into MDR. So here's our last two steps. We don't know how many states the whole fetch will take right now. So I called it state n. Copy memory at MAR into MDR. And then the last one, copy from MDR across the bus into IR. So how do we set MAR? Let's go back and take a look at the data path. So where is the next instruction? In other words, what's the address of the next instruction? In the program counter, right? Good. So it's up here in the program counter. So I need somehow to copy PC down to MAR. So how can I do that? Yeah, I just copy it. See, there's this gate PC here. So I'll just turn on the gate PC. PC will be copied onto these 16 wires. They'll go everywhere around this thick black line, the bus. And then in MAR, you can see that it loads from the bus. So I'll just turn on LDMAR. And that will give me PC copied into the MAR. So in the same cycle then, sorry, hopefully that was clear. So we'll set gate PC and we'll set load MAR as part of our control signals. In the same cycle then, I want to set PC to PC plus 1. Then we'll be ready for the next instruction. So the PC, after the first fetch cycle, will point to the instruction, the new next instruction. So instructions, we're going to execute just in order in memory. So we'll be at some address, say 5,000 hex, and then we'll go to 5,001, and 5,002, and so forth. So in the fetch, we're just going to, in the first cycle, copy PC into MAR, but we're also going to copy PC plus 1 back into PC. And notice this doesn't use the bus. The wires are all in this circle. And that's important because the PC is carrying, I'm sorry, the bus is carrying the PC. So the bus can't also carry PC plus 1. It's a different number. So here's our full fetch sequence. So we have three states. First one, we do two things. Remember, these are parallel. So MAR gets PC, and PC gets PC plus 1. Second state, memory accesses, does a read. So memory at MAR, the bits come out. They get put in the MDR. And in the third state, we copy the bits from MDR over to IR. So there's something I want you to notice here, which is if I execute an address, I'm sorry, if I execute a PC, an instruction at some address, what's the value of PC when the instruction executes after the fetch? PC no longer points to the instruction that we're executing. PC now points to the address of the next instruction. So it's the address of the current instruction plus 1. That'll be important because in LC3, we have a lot of instructions that make use of the value of the PC. So you need to remember that it's not the address of the current instruction. It's that address plus 1 in all cases. No, it is always true. It doesn't use PC. Whenever you use PC, PC is the address of the current instruction plus 1. Sasha? Yeah. Are you using 5, 2, or something else? That's this one up here, yeah. Yeah. That you turned off, that you have? No, this is all happening in one clock cycle. So this is a clock synchronous sequential circuit. So you can see there's a separate set of wires that come over here from the PC. And then they go through this plus 1, which is just some logic to add 1 to a 2's complement number or an unsigned number, either one. That then comes to this MUX. And we're going to select this input. And then we're going to set load PC. So on the rising edge of the clock, PC will become PC plus 1. On the same rising edge, MAR will copy the old value of PC off the bus. So it's just two separate registers that load new values in the same clock cycle. No, because remember that if the rising edge comes, these things happen simultaneously on the rising edge. It's just two separate registers. So it's no different. I mean, it's a good question. But there's no difference from our previous data path where we had multiple registers being loaded at the same time. And this is an important difference between hardware and software. So whenever you see RTL, these things will happen simultaneously if they're put in the same clock cycle. And so all the right sides have the old values. And all the left sides will be the new values. Anything else on this one? OK, so let's go forward and see how these three states can be accomplished. So we'll look at them in a little more detail. So here's the first state of fetch. So PC MUX is set to take this PC plus 1 input. So this is what I was just describing. So we'll go through it in a little more detail. Load PC is set to copy the output of the MUX, which is PC plus 1, back into PC. Gate PC is turned on to put PC back into PC. Turned on to put PC out on the bus. Now, that'll be the old value, not the new value. And then LDMAR is also set so that the value put onto the bus by gate PC, which is the old value of the PC, is copied into the MAR. So again, both of these changes to the registers happen on the rising clock edge. These are just normal flip-flop based registers. So when the rising clock edge comes, MAR will have now a copy of the old value of PC. And PC will now store PC plus 1, the old value of PC plus 1. Yeah. So why do you need to read the bus? Does the PC kind of start the whole read process in the memory that it gets? Because the MAR and the PC are on the bus. So you need to tell the memory what address to read from. And that address is stored in the PC. So the memory only looks at MAR when it does a read. So in order to get it to read from the address stored in PC, you have to copy the bits out of PC into MAR. Make sense? OK. Sure. Mohamed? Can you explain the second state of fetch? Yes. So in the second state of fetch, which we'll look at in a second, we'll tell memory to go do a read. And it will read from this address that we've just stored in MAR. Yeah. That's the third. And I'll illustrate that, too. OK. So here's the second state of fetch. So memory, we're going to enable by setting this input to 1. I've kind of masked out the I-O logic. This is the one, the figure I put in the notes. But the I-O logic, we're not going to use in our class. So you set memory enable to 1. Notice that this MUX is also controlled by memory I-O enable. So that will take the output from memory, which goes through this input. From memory, which goes through this I-O logic again. But it'll take the bits coming back from memory and store them into the MDR through this MUX. The read write signal is put here. So we're going to tell it to do a read when we're doing the fetch. And then the LDMDR signal is also set high. So that MDR, when memory comes back with bits, will store the bits of the instruction at the address MAR. OK, and they are there. So these are some control signals for the second state. So we're just copying, again, the memory at this address MAR into MDR. So we're just doing a read. This is how the read works on the memory. All right, then the last state is just to copy from MDR across the bus into IR. So that's relatively easy compared to the last two. So we set gate MDR to 1. That allows MDR to be copied out onto the bus. And LDIR is also set. So it takes the value of MDR, which is now on the bus. And it copies it, stores it into IR in the third state. Make sense? We're good? All right. OK, so fetch is done. So each type of instruction, then, is going to use a distinct sequence of finite state machine states to execute. So we'll have one set of states for AD, a different set of states for LDR, a different set of states for STR. And in order to get to that sequence, well, we need to say, well, what is the opcode? Now, the finite state machine can't look at the opcode, can't use those bits until they're in the IR. Remember, in fetch state 3, we're copying them into the IR. But they're not there until the rising clock edge. So we can look at them in cycle 4, state 4. So state 4, that's all it does, is it looks at them. And then it jumps to a new finite state machine state, one of 16, based on the opcode. That's all it does. So we call it a decode state. Actually, it does something else. I'll tell you later. But for now, the important part is switch to one of the 16 sequences for that particular opcode. Whatever the opcode is, the opcode is stored in IR 15 to 12, the first four bits, the high bits of the instruction register. All right. So here's what we've got. So instruction processing is going to look like this. These first three are fetch. So MAR gets PC. PC gets PC plus 1. That's in state 1. State 2, read memory in MAR, copy it into MDR. State 3, copy MDR into IR. State 4, decode, and then some variable number of executing the instruction. And that's how we process instructions for the LC3. In general, every processor is going to have fetch decode in some set of execution states. It's always going to take some number of cycles to fetch, some number of cycles to decode, some number of cycles to execute. So what's the relationship between states and cycles? Well, each of those states is going to require at least one cycle, but some might require a lot. So memory, remember, is fairly slow compared to the processor. Real DRAM memory would be even order 100 cycles compared to a modern processor, so quite slow. Memory access states, such as the second fetch state, can thus require more than one cycle. So those states will actually have self loops, or they'll sit in that second state of fetch until memory says, OK, the bits are now in the MDR. So that might take one cycle, might take 100 cycles. Doesn't matter. The finite state machine has to be designed to wait for the memory to finish. So here's the state diagram. So let me highlight some things for you. So here's fetch up here. Maybe you can read the RTL. That's just the RTL we've been looking at. Here's decode. And then you can see it branches out into a bunch of different chains of instructions. And there's just one sequence per opcode. So if you go through and look carefully, the shortest is 1. I think this is add over here. So the shortest is just one state to execute an instruction, and the longest is about 5. Some of these overlap. So some of these for the different loads and stores actually overlap in states. So they share some of their sub-sequences. But generally speaking, you do fetch, you do decode, you figure out what it is in decode, you go execute for a few states, and then you go back up and find a new instruction. So after you finish, you go back to the first fetch state. So finite state machine fetches an instruction, decodes the instruction, executes the instruction, starts over. And that's it. That's a computer. So now you know how to build it from transistors. So here's a little thought problem for you. And you can be honest or not. I won't really even ask you an answer, but think about it. So at the start of the class, I couldn't have even asked you this question. What I really wanted to ask you is, well, how many bits do you need for the finite state machine? So for this high-level state machine I just showed you, how many bits do you need to build a computer? Think about what you would have guessed. And you wouldn't know at that point. But I don't know what you would have guessed. I kind of feel like I would guess, I don't know, a million or something, something big. 42. That's probably a better answer. But Pat and Patel's answer is six. There are fewer than 64 states in that state diagram. So with a six-bit finite state machine, there's the IR, there's the PC. We're playing the same games we did with our abstraction before. But the high-level state diagram only needs six bits. So I find that pretty amazing. You can build a computer with a six-bit finite state machine. I think that's kind of cool. Any questions on this? Yeah? How much do you actually need? How much you actually? This is an actual computer. Yeah, so that's a good question. So if you look at it, it depends on the design. So if you look at something like x86, it's been building up a lot of complexity because it's been growing gradually over about 40 years. And so it's a very, very complicated design. I really, I'm not even sure I can make an estimate. Yeah, it does even things like the external instructions are actually translated internally in a lot of the implementations into simpler instructions for speed reasons. And so there's a lot of state on the chip that logically is part of the FSM. In terms of executing the micro-instructions, it's probably actually kind of comparable. But there's a lot of other things going on in a high-performance design. So for example, they've mentioned this in Pat and Patel, but when you fetch one instruction and then you're going to decode it, well, you could usually fetch the next one at the same time. And then while you're executing the first one and decoding the second one, you could fetch the third one. And executes more than one stage, so maybe you can overlap those two. And so that's called pipelining. And so most modern high-speed processors will do pipelining. There's also things like super-scalar execution, where instead of fetching one instruction, decoding one instruction, well, why not fetch two, or four, or eight? And so those kind of things, if you take 4.11, there's a design competition. And some of our students have tried to build those in their designs. So I mean, it's in the scope of what you can do. That's pretty aggressive. I mean, just to give you a number, some of my staff for 3.91, they had a team where they did actually one of the first super-scalar out-of-order processor designs in 4.11. And they told me they spent 1,000 hours between the three of them on that design. So that's sort of the high end of ECE design competitions. But 3.91 is more fun. But that's because it's in my class. Anyway, so let's see. So the simpler architectures like ARM or Alpha, I think, again, they have all of the things I mentioned, pipelining, super-scalar fetch and decode and issue. But the core is also probably pretty similar in complexity to LC3. And there, there's not the complexity of the translation process either. So we'll come back to that. Yeah, PC has to start somewhere, yes. And so we'll talk about that later, how we make PC point to a certain point and things like that. I mean, a real computer bootstrapping process, PC will be initialized to something. And there will be some code that goes and looks on a disk usually for a small chunk of memory, which is the core of the OS. And we'll load that into memory and then start from there. Or we'll go to a particular place and read only memory and use that to do some of that bootstrapping process. So that kind of thing, you can learn at least the fundamentals of it in 391. But we won't do much in our class. Yeah, yeah, in most laptops and desktops, there's a BIOS like that. That'll be in read-only memory. And that'll tell the computer where to go look for the first chunk of the OS. So there's a bootstrapping process to bring the OS up. OK. So let's, actually, some of these questions that you were just asking, Sasha. So we just looked at some instructions and said, OK, there'll be a PC. And so how does those instructions get there? But you can ask the same sort of questions. So when I made a peanut butter sandwich, why was the bag closed? Why didn't it come open when I wanted my bread? Where did the bread come from? Or why was it whole wheat? These are all perfectly valid questions. So in our model of programming, we'll put bits into memory and then tell the LC3 to interpret our bits. We can also put data bits in memory. And the LC3 can't tell the difference. So if you tell the LC3, oh, execute my data, it will just execute your data for you. And all this stuff that we were just talking about, about bootstrapping and things like that, you'll learn in later classes. You can kind of see how it's done in the simulator here. But in order to really understand it, I think wait until 3.91 or talk to me in office hours. I can tell you more, too. All right, so let's take a look at LC3 instruction processing, what we just did and actually illustrated. So I'll show you a few pieces of the data path. So I'll put memory, register file, PC and IR, MAR and MDR. So it'll look like this. So here's memory over on the right side. I've got 65,000 addresses, except I left a few of them out. Here's a register file on the left side. I put all eight of them there. Here's PC, IR, MAR, MDR. And there's some blanks. What's in those blanks? Wow, you're good at this. OK, there's no such thing as a blank, right? They're bits. They're never blanks. They're always bits. We don't know what the bits are. Why are some values in hex? So that hex is 0000. It's like where you put other hex areas, not like just 24. Yeah, yeah. So that's a slightly different question, right? I mean, normally in LC3 by convention, we'll put our program at 3,000, which is why I wrote 3,000 here. But what I was trying to ask is, well, how come there are hex numbers on here? Because the computer doesn't understand hex, right? It only understands bits. So that's just for humans. So the hex here is just for us, right? All these you should read as bits. If I put bits here, it'd be pretty big. So I got tired of writing bits. But the computer, it's all bits. So 3,000 is 0011 and 12 more zeros. So I got tired even trying to read it. But yeah, as Eric pointed out, the 3,000 is where we'll usually store our LC3 program. So when you get in the lab and write your code, you should write it at address 3,000 by convention. All right, so let's get started. So let's say that we tell the LC3 to go ahead and execute. And so the first fetch step is, well, MAR is going to get the PC. PC is going to get PC plus 1. So what will PC become? 3,001, right? It'll get this value plus 1. What about MAR? What will it become? 3,000. And that'll happen at the same time, as you can tell by the animation. So all right, so to get those new values, so let's put those in there. So fetch stage two, we're going to then go to memory at MAR and copy the bits there into MDR. So first, we'll go to memory at MAR, which is 3,000. Here's address 3,000. You can see the bits here, which for us humans, we can call 670A. And we'll copy those into MDR down here. All right, third stage of fetch, copy MDR into IR. Here's MDR 670A. So we'll overwrite whatever bits are in IR with 670A. Those are the three fetch stages. Now we have this instruction over here, 670A, and we can execute that. So these are the bits now sitting in the IR that we need to decode and execute. Eric? AUDIENCE 1 No, those are three separate states of the finite state machine. So they went in the order that I showed on the slides. So you go through the finite state machine one state at a time. And then decode, you would then start looking at this and decode it and execute it. So it's only in the first state of fetch that you add one to PC. Yeah. You wait till you start processing the next instruction to increment it again. So we will get there. But yeah, we have to wait till we finish processing this one. OK. All right, so 670A, let's put that out in bits. So there it is in bits. And then we have the next instruction, which is 670A. Let's put that out in bits, so there it is in bits. So what does that mean? So anyone remember what this one is? Yeah, it's LDR. OK, and this one is the destination register, so that's what? R3. OK. This one is the base register, so it's R4. Good. And this is the offset, which is what? In hex. Yeah, it's a two's complement, and so it's 0A in hex, right? So the 0 and then A is there. OK. So in RTL, that means, OK, take R4, add A, extend it out to 16 bits, so just put the leading zeros on there. That'll be a memory address, so go there in memory, read that out, and store it in R3, the destination register. So that's one instruction. So what's the memory address here? So let's go back and look at our data path pieces. So the memory address is R4. Here's R4. So R4 is 1230. And then we'll add the 000A to R4, so what do we get? 123A. So what's stored in memory address 123A? So go back to our thing over here, and it's there, right? So 0F, 0F. So we'll take those bits and copy those to R3. So 0F, 0F. So we're going to copy 0F, 0F into R3. So there's R3 over there. It had some bits in it. We'll just write over those and put 0F, 0F. And that's our instruction. That was the first instruction. So all that work for one instruction. So what's next? Fetch, good. Start over. OK, first fetch state. So MAR gets PC, and PC gets PC plus 1. So what does PC become? Good, and what's MAR become? Good, OK. Second state. So MDR gets memory at MAR. MAR is 3001. That was one of the ones I left out. So let's just say it's filled with 16C3. So then we'll copy 16C3 into MDR. And then in the third fetch state, we'll copy MDR over to IR. So IR will now also have 16C3 at the end of fetch. So next is decode. So this is just walking through the finite state machine states as we saw before. So we're going to decode the instruction in IR, which is 16C3. So let's write that out in bits as we did before. And do you remember what that opcode is? It's an add, yeah. OK, and then this is our destination register, which is R3. Source register, R3. Other source register, R3. So it says take R3, add it to itself, put it back into R3. So let's go do that. So we take R3 and change it from 0F0F to 1E1E, multiply by 2, and we add it to itself and store it back. That's it for that instruction. So what's next? OK. Yeah, you can stop. You get to stop in a few minutes. Imagine if you leave the simulator running in the lab. All right, so fetch state number one. What are we going to do? What's PC become? 3,003. What's MAR become? Good, OK. State two. Again, I didn't write this one. So let's say it's 770A. That's the memory at address 3,002. We'll copy that into MDR, so 770A. And then the third state, we'll copy from MDR over to IR. So IR will have 770A. Go into decode, take those instruction bits. So 770A looks like this. The opcode there is, you remember? Yeah, it's an STR. Good. And then this one is the source register, which is R3. This one's the base register, R4. This one's the offset, 0A again, right? Good, OK. So memory at R4 plus 0,0,0A gets R3. So what's the memory address? Same calculation as before, right, since R4 didn't change. So R4 is here. It's 1,2,3,0. We add 0,0,A. And what do we get again? 1,2,3,A. Good. So we're going to store the bits in R3 into memory address 1,2,3,A this time. So the bits in R3 are 1E, 1E. And we're going to store those bits into 1,2,3,A. So we now changed 1,2,3,A to 1E, 1E. All right, what's next? Yeah, for the LC3, back to work for us. Yeah, so that's the end of our instruction sequence. So that's three instructions. And all we did is we went to memory, we read the value out, we multiplied it by 2, we put it back, right? What if R3 had something important? What if it had the only copy of your secret key, your encryption key? Too bad for you. It's gone. Don't do that. You're the programmer. The programmer controls the computer. Computer just does what it's told. If you have something important and you overwrite the bits, those bits are gone, right? So be careful. The computer will do exactly what you tell it to do. And if you had something important and you lose it because you told the computer to overwrite it with something else, your bits don't just magically come back. The computer doesn't stop and say, you know, I think you care about this. It just throws them away for you. All right, yeah? So in our lab, there was a good point. So we'll get to that with part of the ISA. But let me just answer you briefly. So HALT, what it does in the virtual world of Pat Patel is it turns the computer off. What it does in the simulator is just makes the simulator stop running. And now it might change register values. So if you're trying to inspect things, tell the debugger or the simulator rather to do a breakpoint and stop at the breakpoint. But if you execute HALT, you should always end your program with a HALT, and that'll stop simulating. That'll stop the simulated processor continuing to work. Anything else before we go on? Yeah? What does it do for you? So pretty much any computer you use for any purpose is executing instructions. So at some level, your phone, even your watch these days, the software that's written on them has to be mapped down to this level in order to execute. So what it does is everything computers do. This is the only way in which you can make computers do things is to execute at this level. Now, we build things on top of it to make it easier. So the one that we'll get through in this class is an assembler so that we can write things. All right, let me go back a couple more. Things that look like this line instead of things that look like this line. So in next week, you'll be writing this kind of line with 0's and 1's. In a few weeks, you'll be writing this kind of line with R1, nice human-friendly terms. Next semester, you can actually write C and compile that down on x86 and run that. But at the end of every execution process, the only thing the computer knows how to do is these bits. I mean, it'll be a different encoding for x86 or for ARM, but it's still not much more powerful in terms of what it can do. Good question. Yeah. I'm not sure. I'm not sure. But you're changing the PC. You're not reading it. Yeah. Sorry, but the old value of the PC is not relevant if you're changing the PC. Yeah, yeah. You did add. You added one before you executed. You always add one in fetch. Yeah, yes. Yeah, the addition, the increment of the PC happens in fetch. So any time you use PC in the RTL of an instruction, the value of the PC for the execution is the address of the instruction plus 1. Yeah, when you're writing to the PC, the old value doesn't matter. All right. All right, so let's see. So we can talk a little bit about this, and then we'll pick it up on Wednesday in a couple minutes. So we'll talk about it a little bit. So in the ISA, we'll have three different kinds of opcodes. You've actually seen examples of a couple of them. So one is operations. So those are the things we'll do with the ALU. The second kind is data movement. So we have register bits moving to memory, memory bits moving to registers. So to and from memory, we call those data movement instructions. And then the third kind is control flow, where we want to conditionally change the program counter. So let's take a look at each of the three kinds. So when we talked about LC3, we mentioned that the ALU only does three different operations. So there's add, and, not. Each of those operations has at least one source register and one destination register. And then for add and and, we're going to have a second input operator. So where does that come from? We have a couple of choices. So one choice is, well, we could use another register. That's the one I've shown you already. The other choice is to store some bits in the instruction itself. That's called an immediate operand. And you have the choice of addressing mode for your second input operand. So you can have a register, or you can have an immediate value. So let me show you how that looks in terms of encoding. So first of all, two opcodes for the two input operands, the binary operators. So add is 0, 0, 0, 1. And is 0, 1, 0, 1. The mode bit here, IR5, is what decides which is the addressing mode of the second operand. So one choice is that mode bit is a 0. And that says, well, the second operand is also a register. So in that case, these two bits have to also be 0. And then you get SR2 here. Now, that's the one you've seen. So when we did an add before, we had two input registers. We added them together. We stored it to the destination. The other choice, though, is to put a 1 for the mode bit, in which case you get a 5-bit twos complement number. So that means the second operand, where you're add or you're and, will be this 5-bit twos complement number, sign extended out to 16 bits. So what can you do with immediate mode? Why bother to have it? So one thing is you can add small numbers. So for example, it's pretty common to want to increment or decrement. If you're going to run a loop, you want to do an increment, you do an increment, decrement. You can go up to or down to negative 16 with 5 bits, up to plus 15. You can also mask out your high bits. So if you want to just look at the low bits of a number, you can end it with immediate 1. Or the low 2 bits, you can end it with immediate 3. That'll throw away all the other bits in the register. All the other bits will be zeroed out. You can also mask out low bits. So if you want to zero the low bit here, you can end with minus 2. And that'll give you FFFE is minus 2. So the low bit will be set to 0. Or if you want the last two bits set to 0, you can end with minus 4. And then probably one of the most important things you can do is put 0 in a register. So if you want to count from 0 to 9, well, how do you get a 0 in LC3? So one way to do it is to use AND. You AND to 0, now your register is 0. So that's a common way to initialize a register to 0. So just some uses for the immediate mode. Yeah, let me show you this one, and then we'll stop for today. And I'll show you how that works in the data path on Wednesday. So this is the NOT. So you only have one operand. So in this case, IR5 to 0 have to be 1. So the NOT operand is 1001. So that takes SR1, calculates 1's complement of SR1, and puts it back into DR bitwise. So let me stop there, and I'll see you on Wednesday. Enjoy your Halloween. Thanks.\",\n",
       " \"All right. So someone, Daniel, just asked me, what's going on in the holiday party? Why is it so important you go there? There's a, I just, I was just there eating while you guys were waiting outside. I told ECE SAC to come down here and announce it. I don't know, I think they sent it out on Twitter instead. So if you didn't get the tweet, too bad. No, you can still go there until 430. They're doing like a gingerbread house competition. So if you can do a better house than everyone else in half an hour and post it on the, I think on the ECE SAC Facebook page, then you can win. But free cookies, free hot chocolate, stuff like that. So you should go up and hang out. This is just, you take the elevator to the third floor, turn left, there's a big ballroom-like area, and that's where it is. Okay, not quite as fun, but office hours next week, 12 to 2. And then today, I'm just gonna finish up the advice and then talk about review. So we'll do a little mini review session for the final, or maybe not mini, but a full hour, or half an hour, whatever I have left. Final exam coming soon. Coverage, you've seen this, so won't spend too much time on it. Again, this is in the video, too, so if you didn't write it down or whatever. One part each on, so one question, really. Part one, two, and three of the class, so each of the quarters. And then four parts on the last few weeks, so the material since midterm three. I don't need to push buttons here. All right, so this one I talked about, try to do a big project in the next few years. This actually means kind of your own project, so that you're in charge and you make decisions and you can learn how to design things and think about how to constrain things, too. Learn to use a debugger, learn to use tools, avoid optimizing prematurely. I don't remember who it was, I think Donald Knuth, who's a famous computer scientist, said premature optimization is the root of all evil, but it was mostly in context. But the main point is valid, so there's some other context involved. But the main point is that you really don't want to spend time making things smaller or faster or better that are not a significant part of a bigger design, right? So don't waste your time doing that. What you end up getting is a very complicated piece that maybe you have to throw away later anyway because someone has to modify it and no one understands how it works because you spent so much time making it complicated so that it would be smaller fast. So be careful about how you optimize. Make sure things work, right? Do all the debugging and testing and things like that. Then figure out, well, what's the part that actually takes the time or takes the space or takes the power or whatever you want to optimize? The thing that's taking too much and then go make that part smaller or faster or use less energy or whatever the metric is, right, or set of metrics. So use your time wisely in that sense. All right, so this is the one I stopped on. So Seymour Cray was the inventor of the supercomputer. There was a series of companies he founded actually based on supercomputing. But for many, many years in all the national labs and other places that wanted to do high performance computing, they bought Cray computers and that was basically the only thing they bought. But he lived in Minnesota and actually Cray Computer by name, there's still companies up in Minnesota. But he would, there are a lot of lakes in Minnesota, so every spring he would start building a boat to go sailing on the lakes. And in the summers he would sail around. And come fall he would pull the boat up on the beach and burn it. And the next year he would start over, using all the stuff he'd learned by building his boat the year before and the year before that and the year before that. So sometimes it's worthwhile as you're building systems, whether it's software or hardware or both, just say, I've learned a lot by putting this together, but it's better if I just start over and just chuck it and start over and rebuild it. There are other ways to do things and you need to learn those too, but this is one useful lesson is, well, when do I just need to start from scratch and do my own design, even though I've done this kind of thing before, I can do it better now because I know more. So it's worthwhile building even just a prototype and saying, well, what did I learn by that? What was the hard part? What was the easy part? Where should I put more time and energy and thought? Best designers are the best testers and debuggers, best debuggers. So we tried to talk about this when we introduced programming in the last part of the class, that you want to think about what your program's supposed to do before you sit down in front of a computer and start writing code. The people that think about it and draw pictures of their data structures, as I tried to do for you as we're developing code just before break, hopefully everyone at least watched that video. I know you're enjoying eating and relaxing over the holidays. But the people that think about, well, what is it I'm trying to build and have that model in their head, you're going to be a lot better at making sure that that's what's actually in your code, that's what your code is doing. And making sure that there aren't any bugs and that the code is really doing what you intended. So do think about that as you go forward and build your systems. Good code is like good prose. It should be easy to read your programs. I mean, sometimes you say, I can save an instruction or something. That's fine if you find some clever way to do something, but put a few comments in. If it's easy for people to read your code, then they can keep the code around. You can reuse it later when you say, hey, I need something that does this. Well, this old code I wrote is almost right, but now I understand how I made it work so I can change it. If your code is hard to read, for whatever reason, you don't put any comments, you make it cryptic, you do complicated things when simple things would have worked just fine, then you won't be able to do that. You'll go back and you look at it and you say, well, I don't know, or worse, you'll say, maybe, and you'll put it in and it won't work. Or worst of all, you'll say, maybe, and you'll put it in and it won't work, but you won't realize it, and then you'll give it to someone else and they'll laugh at you. Now, I guess worse is where someone actually gets hurt because you give them broken code, but try to make your code easy to read. Take on a big team project. So one of the reasons they want to put the old slides in as a review is you might think, wait, this is the same thing, but it's not. So you should have a project for yourself, but you should also make sure you have some chance to work with some other people. So one of the big changes actually between 190, which is the old version of the first class for ECE students in computing, or computing class for ECE students, maybe is a better way to say it, is that in that class, our discussion sections were kind of more like traditional discussion sections, which you've probably had here, or maybe you're not, because a lot of our departments are changing their intro classes now, where basically it's a little bit like a lecture, right, your TA stands up and maybe does some examples, or maybe just answers homework questions, or whatever. But it's not you getting together in groups and working on problems together. So we changed that, and part of the reason was for many, many years, our alumni and company reps and everyone's been saying, ECE students don't have enough soft skills, right? They know how to solve problems, but they don't know how to work with other people. So we've been trying to put more and more teamwork, but we still want you to build up your own skills. So we did that in this class in the context of discussion sections. You should also do it outside in your outside projects, right? So you should find some friends and build something together in the next few years, just for fun. I mean, not just for fun, for excitement, and you can even make a profit out of it if you'd like to. But fun should be a part of it, right? All right, don't be afraid to break things. There's a lot of stuff available to you as an ECE student. A lot of the independent study projects and labs and things like that, there's some budget lying around here or there. I mean, don't break expensive equipment in the labs. But don't be afraid to take code apart or look into things to figure out how they work, right? If people never did this, we'd never have new inventions, right? So don't worry too much about, if I do this, it's not gonna work. Go instead and see what happens, right? Figure out how it works and play with things. And so last part, hopefully you've seen examples from this. I'll mention one in a second, but look for opportunities to turn dredge work into inventions. Actually, I'm pretty sure I don't want to mention the one I just thought of on video, so. But you'll find lots of opportunities in your life where you're doing something quite repetitive. And you might think, well, gosh, a computer could do this. In fact, I could teach a computer to do that. Well, certainly you could make your life easier by then doing that, right? Maybe also other students. Now, if it turns out to be your ECE XXX homework, maybe that's not such a great idea, but XXX, replace with whatever you want. But there are lots of opportunities for that sort of stuff. So that's where things like assemblers came from, right? People got tired of writing binary code. And they said, well, couldn't we just write something simpler, right? Maybe we could write ASCII characters and we could write a program that turned that into bits for us, right? That's where high level languages came from. So that and lots of other things in the world now all came from this idea of, well, why do we need humans to do that, right? Couldn't we automate that? Couldn't we make that easier for people by having a computer help them out and do the easy parts? Right, so look for opportunities for that. And if you come up with good ones, then make them available to your friends. Or more broadly. So that's it for the advice stuff. And unless anyone wants to ask questions, we'll go into review session mode. No? Okay. That's it. Let me turn this off. All right, so we'll switch over here. And we'll do our customary survey of topics. So what would you like to talk about for review? Or do you just want to go upstairs and eat? Yeah, Eric? See programming? Okay, yeah. So part one of the class will be one question on the exam. The systematic decomposition, which is what I consider to be kind of the key, the core of programming, which is how do you take a task and break it down into pieces, yes, that's part of the most recent material. And there will be programming in that sense on the exam using LC3. Probably assembly more than binary just because although we think it's amusing, we know it's painful. So there'll be a little bit of binary, but programming there will be some of. C programming though, it's possible that one problem might include a little bit of it, but only at the level that we actually taught you, which was really one statement level kind of on the first midterm. Yeah, Nathan? Okay. There is a summary slide in the PowerPoint too for that, but I'll go through it. Yeah, yeah. Hazards. I thought that's start stuff. It is start. Okay. Yeah. Yeah. Run through the concepts we should know. Okay. That's it. Let's see. Where did my. Oh, this is nice. Okay. Skills from part one. You should be able to do those things. I think I even got it all on one page. Okay. Emily. I'm sorry. What? Okay. Okay. What level of detail do you want out of this? Okay. Okay. Yes. You should. I mean, so we didn't cover that many sequential components, right? And muxes and decoders, I would think you know. To know how to use it is sort of to know the equations, which is to know how to build it, because you know how to build combinational logic. So, I mean, I would hope you could reproduce it, even if you haven't memorized how to draw it. I mean, you should in real life, you probably never, unless you go and actually do the cell design for a new process or something, you probably never have to reproduce it. You could probably just drop it in place or even write it as hardware design code. But you should know how it works, and to me, to know how it works is to know the equations, which means, again, you know how to do combinational logic, so you should be able to build it from gates. And it's actually not impossible that, you know, say carbon nanotubes actually become viable as a replacement for CMOS, that, you know, more than one of you might actually be in the business of saying, well, how do we take a bunch of carbon nanotubes and build them into a mux? Right, so, yeah. Okay. There's actually a list over here hidden right now, so I will put it back up in a second. And then, so this is just the summary. The other half of the summary then is just knowing what these words mean. So, I'm going to read my mail now. Yeah, I'll just pop up that attachment. So, I'll be taking the final tonight. You've caught on to our secrets. All right. So, yeah, I mean, there's a terminology list, right? We should recognize all of these, hopefully. Yeah, and actually I put that on there already, so let me switch over. I'm going to zoom out a little. Hold on. Okay. Anything else we should add to this list for today? 320, so we have about 40 minutes, yeah. Glenn Norman? Sure. Okay. I'm going to write the acronym. Yeah, Eric? Yeah, so, okay. Let me put those two together and then put it on the list. Okay, anything else or should we vote? Okay, so, let's see, what was the first one? So, C programming with a two, three, okay. Two past process for the assembler. About 12. Hazards? Yeah, you got to vote for your own two. Control signals? Okay, so a bunch, maybe 20, 25. Micro sequencing? Okay. About 30 to 40. Floating point to decimal? About four. Von Neumann model? Okay, maybe about eight. For floating point to decimal, by the way, there is a tool that, you know, you can look at the videos for a review of examples over the PowerPoint slides, but there's also a tool that will help you do some examples. SecDED codes? Two, three. Hardwired versus micro program control unit design? Okay, so maybe about 10. Okay, so let's talk about micro sequencing then. So maybe I will, I need probably, well I don't need, but it's probably easier to do with pictures, so let me. Okay. Let me do the definition first. All right, so first I wanted to just redefine the problem, make sure everyone knows what it is. So mapping the control signals, which I think we'll end up talking about again anyway, but that's just a question of somehow figuring out how to look at the current FSM state of the control unit and produce the right bits for it, right? So once you've mapped everything into RTL for each of the states and the right sets of states and the sequencing between them, or this transition diagram, let's call it for now, then you have a couple problems. One is creating those bits, right? And that's the one we had last, which is, well, do I do it by combinational logic, which is a hardwired design, or do I do it by treating it as a little program, which is a micro program design? So we'll talk about that later. So the micro sequencing problem then is, well, I've got this state diagram and the finite state machine has to go from one state to another in that diagram following the arrows and following whatever branch decisions I've put in there. And, well, how do I build that logic, right? How do I make it go from the right state to the right next state so that it produces the right control signals to process the instructions for me? So that's the problem of micro sequencing. All right. That's the problem of micro sequencing. So if we take a look at, this is the Pat and Patel state diagram, right? So here's the level at which we've already completed the design so far, let's say. So you can see each of the finite state machines has FSM's RTL in it, rather. And, you know, we have the arrows and we have the branch decision saying, well, you know, here we're going to wait for the results to come back from memory. And if we get a memory-ready signal, we'll go on to the next fetch state. If we don't, we'll stay in this state. So we need some way of building logic that controls those state transitions. And we can separate that out from the output logic, which is implementing the RTL through control signals. So those are two separate logic, I don't want to say logically, we can kind of split those up into two pieces. One is, well, how do we generate the control signals? And then how do we generate the next state? Just like we generate outputs versus next state logic when we design simpler finite state machines. It's the same sort of separation of concerns. Now, at the end of the day, you might end up, you know, sharing gates between those implementations, just like in our designs, we just said, well, let's put all of those bits into the same memory, right? But you can think about them as different problems. So let's see. So we did a couple of these. Maybe I felt like this one was simpler. So I was going to skip ahead here and just look at the Pat and Patel micro sequencer again. Or do you want to look at this one again? Go back to Pat and Patel. Okay. Yeah, this one is also in the notes with a couple tweaks and also in the PowerPoint slides. Pat and Patel is also in the book. And also in the PowerPoint slides. So let me skip to... All right. So this is actually the micro sequencing part of the Pat and Patel design. So in their micro sequencer, they do it as follows. Actually, let me show you the state diagram. So remember that in these kinds of processor state diagrams, let me clear away the stuff. In these kinds of processor state diagrams, usually we only have one or two next states. So most of the time, we don't design them to have three or five or seven next states. They just make very simple decisions about how to process the instructions. Maybe they look at an address mode bit or something. I suppose you could design an ISA that had three address mode bits. But if you wanted to, you could branch on two of them and then branch again on the third in the next finite state machine state. So it's not too hard to get it down to one or two next states for almost all of the states. The exception then generally would be decode, where you're figuring out, well, what kind of instruction is this? Let me branch into a bunch of different execution paths for each of the opcodes, for example, in the LC3 architecture. So in order to put those things together, Pat and Patel for their micro sequencer said, well, we're going to have to have one next state ID. So generally, we've got at least one next state. So we'll have one ID for that next state. And then somehow when we're going to branch, we'll name a condition. So there are five branch conditions in their design, right? Five different reasons to branch to two different next states instead of one other than decode. And so we'll name one of those five conditions. For that, we'll need three bits. So we'll set the six-bit next state, the three-bit condition. And then in order to handle decode, we'll put one extra bit that says, well, should we branch like a decode state or not? And so only one state will have this bit set. It's the decode state. And all the other states are not the decode state. So all of the next state decisions can be made from these 10 bits, right? First, you say, well, is it decode? If it is, then I'm going to go to a particular state for that particular opcode. If it's not decode, I'm going to go to this state modulated by this condition. And so how does that – so these are the conditions. All right, Eric? Yeah, yeah, sorry. I'll give you more detail, and I'll show you the implementation again in a second. It's there. So these are the five conditions. This is the unconditional, meaning that some state has only one next state. So if a state has only one next state, you just set the con bits for it to 0, 0, 0. If it branches on memory like the one we were looking at a minute ago, you set the con state to 0, 0, 1. If it's your branch state and it should branch on the branch enable bit, then you set it to 0, 1, 0. And then there's some others in instructions and concepts that we didn't talk about in our class, but that are implemented in the full LC3 design. So there's some other conditions for that. This table I'm pretty sure is included in – not in this form, but I think the information is in the bits that are given to you on the handout. But if not, double-check and email me, but I'm almost positive. I think I visualized that part of it. And I hesitate to pull it up now, but does anyone have that one here? Some people have laptops, so check it if you don't mind while we're live. We don't care if you memorize this. I'm pretty sure we give it to you. There's really no value in your knowing, oh, the LC3! PSR 15 would be checked if you just set those con bits to one – whatever. But we want to know that you know how to use these tables and fill in the control memory. So we may well ask you to do this sort of stuff. All right, so this is the implementation. So what you can see here is, bottom line, if you have a decode, your J and your cond don't matter. Instead, what you're getting is 0, 0, followed by the opcode, and that's your next state. Remember, we set up those 16 chains based on the opcode, starting with states 0, 1, 2, 3, up to 15. So it's something we didn't study. It's basically the way that hardware enforces the separation between the operating system programs and the user programs. So it's something – if you take 391, you'll see how it works in x86, and you'll need to use it when you go build your operating system. But the design in the LC3 – I don't know, I didn't like it very much. You can read about it in, I think, like, section – chapter 8 or 9 or something like that. I don't remember exactly which chapter that's in. But the idea is basically just to protect the machine, the operating system, from malicious or buggy user programs. So it's a hardware state that separates one from the other. Okay, so – all right, so there's decode, and that overrides everything else. If you don't have the decode state, though, what you'll do is you'll take your J value – that was the 6-bit next state value – spread out this way. And for each of those bits, one of the conditions – so this is kind of like an exploded mux. Again, they're not in order, I think. So here's memory-ready. So this is cond 2 equals 0, cond 1 equals 0, cond 0 equals 1. So if the condition says memory-ready, then if the ready bit is set, the only time this AND gate will output a 1 is the cond is the memory-ready cond, and memory is actually ready, in which case J sub 1 gets ORed with 1. So that's how their micro-sequencer works. Each of the conditions turns on one bit in the next state address. So, of course, when you have a branching state, you have to have two next states that differ only in that bit, meaning the bit that corresponds to the particular condition on which you want to branch. So you have to look at the diagram, look at the bit that's going to change, and then pick two states that differ in that bit, and then the one with the 0 in that differing position has to go into the J value. And the next state that has the 1 bit is the one that'll happen when the condition is true. So it's fairly constrained design. Remember, J is the six bits that you put into the next state ID. So these are all, these 10 bits you specify for every state, and then you store them in the control realm associated with each state. They're just like control signals. So remember that to get these bits, you simply apply the current state ID to the control realm and out come all of the control signals, 39 for the full design, plus these 10 bits. So 49 bits in all for LC3 full design. Yeah, that's right. Yeah, so the implementation, I think I have a picture of it, or did I just, hold on. Where did I put it? Sorry, not in these slides. So basically this implementation is just a 39 plus 10, so 49 bit addressable read-only memory. And the number of addresses, it's a six bit state ID, so it's 2 to the 6 addresses. So 64 by 49 bit memory. And that is the control realm. And then the implementation is take the current state, which is a six bit register, apply it, and then use logic like this to find the next state, and then latch that in to the register every cycle, basically. There's no need to have a pause, as we did in the design I put into my slides, or into the notes. Yeah, they do pauses by self loops in the Pat Patel design. Yeah. Yeah, so the 25 was after we took out interrupts and privilege. So with interrupts and privilege, there are 39. Yeah. So if you look in Appendix C, if you look at that list, that'll be 39 bits. If you look at the list I gave you in the notes, that's 25 bits. And that's just a subset of those, which don't pertain to interrupt and privilege implementation part of the data. Yeah, and the 25 we used in class were the same as the 25 in the notes, and yeah. And the same as the 25 you did in discussion section, I think, last week. Same set. Or same subset, I should say. Okay. Should we move on? More questions on this? Yeah, I don't know if they draw it in the data path, except in the more detailed. So try to look at the most detailed one. The PSR? Yeah, it shows up in the simulator, too, prints the value. Yeah. This is the logic. So the J bits are simply ORed together with one bit for each of the possible conditions, but only one of those conditions can be true. Because this is like, these are midterms on the confits, and then ANDed with the conditions themselves. J5 never changes. So your next states always have to have J5 in common. Yeah, these are next states. So your next state depends on J, depends on COND, and depends on IRD. The 10 bits are used for micro sequencing. Yes. So these are just the, so I know people in the back can't see these, sorry. These are the diagrams that you'll get, allegedly, hopefully, there, all with a pretty small font and hard copy, too. These are the state numbers that Pat and Patola signed. So, for example, in this state, this is 24 and 26, so you would put 24 into the J value, and then, because this is conditioned for memory, when memory was not ready, you'd stay in 24, and when memory is ready, you'd go to 26. And actually, there's some examples of that worked out in these slides. So I went and worked out LDI. So let me go, actually, that one was memory, too, but we'll go down to LDI. So here, yeah, so LDI, that was actually maybe just the one I showed you. Yeah, so this is 24 and 26. So the J value is 24, the condition is 1, which means memory, and the IRD, of course, is 0. So what this does, thinking back to that logic, is the bit here will change when memory is ready, and you'll go instead to this state. Otherwise, you'll stay in this state, which is the same. Does that make sense? Yeah, no? No, no, no, no, so current state has to be a register, right? So the current finite state machine state now in this design is a 6-bit register. And so every cycle, you calculate a new next state, and you store that into the register. That register value, those 6 bits, are then applied to the control ROM, which is 2 to the 6 addresses. So 6 address bits go in there. Outcome, somehow I think it's 51, but by this math here, it's 49 bits, which are 10 bits of micro sequencing, the J, COND, and IRD, and then 39 bits of control signal. Yeah, yeah, so there's a 6-bit register that holds the current finite state machine state ID. Yeah, it switches into privileged mode. You can see it in the full state diagram if you want. No, this has nothing to do with the bus. This is all micro sequencer inside the control unit. Yeah, in that box marked control. Yeah, yeah, this is the implementation of the finite state machine. Okay, I think we probably should move on. So let's see, next on here was control signals, so let me maybe just switch over. So we won't ask you to do the interrupt and privileged control signals, so don't worry about that. Yeah. So maybe I'll go back to the examples we did. I know you did some like this too, so let me just kind of remind you what the rules are as we go through them. All right, so this was the fetch and decode example. So I just mostly want to remind you of the rules rather than derive them all again. I mean, you can look at the slides easily to see the answers. So remember what we're doing is we've got five different groups, right? So one group is the register loads. So what we do here is we just look at the RTL and there's some registers being written. In order to be written, the load signal has to be high, right? And you don't want registers written unless the RTL says they're supposed to change. So if the name doesn't appear here, it should be zero. So the easy way is you say, well, okay, there's MAR. So I go to LDMAR, I put a one. There's PC. It's also written. So I go to load PC, I put a one. Those are my ones. Everything else is zero. So that's your first group. Second group, you really have to look at the data path. So this is probably the trickiest part. So spending some time here just to kind of understand the different types of instructions and how they actually get implemented in the data path might be worthwhile. So why do you need to understand this? Because if you figure out which way the instructions flow, as I've drawn for you here for the first fetch cycle, then you can tell, well, what do the MUXs have to do? Do they have to do anything? What value has to go on the bus? So if you kind of know, well, when I want PC to get into MAR, how does it get there? Is there some funny wire that runs through the middle of the diagram, goes straight to MAR? If there is, maybe I don't need to do anything. Well, there's not. So you kind of have to look at the data path and know enough about what's possible so you can figure out how to implement the RTL. Once you do that, you'll end up with something like this. So I would suggest scribbling on the data path instead of trying to just put it in your head. So scribble on the data path, say, well, PC is coming across the bus going down to MAR. So that means I've got to have gate PC on. PC is also going around this way through the plus one back in through PC MUX and I can increment PC. So it means PC MUX better be set correctly, not to take whatever, say, this input is from the adder. So then we have the second set of signals, which is our gate signals. Only one of them can be set. Remember, these are a bunch of tristate buffer groups. So if we turn more than one of them on, we're going to get shorts. So we should always have at most one. Only one thing can cross the bus. If you think you've implemented the RTL by making two different values cross the bus, you did it the wrong way. Look for some wire inside that lets you route the other bits a different way. Yeah, sometimes you might be able to do that if you were able to actually put two values on the bus. But of course you can't. It doesn't work physically. So in our case, we said, what was it? PC, right? So PC is one. Everything else is zero. Again, go back to the diagram and say, well, what about the MUXes? The third group is our MUXes. Here's PC MUX. We care about that. The other MUXes, three of them here are for address generation. Those are address one MUX, address two MUX. I'm sorry, that's not a MUX. That's an adder. And MARMUX up here. So these three are address generation MUXes. So we don't care about those here. And the other two are not in the diagram. They're controlling what goes into the destination register and what comes out of SR2. So those two we don't care about either because the register file results and inputs are unused. So we only care about the PC MUX. So we have to go look up in the table what value it has. I don't have the table here, but this is the right value for PC plus one. And then the rest, we don't care. So I just want to remind you for each group. You've got the register loads, which is mostly, well, look at the RTL, find the registers that change. The ones on the left, mark the ones that change as one, mark the others as zero. The gating, for which you have to figure out what's going across the bus. The MUXes, for which you need to figure out, well, which MUXes actually carry some of the bits you want to move back to the register you're changing. And whether the ALU is used, which is mostly just for ALU operations like AND and ADD. Sometimes we need to pass something through onto the bus, but that's kind of rare. But there is that option. So a couple of the finite state machine states will use it. It depends what else you're doing. I think the other path you can take, so if you need to get SR1 onto the bus somehow, well, one route is down through the ALU, use PASA, and then gate it through gate ALU. I think the other route would be to send it over to address one MUX through the adder, put in a zero here. So that gives you SR1 on these wires, which you could then, if you need to store it in PC, you don't need to put it on the bus. But if you want to put it on the bus, you can go through MARMUX. So if you need to write, I guess it depends what you needed to write into PC. Let's say you wanted to take something out of the adder and put it in PC. Well, then you could not go this way. So it depends what other RTL. I don't remember that problem. But that was probably one of the things I wanted you to think about is trying to do a couple of things at the same time. If the only thing you need to do is what you asked, then yeah, either answer would be fine. Yeah, good question. Yeah. Absolutely. Either way would work. As in real life, you have many options, all of which work. And sometimes there are metrics that will differentiate them. But in this case, there are a bunch of bits in a control ROM. So as long as the bits you choose make it work correctly and implement the RTL, it doesn't matter. So sometimes you'll have equivalent options for everything you care about. I mean, you could say, oh, maybe we should simplify the data path. And we could save some transistors by not adding all these different ways to do the same thing. But maybe you need both of those paths for something else anyway. So there's this ALUK control. So that's the next group. So if you did need to use the ALU, there are four different choices. And there are add, and, not, and pass A. And those bits are all given to you. So if you need the ALU for something, you'll have to set the ALUK bits. Yeah, yeah. Yeah, do take at least a few minutes before the final to go back and look at that resource sheet. I didn't print it for you again. But if you go to resources, LC3 handout or something like that, or if you look at the old exams, it's this two pages with this data path, the state transition diagram, all of the bits we're talking about, and some other things too. So make sure you know what's on there so when you're preparing your crib sheet, you know what not to bother to put. Anything else on this one? Okay, so that's the fourth group is ALU that Mohamed was just asking about. So, oh, and I put the fifth group here too, which is memory. So in this case, Fetch is not using memory. Memory is down here. We're just putting things in the MAR. We're not actually using the memory. So for memory, we turn it off, which means the read-write control for memory doesn't matter either. And ALU doesn't matter. All right. Should we move on and try to do one more quickly? All right, so the next one, I think, actually, 2PASS process had slightly more. So let me do 2PASS process for the assembler. So let me just find the assembly summary. All right, so remember what the assembler is doing is going through your code one time, line by line, top to bottom, and generating what we call a symbol table. So for every label that you make up in your assembly program, the assembler says, well, let me start. Let's see, you told me ORJ 3000. First thing I see is at 3000. That's a one memory location instruction. The next one's at 3001. The next one's at 3002. It just counts, right? So it goes down, blah, blah, blah, blah, finds a label, foo. Okay, foo is at whatever that current address is. And it puts that in the symbol table. So it makes a symbol table in the first pass. That's all it does. It also checks as much as it can for you. So if it sees that you've tried to do the multiply instruction, it'll say, ah, there's no multiply instruction in LC3. That's bad. It'll tell you as soon as it can when it sees something wrong. If you see R42, hey, I want to put an R42, R9, whatever, right, something that doesn't exist, it'll tell you that doesn't exist. If you try to do a load from, well, let's say an add. Let's say you try to add 300. You can't add 300 in LC3. It'll tell you. You can't do this, right? So any bad operands, wrong kind of operands, wrong mnemonics, things like that, it'll tell you in the first pass. The other thing it can tell you is if you try to define the same label in two different places. And it's already in the symbol table, so the second time it sees it, it says, hey, that's already there. It can't add it. So it'll tell you, okay, too many. Those are the kinds of mistakes it'll tell you in the first pass. Then it says, okay, I got the symbol table. Let me go through the code again. Count from the beginning again. And now when I see something like branch NZ to done, well, then I can say, well, where is done? I'll go look in the symbol table. And if I find it in the symbol table, then I can get the address for the label, can subtract it from my address with the right arithmetic for PC plus one, et cetera, and generate the offset. Now, if that offset is then bigger than the nine bit value I can use for a branch, well, it just gives up and gives you an error. If you say, hey, branch 5,000 locations away. Sorry, that's not an LC3 instruction. So you can get a couple kinds of mistakes. One is, well, it didn't find the label in the table. The symbol table doesn't have that label. So where should it go? It's not going to guess. It'll just tell you, okay, you didn't define a label. Or the target address is too far away. So those are the mistakes you can get in the second pass. How do you undefine? No, you can't, because the assembler just scans from top to bottom. And so the label might be defined later. And it can't know. So if it goes and looks in the table for the label in the first pass, and it doesn't find it, well, is that because the label's below it? Or is that because the label doesn't exist? You can't know until later. So it doesn't try to make a guess. It doesn't try to wait until it finishes the file. It just says, well, we'll figure it out in the second pass. So that's why the undefined label only shows up in the second pass. Yeah. I'm sorry, if it does it, then? It looks for the definition of the label to assign the address. Yeah, yeah. I mean, until it finds the definition, the place on the left side is where you define the label. Yeah, the use of the labels might happen many times. Yeah, but the left side of it. So the reason it's in order is because as it finds them in order, it puts them in the symbol table in order. And then, yeah, I think it pretty sure it prints them out in address order in the LC3 symbol table. Yeah. I mean, sometimes some tools will do things like alphabetize your labels, right? Because maybe that's easier for some people to read or something. Okay. Any other closing questions? Okay. So hopefully see you next Wednesday. Thanks. Or next Tuesday, even, for office hours. Don't forget to go get some cookies and hot chocolate. Thanks. Bye. Bye. Bye. Bye. Bye. Bye.\",\n",
       " \"pushed back, so 2 to 4 instead of 1 to 3. I think you got your midterms back, so if you want to chat with me, feel free to come by. We're going to start sequential logic today, talking about how we store a bit. So we'll look at a gated D-latch, and then we'll look at flip-flops, going into talking about digital time and the clock abstraction in all of the sequential systems that we'll look at, including the computer. I'll tell you more about that when we get there. We'll spend a little time talking about timing issues. In particular, take a look at static hazards and how we can fix them in two-level logic. That's all beyond the scope of the class, so that whole section is just so you understand a little more about timing. In our class, we're going to just sweep timing under the rug, and you won't have to worry about it too much. But it's good to know for later. In 385, you'll have to learn a little bit about it. And if you go into hardware design, it's a little bit more complicated. And if you go into hardware design, you'll have to understand it a little more deeply. But a lot of what people do these days is one common clock and let the circuits people worry about clock skew. So we'll see that and write it off and then move on to the easy stuff with our class. And then we'll talk about registers. So these four topics are supposed to carry us all the way through the end of the day on Wednesday. So we may or may not start serialization on Wednesday and move into part three of the class. This will be it for the second midterm. So basically, this stuff will define the second midterm, which I think is still two weeks out. That's right. Two weeks from tomorrow, maybe. Sounds about right. So that's the plan. So so far, we've talked just about what we call combinational logic. So the idea is that we have the following type of problem. So I give you some bits, A, B, whatever. And we want to combine them using Boolean expressions to produce some other bits. And so we have some input bits, we have some output bits. And we've learned, well, how do you make circuits that do that? We've learned a bunch of ways. We can go down to KMAPs, build them out of NAND, NOR gates, AND, OR, NOT. We can build them out of components like adders, comparators. But where do those bits actually come from? So that we haven't talked about it all yet. So where are these bits coming from? They've just been magically appearing as inputs to our circuits. So now we're going to say, well, how can we actually store a bit? When you have stored bits, instead of combinational logic, you have something called sequential logic, which is actually much, much more complicated to test and debug. Sequential logic stores bits as state. So there are going to be bits now somewhere in our system. We'll show you today how you store them using transistors again, of course. But sequential logic stores bits as state, and its behavior actually depends on those bits. So what a sequential circuit does depends on what the state of the bits is. That's what makes it so hard. Because you can imagine, today's modern processors might have hundreds of thousands of flip-flops, so the state of that chip is 2 to the 100,000, roughly. That's a big number. So you're never going to run through all those states. That's bigger than the number of electrons in the universe, et cetera. You're never going to test it fully. Even, actually, another good example that I steal from Janak Patel, if you think about a 64-bit adder, you think, well, surely they test the adder before they give it to me in the processor. Well, if you have two 64-bit values, that's 2 to the 128 different patterns. So they don't test all patterns for your adder. They can't. So they have to think of better ways to test things. For an adder, it's actually not that hard to come up with a good set of what we call test vectors. But the sequential circuits are actually pretty difficult to test. So we'll start thinking about these. But just like a C program can depend on the state of its variables, the sequential circuit's behavior will depend on the state, which is the values of the stored bits. So what's a one-input NAND gate? Wow, you know this stuff. OK, there's a circuit. What's it do? Stores a bit. Yeah, OK. But it doesn't have any input. I mean, can you prove that it stores a bit? What would you do? Go ahead. Test it. Yeah, unfortunately, there's just some squiggles on a PowerPoint slide. So how are we going to test it? When in doubt, go to truth table. Good. All right, so here's a truth table. It has no inputs, right? There's no inputs to the circuit. So to fill in our truth table, we'll just make a guess. We'll just say, OK, how about if Q equals 0? So pick a value. So Q equals 0. Put it in the table. So what does that mean about P if Q is 0? P is 1, right? Because it goes through an inverter, comes out at the 1. Good. And if P is 1, what does that imply about Q? Q is 0. It's important that you go through all the way and check that, because there are plenty of circuits where some states may not be stable. This is called a stable state. But some states might not be stable, and some circuits might have no stable states. So for example, if I were to put three inverters in a loop, it would have no stable states. That's a design called a ring oscillator. It's used to produce oscillating signals on chips. People actually use it, but it's an analog system, basically. It's beyond the scope of what we'll look at in our class. But if I draw that for you and I say, well, what are the stable states? You should say, well, there are no stable states. It's an oscillator. It just oscillates. So here's the stable state, 0 and 1. But we picked Q equals 0, right? So what happens if Q equals 1? Yeah, P equals 0. So we'll fill that in. And then, of course, we should check again. What does P imply for Q? Q equals 1 again. So that's a second stable state. So this two-inverter loop has two stable states. So we call it a bistable element, because there are two stable states. And bi, you probably remember that prefix, means two. So all of the bits on your chip are typically stored using this kind of dual inverter loop. So if you have 100,000 bits on your chip, there are at least 100,000 of these dual inverter loops sitting somewhere on the chip storing those bits. Well, OK, so that's cool. But how do we set it? I want to put a 0. What do I do? India? Is that an input? OK, there's an input, s bar. So what happens when s bar is 1? Really? So remember, that's an AND gate followed by a NOT. So if you put a 1 into an AND, what does it do? It depends what the other one is, right? 1 and something is something. So in other words, if s bar equals 1, it's just like we didn't add anything, right? Has the same behavior as before. So we can draw a truth table and say, well, if s bar equals 1, we've got the same truth table as we did before, two different rows by stable states. So again, if this s bar equals 1, 1 ANDed with something is just this something. And so this happens to be an AND instead of an AND, but the property of this part of the gate is the same, right? So now we've just got our dual inverter loop. The green part is our old truth table from the previous slide. And when s bar equals 1, s bar does nothing. What about s bar equals 0? Yeah, so that will force q equal to 1, right? Because 0 going into an AND gives me 0, NOT gives me a 1. And p equals 0 then, right? So in other words, s sets the bit q to 1. So the name s stands for set. So you want to set your bit to 1, then you put s bar to 0. Why is it called s bar? So we call it s bar because the action, meaning set the bit q, happens when s bar is 0. So it's called an active low input. So you've probably already seen this on some of the components in the lab. Anytime the input's activity, whether it's setting the bit, resetting the bit, doing something else, happens when you set the input to 0, we say it's an active low input. And usually we label them with bars or primes in order to tell the human, if you want to do this thing that the input's supposed to do for you, put a 0 in. You don't want that to happen, put a 1. You can also, of course, have active high inputs. So I think in the lecture notes on the wiki, you'll see the opposite design using NOR gates. So this one uses NAND gates. If you use NOR gates, you'll have active high inputs. So you can do it both ways. We'll look at the active low inputs. All right, so we can set q equal to 1. What if we want q equal to 0? Just turn it on and off. Eventually it'll be a 0, maybe. What should we do? Yeah, put another input. Maybe we'll call it a different name. Maybe call it R-bar for reset. What happens when R-bar is 1? Yeah, same thing, right? It's an AND gate. If you put a 1 into it, whatever was there before is still there. So 1 has no effect. So if you put R-bar equals 1 in this truth table, the rest of your truth table looks just like it did on the last slide, including all the S-bars. So we're just making our truth table bigger, but we still have exactly the same behavior as we did before. And I didn't highlight it, but this part down here, the lower right four boxes, that's just the original dual inverter loop, when both R-bar and S-bar are equal to 1. So what if R-bar is 0 and S-bar is 1? So S-bar is 1, so we can ignore that input. R-bar is 0. What does that imply? P is 1, right? And then Q is 0, right? Because we put a 1 here, S-bar is 1. 1 and 1 is 1 inverted. Q is 0. OK, so S, I'm sorry, the R-bar input resets the bit. That's where the name comes from. It's the reset input. Yeah, go ahead. AUDIENCE 2 If you're pushing an R-bar, does that mean you're using the same bit? Or is it just a function? Is it just a function? Is it just a function? No, it means when you put a 0, it resets. When you put a 0, it sets. It's active low inputs. AUDIENCE 2 But if you put an R-bar, actually, so the reason they're named this way is actually because of the sense of the input. So there's no inverter. I mean, it's the circuit you see here. And when it's a 0, it performs the activity, either set or reset the stored bit, which is Q. Considered to be Q. Yeah, good question. Wait one slide. S and R at the same time. Daniel? Yeah, so if you were to use NOR gates, then a 0 would have no effect on the OR. And so the low input would have no effect. And a 1 input would cause something to happen. It would cause the inversion and force the output of Q to be 0 in this case. So if you used a NOR here, then this would be the reset input. And this would be the set input to go the other way. And I think there's a picture of that in the notes connected from the Wiki. Almost, yeah. So the question is, is this why we've assumed in the past that inverted inputs are free? And the answer is yes, that since we're always storing bits in dual inverter loops, and eventually Q and P will always be complements of each other, then if you want the complement of Q, we'll just pull it off of this one. It will be in a second. Right now, it's because they're actually not always complements, as you'll see on the next slide. That's why I kept it as P for now. Good question. OK, ready to go to the next slide, answer Mohammad's question? All right, so actually one more slide. I'm sorry, two slides. So this circuit has a name. It's an R bar S bar latch. SR latch is with the NOR gates. This is R bar S bar latch. So we'll store a 1 bit by lowering S to 0, store a 0 bit by lowering R bar to 0. And so here's Mohammad's question. So what if we set both S bar and R bar to 0 at the same time? So what happens? So S bar is 0, R bar is 0. What's Q? 1, right? Because S bar is 0 forces Q to 1. What's P? 1, 1, 1. So that's why I left it as P, because they're not actually forced to be opposites in the R bar S bar latch. So you can do that. It's not going to hurt anything as is. The problem is now, depending which of those two inputs, S bar or R bar, you let go up first, you'll get one or the other bits. Unfortunately, if you let them go up back to high voltage close enough in time, your loop may settle into what we call a metastable state, where it's not actually any more digital voltage. So it's hovering somewhere around the VDD over 2 mark on both of the outputs. And so it's meaningless digitally. It's still an analog circuit. Electrons will move around. But what behavior it has is no longer something you can easily analyze. So don't lower both at once. You've probably heard the joke, right? The patient goes to the doctor. Doctor, my head hurts when I push on it. Don't push on it. So seriously, I mean, when you use S bar, R bar latches, then you just don't do this. You control it in a way that you simply don't do this. So on the other hand, we can also add some more NAND gates to keep ourselves from doing it. So here's a couple of NAND gates and a D input. So what effect does this have? So if I put, let's see, let's check the truth table. So if I put a D equals 0, then what is R bar? So 0, 1 here, 0 here, right? OK, so D equals 0 means R bar equals 0. What about S bar? 1, so 0, 1. So if I put R bar 0 and S bar 1, what are Q and P? So I think I had 0 here, you said, right? So 0 and R bar, so that resets Q to 0, and then P should be 1. Oh, I did it one at a time. Sorry. OK. So let's make sure we understand this. So R bar is 0, S bar is 1. So when R bar is 0, that forces P to 1, and P is 1. So that forces Q to 0, because S bar is also 1. Make sense? The same thing with Q. So Q is 1. Make sense? The same truth table as before. OK. Whoops, I went too far. OK, so when D is 1, again, two inverters here. So R bar is 1, S bar is what? 0. So what is Q? 1, because it's being forced to be set. And then P is what? 0. Good. All right, so now we can avoid the state. We wanted to not have the 0, 0 state on R bar, S bar. Yeah, Eric? Well, you can see D gets copied to Q, right? D copied to Q. D copied to Q. Yeah. Yeah. Oh, so where did D come from? Well, but this lets us store D, right? D gets stored in our dual inverter loop. So you're saying we could simplify this? OK, let's try to simplify this. You're right. It does the same thing. Good call. Good call. That's a good call. Hey, we saved ourselves some gates. Yeah, maybe it's not quite doing what we want, huh? Because it's always copying D to Q, right? If we look back at this, it always copies D to Q. This is a complete truth table, right? We didn't leave anything out. If D is 0, Q is 0. Yeah. Yeah, I evilly plan to add inputs there. That's a good question. So in order to prevent that nice wire-like behavior, instead, let's add some inputs. So there's some more inputs. So now it's not a wire anymore. It is a wire sometimes. So when right-enable, this thing down here, WE, right-enable, is equal to 1, it's still a wire. So when right-enable is 1, it copies from D to Q. Copies from D to Q when right-enable is 1. What happens when right-enable is 0? So right-enable 0 here, what's S bar? 1, 0 here, 1. So R bar and S bar are both 1. So in that case, so here I've used, hopefully you remember, but I'll remind you, here, I don't care what D is when right-enable is 0. So these are actually, each of these lines is like two lines in the truth table. So it doesn't matter what D is. When right-enable is 0, R bar and S bar are both 1. And I can either store a 0 or I can store a 1. Whatever the last value of D is, when right-enable goes down to 0, it keeps that value. Yes, Rob? AUDIENCE 1. So I can store a bit as long as I want? Yeah, so when you lower right-enable, then this holds a bit as long as you keep right-enable low. Yes. So this will store a bit as long as you want, until you set right-enable high, at which point it copies again. Yes. Yes, and as you'll see, we're going to use a clock signal to drive this down. Yes. Yes. Yeah, yeah. So the point that matters in time, and again, we're not going to do much with timing in our class, but the point that matters is what's the value of D when you switch right-enable from 1 to 0. That's the value that will continue to be stored. Yes, the question is, can you store only one bit? Yeah, you can only have 0, 1, or 1, 0. Yeah. Yeah, yeah, this thing, if you're not careful, can be metastable in most modern processes. So you do want to keep it away from that. Yeah, so most of the time, in fact, these will be initialized to keep them from being initialized into metastable states. When I mentioned flipping the power on and off, in most modern processes, you won't necessarily land in 0, 1. You might land in a metastable state. So typically, the flip-flops will be forcibly initialized to 0, 1 when you turn the power on. OK, so there's a gated D-latch. So remember, if I give you the picture again, yeah, there it is. So here's the gated D-latch inside. And then what that looks like, it's actually a little simpler in practice. This is how they used to be built. But you can do it with fewer transistors if you're willing to design at the transistor level. So this design is maybe actually roughly 2x as big as the real one. But you can think of it this way. It's how it works. And symbolically, we draw it this way. So it's just a box with a D input for the D, a right-naval input, and then Q and Q-bar. So now we're labeling them as Q and Q-bar because they're always opposites. So this is, in fact, where the, I think I mentioned it on a later slide, since Sasha already asked about it. This is why when we talked about evaluating the cost of combinational logic for delay in area, we said, well, let's just not count inverters on the literals. Because if your bits are coming from latches or from the flip-flops that we'll design in a minute, then if you want the complemented literal, you just take a different wire. You don't need an inverter physically. You just take the other wire coming from the other part of the two-inverter loop. So that's why we said they were free. OK, so any more questions on latches before we? Yeah. How do you? Yeah, so I mean, the same way you're doing in the lab now, on paper, we just draw the wire to the correct output of the latch or the flip-flop. So you draw it either to Q or to Q-bar. In the tool, you would do the same thing, and that would become a physical wire in your circuit. It would be a piece of copper sitting on a chip or some other metal maybe in the future. So these are active logic. So the question is, how long will these store bits? As long as you keep the power on, they'll store the same bit. Cosmic ray strikes can flip the bit because they can move electrons around. But for the most part, active logic is pretty robust. Because if you think back to what's going on inside these gates, we're actually connecting the high voltage in ground. So there's a constant influx. If there's any variation in the output voltage, this is connected. If this is storing a 1, for example, this is connected directly to high voltage through a transistor that's turned on. And the transistor is turned on because this one is at low. So to flip them, you actually have to do a little bit of work. And that's one reason that the real design provides electrical isolation also and uses pure transistors. Because otherwise, you have to actually, this design is good enough. But the feedback here, when we look at real memory cells, then there's some analog issues for overriding the paths inside through the transistors and avoiding creating shorts from high voltage to ground when you're switching bits. But in here, these are actively connected through the transistors. When it's storing a 1, it's actively connected to high voltage. When it's storing a 0, it's actively connected to ground. So it's rather difficult to make them flip accidentally. Why is not 0 D? And why is that so? So the question is, why does D not matter when right-naval is 0? So look at right-naval. If right-naval is 0, you get a 0 going into a NAND gate. So 0 and whatever is 0. NAND is 1. So right-naval, R-bar is 1 if right-naval is 0. Similarly, S-bar is 1 whenever right-naval is 0. I think we had that on the, oops. Sorry about that. Let me skip out of this. Oops. Here's our full truth table for this one. So when right-naval is 0, R-bar and S-bar are both 1. And in that case, you can store a bit using the bistable nature of the dual inverter loop. So in that case, D doesn't matter. It doesn't have any impact, because right-naval is 0 forces both R-bar and S-bar to 1 all by itself. So while right-naval is 1, you put whatever value you want to store on D. And that gets copied to Q. It acts like a wire. So you copy from D to Q while right-naval is 1. And then before you change D, you turn right-naval from 1 down to 0. And now it stores whatever bit you put there. Yes. Yeah. And once right-naval is 0, Q and P will not change again until you change right-naval back to 1. Any other questions on the latch before we move on? Yeah. So permanent storage is probably outside of the scope of what I want to talk about now. I can talk about it after class if you want, during office hours. Yeah. Yeah, they're usually magnetic or quantum well-based or things like that. Yeah. Or glass, anisotropic glass for CDs and DVDs. All right, so a lot of high-speed designs will actually use latches like this directly. So what do they do? They'll have latches that will store some of your bits. And then you'll use those latches as inputs to your combinational logic. From your combinational logic, you'll produce outputs. Those will get stored in some other latches and so forth. And eventually, those will come back and make a loop. So between sets of latches, you'll have combinational logic. And as you'll see, we'll flip the sense of the right-naval on the two latches. So this is where I was going to explain what I've already mentioned, which is this is why complemented literals are free. You can see into the combinational logic, you have both the Q and the Q bar from all of your latches. So you don't need inverters to get the Q bars. You just connect to the right place. All right, so clock signal, then, is idealized as a square wave. So we're going to use that square wave to drive the right-naval of our latches. So what is a square wave? So it's basically, if you have a 4 gigahertz clock, that means your period is a quarter of a nanosecond. So you've got 1 eighth of a nanosecond at zero voltage, 1 eighth of a nanosecond at VDD, and then that repeats. Let me show you what that looks like. It's something like this. It's a little faster at 4 gigahertz, but roughly like that. All right, so you have this kind of signal. And this is what we're feeding into our right-naval. So here, we alternate that clock signal to have the low and high phases of the clock drive alternating sets of latches. So for example, we might put the, when the clock is low, this set of latches will copy values from D to Q. And when the clock is high, so this copies from D to Q when clock is zero. And this set of latches over here will copy from D to Q when clock is 1. So in the first half of the clock cycle, whatever logic came before this is actually outputting its values and getting copied into this set of latches. But this set of latches, while the clock is low, is ignoring this combinational logic. Then when the clock changes from low to high, whatever values were here are copied into these latches. In the meantime, these latches are now ignoring their inputs while the clock is high. So they basically just shift back and forth with the clock. So in the low cycle, half of your logic is working in the high part of the clock. The other half is working. So the clock frequency is then limited by this logic delay. So before when we said, well, how many gate delays is something? Well, if it's five gate delays, then you can have a faster clock cycle than if it's 10 or 20 or 100 gate delays. So if you want to have a very fast clock, like a few gigahertz clock, you have to be careful about how many gate delays you have in your combinational logic. So that's where your clock speed limit comes from, is this notion of delay in your logic and being able to take the latch values here, calculate whatever Boolean expressions you want, and latch them into these latches here. These days, a lot of the chips will start to have different what we call clock domains, which means just different clock speeds. Historically, though, and still for almost all embedded systems and even a lot of processors, there's just one clock domain for the whole chip. Modula may be some I-O to the outside world. A lot of systems are just one clock domain, and for our class, certainly, you're just assuming one common clock. Good question. So the question is, how do you pick your clock speed, I think? So that's kind of a complicated answer. If you're doing something like an FPGA design, the tool will tell you what it thinks can work. But really, until you test it, you're not sure if it works. Often, it will sort of overestimate, and then you have to make it run more slowly. In practice, also, so you probably know that if you go out and buy a processor, you can get the 4.2 gigahertz, you can get the 4 gigahertz, you can get the 3.8 gigahertz, et cetera. Those are actually the same chip. So what companies like Intel do is they build the same chip, and then there's process variation. So one chip might be OK at 4.2 gigahertz. Another chip, if you run it over 3.5, it'll just break at some point, some point soon after 3.5. And so they do what's called speed binning. And they take all their chips, and they go see how fast they can run each one of them. And then if it's faster, they charge you more money. Oh. Oh. Oh. And that's why I have it. Has anyone overclocked your processor? OK. Wow. OK. So that's why it works, right? Because the bins, they have like four, six, or eight bins maybe. But of course, the answer is continuous, right? So given any bin, probably you can afford to go a little bit faster. You probably can't go to the next bin speed without running into problems. But you can go a little bit faster and overclock your processor and make it a little bit better. Yeah. It can be. Yeah. Yeah, at some point, there is basically an oscillator on the chip or several oscillators on the chip that are generating, or from off chip that are generating clock signals. And then there's also you have to distribute the clock. We won't spend much time at all here. But the reason I'm willing to kind of talk about it a little bit is because you should be aware that distributing the clock is a hard problem, right? And we make the circuits people deal with it so that we can have an easy abstraction, not only in our class, but also people who are designing chips. Is that a modern thought? I don't think so anymore, but I'm not sure. I'm not sure. I'd have to look at specific design. Yeah. Yeah. Yeah, I can't remember. But it should be. Yeah. Yeah, it should be. Yeah, so this, right. So once these values have been set, you have basically half of a clock cycle from when this value becomes visible until this one is going to copy, right, because the clock changed. So you have to split your logic up so that it finishes within the part of the clock cycle that's allocated to you. It's actually a much more complicated game than that, because really, through two sets of latches, that has to complete in one clock cycle. So you can have it be 2 thirds and 1 third, for example. So people do play games like that, but it's kind of beyond the scope of our class. You think of it as you need to finish. This logic has to finish in time for the next half of the clock cycle, because as soon as the clock changes, this latch will start copying from the output. And so if you make this delay too long, the answer won't be there. So if it takes 10 gate delays and your clock is such that it changes after eight gate delays, for some of the input-to-output paths, you simply won't have the right answer. Yeah. So if it's fast enough, extra delay doesn't matter. But the problem is when it's too slow. And so that's why, when you overclock, at some point, the clock is too fast for the logic. Yeah, I mean, well, or you'll get mistakes in what's going on in your processor, which sometimes you might be able to stand a few of those, but usually things will crash. So yeah, that's a good question, although it's getting into some things you'll start to see in 110, I think. And you'll definitely see in 210 and later circuits classes. The higher the voltage, the faster the electrons are going to move. And it's electric field. And so you need a certain number of electrons to fill the wire to bring the other voltage up. And so the faster they move, the sooner that happens. The higher your voltages are, the sooner your outputs will change. So if you raise the voltage, it'll go faster. But there's limits to that, too. Because then the next one, if it's at a higher voltage, it takes more electrons to bring it back down. So sometimes it works. And then if you go too far, it doesn't work anymore. It's a fairly complicated set of equations. It's way beyond our class stuff. So talk to me after class. Yes, at some point, you will use flip-flops to implement a finite state machine in your lab to control a coin machine. And you're building towards that already in the labs. Yeah, usually they'll ramp it up until it fails. And then they'll sell it at whatever the highest one at which it worked was. So the latch is what I've shown you in a flip-flop. I haven't shown you yet. So let's go do that. OK, so yeah, so this is just some comments on reality. So the clock is not really a square wave, because square waves don't exist. Things never happen instantaneously. So the sharp edges just don't happen. Getting it to all the latches at the same time, also, same time is not even meaningful. So we'll use a simpler abstraction than dealing with latches and combinational logic between them. But the problem of clock skew, getting the timing of all the clock edges to the latches or flip-flops at the same time, it's a hard problem. We're going to leave it to the circuit designers. So what we will use is what's called a flip-flop, which is this design here. So you can see I've built it out of two latches. So we're not going to allow any logic in the middle here. So we're only going to have logic between flip-flops. So we'll have pairs of levels of latches where each pair, each other pair, has no logic in between. So it's just back-to-back latches. And we'll have the clock signal inverted here so that, just like I showed you in the previous diagram, this latch copies from D to Q when the clock is 0. This one copies from D to Q when the clock is 1. So this is a flip-flop. This is, in particular, what we call a master-slave implementation of a positive edge-triggered D flip-flop. So where's the name come from? The master-slave part is because we have two gated D latches. So one is the master, one is the slave. The positive, oh, and also I wanted you to notice this. So on the flip-flop, the difference is instead of right navel, we put this little triangle, which means clock. So you put the clock input there. So where does the name come from? Flip-flop stores a bit and changes once each clock cycle. So every clock cycle, the flip-flop will take one new value, and that's it. It doesn't bounce around. It just changes once each clock cycle. A D flip-flop accepts the bit to store using a data input. There are other types of flip-flops. We're only going to use D flip-flops in our class. So you tell it, here's the bit I want to store. Once per clock cycle, it'll copy from its D input to its stored bit, and it'll then put the stored bit out for a full clock cycle. The positive edge-triggered means that the flip-flop's value actually changes on the rising edge of the clock. So when the clock goes from 0 to 1, that's the moment that the flip-flop copies from D to Q. So that's the meaning of this flip-flop, and the design is what I showed you. So what does our use of flip-flops and ignoring clocks to imply? It's discrete time. So for the purpose of our class, time is not a continuous number for our system. It's clock cycle 1, clock cycle 2, and so forth. So each clock cycle is one unit of time, and time is an integer. The flip-flops copy their D inputs to their Q outputs on the rising edge of the clock, and then between integer values of time, we just assume nothing changes. So for all the designs we're going to look at, nothing happens between clock cycle to clock cycle. Everything happens on the rising edge of the clock, so time is discrete. It's a lot easier model to deal with. The circuits people still have to deal with timing and clock scheme, but we don't. Yeah, that depends really strongly on what you're trying to build and what technology you're using. So gigahertz clocks have been around in different technologies for 35 or more years. The first craze to use gigahertz clocks, I think, were mid-'80s to late-'80s. The alpha processors that came out in the early-'90s were gigahertz clocks. The x86 designs, when did they start hitting gigahertz rates? Maybe around mid-'90s to late-'90s. And then power started to be the limiting resource in the early 2000s. So even though we could build faster clocks, the clock speed has actually gone down a little bit in the last 10 years or so, mostly because of power issues. People want to use less energy. Yeah, so that's gigahertz speeds on your typical, your phone is probably gigahertz processor, your laptop, desktop are all gigahertz processors. In contrast, if you look at a small embedded system, you might want to use very, very low power, in which case you might have a 250 megahertz clock or something like that. You can get even slower clocks, and they'll use much less power. So it really depends on the context in which you're asking the question. In the lab, they're going to be pretty slow, too. Yeah. Yeah, so the flip-flop is basically a simplification from the latches. So it's the same thing. It's going to store bits for us, and it's only going to change once per cycle. So it's going to give us this discrete time abstraction at this point x. All right, so remember, in the previous diagrams, I said, OK, we're going to have latch, combinational logic latch, combinational logic latch, and so forth. In the flip-flop, every other level of combinational logic I'm going to reduce to 0. So between the 0 right-naval latches and the 1 right-naval latches, I'll just cross out this combinational logic, and all of my combinational logic will be in alternating levels. Make sense? Yeah. OK, so this one was copying on 0s on clock 0. This was on 1. This was on 0. So instead of having every pair of every alternating set of latches potentially of combinational logic, I'm simply putting these things in a box and putting all my logic between this kind and the next kind. So this has been a flip-flop. So now things only change once per cycle. Instead of worrying about, well, which of the latches are changing when clock is high, which are changing when clock is low, and having different types of latches in my system and worrying about that, I simply make all of my logic go between the path on the rising edge of the clock. Everything changes on the rising edge of the clock. And I don't have to think about latches. I'll do this. Yeah. There are gate delays between. I mean, it takes time for the flip-flop to see the value on the input, and it takes time to get it to the output. So we'll look at that when we start to use them. We'll think about that. Ideally, no. You idealize it as clock is a square wave, flip-flops are instantaneous. And they're designed to have some reasonable flexibility. But in terms of analyzing the gate delays, you have to have a few gate delays for your flip-flops to act as well. Yeah, it's relatively fast. It's just a couple gate delays. But it adds. If you're trying to drive your clock to, say, five gate delays and your flip-flops take two of them or four of them, it's not so short. You only get what's left for your combinational logic. Yeah. Depends how fast you're trying to drive your clock. Yes, but with the flip-flop, again, all of the flip-flops we'll use will change their value simultaneously, because we assume common clock and we ignore clock skew, on the rising edge of the clock. So once per cycle, everything will change. So it's discrete time. So it's a little simpler to think. No, these latches change when clock is zero. These latches change when clock is one. Yeah, these change with zero. Yeah, so then you have to know which kind of latch is changing when. So it's more complicated to reason about. Yeah. A comment, though, for not using combinational logic. Not inside the flip-flop. Yeah. Yeah, so that's what I crossed out here. And that's what I highlighted on the flip-flop diagram here. So before, these two latches, we'd say, oh, well, I want to put some logic here. But we're not going to do that. Yeah, so there will be combinational logic here and combinational logic there. And this combinational logic has to settle before the rising clock edge. And whatever we put here has to settle before the next rising clock edge for the next flip-flop. All right. So free time, simplifying. All right. So here's a timing diagram. I wanted to just show you how it works inside and also show you what kind of behavior it ignores. So here, initially, the data input is high. The internal input is high because the clock is low. So d is being copied to x by the first latch. And the output, so the second latch, also just happens to start low. At the rising clock edge, x will get copied to q. And so q will go high at that point. But also at the rising clock edge, the first latch will stop copying d to x. So there's not much of a margin here. Sorry for that. But you can see d goes down here. But because the clock is high, the first latch ignores d. It doesn't copy to x immediately. Not until the clock goes low does d actually get copied to x again. So when the clock falls, d is copied to x. And x goes down as well. But when the clock falls, the second latch, which copies x to q, stops copying. And so when the clock falls, even though x goes low, q stays high for the full cycle. So until the next rising clock edge, q doesn't change at all. When the rising clock edge comes, look at the value of x, which is the value of d because it's being copied. And then that gets copied to q. So x is copied to q when the clock is high. d is copied to x when the clock is low. Now, you'll notice inside this clock cycle, d actually went up and then went back down. But it got ignored completely. Because, well, not completely. It got copied to x for part of the time. But because it went down before the rising clock edge, x was already low. And so here, at the rising clock edge, we look at x and copy it down here. So x is 0. q is also 0. So even though d went high in the middle, that never showed up on the output of the flip-flop. There are flip-flops that do things that are called things like ones-catching. So if the input ever goes high during that clock cycle, the next output will be a 1, even if it's just for a very short pulse. But the flip-flops we'll use are these positive edge-triggered d flip-flops. So this kind of behavior will never show up on the output. And this kind of behavior makes no sense in discrete time. If I think about this as a discrete time system, only at these dotted lines do I look at what's going on. So at these dotted lines, I say, well, what's d? Oh, it's 1. Copy it there. 1. Here it's 0. 0. Here it's 0. 0. That's it. So that's the simplifying assumption. The only time we ever look at the system is we look at the input to the flip-flop at the discrete time. We copy it to the output. It stays at the output for a full clock cycle. And then we look again, copy it again, stay for a full clock cycle, look again. So it makes analysis and developing, designing the systems much easier. And it will actually work so long as the circuit designers get the clock skew to work. It makes things easier. All right. So all of your designs will be what we call clocked synchronous sequential circuits. So these assume the use of flip-flops and then a common synchronous clock signal. That's what makes them synchronous, is they have a common clock. Latches and flip-flops are what we call sequential feedback circuits. So you should understand how they work. The analysis we did of, OK, draw the truth table, put a value in, see what happens, see what it does. So you should be able to analyze them, but we won't expect you to design any. Actually, not too many people design them anymore. Usually people who are building circuits will actually use what are called standard gate libraries. So there will be people responsible for developing latches and flip-flops for a given process, but there will be relatively few people. And then everyone will simply use their designs and say, OK, I want a latch. I want a flip-flop. And then we'll have a lot of people who will actually design the circuits. And say, OK, I want a latch, I want a flip-flop. Oh, it's getting towards the end of the hour. All right, so instead of going to static hazards, let's just stop there. It's a good time to stop. And we'll talk about hazards and registers on Wednesday. Thanks.\",\n",
       " \"Everything. Okay, I'll put that on the list. But anyone want to be more specific? Eric? C programming? Okay. Yeah. Okay. I'll just put that as IEEE floating point. I'll put to and from and see what... Flowcharts? Flowcharts! Technically, you are not supposed to have to make any flowcharts. I know there was one on the homework, but that's not part of our learning goals for this. Mohammed had one. Where'd he go? But he put his hand down. Okay, yeah. Sure. Sure. Let me add that to C programming. Remember that logical are technically also not part of what you're required to know. So only the bitwise ops, but I'll tell you the difference. Okay. I'll put that also under C. Anything else? Yeah. Sure. Sure. Yeah. Yeah. Yeah. You mean unsigned? Two's complement is a representation. Okay. Oh, I'm sorry. I thought you said versus. Okay. Anything else? Yeah. Okay. Anything else? Yeah. I'll put that with this one and we'll talk more generally about it when we do it. Yeah. Okay. Anything else to put on the list? All right, let's vote. So maybe you can vote as many times as you want, but I'm going to order them numerically from my rough counts, maximum to minimum, and then what we get to, we get to. So how many want to see something about C programming? Okay, I'm going to guesstimate about 60 to 70. 70, okay. IEEE floating point conversion. And it's about 50, I think. Flowcharts? Okay, about 15. Levels of abstraction? About 25 to 30. Two's complement arithmetic and overflow? About 10. And MOSFETs? Okay, about 25 to 30 again. Okay, so let's start with some C programming and then do floating point. All right, so a couple topics on there. Arithmetic versus logical shifts, logical versus bitwise. Before we start, let me just mention the kind of things we want you to be able to do in C. So one is analyze C code. So we'll give you a little program, you take a look at it and understand what it does. I actually didn't bring my computer thinking we were going to do this all on the board. I could pop up and write an example, but probably the best examples at this point would be, you know, they have answers with them in the online tool. So if you didn't do all 14 of them and you want practice on analyzing C code, go there, look at the code, figure out what it does, write your answer in before you pop the answer, because people tend to think they know it when they read the answer. So write down what you really think it does and then push check answer, it'll tell you what the code does. Or answer the question that's there on each of the examples, there are 14 examples. So that's one thing we want you to be able to do. Yeah, that's one. So if you go to my homepage and go down to F16, classes F16, come to the links page for our class, and then the exercise, which is C analysis, the online exercise. So write, you know, math formulas, formula, C. So those are just expressions. And then write conditional. So this is it. And then write loops, for loops. So those are the things that we'd wanted you to be able to do. So let's think of a quick example. So let's say, I think you saw this somewhere already, which I'm worried it's on the homework is due, you turned in that homework. So let's say you want to print, actually, those will get it bitwise too. Let's say you want to print a number as Say you want to print a number as binary in C. There's no percent B for binary. So let's say you want to enter a decimal number And print as binary. For example, So you'd start off, you're always going to start, we usually won't have you write this, but you want to standard IO. And we'll write our main function. What's the first thing we'll do Yeah, declare variables. So let's have We're gonna have to come up and do some more of these. But let's say make an unsigned number instead of a decimal. We'll come back and do some more. Run out of space, though. Okay, so how will I, how will I get the number of the user needs once printed. Yeah, I'll have to scan it. Maybe I should ask them for it first. What do I use to ask them for an F right okay so We've seen more variables later. Fitting. Okay, so just ask them something. What do you want converted and then we'll use scan F. So it should return one. And then we'll use scan F. Fitting. Okay, so just ask them something. What do you want converted and then we'll use scan F. So it should return one. Let's ask for an unsigned number. And what do I, what do I put here. ampersand num right that's where we want to put it. So this scan F. Remember, we'll, we'll wait for the user to type something and they're allowed to type an unsigned number, it'll convert that unsigned number because I said percent you into 32 bit unsigned representation and store that in the variable num. I don't know just did it's going to print in binary. It doesn't really matter. It'll work our code will work with all that usually whenever we do bit rise operators I try to use unsigned because otherwise sometimes it gets a little tricky if you If you do shifts right then you'll get arithmetic shift if you do choose compliment and sometimes you really don't want that cause bugs. Yeah. Yeah. Yeah, to evaluate. So this is a function call. We only showed you print F and scan F, but it has to evaluate the expression. And so when you make a function called part of the expression, it calls that function in order to get the value back. And remember the value that comes back from scan F is the number of things converted for if it fails to convert anything returns minus one. We just write that down. But shouldn't return zero if it doesn't convert anything in the return minus one, which is an error message. Is that legible that big enough. A little bigger. Okay. Okay. Okay, I'll try to write bigger. It just says what I what I said a minute ago, although there are plenty of seats for her. So feel free to come forward. I'll try to write bigger. Alright, so that will do our check for us. And then if that fails, we can just print an error message. I'll just make it something simple. And then just exit program. I don't know, I'll pick three. Okay, so otherwise we have a number. Yeah. Um, maybe. Hey, look at that. Yes, I can. I didn't know I could do that. There's a first time I've used this stuff. I'm not sure if I can do it. Oh, that's it's just the convention a long time ago was zero for success nonzero for for not success. And other than that, there was no convention. My personal convention is three for doing something wrong with a program. So there's no good answer other than don't return zero. That way, whoever started the program knows that the program did not succeed, something like that. Okay, so now we're going to do a little bit of a test run. And so what we'll do, we need to look at the at the top bit first. And then we also want to we also want to go back to the top bit and look at the top bit. And then we're going to do a bit of a test run. Okay, so now we're going to look at the top bit. In order to convert it, we're going to need to use bitwise operators, because we're gonna have to look one bit at a time. And so what we'll do, we need to look at the at the top bit first. And then we also want to We also want to go one step at a time through the 32 bits. I'm just going to assume it's a 32 bit number. I could be a 16 bit number on some platforms, but I'll assume it's 32 So we need to be able to pull out one bit at a time. So first, let me make a loop variable. So I'm just going to make that an int and I'll just call it i, that'll be a loop variable. And we also need a bit that will pull out using a bitwise and will pull out the bit of the number that we want to print. Okay, so we should set that I'll make that an unsigned. I'm going to shift that along step by step. So I found an unsigned. I'll call it mask and I'm going to set it initially equal to the high bit of 32 bit numbers. Okay, so that's the that's the bit 31 if you number them from zero up to 31 that's bit 31 of the unsigned number So now I can do a for loop down here. So how should I make i go from say zero to 31 Okay, so I'll initialize it to zero. And what should my test be So 30 I could do 32 greater than I or I could do 31 greater or equal to I either one's fine and then update I equals I plus one. Good. Okay, so now I will, I will let this this loop execute 32 times And I'll actually have to update mask as well. I'll just do that at the bottom. So in order to tell what kind of thing I have in my number, I need to use a bitwise and I'm going to shift over to another paper and develop the expression. So I have this number and I have a mask. So how do I pull out the corresponding bit of the number What operator Did I use so mask. Remember, just consider the first The first iteration mask is going to be this value. So one bit in there. So if I use what What operator and and right. So if I do a bitwise and between mask and numb. The answer is going to either be zero or it's going to be zero. Or it's going to be equal to mask. There's only one bit on in there. Right. So if I end them together with all the bits 31 out of 32 bits of mask or zero. So the answer 31 out of 32 bits have to be zero. The one bit that said in mask, maybe also a one in number. So the answer will be either be equal to that number up there that big number or it'll be equal to zero. So I can write something Where I say If Zero is not equal to mask and number In that case, then there's a one in that bit position of number. Right. And if that condition is not true, then there's a zero. There's only two possible values for that for that bitwise and it's pulling out one bit. That makes sense. When you do a bitwise and the answer is also in this case are two unsigned. So the answer will be an unsigned with 32 bits in it, but because my and remember this number here if I write it out in binary. There's 28 zeros here. Right. And so if I write out number in binary. I'm sorry. Ah, I have a little preview screen. Okay, so if I write number in binary. Remember bitwise and goes through like this, right. So all of these zeros over here. These all come out as zero. So you've got 31 bits in the mask. And this is the expression value. And this, this one here could be a one. Right. But all the others have to be zero. And so that's how we're looking at just the expression value. And this, this one here could be a one. Right. But all the others have to be zero. And so that's how we're looking at just that one particular bit using the mask. So we have one bit set in the mask. We use a bitwise and the answer is either zero all zero or is that one bit. Okay. Yeah, so it's an unsigned number. It's an unsigned number that happens to have at most one bit set. So it's either zero or not zero. Yes, yeah, yeah, yes, it's an unsigned number still. So it's interpreting it as two to the 31. Okay, but all we care about is zero or not zero, because later we're going to change mask to be a different bit. Alright, so if we find if we find it's not zero, what should we print for that particular bit. A one. So let's print a one. We don't need any format, any format specifiers. We'll just print the number one. And if it's not not zero. In other words, if it is zero, what should we print. Zero. Okay, so that will print one bit of our binary number. So we're going to put that in our loop. And maybe I won't transfer it over. Try to align my papers so you can read it. That legible enough. Okay, so once we're done with that particular bit. Now we're going to need to shift the mask over. So let's print a one. And we're going to print a one. This one. That legible enough. Okay, so once we're done with that particular bit. Now we're going to need to shift the mask over. So what I'll do is mask equals mask. Right shifted by one. Someone asked earlier, why did I use unsigned. So here, for example, if I had used the two's complement number and started with the high bit that would actually be a negative number. And when I right shifted, I would not get bit 30 set, I would get bit 30 and 31 set. Because seeing that it's a the compiler seeing that that was a two's complement number and integer would say, oh, you want an arithmetic right shift when in fact they don't want a logical right shift in this case. For unsigned numbers. Yes. So an unsigned number of the compiler would generate a logical right shift which puts zeros on the left side. If it's an integer, a two's complement number, it will generate an arithmetic right shift and put copy the sign bit on the left side. Because mask is unsigned it inserts zeros on the left. Now that I zoomed. This is legible in the back. I'm sorry. Yeah, thank you. The loop is actually down here. So Yeah, the mask equals was up there. I'm trying to get it all in the slide for you. Okay. Okay. Now we have the whole program. Thanks for that correction. Okay, so now that we've shifted our mask over if we end our loop, then that will change I can come over here for a minute. So we'll go to the next value of I and we will then compare with the next bit by doing another bitwise and after we've shifted mask down and now has bit 30 set So we'll check a bit 30 of the number and print a one or zero corresponding to that bits value, then we'll change mask to be bit 29 I will simply count for us. Once we get 32 of those mask will be down and actually turn to zero. So the other way to finish this loop would be to check when mask gets to zero because you can shift it right off. Shift that one bit right down to the end and out of the number. But once this loop finishes, we'll have printed all 32 of our bits. At that point to be to make it look nice. We might want to print a carriage return. So let's just toss one of those in there. I'm not sure I can fit it all anymore. Let me zoom out a tiny bit. And return zero to say we've succeeded. Okay, so sorry it's not lined up perfectly but Okay, so I think with this example we managed to cover the other topics. Was there anything else on C program. Any people want to talk about or any questions on this code. Why do I, why do I shift mask to the left to the right. So remember that we started mask as the left most bit the high bit. And so by shifting it to the right one step at a time. We're covering every single bit. Starting from bit 31 to 30 to 29. Remember when we write bits out we usually Write them. Sorry, I didn't have any chalk there. Maybe I don't have any chalk period. Okay. When we write bits out, we usually write them as the high bit. Down to Down to bit zero. So when I'm when I'm talking about bit 31 and a 32 bit value. That's the left most bit and then we're shifting to the right down to zero. That's the 32 steps of Yes, absolutely. So the question is, could you instead start with mask equal to one and left shift. The problem is that you probably want the printout the way we did it. Right. So you probably want the high bit first because people will expect to see the number that way. So you could do what you said, but you'd have to store the answer somewhere and then print them out in reverse to make it make sense to the human. Yeah. Yeah, you can do that. But again, that would that would go in the wrong direction. Right. So if you start with a with a low bit. That's the bit you want to print last so you could do it that way without creating a mask. You can also generate the mask on the fly. So you can write Not with the I we have, but you can write one left shifted by 31 minus I. And so if you use this expression, this takes I subtracted from 31. So when I zero that's 31 when I is one it's 30 and then that takes the number one and left shifts it by that much. That's, that's actually the best way to do it. So there are many ways you can solve the problem. Mask was initialized as bit 31 so in hex. It's eight followed by seven zeros. Um, yeah, I mean, do you need if you need to know what on the exam. And, you know, we would, I think we'd give you a hint there. But, but this that's bit 31 right so you can. The easy way to do that is the way that I just wrote it that that way you don't have to remember it. You can write one left shifted by 31 also if you want to initialize You can also write this So, do you need to remember it. No, you can simply write that in the code and the compiler will generate it will solve that without generating structure. Right. Right. Um, yeah. So I think understanding how gates are built is on there right and gates are built out of MOSFET. So to that extent. Yeah, I can't pull it up easily. But does someone have the shirts in there. How gates are how gates are built is not in one six Okay, I can look at it afterwards. It was also low on our topics list. I'm not sure if we're going to get to it. All right. Any other questions on this one. Are you ready to move on. Okay, so we'll check that one off. So I think we're going to I triple E floating point right and someone wanted to start with two and then I'll see how much interest there is in from So, zoom out a little bit. Okay, so remember The high bit in floating point is assigned it Then you have a exponent eight bits. Then you have 23 bits of Ventissa. And except for zero, which is all zero bits. We have possibly either sign all zero except the sign. We have the value is equal to negative one to the sign bit. Times one. This one's implicit Dot mantissa. So this is binary scientific notation times two to the exponent minus 127 You can treat exponent is unsigned. That will give you the right answer. Now there are two corner cases here. One is the one that's not a corner case. So you don't really need to know that except for the fact that there's a zero pattern. So you need to remember that, of course, we have a zero pattern. You can't have an explicit one. Otherwise, you can't write zero. And then the other one is for infinities and nads, right, which you don't need to know. So you can treat the exponent as unsigned. And then you have the value is equal to negative one to the sign bit. So you can treat the exponent as unsigned. And then you have the value is equal to negative one to the sign bit. So you can treat the exponent as unsigned. So in order to find the value just plug into the formula in order to convert to this format, you just write your number in binary scientific notation. So how do you write something in binary scientific notation. This is binary scientific notation. A little more space. Okay, so how do we do that. So say we have a number. Can't do a lot of fractions of powers of two in my head. So let's say we have something like negative 15.625. That one I can do. Okay, so let's say we want to convert this. So the first step is just to break it up into an integer and a fraction. And then we can convert the integer just using unsigned. Remember that the sign is going to go now into the sign bit. And so it's more like sign magnitude than it is like two's complement. Convert the integer using unsigned and then convert the fraction also using unsigned but as a fraction. And then we can put it into binary scientific notation from there. So let's start with the 15. So what's 15 and unsigned. Also, is it odd or even? Odd right so give us a one. So subtract the one divided by two. Is a seven right so odd or even. Seven minus one. Divide by two, we get three also odd three minus one divided by two one also odd. And then we're done right one minus one is zero. So 1111. So there's 15 And what about point 625 How do we do this one again. Multiply by two. So then I multiply by two, I get 1.25. So that's a one right so that'll give me a one and I'll subtract the one off. And multiply by two again. And what do I get 0.5 So that's less than one. So that gives me a zero. So 0.5 minus zero times two is what One gives me a one. One minus one is zero. So we're done. So this one goes this direction. So that's 0.101. Right. So if I put those together. I get 1111.101. So I need to write that in binary scientific notation. So remember how to write scientific notation. You just move the decimal point or in this case, the decimal point. Over after the first number. So we're going to have an exponent of 123. So this is equal to 1.111101 times two, two to the three. And then remember there was a minus sign in front of it, which we'll just put down there. So there's our number. Okay, so now we've converted negative 15 and 0.625 into binary scientific notation. From there, it's relatively simple to just transcribe this sign, this mantissa. Remember the one here is implicit and this exponent into the floating point. So let's go ahead and do that. The tricky part might be converting the number around 128. So what's the sign? 0 or 1? 1, right? Negative. So this is our sign bit. What's the exponent? 130. Right. So here's three. And remember that three is equal to whatever exponent bits are as unsigned minus 127. So what we need to write there is 130. So probably that conversion is a little bit of a pain, honestly, especially if it's small. So let me write it down and then explain. So if it's bigger than 128, remember that's the 128 bit. And so from there, you just need to convert the leftover two, which is down there. So the 128, the two makes 130. So that's our exponent. And then for the mantissa, we simply copy. So remember, this one here is implicit, so we don't write it at all. So the mantissa is these six bits. 111101. And then what? Zeros. So you got six more here, I think. What is that? 186. So 15. So yeah, one more there, I guess. Zero there, and then a lot of zeros down there. Yeah, 17 more. Sorry, I broke it up into two 16 bit chunks, right? But all of the rest are zeros. Yeah. Yeah, so once you've got your two 16 bit chunks, you can go ahead and write your next one. Yeah, so once you've got an in-binary, you mean before or after the binary scientific notation? Okay, so after you've got an in-binary scientific notation, remember from our formula that the actual exponent in binary scientific notation is the exponent bits in the floating point field minus 127. And so basically just invert that formula. Say, well, whatever I'm going to put here minus 127 has to equal my real exponent. So that was what I wrote down at the bottom. I said, okay, the real exponent is three. So whatever bits I write have to be equal to the exponent bits minus 127 have to be equal to three. So just solve that equation, you get exponent bits equals 130. Fill that in. Yeah. Yeah, so IEEE rounds off. You don't really need to understand a lot of the rounding issues. Just understand that it's not exact, right? So it's only 23 bits of precision. There are four rounding modes. The default mode is round to nearest. So whatever the closest answer is, it'll round that last bit off, up or down, depending on which one is closer to the number you're trying to represent. Yeah, so again, by solving this equation, so we saw in the binary scientific notation that the exponent we want is three. And in this form, remember that the exponent bits represented as unsigned minus 127 has to be equal to the real exponent. Yeah, so remember, we wrote it in binary scientific notation. It's right there. Make sense? Okay. Yeah. You need to know that there is a zero pattern, but you don't need to know how to interpret denormalized numbers. So you just need to know there's a zero. Otherwise, it's kind of a weird representation. It can't represent zero. So you should know that. So remember, you'd write it first in scientific notation. So 0.75, the fraction 0.75 is equal to 111. So that's 0.11. But you put that in scientific notation is this. It's not zero in front. Yeah, once it's in scientific notation in normalized form. Yeah. The other direction. Sure, sure, I can do that. You mean write it in decimal? We're not that mean. We're not that mean. If we do that, write it in decimal, it's not zero. It's not zero in front. You mean write it in decimal? We're not that mean. We're not that mean. If we do that, write it as 2 minus 17. But we're not that mean. Yeah. The question was whether we'd ask you to tell us what 2 to the minus 17 is in decimal. No. Because we don't allow calculators on the exam, right? I don't know what 2 to the minus 17 is. Okay. All right. So let me get a feeling. So Sasha, you'd ask that we do one also from the binary into decimal. How many people want to see that at this point? Okay. Okay. Let's just do one then. So. Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? Better? So that to me looks like 11 sixteenths. And I'll cheat. I'm not writing it in decimal. Yeah? So that's 8 sixteenths, 2 sixteenths, and 1 sixteenth. So 11 sixteenths. I don't remember what a sixteenth is. Actually I do. I don't think you should need to. Yeah. Yeah. So I think whichever way you end up doing it just as a fraction is fine. Maybe don't write it as an expression. I mean you might have an integral part and a fractional part. So I mean don't make us solve equations to get it. So you wrote it, yeah. So I think turn it first into, you know, shift the binary point to the right position and then convert that one into integer and fraction. Yeah. I'm sorry, if the exponents were all one? Yeah, the exponents all one, remember, is a special case, but we don't expect you to remember how to use it. It's infinity and not a number. So if the mantis is zero, it's infinity. And if it's non-zero, it's called not a number. But that's more than you need to know for this class. Okay, anyone else for this? All zero bits. Yeah. And well, all zero bits except the sign which could be positive or negative, they're both zero. They're positive and negative zeroes. Anything else? Okay, so with that we finish the folding point. All right, so let me talk a little bit about levels of abstraction. So in Pat and Patel, I mean they don't put the electrons, but down below the devices were electrons. So Okay, so the levels that we'll look at mostly other than the C programming to just give you exposure to the syntax are the hardware levels, the devices, how we build gates, how we then use those gates to build Boolean expressions and then components like adders, which we'll start to look at soon, but are not part of this exam. The micro architecture, which is the way you design a processor out of those. And then the instruction set architecture we'll get to kind of at the end of our class. That's the interface between hardware and software. So that's what tells you what the computer can do with individual instructions. All of the software then has to be compiled when you write C code, it has to be compiled down into computer instructions, or in other languages, there might be another program that actually interprets your language. In that case, that program is written using computer instructions. So the software always has to come down to the level of instructions and then the microprocessor will actually go all the way up to the ISA level in hardware. So the processor in your laptop or in your phone will execute some instruction set architecture and the micro architecture then is just the way of building that. So remember that with a level of abstraction, what you're building, you can build in many different ways. So MOSFETs are one way to build gates. There were other ways to build gates. So historically, there were different transistor technologies that people used to build gates and they built their computers out of those gates. So there are many implementations at every level down. Similarly, the micro architecture, there are many ways to build a particular instruction set architecture. There are different companies that produce x86 processors for your laptops. There are different companies that produce ARM processors for your mobile phones. Those companies don't share their implementation designs. They know the ISA, they support a common ISA, sometimes different ones like ARM or x86, but the companies competing in one space will typically support the same ISA so your software runs on all of their platforms, but they don't share their designs. The designs are the micro architecture, the way of implementing. So the idea with the layer of abstraction is that you provide a certain functionality without telling people how things are built. And so that in the case of the instruction set architecture, what that means is, for encoding in bits of course of instructions, the computer, the micro architecture can execute the intent of those instructions, but you don't tell anyone the details of the implementation. Just like when you build a water faucet, people don't want to know how it works. You want to just be able to get your water out, use a simple interface, you maybe turn it, maybe pull it up, whatever. It's fairly simple. You know how to get the water out without understanding plumbing, without understanding how you make water pressure work. Yeah, absolutely. So there's, I mean, that's how they compete, right? They compete in the metrics we talked about. So area, right? So how big is it? Which means how much does it cost them to actually fabricate the chip? Power and speed. And so speed will determine how fast the processor can run. There's also trade-offs like parallelism for, I mean, this is one we didn't talk about, but how many instructions can they execute at the same time? And so there's that kind of design point, which also affects overall performance. But the raw performance based on gate delays in different parts of their design will also affect their performance. And then power efficiency. So you wouldn't want your typical server processor in your phone because your battery would not last. And so there are different design points there. And they compete in trying to find ways of being better in all of those. Maybe not at the same time. So their designs will have different values in each of those metrics, depending on how they go about building them. So I think understanding the idea of the black box where you've got functionality above and lots of ways to implement and being able to understand that in a way of realizing it. In other words, if we asked you, we might not ask you that question directly. So we could ask you something about whether implementation detail should be exposed or things like that. So let me answer that somewhat obliquely. I mean, in this class, probably not so much. In part of what I said the first day that we're trying to break you gently into the life of an ECE major. So we're shooting for a test average of about 10.5. And we're going to be doing a lot of testing. And we don't want to do this on purpose. We want to make sure that we're trying to break you gently into the life of an ECE major. So we're shooting for test averages like in 80s, whereas my historical average for all the ECE classes was 75. I wasn't really kidding. I mean, I think people didn't do it on purpose, but there have been class averages as low as 30 on exams out of 100. oh my gosh, how am I going to get a 30 on the exam and pass the class? The class is curved. So our class, we're also trying not to curve. The problem with the essay-like questions, I like them a lot. So when you get into later classes, it's a better way to make sure people understand engineering design and trade-offs and things like that. It's much harder to grade. It's also much harder for us to get an 80 average or 85 average. So when you start asking engineering design questions, it's more challenging. So there won't be that many on our exams in this class. But you should expect to see more in later classes, where you really have to integrate the knowledge and be able to answer more open-ended questions. Yeah, so it's a good question. In our class, not so much. But you'll see more in later classes. All right, so was that the people that asked originally about levels of abstraction, you feel like that was enough coverage? Or anything else people want to ask? Yeah, I mean, we also have a, I think the encapsulation idea is probably what they're looking for, whether you have to understand how it works in order to be able to use it. So I think that's the biggest issue, is that you provide that level of isolation, that I can use something, there's a well-defined functionality, without my understanding how it's built. And so that's the value in day-to-day human life, too. A lot of what everyone in the room uses, you probably couldn't build. You might be able to guess at it. You can probably look it up. And as engineers, you can probably even figure out how to do it. But if I just said, here, go play. You don't get to use the internet. Build me a toilet. Are you going to be able to make it work in a way that works nicely? I know I couldn't. But obviously, we know how to use those sorts of things. And so I think it's really the idea that you want to encapsulate something in a way that you really need to know nothing about the implementation. There's a certain functionality that you can expect to use, like a jar or a toilet or a faucet. And there's an interface that we all know how to use, but we don't know how to necessarily develop the implementation. All right, let me spend a little time then on MOSFETs before we finish. So remember, so the main things are two types. So there's P-type. And there's an N-type. The names are for charge carriers, so I'd suggest remembering how things work based on this bubble or no bubble, that the bubble turns on when there's a zero, when a logical zero turns on. And that's because the way the P-type works is there has to be a voltage from these terminals. This voltage is greater or equal to some threshold to turn it on. So if you put zero volts here and then you put high voltage, then that will turn it on. And the only way to turn it on with binary voltage levels is for this one to be zero and then these to be the high voltage. The N-type works with the voltage threshold in the other direction. So the voltage between the gate measured in that direction has to be greater or equal to the threshold to turn on. So you need to put VDD here and then zero volts on one of the terminals. And then the current can flow across the two terminals in that case. And it can pull the other one down to zero volts. In this case, it'll pull it up to VDD. So VDD is a one in binary. Zero volts is ground, is a zero in binary. So that's how they work. And then out of those, we use complementary sets of those, which in the case of the gates we looked at in class was just series and parallel. So we had series. Yeah, I'm sorry. Hold on a second. No, this is someone was pointing this out earlier. We did this after C, right? OK, why am I spending time on this? This is on the next midterm. So you're getting ready too far in advance. Anyway, you will know how to do those one day. Anything else people want to talk about before I stop? Yeah. From decimal to hex through binary. I wouldn't try it without that. It can be minus minus plus. Yeah, yeah, those are the two overflow. If you add plus and minus, it's always OK. It never overflows. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK.\",\n",
       " \"Okay, I think it's three o'clock. So what we're going to do to start off is just finish up error correction and Hamming codes and then sected codes, and then I'll spend the rest of the time just giving you free advice. So I plan to do this anyway, but I was, before I got clobbered by a virus over the weekend, I was going to actually add another piece of material here, but instead we'll do what all the other lectures do and do a review session on Wednesday. So we'll finish all of this stuff up I think today and then on Wednesday we'll do a review session, which is what all the other lectures are doing anyway. I did have to move my office hours. I'm not sure if it was kindness to the instructor or just feeling bad for the students. So when you get to 391 you'll understand you work really hard to do your OS, and right now there are 240 students in there and one professor, and so I felt like they should have some time explaining what cool stuff they did. So I agreed to spend all day Tuesday from eight o'clock in the morning until eight at night talking to students about their projects. So I won't be able to go to office hours. I was going to shift them, but instead the three of us still teaching lectures are going to have office hours on Tuesday, 13 December. I think they're starting at 10 and running till four and mine are in the middle. Mine will be in Daily Byte. Theirs I think are in 3017. There was an announcement on the wiki so you can look up all the details, but the important thing is don't come to Daily Byte looking for me tomorrow. I mean you can try to slip in in the 391 lab if you want, but I'll be there all day. But I will be there next Tuesday from 12 to 2, and I moved it to try not to overlap the final session because I know that some people might have finals starting at 1.30, so you should have some free time in there regardless of your final schedule hopefully. This is yeah, third midterm. Another third midterm. No, this should say final exam. Sorry. So the final exam. Retry. No. The final exam is as you hopefully know Wednesday, 14 December. For those of you that don't know, I guess some of you who are still new to the university, the university tells you at the very beginning of the semester how to map the start, the first time of your class to the final exam time, and most classes will announce time. So I think we announced this at the first day of class and it's been on the web, but for the most part you can figure out your whole schedule at the start of the semester. Anyway ours is Wednesday, 14 December. If that's a conflict for you, and again if you're new you should realize that the university has this niceness clause that says well no one should have to take three finals in a row. And so if you have three finals in a row, including overnight in a row, then the university says you're allowed to take a conflict for one of those. So which one? Well that depends on which classes, et cetera. We have pretty low priority because this is a combined class, right? We have four lectures taking one final. So it's probably going to be our class. But if you have back to back finals, three in a row, you're allowed to take one and take a conflict for it instead. So pay attention to that because otherwise you're, well I don't know, maybe some of you enjoy taking all of your tests in one box, right? Get it done with. But you have that option. So exam coverage, section 4.4, right? Everything since the third midterm in the notes. So section 4.4 is a summary of that. Okay, so again Wednesday will be our review session for the final. We'll spend all day doing that, so come prepared to ask questions. And it'll be on video, so once the final is closer you can go watch it again. Alright, so what's the exam going to be in terms of content? So it is cumulative in the sense that we have one part of seven each on parts one, two, and three of the class. So we'll have one problem on each of those parts, roughly a seventh in terms of points, maybe not exactly. And about four sevenths on the last few weeks, so the material since midterm three. So as you know, things kind of build up, right? If you still don't understand two's complement, then you might get hurt on these two. Alright, so here's where we left off. We were talking about error correction, and I gave you kind of a couple of examples of where it might be important. I don't think I mentioned it's actually now used at pretty much every level of memory hierarchy, even the memories closest to a processor, even on your GPUs. The first generation of graphical processing units didn't have error correction, but people started measuring them in high performance computing and realized, well, they were producing wrong answers often enough that they started putting error detection correction codes. So ECC, as it's called, error correction coding, is now used pretty much in every level of your memory hierarchy. Stronger codes than even the ones we'll talk about are used on disk drives because you have to worry about errors accumulating. And if you're not looking at your bits, then more and more bits will change over time, so the bit error rate goes up. So for the memories and things like that, the codes we'll talk about, like Hamming codes, are what's in use. Alright, so can we correct? I wanted to remind you all, is a Hamming distance code two, like a parity code, is that good enough to correct an error? So this was our 3-bit two's complement with odd parity, so 3-bit two's complement's in black for each of these eight values, and then the odd parity bit's in blue. And of course, if we have one possible error, so if we see this pattern, we know this is not odd parity, right, because it has two ones and two is not an odd number. But that could have been originally the value zero, which is coded this way, and then there was a bit flip that changed this zero to a one, but it's also possible that the original stored value was a one, which is coded this way, and then the parity bit got flipped and it was a one. So we don't know if we see this value, well originally was that a zero or a one. And of course, we can't really make a choice. Making a choice, we have no information other than these four bits. So we don't have any good way to distinguish between those two. So if we have a larger Hamming distance than we can, so this is the three copy code. This is a terribly inefficient code, but it's somewhat intuitive as to why this works. So if you take all your bits and you say, well let me make three copies of them. So here I've done that just with two bits. So three copies of two bits for a two bit unsigned representation. So what's the Hamming distance? Three, right? OK. Yeah, because if you look between any of these patterns, the minimum distance is three. Actually between one and two, the distance is six, right? But what matters for the distance of the code is the minimum distance. And so you can see between zero and one, for example, the distance is three. Between two and three, the distance is three. And then I guess between one and two, it's six, and zero and three, it's six. So depending which way you pick things, you'll get three or six. So the minimum is three. So what happens if one bit flips? This is also things we kind of glanced at quickly last time. If one bit flips, then only one of the three copies can get changed, right? If only one bit flips in the whole thing, that bit has to affect one of our three copies. So that means we can always just vote, and the other two will be their original values, and so they'll always outvote the wrong copy and we'll get the right answer. So what happens if two bits flip? Well, we only have three copies. So if those two bits happen to affect two different copies in the same way, then we're just out of luck. Now if it were a different two bit flips and then we got three different answers, we would know something went wrong, right? But there are cases where only two bits change, and now if we try to vote, well, these two zeros will outvote the two and we'll get the wrong answer, right? So we'll say, oh, you know, we try to correct, and then we'll say, well, this originally was zero, and of course it was two, right? Yeah, so if they were both blue, you would be able to correct, right? So if you flipped the two blue bits, you would be able to correct the answer. That's right. So the answer is sometimes, but in order to have strong error detection or correction properties, you want to be able to detect or correct regardless of which of the bits flip, right? So in this case, you always want to look for the worst case in your analysis. So in this case, the worst case is that the same relative bit in two of the copies flips, and that way you correct incorrectly, which is that red bit. Yeah, Robby? Sorry, that value. So I haven't told you the relationship between Hamming distance and the number of bits that you can correct, but yes, there will be a relationship. Yeah, so all I've shown you so far is that Hamming distance two cannot correct any errors. Hamming distance three can correct one error, but I haven't, I actually haven't even shown you in detail why that's true. So let me, it's a good question. So the question is, what's the overhead for doing this stuff? The overhead's not so big, but let me show you a code that they actually use, and then we can calculate it from there with a concrete code. Yeah, it's, I mean, the short answer is it's roughly logarithmic in the number of bits, right? Which is big if you want to protect two bits at a time, but very small if you have 50 or 100 or something like that. Okay, so, all right, so let's try to generalize a little bit. So let's say that we have a code word C. I want you to define the neighborhood, the K neighborhood around code word C as all of the bit patterns that have Hamming distance of less or equal to K from C. Okay, so this is what you get if you flip up to K bits, right? So if you flip up to K bits from some original pattern C, what you end up with will be in this neighborhood. So you don't flip more than K, you might flip less than K, but regardless of how many from zero to K you flip, whatever bit pattern you end up with will be in this neighborhood. And that's how we define the neighborhood. Yeah, Mohammed? Yeah, but only in chalk right now. I mean, I drew an illustration. I don't know if it will help. Let me, all right, so is it okay if I just start with all zeros? Okay, so for example, the neighborhood here, if you flip one bit, you'll get one of these four patterns. And then if you flip, sorry, I hope those are legible in the back. If you flip a second bit, then you would get 0, 0, 1, 1. So this is flipping a second bit on this one, not the same bit, of course. And then, let's see, this one would also be able to take you to here, but it would have two other patterns, which would be all of, these would all be two 1 bits down here. So all of those bit patterns together would be the two neighborhood around the 0, 0, 0, 0 pattern. So basically, anything you get by flipping up to K bits, any bit pattern you would include in the neighborhood. Yeah? Because that would just, I already have that. So that would just give me an example of, of flipping fewer than, fewer than K bits, or fewer than what I was flipping. Yeah? Purely within memory. So this is the idea that you're storing a bit or transmitting. I mean, it could be a transmission as well. So either I'm storing some bits somewhere, and I put some extra bits, like a parity bit, or for error correction, like a triple code is the only one you've seen so far. Later I look at it again, some of those bits have changed. So that's one model. The other is, I transmit bits to you, but some of those bits are corrupted, and you get them incorrectly. Yeah. Oh, that's way outside the scope. People, people do things like residue computation. So you can, for example, calculate some bits, mod some prime number, and then when you add things together, you can percolate that through your function unit, your adder, or multiplier, whatever, and make sure you get the right residue out. But that's outside the scope of what we're worried about. Those kind of errors are much less frequent anyway. So in practice, those kind of, those kind of capabilities are not on typical processor design. Yeah, it's a good question, but kind of outside what we're doing. Yeah, yeah, so k, it would be anything up to k, so including zero, right? So C itself is in the neighborhood as well. So C is up here. So all of the bit patterns, I didn't draw all of the patterns here, but including C, including everything next to C, one bit off, two spaces away. Okay, so when can we correct errors? So if we assume up to k bits flip in a stored bit pattern to produce a final bit pattern F, we know by the definition of the neighborhood that F is one of the patterns in the neighborhood around, of k bit flips around C, right? So we know F is in there. So when can we, if we know these two things, we know F and we know this neighborhood, when can we say, oh, that must have been C? Well, in order for us to be able to make that deduction, right, we can't make guesses, so unless those neighborhoods don't overlap, then we can't do it, and if they don't overlap, then we can do it, right? We can say, well, which neighborhood did F fall into? That tells us uniquely, well, what is C, as long as those neighborhoods don't overlap. All right, so here's the illustration. So if we want to, if we want to correct k errors, so here's my attempt to illustrate what I drew on the chalkboard there. So you've got some neighborhoods Nk of C, which is all of the up to k bit flips, all the bit patterns up to k Hamming distance away from C, right? So the farthest ones away are distance k. If there's some other code word that this thing you're looking at might have been, well, that'll be some other code word D, and so it also has a neighborhood around it. So if you want these to not overlap, then the things that are farthest away still have to be distance one, right? So in other words, the distance between the code words has to be k plus one plus k more, if you want to deal, if you want to deal with k bit flips. That will allow you to have disjoint neighborhoods. The neighborhoods don't overlap. So if you say, well, I saw this one here, this was F, you know that this F cannot also be in another neighborhood. You know that it can only be in one neighborhood because the neighborhoods are disjoint. They don't overlap. So if it's in one neighborhood, it's not in another, so you can uniquely identify the code word that generated that neighborhood. But that's just Hamming distance, right? The minimum distance between two code words in the whole code, that tells us the Hamming distance. So if my Hamming distance for my code is at least 2k plus one, it can correct k errors. Make sense? Okay, so distance, the Hamming distance D has to be at least 2k plus one. If you flip that around, you get k less or equal to D minus one over two, but k is an integer so usually we might write it with a floor function. So this is the thing to know basically, that if you want to, if you want, if you have a Hamming distance D, then subtract one, divide by two, round down, that's how many, that's how many errors you can fix. So with three, let me, let me give a couple more details and answer your question, Daniel, if D is three, right, three minus one over two is one, and round down you still have one, so with Hamming distance three, you correct one error. With Hamming distance four, four minus one is three, divided by two is one and a half, but round down, so still one. So yes, there is, and I'll show you that at the end. That's what a SECDED code is, is Hamming distance four. So, and that's, I mean, I can tell you just by the name, it's single error correction, dual error detection. So we'll come back to that at the very end, though. Good question. Okay. All right, so what's a Hamming code? So, did I tell you before who Hamming is? I did, right? Okay, so Hamming code, also named after Richard Hamming, is a general and efficient code with Hamming distance three. So it's a nice way to generate codes. It's particularly nice because it gives you, as you'll see, a very easy way to say, well, this was the bit that was flipped. Let me flip it back. All right, so it's very easy to do. And it's a general way for arbitrary number of bits of coming up with a set of parity bits that protect those sets of bits. The parity bits cover subsets of all of your bits, as you'll see. All right, so, so to define a Hamming code on n bits, start by numbering the bits from one to n. Okay, so not no zero bit, start from one to n. And then all of the powers of two are going to be even parity bits. And each even parity bit p, so p then is some power of two, is based on the bits with indices k for which bit p appears as a one in k. So in other words, k and p equals p. So the binary number that you get by writing the parity bits in error as ones then gives you the index of the bit that's mistaken. So let me make this concrete, because it'll be a lot easier to follow. So here's a 7-4 Hamming code. So here are the bits, right, numbered from one to seven. So the parity bits are x1, x2, and x4. The other four are data bits. Okay, so you get to put four data bits in, and then you have three parity bits. Now that doesn't seem terribly efficient, right? It's almost a factor of two, but, you know, that's because we picked such a small number. If we picked 1,000 bits, right, 1,023 for example, then you still only have 10 parity bits, but now you have 1,000 bits of data, or almost 1,000 bits of data, right? So it's logarithmic, and if you pick small numbers, it seems big, but if you pick bigger numbers, it's not so bad. Anyway, so in the 7-4 Hamming code, you've got these seven bits again. The data bits, sorry, the parity bits are x1, x2, x4, so 3, 5, 6, and 7 are data bits. You can put anything you want in there. So how do we calculate the parity? So the parity is even. So x1 is the parity on the bits for which the 1 bit is 1, in other words, the odd-numbered indices. Okay, so 3, 5, and 7. So you xor 3, 5, and 7 together, and then in order to get even parity, you set x1 equal to that, and that gives you an even number of 1s for those four bits. Make sense? Similarly, x2, so x2 is the indices for which the 2 bit is a 1. So if you, maybe I should write these out. Sorry, I should have done this on the slide. So remember, there's no, there's no 1 index, so the indices run from 1 through 7. So here you can see, these are the x1, there's a 1 bit, the 2 bit, and the 4 bit. So this is x1, which is defined as x3, x5, and x7. This is the 2 bit, so here is x2, but that's defined as x3, and then x6 and x7. So you're just taking the binary numbers and looking where they have 1s. So it's pretty straightforward. It sounds complicated in words, but pretty straightforward in practice. Okay, so that's where we get the 3, 6, 7 to define x2 here, and then x4 is just the positions where the 4, I'm sorry, the indices where the 4 bit is on, so that's these four down here. So here's x4, and then that's defined as x5, x4, x6, x4, x7. Make sense? Yeah, Emily? Yeah, so we'll do that in a second, and we'll go do, we will plug into these equations. I just want to make sure you understand where they come from. I mean, most of the stuff we'll ask you to do on exams too would be with, for example, a 7-4 Hamming code, but I want you to know how to do it if you need to someday generate a 31-bit Hamming code, for example. Yeah, Mohamed? Now these are XORed together, so it's even parity across these four bits. So it's x3 XORed with x5, XORed with x7. You XOR those three together, that defines x1. Okay, let me, let me, Eric? Oh, that's just how we define Hamming codes. I mean, it's a very easy way to find mistakes, but let me do a concrete example now. Okay, so if you want to encode something with a 7-4 Hamming code, what you do is you get to pick four data bits, which are these. So pick four bits for me. 1, 0, 0, 1. Okay. So then we just go plug in these equations. So x1, then, is even parity across these four. So this one, this one, this one, and itself. So since it's even parity, the way to figure out the bit is basically to XOR the other bits, or to count them if you'd prefer. So 1, not 1, 1. So it has two 1s. So in order to get an even parity, we should put a 0. Now if you plug into the XOR, you have, what did I put first, 3, 1, XORed with 0, XORed with 1, which is also 0. So that's where the x1 comes from. Like that. Yeah. So you mean which indices? That comes from this table over here. So the x1 bits are, we look at the indices where those indices have a 1 when written in binary. X2 when they have a 2 when written in binary. X4 when they have a 4 when written in binary. If you kept going, it'd be, you know, x128 when they have a 128 written in binary, and so forth. Yeah. Yeah, so those are all defined by the construction of the Hammond code, basically. Yeah. The not, you mean the data bits? You can put anything you want in the data bits. Yeah. You put anything you want in the data bits, and you calculate parity bits to find the code word. Yeah. And then it's protected. Okay. So to calculate x2, then, we would XOR x3 with x6 with x7. So this one, this one, and this one. So what do we get? Zero. And then for x4, we would XOR these three. So what do we get? One. So that would be our 7-bit Hammond code word. Okay. And then if something happened, we could figure out, I'll show you an example of how to figure it out, but we could figure out what went wrong if only up to one of those bits had flipped. Whoops. Here's a graphical version. We used to do this in discussion section. But, so this is a graphical version. This shows the interaction using, well, 2D spheres. So you can think of each of these as being the, each of these circles as being the one bit in red, the two bit in yellow, and the four bit in blue. So to find the parity bits, you can write your data bits into the three, five, six, and seven positions. And then you pick the parity bits such that each circle has even parity. And then to check the parity bits, you just check that each circle has an even number of ones in it. And to correct an error, you'd find the circles with odd parity and then flip the bit in the overlapping area that corresponds to which circles have the wrong bit. Okay. But I won't go through the graphical model. Let me do the algebraic model. Whoops. That was strange. All right. So this graphical approach does generalize, by the way, but it's hard to draw circles or spheres above two dimensions on paper. So unfortunately, it doesn't go much further than a seven-four Hamming code. All right. So here's the algebraic encoding. This is what we just did on the chalkboard. We said, well, let's say we want to store, oh, did I pick the same value? All right. Sorry. Yeah. Sorry about that. I didn't do that deliberately, really. All right. So anyway, so here's the three, the five, and the seven pulled out. We got, oddly enough, exactly the same answers you gave me a minute ago. So this is our coded word. So then let's say that a bit flips, and I didn't tell you which bit, which is purposeful. So this has one bit different, and I guess you can now look over there, but don't do it. So this is something with a bit error, right? So we start our value, and we came back, and one of the bits had changed. Let's see what happens when we try to correct it. So to correct it, what do we do? We recalculate this error bit, which is basically saying, well, for each of our parity bits, does it now have odd parity or even parity? It's supposed to have even parity. So if it has odd parity, something's wrong. All right. So we can take x1, 3, 5, and 7, XOR them together. Believe me, I just pulled these out. I think I'm right. 0, 1, 0, and 1, XOR those together, we get a 0. So there's nothing wrong with the one parity bit. E2 is 2, 3, 5, and, I'm sorry, 2, 3, 6, and 7. That's 1, 1, 0, and 1. XOR those together, we get a 1. So something went wrong amongst one of those bits. And then for E4, we take 4, 5, 6, and 7, XOR those together. That's 1, 0, 0, 1. That gives us a 0. And then all I have to do is write these three from high to low. That gives me 0, 1, 0. And that tells me this number 2 is the one that got flipped, which, in fact, if you now look at it, you'll see all I did was I flipped x2. So this is what I meant when I said it's easy to identify. All you do is you recalculate the parity bits, you line them up in order, and then that tells you a number in binary, which is the bit that you have to flip to get back to the right answer. Yeah, go ahead. Is the graph for ECC in the binary, right? So where does that, like, end up at? Oh, yeah, the LC3 doesn't have ECC in it. Yeah, sorry. Yeah, LC3 does not do error correction. Yeah. Yeah. I mean, you could have a memory that does error correction that, you know, all within the memory, for example, attached to the LC3, but there's no ECC in the LC3 data path. Yeah. Yeah. Okay, Sasha? Yeah. Yeah. So exactly. So what if no error occurs, right? So this is kind of your question. What, why is there no x0? So if there's, if there were an x0, you know, all, if there's no error, we get all of the E sub 1, 2, and 4 values, this should say E sub i or something, all of the error values will be zero, right? Because all the, all the parity bits are still correct. And so your error pattern will be 0, 0, 0, and that has to be able to tell you, well, nothing went wrong. You don't need to flip any bits, right? So we don't include a 0 bit for that reason. So, so there is no 0 bit. So if you get that pattern, that means there was no bit flip. You don't have anything to correct. Okay. Any other questions on that? Okay. Okay, so this is the, this is the SECDED code. So let me finish this and I'll see if you want to do another Hamming distance example. I'm sorry, not Hamming distance, Hamming code example. So what happens if we add a parity bit to a Hamming code? So in general, I won't prove this here, but it's, I think I put a proof or proof outline at least in the notes. If you add a parity bit to a code with, with odd Hamming distance, that actually gives you a code with, with one more Hamming distance, which is kind of cool. I mean, it's somewhat intuitive because you can think of the odd Hamming distance. They've got to have different parities. So if you add a parity bit, that means anything that was close together now has to be a little further apart. And so the codes that were close together, meaning at the minimum distance of D are now forced to D plus one. So now your new minimum is D plus one. Unfortunately, this is not so simple going from a code with, with even Hamming distance to one with odd Hamming distance. Otherwise we could just make Hamming distance arbitrarily large. But we can add, we can take our Hamming code and add a parity bit and that will give us a Hamming distance of four. So what's, what's good about that is we can then use that. We can still only correct one bit flip, right? But what we can do is we can, all I did is I plugged into the equation and got one, right? So we can only correct one bit flip. Sorry, I flipped through that slide too quickly. But if two bit flips occur, what actually happens, right? So you think about the, there are neighborhoods of one bit flip, right? Because we're only going to correct one bit flip. But if, if two bit flips happen, my code, the thing I see moves out of the neighborhood, right? So two bit flips will take me out of the neighborhood next to my code word of one bit flip away. So what I see, the final answer is not actually in any, is in, is not actually in any neighborhood of any code word. So I'll know something went wrong, right? So if I have a Hamming distance of four, unlike the Hamming distance of three examples I showed you before, with a Hamming distance of four, if two bit flips happen, I won't make the mistake of correcting to the wrong answer. I'll actually know, well, something else went wrong. I have to give up, right? So I can do single error correction, double error detection. And so I'll know the difference between one bit flip that I can correct and two bit flips that I have to give up. Three bit flips, of course, I'm just out of luck, right? Three bit flips, too bad. But you know, we, people play the probability game, right? So, so this is a SECDED codes for this acronym here. And they're, they're actually pretty common, too. Okay, so do people want to do another example or two of Hamming? Yeah, okay. All right. So let me, I think the next thing was advice. Yeah. So, so maybe I'll send around these sheets. I don't know if we'll actually finish it today, but this was my printed copy of advice for all of you. And let me switch over to the, to this thing, which hopefully won't take forever. See how quickly I can set it up. Oh, and then the question is, do I have any paper? Wow. We're very limited paper resources. Okay. So let's start by encoding something. So pick, someone pick a paper. Okay. So I'm going to pick four bits for me. 1, 1, 1, 1. Okay. Good choice. All right. So remember, this is X7, X6, down to X1. Maybe I'll number them all. Zoom for now. You'll have to zoom out later. Okay. And for the data bits, these four are data bits. Okay. So how do we calculate X1? So remember, X1 is, is the even parity across those indices with the one bit set, right? Which is just the odd bit. So 3, 5, and 7. So we'll look at 3, it's a 1. 5 is a 1. 7 is a 1. That's three 1s. So to make even parity, what should I put next one? A 1. So the other way to do this is as XOR, right? Okay. What about X2? Oops, sorry. I'm going to have to zoom out a little. Okay. So, oh, it didn't focus yet. Supposed to autofocus. All right. So X2 will be the indices where the two bit is on, right? So those were 2, of course, but 3, 6, and 7. So 2 is defined by 3, 6, and 7. So again, 1, 1, and 1. So what's X2? 1. Good. And what about X4? 1 also, right? It's X5, X6, X7. Those are the three where the one bit, I'm sorry, the four bit is on in the index, as you can see over in the table to the side there. And 1, X4, 1, X4, 1 is 1. Okay. So there's our coded Hamming word. So let's say something comes along and flips a bit. Who wants to pick a bit to flip? 5, 5, 1. Okay. So then we don't know what the original word is, right? All we see, so I won't even show it. I'll just say, well, what we see is 1, 1, 0, 1, 1, 1, 1. So those are the bits we see, and we have to figure out, well, did something go wrong? Let me try to see if I can get this to autofocus. I don't know why it didn't. There we go. All right. So let's see. How do we do that again? Yeah. So let's calculate error bit 1. So it's X1, X3, X5, and X7. So what is that? A 1. Okay. Okay. What about E2? It's a 2 XORed with what? Okay. So that's a 1 XORed with 3, XORed with 6, and then 7. So what is that? 0. Yeah, there's still four 1s, right? So that's even parity. Good. What about E4? It's 4, 5, 6, 7. Okay. So that gives me 1, 0, 1, 1. Which is what? 1. Okay. So if I write E4, E2, E1, then that gives me 1, 0, 1. So that means bit 5, X5 is wrong. Yeah? Make sense? You want to see what happens if two bits flip? Yeah? Okay. Someone else pick another bit to flip. I hear 3, 2, 4. Okay. Anyone against 4? Okay. We're going with 4. All right. So 6, 7, 6, 5, 4. Okay. So two of our bits have flipped. Our original pattern was all 1s, but we don't know that. So X5 and X4 flipped, and we want to go figure out, you know, what was this answer. With Hamming distance 3, we can correct a bit. We can detect, we can always detect two-bit errors, but we have to make a choice. And Hamming distance 3, I told you, well, you can detect D minus 1 if you have Hamming distance D. But if you choose to detect, you have to give up on all cases. You have to choose detection or correction for Hamming distance 3. So you know this is wrong. Some of the parity bits are wrong. So in that case, you could say, any time I see parity bits are wrong, I give up. And then you could always detect two errors. But if you choose to correct, and you only have Hamming distance 3, well, let's see what happens. So what's E1? So X1, 3, 5, 7, which is 1, 0, 1? 1. What's E2? 2, 3, 6, 7? What's that? 1, 1, 1, 1. Still the same? 0? What's E4? Sorry, I can't write quickly. So 0, 0, 1, 1. So what's that one? Aha. So E4, E2, E1 equals 0, 0, 1. So bit 1 was wrong. We fixed it. Yeah, exactly. So you will get an answer. And if you go change that bit, you will still have bits. You won't, however, know that those bits didn't happen to match the bits you put there originally. So the bits you'll get, by the way, if you look at this, you know that the pattern's coming out. If only bit 4 had flipped, the error pattern would have given us 1, 0, 0. Bit 5 flips, we would have gotten 1, 0, 1. If you XOR those two patterns together, you get that. So if you XOR 1, 0, 0 with 1, 0, 1, you get 0, 0, 1. So that's the answer you get. You won't know whether two bits flipped or only bit 1 flipped or whatever. You won't be able to know. Yeah, Eric? Yeah, I mean, if you say you want to do error correction, you're going to flip bit 1, and then you have the wrong answer. So you'll flip bit 1. You will not have flipped bit 4 nor bit 5. Because you have only Hamming distance 3. And so if you have two bit flips, what happened in terms of the neighborhoods was this, that we have our original code word, which is this one. And one of its neighbors is, for example, the X5 bit being mistaken. And then over here, we have another code word, which is, let's see, 1, 1, 0, 0, let's see, 1, 0, 1. And then here, one of its neighbors, which is 1, 1, 0, 0, 1, 1, 1. Zoom in on that. So the way the Hamming code works for error correction, it says, well, if you're in this neighborhood, I'll assume you got that one, right? You came from that one. If you're in this neighborhood, I'll assume you came from that one. But what happens with two bit flips is, well, start here. There's one bit flip. There's two bit flips. Now we're in the wrong neighborhood. So if you correct, you get the wrong answer. Yeah, if you want to correct two errors, you need actually Hamming distance 5. If you want to detect two errors, you need Hamming distance 4. Then you'll know something went wrong. That's a SECDEAD code. Yeah, yeah, that's right. OK, yeah. Oh, it doesn't matter where, so long as you remember it's the parity bit. Yeah, it would be parity over all bits in the Hamming code. So for example, you would put it anywhere, as long as you know that's the parity bit. Yeah. Yeah, it's just like I put it on the right side. But as long as you know it's the parity bit, you can put it anywhere. Yeah. I mean, when people do transmission codes, they tend to put it at the end, because that way you can calculate it as you transmit. You send all the bits, and by the time you've done, you've XORed all the bits together, and then you know which bit to send as the last bit. So people usually put parity bits at the end. Yeah, Dan? Yeah, I mean, usually those will go in higher-end storage systems. I'm trying to think of what the actual codes used to format information on the drives themselves are a little different, because you're physically writing magnetic fields on the hard drives. And so they're actually two-dimensional codes as well, because you've got a surface area that you're writing onto. So they're substantially more complicated in terms of how you figure them out and how you manage error information. Yeah, the kind of Hamming distance 5 stuff I was talking about is usually for high-end storage systems where you have lots of separate disks, and then you'll use Hamming distance 5 codes across disks. So if you have a disk failure, for example, you can deal with that kind of stuff. Or if you have bits being corrupted over time as well. Yes, it doesn't matter. The order doesn't matter. The order is purely for us to know where to go find the bits to include in each of the equations and things like that. In some areas, but not all. Yeah, sometimes. Okay. Wow, we're nearing the end of the hour. Okay. I may spend some of the time, maybe let me get started on some of the advice stuff, and then maybe we'll finish it up on Wednesday. Okay, so Sanjay Patel and I came up with this, wow, maybe 12, 13 years ago, when he started teaching with the book, Pat Patel here at Illinois, and he taught the first time he taught. He and I came up with a list of what we thought we should tell our students as they left the class. And so this list is from that. So I should give him credit for most of it. So one thing is take on a big project in the next few years. So the stuff you do in class will be useful, and we try to make it fun and exciting and worth your time. But if you really want to learn stuff, the best way is to be self-motivated and driven. And those kind of things will be good to talk about when you go to career fairs, and when you go out and even grad school. So figure out something that excites you and go spend some time on it. You can go to the place next to Daily Byte. There's student offices there. They have all kinds of projects. Do something with the AOH. There's all kinds of things you can do. But do something. Do something that you can talk about and say, hey, I worked on this really cool thing when I was an undergrad. Learn to use a debugger. So you've used the LC3 simulator, which kind of helps you walk through things and see what's going on. When you start doing C programming, there's a tool called a debugger that will help you, because it will help you look at state as the program is in the middle of executing. Unfortunately, it's hard to know when to give that to you, because some students will not need it yet. Their mental model of what's going on in the program is so good that they'll look at this thing and say, so I'm going to spend 10 hours learning that thing when I know how to fix my bugs? Wow, you're crazy. This is a waste of time. Then by the time they go back and realize that, well, we told you for a reason, they've been banging their heads on the keyboard for a while. Then other students, they could have used it three weeks earlier. So it's always hard for us to know exactly when to give it to you. But at some point, your bugs will be hard enough that a debugger will make your life vastly easier. So there are tools that will help you. They're like the LC3 simulator. You can go step by step. Say, well, what does this next instruction do? Let me watch. Let me do one instruction. So the same sort of thing, except in a debugger, it's usually an AC statement. Do one C statement. Let me look at the rest. Don't put off learning about tools. There are tools that will be useful for you, scripting languages, things like that, MATLAB. Don't put it off, because they will also make your life easier. Why are they there? Because someone ran into some problems that were painful to keep solving, and so they made a tool for it. I'd like you to know how to multiply matrices and invert matrices, but if you don't want to learn that, you can go use MATLAB, for example. Avoid optimizing prematurely. It's very tempting. Engineers like to optimize. They like to go down and make everything perfect. When you're working on bigger systems, don't spend your time on things that don't matter. Be careful about where you spend your time. There's something called Amdahl's Law. If you have a program and part of that program takes 1% of the time, and then you make that go 100 times faster, well, the other 99% is still just as slow. And so at the end, you're not going that fast. Don't spend your time making things go fast unless they matter overall. Be careful how you spend your time. There's some quotes on that, but maybe I'll skip it. This one has a story attached, so I'll do that one on Wednesday, and I'll try to keep the rest short for you so we can do a review session. Thanks.\",\n",
       " \"So maybe don't call me that. We have three other sections. You're welcome to go to any and all except the fire marshal doesn't like the room to be overcrowded and have people all over the aisles. So the big room there are two lectures. 1013 is a smaller room, but you know if you want to if you miss a lecture we have them video recorded so you can watch them online. I encourage you to come that way you can interact and ask questions and do things like that. So, please don't just only watch the lectures online, but we will record them for you if you want to review or something. If you're a James Scholar take a look at a wiki and then talk to Professor Varadayan and he will help you set up a scholar program in this class, which will be fun. So I want to start by just telling you a little bit about you know, what is this class? What are we trying to do and why? So you may have heard this pitch from Bill Sanders because I know he's been going around and giving this pitch. So, but what we wanted to do when we redid this class a few years ago was really try to give a systems perspective to our students. So we wanted to get people to understand that as an engineer you're going to need to solve problems and the tools at your disposal as an ECE major are hardware, software, some math, theory, things like that. But you really want to take the right tool for each problem, right? So you can learn to do software and then you can try to solve all problems with software and it's during complete which I'll explain in a minute, which means you can solve all problems. It's just not necessarily the right way to do it. You can do the same thing with hardware. You can solve all problems. Just not necessarily the right way to do it. So the question is how do we get people to do it the right way, right? How do we get our engineers to go out and be successful and be the people that get the right solutions to whatever problem they're trying to solve, even unsolved problems, and enable you to go down that path? As you probably know, our department has a huge history of success in that regard. What you may not know is that we've got alumni in fields all over the place. So you'll have an opportunity every year to see alumni award winners. I think we're getting them videotaped again. So I think you might be able to go back and look at the archives. But people like the founder, one of the co-founders of C-SPAN, for example, which you might not think, well, ECE major would go found a television network for documentary political television. But in fact they did the Mars Lander program. That's something more, yeah, probably someone in ECE is in charge of that, right? Let's see. What else? Patent lawyers, so antenna patents and things like that. Antenna designers. So many, many different fields. You can do whatever you want with an ECE degree. I was going to bring it up later, but maybe I'll bring it up now. We've got College of Medicine based on quantitative science coming together here in a couple of years. So if you're interested in medicine, but you really want to be more quantitative, you're in an ECE program, that's one path you might want to consider. You will need to get a little bit of chemistry, biology experience to apply to a medical program, obviously, but that'll be opening up here. So I wanted to encourage people to consider that. There's also a program with the business school. So if you're interested, you'll find out about it soon enough, but if you ask me I can explain it to you, come to office hours or something. So that was kind of what we wanted to be able to teach people. Some of the other things that we need to give you as your introductory class is just an introduction to kind of the ECE culture and the goals of the department. So I mentioned some of the goals, but the ECE culture, this is the hardest department in the campus, we like to say, and our students all tell us that. And we're proud of it, right? You're gonna work hard and hopefully you'll love it. And I mean if you don't love it, then... But you know, you don't necessarily know what you want to do when you sign up, right? So a lot of engineering schools make you choose going in. So many of you know, hey, I really absolutely want to do ECE. Some people are saying, well, I had to pick something. It sounded kind of cool. Some people maybe, I'm not sure, but we'll check it out, right? It doesn't matter, you know, if you like it, great. I love it, obviously, so I would like to share my love of it with you and have you love it, too. But it's okay if you don't. I mean, there are lots of other good things to do in life. So, but the culture is work hard and be successful and we'd like to see our students go out and be enabled to change the world. Right? So we're hoping that you can go out and change the world as have many alumni before you. Right? So we will train you to do anything and, you know, you can then go out and choose and you'll be able to choose between going and changing the world or if you want a more relaxed life, you can pretty easily take a job with, you know, 40 hours a week or whatever and that'll be fine. But it's up to you. You'll have those choices. All right. So expectation of engineers. You know, engineers are often in positions where what you do will matter in a lot of ways that you might not initially think about. So, you know, when I first created this class with Doug Jones, one of the examples he gave I really liked. It's kind of an ethical question. So, you know, when you design software, for example, your software will live on and people will use it and grab it. And so you have to think about how they're going to use it. Turned out that there was a piece of software that controlled a medical device, an x-ray machine. And so the software, the medical doctor would enter, well, how much radiation do you want to use for this dose? Because they would have to vary it. So they type in a number and they press go. Well, turned out the person who wrote the software didn't put any air checking. So if they mistyped something, it just translates whatever they type as an ASCII code and turn that into a number and irradiate the patient. Well, turned out that you could type lethal doses in and then the patient would get a lethal dose of radiation. All right. So it turned out someone died. So as an engineer, you kind of have to think, well, am I working on problems that one day may actually be safety critical? Right? Where you may have to think about, is there human life at risk? Is someone going to get hurt as a result? So there's a lot of ethical issues as an engineer. And, you know, we want you to understand you should be thinking about them. You should be thinking about what is the impact of what I'm doing, whether it's hardware or software or whatever. I mean, medical device technology, for example, when we talk to people in medical device companies or actually in the people that build the processors that are used, they say, well, you know, our processors are not designed for medical devices. We don't think they're reliable enough. But the people who want to build medical devices, well, they need processors. So they say, well, we're just going to use yours. So what happens if something goes wrong with the processor, if it has a hardware fault? Whose fault is that? So, I mean, whose problem is it that then the system crashes and something goes wrong and someone gets hurt? So as an engineer, you know, there's a lot of things you need to consider, right? And you're all smart. So otherwise you wouldn't be here. So you can handle those sort of things, but there are things that you want to be conscious of, that you're in a position of responsibility. You're also in a position where, you know, you can help society, right? So you can help your community and help people understand what the issues are, merging technology with life. Lifelong learning. So we can't teach you what you're going to use in 10 years, probably not even half of what you're going to use in five years, right? Things change all the time. So all we can teach you is how to learn about things, how things are designed, and maybe instead of learning about the next thing in five years, you'll be the one that designs it. That's probably where we'd like you to be. But, you know, you need to be able to learn for the rest of your life as an engineer. So that's really what we want you to take away. So there'll be concrete tools in our class, for example, and in many of the classes that you will pick up, and those will be relevant today, but those will probably not be the same tools you use in five years or ten years, right? So you need to be able to understand how and why those were built the way they were built and the engineering trade-offs. Again, in engineering, so I'm kind of moving to the next bullet, in engineering, there are always trade-offs, right? There's no meaning in most cases of, well, what is good? There's usually four or five meanings. So I'll give you examples of that in a few weeks, in particular for hardware design, but as an engineer, you need to understand trade-offs. And of course, we're quantitative people, right? We're engineers. So you want to be able to quantize them, but then also understand when you have more than one metric, more than one way to say what is good and measure what is good, how do you decide between them? So as an engineer, that'll be constantly the problem, is knowing, well, how do I measure goodness in the first place, right? Measuring goodness and then saying, well, is four better or six better? If good is bigger, right? That's not hard, right? But figuring out, well, how do I measure it in the first place? How do I get the four or the six for different design choices, right? Or if you've got more than one metric, how do you choose between them? When one is better with one metric and another one is better with the second metric or the third metric. So that's another issue. Look around, it's an international group, right? So you look around the room, you've got people from all over the world. This is a university where we draw students from everywhere and that's a big advantage. All of the engineering companies these days are global, okay? So you're working in a company, you're gonna have people on your team spread around the world, you have an opportunity here to learn different cultures. If you're an international student, of course, you've come to the US, you've got an opportunity to learn US culture. You also want to make sure you learn enough English that you can get as much as possible out of the program. Yeah, I know, well, all right. But if you're a domestic student, take the opportunity also to learn about other cultures by just meeting people in the room, right? You have a big opportunity in that sense here. Let me make one other comment about the English. You know, I've been in many different foreign countries and it's always really intimidating when your language and another language you feel is like not good enough. So I was teaching in Vietnam actually three weeks now, last three weeks, and my Vietnamese is awful. I mean, I don't know if anyone Vietnamese is in the room. It's embarrassing even to try it. But even to go somewhere and say, hey, you know, I want to try that food, right? It can be embarrassing and you feel kind of lonely and you feel like if there are other people that speak your language, hey, I'd like to just hang out with them and be able to relax when I'm not in class. Be careful, right? Be careful that you don't take advantage of the opportunity to improve your English so that you're getting again as much as you can out of your classes, right? If you're in a position where you're not able to follow your lectures, you're not able to do as well on the exams because your English is a stumbling block, it's your loss, right? So you really want to make sure that you're not in that position. So I want to encourage people not to do that. There's an international program, international program in engineering that brings people together and gives you free food. I mean, what could be wrong with that? So I'll try to tell you about the opportunities and I'd like everyone to show up. They don't actually have capacity for everyone in a class, but we'll try to overcapacity them. And I think you'll have fun with it. And I think it'll help you in terms of leveraging the international community here. All right, academic reality. I told you ECU was hard. So it turns out half of the people in the room are under average. Yeah, and you're probably thinking of LaMetta. Oh, sorry, wrong finger. So you get into grad school and it turns out half of grad students are under average. And you know, you'll be a faculty one day, professor somewhere, it turns out half of professors are under average. It really sucks if you get to that level and you're like, oh man. So you really have to remember what pool you're in, right? You're all ECE students. Well, some people transferring in, but you know, I think you'll all be ECE students. So you're in a pretty prestigious pool already, right? I've had advisees that had B- average or something and went on to get their dream job. And I see students that, you know, they get one B in their class and they're like, oh, I'm going to get a B. You know, they get one B in a class or they're headed towards a B and they come to me like, professor, should I stay in ECE? I don't know if I fit in. And the answer is absolutely. If you like what you're doing, absolutely. So, you know, I read pretty widely. I've been reading, I read this book that Steven Pinker, he's a developmental neurologist, neurobiologist. But he was talking about how people kind of, they build their egos around what they're good at. Right. So a lot of you are probably kind of the math and science go to person at your high school. Right. You feel like, hey, that's what I'm really good at. And, you know, look around here. Right. I mean, one of you in this room will be the best, the best of the class. Everyone else will not be. So your ego should not depend on this. I guarantee you that in a couple of years, when you go out to do internships, you will be the best. When you look at people from other schools, you say, wow, I really learned a lot. Let me help you with that. And in a general environment, when you're not amongst all the ECE students, you will be the best. So don't let that feeling of like, hey, you know, maybe I should transfer to that other department and then, you know, I could stand out as the best again, just like in high school. Don't worry about it. You will be. So we worry about that. I mean, we worry about that a lot because we don't want you to leave, leave the department thinking, you know, you won't be able to succeed when we know you will be able to. So what we decided in this class is to make grades a little easier. In fact, well, they wouldn't take me seriously. When we started the class, I told my colleagues, look, let's just give them all A's. OK, everyone, don't just give them A's. I mean, that's what MIT does. Freshman class is pass fail. You all pass. You're good. But we'll actually tell you the real grade. My colleagues were like, are you insane? So that didn't work. But eventually we agreed that we'll give an easier grading scale. So this class is honestly an easier grading scale than most of the ECE classes to help sort of nudge you in the right direction to not have this psychological shock. OK, so that said, that's the reason for it. And you don't have the perspective yet. Right. I said in two years when you go out and do internships, you'll meet people from other schools and you realize how much you know. Right. But until you get that perspective, you know, I can say whatever I want. And then the feeling versus the words are a little hard to match up. Right. So. So that's why. So. All right. Enough philosophizing. Let's talk a little bit about the content. So we're going to build computer systems from the ground up. We're going to start with bits and gates and build upwards through their extraction layers. And eventually, by the end of the semester, you'll know how to build a computer, how to design a computer from bits and gates. Why do we study computers first? If you talk to your friends in AeroAstro, I don't even know this term. I just picked it out as some advanced design. You know, do they start with a high bypass turbofan engine? You know, is that what they say? I'm a freshman in Aero. I'm going to look at the high bypass turbofan engine. No, that's probably something in a senior class or something. They're going to do dynamics, right, in physics and lift. Talk about airfoils or something like that. So why don't we build up to computers slowly? Why in this class are we going to start and build right into computers immediately? So in 1936, Alan Turing wrote a paper about universal computation devices. So take the space of all possible things you might want to do, things you might want to solve problems. And so some of them are computable. So I drew that in green there. So some of them you can answer questions. And then in that are the computers that can solve those kind of problems. So, you know, Blue Waters, the biggest and most powerful scientific supercomputer in the United States, a little bit south of here on the campus, versus iPad. Same power, same ability to solve problems. It's just memory and time. That's the difference. Blue Waters has a big chunk of memory, petabytes, but iPad, I don't think they have petabytes. Maybe there's a new option or something. So it's just memory, right, memory and time. But otherwise they can solve the same problems. Android phone, same thing. LC3, the computer, little computer 3 that the ISA will study in this class, the computer will study in this class. They're all the same. So if there's a problem you can solve with one, you can solve it with any of them. So that's one reason that we're going to look at computers first, is that things are either computers or they're not computers. There aren't different types of computers. They're all the same in that sense. So we're going to look at a somewhat simple design for a computer, but it can still solve all the same problems. And that'll be the LC3. There are undecidable problems. Probably won't talk about it much in class. There's some detail in the first section of the notes. So if you want to know, well, what is an undecidable problem? Actually, Alan Turing gave us an example in 1936 called the halting problem. So you can see something outside of this box and none of these computers can solve the halting problem. So those are undecidable problems. The Church-Turing hypothesis is worth mentioning. So one of the other things that Alonzo Church and Alan Turing both hypothesized was that this green thing here is the same as what humans can compute. So in other words, if you or I could solve a problem by sitting there and trying to work it out systematically, a computer can solve it too and vice versa. So that's the hypothesis. It's never been proven or disproven and it probably won't be. Because how can you prove what a human can or can't do? But most people in computing and technology believe this to be true. That computers and humans can do the same things. Now, there's a lot of stuff we don't know how to do systematically. So the things that our brains do with neurons, things even like vision, we don't know how to do systematically. So why do captures work? Why is it that when you make someone look at text that's been fuzzified a little bit, why does that keep a robot from being able to break into your website? Well, it's because we don't know how to solve that problem. Our brains do it very easily, but we don't know how to do it systematically. So we can't teach our computers, which are dumb. Computers are not smart. We can't teach them how to solve that problem. So until someone figures it out, captures are effective. Okay, so I promise I won't do this to you very often, but I'm going to read you a quote. All right. It even came out sort of big enough font, but it's in the notes that you can grab online if you want. You don't really need to know it or anything. The apparatus they, animals, use for timing their movements has more in common with an electronic computer, although it is strictly different in fundamental operation. The basic unit of biological computers, the nerve cell or neuron, is really nothing like a transistor in its internal workings. Transistors are what we're going to use to build our computers. Certainly the code in which neurons communicate with each other seems to be a little bit like the pulse codes of digital computers. But the individual neuron is a much more sophisticated data processing unit than the transistor. Instead of just three connections to other components, a single neuron may have tens of thousands. The neuron is slower than the transistor, but it's gone much farther in the direction of miniaturization, a trend which has dominated the electronics industry over the past two decades. It was in 1976, by the way. So he's talking about starting in 1956. This is brought home by the fact that there are some 10,000 million neurons in a human brain. You could pack only a few hundred transistors into a skull. So that was in 1976. So miniaturization from 1956 to 1976. Moore's Law continued in the intervening 40 years. So 1997, when the Pentium was released, there were 4.5 million transistors on it. Today there are chips you can go out and buy at Best Buy with 4.3 billion transistors on a chip with 541 millimeters squared and very, very thin. So if you do the math, you can see that you can pack a heck of a lot more transistors into a skull than you can neurons. So they're much, much smaller. There's still only three terminals. So complexity arguments. Yeah, we'll see. But certainly transistors and computers have gotten much, much more powerful. And there's interest and some promise in trying to see if we can get these digital systems to do what human brains do. So that was Richard Dawkins in his selfish gene book. All right. So what's happened in ECE in the last couple of decades is that we've seen really a digital convergence. So most people, even our EE graduates, have gone on and they end up being computer people, using computers in their daily life. I mean, you use computers in your daily life, I'm sure. Most of the solutions across our fields are digital. There's not much room left for analog engineering. I mean, it's kind of fun and it's hard, but there's not that many jobs out there and there's not that much research going on in a lot of fields with analog. Most things are digital. Digital system design thus provides you with a critical set of tools and a critical set of skills that all of our graduates need. And so we want to make sure that all of you have these skills, which is why we require that everyone take these classes. And you'll go a lot further and faster with these tools in your toolbox than without them. So that's why. I mean, sometimes, you know, this is in some sense the lead into computer engineering program, but at the same time, all of our EEs are in here. And so sometimes our EEs wonder why us? Well, because honestly, in most of the subfields of electrical engineering these days, these will also be critical skills for you. All right. So why do we do bottom up? So we really want you to have a firm understanding. We've seen far too many programs where people go from the top down and they end up kind of waving their hands and not really understanding what's going on underneath. And so we feel like, you know, this is it's important to have you understand what's going on underneath. Before you talk about what we build on top of it, you'll see that we'll build upwards through layers of abstraction in the class. Because then when something especially when you're trying to build something, when something goes wrong, you have a model of what's going on underneath. And you can understand and reason about the system as a whole instead of guesswork, instead of making guesses. So we don't want you making guesses about how to do things. We want you to be able to reason about it based on your understanding of the systems underneath. And so that's one reason. If you're designing at different levels, then it's critical that you understand the layers on what you're building. Because you need to be able to understand, well, if there's a problem at one of the layers, is it easier to push it into a layer underneath you, to hand it up to a layer above you? So these kind of decisions, if you're working in a sub area, in one of the layers of abstraction that I'll show you for digital systems, interacting with your adjacent layers, you really need to understand those to a certain degree. So we're building upwards so you have an understanding of all of them in your first class. And of course, our students have been successful with this approach. Okay, so where do you find information? Well, you start with a wiki. So one way is, you know, you can bookmark this or whatever, type it in one time. Unfortunately, you can't Google EC120 wiki and it won't come up. It won't work. So instead, you can Google my name. So if you can remember how to spell my name, then you can Google it. So just as a demonstration. Let's do it this way. I claim, if you type Steve Lomeda into Google, that I will be first. There we go. And then you can go down here to F16 under classes and go there. And then there's a link to the wiki at the top along with some other stuff I put there for you. So I won't show you the other stuff now, although actually down at the bottom is lecture slides. So if you want to see this stuff on your own. And so there's a link to the class wiki. If you haven't used a wiki before, you know, it's basically just a hierarchical web page. There is a menu, menu driven system on the left. The only thing I kind of don't like about it myself is that if you click something like syllabus, then you'll get a page with interesting information on it. And then down at the bottom, it'll say child pages. So if you want to see those child pages, you can expand the menu on the left. So I find, I don't know, I don't like that interface much, but that's the way it works. So this is the first place you should look is this wiki if you're looking for information about the class. And you should read it every day. We'll post announcements there. So do try to look at it every day. Let me go back to go back to this slide. Yeah, so take a look every day. So what you'll find there is announcements for the class, due dates for homework, assignments. You can pick up your assignments there. We'll post solutions for homework. Those will be there to course information, timing, office hours, staff members, names, email addresses, so forth and so on. It's also a place for exchanging information. So you can add questions and comments on assignments and then get answers there, which is the right way to do it. Right. Because if you have a question, chances are really good, lots of people have that question. Right. So don't feel shy about just putting your question there and then seeing what's the answer. You can try to help people if you feel you know the answer. That's fine. Don't post answers, please. Right. So if you have. That sounds weird. Don't post solutions. Right. So if you know the answer, the correct solution to a homework problem, don't post it on the wiki, please. And for one thing, you'll end up getting mad at you. But but they will also have to delete it. And it'll ruin all the fun for everyone else. But any non-personal questions you should put here. Right. So unless it's something like, hey, you know, I want to talk about my grade. Right. Those kind of questions you can use email. Anything else you should put on the wiki. Right. Because again, anything anything that isn't personal to you is probably something other people are going to want to know the answer to as well. And so we'd like to have that answer be public. So please use that for those reasons. What to read and what not to read. Here's our textbook. It's the second edition of Pat and Patel. Sanjay Patel is another one of our faculty members. Yale Pat is his advisor. He's still at Michigan. I'm sorry, not at Michigan. He's still at Texas, University of Texas, Austin. So this introduction to computing system. It's a good book. Doesn't go quite as much into digital design as we had wanted for this section. This two class sequence, 120-220. So there's also about 150 pages of notes that I wrote for you. So that's on the page. It's on the wiki. But the notes will help you read the book, read the notes. But suggested first you try to read them before and after class. The wiki will tell you the relevant sections. Students have told us sometimes you need to read things more than once. Actually, an alumni, quite a famous alumni came in and his comment to the students was, when I was in school, you know, I would sit down and I would read it once. Then I would read it again. And then because I knew I didn't really understand it, I'd read it a third time. So don't feel too bad if it takes a little while to sink in. I mean, I tried to put lots of examples. I think this is a great book. So hopefully it doesn't take so long. But if it does, really don't worry about it. You can go on and be successful and happy. I mean, this was again one of our famous alumni winning the Senior Alumni Award. So if you read it a couple of times, it's OK. But if you come if you read it, then you'll come prepared to have questions. And I would like this to be a dynamic, dynamic environment. So take a look at also the notes have summary sections that tell you the learning objectives. So if you want to know, well, what am I supposed to learn? It'll be summarized for you in those sections. I've never taught this class with PowerPoint. I always use the chalkboard. I'm going to try to switch over to PowerPoint. Just give you more resources. But so two things about that. One is I have to do a better job of rate controlling myself, which with chalk is a little bit easier. Although I'm told I'm one of the fastest writers in the department. But, you know, feel free to ask questions. So if you have questions, just raise your hand or for some reason I'm looking the wrong way, then just say hello and ask your question. OK. It's a small enough class that I think don't worry too much about about interrupting. I will repeat your question because since we're videotaping, I want to make sure they get on the on the recording. We have some online tools in JavaScript. So use those to practice your skills. They're for the first and second parts of the class. Class is divided into four sections by midterms and then the final at the end. So there's some tools you can use to practice your skills and make up random problems for you. They'll give you instant feedback on your answers. So it should be helpful. They're JavaScript based. You can run them on your desktop or your mobile. Unfortunately, I don't own an Apple product, so I can't debug them. And I know they're not so nice user interface wise on Apple. So I apologize to Apple users. But one of my students at Apple sent me one, then I'll be able to debug. Watch out for the web. Right. I mean, I do expect you to be able to go out and Google things. But on the flip side, I know there's a lot of bad information out there. So be careful about just trying to look up and learning from random stuff on the Web, because often the people writing it or shouldn't be writing it. They wouldn't be allowed to write it. So I've seen a lot of confusing things when I was looking for resources for this class. And, you know, I wouldn't point you there, but you can also find them. So just be a little careful because the Web is not filtered. Which I think you know, but sometimes it's worth being conscious of. All right. So let's spend some time talking about what are we going to do in the class and how are we going to grade you and stuff like that. So what's the workload? Every week you will have a lab. So software and hardware. Some will be programming. Some will be building hardware. You'll build a little finite state machine that interacts with the real world at some point with sensors and actuators. You will write some programs. So labs will vary from week to week in terms of what they are. And so how you turn them in will also vary. They're usually due Wednesdays at five. But look at the assignment because it will not always be the case every week. The first one is due next Wednesday. So not two days from now, but next Wednesday, 31st of August. Their weekly homework assignments. So those are paper and computer based. The paper stuff you'll turn in at a box near 3070 in this building, which is the student lounge, the undergrad lounge. And those are due Fridays at four. First one's next Friday. So you have a little time there. But you'll have those every week. And then, of course, we'll have some exams. We try to make more of these just so people don't feel so pressured by them. So you'll have four exams. So it kind of breaks the class up into four pieces. And we'll have evening exams. The philosophy is we don't want you to be time pressured. So these are designed to be 45 minute exams. And then we'll give you an hour and a half to do them. So hopefully by the end of the hour and a half, most people are gone. If you're still there, don't worry about it. We don't always get it right. I've gotten it really badly wrong sometimes and had almost all of my students there at the end. And I felt that. But yes, I see people smile. So it's funny because, you know, if we give an exam, I used to target 75 average. We're targeting a little higher now because we're moving on to definitely absolute scale, as I'll mention in a minute. But other schools, people target 50 because it gives you the most information. And I know most of you, most of you have probably gotten, you know, 90, 95, 98 through most of your life. And you come into college and you get a 50. Oh, man. And if no one tells you, oh, the average was 50 and, you know, you're in this great class of really good students, then you might not realize, well, that's pretty good score. Right. So it's really kind of psychologically challenging and traumatic sometimes. But so we're targeting higher averages with these. But we are. We do screw up sometimes. So, you know, if we screw up, we will account for that. So we'll give you an absolute scale. But if we mess up stuff and the average is lower than it should have been, we can push your grades up, but we won't push them down. So if you if you're on the absolute scale, then I'll show you in a few minutes and you get an A or B or whatever, then you'll definitely get that grade. And if we've messed up and given too hard exams, we'll fix it. Don't worry. All right. So three midterms, one final. Those are the times and dates are on the wiki too. So. If you have a conflict, let us know early. There are some rules that the university provides for figuring out if you have a conflict. But let us know. The finals rules actually depend on class sizes. So in some cases you won't know. Right. Because maybe not everyone comes to class or there sort of seems similar when you look around the room, in which case go to Laurie Fisher and she'll know because she can look at everything. She's up in the advising office. So. So if you can't figure it out, just ask her and do it soon enough that you know which classes are going to offer you a conflict. Some, some classes. I mean, I think we'll do this, but some classes will let you take a conflict if you need one. So if you need a conflict, sometimes the rules will say, well, that class has to do it for you. And if that class is offering a conflict or is not a well, sorry, let me make this clear. If you have two classes that conflict, then one of those classes definitely has to offer you a conflict. So you're protected from people saying, I don't want to be bothered. So you definitely deserve a conflict. Now, which class that is depends on the rules. Sometimes it's actually both have to offer you a conflict. But classes that don't have to offer anyone a conflict by the rules for finals might say, well, we don't want to create a conflict exam. You have to take the one that offers you one. Right. Other times, the bigger classes tend to say, well, if we're going to make the conflict exam available, then anyone who has a conflict can choose ours, even if even if technically they were supposed to choose the other one. OK, so this, I think, will become clearer over the next few years. But but the main point is, let us know early, because we do have to arrange to find a time with you that you can take the exam. So to let us know early, there's a default time. But but all of the classes, a lot of big classes will try to have default times. If the default time also doesn't work for you, it is the class's responsibility to find a time that does work for you. OK, but you but you do have to let us know. So let us know early. Oh, it's up to my. I want to ask you. All right. So no one asked a question yet. All right. So the question for you. What's the what skill is least developed in most in many of our grads? You saw the answer. It is so lame. Sorry. Oh, good answer. Good answer. I wonder how you knew that. I don't know why my laptop did that to me. So shameful. All right. So, yeah. So a lot of people, a lot of our alumni tell us in industry, industry contacts, people that come and recruit here say, you can probably do a better job with your soft skills. Right. So one of the things you will do in this class in discussion sections, you will work in groups. So you have an opportunity to meet people in the class, solve fun problems related to the lecture together and practice working with others. In later classes in ECE, there's a lot of teamwork. There's always hands on work and there's a lot of teamwork in later classes. This is actually feedback from a long time ago, although I think we can still continue to improve. But there's now required team projects, I think, in every route through ECE. So you will eventually have to do big class projects with team members. But even in these introductory classes, you're going to be working with people every week. OK, so so use it to meet people that you can work with, talk to, do your homework together and try to develop your soft skills because employers are looking for that. It is important. All right. So how are we going to grade? So we got 15 percent on labs, 15 percent on homework, 5 percent on discussion sheets, midterms. First one is 10. Others are 15 and the final is 25. A lot of people, if you are if this is your first semester in college, you might wonder on an exam, well, did I get an A or a B, etc. We don't typically do that in engineering classes. We just do points. Right. So you've got some number of points. And out of out of all the possible points, you'll get some number from zero to 100 percent of the points. And then we'll map that. I'll show you a mapping in a second. But it's your typical absolute scale. And so we'll map that to a grade only in the end. We will, as part of that calculation, drop your lowest score for your lab, your lowest score for your homework and your lowest score for your discussion sheets. So if you if you get sick and you miss a week or something, don't worry too much. But we don't accept late assignments. So make sure you turn things in on time. Part of that is part of that is that, you know, we're going to put homework solutions out. So once the homework solutions are out, we can't really take take the homework because the solutions up. So so do them on time, please. And the other reason, honestly, too, is if we extend an assignment with a 400 person class across many weeks, it becomes a challenge to grade. We have a big team of graders that's going to try to get your homework back quickly so that you can get the useful feedback in time. And if they then have to go back and grade previous week's homework because people turned them late, then it just becomes completely unmanageable. So it's another reason we just decided, you know, no, no late assignments. So finish them on time. And we do try to drop one of each to to account for, you know, S happens kind of things. I guess I can say it in other languages. So the ECE 120 grading scale is absolute. So, again, we calculate total points based on the percentages you just saw. If you get 90 percent of the points, you get an A of some sort. More details on the wiki. I think it's like 93 is 90 to 92 is an A minus 93 to 97 is an A, 98 and up is an A plus or something like that. Look on the wiki if you want more detail. 80 percent and up is a B of some sort. 70 percent is a C of some sort. Many of your classes here will be curved. Right. So many of your classes will just say, well, you know, we'll target something on the exams, maybe 75 percent, maybe 50. Actually, some ECE classes, I think we're targeting 30 based on their outcome. But that's the average. So remember, if you got like 35, that was actually a good score. Yeah. You can imagine that feeling right before you know the average. We've all been there. So it's OK. So many of your classes will be curved. Right. So just realize that for the future. And you can ask the professor in your class, is this curve? Is there a scale? What's the scale? In here, this will be this will be absolute unless we really blow it on an exam. And the exam average is 50, in which case we're going to we're going to raise up, raise people up so that more people are getting A's and B's than the absolute scale. So we will make it easier. We won't make it harder. All right. Again, I mentioned soft skills, but but do get to know people. Right. So, you know, talk to people in your lecture, talk to people in your discussion section, go to Open Lab. Once a week we have this Open Lab every Wednesday, nine to five in 2022. There's a Redbook. So if you want to if you want to meet people, there's a Redbook. You can sign up in Terry Peterson's office in the advising office. You know, I was sort of joking, but, you know, if you want to turn and say hi to your neighbors now, it'd be OK. I'll walk over there slowly. All right. So don't cheat. You know, this is always painful to talk about, but but it does happen sometimes. So I want to mention it just because we do say we do take it seriously. There's a code online that that describes it in a lot of gory detail for you, which you should read once in your life since you're here. So that's the number. If you type section one of one for two academic code UI, you see it'll come up. Discussion sections. So the other thing I actually much more serious note, every class is different. Right. So every class will have a different interpretation of what it means, what's allowed and what's not. So be sure in every class that you figure out what that class allows and what they don't, because the line's a little blurry and it's in different places for different classes. So make sure you know where the line is in every class. So this stuff is just meant to help you with what's the line in this class. So discussion sections are done in groups and some labs you'll have partners. Otherwise, your work should be your own. So you can talk to each other, you know, help each other understand, but don't give each other answers, share answers, give any kind of electronic answers. Let someone copy your answers. You know, if one person lets another person copy and we find out we give them both zeros. And we apply that penalty. So, so please don't. And I don't think any of you will, but somehow it happens. Your guide to the slides. I'll leave this. I won't go over it here, but, but it's there in the slides. So. All right. We've got a few minutes left. So let me talk about, you know, actually, with my remaining few minutes. I mean, you probably know this, but you can't eat here. So if you get a little peckish in the afternoon. Sorry. But I'm a professor. So. I can do what I want. Unfortunately. You know, it's a little embarrassing. I need, I need your help because my kids eat this thing called a peanut butter sandwich, but. It's a little embarrassing. I just need your help to tell me what to do. So I got some bread. It's sourdough bread. I hope that's okay. And I got some peanut butter. I got some paper towels because the janitors will still kill me. And I got some white paper towels too to destroy all the evidence. And I have this knife. What should I do? Can you help? Can someone help? What do I do first? Yeah. What's your name? Eric, what do I do? Open the bag? Okay. It's not working. Yeah. All right. It's open. It's open. What's next? Take the bread. Good bread. Someone else want to help me? Yes. What's your name? What should I do next other than chew? You're really going to let me do this? All right. So what's the point? There's abstraction, right? You kind of think I know how to use things like a plastic bag or maybe how to undo a lid. And humans have a lot of abstractions that we learn about. I'll give you a couple more examples in a minute. But that abstraction, we think about it in terms of interfaces. Like you tell me, okay, open the bag. Eric told me to open the bag. And Raul told me to open the jar. And you expect that I know what to do. And there's an implementation. There are lots of different jars. There are lots of different bags. And each of them has that interface of, well, open it, close it, take something out, put something in. And you expect that I'm going to know what that means and how to use it as a human. So an abstraction layer is just that. It's some implementation that provides you with a set of functions. And it's built on something underneath that also provides a set of functions to it. But many different ways to do it. Many different bottles, many different bags. So that's an abstraction layer. Just to give you a couple more examples, humans know all kinds of abstractions. So if you get in a taxi, you don't tell the taxi driver, okay, lift your right hand and put it on that stick there. You tell them, hey, I want to go to the airport. And you expect that the taxi driver is going to take that airport and turn it into driving instructions. And maybe even helping you put your bags in the back and so forth and so on. There's an abstraction of you just say where your destination is. Taxi driver takes you there and then takes the money. And you should tip. And then the water faucet. What's the abstraction? Well, the functions are get water at some fuzzy rate. There's a low rate and a high rate and maybe a medium rate. And there's a lot of ways to do it. You could use plumbing. You can use water tanks, cisterns, wells, aqueducts, valves, knobs. There's lots of ways to build a faucet. And you could probably use all of them as a human. But the abstraction is, you know, get some water. And you don't want to care. How many of you know how to build a faucet? Okay. So some people. Raul, right? Some people do. And probably most of you could drive a taxi for some form of drive a taxi. But, you know, there's lots of actually probably not many of you would know enough about the local area to drive a taxi well. But you could do the driving part. But the, I guess you can buy GPS. But those are abstractions. So starting, I guess we have a few minutes left. So maybe I'll start with the first few of these digital systems. We can break into seven layers. So this is taken from Pat and Patel. This is figure one six, as I recall. Digital systems break into seven layers. So down beneath this is the electrons. Right. So what we'd like to do is say, electrons, I want to go to the airport. And the electrons will form up a taxi and I'll climb in and then they'll zip me down to the airport. And then it'll be good. Unfortunately, no matter how much I talk, I don't talk to electrons. No matter how much we try, it doesn't work. Right. Electrons don't understand human language. So we've got all these other layers in between where we try to turn human language that describe problems and tasks into electrons moving around on a chip that can implement some problem solving. Problem solving for us, including autonomous driving. So not really too much of a joke to use a taxi. All right. So the color coding I've added human language theory is yellow. Software is green and hardware is blue. Those are sort of typical implementations of these layers. So let's let's go through these. So, yeah, that was my electron joke. Actually, I stole that one from E.L. Pat. So credit him. All right. So problems and tasks. So this is the first layer at the very top. So, for example, these are state and natural language. And I want you to answer this question. What's the sum of numbers between one and three? Think of it in your head. Don't shout it out. OK. Is it hard? You got it? You ready? I have to walk all the way back over here. So. All right. Sorry, your answer was wrong. It's mean to play tricks on your non-engineering friends and take money from this from this question. So don't do that. All right. So what's the sum? Did you answer? How many of you answered six? How many people said, oh, some of numbers from one or three? Yeah. Some people answered six. But no, because if I ask you, OK, look, here's my bread. Pretend this is a sandwich. What's between the bread and the sandwich? Is it the bread? So if I say what's between the bread, you wouldn't say, oh, it's the bread. The bread is between the bread. So you shouldn't add one and two. I'm sorry, one and three. Right. Well, what if you answer two? So you say, I have a better answer. No. What about two point five? Did you include what about pi over two? What about E? Do you add those in? Right. So maybe some of you did anyone answer infinity? OK. Oh, my gosh. Right. You can read. The answer is still wrong. The answer was six. All right. So what's the problem there? The problem is inherent to natural language. Right. There's ambiguity. What is between mean? Right. How did we know? Did I mean integers? Did I mean real numbers? Maybe I meant complex numbers between one and three. Right. Along the line in the complex plane. So another example, time flies like an arrow. What does it mean? How many of you do Pokemon Go? A lot, huh? So before Pokemon, there was Yu-Gi-Oh. You know Yu-Gi-Oh? And one of the Yu-Gi-Oh characters was Time Wizard. He looked kind of like this. This is Time Wizard. Time Wizard and I, we're good buddies. I'm on a first name basis. I call him Time. Turns out that when Time Wizard flies, don't try this at home. This is purely television, you know. Could hurt people if you try this at home. I talked about safety. Critical, critical technology. OK. I'm doing this really fast because we're running out of time. So it might not fly as well as it should. I'm not an aeronautical engineer anyway. Time flies like an arrow. Clearly that's what that means. Right. Time flies like an arrow. At least when you give him the proper plane. OK. So I don't want to run too much over time. So I will stop there. But I did want to show you. And you can just come down and look at them. Or maybe I'll take them outside. Here in Illinois, we have the, I think still the only fabrication facility. Intel donated one of their old tabs. These are examples of chips students have built here. So try to be careful with them. But you can see already some of them are broken. So don't feel bad if you break them. And I'll let you take a look if you're interested. And then maybe I'll drop them. But there's a lot of cool stuff you can do here. There's also a new nano lab just outside, up one floor. Transcribed by https://otter.ai you you you you you\",\n",
       " \"Okay, so yeah, I'm sure you saw your email. Well, hopefully you saw your email. So yeah, sorry about that last time. So today we're gonna talk about wrap-up fixed and floating-point. Maybe do another example, maybe on the tool or something. Talk about human text representations, and I want to give you kind of a taxonomy for thinking about bits versus representations versus data types as I'll use those terms in class. So before we get started, you know, since I taught this class a couple years ago, somehow they took five lectures and then they took some of it out and they left three, but I still have five lectures to deliver it. So we're a little bit ahead. So I have to speak really slowly. So how many of you saw Zootopia? Yeah, okay. So if I teach like a law... Yeah, anyway, so I can't stand it. I'm sorry. I'm gonna have to go back to fast mode. Oh, it's supposed to click. There we go. Yeah, how many of you watch movies? You like movies? Okay. So I figured I'd just waste some time and ask for your help. You know, I was talking to Ravi Iyer and he's teaching a junior-senior level probability class and he's saying, you know, I asked my students to do a Karnaugh map or he mentioned something they could use a Karnaugh map. You'll learn about those in a couple weeks. And they said they couldn't do it and his grad student said, well, it's probably context. And they're just out of context. All right, so let's talk about movies. So you watch movies, right? I need your help. So my friends want to have a movie club with me. So there's three we're thinking about that are coming out here. There's a Jackie Chan movie on the way. There's wildlife, there's animation. Both of those are kind of funny and there's a Beatles documentary coming up. And the problem is that, you know, I'm a professor and they're kind of picky too. And so we have to agree in advance which ones we're going to watch. Otherwise the deal's off. We're not going to go out together. So I need your help. So here's the rules. So for me, I was in Asia. Jackie's movie came out a while ago. I don't want to watch it again. It was good, but I don't want to watch it again. But I do want to, you know, what's the point of a movie club if you don't go see a movie, right? So I say got to have one movie, but I don't want to watch a Jackie Chan film because I saw it already. If you want to watch movies before they're out in the US, you have to go somewhere else in the world where they get released earlier. My first friend here says three is too many. So can't watch all three. My security friends Alice and Bob, Alice says let's watch exactly one comedy. Beatles or no Beatles is fine. And Bob says Bob loves the Beatles. So we have to see that one. So somehow I need your help. I mean, I need you to help me satisfy all of these people. Have any ideas? The last two? You just solved that problem in your head? Can you help me a little more slowly, please? Can we maybe apply something? I know you. Okay, maybe it's too easy. Sorry. Okay, so this first sentence, I won't watch Jackie Chan, so it means not Jay, right? Good answer. Okay, so we need to translate this into Boolean, I think, right? So won't watch Jackie Chan means not Jay. So I need to connect that then to this other clause. How should I connect it? So don't translate it yet. Once I translate it, what should I use? What operator should I use to connect my J prime to this next one? And, right? Because it has to both be true. Otherwise, I'm not satisfied, right? So I want J prime and, okay, now go ahead. What do you want this watch at least one to? So W or B. Technically, if I forget that I'm going to end it with this, it's actually all three, right? Watch one movie is just this thing. Now, you're right that the J doesn't matter because once I distribute this, I'll get J prime J, which is always zero. So I could just cross out the J. That would be the right answer, too. That's okay. And so some of you are kind of skipping it and, you know, optimizing it in your heads before you answer. So that's fine. But this is not optimized, right? Watch one movie means one of the three is true, right? Any of the three is true, an or function. So good. Good. I think we're making progress. So you've got LaMetta translated to Boolean. Okay. What about this next one? Three is too many. Okay, I'll let you all think about it. So not J or not W. Okay, here's how I did it. Does this look like... So I claim this. So if I don't watch this one, that's fine. Or I don't watch that one. That's fine. Or I don't watch that one. But one of the three I'm not going to watch. As long as I don't watch all three, that's okay. I think that's it. You know, there are lots of ways you can write any Boolean expression. So as long as your way was equivalent to this, that's fine. Okay. Actually, we'll look at good ways to write them in a couple of weeks too, Boolean optimization. All right. So Alice, my security friend. Many of you understand that joke? It's okay. You will later. The question is when you take a security class, whether you think, oh, now I get LaMetta's joke from two years ago. All right. In security protocols, the two people trying to communicate securely are always Alice and Bob. So these are my security friends. Yeah, it's a cheesy geek joke. I know. I know. I gave it away. I did the spoiler on the joke. So how do I set this into Boolean? Okay. So I'm hearing some J, X, or W. So let's watch exactly one comedy. There are two choices, right? So I can use XOR, the odd function, to say, well, I want either J or W. So J, X, or W. Is that right? Okay. And then Beatles or no Beatles is fine. So that's an and. And what does that give me? B or not B. And here I simplified and I just put a one. So yeah, B or not B would be a more accurate rendition, which of course B or not B is one. So I cheated and put the one. Okay. What about Bob? Just B. Bob says B. Anything else? Don't care. But B is not there. He's out. Okay. All right. So we've got the Boolean expressions. Now we need to satisfy all four of these people. So again, the all function, we need and. So pop up our handy truth table. So help me fill these in. So when I have an and, the easy way to fill in the truth table is to say, well, anytime any of these functions gives me a zero, that's a zero, right? Because in order for me to put a one, I have to have all of them be true. So what I can do is go one by one and look for the zeros, fill the zeros in. Whatever is not filled in is a one. So let's start at the top. Let's take my first clause, J prime. So J prime means anywhere that J is equal to one, that's going to be a zero. So this one, this one, that one, and that one. Those are not good options. Because I said I'm not going to watch the Jackie Chan movie. So those four options in my truth table are out. So then we'll go on to the next step. So what is this blue clause roll out? Yeah, good. So that zero, zero, zero line, that's not allowed because I said, well, we've got to watch some movie. It's a movie club. What's the point of saying, hey, I have this really cool movie club. Well, what did you watch? Well, we didn't watch anything. Wow. Okay. So that's that clause. What about this next one? Just the one, one, one, right? So that's already a zero. I'll just put the little color coding. I added that late. So if you look at the slides online, the extra color codings are not there. But, but that's just overlapping. That's already a zero. So what about, what about Alice's comedy role? So J or J X or W. Yeah. So zero, zero, one's not acceptable, right? Zero or zero X or zero is zero. So this one up here, that's not, that's not good. So there are some other ones. Yeah, the ones down, zero, one, zero is okay. Right? Zero, one, zero, we've got J is zero, W is one, so zero X or one is one. So that one's okay. This one's okay. These two, yeah, those two are not allowed. And this one up here also not allowed. So we could add those in, but they're already zeros. So let me add the little color stripes there. And so Alice would also rule out those, those three, but they're already zero. And then what about Bob? B has to be one. So this one here is out. And there's some other ones that, that Bob would also say no to, except they're also already zeros. So that one left. We've checked all the clauses. So that one that's left is a one. So got the right answer. Eric's answer was right. Okay. So you're able to apply this for useful, useful real life examples. Okay, I'm done. I'm going to watch my movies. Okay. They don't open till the second. So, and that's, that's the Jackie Chan film. So we're not going to watch that one. All right. It's a good movie though. I already watched it. Yeah. I didn't tell you the name. It's, should I say it on video? Yeah. There's a new Jackie Chan film. It was already out in Asia. So I watched it. It's out on the second tier. You should watch it. It's funny. All right. Yeah. Those were all actual movies. I pulled them up off the movie opening website last night. Okay. So let's, let's go back and look again at floating point. And I want to go through this and do a couple examples, but remember that we use 32 bits to store a floating point number in IEEE floating point. We've got a sign bit, we've got an eight bit exponent and we've got the 23 bit mantissa and the meaning for most of the numbers is given by this equation here, right? So we have the sign bit, which tells us positive or negative. We've got 23 significant binary digits. And then we've got an exponent that lets us run from about 10 to the negative 38, which is two to the minus one 26 up to 10 to the 38 or so. That was review. I mentioned, I mentioned denormalized numbers, infinities. Those are not things you need to know for exams, but I'll tell you a little more about them. Cause we do have a little time. So I added some starred, I added some starred slides. So this means not testing material up here. So if you see stars in the slides, just like if you see the starred sections of the notes, that's just so you can kind of learn ahead if you want to. So if you're excited about the material, you want to know more now, it's stuff you'll probably see in later classes, but you know, feel free to read it. Feel free to look at these slides. If you feel like you've, you've seen enough and you're getting stressed about exams, don't worry about this stuff. It's not going to be on there. So IEEE floating point was allowed, was designed to allow you to, to have solutions to problems like dividing by zero. So if you take a positive number, you divide it by zero. There's actually a representation for infinity. There's a representation for negative infinity, and there's a set of representations, anything with a non-zero mantissa and exponent 255 called not a number. So what is that, what is that good for? For one thing, if something goes wrong with your computation, you can kind of look at where the not of numbers, where the not a numbers are and figure out what went wrong. You can also ask things like, well, if I write some set of mathematical equations, let's say that I don't know one of my original variables, what are the outputs that depend on that variable? Rather than looking through the code and trying to understand it, you can simply set that input to not a number, run your code, and then whatever outputs end up as not a number, those are the ones that depended on that input. So there's some useful things you can do from kind of a software debugging point of view. You get not a numbers when you try to do things that don't make any sense from a numeric point of view, like you take infinity and multiply by zero. So it might've been had you not taken the infinity first, that this would be some finite value. But if you tell the computer multiply infinity by zero, it doesn't know whether it should give you one or five or zero or infinity. And so it gives you not a number, right? To say, well, I don't know what the answer is. But has that one useful extension. The other extension that I mentioned briefly because it gives you a zero, but it's the idea of denormalized numbers. So we talked about, go a couple of slides back to remind you. We talked about this implicit one, right? That the only in canonical scientific notation, normalized scientific notation, the only digit that we go at the start is a one because it's written in binary here, right? It can't be a zero, so it must be a one. Now that doesn't let you write zero. So that's one issue. But it also has this issue that if I were not to have denormalized numbers, my smallest exponent would be zero minus 127, right? So this would be the smallest number at the closest I could get to zero. So plus or minus two to the negative 127. And then I would have, if I just had a three bit mantissa, just for illustration purposes, I'd have seven digits spaced out to the next, I'm sorry, seven bit pattern spaced out to the next exponent at two to the minus 126, right? So the numbers I would be able to represent without denormalization would look like this around zero, actually would not have a way to represent zero either. So that's a different problem. But these are the numbers that I would get. Instead, what we do is we denormalize, which means instead of having the implicit one, if the exponent is zero in the IEEE format, then what happens is you have an implicit zero, right? And so then the representation represents the numbers as I've drawn them here. So you can see it just takes these same bit patterns and it spreads them out. And it gives you actually two different patterns, plus or minus zero, right? So it gives you a nicer set of numbers around zero. So that's why they included in the spec. And you certainly need some kind of representation for zero. And again, the representation for zero is the all zero bit. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. That's right. That's right. And so there's also an offset issue that the exponent for denormalized numbers is still two to the minus 126 instead of two to the minus 127, but the bits themselves then go down below that level because there's a leading zero instead of a leading one. So visually, there are 23 bits of mantissa, right? But that would be 8 million lines for me to draw here. So it'd be hard to understand the diagram. So this is what the three bit mantissa. You can see it a little more clearly how it works. But the idea is to get numbers spaced around zero instead of having numbers be scrunched up around the smallest leading one. So that's the denormalization idea. And that's why they put that into the spec. Okay, so I wanna go back and just do an example. There's an example in the notes, but let's not do that one. That one you can look over yourself at your leisure. Let's instead pull up the tool and we'll do an example. So we'll go in both directions. We'll do this one first maybe. So if we wanna convert from decimal to IEEE floating point, what we'll do is take our decimal number and convert first the integer part to decimal. You know how to do that, I think, from very start of class. And then we'll take the fractional part and convert that to decimal. That'll give us binary scientific notation. We'll normalize that. And then we'll take the three pieces, the sine, the mantissa, and the exponent, and we'll put that into our floating point format. So before we go off and do that, here's the math behind it. So if you take your fraction, again, you can write your fraction using a polynomial. So it would be the part after the binary point. So 0.101 or whatever. So those terms after the binary point can correspond to inverse powers of two. The first digit is the halves digit, the quarters digit, the eighths digit, and so forth. So in order to take this formula and get the individual A terms out, what we need to realize is that, well, it's a fraction, but if we multiply it by two, then it can become bigger than one. So fraction, I mean something between zero and one, or zero and smaller than one. But if we multiply it by two, it can become bigger than one, but that can only happen if this one, this term here is a one. Otherwise, all of these others, a quarter plus an eighth, et cetera, those don't add up to one. And so if we multiply by two, the only way we'll get something greater or equal to one is if A minus one is equal to one. So we can just multiply our number, our fraction by two, and that'll tell us A eighth minus one. So then we can subtract that term off, and we can do the same for A minus two. Then we can subtract that term off and do the same for A minus three, four, so forth. So let's go do that, not for this one. Okay. Let me make sure that it's gonna let you see what I'm doing. Okay, we'll go to representations and logic. All right, let's get a more intimidating looking one. So I'll just keep pushing new problem until we get something moderately long. Okay, how about that one? This one's a little easy because it doesn't have an integral part, but actually maybe that makes it a little more challenging. Okay, so let's figure out how to turn this into IEEE floating point. So we got 0.5625. So our integer part is zero. So let me go over to Notepad. So the fraction then is 0.5625. And so we'll multiply that by two. And what do we get? 1.125, all right. Looks right, I think it's right. Okay, so that's our first round. And you can see that's bigger than one. So that tells us A minus one is one. Okay, and then we'll have 1.125 minus one, subtract off the A minus one. That'll give us 0.125. Multiply that by two. That gives us a quarter. Now that one is less than one. So that means that A of minus two is what? Zero, right? Good. Okay, so I'd subtract zero. So let me write it out even though it's not gonna do anything. Oops, sorry. So my 0.25 minus zero. So I'll just be explicit. I do have to subtract the A minus two, but it's zero, right? So you don't really have to do this part when you do it yourself. I just wanna make it clear what we're doing. So two times 0.25 is 0.5. What's A minus three? Okay, so I'll just subtract the zero again. Two times 0.5 is one. So what's A of minus four? Good. And one minus one is zero. So, okay. So there are my four bits after the binary point. So the integer is zero. So I have 0.1001, and that's my fraction. Let's write that down here. So if I put that in binary scientific notation, what is it? Yeah, so I need to shift the binary point over here, right? Cause I need the leading one. So it'd be 1.001. And what's the exponent on the power of two? Negative one, like that. Okay, all right. I'm sorry. Oh, I screwed it up. I'm sorry, thank you. Okay. Yeah, same thing, right? All I did is shift the binary point over by one and put the exponent of negative one on the two. Good. All right, so now we can go back to our tool. And what's the sign? Zero, okay. Oops. The exponent then was negative one. And remember that we need to have negative one plus 127, right? So we should have 126. Right, cause we're gonna subtract whatever number we put here to get the exponent back, we're gonna subtract 127. So to go in this direction, we'll take the exponent minus one, add it to 126, and that'll give us the exponent value that we write into the floating point format. 126 is 7e. So this, unfortunately I had far too much experience translating decimal numbers into binary, but wouldn't expect you to do that in your head or anything. But 7e is the exponent. So let's go fill that in. Oops. There we go. So 01111110. Okay, ignore that last one. We can actually go check the answer now to see that we've got the exponent right. So the green means that we got it right. So we filled in the sign, filled in the exponent, those are both correct. And then for the bits, let's go back and look at our answer. Again, remember the leading one is implicit. So this is not represented in the floating point format. These are the bits of the mantissa. 001 followed by a bunch of zeros. So I'll go back to the tool, put in 001, and then hold zero down for a while, and check the answer. And ta-da, it was right. So that's it. So hopefully it's straightforward enough that everyone feels like they could do it themselves. We can also go in the other direction. So you can go push decode, and you get this rather intimidating looking bit pattern. Well, you'll notice there aren't a heck of a lot of, aren't a heck of a lot of one bits, right? And so it's not gonna be nasty to you. There won't be too many one bits in the tool. So if we wanted to translate this, let's see. So the first step would be to turn this into scientific notation. So what do we have? So what's our sign, positive or negative? Positive. And what's our exponent? This one's the 128 bit. That one's the one bit. So that's 129 minus 127. So two, right? Okay. And then mantissa, we just have a one. So let me go try to write that all down. So go up a little bit here. So we have 1.1. First one's implicit, right? And then the mantissa was one followed by a bunch of zeros times two to the two. You said it was the exponent. So maybe I'll translate that to regular binary. So that's one, one, zero. That's it, right? What number is that? Six, good. Six, correct. So it'll give you kind of a hint because it'll tell you how many digits you need for your typing, but you can do those exercises until you're happy and comfortable, which maybe is already the case. So you can use it to go back and forth and do those exercises. Do you feel comfortable with that? Feel like you could do it? How is it six? Okay. So let me highlight parts. Yeah, so there's this implicit one, right? This part is implicit. And then this part was the mantissa. There was just a one bit in the mantissa. Let me go back and show you that. So the mantissa here are the blue section of the bits and you can see it's all zeros except for that one, one. And so the binary scientific notation, there's the implicit one followed by the mantissa, which is just one, one. So 1.1. And then the exponent, remember the 128 plus the one bit. So that's 129 minus 127 is two. So that gave us our times two to the two. So that's where our scientific notation form came from, which is here. And then all I did is I shifted that bit over by two for the exponent to give myself one, one, zero, and then translated one, one, zero, which has no fractional part. So it was a relatively easy problem. Yeah. Yeah, sure. Let's get one with a fraction, right? I think that'd be better. Did you have another question? Yeah. Yes. The question is, there's a negate on the tool and what is it checking? Yes, it's checking that you were paying attention in class. Scale is kind of similar. Yeah, so how do you negate a floating point number? Well, you flip the sign bit and then you type all those others. So that's why there's lots of ones and zeros there, because it should be pretty easy to copy them. Yes. So hopefully you don't use this one too often. I mean, you just need to flip the sign bit. Scale too is, if you think about this a little bit, so it does things like asks you to multiply by powers of two or divide by powers of two. So you need to figure out how big a power of two and then just change the exponent. So some are easy, some are more challenging. Let's go back and do, let's see, oh, this one looks long. OK. Yeah, the question is whether I can do that fraction in my head. OK. I have a calculator. So all right, so let's do this one. So let's see, what's the exponent? That's the same one we had before, right? 126, so negative 1. OK. And then the sign, positive or negative? Negative, good. And then for mantissa, we've got an implicit one followed by four ones. Let me go put that in. OK, let me fill some space. Space. OK, so implicit one, four ones in the mantissa, exponent minus 1, and minus sign in front, I forgot. Did I forget anything else? Yeah, yeah, yeah. So this is just scientific notation, right? So if you were to change this into non-scientific notation, which we'll do before we convert it, you shift the binary point over left by 1, and then you'd put a leading 0 to make it look like a normal number. So this will be minus 0.11111, which is 31 32nds. Is that right? OK, so I'm going to cheat. And it's not really cheating. I don't really care if you know what 31 32nds is. 31 divided by 32, 96875. So this is equal to negative 0.96875. And we'll go over here and say negative 0.96. OK. Make sense? Yeah. OK, so the part without the calculator was this. Halves, quarters, eighths, sixteenths, 30 seconds. So this is 31 32nds. Yeah, yeah, the fraction is 31 32nds. Yes, this is a half, a quarter, an eighth, a sixteenth, and a 32nd. Yeah. Yeah, so all I did is I converted that to 31 32nds. I think someone in the audience said that's 31 32nds. So yeah. So I took that and took the calculator, 31 over 32, and it told me this answer. If you happen to know what a 32nd is, and you can subtract it from 1, you can do it that way too. I'd have to think about it for a minute. OK. All right, let's go back then. Let's go back and we'll skip over this part. So let's do this one. OK, so here's a trick question for you. What is that? Anyone? Now you're nervous? Do the minus 30? OK, good. What's this one? Really? That's not what my computer told me. OK, I'm hearing that makes sense. I mean, to me, I'm not sure it makes sense, but that's how floating point works. So let's explain why it works that way. So our first sum in that second problem was 2 to the minus 30 plus 1. So you want to put the 1, your exponent's got to be 0, right? To hold that integer 1, you need to have that be the leading term in your binary scientific notation. Well, so we got 23 mantissa bits. What are those? Those are powers of 2 down to 2 to the minus 23. So if you add in 2 to the minus 30, it's got no place to put that, right? So 2 to the minus 30 just kind of falls off the end. It's too small. So 2 to the minus 30 plus 1 is 1 in floating point. And then, yeah, 1 minus 1 is 0. That's exactly right. So floating point is not associative. So this can be a problem. It's a very hard problem, actually. I've seen people whose work is computational science sometimes not realize that this kind of problem is giving them wrong answers. I could tell you actually quite a few stories about that. There are fortunately some very good numerical analysts on this campus over in CS. So if you're interested in understanding exactly how to deal with these kind of problems, I would strongly suggest you take a numerical analysis class from them. My Keith, who used to teach them, but he's retired now, was also one of the best teachers on the campus. So I think there's some good classes you can take. Yeah? AUDIENCE 2. Is floating point associated with speed? So the question is, does the non-associativity affect speed? No, the non-associativity, I'm sorry, the speed is due to the fact that you're simply doing a much more complex operation. So if you think about, if I were to ask you to add two floating point numbers, what would you need to do? You'd have to look at the exponents, line them up, add them up, decide how to round. So there's actually quite a bit of complexity. And because it's more complicated when we build hardware, it tends to be slower. So, yeah? AUDIENCE 3. What happens to the bits that have some power? Yes. So kind of the point is that this can't be stored together with the number one, because there's only 23 bits of MENTISSA. So when you add those two in a floating point adder, the output has to discard that 2 to the minus 30 term. And anything else in those other ones as well. Now there's one slight difference. If you had one at 2 to the minus 24, then it has to decide whether to round up or round down. But if it's not 2 to the minus 24, then it's going to typically just throw it away. I guess if you round it up, maybe it would add it in. Yeah, so there's a rounding direction. I don't want to spend too much more time on this, but there are five different ways to round things in IEEE. I think it's five, maybe it's four. But people were seeing in one computation of weather prediction, seeing 30% differences in the final answers. And they traced back why. It turned out one machine rounded up, the other machine rounded down, down at the negative 23rd power level. So they can explode. They can be sort of chaotic behavior if you're not careful with your applications. All right, so here's hexadecimal. I want you to memorize this bit pattern. Do it quickly, because we're now running short of time. Computers always use bits, but for us humans, we can use hexadecimal, base 16. So you got that bit pattern? Good? Good. You're all ready, right? Got it? OK. All right, so here's hex. 16 digits. It's base 16, so that means each digit represents four bits. So each of the, we add in a through f, so a is 10, b is 11, so forth. And it's just a way to help us humans. So to make it easier for us to deal with bit patterns, because we can look at just digits instead of a lot of zeros and ones, which are hard to remember. Although I know you're good at it, because you memorized that bit pattern. OK. Ha ha ha. You're making it up. Ha ha ha. Ah. Ah. Terrible. Terrible. OK. So try it again. This time do it in hex. When we write hex, we usually have, in human form, we usually put some extra things. Because if I just wrote 1, 3, 5, 6, 7, you'd think I meant decimal. So usually we'll put something else in front of it, like an x, for example, to say, hey, this is hex. So this is all base 16 numbers. In C, we'll put another 0 in front of the x. But in Pat and Patel terms, just put an x in front. So that's hex. How do we represent text? Text was historically represented using an 8- or a 7-bit code called ASCII, American Standard Code for Information Interchange. But it was basically designed to represent English. So we had English letters, upper and lower case, Arabic digits, punctuation, some special symbols, like a dollar sign, a pound sign, hash mark, if you want to call it that, control characters for terminals. So people designed this code 50 years ago and kind of standardized it. And that became the thing everyone used for human text. Once most machines had 8-bit bytes in them, then most machines said, well, gee, we can do something with the other 128 patterns. So there were these extended ASCII character sets for graphics and things like that. But those more or less were not standardized, meaning that every manufacturer had a different meaning for those extra 128 patterns. There were standards, but no one really built machines to them. So other languages, other human languages, kind of caught on after Illinois invented the browser in 93. So MIT's media engine will tell you differently, but you should know the truth. Oh, well. MIT puts a lot of money into making you think that. But you're an Illinois student. So Unicode is the 16-bit modern form that includes most human languages. So Unicode will capture most other languages in the world. And that's the other one that probably I'd want you to know about. We'll try to differentiate in our class between representation and data type. I may have mentioned this before, but I want to use representation to describe a way of describing or turning something like signed integers into bit patterns, but not necessarily for a specific length. Whereas a data type will have a specific number of bits. So for example, we can talk about 32-bit unsigned or 64-bit unsigned. Unsigned is the representation. The 32 and 64 bits, those would be data types. The reason I want to make that distinction is when you get into higher-level languages, every variable that you use will be associated with a data type, meaning a specific number of bits. But the representations, in many cases, are just ways of encoding information into some variable number of bits. I'll show you this taxonomy that I dreamed up to try to help explain what I mean. So they're bits, and we use bits to represent everything. So whatever you want to represent in a computer, everything we've done, and vegetables as well, or ice cream flavors, you're going to use bits. For everything you might want to represent, there are different ways to represent them. So for non-negative integers, we looked at unsigned. We looked at a couple of ways to do just general integers. There are actually many floating point formats. IEEE is kind of the more modern standard that all the computers implement today, but there were other forms. There's fixed point as well. There's ASCII. There's Unicode. And then there's data types, where we say, OK, fixed number of bits. So for each of those, there are particular data types that we have particular number of bits. So this is kind of my attempt to try to help you organize some of the ideas that we've been playing with in the last few days or the last couple of weeks. All right. So most of the time, when you open a text file like you did in your lab, for example, everything in there is going to be either an ASCII or Unicode. So human text is generally going to be represented either ASCII or Unicode. What you type is going into ASCII, going into the computer in that form. Text is printed for you to read, comes out in ASCII on your monitor or in Unicode. But the computers don't understand what those bits mean. So when bits go in and out, they're just bits to the computer. So for example, if you tell a computer, hey, I want you to add the ASCII character for 3, the number 3. But it's the number, right? It's the ASCII digit 3. I want you to add that to 2. What do you think the computer will do? It'll add the bits. You told it to add the bits. It'll add the bits using an adder. You didn't tell it it was ASCII. You said, add the bits. OK. I know how to do that. So, oh, sorry. I was going to let you help me. 1 plus 0. 1, good. 1 plus 1. 0 carry the 1. 1. 0. 0 carry the 1. 1 carry the 1. You know what that one is? No, it's not an overflow. It's the letter E. You thought natural log was hard. Natural log is far. OK. Yeah, don't tell computers to do that. The right way to do that is you need to do something in software, probably, to convert your ASCII to 2's complement or unsigned, add those two numbers using an adder at that point, and then convert it back to ASCII if you want a human to look at the answer. So there's more steps involved to get it right. Yeah, there are other classes where, sadly, I've seen people struggle with this, where they write this kind of code in high-level languages, and they can't understand why the computer's not doing what they wanted. Hopefully, none of you will ever have that problem. Wow, good job. Excellent. OK. I think you get the point. I won't really give you any exercises to memorize this thing. Sorry, it's not a learning objective. But it's a lot easier. It's a lot easier to remember fewer digits than to remember lots of 0's and 1's and what order to put them in. Oops, wrong button, sorry. All right, so one more thing before we wrap up for the day. So this is it. And then we'll do C coding on Friday. So remember this overflow condition? We could give it a name. Let's call it V, that we developed for 2's complement. So I said that, well, there were two cases. And we actually wrote it originally in words. And then we wrote the Boolean expression for it. So you remember that we had two ways to overflow. If we wrote our addition this way, and A was the sine bit of one operand, B is the sine bit of the other, and then S is the sine bit of the sum, well, if I take a 1 in A, that means A is negative, and B is negative, and the sum is non-negative, something went wrong. Add two negative numbers, get a non-negative number, something went wrong. Or if I take a non-negative A and a non-negative B, and I add those up, and I get a negative sum, something went wrong. So those are the two cases that we had in overflow. And I said you should go read the proof. You did that, right? OK. In the other lectures, they were told a different formula. They were told that if I instead look at the carry out of bit n minus 1, the one that would feed in to add to A plus B, if I look at that and I XOR it with the carry out, that gives me overflow. So my question for you is, well, are those the same? We could use algebra. Want to use algebra? Not really that fun. I did it. It's not that fun. What about some brute force here? Brute force, yeah. Let's do a truth table. So we can calculate, if you think back to that sum, if I know Cn minus 1, I can add that to A and B. That'll give me S and Cn. If I add those three digits, I get the other two. So really I only have three variables. So that's only going to be eight lines. Let's do the truth table. So here on the left, I have the different possible values of the A bit, the sign bit of the first one, the B bit, and Cn minus 1. So if I add those three together, that'll give me a sum and then the carry. So what's 0 plus 0 plus 0? 0 carry 0. What about 0, 0, 1? 1 carry 0. 0, 1, 0? 0, 1, 1? 1, 0, 0? 1, 0, 1? 1, 0, 1? Good. 1, 1, 0? Good. And 1, 1, 1? OK. So now we can go calculate what we used as overflow. So if we have A and B the same, but S different than A and B, then that's an overflow. So the first line, we have A and B are 0, but S is also 0. So that's not an overflow. Here, a second line, A and B are 0 again, S is 1. So that's an overflow. Here, A and B are different, so we don't have to look at S. 0, 1, 0, A and B are different. A and B are different again, not an overflow. Different again, not an overflow. Different again, not an overflow. How about this one? It's an overflow, right? A and B are 1, but S is 0. So that's an overflow. And what about the last row? Not overflow. A and B are 1, but S is also 1. So all the numbers are negative. That's OK. All right, so now XOR the CN minus 1 and CN for me. First row, 0. Second row, 1. Third row, 0. Fourth, fifth, sixth, seventh, and eighth. Good, so we're done. Same columns, right? We just proved that the two are the same. Just fill in the truth table and compare the columns. They're the same function. Don't need to do algebra. All right, so that's the message. In a lot of the Boolean stuff, you can do algebra. You can prove by manipulating algebraic forms, which may be easy for you, especially if you do it a lot. But you can often prove things by pure algebra. But you can also, in many cases, simply write down a truth table. And if you're talking about two or three variables, that's four or eight different things to plug in and say, well, are they the same or not? So you definitely want to pick the easiest and fastest proof strategy. And brute force, especially in these kind of problems, is often something you seriously want to consider. Because you can get it done quickly and easily and have a correct proof. So let me leave you there. I guess you're 45 seconds early. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\",\n",
       " \"handout. Is there anyone sitting that doesn't have a handout already? We kind of need them in the middle, so let me try to pass a few around. And also come grab some candy if you'd like some. These are $2.25 in back. Let's see. You didn't have one, right? Okay. Yeah, one of each, one on top, one on the bottom. All right, so let's go ahead and get started. Let me go through this. So we'll talk mostly about LC3 ISA today, and then we might spend some time doing an example. Otherwise, we'll work through the example on Friday, examples counting to 10. I'll show you in a second where all the code, I just put up some more code for the next week or two. I may add some examples to that too as we go. So there are two handouts. One is the LC3 reference sheet. That's what will be attached to your midterm three and your final. And the other is the counting example code that we'll work through together in class. Let's see if it will let me switch over here. Okay, so now you can see that. All right, so if you go to this links page, and you go to the bottom, I added this LC3 code examples. So somewhere in PDF, if you want to play with the code, you can download it from the binary version, meaning LC3 binary that you can then compile with a tool. There's also assembly versions. We're not going to talk about subroutines in our class, but I just put the subroutine version up there if you're interested. There are also PDF versions, so you can just look at the code if you'd like to. So you can click on any of those. Let's see, let me go back to this mode. Okay, so those are all on the webpage now. This one again, I just keep reminding you until the deadline comes next Friday. All right, so the LC3, as we talked about a little bit last time, LC3 has three different kinds of opcodes. So there are operations that use the ALU, there are data movement where we move bits to and from, well, between registers and memory, and then there's control flow where we'll conditionally change the program counter. So control flow, if you remember when we talked a little bit about C, we said, well, you can break things down in sequences. That's what we get normally, right? We add one to the PC and fetch, and then we just walk through memory and execute, execute, execute. But if we want to do something like a condition or a loop that we do in C, well, we need some way to change the PC, right? It can't all be one line, a straight line of code through memory. So that's what those will be used for. So let's see, on Monday we talked a little bit about the operations, we reminded you that, well, the ALU and the LC3 data path only does these three things, add, and, and not on 16 bits each. All three of them, rather, have a source register and destination register, and then add and and have a second input operand. We said, well, there's two choices. We can either have another register, which is what you'd seen in detail in some of the earlier examples, or we can have an immediate number. And so we looked at how that got encoded. There's the opcode, which is either one for add or five for and. There's the destination register, these three bits from 0 to 7, and then source register 1. And then if mode bit here, IR5, is equal to 0, then that's the second register operand. So there are these next two bits, IR4 and 3, also have to be 0. And then the last three bits of the instruction specify the second register. So if you have this mode with this bit 0, IR5 equal to 0, then whether it's an add or an and, it takes source register 1, reads those 16 bits, source register 2, reads those 16 bits, does the operation through the ALU, and then writes the result back into the destination register. On the other hand, if the mode bit is a 1, then the second operand is an immediate value, which means that it's a number stored in the instruction. And so that number, since we only have five bits left, is a 5-bit 2's complement number that gets sign extended out to be a 16-bit value. And so when I say it's 2's complement, that means before you can put it into the ALU, you need 16 bits, so we're going to sign extend it to 16 bits. All right, and then we talked a little bit about what good are these instructions. So we said, well, if you want to add small numbers, you'll often do that when you're running a loop, right? You're adding one or subtracting one. You can add other small numbers too, but the range is pretty limited. If you want to add a bigger number or subtract a bigger number, then you need to use two register inputs for your add or your and. You can also mask out low and high bits of a particular register. So you can say, OK, just give me the low bit, just give me the two low bits, set the low bit to 0, so put two low bits to 0. Or you can put 0 in a register. So this one's kind of the most useful thing for and is just setting a register to 0, because we often need a 0 in a register. And then I think this was the last one we looked at on Monday. So this is the NOT encoding. NOT is opcode 9, destination register, source register. Since NOT does not have a second input operand, we just set all the rest of the bits to 1. So let's take a look at the data path now and see how we set up the data path to execute these operate instructions. So over here is source register 1. So there is a little logic that's not shown in this diagram. It's in the notes, but basically those three bits out of the instruction are used most of the time to set the source register, which then comes out of this port. So whatever 3-bit register name we give the register file, it delivers that register to this output port on the right here, the SR1 output. And similarly, SR2 would then go into the SR2 input of the register file, and SR2, whatever we've picked, will come out on this left port, read port of the register file. Now that's going to be true regardless of which operand mode we're using. As you'll see, we're going to read it all the time, and if we wanted the immediate value, well, we'll just throw away this answer. So the other thing that we'll always do is actually look at IR4-0, the 5-bit immediate opcode, sign-extended here. And then you can see this MUX over here. We're going to feed both the immediate value and source register 2 into the MUX, and that's the point at which IR5 will be used to say, well, which one do you want to use? And so if IR5 is 0, this input will get forwarded to the output of the MUX. If IR5 is 1, this input will get forwarded to the output of the MUX. So in hardware, typically, we'll actually look at both answers, and then we'll just pick one with the MUX. So there's SR2 MUX that decides which of those two is fed into the B port of the ALU. The ALU is then configured here with this ALUK control signal. And you'll notice that each of the three opcodes here have two initial bits. So for example, we could just feed IR15 and 14 into the ALU to decide what we want to do. That's one way to do it. So once we've set this all up, now we get the right answer. It comes out. It actually would go out onto the bus in one cycle and come back into the register file. I eliminated the bus from the figure. But you can see where DR gets fed into the register file. So when the rising clock edge comes, this answer is going around the bus and then being latched into whatever register we picked for the destination register. Now since this is a clock synchronous sequential circuit, you should realize it. But I'll just go over it just to make sure that you don't get confused thinking about it at the higher level. If your source register and your destination register are the same, that's OK. Even if both source registers and destination registers are the same, that's OK. Because when the rising edge comes, that's when the change happens. So just like a finite state machine, we make sure that the clock skew in the circuit is small enough that all of the flip-flops see the rising edge at the same time. So the old value and the new value, even if we're feeding one back into the other, it doesn't make any difference. All of the clock edges will happen at the same time. And when the register changes, it'll stop looking at the input. So when the register changes, then the output will change also. But that doesn't matter. We'll have the new value latched. And so it's safe to have one source register and have the same destination register. You don't have to worry about it. So let's take a look at loads and stores then. So data movement instructions are the next kind of instruction with LC3. And we're going to actually have four different addressing modes. There are loads. So a load, remember, takes data out of memory and brings it into a register. There are also stores. Stores take data from a register and put them somewhere in memory. So whenever we want to do that, well, it's easy to name the register. We need three bits to name a register. How many bits do we need to name a memory address? 16 in LC3. But we only have nine left. After we say we want to do a load or store of some sort, that takes four bits. We've got to say which register we want. So that's three more bits. We have nine bits left. So in fact, with most of the ways we're going to approach this problem, we can't go anywhere. We can't go to any address. We're going to have to somehow use bits from somewhere else to specify our address. But these nine bits with the different types of loads and stores will generate our address for us. It'll tell us how do we get the address for the load or the store. So let's take a look. So here's the first one. The first addressing mode is called PC relative. So what that means is we're going to use an address that's near the PC. So we're going to take those nine bits and say, well, let's start at the PC. And then we'll add that nine bit offset as a two's complement number. And that'll give us our address. So here's one opcode. This is LD. So LD says, well, take PC, add the immediate field here, nine bits of offset, sign extended to 16, add it to the PC. That's then our address. So go to that memory address, get the 16 bits. This is the load form. And bring those into the data path and store those in DR. And then the store form, of course, goes the other way. So you take for the address the same thing. So you see the address formulation is the same. So you take your PC, take your nine bit offset, sign extend that to 16 bits, add that to PC, and then use that as the memory address at which you store the bits in the source register. So same address generation for LD and ST. They just go in opposite directions. You could use this bit, IR12, the last bit of the opcode, as your memory rewrite control, for example. You'll notice as we go through the load and store style opcodes that in all cases, loads are zero and stores are one. Program counter. That's the address of our next instruction. It's a register. So wherever your address happens to be, remember fetch will increment it. So whenever you execute one of these instructions, PC will hold the address of the instruction plus one. But in general, it's a register sitting in the control unit. You will have to calculate the offset that you need here relative to the PC, which is relative to the instruction. So it's actually all of the PC relative instructions are relative to wherever the instruction happens to be. So it's very, very easy to do and very error prone because it's so simple. So you'll see as we write code, there's a lot of counting involved. So it's good that everyone here is good at counting because it'll take all the skill you have to stay focused. Yeah? So you need to know that PC, when it executes, holds the address of the instruction plus one. So you do need to remember that. And I'll go over that several times. In fact, very soon. Okay. So in fact, there it is. But I want to do an example just to make sure everyone understands. So PC is the value after fetch, right? When the instruction executes, that's when we evaluate this RTL here. And so it's the address of the loader store plus one. So for example, if I have a load at address 1480 in hex, and that load is destination register R3 offset nine. So this is just human notations convenient. So what would this instruction do? So if we go back and plug into our RTL, we've got memory at PC plus sign extended to 16 bits of hex 09. And then take that the memory at that location, store it to R3. So what is PC in this case? 1481, right? Because remember, after we fetch the instruction from this address, we'll also increment the PC in the same first fetch cycle. So PC will have value 1481 hex. So what's the answer? 148A, I think. So just make sure you don't think it's this. There are a couple of ways you can check, right? Once you write some code, you can go into the simulator and you can say, Oh, show me my code, make sure that whatever you did got the right answer, because it will show you the address. So it'll say load from this address when you tell it to show you the code. So you can check that your offset is correct that way. That's actually probably the best way to check is to have the computer check for you. But yeah, that's the easiest way. Okay. So time for quiz. So what's bits? Wow, you're good at this. I like this. 16 of them. Yeah. Okay. What's the next question? How do we name a memory address? That's good. Good. 16 of them, right? So what's the difference? 16 bits, 16 bits. If you were a computer, what's the difference between 16 bits and 16 bits? Nothing. Good. So I could, for example, say, well, 16 bits, it could be a memory address, right? And if I go to memory and I get 16 bits, well, it could be a memory address and I could keep going and going and going. So it's an important concept in software. And I'll come back to that in a second. But this indirect mode is going to do exactly that, but only do it one time. So what does it do? Well, it generates the address as if it were a PC relative address. But then what it does is it said, Okay, I'm gonna go to memory again. So here, what you can see is, well, we go to PC, we add sign extended immediate nine, just like before, just like PC relative. We go to memory and we get those bits. But wait a minute, there's another M outside of that. So those bits come back from memory, right? And then we say, well, that's an address. So we go again to memory using those 16 bits as an address. And we read memory again, we get a different 16 bits. Those are the 16 bits we then store in DR. So instead of just going once, we then take the 16 bits we get back and we go again to memory using those 16 bits as an address. And then we get 16 bits back again. Those are the bits we put in the register. What about the store? The first operation here is a read from memory, right? We still have to go generate our address by adding PC to the sign extended offset. Then we go to memory to get 16 bits. That's a read operation. Then we use the 16 bits we get back to do the store. So we do one read and one write for the STI. We do two reads of memory for the LDI. Yes, I can. Good call. All right. So why did they define this instruction? It's purely to make sure you understand what we talked about. 16 bits can be an address. An address is called a pointer in software. It's a really important concept for pretty much all of the higher level languages like C, C++. They're actually used in some level in other languages like Java, but you'll never know it. So they try to hide it from you. But in C and C++, you use pointers all the time. All of your data structures will be based on pointers and all pointers are as memory addresses. So if you understand what's a memory address, then you understand what a pointer is. How would you do recursive indirect? Well, I'll show you something in a second. You mean keep going and doing it? Okay, I'll show you another instruction in a second. Let me make sure. So you should realize this and indirect does it once, right? Go to memory, get 16 bits, use that as an address for your load or your store. Okay, so here's another one which you've actually seen. Once you get some memory bits into a register somehow, then you can use your register as the address of memory. So if you want to keep doing this as Daniel asked, you can use this instruction instead. So what is base plus offset mode? Well, your base is specified by another register. So now instead of only being able to access memory near the PC, right, plus or minus 255 or so, now you can use 16 bits of another register to generate your address. You can still add this six bit twos complement offset. So what we'll do is we'll take that six bit twos complement offset, sign extend it to 16 bits, but add it to some other register that's specified in the instruction. And that will give us our address. So then we'll go to memory, read 16 bits out, store that in DR. So for example, if you wanted to leverage the continued indirection, and often in software, you will build pointer based data structures where you might have to chase down them, you know, even a few hundred times for bigger data structures or thousands of times. But what you can do is put those bits that come back from memory in a register and then use LDR to go get the next 16 bits, put those in a register, use LDR to go get the next 16 bits and keep going and going and going and do what's called dereferencing your pointers in the software language for those of you who have done that. And the store side then, same address generation, take the offset, sign extend it to 16 bits, add it to your value of 16 bits from the base register, use that for the memory address, put the 16 bits from the source register into that memory location. Alright so how do you actually get an address into the register in the first place? So one option I'll show you in a second is a fourth addressing mode. You can also use load or store but you'll have to put data near the current instruction, right? The things I've showed you so far, other than LDR, STR, which then sort of begs the question of well how did I get some other address at all into the register so that I can then use that LDR, STR instruction. So those allow you to put data nearby and then to load those data into the register using LD or LDI. But if you want to just put an address directly into a register, there's a fourth addressing mode known as immediate. So here's an immediate value and what we'll do is generate the address in the same way that we did with PC relative addressing mode, but you'll notice there's not actually any memory access. So this is called load effective address, or LEA, and all it does is, so address is the same as PC relative but the memory is not accessed. So it's not even really a data movement instruction. Just generating an address, putting that address into the register, into DR. We can then use LDR to access adjacent memory locations using the offset. So this is the fourth addressing mode. There is no store form of LEA because it's not really even touching memory. So it's just loading the address into a register. Any questions on this? All right. Okay, so let's take a look in the data path. So first thing I want to show you is PC relative addresses. So up here you can see the PC is coming around and going into this MUX down here. So the PC goes along these wires. This is not the bus, right? So we're not using the bus for this. Goes into that MUX and then goes into the adder. So when we want to generate a PC relative address, sorry, I should have told you we'll configure this MUX to forward the PC input. Here's sign extended IR 8 to 0. So these are the low nine bits of the instruction. Those are sign extended to 16 bits. Then they go into this MUX, which we also select for PC relative addressing. We select this 8 to 0 sign extension. So those two then get added together. That's where the addition happens in this adder. PC plus the sign extended immediate nine field. That then comes out of this adder and goes into the MARMUX, which is then sent, forwarded that input onto the bus. So that goes out into the bus and goes into the MAR. So when we want to generate a PC relative address, these are the pieces we use in the data path to generate the address, the PC relative address, send it out on the bus into the MAR. Then we can simply tell memory, go read or go write. If we want to do a store, we'll put the bits into the MDR next. Those also have to go across the bus. Then we'll tell memory to do a write. If we want to do a read, we've got the address there. So we'll tell memory, do your read. And then we'll take the bits out of the MDR, put them across the bus into the destination register. Here's the data. So for a load, the MDR, after memory is told to read, will be copied across the bus and then stored in the register file. For a store, the ALU actually has a pass. So we'll take SR1 and we will pass it out through the ALU, ignoring the B input. So there's a fourth operation of the ALU, which was just give output A and put that onto the bus to move it to the MDR, which we can then tell the memory to write at the address in the MAR the bits of MDR, which is the source register. Make sense? Andy's wearing off, isn't he? All right. So LDI and STI, how can we do that? So there we're going to have to get 16 bits back in the MDR and that's going to be our address. Well, that's actually not too tough, right? So this is zoomed in on the bus near the MAR and MDR. So all we have to do is say, well, take the MDR after we do the read and copy it across the bus into the MAR and then we can do our load or store, right? Our LDI or STI, the second step is either storing or loading. So once we've gotten the first read set up for the LDI or STI, the second step, another read for an LDI or a store for a STI, we simply need to move these bits that we've gotten back from memory into MAR. And then for a store, we would use the previous mechanism to put the bits we want to write into MDR for a load. We just go ahead and exercise memory after setting up the MAR and then move the final result out into the destination register. All right. So one more, which is the base plus offset mode. So in this case, you can see here's the base register that falls in the same place as SR1. So that now comes out and instead of forwarding the PC from this address one MUX, we forward SR1. And so that comes in here. You can see the sign extended five to zero piece also of IR0 also goes into address two MUX. So we then pick the six bit sign extended field from the instruction, add that to the base register that gives us our base plus offset. And then again, that just goes through the MARMUX, gets selected to be put out on the bus, goes around the bus to the MAR. All right. Okay, so that's it for data movement. So the last kind of instruction is for control flow. So after we execute, so far what we've seen is we executed some address, call it A, and then the address is stored in the PC that gets incremented in the first phase of fetch. So it'll store A plus one. So after we finish our instruction, we say, well, let's go get another instruction. Well, we go to A plus one. And then in first stage of fetch, it'll get incremented A plus two. Then when we finish the instruction, we'll say, okay, let's go get another instruction. And I'll start looking at A plus two and so forth. But what about things like if statements and loops? We need some way to be able to say, well, I don't want to go just get the next one in memory. I want to go somewhere else because I want to have the ability to branch. I don't want to be able to do a conditional test and then execute two different pieces of code or do a loop, right? Go back and do the same code again. So control flow instructions will conditionally change the PC. So I'll explain what the conditions can be now. The LC3 actually has three condition registers that I hadn't mentioned before. We call them condition codes, but they're really three one bit registers sitting in the data path called N, Z, and P. So these are based on the last value that you wrote to the register file. So if you do an add, that writes to the register file. If you do a load, that writes to the register file. It's actually only for the operations and the data movement. There's some instructions. We're not going to talk about the details that also write to the register file, but they don't set the condition codes, just the operations and the loads. So the three choices, well, it's some last value. Treat that last 16 bit value as a two's complement number. And then you say, well, was it negative? And if it was negative, you've got this N bit set. And if it was zero, you've got the Z bit set. And if those 16 bits were a positive number, then you've got the P bit set. So obviously, exactly one of these three bits is one in any cycle. Always, if you've got a 16 bit two's complement number, it has to be negative zero or positive. It can't be a combination of them or anything like that. So you've got exactly N or Z or P, one of those three. So here's a conditional branch. It happens to be opcode zero. What you see here is three choices. So when you write your instruction, you can pick, do you want to look at the N condition code or the Z condition code or the P condition code or some combination thereof? So I'll tell you a little bit later how we combine them. But once you make that decision, that gets fed into this branch enable condition. And then the branch enable condition, we'll call it Ben. It's a little register also, one bit register, is used to decide, well, should you change the program counter or not? And only if the branch enable is set is the branch taken, in which case the PC gets changed to current value plus this nine bit value sign extended to 16 bits. So when you do a branch, the first thing that happens is the processor needs to check, well, let me look at the last thing that was written at the condition codes. Let me see what you're asking for. And if you want to, if that sets the branch enable bit, then we'll take this branch by changing the PC. If the branch is not taken, if the branch enable bit is false, nothing happens. Branch does nothing. And then you go to whatever your current instruction was for the branch plus one current address. All right, so for example, if you have, we write the branch instruction as humans with the bits attached. So we might write BRNP. It's actually case insensitive with assembly code. But we write BRNP to mean, well, the N bit is a one, the P bit is a one, and the Z bit is a zero. All right, so how is the Ben calculated? Well, it's calculated actually in the decode state. So the other thing that happens in decode, in addition to just doing a transition into some sequence for that particular opcode, is we actually calculate the value of the branch enable bit. And it's calculated like this. So you take your negative condition code and you AND it with the bit of the instruction IR11 that says whether this branch instruction wanted to look at the negative condition code. And then you do the same for Z and the same for P. So you take these three bits and AND each one of them with the corresponding condition code bit. And then you OR those three together. And then that's stored in the Ben. And the Ben is then used to calculate whether or not you take the branch, whether or not you change the PC. So let me do a few examples with you. So the first one up there, BRNZ. So when would you take the branch? When would you change? Yeah, N or Z. The condition codes, remember, only one of them can be true. So N or Z, which generally you can interpret as not positive. So branch if it's not positive. What about the second one? Always, right? So you can write unconditional branches by just putting all three. One of those three is always true. So if you take all three together, it's always going to branch. What about BRNP? Yeah, not zero, right? Because we left the Z bit out. So if it's negative or positive, whatever the last value after the register, if it's negative or positive, you'll take the branch. Otherwise, you won't. So by convention, you might run into this. So I just want to warn you, if you type BR with nothing, you might think, oh, that just does nothing. Well, no, by convention, BR means unconditional branch. And so if you type BR into one of the LC3 tools, you're going to get BRNZP. Yeah. So remember, let me go back to this. So whenever you write something into the register file, we're going to set the condition code. So the reason is, when we want to test, if we're counting, for example, let's just make it easy. Let's say we're counting down, and we're decrementing our register over and over again. That add instruction will generate a result that's written back to the register file. And so we can test, well, did we reach zero yet by checking when the Z flag, the Z condition code goes high. Because before that, presumably, it's a positive number we're counting down. And so until we reach zero, the P flag will be set. And then on the instruction that generates the one to zero transition by subtracting one from that register will generate the Z condition code instead, because we're at zero back to the register file. So anytime we write back to the register file with a load or an and, an add, a not, then we're going to go set one of these three condition codes based on the value that's written back to the register file. Trying to remember if I have the data path in a convenient spot. I don't think I do. Okay. Ah, here's a data path. So you can actually see it down here. I wasn't going to highlight this for you, but you can see the condition codes down there. There's also a control signal to tell the, tell the data path to load these three. It's not shown here. This actually comes straight off the bus. So it's whatever value is going back to the register file across the bus, you can, you can also tell the condition codes to just look at that value and set one of the three bits appropriately. Yeah. Well, yes, it's deciding. So for not, so n does not need to, right? So if you want to know is a number negative, you don't need to look at all 16. Yeah. But for zero and positive, you have to look at all 16. So how can you tell whether a number is positive? Well it can't be zero. Yeah. So both of those two, I mean, you can use the same logic to make the decision, right? You look at it if it's zero, and then if it's, if it's not zero, and it's not negative, then it must be positive. So yeah. That's right. Yeah. Yes. NZNP, exactly one of them will be one. You just changed a PC. Yes. So if you, if this, if branch enable is false, that means whatever the address of this branch is, PC will have been incremented. And so you will simply go to the next instruction in memory. If the branch is taken, you can change it to some other address. Right? You've got this offset encoded in the branch instruction. So you specify when you write the instruction, where should it go if this condition holds? And you specify the condition also by specifying the branch instruction. I'm sorry, on your code on the- Yeah. Yes. Yes. Yeah. So you have to put some other code elsewhere and then target that, that other piece of code with your branch instruction. Yes, that's right. That's right. And we'll do that a few times. All right. All righty. So let's take a look at this. So here again, let's look at the PC, the mechanism for changing the PC. So we'll take the PC. We're going to add again sign extended eight to zero, right? Because again, it's an eight, or I'm sorry, nine bit offset, sign extended to 16. So same nine bits coming out of the IR, sign extended, going through the address two mux. Address one mux is set to forward the PC. So we add PC to the sign extended nine bit offset. And that then will not go out onto the bus because it's not going to MAR, it's going back into PC. So this PC mux will be selected to have the output of the adder come through and will set load PC to one. So that'll change the PC. Now, actually, the new PC is only loaded on branch enable, right? So we'll change the PC if the branch is enabled, and we won't if it's not. Now the branch can only reach plus or minus 255, right? It's a nine bit offset, so minus 256 to plus 255. And then the PC is your branch address plus one. So if you add those all up, it's roughly, you know, plus or minus 255. But what if you want to go further away, right? What if you've got a lot of code, you couldn't quite squeeze that target where you want to go with your branch, couldn't get it close enough? What are you going to do? Well, there's another instruction for you. I won't tell you the encoding. If you want to use it, you can look it up. But it's called the jump instruction. I don't think you'll need to write this much code anytime soon. Yeah, so you can hop. Yeah, you can do that. But you have to have a place to put that other branch too. So yeah. Yeah, at that point, it's probably better form to hop over one jump instruction and use the jump instruction to go farther. Yeah, and change the branch condition the other way. Yeah. Yeah. No, so the idea is this is some arbitrary 16-bit value you can put in a register. So you can go anywhere with the jump instruction. You can put any address into a register. And so you can do a jump instruction to any address, whereas a branch can only reach about 512 addresses. Does that make sense? Yes, that's it. That's all. That's the RTL. You take your base register, take the bits, you put them into your PC. Because you then have to put the bits into a register before you can branch. So yeah, and this is unconditional. So in order to use the conditions, you need a branch. There's no conditions on this jump. It's just change PC to base register. Yeah. Yeah, so that's two important parts, actually. So let me make sure everyone understands that. Eric asked, well, why not just use jump all the time? Isn't it more powerful? Well, it doesn't have condition codes, right? So we would have the same problem we did before. We could make an infinite loop. We could go somewhere else. But we wouldn't be able to make a decision, right? Because jump does not have any condition. And the other issue is just that, you know, in order to go somewhere, you first have to prepare a register with the target, the new address you want to reach. So it's not quite as simple as, well, just do a jump. You have to somehow get the bits into a register. Then you can do the jump. All right. So one more instruction for the ISA. There are actually a few more. So if you want to read them, you can. You won't need them. Some you'll never need. Some you might use. JSR you'll use in 220. But for us, we want to look at trap. So trap is the last control flow instruction we'll look at. And what it does, from our point of view, it just invokes operating system services. So again, if you want more details, this is starred in a couple of senses. So this is 220 material. So if you want to understand how it works and you want to go look at the operating system code and understand devices, read chapters 8 and 9 of Pat and Patel. But from our point of view, it just invokes one of these operating system services. And which service depends on this 8-bit vector. So trap has opcode 1111. These four bits are 0. And then you can specify any 8 bits there. But there are only three useful 8-bit patterns for us. These, by the way, are page 543 of Pat and Patel. There are a couple others you could use if you wanted to. So one is the trap vector. I'm sorry, this is the trap vector number. So hex 20 is the getC trap. So what that does is it says, well, give me a character from the keyboard. So it will actually wait for the user to push a character on the keyboard. And it will give you that character back as ASCII in R0. So when you call this trap, you first need to make sure that you don't have anything important in R0. Because when that trap finishes, R0 is going to hold the ASCII character. So whatever bits you have there are gone. So if you're writing your code in the lab, make sure if you need to do a trap, you don't put important stuff in R0 before you execute a getC trap. The out trap then is kind of the opposite. It says, OK, give me one ASCII character, put that in R0, and then invoke trap 21 hex, and that will send that ASCII character to the monitor for you. So this is how you print to the screen as you send it ASCII characters using the out trap. Again, you need to have R0 free to do that. So you need to put the ASCII character there. You can't put it in R3 and a computer won't figure it out. You have to put it in R0. And then the last one, which you should always put at the end of your program, is, well, stop my program, go back to the operating system. So I think in the lab it talks about the difference between halt and end. And end will show up in assembly language. End tells the assembler that you're done writing assembly code, and halt tells your program to stop running. So you always need a halt in your program. So those are the three traps we'll look at. There's one side effect of trap I do want to mention, and this has to do with how it actually works. Anytime you do a trap, R7 will get changed. So when you write code in the lab for R class, the easy answer is don't use R7. You've got eight registers, don't use R7. Now you have seven registers. There are better answers if you really want, but you probably don't need eight registers for the kind of code you'll need to write for R class anyway, so just don't pick R7. If you do, anytime you do a trap, it'll change its bits, and so that'll be confusing. And also your code will not work if you cared about those bits. So this is the easy way to handle it for now. And again, if you really want to understand why and how it really works, you can go look at that. It's to do with the way it works. What it's really doing, and again, this is beyond the scope of our class, but what it's really doing is there's a routine that interacts with the I O devices. It's a piece of code. And so what the trap instruction really does is it goes to that routine, and it executes that code, and then it comes back when it's done. And how does it know where to come back to? Well, it puts the address of your code in R7. So now you all know. So if you want, you can play with I O registers directly. The LC3 simulator has all the LC3 OS code, so you can go read that by just listing it. You can download the source yourself if you'd rather read it in assembly language. It's all available to you. Yes. Yeah, you get a, the computer says you're not allowed to execute that instruction. But we're not going to, all right. So again, this is kind of out of the scope. Computers sometimes run into problems they don't know how to solve, and so they generate things called exceptions. So the hardware will say, well, I have some condition I don't know how to handle. So if you give it an illegal instruction, that's an exception. If you tell it to divide by zero, that's an exception. There are a bunch of others in real processors. You'll learn more if you take 391. But what really happens when that exception occurs? Well, the hardware literally goes to some other piece of software, just like a trap, and then the operating system says, well, what should I do? If you generate an exception in your operating system, typically it'll panic, right? And then, because the operating system shouldn't have buggy code. But if you generate an exception in your user-level program, typically the operating system will say, well, you're a bad user-level program and just terminate it. So, but the hardware generates that exception. And it does so on things like illegal instructions, divide by zero. Yeah, we're not going to talk about privilege in our class, but it's mentioned in the book. So if you look at Pat Patel's privilege implementation, if you try to do something where you don't have privilege and it's supposed to be privileged, it'll generate an exception there too. And there are lots of other cases in real processors having to do with more advanced design issues. Okay. Where are we on time? Sorry. We started well. All right. So maybe we can, hmm. We're not going to get too far in seven minutes. All right. So let me set up the problem. Actually, I'm going to summarize first. So we just looked at the LC3 ISA and went through a more or less complete subset. So the ISA, you know, I wanted to give you kind of a definition after having seen one, right? So the ISA is going to answer these three questions, right? So first of all, what's possible, right? So we went through and we looked at all the different instruction opcodes in LC3. We said, well, what are the things you can do with instructions? So why does that matter? Well, when you write programs in LC3 assembly or LC3 binary, it can only do the things that the ISA defines, right? So you have to break your human task down to the level of LC3 instructions. And that's always happening, right? So even if you write something like C or Java, you know, at some point things have to be broken down to the instruction level for the processor in which you run them, because that's all the processor knows how to do. So once you know, well, what are the operations it can do? Well, what are the operands you can use, right? How can you specify the operands for each of these operations? That's another thing, another question the ISA has to answer. And then finally, well, what is the representation we use, right? We have to express the instructions to the hardware. How do we encode those? What do the instructions look like? So all of the previous slides today were the encodings for the different opcodes in the fields, right? But that's part of the ISA is to tell the programmer, well, how do you actually express these things? And also to tell the person implementing the processor, if you see this instruction, what does it mean? Because the ISA is the interface between the hardware and the software. And so some set of people is building a processor that looks at these bit patterns and says, okay, when I see that bit pattern, I have to do this set of operations. And then the other part is the people writing the instructions somehow, whether it's because they're writing a compiler or writing assembly or binary instructions directly, saying, okay, here's what I want the computer to do. Let me put those bits together and put them in memory. And those two people, they don't even have to communicate so long as there's a clear and well-defined ISA. So here's kind of what we saw for the LC3. We had three operation or operates, ALU operations and, and, and, I should say add, and did not. Loads and stores, this was the PC relative, indirect mode, base plus offset mode, and immediate mode. And then the control flow instructions we just looked at were branch, jump, and trap. The data types, so why did I put data types up here? Anytime you do operations inside the data path, right, you can, you can imagine supporting different representations, right? When we started our class, we said, well, let's build an unsigned adder. And then we said, oh, look, it's the same as a two's complement adder, right? If we built a multiplier, then those two aren't quite the same, right? When we did a comparator, we also had to change things a little bit. So the question is, well, what kind of hardware do you actually have in your data path? The only hardware the LC3 has, it's all aimed at two's complement. All the offsets are two's complement, all the, the ALU, I mean, it does logic operations too, but the ALU, when it does add, you can think of it as two's complement. So everything about LC3 is two's complement in terms of how it operates on, on values that are passing, passed around in the data path. The addressing modes we saw for various instructions were register, immediate, PC relative, indirect, and base plus offset. The three condition codes we provided are negative, zero, and positive. Some, some processors will give you more condition codes, right? So you'll notice, for example, you can't check whether an add overflowed. There's no overflow bit here, right? There's no carry out bit either, right? So you can't easily check in LC3 whether you're, you're 16 bit addition overflowed. You have to go check it by hand by looking at the bits. Now you can do that, but it's not that pleasant. The only thing you can do with LC3, you can write an algebraic expression and then you can rework it to compare it with zero, right? So then you can compute the algebraic expression and you can check whether it was negative, zero, or positive. And so when you, when you start at a high level, you're going to have to cast everything in terms of a comparison with zero, because that's the only thing you can do with your branches in LC3. And then for the encoding, you know, again, you've got a, you've got a sheet that shows you that. Don't worry too much about the details there so much as how to use it. All right, so I think we're not going to get too far in this, but let me just say a few words about what we'll start on Friday. So we're going to count to 10 together. It'll be exciting. There's actually three variants on the sheet. So we'll do indirect addressing together, and I'll leave you to do PC relative and base plus offset on your own. So here's, here's what the sheet looks like. So there's some starting code, which we'll decode together. There's the loop body here. Actually, I can walk through this. So the PC, we're going to start at 3000. Then we'll do this code, second part down here, some values, some data we've placed in memory, and then here's the loop. Okay, so we're going to look at how we actually execute a loop 10 times, see what instruction scaffolding we build around that using LC3 instructions to make it happen, talk about what happens if we change things a little bit. And then after that, we'll do some examples of like typing in a number and stuff, stuff that you've seen at the start of class on the website. So let me just stop there and I'll see you on Friday. Thanks. Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai\",\n",
       " \"Hello. Test. Okay. Sorry, a little late. The batteries, no one apparently replaced them. So all right. So we're going to pick up with talking about static hazards. We'll actually talk a little bit briefly about other kinds of hazards too. I should have put a star here. Sorry. All the hazard stuff is a timing detail. I just want you to kind of see it so you understand the types of behaviors that real circuits have that we will have to, well, we don't have to, we're going to sweep under the rug in our class and just use discrete time, make our lives a little easier. A lot of these problems are actually also simplified in typical real processor architecture design, for example, but often you avoid thinking about timing by using a common clock. So a lot of digital system design, we push these issues off on the circuit designers and just say, well, give us a common clock and then, you know, fetch your job. And then we go off and have fun with discrete time. So I just want to give you a few pointers about that. I think there's still things we have to think about timing in EC385. So you will need to have a little bit more understanding of these later in your career, but for our class, it's just for your enjoyment and also to see some of the complexity. Then we'll spend the rest of the day probably talking about registers. We may get a little bit into serialization, but that's supposed to be the third part of the class. So we're going to start that on Friday, definitely, but that's kind of where we're headed. So I wanted to do a little bit of review. So this was our flip-flop. So this is a master-slave positive edge trigger D flip-flop. So it gives us the notion of discrete time. I have a timing diagram again, just to show you, but it's basically two of these D latches with one inverted on the right navel sense from the clock signal. So the first one copies from D to Q when the right navel is low, right? So, or rather when the clock is low, sorry, where enable is high. And the second one copies when the clock is high. And so what this effectively gives us is when the rising edge of the clock comes, this first latch here will have been copying during the low phase of the clock. And then when we switch to the high phase of the clock, whatever value was last stored there is locked in place because the clock has gone high, which means this one's right navel is low. And then at the same time, this latch starts to copy from its D, which comes from this first latch is Q. Let's call it X, I guess, from X to Q here. And so whatever value was present on the input right when the rising edge starts will actually be stored here in the flip-flop for a full cycle. The second latch will not change value again until the next rising edge, because this first latch can't change until the falling edge. But then at the falling edge, this latch is again no longer copying because when our clock is low, this latch holds its value. And so effectively what we've built here is something that gives us discrete time. So once a cycle at the rising clock edge, we copy a new value from D over to Q, we keep that value for one full clock cycle. So everything about, well, time is continuous, you have to worry about timing issues, this lets us just ignore that. So we build out of these flip-flops. So it gives us the discrete time. And we're going to assume that between integer values of time, nothing's going to change. So all of our flip-flops will have constant output. You will in your lab see a non-square wave clock signal. So we wanted to do something in the lab where you interact with the real world. So you can have fun doing sensors and actuators and realize that you can build robots and other things with what you're learning in 120. But you'll do a finite state machine that interacts with the real world as a vending machine sort of. You put coins in, and it's actually the coins that will drive your clock. So when they go past a sensor, that'll drive the clock signal in one direction. And when they're past the sensor, the clock will follow in the other direction. So that'll be your clock signal coming from the coin rolling past the sensor. So that'll be more continuous time. But logically, it's the same discrete time, but that gives you one clock signal. So you can read about that ahead in the notes if you'd like. There's a section on how the lab was designed in that relationship. So all of the designs in our class will be clock synchronous sequential circuits. You do need to know a little bit about sequential feedback circuits like latches and flip-flops. So you should understand how they work, basically. So in class on Monday, we looked at the design of the latch and the design of the flip-flop. And we did the analysis where we said, well, what if we start with a zero on this loop? How does the feedback work? And how does it settle into a stable state? So we expect you to be able to work through those kind of things if we'll give you a different design. But we won't give you very complicated designs, usually one or two loops. So let's talk a little bit about static hazards. So again, you only need to understand the basics of timing. So how to estimate delay as gate delays, simple heuristic for delay of circuits, how to check for stable states that I just mentioned. In later classes, you will have to have a deeper understanding of timing and probably even run into timing bugs in some of your designs. Even if you're building hardware on FPGAs, sometimes the tools may not actually get the timing perfect. And so your synthesized version may actually exhibit timing errors, essentially, where something hasn't finished before your clock says, well, I'm going to grab the new value. So let's take a look just for a preview at how timing can matter. Why do we care? Why is it not just all easy, even if we have more complicated timing? So I'm going to give you some terminology first. So if a circuit may have a problem, so if I have a circuit design and that circuit may have a timing issue, we say that circuit has a hazard. So that doesn't mean it shows up. It just means that circuit may have a problem because of timing. If it shows up, if some output from my circuit becomes a variation in my output voltage, we say that that circuit exhibited a glitch in its output. So a hazard is a potential problem. A glitch is a problem that actually happens in the output. And then if you have a sequential circuit and that circuit changes its state in a way that was not designed to do, not because you built it the wrong way, but because of some hazard or glitch, we say that it had an error. So hazard, glitch, and error. Now typically, if you have an error, it could just be a bug in your design. Whatever you built was just wrong. But assuming that you built it correctly, typically if you have an error, that means that something in there had a glitch. It actually changed the output bit and that bit got latched, got stored in a latch or a flip-flop. And a glitch implies a hazard. You don't get a glitch unless you have a hazard, but the opposite direction doesn't hold. So you might have a circuit that has hazards, but it doesn't matter because they can't turn into glitches. Or you might have a circuit that exhibits glitches, but they can't have errors. So for example, when we assume that we only look at the rising edge as the only point at which we sample our data input, well, even if that data input has glitchy behavior, even if it's bouncing around, so long as it's stable at the rising edge of the clock, we don't care. So that's one reason that you don't have to actually solve some of the static hazards we're about to talk about. Because in the space in which we're designing clock-synchronous sequential circuits, we only care at the rising clock edge. And so the fact that something input to our flip-flop might be bouncing around beforehand, that doesn't make any difference. So it's okay for your combinational logic to have the static hazards I'll show you, because you're working with clock-synchronous designs. All right, so if you want to read more, section 2, 6, 3, 4, and 5 are the three types of hazards. Static hazards, I just want to give you a definition. So with a static hazard, the idea is that you've got some combinational logic circuit, and you're going from an input combination that produces, say, a 1, to another input combination that produces the same value, so say again a 1. And so you think, well, if it's supposed to start at 1 and end at 1, it should always be 1, right? It shouldn't go bouncing around. If your circuit has a static hazard, that might not be true. It might be possible that even though one input combination gives you a 1 for output, second input combination also gives you 1 in between, drops down, goes to 0. So that's the hazard. That one is called a static 1 hazard. It's also a static 0 hazard. It's supposed to be 0 and 0. Instead, it bounces up to 1 and goes back down. So static 1, static 0 hazards. Yeah, Eric? So the static refers to the fact that the output is not supposed to change. So both of the two input combinations are supposed to produce the same output value, either a 1, which makes it a static 1 hazard, or a 0. So static refers to this static nature of the output. So we'll go through a detailed example. Yeah. Yeah, so. Okay, so let me be careful here. Yeah, so the question is, what's the cause of a static hazard? No, it's not metastability, if that's what you're thinking about. But it is the case that if you have multiple levels of logic, different gates may actually be changing from 1 to 0 and 0 to 1. And those gates might be input to another set of gates. And so the output of that additional set might be bouncing around. And so that'll be the example I give in a few slides. That was a good question. Yeah. All right. So before I give you the static hazard example, though, let me also define other types of hazards. I won't go through examples of these in the class. They're substantially more complicated to understand and figure out. Static are relatively easy. Dynamic hazards, and here again, dynamic refers to the output. So in this case, the output is supposed to change. We have an input combination that, say, produces a 1. And then one of the inputs changes. And the new input combination is supposed to produce a 0, for example. So what we'd like is a clean transition. We'd like the output to start at 1 and then at some time go down to 0. And that's it. It changes once. If you have a dynamic hazard, the output may actually bounce around. So it may drop to 0, then go back to 1, then drop to 0. It may do that many times. So hazard just says that it might not change cleanly. It may bounce around before it settles to its final value. That's a dynamic hazard. Again there's an example in the notes, but I'm not going to do that example in the class. It requires more deeper circuits, more than two-level logic, to actually have any dynamic hazard behavior. So there's an example in the notes if you really want to go understand it. But I'll show you static hazards in class. The last one is actually quite important, but it occurs in sequential circuits. They're called essential hazards, and they're related to the function that you're implementing. So for static and dynamic hazards, you can change your design in a way to get rid of them. So you can say, well, I don't want to have static hazards, so let me change my design. I'll show you how. And that will get rid of my static hazards so I don't have glitches from static hazards. Similarly, again it's harder, but you can change your design for dynamic hazards so that you don't have dynamic hazards anymore. Essential hazards, there's nothing you can do. Having the essential hazard is part of the function you're trying to build, and there's no way you can build it and not have the hazard. So they're quite problematic in that sense. They can't be eliminated. On the other hand, by using this abstraction, this clock synchronous sequential design, sequential circuits, what we're doing is taking all essential hazards in any design we do and manipulating them so they show up as clock skew. So the only essential hazard you'll have in a clock synchronous design, one where you have common clock going to all of your flip flops, is clock skew. Which again, we're going to push off on the four circuits people and say, well, good luck. Yeah, Eric? Yeah. Yeah, it's how you implement the function. You can change, and we'll see that with the static hazard example, that if we change the implementation we can get rid of the static hazard. It's not always easy, but you can do it. Whereas essential hazards, you can't get rid of them. There's nothing you can do. You can change where they show up, but you can't get rid of them. You're always going to have potential essential hazards. The reason this matters, actually, by the way, so when you build a chip, it's not just design that goes into your chip. There's also variations. These are quantum phenomenon. So if you've taken quantum mechanics, this will make a lot of sense. If not, think of it as we've got now maybe 10 atoms of thickness between our transistor and the part that would let it leak electrons out into the world. So sometimes it might be 9. Sometimes it might be 8. Sometimes it might be 12. But that's a 20% variance in that transistor. So that's a huge swing because of quantum mechanics, that they're quantum devices. Similarly, there's a small number of dopant atoms. Those things also, there's a discrete number of atoms. You never have 3 and 1 half atoms. You've got 3 or 4 or 5. And so the variations that we see now in modern processes are pretty big. And so even though you design your circuit so that it should work, you can get timing behavior because of the variations. And so that makes it very, very hard to design it and have all of these problems be solved and guaranteed to be solved. That's why we have to do very careful testing of chips that we build because the variations can affect their behavior a lot. And so I think on Monday I was talking about speed bending. That's one of the side effects of having process variations in the semiconductor world. Those are all research topics too. So you don't need to understand them too deeply for our class. Not at all. But it's fun. All right. So let me give you the static hazard example. So here's a little circuit. So it's built out of a couple of inverters and a few gates. So what is S in terms of A, B, and C? Yeah. So A and B in this hand gate. And this is B0, C0. And then we OR those together. Good. So now let's think about, so what happens when we move from ABC110 to ABC100? So take a look at the function and verify that you think the answer should be 1 in both cases. You agree? OK. So in the first case, we've got A and B equal to 1. So this should be 1. And then OR it with something. That gives us S1. And over here, B is 0 and C is 0. So B prime C prime should be 1. OR 1 with something, we get a 1. And so we should get 1 in both of those input combinations. Only one bit has changed. Only the B has changed. So let's take a look at what might happen. So B changes. Let's say that's step 1. B changes from 1 to 0. So what happens as a result of B changing? So this one changes, right? Because that one went, this was 1 and this is 0. So our AND gate now produces a different value. So that's going to change. Good. So the AND output's going to drop to 0. What else happens? Yeah, there's an inverter down here, right, taking B. So that's going to change. So that NOT output rises to 1. That happens roughly at time 2, let's say. These could be gate delays. I would have made this one 0 and these 1, right? So wait a minute. Now this NOT output's going to go to this AND gate. So what's going to happen over here? It's going to go to 0, because this AND gate's currently outputting 0, right? When we're in this state, this AND gate was outputting 0. So now this has got 0 OR 0. What's 0 OR 0? It's 0, right? So the OR output is going to drop briefly to 0. Later, it's going to come back, because this AND gate now has 1 and 1. It's going to produce a 1. It's going to turn the OR gate back on. But for a brief amount of time, that OR gate at the end is going to give us a 0. So that's the glitch. So here it is in a timing diagram. So you can see, you can go verify that I got these answers right if you want to, but this is the transition that we're talking about. We have A equals 1, B equals 1, C equals 0, S was currently 1, and then B drops down. That causes B to go low briefly. And then when B prime goes high out of the inverter, that drives S back up. So this is our glitch. Yeah, so in the past, when we were introducing those ideas, it was, let's look at combinational logic in isolation. And so often, you're building combinational logic between sets of flip-flops, right? And so if it's a flip-flop coming in, as you saw yesterday, I'm sorry, not yesterday, but Monday, then you can get both Q and Q prime for free, right, without a gate delay. They're both available at the same time. So that was why they were free. If for some reason you don't have your logic coming out of flip-flops or your, I mean, here, we're not assuming, we didn't assume that we had this for free, partly because I wanted to show you the glitch, right? So I came up with an example that would show you a glitch. So you got me. But one can imagine making a different circuit where we didn't have that, or in some cases, in fact, we won't always have the complemented inputs if the values are not coming directly from flip-flops or latches. So in this case, it was a little bit contrived, and so that was why I wanted to count it, but to show you the glitch. But there are designs where you might not have the availability of complemented inputs, in which case you do need the, you do need to count the inverter. So in fact, even in the bit slices, right, where we're going bit to bit, we don't produce complemented outputs. So really, we should have counted the inverters there, but I was trying to make life simpler at that part of the class. Good question. Yeah. Yeah. Yes, so I showed you something with the latches and the flip-flops timing diagram. So clock skew is, we assume that the rising clock edge arrives to all of the flip-flops all at the same time. So we have a common clock, and the rising edges arrive at each flip-flop at the same time. Now, that's one, that's not really possible to do, and two, it actually doesn't mean anything in the real world because special relativity tells us the same time in two different places doesn't have meaning, which if you haven't learned yet, you'll have fun learning. But if they arrive sufficiently far apart in time that information can propagate between one flip-flop and another, then that can actually cause us problems in the behavior, right, because one flip-flop may change its value, and then its output may affect the input to the other flip-flop. And so if the clock edges don't arrive simultaneously to all of the flip-flops, that can cause problems. And that's clock skew, is differences in the arrival time of the rising edge of the clock. Yeah, good question. Yeah. Well so, I'll show you a fix in a minute, but the, yes, the delays through the circuit as designed are opening the possibility, or are a hazard, and open the possibility for a glitch. Now, if we just assign different amounts of time to these various gates, we could set it up so that the glitch never showed up, right. So this, a hazard doesn't necessarily ever show up as a glitch, but this circuit has a hazard regardless because if I put the wrong amounts of time through these gates, then it can show up at the output, right. So if this path from here through here is slower than this path through here, then it'll show up. Yeah. Yes, and more particularly, there are two separate paths from B to S, and the timing of those paths may be such that even though the end value of S is the same, the timing of those paths creates a downtime in S. Yeah, it's the longer delay along this bottom path through the inverter and this AND gate and this OR gate. Yeah. So all we really need for the glitch to show up is for this path to be slower. So I didn't even really need to add the gate, I just need to have that path be slower for whatever reason. But that's harder to explain, right. I mean, I don't really want to have to have everyone understand process variations, but it's possible for even without this inverter, even if I had the complement available for that path to happen to be slower than the top. But this makes it, I think, easier to understand that we can just count gate delays. Okay. All right. So what can we do? Briefly, yeah, just like this. Depends what you're doing with it, right. So humans, for example, are pretty good at catching flickers, right, because our lives used to depend on catching the predator flickering amongst the leaves, right. So if you're driving some output that a human can see, they might actually see that it's doing something weird, right. If for some reason, whatever you're doing might also use this value and expect it to be constant. And if you have something that realizes it's gone low and does something in response, it will also react. It doesn't have to be a human, it could be some electronic circuit. Yeah. Is there another question? Yeah. So that's one answer. I mean, as long as I guarantee that my clock edge doesn't come in the glitch. Yeah. As long as I wait long enough to make sure that all of the paths have settled through my circuit, right. So I can count, like you said, I can count the paths, find the longest one, make sure that my clock between the change and the latching of the output is sufficiently long that all of my paths have settled, then I can use a D flip-flop and I'm guaranteed never to see this behavior. And that's practically what we're going to do in our class, right, is to say we're going to ignore this kind of stuff, because we always wait long enough and run our clock slowly enough that we just never see the glitches. Good answer. But I can actually change the circuit too, so I don't see the... So how about this? Let's take a look at the K-map. So those are the AND gates, right? Those two loops are the AND gates. So remember there was AB, which is this one here, right? And there was B'C', which is this loop on the left. So the behavior we're seeing is this input combination, so 0, 1, 0. I'm sorry, 1, 1, 0. So A is 1, 1, 0, going to 1, 0, 0. So you can see it's crossing between loops. So in other words, one of the AND gates is going to switch from producing a 1 to a 0, the other is producing 0 to 1. So how can I prevent the output, which is the OR of these loops, from going down? Yeah, I can add another one, right? Well, let's add a new loop, another AND gate. Cost me a little extra area, got to have the extra AND gate. But now this purple AND gate here, this new loop, that's 1 for both input combinations. So that AND gate's going to always produce a constant 1, which is going to go into the OR gate. The OR gate's going to produce a constant 1 also. You can imagine this is substantially more complicated if you have more than two levels of logic. It's more complicated if you have to draw extra loops between all of your loops to make sure there's never a transition that isn't covered. So it's not necessarily easy, but you can do it. You can add extra gates and get the answer. So that new AND gate's going to stay at 1. So we can fix our static hazard that way. So it's going in any transition. So when we analyze sequential circuits, we assume that inputs don't change simultaneously, that only one input changes at a time. So what that means is a KMAP is moving from adjacent box to adjacent box. So you only move from one input combination to adjacent boxes at any time. So all of the transitions you have to analyze are the edges between the boxes in the KMAP, and a static 1 hazard would be to go from any 1 to any 1. So you then look at all of the loops you have and make sure that anywhere you can go from 1 to 1, it's always inside some loop. And that will be an AND gate that produces a 1 constantly during that transition. And if you did POS, you would do the same, except that for all of your 0 to 0 transitions, you'd always have a loop that enclosed every transition. And that would guarantee that those OR gates would always produce a 0 during that transition for static 0 hazards. If you do SOP design, you don't have static 0 hazards because none of the AND gates is on. So you're going from no AND gates to no AND gates. So you don't have to worry. All right. So I think that was it for our fun time with hazards. Any other questions before we go back and talk about registers? Yeah. So generally speaking, we always assume with any kind of sequential logic analysis that only one input changes at the same time, that the transistors react quickly enough that any tiny little difference in changes will be seen sequentially, that one change will happen before the other. So we simply ignore that possibility. That would correspond to two box change. But we assume that never happens. Yeah. Again, we assume that one input changes at a time, that even if they're very close in time, the transistors react very quickly. And so they're separable and serial. And so we assume that only one input bit changes at any time, never simultaneous input transitions. Yeah. OK. It's not always the perfect assumption, right? But as I already mentioned with latches, right, if they happen, if you let, with the R bar S bar latch, if you let them both go up at the same time, you might get metastable states, right? So it doesn't always work, but that's generally the assumption when people analyze sequential circuits. OK. Yeah. Yeah. It can bounce, yes. Yeah. So if you took our circuit here and you connected S to another piece of combinational logic, well, you're changing the input, right? So the outputs, of course, can also change. Yeah. That's right. So these changes, if you connect this to more combinational logic, will propagate through. And that's where dynamic hazards come from. So if you look at the example in the book, you take a static hazard, then you add some logic to it, and then that can create a dynamic hazard. All right. So let's spend a little time on registers then. All right. So, so far, we talked a lot about representations, right? We had usually a bunch of bits together in groups, like unsigned, two's complement, floating point, ASCII. And we talked on Monday about how we store a bit, right? So flip-flop's going to store one bit. Well, what if I want to store a 32-bit unsigned number? Well, let's build something to let us do that. We'll call it a register. So it's a storage element that we're going to build out of flip-flops. And it's going to store things, groups of bits. Again, all of our flip-flops will operate on a common clock. Now, a flip-flop stores a new bit every cycle. With a register, we want to have some control. We don't want it to just store some new bits every cycle. We want to be able to say, well, in this cycle, I want to put a new 32-bit unsigned number in my register. And I want it to stay there until I tell the register to put a new value in again later. So I'm going to add a load input, maybe LD or load. So when load is 1 on a rising clock edge, the register will store a new set of bits. Otherwise, it'll just keep the same bits. So the only time it's going to change is when load is 1 on a rising clock edge. Otherwise, constant value is stored. So how am I going to do this? So here's an attractive option. It might seem attractive. You say, well, OK, so I'll hide the rising clock edge. You don't want to see the rising clock edge. You don't want to change your bits. So hide the rising clock edge. I can add some logic down here. You probably don't want to use this. Until even a few years ago, it goes in phases. So for a while, people were doing clock gating. Then they realized, as I'll talk about in a minute, it adds to clock skew. And so they said, don't do this because it makes the circuit people's lives miserable. So for many years, we've said, no, never do clock gating. Just rule it out completely. There are power reasons that people are starting to think about it again. It can save you power sometimes. But for our class, never think about doing clock gating. It will introduce clock skew. And so it will introduce ways to have nasty, subtle bugs with essential hazards. And if you do it in your lab, good luck. Don't do it. So here's another reason. You have to actually be careful with how you manage your load signal. So load affects your perceived clock, C. So your perceived clock is now this signal, C, here. So your perceived clock, you can get specious rising and falling edges. So for example, here, while the clock is low, if I raise load, I get a specious falling edge. That doesn't matter because I have a positive edge trigger, D flip-flop. This was a real clock edge, so that's OK. But unfortunately, if I lower load while clock is low, I get a specious rising edge. So in the middle of my clock cycle, I do a load. So if you're not careful, you can make your flip-flop store values even in the middle of a clock cycle. That's probably not what you want to do. So you have to manage your various signal timing in addition to thinking about the clock and worrying about clock skew. So that's the main reason is the extra logic contributes to clock skew. It slows the rising edge to the clock. So you want to avoid doing that. So we will have one application that uses a different clock for some flip-flops. It's called ripple counters. You'll see it in maybe one or two weeks. But otherwise, you should always assume common clock signal to everything, and you shouldn't try to build clock gate. What should we do? And with the input. And what with the input? But then that would load a zero, right? Yeah, so you're building up to something that we've seen. So we want to pick between keeping the old value and taking a new value. What should I use if I want to make a choice? Say loud. A mux. Good. Okay, there's a mux. And it's true, Peter, what you were saying that inside of that we're ending the load signal with one and ending the old value with another min term of the load signal, I should say. That's how mux works internally. So you're on the right track. But let's just plop it down as a mux. So what happens here, when load is equal to zero, we take the Q output of our flip-flop, which I probably should have drawn there, and bring it back. That's a zero input of the mux. So the mux forwards the old bit, and that just gets stored again. So it just retains its value. When load equals one, we take in, and we copy it to D, and then at the rising edge, D stores that value for us. So this is one bit of a register, and then we'll use that design as a bit slice. So for an n-bit register, we'll have n of these, n muxes, n flip-flops. So here's an example for four bits. This design here, we say it uses parallel load. So we've got four input wires, and they're coming down. The load controls all four of the muxes. So when load equals one, the entire four-bit register stores a new value. When load equals zero, the same four bits are stored there until load equals one again, and it sees a rising clock edge. Again, common clock. At some point, I'll no longer even draw the clock signals. Right now, I'm still drawing it just to show you there's one signal that goes to all four of these. With a 32-bit register, same thing. One clock signal to all of them, one load signal to all 32 muxes, and then 32 separate wires for parallel load for the different bits. So that's a register. Now sometimes, we want to load registers one bit at a time instead of loading them all at once in parallel. So we have a notion of a shift register for that. So here's a shift register. So you can see what happens. We have a serial input on the left. That's the thing that puts a value into this flip-flop here. This flip-flop's value, stored value, in the next clock cycle is then shifted over to this flip-flop. At the same time, this flip-flop's value is shifted to this flip-flop, and so forth, all the way through the shift register. So if you think about cycle to cycle, what's happening is we have the input. We're putting one bit at a time, and those bits are just shifting through our register. That's why we call it a shift register. At the end, we have a serial output. So we can see the bits coming out one bit at a time from the serial output. Or we can look at all of the bits at once if we want to. So those are the parallel outputs. So if you want to look at the value of the shift register, you can simply look at these output wires, and that'll give you all of the bits at one time. So I'll talk about a couple of applications. In some cases, we want to look at the bits in parallel, and in some cases, we want to look at them in serial. So it depends what you're trying to do. You can look at a shift register's stored value in parallel, or you can look at it in serial. It depends what you want to do with it as to which way you want to look at it. So let me give you a couple of examples. So there are lots of applications. One is SERTIs. So optical networks, for example, go at about 100 gigabits per second. You can't clock the typical CMOS processes at 100 gigahertz. So what happens is you get the optical fiber coming in. It's producing 100 billion bits per second. And 100 bits per second, you could probably do in CMOS. So 100 billion bits per second, and you use other semiconductor processes to build this logic, but you put that into a shift register. So they're going in there at 100 billion bits per second, and then you pull them out using these parallel wires. Say you built a 25-deep shift register. You pull them out at 4 gigahertz. So every 25 cycles of 100, you pull out 25 bits. And so now that's clocked at 4 gigahertz, which you can do on CMOS. So you hand those to a normal CMOS chip, and you get 25 wide at 4 gigahertz instead of 1 wide at 100 gigahertz. So this is deserialization of the optical signal. You also use a similar strategy for serialization. When you want to go from a 4 gigahertz processor to 100 gigabit per second optical line, you do a serialization process. So it's a similar application. So that's one thing to use shift registers for. My postdoc was actually using shift registers a couple weeks ago, so I thought I'd just mention it. He's working on computational genomics applications. We get data coming in from memory, let's say, at one clock cycle, but then we need to feed this computation with different parts of the data at different clock cycles. So how do you delay it? Well, put it into a shift register. Want to delay it two cycles? Put it into a shift register two deep. Each bit gets delayed two cycles. You want to delay it five cycles? Five deep. So it's good for delay applications as well. So we can also design them to stop shifting. So of course, if we want a shift register that we can say, well, in this cycle, I want you to shift. Next cycle, I don't. I want you to just hold your value for a while. Well, of course, we could just put a MUX down. So SI is now going in to the left, just as before. As before, Q3 is coming up to the one input here. So if shift equals one, this behaves like the old design. If shift equals zero, it just freezes and holds its value as long as shift equals zero. Some other things we use shift registers for. So the serial load idea that we use with a shift register is critical when we don't have a lot of wires. So for example, well, what does that mean? So in the parallel load, remember one wire per bit. So if you've got a 32-bit register, you have to have 32 wires to fill it. On a chip, for example, we have 100,000 flip-flops. So if you want to test the chip and you need to fill 100,000 bits, you don't have 100,000 pins. Nothing will give you 100,000 pins into one chip these days, maybe a few hundred. So how do you fill them? Well, you use shift registers. So you use fewer pins and you shift bits in through the flip-flops, one flip-flop to the next. You fill them all up with bits to test your chip. You run your chip for one cycle, and then you shift out the answers while you shift in a new test vector. So we're using shift registers to test our chips. Reconfiguring hardware. So how are field-programmable gate arrays that you use in 385? How do you configure them to execute hardware? Well, again, we don't have so many pins to shift everything in in one clock cycle. It would also melt the chip. So we shift things in using shift registers. So all of your hardware designs that you build and synthesize in 385 will be shifted into the FPGA through shift registers in order to configure the hardware to simulate your design. So both of those applications use shift registers. All right. So I wanted to give you some terminology. So you can do left shift, right shift. Yeah. Yeah. Yeah. So you're filling up your shift register with 25 cycles of 100 gigahertz, and then you're pulling that out. I mean, the rate at which you take data out is 4 gigahertz. Now, you don't have one, what is it, a quarter of a nanosecond. You don't have a full quarter of a nanosecond to pull it out. You've only got 1 one hundredth of a nanosecond, 10 picoseconds to pull it out. But once you get it out, then you can treat it as a normal 4 gigahertz clock once you copy it out of the shift register. Now, you pull all of the bits out simultaneously using these wires down here. No, because you wait for it to fill up again. I mean, here we're only showing 4, but if you wanted to do it 25 to 1, you would have 25 deep. You'd fill all 25 using a serial input, pull 25 bits out, fill all 25, pull 25 bits. Make sense? All right. So let's see. So this one we talked about. All right. So right and left just corresponds to what we might put in in terms of representation. So if it's on a piece of paper, they correspond to the piece of paper. If it's in a representation, it'd be from least to most would be left, and from most to least significant would be right. Hopefully you remember the difference between logical and arithmetic shifts. So if you have a shift register that's supposed to operate on unsigned values, then you would use a logical right shift. If you wanted it to operate on two's complement values, you'd use an arithmetic right shift, which would copy the signed bit. So remember logical, you shift in zeros. Arithmetic, you copy the signed bit when you shift right. Both directions shifting left, you shift in zeros. And then there's also applications of cyclic shift registers where you bring one bit from the serial output back to the serial input, sometimes going through another register. That allows you to build bigger shifts. So typical modern processors will allow you to build, say, 64, 128 arbitrarily large shifts by doing 32 or 64 bits at a time. So you do a cyclic shift, you bring one bit out into what's called a carry register, and then the next set of 64 bits, let's say you shift your carry register in on one end, pull another bit out, go to the next set of 64 and keep doing that. So that's why processors often support this idea of cyclic shift. It's just a circle in your shift register. All right, so we don't have to pick one design. So let's build one register that does one of four things. How can we do this? I want one register, I want two control wires, C1 and C0. And if I put in 00, I want it to hold its current value. If I put in 01, I want it to shift left from low to high bits. From 10, I want to load a new value, parallel load, from I'll give you some wires in sub i. And then if I have 11, I want it to shift right from high bit to low bit. How can I build something like that? When I want to pick one of four answers, a MUX, right? Yeah, a decoder will give us the minterms. So you could do it and then you could use logic of the minterms. You'd get the same effect. But the MUX already gives me what I need to bring it together. So all I'm going to do with that output out of those four possibilities is put it into my flip-flop. So next cycle, it's going to store one of the four answers. So I could do this with a decoder too and then put the extra logic to bring the four outputs together and put that into d, but MUX already does it for me. So usually if we need to pick among several things, we're going to use a MUX. Decoder is only when we need to do separate operations on the four outcomes. So here, let's take a look at this design, make sure it actually works. So I said zero, it's going to hold its value, right? So if I put 00 here, I pick the zero element that comes from its current value. So this is my bit slice. Anytime I set C equal to 00, then this register here is going to just keep its value as long as I set C equal to 00. If I set C equal to 1, 01 in particular, then this comes from QI minus 1. So that's a less significant bit. So that's going to shift left from low to high. So this QI minus 1 is the next bit over here. It's going to take its current value of that bit and copy it into that, the bit that I'm showing on the slide. So that's a left shift. If I set C equal to 10, the number 2 in the decimal, then it's going to take this input wire for this particular flip-flop and store that into my flip-flop. So that's a parallel load. And then last, if I set C equal to 11, 3, then I got QI plus 1. So that's some bit I haven't shown over to the left. So we're shifting now to the right. We're taking the high bit, shifting it down to the next lower bit. So that's a right shift, which is what we had in our last diagram. So by using this 4-to-1 MUX and wiring it up correctly for each of our bit slices, we can build a register that does any of these four operations and does whichever operation we tell it in each of the cycles. So you can do arbitrary combinations of these things. If we were to ask you on a homework or an exam, OK, we want you to shift left. We want you to do arithmetic right shift. We want you to do logical shift left. We want you to do cyclic shift. Just any combination, really all you have to do is this MUX and then maybe some logic at the end. If we say arithmetic versus logical right shift, you have to decide what to do with that input on that side. But for the most part, this MUX design will allow you to combine arbitrary register designs pretty easily. So I think that was the last slide on registers. There's a few more pictures of these things built out into multi-bit registers with the bit slicing in the notes, if you want to see that. It's sort of the same as the earlier ones I showed you, but it has this bit slice in it. All right, let's see. We've got a couple minutes. I'll just give you the idea of what we're going to do here. So more on Friday now, but if you think back to bit slices, each of the bit slices we worked with would have some number of inputs, operands, like the comparator had two operands, the adder would have two operands, a power of two checker would have one operand, but we actually did it two bits wide, so it had two. It produces some number of outputs for each bit slice. The comparator produced nothing, and the adder produced just the sum bit. The power of two checker also produced nothing down here. And then some number of bits between bit slices. For an adder, just the carry bit. For a comparator, we had two. For a power of two checker, we had two between bit slices. So you can do sort of a general model with p bits in, q bits out, and n bits in between. And then what we're going to do with that is use flip-flops to produce a serial design. So remember when we were talking about this initially, someone said, well, can we, instead of putting n bits back to back with hardware, couldn't we use fewer bits and then use software to make the bits flow through them? We can. In fact, we can make the bits cycle through the same physical hardware in hardware also. So what we'll do on Friday is think about how can we use flip-flops to take our bit slice design and turn it into a serial design. So we'll have one copy of the bit slice, just one. And we can do arbitrarily large operations by just using it cycle to cycle for n cycles instead of building a big design. So we'll trade a smaller area for a slower speed. Thanks......................................................................\",\n",
       " \"Okay, ready to start? So not much on here. Since this is a kind of complicated example, we'll spend most of the day, I'll try to spend all of the day actually finishing up this example of building a finite state machine to implement some C code. If I don't manage that, we might start on von Neumann model, but otherwise we'll do that on Friday, and that's Pat Patel chapter four. This example is the notes three seven. So I wanted to just go through this a little bit, what we talked about. So we set out to develop a finite state machine to implement a piece of C code. And we're going to take our strategy to build with abstraction. So we decided we're going to store variables from the C code and registers, counters, things like that, sequential logic, right, what you've learned a few weeks ago, and then execute the statements using components like comparators. So here was the C code. So what this thing does is basically just find the minimum of 10 numbers. So this, remember, is an array of 10 integers, 32-bit 2's complement values. And the way this code works is first we take the first value, value sub zero, and copy that into min. And then we look at the other nine values from one to nine, according to this loop control. We compare each one with the current minimum. And then if it's smaller, we replace the current minimum with that value. Once we look at all of the other nine, we're guaranteed to have found the smallest of the 10. And so when this loop is done, we'll have the smallest of the 10 values in this variable min. So we built up this flowchart to show how it works, sort of the same thing, just in color-coded statements. So initialize the variable min, and then start the loop. So initialize index to 1, compare it to 10. Once that's false, we're done. That's the whole program. But as long as it's true, we go around this little piece. This blue is the if statement. So check if the thing we're looking at, values subindex, is less than the minimum. If so, copy it into minimum. Otherwise, just update the loop by incrementing the index, and go around nine times. So we decided the array was going to become a memory. We know how to build a memory, so we'll use a memory for that. Other variables we decided would be registers and counters. The if statement will be a comparator. And I said that we're going to use a serial comparator. So I just wanted to kind of make clear why. There's no good reason. The reason is purely to show you that just like before, when we did the keyless entry extension where we had a hierarchy of states, we showed you the high-level four-state diagram. We kept that throughout. Even after we'd done the extension, we still had that same state diagram at a high level. But the alarm state became something like five billion states. And of course, we didn't draw five billion states on paper. But we had a hierarchy of states. Here again, we're going to have a state that uses the comparator. And in order to use a serial comparator, we have to compare one bit at a time. These are 32-bit values in our code. So we're going to execute for 32 cycles looking at one bit at a time. And when that's done, at the high-level states, we'll move to the next state. But we'll also have that one high-level state for comparison that takes 32 cycles. And it's really 32 different states. So I just wanted to illustrate that for you again. That's why I decided to use a serial comparator in this design. Now in order to use a serial comparator, we needed some other components. So we need two shift registers to put bits into the serial comparator. Remember the way it works, it looks at one bit every cycle. We have two shift registers to give it one bit every cycle that it can compare. And then we also need a counter. How do we know when 32 cycles are over? Well, we have to count them. So we have a counter for that. So those are our pieces. Now I mentioned this, but I kind of realized talking with people in office hours maybe wasn't entirely clear, it's hard to make it clear without having you actually do the process. But whenever you're doing a design process, you don't just make decisions and then that's set in stone. Typically you're going back and forth. So we talked about components. The components we chose affect how we can pick the states, how we can design our states, how we can break up the pieces of the flowcharts into states. And then vice versa, the way we want to do that affects which components we need. So it'll be clear at the end, you'll see how things fit together. But usually when you do this kind of thing, it's not that you just say, OK, let me throw some things down and then I'll just straightforward break the states up. Usually you're going to say, oh, well, there's this other thing that I don't know how to resolve given the components I put into my data path. Let me go back and add something. Or go from the components to the states and figure out how you want to fit the states to the components. So it's really a back and forth design process. Now this is what we did with our flowchart. So we broke things up into five states. So the first state, remember, let me just explain it a little more. So in this init state, we're doing three different things. So the three things we're doing is we're putting a new value into the min register. Turns out index will actually be a counter, but it doesn't matter. We're putting a new value into min, a new value into index. Those are separate pieces of logic. So in one cycle, we can put a new value in both of them. And it doesn't matter. That's why we're allowed to put two different pieces of our flowchart into one state. They actually happen simultaneously. What about this one? Well, the first time we go through the loop, index is one. And you know that 10 is greater than one. So you don't need to do any work in your finite state machine to figure out that 10 is still greater than one whenever it runs. So that's why we're able to pull that in the first time. You might wonder, well, what about this part, where we come back after our loop is done and we check it? So what's going to happen there is index is just a counter. So we can look at its value when we're in this green state, the copy state down here. And when it's equal to 9, then after we change it, it'll be 10. And 10 is not less than 10. So instead of doing anything here, we can simply make copy go directly to done, the wait state, when index is 9. So that's how we're going to resolve the other use of this box here. So you'll see that as we walk through the design. But basically, we never really have to do this comparison. It can all be done ahead of time and using in the copy state using the index's value comparing it to 9. So I'll show you how that works. But just wanted to go through it more slowly. All right, so this is what we got generalizing our state machine. So we'll start in the wait state. The idea is that we've got this finite state machine, some other logic is going to fill the memory up with 10 different numbers. Then we're going to say go or start rather. And the start signal will tell the finite state machine, OK, go out of wait and start doing your initialization. So that was the gray states on the previous slide. Initialization takes a cycle. So the next state will always be the prep state. Remember, that's where we had to set up to use the serial comparator. So we're putting values into the shift register, and we're resetting the counter so that the serial comparator can do its work while the counter is counting to 32 for us. Because that's a prep state. Then we'll let the counter run. So prep also takes always one cycle. So then we'll go to compare. Compare will take 32 cycles. So we're going to look at the counter value. And until the counter says 31, which will be the 32nd cycle, until the counter says 31, we're just going to stay and compare. When the counter says 31, we're going to move to copy. Now in that cycle, when we're in copy, the comparator, the serial comparator, will be telling us whether A was less than B. In other words, or A was greater than B, I think is what it ended up being. But it'll be telling us whether min is greater than the new value we're looking at from the array. And that's the case in which we want to copy that value into array. We'll use that serial comparator output as the load input to our register to perform the copy. So this one copy state does both the then case of the if, as well as logically sort of the comparison. And also the update of index. And that was shown in the flowchart. So let me flip back there. So the copy state will do this copy if it's appropriate, if we came down the true arc. And that'll be stored as the comparator output. And it will also do the index equals index plus one. So both of those in one cycle. So once we're done with copy, I mentioned we would look at index. The index register, if it's not nine, we still need to keep going. And if it's nine in the cycle in which we're copying, then by adding one to it, we'll make it 10. That's when the loop is done. So if it's not nine, it's not the end of the loop. We'll go back and start to look at another value. If it is nine, we're done. And that's it. So this is our high level state diagram. And this is where we kind of left off on Monday. OK, so that's our abstract state diagram. So now let's talk a little more detail. Now that we have an idea of what we're going to do with our finite state machine, let's put a little more detail into the components and what they need to be able to do. So we said that index in the C code is a 32-bit choose complement value, an int. So what we're going to use instead, we're only using it to count from actually one to nine. So let's just use the four-bit binary counter. We don't really need it to be a 32-bit value. We just need four bits. It just goes from one to nine in the loop. Now in copy, we're going to increment our index. That was a state where we're at the end of the loop and we do the loop update. So we want to count input to control the counting, because we're not incrementing in every state, just once we go around the loop, which is multiple FSM states. So we'll have this count input that says, go ahead and count. And if that's zero, the counter won't count. It'll just hold its value. Now similarly, if we want to, in the wait state, we can reset the counter to one. And then in init, instead of having another way to set it to one, we can just let it count. So normally, you'd have a reset input that resets it to zero. We can use a reset input in that way. In the wait state, we'll set the counter to zero, the IDX counter to zero. And then in init, it'll go from zero to one. And then here in copy, it'll be incremented using the count input. So those are the controls we'll need on the index counter, the reset for setting it to zero, and count to tell it to go ahead and count up one. But what about the array? We need 10 32-bit 2's complement values. So instead of just having enough cells to store 10, let's just stick down a standard memory. So some power of two addresses. So we'll round up. We'll say, OK, we've got 16 addresses, each of which stores 32 bits. And so you hopefully remember how to build this kind of memory. We've got read right here. We've got address here. I didn't put a chip select down just because it's always going to be on with our finite state machine. So you could hardwire chip select to one if you had a memory with a chip select. We're only going to read. The only thing we ever did in our finite state machine was read those values out. So from our point of view, obviously, someone else is going to have to override this at some point. But from our point of view, we could just always set this to one. Now before, I had this as write enable. Here I have it as rwbar. So here, a 1 means the r. So it just means always read. And if you look back at the code, whenever we read from this memory, we always read value subindex. So in particular, in the first state, we read value subzero. But remember that in that first state, in init, the counter index, we decided to set it to zero. So if we read value subindex, we're always going to be reading the right value. So in other words, this input here for address, I can just take the value of the index counter and hardwire it in there. And then it'll always be coming out down here, value subindex. So I don't need to do anything with that other than connect the wires. And you'll see that in the full data path in a minute. Make sense? Let's keep going. Almost to the data path, just need to talk about a couple more components. What about this min register? So min keeps track of the smallest number we've seen so far. It's a 32-bit two's complement value. So we need a register. So we'll have a 32-bit register. We'll call it min. So I'm using the fonts here. So this is the C code variable. This is our register and our data path. But otherwise, they have the same names. So what do we need for that? We need to be able to change it. So once in a while, we write a new value into min. So let's have a load input, like a parallel load input for a register. And so of course, we have to have it coming from somewhere. Well, where does it come from? So in copy, we copy value subindex into min. And in init, we copy value subzero into init into min. But in init, as I mentioned on the last slide, index is zero. So we can take the output from the memory, which was value subindex at all times, because we're going to hardwire the address port to the output of the index register, or counter, sorry. We just take that and put that directly in here. And whenever we set load to 1, min will copy value subindex. And so another thing we don't have to do anything to control in our finite state machine, it's always the same. Anytime we set this load signal to 1, min will then copy values subindex. Whatever index value is, that'll go into the address port of the memory. Out will come the 32 bits stored at that address, and that'll get copied into our min register. I'll go over this in the data path, too. OK, so then we had a couple more shift registers, shift registers A and B. Now, we decided we wanted to put values in those in one cycle. It's a little bit painful if we try to shift them in a bit at a time. We'd need to also count how many cycles that took. So we need something to just do a parallel load, let's say. So we've got a parallel load input on each of these two shift registers. They're right shifting, and then the bits will come out here. Remember that our serial comparator looked at the least significant bit first. So we want to look at the least significant bit first and work our way up to the top bit. So we're going to right shift those bits out of these shift registers. But when we want to load them in prep, we want to do a parallel load using this load input here. The 32 bits will come down from the top, get latched into the 32 bits of the shift register, and then they'll shift out one bit at a time in the compare state. So now, those only load one value. A is always set to min. B is always set to value subindex. So again, we can take the min register and take its value and just copy it directly into A, just wire it down here. And value subindex, we can wire directly down into B. And then whenever we want to set those values, we just set load and load to 1. OK. Last piece before we show the whole data path. So we need this counter to drive the serial comparator for 32 cycles. So we'll use a 5-bit binary counter. We'll call it count. We'll need a reset input, because again, when we're going to prep for the comparison, we need to reset that counter so it can count for us. Remember that the comparator here has a first bit indicator. So we have to tell it this is the first bit of the comparison. So that will be generated by a 0 signal. So when the counter holds the value 0, it'll generate 0 equals 1. And that will tell the serial comparator that the first bit is coming out to be compared. There's also the bits coming from the A and B shift registers down into the serial comparator. And so it's always just comparing the two serial output bits of the two shift registers. All right, so there it is in its full glory. So all this is, then, is the pieces I've shown you, and then a couple of other parts that we'll talk about later, like this done signal and this last signal and the then signal here. But you can see the memory. So the memory is always reading. It's taking its address from index. Here's our binary counter index. So it's driving the address port of the memory. The value subindex, then, is copied both into min and to B, but only when they exert their load signals. So if we want to copy value subindex into min, we set min's load to 1. If we want to copy value subindex into B, we set B's load to 1. The shift register A copies from the min register here, again, only when we set load to 1. A and B, then, feed the serial comparator. And then here's the counter that counts 32 cycles. Yeah? OK. Yes, so remember that the way this finite state machine will be used is some other logic will fill the memory with values. And then it will exert the start signal on the finite state machine, which will take it out of the wait state and start it doing its computation. And then once it's done, it'll go back to the wait state. And the external logic, whatever that might be, can come read this register value. And that will hold the minimum of the 10. Any other questions on this one? Yeah, Eric? Why is it so hard? Yeah, so we'll come back to this. We'll come back to this. We're going to use this. The counter will count from 0 to 31. And then when it equals 31, we shift out of the compare state into copy. And that will have been 32 full cycles in the compare state. That's right. That's right. After 32 cycles, the comparator's done. All right. So now we have all these components. We have them wired up nicely. So how does it actually relate to this finite state machine state transition diagram we drew? What's the connection? So not all of the signals in the data path are fixed. We still have a bunch of load signals and things like that. I'll highlight them in a second. What's left, those remaining input signals, are what you can call control signals, or what we call control signals. So the control signals tell the data path what to do in any given cycle. And it's the finite state machine that will decide what values the control signals will take. So the finite state machine will have, as outputs, those control signals. There are going to be six of them in this design. So using these signals, these control signals, the state of the finite state machine will cause the data path to perform the actions associated with that particular state. So I'll show you what I mean by that. First, let me show you the control signals for our data path. So on index, we've got index reset. The finite state machine has to decide, do I want to reset the counter now or not? Similarly, do I want to make the counter count now or not, for each state? Again, for, let's see, min, there's min LD. Do I want min to load a new value? There's also A, the A register. Do I want A to load a new value or not? So just ones and zeros. B, do I want B to load a new value or not? And then there's one more, which is counter reset, which is down here. Do I want to reset that counter? So by generating those six bits, the finite state machine controls all of the components in the data path to execute whatever action those particular states want to take. We haven't defined those yet. We've just talked about them. So how does the finite state machine then move between states? Well, aside from the logic we've already talked about, that well, after a knit, we always go into prep. I mean, that one's easy. We don't have to look at any inputs. The data path generates a few signals that the finite state machine can use as inputs for its transition. So there are three that we're going to care about. And they're these. So there's a done signal, which says, well, we're done with the last loop iteration. We've done this comparison nine times. We started with the first value. We compared the nine other values. And we're just done. The whole loop is done. We should go back to wait. And that's when index equals 9. So I'll show you that again in the data path in a second. There's the last signal. So that's raised in the last cycle of the counter. Counter is going to go from 0 to 31. When it gets to 31, after that cycle, we'll be 32. So in that cycle, that's when we want to transition the state machine out of the compare state into the copy state. So that last signal will just be equal to, does the counter equal 31? That's all. And I'll show you that in the data path in a second, too. The then signal, it says that a new minimum value has been found. We did the serial comparator. And it says, well, a is greater than b. We were comparing min to value subindex. And so if that's the case, we need to copy value subindex into min. And so this is the comparator output that says a was greater than b. These signals are going to be inputs to the FSM. So here they are. So here's done. You can see we take the index value. We compare to see, is it equal to 9? And if the answer is yes, then done is 1. If the answer is no, done is 0. Here we compare the counter value to 31. If the answer is yes, then last is 1. If the answer is no, last is 0. And then using the representation for a comparator, which you can look up in the notes, or just this is the right answer, z1 out of the comparator means a greater than b for the design we did in the notes. So this will tell us that, in fact, the two values we put in the shift registers, min and value subindex, min is greater than value subindex. And that was the condition under which we want to copy value subindex into min. So those are our three outputs from the data path that we'll use to drive the finite state machine. So why didn't I bother saying much about these? If I were to ask you to build this, would it be hard? Somebody said, OK, get out a piece of paper. You have five minutes to build this. Could you do it? You could. So what would you do? What's 9 in binary? 1, 0, 0, 1, right? So that means the four bits of the counter have to be 1, 0, 0, 1. That's all. And so it's just a minterm. So you'd say, OK, take the high bit. I don't know, call it index sub 3. And that with index sub 2 prime, index sub 1 prime, and index sub 0. If the pattern in the counter matches 1, 0, 0, 1, it's equal to 9. Otherwise, it's not equal to 9. So it's really maybe an AND gate and maybe a couple of NOT gates. That's it. Same thing down here. In fact, I think this is just an AND gate, all ones pattern. So those are easy. This is literally just the Z1 output. All right, so everything in the data path you know how to build. So let's go through then and make an abstract next state table. So we have five states. I want to use something called register transfer language. So what is that? It's just a way of describing how bits are moving around in our data path. So for example, start with a wait state. So for example, I'll show you RTL in a second. What does a wait state do? So wait is the state in which the FSM sits when we're waiting for some other logic to fill up our memory with values, so we can go compare them. Yeah. What? AUDIENCE 1. How do you compare them? How do you compare them? How do you compare them? How do you compare them? So if you remember the way our serial comparisons worked, the first F means first. Yeah, F means first. So for the first bit, you give it a 1. And for all the other bits, you give it a 0. All right, so wait is going to be the state we sit in. So what do we do? Well, when we get to init, remember, we wanted IDX to be 0. So we'll set IDX to 0 and wait. That way, when the start signal comes, index will always be 0 in the init state. And then we just sit there in the wait state until we see the start signal. So that's all this wait state's going to do. So we'll write that index gets 0 in RTL as follows. So you can see the thing you're writing into is on the left. You have a left arrow. And then the thing you're writing into it, the bits, on the right. So this could be some other register value on the right. That's what you'll see in some later RTL examples. But it's very simple. So there's an assignment operator, which is this arrow. So let's write that into the table. And then we'll have two next states. So the condition for the first next state will be, well, let's see if we see the start signal. I put one up there for you. So on start, we'll move to init. So if we see the start signal, we'll go to init. What if we don't see the start signal? Stay in wait. So if start is false, then we'll stay in wait. And that's it for our next state diagram, for this particular state, our next state. Let's look at init. So init is going to perform two different actions. So one is it's going to copy value sub 0 to min. And it's going to set index to 1. So how's it going to set index to 1? Well, just by telling index to count. So it'll actually set index to index plus 1. And then the next state from init is always going to be prep. So let's go back to our state table. So init does two things. So it sets min to value sub index. Remember, index in this state is 0. So this is the RTL that's actually executed, is to copy value sub index into min. And index plus 1 copied into index. That's the way we express things in RTL. So there's one thing I want to point out here. So in RTL, things are happening in the same cycle. So we might have a whole bunch of different actions. They all happen at the same time in parallel. The order that we list them cannot matter. So here, you see I'm changing index. So if this were C programming language or something, if I put this line down here in front of the other line, you might think, oh, I should use the new value of index when I go read the array. That's not the case with RTL. Even if you swap this order, you get the same result. Things happen at the same time. There's a piece of hardware. They happen in one cycle. You take the old value of index on all of the right sides. The fact that you're changing index, that happens in the next clock cycle. So just make sure you understand the notation, because otherwise, when you try to understand the diagram and the data path, and then later in 385, you'll also get confused. So in RTL, everything, all the actions happen in the same cycle. So just make it just to be clear. It doesn't matter what order we put them here. It means the same thing. So the next state, then, is always prep. Make sense? Let's go on. So the prep state, we have to do three things. We have to copy min to the A register. We have to copy values of index to the B register. These are both the shift registers. And we have to reset the counter to 0. And then we're always going to move from prep down to compare. So let's go back to our table. All in one cycle, all three actions. So condition, always, next state, compare. So remember, the counter, CNT, is what keeps track of the 32 cycles for our comparison. So by setting it to 0, we're getting ready to start counting. If we don't reset it, it's going to have some random bits in it. Good question. So let's go look at compare. So when we get into compare, A and B are ready to go. They got the 32-bit values. They're ready to shift out the first bit. The counter is just reset to 0, just as we talked about. So when we enter this state, that's what's set up for us. So all we need to do is just let the zero compare to do its work. We just need to sit there and wait, not do anything on anything else in the data path. The comparator and the shift registers will just keep shifting one bit at a time into the comparator. Comparator will keep cranking away, saying, well, what do I think about this bit? What do I think about these bits? And it'll keep doing its thing until the counter gets to 31. So this is a little easy to get confused. So maybe look at the extrema. If you wanted this to operate for one cycle, then on the first cycle, the counter value is 0. And so if you compared counter to 0, that would mean you spent one cycle in compare. So compare to 0, you spend one cycle. Compare to 1, you spend two cycles. Compare to 31, you spend 32 cycles. So we compare to 31. And then at the end of the 30-second cycle, we shift over into copy. And that means our serial comparator is fully done. And the comparison output are latched into the output flip-flops of the serial comparator. So we can then compare, was a greater than b? Remember, a was set to min, and b was set to value subindex. So when we're done with that, we'll go, when counter's 31 on the last signal, we'll go over to copy. So there's nothing to do in the data path, no RTL. So what are the next states? So what if last is true? Where do we go? Go to copy. What if last is false? Just stay and compare. I didn't draw the self-loop on the diagram, but just stay and compare. No, the shift registers are always shifting. We didn't put control. Only if you need to do something. Yeah, so OK, so the question is, do we need to do anything to make our shift registers shift? If we had had a shift input where we allowed ourselves to say, well, if I set the shift input to high, then they shift. And if I don't, then they don't. Yeah, the shift registers we put in are shifting every cycle all the time, regardless of what else is going on. So we don't need to take any action. Yeah. Yeah, so that was a more complicated shift register, just to show you how you could use a MUX to do different kinds of shifts in the same register. We don't need anything so complicated. Yeah, we only need a right shift register that's capable of parallel load. Yeah. 32. Yeah, so remember, these are all 32-bit values. And this is a serial comparator. It compares one bit per cycle. So to compare 32 bits, we have to wait for 32 cycles. Why does the counter start from 0? Because we reset it right here. Yeah, OK, so why did we compare to 31? So imagine that instead you compared to 0. How many cycles would you spend here? But when you first cycle, you come in, it's set to 0, right? So then in the first cycle, you would immediately move to copy. So if you compared to 0, you would spend one cycle here. If you were to change it to 1, compare to 1, you would move to copy. So if you compare to 0, you would spend one cycle here. If you compare to 1, you would spend one cycle with counter at 0. Counter would count to 1. And after two cycles, you would move to copy. If you compare to 2, 0, 1, on 2, the third cycle, you'd move. So whatever you put here, you'll spend this number plus 1. So by putting compare with 31, it means we move on the 32nd. Yeah, this is easy to get confused. So when you design these things, it's easy to be off by 1. It's like the A and C code, actually. It's very easy to be off by 1. So those are the kind of mistakes that people make all the time. And it's important to go through and look and make sure that you're really doing exactly the right number of cycles. Because if you compare for 33 cycles, you'll never have the right answer, right? It'll just be some random bits coming out of the comparator. Actually, that's not true. The way our comparator works, it'll shift more zeros in. So you can, our comparator is forgiving, but most hardware won't be. OK? All right. OK, one more state. So this finite state machine is going to move to prep or wait based on the data out, data, whoops, data path output done. So remember, done was going to compare index with 9 to see if we've looked at all of the array values. So done is equal to 1 when index is equal to 9. Copy, then, is going to, before it moves, it's going to increment index. And it's going to also copy values indexed to min if and only if the then signal coming out of the comparator is 1. So let me show you how we write that. So you can see there's two pieces of RTL. So again, they execute in parallel, right? So this index on the right and this index, OK, this thing is getting flaky. The two index values on the right, I'll stop using my laser, sorry. The two index values on the right are the same. And they're the old value of index. Index only changes in the next cycle. So again, the RTL is parallel. The two different statements happen at the same time. The then colon notation means that the action after the copying value subindexed to min only happens if then is equal to 1. So this is how you write conditional statements in RTL. You put the condition, you put a colon, and you put the actions that follow. So this says, well, if then is equal to 1, we'll copy values subindexed to min. If then is equal to 0, we do nothing for that first statement. There's no else clause in RTL, at least usually. I suppose you could write else and then do something else. Normally, you would write a then prime clause instead. So you'd have multiple conditional clauses. The index equals index plus 1 is not conditioned by then. So the counter will always increment. Now, when we see the done signal, we go to wait. Get my laser to work. When we see the done signal, we'll go to wait. If done is off, we'll go to prep. We're never sitting in copy for more than one cycle. Here. AUDIENCE MEMBER 2 Are not, like, inside the states? That's right. There's no difference? Yeah, on the right here, these are the transitions. And these are the actions inside the states. So if you remember, when we wrote next state tables before, we had state output and next state. These are actually the coded outputs. The RTL is the coded outputs. We're going to translate that in a minute into the data path control signals. So each statement in RTL, we have to be able to translate into data path control signals. And that's the part where you might have to go back and forth. If you realize you don't have components that can execute what you want done, you might have to change your components. All right. So it's time. I know you've been waiting. You're excited. Oh, I gave you the answer. How many bits do we need? Three? OK. Is that OK? Two flip-flops? Can you give me two flip-flops? So we're going to do something called a one-hot encoding. Why we're going to do that, you'll see shortly. You'll see what it makes easier. So here's what it means. So in each of our states, there will be one 1 in one flip-flop. All the other flip-flops will be 0. So it's one-hot. There's one 1. So the wait state will be 1 and a bunch of 0s. The init state will be 0, 1, 0, 0, 0, and so forth, as you see there in the table. So let's fill in the control signals. In wait, we have to set index to 0. So what should we do for index reset? Put a 1 there. That'll force index in the next cycle to have the value 0. What about count? Probably safe to do 0. We didn't actually define the behavior for our counter if we tell it to count and reset in the same cycle. So let's just set it to 0. For the rest of them, they probably actually don't care. But I'm just going to make things simple and just set them all to 0, because we don't want to change any of those other things. We don't want to change min. We don't want to change a, b. Otherwise, we'd see it in the RTL. So we don't need to reset the counter. Let's just set all of those to 0. So here's init. We do two actions. So we're going to set min to value subindex and index to index plus 1. So what about index reset? What should that be? 0. We don't need to change index. What about index subcount? Or we do need to change index, but we don't need to force this to 0, I should say. What about index subcount? 1. What about min load? 1. So wait a minute. So all I did is min load. How do I make value subindex get into min? So if you think back to the data path, any time you set min load, it's always going to load the same thing. And the same thing is whatever is on its input wires, which is always value subindex. So in the way we built the data path, any time you put something new into min, that something new is going to be value subindex. That's just the way the data path works. All right. What about a subload? 0. Don't want to change a, right? How about b? 0. Count reset? Good. All right. How about prep? So in prep, we had three things to do. So set a to min, b to value subindex, count to 0. So what's index reset? 0. Index count? 0. Min load? 0. a load? 1. b load? Good. Count reset? Good. OK, so compare. We had no RTL. What's index reset? 0. Keep going. 0, 0, 0, 0. Good. All right. There's no RTL, right? The counter, the way we set this up, the serial comparison and shift registers, they just do their thing. We don't have any work to do. And so we just send all 0s as our control signals. What about copy? So this one's a little tricky. So we need to increment the counter. And then conditionally on the data path output then, we need to copy value subindex into min. So what's index reset? 0. What's index subcount? 1. What about min load? Then. Good answer. So somehow, we need to make sure that this min load only happens when the then signal is true. So we're going to use then as the bit that we send. Good. What about a load? 0. b? 0. And then count reset? OK. So now you'll understand why one-hot encoding is nice. What's index reset? Come on. Hurry up. S4. Good. That was easy, right? That's why one-hot encoding is nice. What's index count? S3 or S0? Good. What's min load? S3 or then S0? Good. And then what are the rest of them? S2. Pretty easy, right? No k maps at all. So often, if you do the one-hot encoding, you have this table of control signals. You just write it down, you're done. It's very, very easy. For two flip-flops, we saved ourselves a lot of time. If you want, you can go back and do this the hard way. Why don't you use it all the time? Once in a while, you might want to have a more compact. If you really want to minimize your design, you know how to do it. But this is easier. Also, we had only five states. If you had 1,000 states, maybe you don't want 1,000 flip-flops. It depends on the complexity of your design. The trade-off is still exponential. But the exponent here is tiny. Y is what? S0, because you have to be in this state in order to. So each of the states has its own S variable. And this one, we have to AND it with then in order to make sure we're in copy when we apply the bit. All the other, well, not all of the other bits, but the three other states here, if we just put then in, we would have all these four states included. And the then output, the comparator is always outputting 0 or 1. So we don't want to change states. I'm sorry, we don't want to change min just because the comparator happens to output a 1 bit in some random cycle. So let's see. Next state logic is also pretty easy. But in order to figure it out, we have to look at the incoming arcs. So let's do that. So here's the wait state. What are the incoming arcs? So I didn't draw the self loop. But whenever you don't have a start signal, you stay in wait, which is an incoming arc. And it also comes from copy at the end of the loop. So that's on the done signal. So you've got two incoming arcs. So to write that, we'll say we're in the wait state S4. And we don't see the start signal. So S4 ANDed with start prime. Or we're in the copy state, which is S0. And we see the done signal. Those are the two cases in which we're going to move into the wait state. Now, again, it's really easy here because we just have to calculate the cases in which S4 is 1 in the next state, which means the incoming arcs. So this is the answer for S4 plus. So what about S3 plus? Start ANDed with something? S4, right? We want to make sure we're in wait. We don't want to just go there any time we see a start signal. So S4 ANDed with start, good, is S3 plus. What about prep comes from init, right? And from copy, but only when the done signal is on. So what should S2 plus be? I'm hearing an S3. Yeah, OK, so this is S3, right? Or S0 ANDed with done, done not, yeah, sorry. Good, so that's S2 plus. What about compare? Well, I did leave the self loop out, right? So S2 will bring it from prep, ORed with S1 ANDed with what? And last. Then, remember, is the then statement in the original code. So it's the thing that changes if we find a smaller value. Changes min if we find a smaller value. All right, so copy then comes from compare when we see the last signal out of the counter, right? So what's the S0 plus? S1 and last, good. OK, we're done. So this is a pretty complex, confusing design, I know. But hopefully, we went through it carefully enough that you feel like you understand it. It is in the notes. A lot of finite state machines will look like this. But more importantly, this is what a computer is going to look like. So we're going to break up our computer into a data path, which will have a bunch of components that can execute instructions. So instead of taking a fixed piece of code, we're going to have little pieces of code, which logically do small amounts of processing. And those will be our instructions for a computer. And the finite state machine then, all it's going to do is it's going to say, OK, I'm a computer. I'll go fetch the instruction. You're going to store all those instructions in memory. That'll be your program. So the finite state machine will go fetch an instruction from memory, look at the instruction, figure out what you want it to do. There'll be a representation for your instructions. And you'll say, OK, I can do that. It'll go through a few states to execute that instruction. Then it'll start over. Another instruction. Do its thing. Oh, another instruction. And that's a computer. Just infinitely, finite state machine, fetch an instruction, decode it, execute it. Fetch it, decode it, execute it. Yeah, a modern calculator will have a processor inside of it. And the processor is doing that. It's running a little program that corresponds to watching key entries and displaying. The computer processor itself is based on FSMs. The program is written as software is encoded instructions and stored in memory. And the processor is basically the finite state machine and the data path. Finite state machine will look at the instruction, fetch the instruction, look at it, decode it, and execute it, and then do that over and over again forever. No, because next is von Neumann model. But I want to just make sure if anyone has any questions about the design or anything, too. So any questions on that design? Feel like you understood it well enough? I know it's pretty fast. No, I mean, realistically, we couldn't ask you to design something this complicated on an exam. I wish I could. But there are so actually, OK, so in terms of the exam, the thing to look at is the examples from previous exams. A lot of it is analysis. So there is, I think at this point, we won't have time to cover it in class. But there's an example of analysis of a traffic light controller in the notes in section 3.3 at the end. And part of the point of that is helping you to learn how to go look at the diagram and analyze it, understand what the human meanings are, and things like that. There's also a little bit, there's a little mistake there. So you want to go through, I mean, purposely there's a mistake in the design. So you can do the analysis and understand how it's supposed to work, and then understand what the issue is. And it'll lead you through that. We often have that kind of thing in homeworks and exams. So I mean, it can't be as complicated as the one in the notes. That'll take you a while to work through. But you'll see, if you look under midterm 3, there's a whole bunch of old 190 problems that I solved for you. And so there's a couple of packets, one of the problems and one of solutions. And so I'd highly recommend people go through those. There aren't online tools for finite state machines yet. So look at all those examples, solve them. If you don't understand the solution or you find some of the other old exams with examples, I'm sure you can. I'm happy to talk about them in office hours. Come show me your answer, and we'll talk about it. But I think do spend some time on it, because we probably will have an analysis kind of question, where we say, here's a state machine. Figure out what it does, and figure out how it works. Which would be, look at the data path and figure it out. On the final two, I mean, we're going to start looking at the LC3 design. And on the final, you'll be expected to understand that well enough to make use of it. But we have a few weeks for that. Yeah. All right. Yeah. Yeah. I can't find it. Mm-hmm. I can't find it. Yeah. So how do you figure out how to break things up? It's partly, again, dependent on the components. So what you can do is just try to map it onto the set of components you're thinking about using. If you can't make it work in terms of control signals, then either you add components or you add states. And then you have to do one or the other. So it's up to you to make them match, that you have more freedom than I showed you here. Because you can also add components. You can make more sophisticated components. We could have started out, as I mentioned, on Monday, and said, oh, you want to compare 10 things? I know how to build a 10 operand comparator. We're done. Finite state machine. Run comparator. Get answer. Done. All right. We'll start over. OK. Does it make sense? OK. And I think we're out of time. If you want to ask more questions, come on down. Otherwise, we'll start by Noem in on Friday. Thanks. Thank you.\",\n",
       " \"I know midterm. Yeah, another midterm tomorrow night. No, I'm just kidding. All right, so sorry I'm a little running a little late. So today we're going to do start talking about designing finite state machines using components. So the first thing we'll do is take our keyless entry design and add a timeout. So we'll use a counter to do that. And so we'll, we'll talk about how to do it and then show how we can do it without actually even knowing what the implementation is. So we'll use whatever you came up with. So remember, I left that open for you to do the next state logic. And we'll just take whatever your next state logic was and extend it using a box. So then we'll do a vending machine. So both of these are just examples taken from the notes. So you can look there for more detail if you want. So to get started, first, I wanted to just remind you that, you know, when we did combinational logic design, the first thing we looked at was just taking it all the way down. We did truth tables into k maps, we solved k maps for good forms, either SOP or POS. And then we took those and turned them into gates. So we can always go down to that level or even lower. We can optimize at the transistor level if we want to. But it's often easier to build combinational logic with components. So we can pull an adder off the shelf, a mux, a decoder, whatever, comparators, and then plug things together and then just kind of get the meaning and build it pretty quickly. Won't be as small or as fast, but it will be much easier and much less likely to have errors. So we can do that with combinational logic. We can do the same thing for finite state machines. So we can always go through the way we've been doing it and say, OK, for each state, we're going to draw a circle. We're going to think about how many states there are. We're going to do log base 2, round it up, figure out how many flip-flops we need, assign just as many bit patterns as we need, and then go from there, do the logic with k-maps, et cetera. But we can also organize them hierarchically. So we can think of a circle as representing a bunch of states. And we can think about motion between those groups of states. And we can build our finite state machines up hierarchically. So to do that, we can use both the combinational logic components, things like I mentioned on the last slide, adders, comparators, muxes, decoders. But we can also use things like registers and shift registers. So registers and shift registers can hold part of our state for a finite state machine. So let's go through the keyless entry just to remind ourselves of what it was in terms of inputs, outputs, state machines, stuff like that. This was a week or two ago, right? One midterm ago, as we measure time. So as you may recall, the finite state machine design only reacted to user input. So we had unlock, lock, and panic buttons, which if you have one of these things, I happen to have one in my pocket, you can see the little red panic button on there. Actually, mine has a trunk button too. So if the user pushes the panic button and didn't do anything else, then the alarm would stay on forever, right? Or until the car battery dies, whichever comes first. So let's modify that design. So let's make the finite state machine actually turn the alarm off after some amount of time. So if you push panic, the alarm starts sounding, and then you walk away. So maybe you were just out of hearing range and you pushed it, your car starts making loud noises, but you don't notice it. So you go into your lab or whatever and you come out 12 hours later and your car battery is dead. So instead, let's make the finite state machine turn it off after some time. So here were the outputs for our keyless entry system. So just to remind ourselves, so we had D, R, and A. So that was D means if it's one, that means we've unlocked the driver's door, zero would still be locked. The other doors, all the other doors controlled by this R signal, one again means unlocked. The alarm is on when the A signal is one. So those are outputs. And then our inputs were unlock button, lock button, and panic button. And we get one when that's pressed by the user and zero if it's not. So then we had our state table. This is just the state table with bits. So we had four states, the lock state, the driver state, the unlock state, and the alarm state. And then these are the outputs for each of those states over here and the representation we picked for the states. And then this thing is our full state transition diagram. So I color coded these when we built it up. So maybe I'll just go through them color coded again. So the normal protocol of walking up to your car and unlocking it and maybe someone else is with you, so you unlock it again. So the first time you push unlock, you go from the locked state over to the driver state. And then you push it again, you go from driver down to unlocked, and you can keep pushing it if you want to, but you stay in that state. All of these, oh, sorry, I guess I left this loop off. There's a self loop here for staying in the driver state if you don't push anything. But if you push the lock button, that has second priority, actually second to panic, which are the red arcs. But the second priority is the lock button. So if you push lock, it doesn't matter whether you push unlock. So this is X for the U input here. But all the black arcs go into the lock state. And then similarly, the red arcs out of all of the states into the alarm state. So if you push the panic button, we said that has the highest priority. So regardless of what's going on with the other buttons, XX1 and ULP arcs, they all go into this alarm state. So that was our design, our initial design. So what exactly do we want to do with that? So after user turns on the alarm, we want the finite state machine to start measuring time. And then once a certain amount of time has passed, the finite state machine should turn off the alarm. So how does a, how does a, well, in what unit can a finite state machine measure time? Yeah. Question or answer? Okay. Yeah. So that's, that's the same thing I'm trying to describe. So my, my question for you then is the same. How can you measure time? Clock cycles, right? Yeah. Good. Did you have a question, Daniel? You're just going to answer. Okay. You're going to answer. Good. In clock cycles. So what component can we use for that? Someone already said it. Counters. Yeah. So we can use counters. You can use a ripple counter. You can use a binary counter. I'm not even going to look at the counter, right? I'm just going to say there's a counter, right? We know how to design counters. Actually, we'll look at the counter a little bit. So we'll use a counter. Here's the counter we're going to use. So it's a down counter. So it's going to count down. We're going to put in some value from the top and we'll decide what value later. I should have next slide, but we'll put in a value by, by putting this load input equal to one. So when we set load to one, the counter will load a new value and then I'll start counting down from that value. When it gets to zero, it'll produce Z equals one. Okay. So this will count some number of clock cycles for us. And after that many clock cycles, it'll generate the Z equals one signal to tell us, okay, the time's up. You know how to build one. Right? So if I said, okay, get out a piece of paper, I'd expect you would all be able to do this for arbitrary size counter. It's just going down instead of up. It's just a binary counter. So the counter gives our finite state machine some new inputs and outputs. So first of all, we've got this output Z from the counter, which is an input to our finite state machine. So that's a new input. And then to control the counter, the finite state machine has to output this LD signal to tell the counter when it should load a new value. And it has to somehow set the counter input value. But I claim that the counter input value is just going to be a fixed timeout, right? We're always going to have the same timeout. We're not going to say, well, this time, let's make it five minutes. Next time, let's make it 13 minutes. Well, now seven minutes, right? It's always going to be the same amount of time. So let's just hardwire the value input. So some T cycles, I'll set T minus one as the counter input. And I'll illustrate why it's T minus one instead of T in a second, that T will be the timeout in cycles. So the number of bits in the counter then depends on T. If we're going to load T minus one into the counter, the number of bits we need depends on T. And that in turn depends on the clock speed. So I pulled a 16-bit microcontroller from TI off the web, and its clock speed was 16 megahertz. So if you go buy one today, that's the typical clock speed. So if you want a five-minute timeout, well, that's 300 megahertz. And the clock speed is 1.6 times 10 to the 7 cycles per second, 16 megahertz. So you need this many cycles, 4.8 billion cycles to count. So you need a 33-bit counter. And once it's counted to 4.8 billion or down from 4.8 billion, five minutes have passed. I got that right. Sounds big. But you need a 33-bit counter. OK, so I couldn't fit those many circles on my slide. So I'm going to draw a few. So let's use those counter bits, which I'll call timer, to split the alarm state. So we had one alarm state. So now we're going to split it up into, I guess, four or almost five billion states. So we'll have lots of states. When the user turns on the alarm, the system will enter the alarm zero state. That'll be the first alarm state. By setting timer equal to t minus 1, which means just setting load high. And that'll force the counter to load t minus 1 into the timer bits in the state of the counter. And it will be done. So we've got a few states here, I guess almost five billion. So this dot, dot, dot is 4,000,900,000. So that's what we're going to draw it as. So we've got the alarm zero state on the left. And there we've loaded the timer bits with t equals 1. So this is the first alarm state. And then after a cycle, we go to the second alarm state, alarm 1, which has timer t minus 2. And then we just keep going and going and going. And eventually, we might reach alarm of t. I guess that should be t minus 1, sorry. Alarm of t minus 1, where timer equals 0. And that would be the state where the counter output z equals 1 to say it's reached 0. So this is why I set it to t minus 1. This should take t minus 1 steps to get to there. And then once z equals 1, the finite state machine can turn the alarm off. And so that's t cycles after you've turned it on. So t is some really large number. Yeah. And if you had a 16, so going back a slide, if you had a 16 megahertz clock, t would be this. Yeah, 4.8 billion. So it's a fairly large number. Not for computers, but for us. All right. So before we had S1 and S0. So in all of these states, we're going to keep S1, S0 to be the alarm, the original alarm representation. So when S1, S0 equals 0, 1, that still means alarm. Our output logic will be the same. Actually, the logic for all of the states except the alarm state will be the same. So we're going to replicate all the outgoing arcs from alarm, because we've already got logic that takes the system out of the alarm state to other state when things like you push the lock button. So if you push the lock button, you want to go to the lock state. So that was an outgoing arc. So for each of these states, we're going to have an arc labeled ULP X1, 0, meaning we don't care what unlocked was, but if they push lock, then we're going to go to the lock state. So if the alarm's been going off, doesn't matter how long it's been going off, you push the lock button, the car locks, the alarm turns off, just as before. So what if the user pushes panic? What should we do? So the alarm's on, and say two minutes have gone by, and they push the panic button again. We should reset. Good. That's what I thought, too. I mean, you could just let it keep counting down, but then every five minutes if there's still panic, or for some reason they have to keep pushing it. So let's go ahead and reset it. So what does that mean? Well, that means all of the transitions with ULP XX1, any time they push the panic button, which I didn't draw here, but any time they push the panic button, they go back over to the left side. So they're going to reset the timer back up to T minus 1, and then the timeout will actually happen five minutes or whatever we represented, five minutes after the last time they push panic. That's when the system will turn the alarm off. So you've noticed I've added, or you may notice I've added these down here as well. So now that we have this arc I'm not showing with XX1, then we know the leftover, the motion between these states is when you don't push panic or unlock. Remember, this is UL and LP. Unlock, remember, we decided when we did the original design, we decided that unlock would not affect the alarm. So if you push the unlock button, it doesn't turn the alarm off. So similarly here, if you push the unlock button, it doesn't matter. You just keep counting along and eventually you'll turn the alarm off automatically. So what happens then when the timer reaches zero? So the counter is going to output Z equals 1, and the finite state machine can use that to leave the alarm state. So where should it go? Locked. So why not unlock the driver? Yeah, it's probably not a good idea. I mean, it's a design decision, but you turn your alarm on and you walk away, and then when you come back, your car is unlocked. Not the best thing, right? All right. So sometimes design decisions, they seem like there's a good answer, right? But no one would think about it. It's just the right answer. All right, so let's say locked. So we'll add that in. Whoops. We'll add that in down here. So I've added this little arc saying, well, once you time out, that transition that turns the alarm off will go back to the lock state. All right. Well, that's the design so far. So we're going to treat these other states as just single states, right? I mean, the bits are there in the timer. The finite state machine state now consists of, let's say, 33 extra bits. But we're not going to even think about, well, what about the driver state, right? It's now 4 billion states also, right? But it's OK. We're just going to treat it as one group of states that has the same behavior and has no dependence at all on these timer bits. Same thing for locked. Same thing for unlocked, right? They have no dependence at all on the timer bits. Oh, yeah, that's a good. I'll let you do that on an exam. That's a good question. I don't know what to say. I actually did put that on an exam. But maybe I won't do it for you now. In fact, I was surprised because I put it on an exam. And then, of course, I wanted to solve it before I put it on the exam. And I found that it actually further simplified the design. I was very surprised. So yeah, you can use the same timer to, say, do something as Advaita is suggesting that after you've unlocked the doors, maybe they automatically lock after a certain amount of time. And that time doesn't have to be the same, right? If we picked a different time, say, Q, what would we do to decide whether to put Q or T into the counter? Amox, right? Yeah, good. Can you have asynchronous finite state machines? Yeah, you can. Yes, you can. And I mean, the finite state machine abstraction in general doesn't need to be synchronous with regard to anything. But in our class, we're only looking at digital systems based on clock synchronous design. So I mean, in any real world system where time is a continuous variable. So I mean, when we model aircraft behavior or things like that, we don't model it as a time dependent. Anything where there's rates of change also, they're not synchronous. So the states are split, but their behavior is independent. So we're going to keep treating them as single states and not worry about it. We could use the timer for other purposes. We could use it, as Advaita suggested, to turn off the, or I'm sorry, to lock the doors after a certain amount of time. But we don't have to. So let's think about the implementation. Can we use the old design? Yes, we can pretty easily. We just have two things we need to think about how to do, right? So if we have the old design, we put the timer down, the counter down, I should say. What do we need to do? Well, first we need to set the timer to T minus one whenever we enter the alarm zero state. And so if we enter that state, we need to make sure the timer bits are accurate. The counter, actually I'll jump down, the counter is actually going to handle the transitions between those states, right? It's the down counter. So every cycle, it's just going to count down. That'll take us from alarm zero to alarm one to alarm two, et cetera. So we don't need to do anything there, right? The counter already has that logic. To move from alarm to locked when Z equals one. So somehow we have to set up logic somewhere in our next state diagram or our next state logic to make sure that when we hit alarm T minus one, that we take the system from alarm to locked, right? And that we'll know when to do it because we'll see Z equals one. All right, so let's look at this first one. So we want to set the timer to T minus one when alarm zero is entered. So remember that we decided when are we going to enter alarm sub zero? Well, anytime we press the panic button, right? So what signal should I use to load the timer? Just P, right? If I just do this, I put up, sorry. If I put P into LD, right? Then anytime you push the P button in the next cycle, the counter will load T minus one. So as long as we also make, well, we already know actually in the original design, whenever you push the P button, you'll go into the alarm state. So I guess this solves the whole problem, right? The other logic for going into alarm sub zero is already part of our state machine. We've already got the logic to go S1, S0 equals zero one. So now we also have the logic here, just by putting, connecting P to LD. We also have the logic to make sure that we're going into the alarm sub zero state anytime you push the panic button. So that serves both to enter the alarm state as well as to reset the timer if you're, if you're pushing it again. Pretty simple. All right, so we're half done. What about this one? This one's a little trickier. So we want to go from alarm. Alarm is S1, S0, zero one over to locked, which is zero zero when Z equals one. So we only need to change S0. So how can we do that? Is there an easy way or do we need to go look at the big state table and, you know, add another variable? We had five already. You want to do a six variable Kmap? Okay. So do you think of a way that I can, I can somehow, I don't know, choose between the old stuff and the new stuff? I liked, I liked the besides the something. If you put a, if you put a flip flop in the middle, you're going to end up delaying things by a cycle, right? If you use that as state, but maybe. Yeah, I think, I think I'm hearing mucks and mucks a couple of places. So let's just use a mucks. So we've got the thing that you were supposed to build on your own, right? This original S0 plus logic, right? I showed you the table and I said, okay, you know how to do this stuff, so I'll leave it to you. Let's say someone's done it, right? So we've got that. We'll just put the zero input of the mucks from there and we'll have the one input of the mucks be zero, right? So when the, when we want to go, when we want to force the system to move from alarm to lock, we'll set the mucks selection input to one and it will go to that state. And then otherwise if the mucks select input is zero, it'll just act as it always did before. Okay. So all I did is kind of push the problem around a little bit, right? So what controls the mucks select? So when do we want to go from one to the other? Z is one. I put that last, so we'll remember that one. Okay. What else needs to be true to force this transition? Yeah, no panic, right? What about other buttons? So unlock we decide to ignore, right? Okay. So unlock doesn't matter. What about lock? Yeah, it's, it turns out it won't matter either. But, but in terms of the transition that we're adding, we said it was ULP equals X zero zero, right? And what about just being in this alarm state? What is the alarm state? Zero one, right? S one S zero zero one. So we don't want to force, if we're in some other state, we need to be a little careful. We don't want to force this, this S zero to zero for in some other state, right? So I would argue the first, the first thing we need to make sure is we're actually in the alarm state. So if we're in the alarm state, and there's other things that people mentioned that we need ULP equals X zero zero. So it didn't push locked in push panic. That was our transition label. So this is the state, right? So all I really did is I read, okay, I want to go from alarm to locked. Here's the state that I'm starting in, here's the transition label. And by the way, I wanted to add this thing, which is the other thing people mentioned, right? So this thing says, okay, the timer has now counted down to zero. So if I put all those three conditions together, I get S one prime S zero from this, I get L prime T prime from from the transition label, and I get Z. Now, as someone already mentioned, if we press L, we're also going to locked, right? So our system is already going to do that to us. So it doesn't much matter if we just drop the L prime, right? If we drop the L prime, this is this is going to give us the same behavior. Alright, so here's the diagram. So you'll notice that I've encapsulated the S one plus and S zero plus logic in these little boxes, right? Whatever someone already solved, that's all done. It's just a box, it takes ULP S one and S zero, and it calculates next state for S one plus calculates next state for S zero, sorry, which is S zero plus. And those would have normally just gone into S ones D input and S zeros D input. And that was our finite state machine. Now we've added our counter, we've taken P and connected it to the load input as before, put t equals one hard coded bits into the counter, parallel load input. And then down here, we have z equals one and it with P nodded, so P equals zero and it with S one nodded and it with S zero. So this is our mux control signal. So if that thing is on, we want to force S zero to be zero, which we do with this mux input is one, you get the zero and put that into S zero. Otherwise, you've got a zero on the mux select, then S zero plus just goes in there and the finite state machine acts like it used to. So all we needed was a counter, a couple of inverters, an AND gate and a mux. That's all. Any questions? The output logic is also the same. I didn't draw it on here, but we don't need to touch it. So whatever we calculated before, we just keep the same output logic. All right. So there are a few examples, we won't go through all of them. But I wanted to do at least one. So I think we'll start this, I doubt we're going to finish it today. So this is a vending machine. It's more complex than the one you do in the lab. So it's a more realistic vending machine. But I wanted to show you how you can build things out of components. So we're going to use a few different components for this vending machine. We'll have registers, we'll have adders, we'll have muxes, we'll have decoders. We're also going to develop a new component, priority encoders. So the priority encoders are often used for things like deciding which device gets attention when you have multiple devices on one processor. So you prioritize them, and you put the inputs about getting attention from the processor into priority encoder, and out comes an encoded number saying, well, this particular device you should look at now for the processor. So we'll also do one little module specific to this FSM design, which will translate an input representation into a value for us. Not unlike the one on the midterm last night, actually. So let's assume that we're going to sell three items. So why three? So every item we put into our machine is going to have a price. So we have to keep track of that. We have an input to identify it like a button. So when you have your vending machine, you have to be able to buy that thing. So you're usually going to have a button or some set of buttons that scale up with the number of things you could buy. And they'll also need a release mechanism to drop that product when you buy it. So if we choose three items, it's big enough to be interesting. So all of the pieces we'll have to develop, we'll have to think about and think about how we would scale. But it's small enough that we can fit it on slides and kind of show you easily. So that's why the vending machine will sell three. I think once you understand this implementation, you could pretty easily say, well, I want a vending machine that sells 100 things and just go extend those. It's not that hard. So let's think a little bit before we start. How is our vending machine going to work? So I claim this is kind of a general protocol for a vending machine. So you walk up to the machine, say you're the user. You look through the items. You say, OK, I want that thing. It's probably Dew or Nutella or something. And you see you want to buy it. And you then put some money into the machine as the next step. The machine has to keep track of how much money you put in. So we need some state in the machine to do that. When the user has put enough money for the item, then the user pushes a button. So this is our expected protocol. This is the abstract model design process, the first step of designing a finite state machine. So you push a button. And then the machine checks, of course, how much money you've put in. And it sees you've put in enough money, releases the item for you, and deducts the price of the item from how much is stored inside of it. So it has to keep track of that, too. Often, most machines you'd encounter would then give you back all the money that was left. Our machine won't. It'll just keep your money and hope you'll buy something else, mostly for simplicity. But we won't do this last step. So I'll just read it out. So what's going to be the main state of the vending machine? OK, so let me ask this a little different way. So yeah, I mean, if you get no input, you'll stay in the same state in the couple meanings of state. So what I meant here is, what information does the vending machine have to keep track of? It's the money, right, is the main thing. So simplest answer is maybe how much money is being stored. And as people said, if we don't do anything to it, it'll store the same amount of money. That amount will only change when the user pushes buttons or puts coins or bills in or something. So let's use a register. Let's use a register to hold the amount of money. So when the money is inserted, we can use an adder. You put some money in, you've got some money there, put some more money in. How much money is there altogether? Well, why don't we just add it? We'll store it as a number. We'll add the new number, put it back in the register. So what about when I buy something? What should I use? So subtractor, which is also an adder, by the way. So when we want to make a purchase, we'll subtract. So we'll just represent the amount of money as some integer. And then when we put money in, we'll add to that integer, put it back in the register. When we buy something, we'll subtract from that integer and put it back in the register. So those are some of the pieces we'll use. So how much do products usually cost in a vending machine? A couple of dollars? Yeah, that's what I thought too. So $1 to $2. I've seen them up at like $5 to $10, but I don't go back to those vending machines. So how much money can the machine store? What do you think? Yeah, OK. Yeah, I said $2 to $4. So that's probably about enough. We can make it bigger pretty easily. Coins or bills or both? Yeah, probably both, right? Or credit cards, even better. Our answer is going to be coins. So we're going to accept coins, but no pennies. So let's count money in nickels. So the amount of money we'll store will be a number of nickels. So our state is register N, which is the number of nickels stored. I just really like nickels. So I just wanted to have, it doesn't actually matter much at all, right? So I wanted to have a variety of values that were around the cost of an item. And so if you put coins in, then those are all close enough to the, somewhere under a dollar, up to a couple of dollars cost. So it gives some variety. That was why, to make it more interesting. Plus, I can use the N for the register name. I needed other letters for other stuff. All right, so the machine we said should store a few dollars. The value of N is in units of $0.05, $0.05. So N should hold maybe 40 to 80. So we'll just have a six-bit register. Again, you can take this design. You can make it eight bits. You can make it 20 bits if you want pretty easily. Just cross out the sixes, replace it with whatever size you want, right? So it's pretty easy to extend this. So in this case, the maximum is 63 or $3.15. So that's what our machine will be able to store. So we have to pick something, right? It doesn't much matter for the design process what we pick, but we have to pick something when we build it. So what about item prices? So these should be easy to change, right? So we could say, OK, to make our design easy, we could hard-code these prices. So item 1 will be $1. Item 2 will be $1.50. But instead, let's keep those in registers. So we'll throw some more six-bit registers in to hold item prices for our three items. Whoever owns the machine can then set the prices. And I wanted to also introduce this idea of abstraction in the sense that we're now going to design a finite state machine where decisions will be based on numbers, but those numbers will actually be in registers. So we won't be able to even know, well, what exactly transitions do we have without thinking about specific values of these registers? So we're actually going to abstract away the notion that, well, we have to look at every arc. I mean, every arc has to be specified. We'll actually specify them in terms of unknown values. The values are there in the registers, but we have to read them out to use them. So the prices will be stored here in registers P1, or rather, as values P1, P2, and P3. We'll store those in six-bit registers. So those are state. That's another 24, I'm sorry, 18 bits of state there. But again, we're going to abstract those away for the most part. So we're going to design our finite state machine, assuming that our prices are constant, but they're not known in advance. So they're just going to be numbers. So the user will set the prices, and then the finite state machine will operate. But we won't know what those are until we're actually operating. OK, so now we have a model of what we want to do. We can start to draw an abstract state table. So here are a couple entries. There's a more complete table in the notes with all of the possible inputs. So here's just an example. Well, so here's the first one that someone already mentioned. So if nothing happens, if the user does nothing to the machine, all of these lines are coming from state n. So if you're in state n, meaning that you've got n nickels, and nothing happens, they don't push any buttons, they don't put any money in, then what happens is you always stay in that state. You don't accept any coin, or rather, this x says, I don't care if the coin accept signal is yes or no, because you didn't put a coin in. And you don't release any products. You don't just drop products out every once in a while. All right, so that would be nice, but maybe not to the owner. So the other thing here, I want to mention now the condition. So you can see there are two input events, quarter and serdu. So what actually happens depends on the current state. So well, there's a design decision implicit here, actually, in the answer. So what should happen, do you think, if you've got, what do we say, up to 315? So you've got $3 in the machine, you put a quarter in, what should you do? Steal the money. Okay, we need to change this. Yeah, so I've used those machines too, but we're going to design a nicer machine. Yeah, I've used the machines where you don't have to have $3. You can have nothing, and you put the quarter in, and it just goes away. What quarter? No, but if you're going to overflow your register, right, if you're going to go above 63, instead, we'll just return the coin. Okay, so this is checking, right, a quarter is 25 cents, so it's five nickels. So if you add five to 59, you get 64. So we don't have space for that in our six bit register. So if n is greater or equal to 59, then we'll stay in state n and reject the coin. So we'll send the quarter back. We still won't release the product. On the other hand, if we can add five, the value of the quarter to n, then we'll go to state n plus five, keep the coin, and also not release any products, of course, for coin insertion. Okay? Make sense? Okay. So here's another couple of examples. These are for the product selection. Again, they're actually same things for item two and three. All of these are in the notes if you want to see the big table. So again, starting from state n, again, two choices, and then this condition. So in this case, what we do depends on whether n is greater or equal to the price. So here the user is trying to pick item one, we have price one for item one. So if the money in the machine n is at least as big as p1, we're going to sell them the item. So to sell them the item, we make two changes. First, we subtract p1 from our current number of nickels held. So we go to state n minus p1. And then we also release the product number one. So we give them the product and we take away their money. Except coin doesn't matter here because we're just doing the abstract model. So there is no coin. And so we just don't care. On the other hand, if they haven't put enough money in, then we just ignore them. We stay in the same state, we don't release a product, and except coin again doesn't matter. All right, so you would you would flesh all of these out as part of your abstract state table for all the different possible inputs. So then let's go on to step two of our FSM design process and say, well, what exactly do we want our inputs and outputs to look like? Right, we need bits. So input, we're going to get a coin sometimes. So it's going to be a three bit value, c. It's going to be c21c1c0. We're going to assume that someone's providing us with a representation. So I'll show you that representation on the next slide. But we don't get to pick it. It'll just be this is the kind of coin you're getting. And here's here's the three bit value to tell you that. So get that input. We'll also get product selection buttons. So these will be like the UL and P buttons before except it'll be well if I want product one, I'll push b1 and then b1 will be a one. There's also b2 and b3. So those are inputs, six bits of input. Our outputs will be coin accept. So one means accept the coin that just came in. Zero means rejected. And then item release signals are one or two or three, each of which means release one particular item. So if you set that high, that gives them one of those items. So that's our I O. This was the representation I mentioned. So often, I talked about this a little bit earlier when we first talked about designing I O, but often someone else is going to pick the representation, right? You're going to have to interface with some standard or you're going to interface with a component someone has already built or is just buying off the shelf. And so what information it gives you and how that information is represented, you don't get to control, right? If you want, you can translate it to a different representation. But again, you have to build logic to do that, right? So here's the representation we'll assume. So if no coin comes in a cycle, we'll get one one zero. If a nickel comes in, we'll get zero one zero and so forth. So we've got five different kinds of coin. We've got this no coin input, right? That's the no event, or no input event. These are the values in dollars. These are the values in nickels. That's for later. But this is the representation we're going to use. So of course, two patterns are not used, right? There's only five coins and one no coin. So two patterns are not used. And when we use this, we'll put don't cares for those because we'll assume that this representation is valid and the coin mechanism is never going to give us the other two patterns. So one aspect of the outputs that we need to be careful about, and we need to make sure that we communicate with the people building the other parts of the system, we decided that the finite state machine never produces outputs based on inputs. So in other words, these tables, the abstract state tables I just looked at, and the next state table we just looked at, it gave the outputs as a function of the inputs, but we don't build things that way in our class, right? So we're going to calculate the outputs based on the state and the inputs, but then we're just going to put those in flip-flops. So the output for the coin, you put a coin in cycle 10. In cycle 11, the coin mechanism will get the accept signal. So the coin mechanism designer needs to know, well, you're not going to get the answer until next cycle. They can keep putting coins in every cycle, they'll get an answer delayed one cycle, because we don't want our output to depend directly on the input. So we'll just put those in flip-flops, but those outputs now are also state. So we've got four more bits of state. So we have an abstract model, we have IO, what's next? Remember we had this six-step process, right? We said, okay, do an abstract model, specify your IO, then you've got to complete your specification, right? Okay, good. So how many bits of state do we have? So if we ignore the prices, let's see, ignoring the prices, we have six-bit register for the number of nickels. What else do we have? Four bits of shared output, of stored output, right? So 10 bits, okay, 1,024 states. Not too bad, right? Anyone want to draw 1,024 circles? What about inputs? Remember? We have coin, right, which is three bits, and then we have three buttons, so six bits. Okay, so 1,024 states, each with 64 arcs. Remember, digital system has to be complete, so we have to know what each of those does. Good luck. All right, so we better simplify. So first of all, this poor output bits, those don't have any impact on where we go next, right? So even though we have 1,024 states, we're going to ignore the output bits. We're just storing them because we want them to be held for a cycle so that the coin mechanism can see clearly, accept or reject for a full cycle, can use it to drive its gate or whatever, right? So those we're going to ignore. So each of our state sub-ends will then be actually 16 equivalent states. So just like we said, well, the driver state, it's got the 33-bit counter, but it's all just one state for our purposes, right? So here, each of these states, based on the number of nickels, nothing matters. Sorry, these output bits don't matter at all, so they all look the same regardless of what the output bits are. So we'll have 16 equivalent states, but we'll just represent it as state of n. So that reduces from 1,000 states down to 64 states. So the other thing to notice is that we have these two unused bit patterns in our coin input, so really it's not 8 times 8. It's not 2 to the 6th. It's 8 from the button input. It's 8 different button combinations and 6 choices of coin. So we only have 48 arcs. That's still a lot, right? 64 states, 48 arcs each, that's a lot. So before we make it easier, so our table had only 9 input events, right? So we had nothing happen with 5 types of coin and we had 3 types of purchases. So where did the other 39 arcs come from? How come we have 48 arcs? So when we completed specs before, what kind of things do we have to worry about? Short answer is humans, right? Long answer is people pushing more than one button, people putting a coin in while they make a purchase. These input events are only 9 of them that we care about, but nothing keeps a human user from doing them at the same time. So when we multiply them all out, we get 48. I wonder how we map them to a function that says... In the past, we did pretty simple strategies. I wouldn't say they don't care. You do have to make a decision that makes sense. I mean, for example, probably a user wouldn't be happy if they put a coin in and push the button, it happens to be the same cycle, so you just decide to eat their coin. An owner wouldn't be happy. I mean, if you said it don't care, you could also release all 3 products, right? Yeah, so that's a good answer, right? So one strategy is just to say, well, let's pick a priority, and that's what we'll do, is we'll pick a priority, and then we'll say, we're just going to strictly prioritize. I'll show that in detail in the next slide. Do you want to say something? I was going to ask, like... Yeah, yeah. So Eric's suggesting that, well, what if we just say, if you do more than one input, we ignore all the inputs. And absolutely, yeah. So if you do more than one input, we could say, okay, in that case, we do nothing, right? The choice we'll make this time is just to pick a prioritization order. So let's choose a strategy. So we'll prioritize, and we'll prioritize strictly, so meaning that we'll ignore the lower priority events and try to execute the highest priority event. Now this is a little... There's going to be a little strangeness here in the following sense. So let's say that your highest priority event is a purchase, so you put a dollar in and you push the button too quickly. Your dollar's enough to pay. Without the dollar, you didn't have enough to pay, and we're going to prioritize purchases. So we check, do you have enough money? We say no, we don't let you buy it. We're not then going to go say, oh, but you put a dollar in. No, we're just going to ignore all the other input events. So your dollar will get returned also. It's a little strange. You could make it more flexible if you wanted to, but it's a little more complicated. So we're going to have it very simple. We'll prioritize them strictly and try to execute just one of them. So our strategy will be purchases are highest priority. Item three is the highest priority. So if you push button three, the only thing the system will do is try to sell you item three. If you didn't push button three, then it'll see if you tried to buy item two, then item one. If you didn't try to buy anything, then it'll see if you tried to put a coin in. Now the coin inputs are all distinct. We're getting this three bit input that says nickel or dollar. You can't put both in at the same time, so we don't need to do anything there. We don't need to pick a priority. All right, so now we can actually go back and write a complete next state table. It's actually quite large, so you don't want to really do it. But just to show you what the kind of thing it would look like, so if you pick some prices, so let's say that P3 is 60 nickels, P2 is 10 nickels, P1 is 35 nickels. And let's say that we're in state 50. So I've ordered these in priority order. So the first one says, well, if you push button three, then it doesn't matter whether you push the other two buttons. So those are don't cares on the input side. It doesn't matter if you put a coin in or not. Don't care about that pattern at all. Your final state will be state 50. Wait a minute, why is that? So you tried to buy item three. You had 50 nickels. Oh, but item three costs 60 nickels. So the answer is no. You only put 50 nickels into the machine. You tried to buy something for 60 nickels. So the answer is no, you can't buy it. So don't release anything. R3 is zero, R2 is zero, R1 is zero. We don't release any product. Why do I have zero here instead of don't care? Yeah, so we said we don't care what coin they put in, but if they put a coin in, it should come back to them. We don't want to take it just because they happen to try to buy something in the same cycle. So even though in the abstract diagram when we try to make a purchase, we said we didn't care, in this case, we actually do care. We want to return the coin to them. So the next line is trying to purchase item two. So we're kind of running out of time, so I think I'll try to finish this one up and maybe start again with it on Friday. Try to purchase item two. In that case, item one doesn't matter, coin doesn't matter. The cost is only 10, right? So we'll go ahead and let them purchase it, which means we'll go from state 50 down to state 40 by subtracting 10, and then we'll release item two for them. Similarly, we're going to reject any coin they happen to put in. Technically, yes, but we're going to design with components and make sure that our rules are followed. So that's why I said you wouldn't want to really write this out, because it also depends on the prices. So when we get to this level of abstraction, you really don't want to have to—you want to be able to verify your ideas without going to this level, because this level will blow up. Yeah, so I mean, we would still say go from—we would still have our conditions and still say to go from n to n minus p. Yeah, yeah. Okay, let's stop there and we can we can follow up more offline if you want, because the time's up. Don't want to hold people up. Thanks.\",\n",
       " \"Okay, so I think it's three. So today we're gonna start off with binary counters so we can start doing some finite state machine designs. It looks like the amplitude is up. So we'll talk about synchronous counters, we'll talk about ripple counters. Synchronous counters are clock synchronous sequential circuits and ripple counters, the flip-flops of some, I'm sorry, the flip-flop outputs drive the clocks of other flip-flops. I'm gonna turn this down slightly. Okay, maybe that's better. Then we'll talk about machine models. So in our class, we'll assume that outputs are never a function directly of inputs, but I'll show you a machine model where that is the case and talk about the differences and why we choose not to allow that dependence in our class. And then finally, we'll go through a six step design process for finite state machines and use that for a small example. On Friday, I think we will cover mostly the design of the lab FSM that you'll be building on your protoboards. I mean, you've already started building that, but actually implementing it in the protoboard in the next week and a half, and maybe two weeks. So that's the plan. We did get your feedback surveys and we have the tallies. I read through most of the written comments. The only thing is they didn't correlate the written comments yet with those which are from you versus those from other students. So I'll look at it more deeply over the weekend and come back on Monday. So reminder, we have midterm coming up, which hopefully you know. Next week, next Monday, we have a review session and this slide you've seen a couple of times, so I won't spend too much time on it. Oh, there is one other bit of information I have, except I should have written it down from the email. Eta Kappa Nu is running another review session on the weekend. It's on the 15th, I think it's on the 15th. I'll give you the details on Friday, but you can probably also find it out from Eta Kappa Nu people, or post it on their site or something. As always, we can't endorse, if they make mistakes in the review session, we can't endorse that, unfortunately, but it should be useful. All right, so what happens if we think about a finite state machine that has no inputs? And so it's gonna start in some state, and then where's it gonna go in the next clock cycle? Oh, it goes to some other state, right? There's no input, so there's exactly one arc going out of the state, it goes to some other state. And then what will happen next? Go to some other state. We'll keep doing that, right? But at some point it'll run out of states because of the finite state machine, there are finite many states. So eventually it's gotta go back to one of these states. So eventually it's gonna go back to a state. So let's just go back to that one, and we're gonna get a loop, right? Yeah. Sure. So it doesn't have to change state, that would be a loop of one state, right? So it would also be a loop. So you can decide how many states you want in your loop, it could be one, it could be four, it could be a thousand, but it has to be finite, right? And that's a good question. Okay, so it'll go around in some loop of some number of states. Now, if we have such a finite state machine, we call that a counter. Now, counters sometimes will add inputs to them. So we might say, well, I wanna be able to start and stop my counter, so I'll use an input for that. Or maybe I want a counter that counts up and down, so both ways around the loop. So maybe I'll add another input for that. Sometimes maybe I wanna reset it, so I wanna force it back to a known state, maybe I'll add an input for that. But generally speaking, when we talk about counters, we're talking about something with one loop and it's normal operation is just to go around that loop of states. So we're gonna talk about two kinds of counters. One is synchronous counters, which are clock synchronous sequential circuits. So these are the same kind of designs we've been talking about for the last couple of weeks. We use flip-flops to build them, we use a common clock to all of the flip-flops and they all change state and allow us, they all change state on the rising edge of that clock and allow us to think of time as being discrete. And so time's just an integer. We'll also look briefly at ripple counters where the flip-flops of some, I'm sorry, the outputs of some flip-flops are used as the clock signal to other flip-flops. We're only gonna look at binary counters for these, so simple designs. But so the reason we'll look at them is they can actually save you a lot of energy. Let's start with an example of a counter, we'll do a synchronous counter first. So here's a state transition diagram with eight elements. And if you look at these, these are just counting from zero and unsigned, zero, one, two, three, four, five, six, seven, go back to zero. And so this is a three bit binary counter. So in order to build this thing, first thing we'll do is just copy that into a next state table. So what's the next state from zero, zero, zero? Good, and then? Good, keep going. Good, good, okay. So you realize this is very easy for this one, right? Generally speaking, it's not too hard for a counter. What if I had six states? What would I do with the other two rows? Just put Xs, right? Because I don't care. Now, we'll look at a design like that probably on Wednesday, because on Friday, we'll do the lab design. We might get to it on Friday. On Monday is a review session. So we'll look at a design where we have some Xs later. For now, let's just do K-map. So we'll start with S0. So here's K-map. So let's copy. So remember when we copy, what I did is I put S1 as zero on the top here. So right across the rows, as S1 as zero changes. And then since this is gray code order here and the K-map binary order here, I'm gonna go first, zero, zero, zero, one, over to one, zero, and back to one, one. So one, zero, one, zero, one, zero, over to here, one, and then back to the one, one slot, zero. And then one, zero, one, zero again. So one, zero, one, zero. Okay. So what's the, what's, what loop should I circle there? The square on the outside? Yeah, okay. I'll do all of these SOP, by the way. Yeah, good, good thinking, those of you who are about to ask me about POS. It's just as good, right? It's actually the same answer here. So I think that's the S0 prime loop there, which you could also choose to write as S0 XORed with the one value. You'll understand why later. So then what about S1 plus? So throw up a K-map, copy. So zero, one, one, zero, zero, one, one, zero, and then zero, one, one, zero again. What are the loops here? Yeah, so these two and these two, right? Okay, good. So that's S1, S0 prime, S1 prime, S0. And that's just S1 XORed with S0, right? Okay, so we have S1. So what about S2? So, I'm sorry, zero, zero, zero, one, zero, zero, zero, one, and then one, one, one, zero, one, one, one, zero. Oh, this one's messier. Okay, so there's one. What else? These two over here on the left, okay. And then two again. Okay, good. So if I wrote those out, that's S2 prime, S1, S0, the same order. So that's this one. S2, S1 prime is this one. And then S2, S0 prime is the one that wraps around there. Okay, so that's a little messier looking. Maybe we should try to do five bit and see if it gets uglier, we think. All right. So I wanna ask you a different question. When you count, have you been counting recently? Yeah, counting is important. When you've been counting, when does the place value change? So for example, you're counting along and you get to what number that say the thousands place value changes? 999, like here. So you're at 0999. Sorry, I'm a computer engineer, so I put a leading zero. So then the thousands place changes, right? Or if you're at, what's the next one? 1999 or 2999? What about the 10 thousands place? When does that change? Ah, so 0999. Do I say enough lines? Anyway, it's up there. So like that, right? So you see the rule? What's the rule? All the lower digits have to be nine, right? So that's when a place value changes. So what do you think that rule is in binary? All ones, good. Okay, so, so far, whoops, you didn't answer. So, so far we have these equations. So we have S0 plus is S0 plus XORed with one. S1 plus is S1 XORed with S0. S2 plus is this nasty thing. Can you simplify that? So remember, it's gonna change when the lower digits are all one, right? So here, there are no lower digits. So the lower digits are always all one. So we XOR the digit with one. Here, the lower digits is just S0. So we XOR the digit with the lower digits, which is just X0. So here, we've got two lower digits. So we should XOR S2 with what? S1, S0. So I'll leave it to you to verify that these two are the same. I think they're the same. Is it that easy? Okay, yeah. If you apply to Morgan's, I'm sure, yeah, you'll get this one out, right? Okay, good. I can't say it that quickly, but I'll believe you. All right, so let's use our general theorem to build a bigger design. So what if we wanted a four-bit binary counter? Do we need to draw a K-map or can we just write down S3 plus? Sure, what is it? Like that? Okay, good. And then S4, sorry, I skipped ahead. Okay, and what's S5 plus? Like that. Okay, so we can build an arbitrary big counter, right? So here is a counter using what's called parallel gating. And so you can see that in this design, we're basically just using the equations. So here, I've just fed the inverted output back. So that's equivalent to XORing with Y, right? Here, I am XORing the current value of S1 with S0 from over here. Notice that I've drawn these flip-flops backwards, right? So the least significant bits now on the left. I did that just because it's easier to draw the logic. So most significant bits are over on the right. The next digit, we've got S1 ANDed with S0 out of these two flip-flops, then XORed with S2, and then the last one ANDs all three of them together before feeding into the XOR. So these are just the equations we saw. Yep. That's okay. Good question. Here's an answer. Here's a serial gating. So what you should notice is, as Raul pointed out, so now we have, instead of, let me go back a second. So here we were starting to build up, right? This AND gate has three inputs. If we continue, the next AND gate would have four, AND gate after that would have five, but here's S5 plus, right? It has an AND gate with five inputs. S6 plus would have six inputs. S10 plus would have 10 inputs, right? Bigger and bigger AND gates. So instead of doing that, we can build in this serial approach where it's the same label, but you can see I'm using S1 as zero. I'm reusing the output in order to calculate S2, S1, S0, right? So these are serialized so that each of these AND gates, instead of getting bigger and bigger, is now only two input. So I'm saving a little area. And the expense, as Raul also pointed out, is that, well, now I have to wait to go from here through here, through here, through here, instead of, in the parallel design, taking the outputs and all merging them into through this one gate. Now, of course, the gates are actually gonna be limited in number of inputs, so we couldn't really build it exactly this way. So in practice, they use a combination, right? So parallel gating gives bigger gates, so more area and less delay. Serial gating gives smaller gates, so less area, but more delay. In practice, your gate sizes are limited. You can't have 20 inputs. So you use a combination of the two. Yeah, Raul. Yeah. Time. So usually, it's a function of the actual semiconductor process. So the process technology will tell you which implementation would be faster. And there's actually, usually, you're also leaving things like transistor sizing for the tools to finish off for you. So it's really, without going into those proprietary parameters in the process, you probably couldn't answer that question precisely. So it's, now, in terms of rules of thumb, usually, maybe four inputs and drive four outputs is about the point at which you wanna go to more gates instead of bigger gates or more outputs. Okay. So that was a synchronous binary counter, right? So what does that mean? Ripple counter, one loop of states. Binary just means the outputs are binary, hence, I have numbers going in order. And synchronous means they have this common clock. So now, let's go take a look at a binary ripple counter in which the clock is not shared. Okay, so now, the flip-flop clocks will not have all the same clock input. The flip-flops will not have the same clock input. So in a ripple counter, we're gonna take the outputs from some of the flip-flops and use those as the clock input to other flip-flops. And I'll show you an example in a second for a binary counter, binary ripple counter. Why are we gonna do that? So remember, when we talked about power, I mean, I said, mostly, it's outside the scope of the class, so don't worry too much. But remember, when you change a transistor, you're gonna have electric current flowing, right? So you're gonna change some voltage from zero to one, one to zero, electric current's gonna flow, it's gonna generate energy, basically, flowing through a resistance, it's gonna take energy, right? It's gonna take power. So it'll increase power consumption. And so by clocking the flip-flops more slowly, then what happens is we reduce that power consumption. So total energy is reduced. So in a lot of embedded systems, people use ripple counters. The trade-off then is that the changes to the internal state instead of just happening at the same rising edge of the clock, in order for that change to happen throughout the counter, well, what you'll see is the change has to go through one flip-flop, then the next flip-flop, then the next flip-flop, and so on, till it gets to the end. So the changes, just like the ripple carry adder are gonna ripple through the counter, they'll be much slower. And we won't actually quantify that, but you'll see that it's slower than synchronous counters. The other thing you might think about... Let's take that offline. I mean, basically higher voltage is a stronger electric field, so electrons will move more quickly. So you're fighting the delay issues. As you'll see that it will be a bit-sliced design. I wouldn't say that in general, you couldn't do anything more complicated, but for our class, the only one we'll look at is a bit-sliced design. So what about clock skew? We said, well, let's avoid clock skew. In general, it could be an issue. We're just gonna look at one simple design. And honestly, more complicated ripple counters, as long as you're operating, as long as the clock is just managed within the counter, you can say, well, as long as the circuit person gives me a level clock edge into my ripple counter, I'll manage the clock delivery within that counter. So it's not really as hard as general circuits problems. All right, so here's the ripple counter we're showing. So you can see this is a simple bit-slice. So each of these is just replicated four times. And then what's going on is for each of the, the bits are again backwards. So least significant bit takes the real clock. And then the next least significant bit takes the inverted output of the first bit, of the lowest bit as its clock input. And then the second bit does the same. Third bit does the same from the previous bit. So Si plus one takes its clock input from Si inverted, Si prime. So that's these circles down here. Also notice that Si prime is also the D input. So for each of these flip-flops, the bit-slice takes the inverted output and feeds that back into the D input. So what that means is every time any of these flip-flops sees a rising clock edge, it's going to toggle its value. If it's holding a zero, it'll become a one. If it's a one, it'll become a zero. Okay? All right. Yeah, go ahead. The initial state of Q naught, if we assume that the bits are starting all zero, then the initial state of Q naught would be one. Yes. Yeah. Okay. So let's take a look at a timing diagram so that we can understand what's going on. So up here, I've drawn a square wave clock, and these dotted vertical lines are the rising clock edges of the clock. So that clock is going into Z naught. And then the clock is going to be a one. So that clock is going into Z naught. So these are the initial values of the three bits we're storing. So they're all starting low. So at this rising clock edge, what's going to happen to Z zero? It's going to flip, right? Remember that on all of these, we fed the value complement back into the D input. So anytime we see a rising clock edge, we're going to flip the value. What about this rising clock edge? It'll go back to zero, right? Good. How about that one? Up to one. Good. What about the next one? Zero. And that one? One. Good. And one more. Good. All right. So then let's think about, well, what about this Z one? So remember Z one sees Z zero inverted as the clock signal. So when you've got this rising edge in Z zero, that's a falling edge for Z one's clock. So when a flip clock sees a falling edge, what does it do? Nothing, right? These are positive edge triggered flip flops, just like we've been using. Right? So when it sees a falling edge, just ignores it. Z one stays the same. What about when Z zero drops here? What happens? It's going to flip Z one, right? Good. What about when it rises? Nothing. Good. Falls? Flip. Okay. And then I'll skip the next one because that's just another rise, which when you invert that, sees another falling edge in Z one's clock. So what about this last one here? Flip again. Right? Good. Okay. And so Z two then, remember, sees Z one inverted as the clock signal. So Z one is flat. So this one also won't change, right? What about on this? Would it follow Z zero? So Z two, the only clock it sees is Z one inverted. So Z one inverted doesn't change here at this dotted line. So it's just a solid, Z one inverted is a solid one. So that clock for this flip-flop does nothing but stay high through this dotted blue line, the first dotted blue line. So Z two doesn't change. What about when Z two goes from low to high? Going to ignore it, right? Because remember it's Z one inverted is the clock input for Z two. So this is a falling edge for the clock of Z two. So it gets ignored. And this one is flat. So ignores that. What about this falling edge in Z one? It's going to flip, right? Because the falling edge in Z one is a rising edge in the complement of Z one. So that'll change Z two. And that'll stay fixed because we don't have any other falling edges in Z one. Yeah, Rahul? The flip-flop's expected to stay at a constant height. Yes. So the observation Rahul made is that basically the period of each of these flip-flops, if you look at it as a period, so this one is twice the clock period, right? So if our clock, for example, were in gigahertz, this would be flipping at half a gigahertz. This would flip at a quarter gigahertz. This would be an eighth and so forth. Okay, so what that means is basically, if you remember summing up exponential powers, if you had an infinite number of these bits, the first one flips half the time, the next one flips a quarter, the next one flips an eighth. If you add all of those up and you say, well, on average, how many of my bits will flip? It'll be two, right? I'll show that in a second, but thank you. Yes, it's counting. But the point there was two bits will flip on average, whereas if you're toggling all of your clocks, then internally those latches will be changing a little bit. The clock will be recognizing that the, I'm sorry, the flip-flops will recognize that the clock input has changed. Some of those transistors will turn on and off. And as a result, you will be burning energy. Here, you're only flipping on average, you're only showing the clock edge to two of your flip-flops on average, right? And so you're using a lot less energy for that reason. So let's look at the counting comment. So I want to make sure you understand how to read these. So I'm going to draw a line down in this clock cycle to the left of the first dotted line. So remember, this is the high bit, right? So this is zero, zero, zero. So that's a zero. What about this one here, this clock cycle? Zero, zero, one, right? So that's one. This clock cycle, zero, one, zero is two. Zero, one, one, three. One, zero, zero, four. One, zero, one, five, and one. I see we're going to have to put counting on the exam. Okay. Yeah. Yeah. Yeah. So it's a ripple counter, but yeah. So you're worried about the speed? Yeah, I mean, the speed is going to be slower. Keep in mind, it's only rippling here through three flip-flops, right? So it takes, the clock speed may be limited by the delay of rippling through three flip-flops. So that may be the longest delay in your system. So that may limit your base clock speed. It wouldn't be what? It depends what you're trying to do. If you're talking about an embedded, so the question is, is this useful for a 32-bit processor? If you have an embedded system at the low power design, so your clock is probably not multiple gigahertz anyway. And so since you're not trying to pressure clock speed high, it doesn't matter that this part is relatively slow. And it also saves you a lot of power. So I think it depends in context of embedded systems, the low power designs go sort of hand-in-hand with slower clocks. You really don't need your intellect breaking system and sampling it, 100 megahertz even, right? I mean, human real world events just don't happen at that speed. So you don't need a processor that runs at that speed and you don't wanna drain your battery, even though it's just your car battery. Okay, so let's then talk a little bit about machine models. So there are two machine models. These are mostly names of historical entrance. So we've said a few times now, the FSM outputs in our class are gonna depend only on the state, right? So FSM outputs could depend on inputs, but in our class will only depend on state. So historically that kind of finite state machine was called the Moore machine. And the more general model in which these outputs could also be a direct Boolean expression of including the input variables was called a Mealy machine, right? So in practice, once you go out in the industry and you start building these things, even in 385, I think, you can always use Mealy machines, right? To the point that most of my alumni in industry come back and tell me, why do you still teach these things? I don't even know what they mean. So the names are really just historical interest. There's reason for this and I'll kind of illustrate why. And I also wanna tell you, well, so if everyone is using this one in industry, why are we teaching you the simpler version? So if a designer wants an output in industry or in practice, let's say, if you want an output to be independent of inputs, well, you simply write equations that don't include the inputs, right? You want them not to include the inputs, we'll write equations that don't include inputs. You're done. So it's not that hard. So why do we use, why use the general model in industry and in practice? Well, inputs carry information, right? There's information in your inputs. And if you use that information, sometimes your finite state machine will be a little smaller, a little faster and so forth. So people say, well, of course, we're gonna just try to use it. So why not? Why don't we use it in our class? So as you'll see in a second, if your outputs depend on your inputs, what that means is your output timing depends on your input timing, right? And so now instead of having this nice model of discrete time, now we've reopened the timing issues, right? And so instead of allowing that to happen without thinking about it too carefully, we simply use the Moore model and say, well, output should not depend directly on inputs. Well, let me give you an example to illustrate the timing issues. So let's say that we wanna recognize the sequence zero one on an input. So the idea is we've got some serial input, every clock cycle, there's a new value on this, sorry, this should say in, not B, and this should say out, not Z. So whenever the input is zero in one cycle and one in the next, we want our output to be equal to one. So this is something we call a zero one pattern recognizer. So here's a design for it. So this is a Mealy machine to solve this problem. So we've got a flip-flop and we've got an AND gate. So we've got the input here, goes into the D, and then we've got the AND gate with a complimented value of the stored bit and the current input. So output is now a direct function of input. So what is the next state equation here? What is S zero plus? Just whatever goes in here, right? So what is that? Just in, not meant to be hard. All right, what's the output equation? So what's out in terms of this one and that one? So in ANDed with S zero prime, right? So if you look at the output equation, in means that the current input value is one and S zero prime means that the last input was zero. And so we said, we're going to do zero one recognizer. If you take these two conditions and AND them together, you've seen a zero one, so the output is high. Otherwise you didn't see a zero one, so the output is low. So remember that we are assuming still on the SO values, these only change at the rising clock edge. Not so easily, not so easily, because then you'd have to factor in all the gate delays and go back to continuous time. Now, if you can do full simulations between the time is continuous and that output and language and dots Time 0 last to last impacts, then we don't need 1, 7, 2, 7, 6. simulations, treating time as a continuous variable and doing transistor simulations and IV curves? Yeah, I mean, you don't need it, but you'd probably want to. You can do it by hand if you want, but it's not that fun. To some extent, I mean, to some extent, that's what we were doing when we were counting gate delays. So I mean, you do the same thing. You count gate delays. That's an estimate. OK, so all right. So let's then draw the state diagram for this thing. So we have two states. We have S0, so just one flip-flop. So we have a 0 and a 1 state. Now, state diagrams are going to look a little different, because outputs, so here you'll notice there's no output bit. And that's because outputs now depend on inputs. So it's not a function of the state anymore. It depends on the input, too. And if the input changes, the output will also change. So we can no longer label our states with output values. So instead, those are going to go in the arcs, in the transition arcs. So now our states will just have state bits. So this is S0 equals 1. This is S0. I'm sorry, S0 equals 0. This is S0 equals 1. And our arcs will be labeled with input in slash output out. Let me add some arcs here. So when I get a 0, I'm going to go into the 0 state. And when I'm going into the 0 state, well, that means my output is always 0. Also, so this is 0 slash 0. So input and output are both 0. When I'm already in the 0 state, well, I stay in the 0 state, right? My D input is still 0. So I've got a self loop from 0 back to 0 labeled 0 slash 0. So what about if my input is 1? If I'm over here in the 0 state and I have an input of 1, well, then my next state is 1. In is 1. And my current output is 1 also here. So that's 1 and 1. So my output should be 1. So the arc here going from 0 to 1 when I have a 1 input will also produce the 1 output. That means I've recognized the 0, 1 combination. All right, then I have a self loop 1, 0. So again, if I see a 1 on the input, my next state is 1. But if I'm already in the 1 state, now this output is low. And so my AND gate produces a 0. So this is the complete state transition diagram for our 0, 1 recognizer as a Mealy machine. So let's take a look at what that does in timing. So remember, out is in ANDed with S0 prime. So first of all, in this diagram, you see a rising clock edge here. That rising clock edge causes S0 to accept input as its current value. So after this first rising clock edge, S0 is 0. Once this input then goes from low to high, so S0 is 0. So this output is high. Once in goes high, this output now produces a 1. So this input rising edge produces a rising edge in output, even though the clock cycle has not changed. We're still within the first clock cycle. Now, that output stays high only until the next rising edge of the clock. As soon as the rising edge of the clock comes, input is high. So S0 will change to 1. That means the output will go low again. So once we get over here, the output will drop back down. So I've drawn this pretty thin. And the thing is that, well, if that rising edge on input came later, it would be even thinner. In fact, it can be arbitrarily thin. Its width depends on the timing of this input rising edge here. And if that arrives at some arbitrary time with respect to our clock, we can't put a lower bound on how thin that output pulse is. So it could be very, very thin, that we only produce this little tiny bit of 1 output. So usually, that doesn't matter so much. So if your inputs come from some flip-flops on the same clock and your changes arrive early enough, it may limit your clock speed. But usually, it doesn't matter. If you're coming from some other flip-flops on a common clock and you're using flip-flops, or rather, you're driving other flip-flops with a common clock with your outputs, it's not going to make much difference, which is why, in practice, people just use this model and don't worry too much about it. The problems will come if you have inputs that are external. So if there's some human user producing inputs or some other system with a completely different clock producing inputs, or if your outputs are used by some other system that's not on the same clock, in that case, you really do have to worry about the relative timing. So when you start putting things together in later classes or in industry or something, you will have to worry about these kind of things at the edges of your designs, and not in the same clock domain, really. And in our class, you don't have to worry about it. So how do we fix this? Should we just go redesign it all with a Moore machine? What should we do? Can you turn this into a Moore machine for me? How about this? Just throw a flip-flop in. So if I just add a flip-flop, now there's a Moore machine. I mean, this is the state bit, so I can affect the output with a state bit. Wait a minute, that's sort of delaying things. In fact, if you think back to our serialized designs, we always delay things. The output of these machines is never reflecting all of the inputs until the next clock cycle. So let's take a look at a timing diagram, but I claim it's no different from the things you've already seen, which is a factor with using Moore machines. So let's take a look at it. So what this is going to do, by adding this flip-flop here, we're actually logically splitting this one state into a 1, 1 state and a 0, 1 state. Now, the 1 and the 0 are different, because they call this one S1. So that's the high bit. So we've got three states now. And now we can put our inputs or outputs into our state. So we've got the 0, 0 state, which is 0 here and 0 here. In that case, remember, output is just S1. So S1 is 0, so output is 0. Here's a 1, 1 state. Output is just the same as S1, so the output is 1. And here's a 0, 1 state. Again, 0 is just equal to that 0 there. So now the outputs are part of the state, just like you saw when we talked about finite state machine transition diagrams on Monday. And that's because there's a Moore machine. So here, sorry, I meant to do this analysis first. Well, n is just going to S0. So if I have a 0 on my n, then S0 plus will be 0, because that just goes straight there. Similarly, n goes over to this AND gate. So if my input is 0, S1 plus will also be 0. So that's why any 0 takes me from any state into 0, 0 state. So I have these three arcs all going into 0, 0. What happens when n equals 1? So then S0 will be 1. I'm sorry, S0 plus will be 1. So if I give a 1 input, my next S0 plus bit will be 1. And let's see, S1 plus will be 1 ANDed with S0 prime. So S1 plus will just be S0 prime. So from here, I'll go to 1, and then S0 is 0, so to 1, 1. So if I see a 1 in the 0, 0 state, I'll go over here. Now, I claim that's actually my recognizer. So to be in this state, I should have seen a 0. And after that 0, I saw a 1. And that'll produce one cycle of my output 1. And that's what I wanted. I wanted to recognize 0, 1. So what if I see another 1? Well, I shouldn't produce another cycle of 1, because that would say, well, 0, 1, 1. So I should stop producing output 1 at that point. So if I get another 1, I'll go from here or here. In both cases, S0 is equal to 1. So S0 prime is equal to 0. And so S1 plus is also equal to 0. So both of these states on a 1 are going to go down to this state and not produce a 1 output. Yeah, Will? What if I see another 1? Yeah, that's a good question. So that's why I didn't put it on the slide. So why didn't I put a 1, 0 state on the slide? I'm sorry, 0, 1 state, 1, 0, 1, 0 state. That should be 1, 0. Yeah. Oh, why didn't I put the 1, 0 state on the slide? It's not reachable. So this is the full state diagram for these states. You can see there's no arrow going to 1, 0. Once you're in these states, you can never go to 1, 0. When you turn on the machine, it may start in 1, 0. But after that first cycle, it'll never be in 1, 0 again. So that's why I didn't bother to draw it here. I thought it would be more confusing to the thinking about what's going on. So let's take a look at the timing diagram. So here we have our new Moore design. We have the same issues. So here at s0, this rising clock edge, input is low. So s0 becomes 0 at this rising clock edge. But now, even though input goes high here, the output doesn't change. That just changes s1 plus. And s1 is ignoring that input right now. So that's a good thing. And s1 is ignoring that input right now. Until the rising clock edge, s1 does nothing with that input. This flip clock does nothing with that input. So when the clock edge comes, then output goes high. So you can see this is slightly delayed. So instead of seeing the output equal to 1 as soon as the input goes to 1, even though we know there's been a 0, 1, we delay that output until the next clock cycle. On the flip side, we then keep output high for an entire clock cycle. The output has no difference. The width of that output pulse does not depend on when the input arrives. It's always full clock cycle. So that's the nice timing aspect. So that gives us discrete time on our outputs. We've got a full clock cycle of 1. But it's a little bit delayed. So that's the price we're paying. So out is high for a full clock cycle. So to summarize, the more machines that we're using in class, the outputs depend only on the state, not on the inputs. The Mealy machine outputs also depend on inputs. In practice, everyone uses Mealy because you can get a smaller design, but you might have these thinner output pulses. To fix it, it's pretty easy. You just throw some more flip-flops down, and then you're done. Any questions on that? So we'll use the more machine throughout in the rest of our designs. So you can always assume that inputs will never directly affect your outputs. Outputs will only be a function of state. Before the output. Yeah, so you can certainly do it that way. You're not going to be able to make that output visible earlier in that kind of design. So you might be able to get away with fewer flip-flops if you rethink your entire design. I mean, not in this one, but in a more complicated design, you might be able to manage to use fewer. Whether that's a worthwhile exercise or not depends how much you need to think about your area. Anything else? All right, so what I want to do in the last 10 minutes or so is give you an outline for how you design a finite state machine. So we really kind of walked through this on Monday with our keyless entry system. But now I want to give you an overview of the process. This is mostly just to give you a way of thinking about what are the steps you need to do to design a finite state machine. Here's a structured methodology, six steps. So develop an abstract model. I'll go through each of these in more detail. So develop an abstract model. Specify your I-O behavior. Complete the specification. Remember that for a digital system, it has to be complete. A digital system just runs on bits. There's never blank bits or anything like that. So we need to make sure we think about what's going to happen when something is outside of the intended behavior. So we'll have to complete our spec. Choose the state representation. That's going to affect our logic. So we'll talk a little bit about how we think about doing that. Calculate logic expressions for next state logic and output logic. And then just implement with flip-flops and gates. So those are our six steps. All right, so the developing an abstract model, this is really just thinking, I want to build something. I know what I want to build in human language. But I have to turn that into a model. I have to have states in my model that can be eventually represented with bits. I need to know what desired behavior I want. So when I talked about the keyless entry, we talked about, well, my car's locked. I walk up to it. I push a button a couple of times. It unlocks a certain number of doors. Then when I leave, I want to push another button to lock it back up. Maybe I get a little scared sometimes, so I want an alarm to sound. So you think about the different things you want your finite state machine to be able to do. You think about the behavior, how you want the inputs to affect that internal state. And you just make some notes about that and list the states. So list the states of the system. Maybe write abstract next state tables to talk about how you move from one state to the next. But pretty abstract process at this point. The next step, then, is to start to formalize by thinking about I-O as bits. So what are the inputs? What are the outputs? Those need to be bits, and you need to think about what representations you're going to use for your finite state machine. Sometimes your finite state machine will be getting inputs from other systems, from other parts of your bigger design. Might also be controlling other parts of your design. So for example, when we talked about logic, combinational logic for an ice cream dispenser, we said, well, we have to produce two bits that control how much ice cream is going to come out. Now, actually, that would have been a timed process, so an FSM would be a little better for that purpose. What we did was just give two bits more or less constantly based on the button. But we have to use whatever spec is there. Usually, we're not in charge of all of the other parts of the system, so we have to agree, well, what bits will our finite state machine produce? What bits will it receive? So we have to interact with other systems for that purpose. Once we've done that, then we can go back and say, well, let's now think about all the corner cases. So we know what we wanted to do, but what about all the things that might happen? So go through and complete the spec. Think about, well, what are all the combinations of inputs, make design decisions. So in the keyless entry example, we said, well, we're going to prioritize the buttons. We could have also done what we did with the ice cream dispenser and say, well, now, only one button at a time. If you push more than one, we'll just ignore it. You can make any design decision, but we're going to prioritize the buttons. And you can make any design decisions you want, but you should make them. And try to complete the spec. Make sure you've handled all of the cases. Any implicit assumptions you made should be written down. We could leave some behavior at this point as don't care, but do that carefully. And then at the end, come back and check that it was, in fact, something that was acceptable. Once you've completed the spec, then it's time to pick a representation. So you can implement with flip-flops. They store bits. Later, maybe you can implement with registers or things like that. Actually, we'll do that next week or so. But for now, think of it as just flip-flops store the bits. There's some ways to choose. So sometimes the output patterns will be unique. In that case, well, the stored bits can also just be the output bits. And you don't need any output logic. You've just simplified half the problem. So that's one way to choose. You can map states to a hypercube such that your transitions are just along edges of the hypercube. That will tend to simplify your logic. But one of the best ways for bigger designs is just group your state into meaning for a human. What that does is it separates your bits into groups such that most of your logic will only depend on one of those groups. And so you can ignore the rest of the variables. So I'll show you several examples of this. But in fact, when you get to the design of the LC3 processor in the book, you'll see that a lot of the design of the LC3 processor was done with this in mind, using human meanings for the different parts of bits that flow into the finite state machine which controls the computer. So step five, this one's relatively easy. It's something you've been doing for several weeks now. So once you've completed your spec, you've got next state tables that tell you your next state in terms of your input and your current state. You've got outputs in terms of your current state. And all you need to do is build combinational logic. So if you have lots of variables, you might want to break up your truth table, use a mux, some of the tricks we've looked at. You can use components as well if you find it helpful. You can build it any way you want. All you need to do is build combinational logic to implement those equations or those sets of those tables, basically. State bits that have human meaning will also help here. Because again, if there's some bits that have, well, so let's think about some kind of ice cream dispenser. Bits that specify flavor don't have anything to do with how long we output the ice cream. We can have a counter that controls how long we output the ice cream. Separate bits that specify which flavor of ice cream. So now, when I decide whether I want to keep outputting ice cream, I don't need to know which flavor. I just need to know if the counter had to reach zero. Whereas when I want to know, well, which flavor should I dispense, I don't need to know how much more time. I just need to take those maybe two or three flavor bits, put them into a decoder, and then one of those lines will tell me, well, yeah, it was strawberry or mango or lychee or something. Each of the decoder lines would give me one output for a different flavor. All right, so the last step then is implementing with flip-flops and logic. So state bits are then going to be stored in flip-flops. And your logic is just built as combinational logic. There's nothing really special. It's just the same thing we've been doing. So do it the same way. This next state logic then feeds into the D inputs of the flip-flops, and the output bits are functions of the flip-flop state, the stored state. So let's go. We actually only got a couple of minutes. So maybe I'll save this one. This is the example. It's already posted. So if you want to read through it now for continuity, you can find it on the web. But I will go through it on Friday first thing, and then I'll stop one minute early. OK, thanks. Yeah. I don't know if it was easy to keep the loop running for a couple of minutes. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK.\",\n",
       " \"Cover for the day and kind of let it sit there before we start. So these are the things we'll cover today We're gonna finish up abstraction layers and digital systems Talk about representations and bits and maybe get through some of energy representation One thing I didn't mention last time But I wanted to make sure you understood just because I tend to talk a lot and talk quickly And I'll tell you stories things like that if it's important, I'll write it down Okay, so if I just tell you something or answer, I mean sometimes you might ask a good question in which case the answer is important But if it's something I'm planning to say and it's important, I'll write it down Okay, if I'm just telling you a story it won't appear and it's okay It's not going to be test material or anything like that It'll just be for your interest or to help you better absorb the material but important stuff will be written down either here in the notes One other thing I wanted to mention There's a rule that I wanted to explain why this rule is there. So tomorrow you have your discussion section I remember those will be working groups So you need to arrive on time because if you show up late then you kind of disrupt your group and delay the start And so people will be unhappy with you. So as a result, you lose a few points. Okay, so that's the rationale It's not my favorite rule either, but but please show up on time All right, so a couple of review slides We started talking on Monday about abstractions about abstraction layers Each one provides some functionality to layers above it and then is implemented on layers below it. And we looked at digital systems as Seven layers we didn't get through this whole diagram But we had gone through Problems and tasks and I pointed out that there was ambiguity, right? Probably no one in the room realized that when I say time flies like an arrow what I meant by that But now, you know, you might have thought it meant something else So there's ambiguity in human language So, how do we implement our problems and tasks in digital systems? Well, there each problem or task will map down to what we call an algorithm and for any problem or task There are many algorithms we can choose from Okay, what is an algorithm? It's a step-by-step process. Okay, so it's a step-by-step process that has three characteristics One is definiteness. So we got to get rid of the ambiguity when we talk about human tasks Like what the number what's the sum of numbers between one and three? There's ambiguity What do I mean by between? Do I mean integers real numbers? What am I what am I trying to ask you? With an algorithm all of those questions have to be answered. We have to be specific and definite in terms of what we mean We also have to have effective computability. Computers are not smart, right? They can only do very simple things add two numbers move move some value from here over to there And we need to express our algorithm in terms of very simple steps. So that's called effective computability And they also need finiteness. So how many of you how many of you know how to count? Good, you know, I've been I was teaching in vietnam a few weeks ago whenever i'd ask them a question like that No one would raise their hand. So i'm glad that all of you know that how many of you finished counting? Really? Okay, I need to I need some people are saying they finished counting. I always thought it was impossible But I guess maybe i'm just not smart enough. I don't know Yeah, so it needs to be finite right the task the algorithm needs to be finite needs to finish in a finite amount of time Maybe you mean you finished because it's you don't really need to do it, but you'll find later in our class. We're going to use counting So each of our algorithms, uh, we can implement on many different computer languages, right so some examples there are actually thousands to choose from so Thousands in the research literature thousands of prototypes Actually probably hundreds of commercially available languages that you could go write an algorithm in Some examples you may have heard of c c++ java python some you may have used javascript We're going to use c in this class in the second class 220 Why do we do that one is there's an easy mapping to low level so by the time you're done with this two sequence course When you write c statements, you'll understand exactly how those are turned into instructions when you're doing the math You write c statements. You'll understand exactly how those are turned into instructions, which is going to be the next layer down in the hierarchy The instructions are what the computer actually executes. Okay, what a computer actually executes so you'll understand that mapping to lower levels C is also a subset of some of these other languages So once you know c you can learn more about those languages, but you can already do everything with those languages Okay, it's just there there's extra syntax and things like java and c++ But the mappings are not as simple Yeah question So c and java They're fairly similar in terms of syntax in terms of what the code looks like Um, but java has java the way you write java Is more object oriented and so you build things around data structures and so The way you approach problems is slightly different and so that's why people like bjarne struestrup who invented c++ believe that that's Fundamentally, you should start with something like his language c++ because it's object oriented whereas c doesn't force you down that paradigm so I think by learning the basic syntax at the end of the day most c++ most java code will have will have to be written In small procedures and those you will know how to write after learning c So so I feel that this is the right way to do it, but not everyone in in the world agrees with me. Yeah I know that there's a assembly simulator You can run off your laptop Yeah, i'm wondering is there any physical chipset Like in class Okay, so the question is, um, is there an actual chip that implements lc3? Uh, so I I don't remember whether anyone actually ever did it in 385 There's no commercial lc3 lc3 is an educational architecture but um Some of our students have been so excited about having fun with lc3 that I think they may have done it in an fpga So and if not, you can do it. You can be the first so Yeah, okay. So Next level down we take our computer languages and those get mapped into computer instructions So there's a layer that we call the instruction set architecture which specifies what are the things that can be done by the computer? Okay, so that's the interface between software and hardware. The software has to be expressed in instructions We can have things like c things like java But at the end of the day, the only thing the computer knows how to do are instructions add two numbers Put the result somewhere put the sum somewhere for example, it would be a typical instruction examples here x86 Most of your laptops most of your desktops have probably have an x86 based processor in them Um arm most of your cell phones if you have a smartphone probably have an arm processor in them Power pc is another embedded processor. Your car may have a power pc in it for example Below that. Oh, and of course, uh computer languages can be implemented by many instructions at architectures We can map computer languages to many isas We can also map isas to many micro architectures So once you have the instructions you can build something to execute those instructions in many ways the way you build it is called the micro architecture, okay, so for example Uh the x86 there are i5 i7 From from intel optron and phenom from amd for arm. You've got cortex a15 cortex a9 Kinetis k so there's there's many different implementations. We call those the micro architecture Micro architecture So, what does our class cover we're going to build from the ground up through the isa level that's where our class will go We're also going to dally briefly, uh in week three at the c level doing a little bit of c introduction So we put that into this class Because our students in the predecessor classes had trouble picking up programming In the space of two-thirds of a semester now when we first taught this class Because there's there's going to be just a little bit on every homework to try to keep keep your Keep you absorbing the C syntax so that you can learn programming more slowly Some people might be tempted to say I'm not having fun with that part. Let me just ignore it That will be at your expense right the expense will not be a few points It means you will have to learn to program more quickly later So please do the little parts of the homework that are you know go into the lab and play around with C Write a couple lines of C that was deliberate so that you can absorb that more slowly and being kind of more level playing field With people in the room who have been programming for a while, okay? So we'll do that briefly in week three Future classes like CS 374 for the copies will teach you algorithms I think it's worthwhile for everyone to take that but as an EE you have to choose among many options For copy you're required to take 374 the algorithms class. So that's kind of where things fit in with this diagram now We've been working on trying to figure out how to get human tasks into digital systems more effectively for something somewhere between 50 and 200 years So in a few years, it's your turn. We be with that But before we start the next section I gotta say, you know, I'm disappointed with Illinois students because MIT students What was it? 1967 did I put it on there? I think it was 1967. They came up with this idea of the Big Screw Award Okay, so what where who gets the Big Screw Award? It's whomever screws over the students the best during one year, right? I'm a little disappointed So one student the one professor there actually taught the class in French in order to win the Big Screw Award But this is Illinois. So here people might actually speak French Not like MIT. No one there. So I don't want to waste my effort. So instead I'm gonna use this code Okay, anyone here know this code? Perfect All right, so the rest of my lectures will be in this code I Hope you're ready So what's a representation? Often we need to represent one kind of information with another inside a computer You'll see we don't have many ways to represent things, but we'll get to that in a few minutes But we need to represent one kind of information with another kind So maybe physical quantities patterns like the drawings I just showed you and so forth So English letters represented by by some drawing right or that's what you just saw Colors represented by variations in radio amplitude some people call that television The mapping from one form to another we call a representation I Think my day here is done. I'm gonna watch a video while you do that. Okay I'll give you a little hint You you Give up no, that's not give up bingo on word one Oh, I hear someone clapping good job. All right All right. So representation when I was a kid, we used to send secret notes in this code So I I'm a little surprised surely you had some code to use to keep the teachers from knowing what you were writing to your friends Right, you don't want to just pass it in normal writing because then they can read it you get in trouble All right, so we have a representation what makes it a useful representation Was it useful when I just showed you the code? I mean, it seems no one got it before I showed you the how I mapped letters into patterns, right? So For it to be useful, especially for computer computers are not smart for it to be useful We need to agree on this mapping the translation Before we try to use it, right? So our purpose here with representations particularly in this class is not obfuscation, right? So we're not trying to hide things what we're trying to do is communicate But we need to express the the form of information that we want to use into some other form in order to do that communication Okay, so we need to have this translation in advance and it needs to be well-defined So that's one property. So what about this one? Here's a here's a here's another representation. So I take the English letters and I represent them with digits Okay, so the letter P Think I have a laser on this not a very good one the letter P. I represent with the number five So what does one four three mean? Okay, so I heard bed let's see yeah, I got that one what else I Hear box Oh really LEDs up there. Oh, I should have picked that one. Darn it. Good call Why does it have to be some acronym you recognize couldn't be VIN? What's wrong with VIN? So computers are dumb. They can't guess. Okay, so it has to be well-defined unambiguous When we use representations with computers every given pattern whatever that pattern is can only represent one thing So over here on the left, you see I've got green represented by four blue represented by one. That's good on the right I've got a representation where green and blue are both represented by four. That's not so good in that case a computer Or digital system is not going to know when you put four Did you mean green or blue just like in the previous slide when we put one four three? Did we mean bed box LED VIN? What did we mean computers are not going to be able to just guess like we could Now some patterns may not represent anything we'll use this in the end of the semester But I just want to make sure you understand what the rules are for representations Okay, so for example here I have a representation where each of these five colors has its own digit But there are five other digits we could use if what we're using our digits to represent the colors and those those digits Just don't mean anything. That's okay. That's a valid representation So those are the two things we need with our representations we need them to be well-defined and unambiguous Inside digital systems inside computers computers are based on electrons The only thing we have to represent anything whether you want to represent ice cream flavors Or you want to represent makes and models of cars or student ID number, whatever. The only thing we have Electrons, that's it. So what can we ask about electrons? Well, we can say okay at this point here How many electrons are there? It's closely related to voltage I think I think people have probably in maybe high school physics seen seen voltage with electrons and things like that so We can look at a particular place and we can ask what's the voltage there? So we'll pick some some ground and that'll be zero volts by definition. We'll pick some higher voltage. We'll call it VDD and I'll push the wrong button. Sorry So at a physical location we can say what's the voltage and if the answer is well, it's close to VDD We'll call that a one and if the answer is well, it's close to ground zero volts. We'll call that a zero So that location thus gives us a binary digit. It's either a zero or one which we call a bit Bit, okay Now each bit is in some particular place So it's pretty easy pretty natural then to use what we do as humans with our with our number system to use positional value or place value So in in decimal we have the ones place. We have the tens place. We have the hundreds place Thousands place so forth and so on In binary, we've got the ones place the twos place fours place eights place sixteens place Powers of two those are powers of ten for decimal. These are powers of two So keep in mind as we go forward the only thing we have inside computers inside digital systems is bits, that's it There's nothing else we're using to represent information. So as humans we talk about abstractions. We talk about using Hexadecimal or something like base 16. That's not what's in the computer Only thing in the computer bits zeros and ones and no blanks. No Multiplication signs nothing else no colors All computer representations are based on bits Okay, so now some questions for you so if I have numbers in the range 0 to 31 integers I'll tell you that so otherwise you'll tell me infinite So if I have the numbers 0 through 31 whole numbers, how many bits do I need to represent one of those numbers? Five I'm hearing so why is that? So we have 30 32 different integers, right 0 through 31 is 32 different integers and Remember representation has to be unambiguous. So for each of those I need at least one bit pattern So that means I need 32 bit patterns If I have five bits that gives me two to the five different bit patterns It's 0 1 1 1 1 1 0 1 1 1 1 1 and so forth and so on right there 32 of them Those 32 I can uniquely assign to the 32 numbers and that would give me a representation And so I need five bits. What about the number 0 to 100? 7 right so again 101 different integers in this case 7 bits gives me 128 patterns 27 of those won't be used but that's okay It's okay to not use patterns. It's not okay to assign one pattern to two numbers. So I have to round up So seven bits for those good All right. So here's a trick question for you. See I'm nice to you. I tell you what I'm gonna ask you a trick question So two books here The collected works of E.E. Cummings my anachronistic dorm mate who you should read because he's a good poet and Our textbook Pat and Patel. Oh great books. You should read both of these How many bits do I need to tell you which of those books you should read tonight Good answer. Wow, you're good at these trick questions. I left my controller over there. I'm so excited All right. So yes, that's right one bit right two books one bit What matters is not what those things are what matters is how many things we want to represent in this case? There are two so we need one bit. That's it Okay So whenever you're thinking about how am I going to represent this set of things? All you need to do is count count how many there are that'll tell you how many bits you need so let's go through and do a few more examples, so Let's see number from 1100 whole number from sorry thousand to eleven hundred Seven right same as before it doesn't matter what the numbers are. There are hundred hundred and one of them. So seven bits good 199 flavors of ice cream. Sorry, I clicked ahead, but I think sounds like people are getting the answers, right? So What about the next one living person? Zero So what is it? Okay, I guess it depends how you interpret that I guess the way I thought of it is someone someone living means a person living on earth, right? I don't think there are too many. Well, there aren't people we know of off of earth So at least I don't know anyone off of earth. So how many people how many living people are there roughly? Seven billion right? So we got to round up a little bit. So seven eight billion people. So 33 bits 33 bits is just over eight billion Okay. What about the last answer if I don't tell you the number I just call it n Okay, I'm hearing good answers so log base 2 of n rounded up so the ceiling notation means the integer that's at least as big as what's inside Okay, so let's go on and talk about what we can use to represent integers So we've been thinking about different numbers we'll need but what if we want to make a representation how should we go about doing it? So we can represent anything with bits. So using zeros and ones we can represent anything integers real numbers human language characters I want to make sure before we go forward to emphasize and I think you'll get tired of hearing me do this by the end of the semester But computers do not understand the bits. Okay from a computer point of view. There are some zeros and ones So when there's some zeros and ones, what do they mean? Well, it depends how we interpret them as people. So you can tell the computer Interpret this as an unsigned number or as a signed integer or as a real number or as a color or an ice cream flavor But unless you do that or someone else another programmer or a hardware designer Someone does that and says these bits mean this kind of thing and build that into the system The computer will have no idea. So if you tell your computer Here's a representation from ice cream flavor to bits and then you tell the computer Please add mango to strawberry. It will simply add the bits and you'll get something strange So it'll it'll just do what you tell it. It's not smart So what number should we represent if we want to represent whole numbers greater than greater equal to zero What should we represent? About we can go around the room that I don't know 150 people some odd each one can pick our favorite number My favorite number is 42. You know why I hope Because I can ask you what is 6 times 7 And I can ask you what is 33 plus 5 I'm hearing some 42s, but I'm hearing some wrong answers So what you need to know is you can need to tell the professor what they want to hear which is 42 because 33 plus 5 in base 6 is 42 All right, so contiguous set of integers maybe instead of just picking our favorite numbers might be better. Maybe we should start with 0 So let's think about what are we trying to do with this stuff, right? Maybe we want our computer to do arithmetic. A lot of people use computers to do arithmetic So what does that mean? Let's say we just pick a range. Let's say okay I'm gonna represent the numbers 100 to 131 with 5 bits. Will someone pick a number from there? Shout it out. Okay, 42 is not in there. Good choice though. I like that. I like that 100 and 120. Okay, good choices. So if I add 100 and 120 we get 220 It's not there So if we add two numbers, it's never there. So maybe we should pick our numbers in such a way that at least sometimes when we add them or when we multiply them the result we get, product, sum, whatever, is also in the range so that we can represent it. Because if I add two numbers from here I can never represent the sum. If I multiply two numbers from this range, it can never represent the sum It's not so useful for arithmetic So maybe we'll pick a contiguous range including zero So at that point I want to say in general, you know, when we have human representations for the same thing Usually those are a pretty good starting point. So as humans when we want to write down a number Well, we use decimal but probably in high school you might have seen base 2, right? So there's base 2 from mathematics. We could use that as a starting point. Remember in base 2 We just write ones and zeros, right? So here are some examples 17 in base 2 is 1 0 0 0 1 42 in base 2 is 1 0 1 0 1 0 and 1,000 is those numbers there In human representations we use these subscripts to tell you which base we're in So when I said 33 plus 5, I really should have said 33 6 plus 5 6 equals 42 6 but here Here are three different numbers. Is this okay? Can we use this in a digital system? Why not? They don't have the same number of bits. So in particular we've got this blank space here, right? There's no blank bit. 0 or 1. That's it. There's no blank. You can't say well, you know This is a this is a small number. So I'll have some blanks. There's no such thing 0 or 1 So that's that's not such a tough problem, right? We'll put the leading zeros So we'll put leading zeros on our numbers That'll fix the number of bits to some n and we'll get this we'll get what's called the n bit unsigned representation So if I take my previous examples and I write them as 8 bit unsigned what I get is what you see here So if I take 17 then instead of just the 1 0 0 0 1 I get three leading zeros and I get 0 0 0 1 0 0 0 1 42 I just need two leading zeros How can I represent a thousand in 8 bit unsigned? I can't right? I needed more bits so I can't do it 8 bit unsigned does not represent 1,000 So then you can ask yourself, okay Well, if I have say 8 bit or 10 bit or whatever what values can I represent, right? So if I want to use this unsigned representation, what's the range of numbers that I can represent? The smallest number of course is going to be all zeros. So that'll be 0 and we kind of chose that already What about the biggest number? Yeah, so I'm hearing some 2 to the n minus 1s It helps me to remember that if I put 1 followed by n zeros Well, that's 2 to the n right by place value. And then if I subtract 1 from that that's n bits This is actually n plus 1 bits here 1 1 1 digit and then n 0 digits And so then I have n bits left all of them ones. That's the biggest value. So as people said 0 up to 2 to the n minus 1 so that's the range of an n bit unsigned representation This is one of the common representations in almost every computer you want. So this is a real computer representation So let's think about As humans sometimes we'll need to go back and forth from decimal into Into unsigned so just think for a minute about how we do that And I want to actually show you the tool if you want to if you want to practice So you can think of the you can calculate a decimal number from a bit pattern Using this idea of a polynomial. So your decimal number I'm sorry, your bit pattern will be some set of bits here. I've drawn six, right? So you can think of those as coefficients on a polynomial. Remember they have place value So the rightmost which I called a zero that has place value 1 a 1 has place value 2 A2 has place value 4 and these are powers of 2 so you can write it out this way You can write it out with the powers of 2 written out a 5 times 32 a 4 times 16 and so forth Or you can just remember they're the powers of 2 So that's how you can translate from bit pattern into decimal So let me go over here And remind you I thought I left my Google open, but I didn't Okay Remind you how to get to this page Sorry, I turned off my wi-fi that was foolish because I knew I wanted to do this All right, so we'll come back to that while it brings my wi-fi up Hopefully it won't Will not make me Log in Okay So what about going the other way? I'll show you the tool in a second. Sorry about that. I turned off my wi-fi not thinking um What about going the other way? So if I give you a a decimal number Um, can you tell me the bit pattern? So if I say hey, I want the 8-bit unsigned bit pattern for the number 193 That seem harder Than going the other way. I mean the other way you need to look at the powers of 2 add them up, right? All right. So it turns out it's actually not that hard. There's a pretty systematic way to do it. So remember that Every bit pattern represents a different number, right? So the the bits we use the a sub i as I called them. Those are unique right So if you write that down You say okay. Well, my my decimal value is equal to this polynomial All of those terms on the right side are even right because the powers of 2 All the way down to 2 to the 1 those are even numbers So if I multiply whatever the coefficient is times that those powers of 2 I get even numbers The only odd number is maybe this one Right if a 0 is 1 this one is odd. It's 1 So if d is odd Then a 0 is 1 If d is even Then a 0 is 0 Then a 0 is 0, right? So I can just look at d and say well, is it even or odd? And if it's if it's even again a 0 0 if it's odd a 0 is 1 so then I can subtract a 0 from both sides Divide it by 2 and use the same reasoning until we run out of digits Okay, so let's do that just for a quick example So if I start with 37 for example, that's odd, right? Okay, so a 0 is 1 Subtract out the 1 divide by 2 On this side subtract out the 1 you can see the a 0 has gone away divide by 2 What's left is this new polynomial and on the left side 18 You can see again. We have 2 to the 0 now attached to the a1 term So all I need to say is well, it's 18 even or odd It's even so a 1 Zero Do the same thing subtract 0 divide by 2 i'll get 9 Subtract the polynomial i'll get the the new polynomial now the 2 to the 0 terms on a2 So that's where I was 9 is odd so a2 is 1 I can roll forward on this Do all the math And if I put them back in order that's what I get right Of course depending on what size how many bits you want in your unsigned representation you may have to add some leading zeros, right? But your bits will come out from from low to high in this process Okay And you don't really need to write down the polynomial, right? That's just for uh, that's just for make sure you understand why it works So for example, if I ask you well, what about 137? How can I get the the unsigned pattern for 137? Well, that's odd, right? So gives me a 1 Subtract 1 divide by 2 I get 68 gives me a 0 it's even so subtract 0 divide by 2 34 Blah blah blah go on go on go on Okay It took me longer to write the slide than it so don't worry if the So now which direction should I read those? Well, remember we get the small bit first So I'm going to read from the bottom to the top, right? So those are my bits so if you want to know what's the unsigned bit pattern for 137 it's 1 0 0 0 1 0 0 1 So not as hard as one might have originally thought The systematic way to do it Let me see if my wi-fi came up because I do want to show you this tool So if you feel like you want to spend time, um Making sure you understood that then Ah, there we go. Okay. So remember Type my name into google that'll give you my home page And then go to the oh This one doesn't uh, shoot. There we go Go to the f16 link there for fall 16 and that will give you this page Now what I want to show you is down here We have these javascript exercises. So the first one is representations and logics So if you click on that you can do this on your mobile, too um You will have a little tool that will let you Do translations and will give you Check answers for you. So here for example, um, we have the number 70 and we're supposed to convert that to the unsigned representation on 8 bits You can see up there. You can go up to 16 bits if you'd like to um You know, you'll want to use maybe a piece of paper for that But uh, if you want different examples, you can click this new example. It'll give you as many examples as you'd like to play with So it'll just keep changing the number. So let's get a nice number So how about 113? That sounds good So then we can go over to uh go over to here So is that even or odd odd good, okay, and then I take 113 minus 1 divided by 2. What does that give me? 156. Okay, so that gives me a zero, right? Okay, and then 56 minus 0 divided by 2 28 And then 28 divided 28 minus 0 divided by 2 14 14 divided by 2 7 so that's a that's odd 7 minus 1 is 6 divided by 2 That's 3. That's odd Uh 3 minus 1 is 2 divided by 2 1 that's odd and then we get 0 so we're done. So it looks like 1110001 and then I'll have to put the leading zeros So, let's see. So go here I think that was it, right? Okay So let me make something wrong just so I can show you this. So if you push enter if you go push this Check answer button it will highlight the bits you got right and and put The bits you got wrong in this darker color to tell you you got that one wrong Okay, so it'll give you feedback instantly on your answer and then you can go and correct it And it will tell you they're all right. And if you push enter again, it'll give you a new problem Okay, so feel free to play with those tools There's actually quite a few choices in terms of different representations different exercises, but that will help you hopefully Make sure that you know how these things work so Let's move forward Okay So that's the unsigned representation so what about negative numbers? As humans we write minus sign, right? So if I want to say minus 24 I'll put a minus sign and I can do that in base 2 just as well as I can in base 10 So I can put a minus sign, but there's no minus in a bit zero or one You might think well That's okay. I can say, you know, there's actually implicitly if I write 24, there's implicitly a plus right? So how many choices of sign do I have? Two right I could have minus I could have plus I could use a bit for that, right? So we just say okay zero means plus one means minus i'll have a special sign bit That's called the n bit signed magnitude representation And that'll give me numbers from this blue part will give me remember 2 to the n minus 1 I'm, sorry. Yeah 2 to the n minus 1 minus 1 And then the sign will let me make that negative or positive So my whole range is from negative 2 to the n minus 1 up to 2 to the n minus 1 So that's sign magnitude That actually was used in some computers a long time ago like the ibm 754 Wait a minute if that's the range If that's the range And I calculate well, how many numbers are there? There's only 2 to the n minus 1 what happened to our other bit pattern? Yeah Um, so this is a bit pattern as opposed to the bit right so we got one leftover bit pattern somehow, yeah Ah positive and negative zero good answer. There are two bit patterns for zero. That's okay, right? Right. Remember we said it's okay. As long as every bit pattern means something unique It doesn't matter that you have multiple bit patterns for the same number again There were computers built using sign magnitude representation. They work just fine It does make the hardware a little more complicated which is why today none of the computers use sign magnitude in practice Okay, but people use this for a while because it's a natural human representation that you can easily turn into bits, right? Right So then that begs the question of well So, how do you know you make up a representation? Is it a good one or not? Right. Now this is a little unfair because some of these questions This question you can't really answer. So i'll give you the answers. Um In particular the second one, right? How do you how do you know? What's easy and fast hardware implementation when this class is supposed to teach you how to design hardware, right? So so that's not a fair question. So i'll just give you the answers this time One is efficiency. So unary right where we make these hash marks That's not efficient because if I want to represent the number a million I have to make a million hash marks Right, and you know if you go take log base two of a million You don't need a million bits to store a million, right? You need far fewer about 20 so So you don't want your representations to be inefficient You want them to store store numbers effectively and basically use all of the patterns or at least most of the patterns most of the bit patterns You do want them to be easy and fast implementation. So we'll come back to that later One thing that I think is fair is well What if I told you I can come up with a representation for signed numbers? Where I can use the same hardware as I do for the unsigned representation, right? So I get it for free Right clearly that's better than another representation where I don't get it for free where I have to have another piece of hardware to do addition say of of signed integers That would be separate from my uh from my unsigned integer adder So here's an unsigned adder. So imagine we've built something, right? It adds two bit patterns of an unsigned representation So if I feed in the number two zero one zero and I feed in the number three zero one one Then out comes one zero one how it works for now. It doesn't doesn't really matter. I build this thing And I ask well Can I actually use this same thing? To add sign to numbers if I pick the right representation the answer is yes Okay So how can we pick the right representation? So first let's think about addition, right what does it mean to do addition on unsigned bit patterns? Well, since we drew the unsigned representation from the base two Representation for humans and math we can use the same sort of arithmetic, right? So if I asked you okay write down some base two numbers and add them up You'd line them up just like you do in decimal and then you add them so you can start though with a single digit addition Right. So if I say okay, what's zero plus zero? Zero good zero plus one One good one plus zero One good one plus one Ten There there are ten kinds of people in the world those who understand binary those who don't Okay, that was a bad joke, but it's an ece joke you have to laugh all right um so Yeah, so this is the whole table, right? I mean you remember in elementary school you had to memorize that big 10 by 10 table It's a lot easier in binary, right? You don't have to memorize a big table. You just have to memorize four things and probably you can rederive them All right, so it's pretty small And then from there, well, you do need to know what's one plus one plus one We'll see why in a little while, right which is one one All right So here's what we do. We line up our numbers and we we just add them up column by column with carries So here's two numbers. The top one is uh 14 and the bottom one is four So we start on the right we say zero plus zero is Zero, you told me right one plus zero One plus one zero carry the one right so put the one on top one plus one plus zero Zero carry the one good and one plus zero plus zero One so we add those up. We get this number at the bottom that represents 18 and lo and behold we got the right answer So we're happy, right? Everyone happy Yeah Ah good point so We only got this answer because we chose our representation in a way that we can use this arithmetic process to get To to do arithmetic and that's absolutely right So because we decided to use the human representation to design our unsigned representation We're allowed to use the human arithmetic process To to add unsigned numbers. Okay, so we'll build hardware that simulates this human arithmetic And that will add unsigned numbers for us, but that's a good point If we had chosen some other representation, we would have to design a more complex piece of hardware likely good point All right now there's a problem though Even if we follow the human rules the unsigned representation we have to pick n bits, right? We have to say what n is It doesn't just grow So sometimes we'll add two numbers and we can't represent the sum So what is that condition? So I claim that that only happens when the most significant bits generate a carry So if a carry comes out of the left side of our addition Then we'll have an overflow and we can't represent the answer If a carry doesn't come out as it didn't in the previous example Then we get the right answer Then we represent our answer with the bits So let me show you an example So let's do this example So on top now we have 14 On the bottom we have 21 So if you remember 5 bit unsigned we can represent up to 31 You add those two numbers together it's bigger than 31 You should expect this not to work Because we're going to have to try to represent 35 So let's take a look So 0 plus 1 on the right is 1 1 plus 0 is 1 1 plus 1 is 1 1 plus 1 is 1 0 carry the 1 1 plus 1 plus 0 0 carry the 1 1 plus 0 plus 1 0 carry the 1 So we have no place to put that 1 So we have overflow Exactly We don't have any place to put that bit If we want to use 5 bits to represent our numbers We're out of luck We can't represent the sum So instead we get 3 So remember for your exams 14 plus 21 is 3 I don't think it will help you You should remember So the carry out tells us that we have an overflow What we added together we can't represent with those 5 bits With that 5 bit unsigned representation So we have a way to decide By looking at the carry out Is the answer right or is it wrong? So it turns out that unsigned arithmetic corresponds to Something we call modular arithmetic in math Or unsigned addition So it's related to the idea of remainders and division And it's defined mathematically as I've shown here So if I take 3 numbers A, B and M Integers A and B are said to be equal mod M If and only if A equals B plus some K Another integer Times the sum of the integers K, another integer Times M So we can also K can be negative or zero So two numbers are certainly equal If they are the same number But A and B will be It's a symmetric relationship Because the two K's would be negative of one another We can also write A equals B mod M That's how we say that this relationship holds So that's the definition of modulus It's like remainder So you can think of it as If they have the same remainder If A and B have the same remainder When you divide them by M Then they're equal mod M You can think of it that way I should have written that down, it's an easy way to remember it So Let's think about what we get When we add two unsigned bit patterns So if we add two unsigned bit patterns If there's no overflow Then this thing we get, we'll call it sum So if there's no overflow Then the sum is just equal to A plus B So without overflow, we get the right answer On the other hand If we get an overflow The problem is that there's that carry out That carry out, it should have gone In the 2 to the N place But we threw it away, so it went from 1 to 0 So if we take what we get The sum, and we subtract off What we should have gotten, A plus B We subtract off 2 to the N Then we get what we actually got For the sum, so if you think back to our example Was it 14 plus 21 Should get 35 Subtract off 2 to the N, 2 to the 5th Is 32, 35 Minus 32 is 3 And that's what we got So in both cases You'll notice that whether we Overflowed or not, the sum Is equal to A plus B mod 2 to the N In the upper case The multiplier is 0, they're actually equal And in the lower case, the modifier Is minus 1 Minus 1 times 2 to the N Added to B I'm sorry, added to A plus B Gives us the sum So they're equal So whatever we use to produce our answer Is going to give us the right answer Mod 2 to the N So we can use that idea To produce a signed representation A representation for signed integers So including negative numbers That uses modular arithmetic If we do that, we can use The same hardware to add Unsigned numbers and to add signed numbers That representation Is going to be called 2's complement So, whoops, wrong button Oh, really, did I finish it all? Okay, well let me open Another one then I didn't think I'd get this far I don't know if that's the right one Okay Push this one Okay Okay, so here's our strategy So we want to use Modular arithmetic to define a representation We're not going to be able to finish this one today But we'll think about it a little bit So we're going to use Modular arithmetic to define a representation For signed integers And by doing so We know that we'll be able to use The same piece of hardware to do addition On unsigned as well as signed integers The computer's not going to know which one It's just going to blindly put bits together And add them, but because the answer Will be correct, mod 2 to the n The answer will be correct regardless Of which way we interpret those bits So, what about the name later? So here's an illustration Of 3-bit unsigned So on the outside Are the decimal numbers And the inside are the bit patterns And I claim that adding a number Corresponds to going clockwise around the circle So for example, if I start with 4 And I want to add 3 Then 4 plus 3 is 7 And the answer Is always correct, mod 8 So if I say, well what's 6 plus 3? Well, 6, 7, 0, 1 So 6 plus 3 is 1 Which is equal to 9, mod 8 So it's always correct Mod 8 For 3-bit unsigned So that's one way to think about it Is the circle You can also realize That this is a quality mod 8 So, if I do addition I go clockwise, if I do subtraction I go counterclockwise And we can also I'm sorry, we can extend our numbers So what I've done is I've added labels Let me go through that again, sorry We can extend our numbers in a clockwise direction So in addition to 0 We can write 8, we can write 9, 10, 11 All of those groups Are equal mod 8 We can also go in the negative direction So by 7 We can write minus 1, by 6 we can write Minus 2, and so forth So we can add labels All of the groups, each group Is all numbers that are equal mod 8 Overflow happens because When we pick a representation We have to pick one of these labels for each bit pattern Remember, we can't have ambiguous Representation So any representation we define We can only pick one meaning So we have to pick one of these outside numbers For unsigned, we pick 0, 1, 2, 3 All the way up to 7 But we don't have to pick those We can pick any set we want And we'll get something that works mod 8 For addition and subtraction So what if we pick a different set of labels The arithmetic doesn't change Let's pick positive and negative And try some addition So here's a set of positive and negative numbers If I take minus 2 and I add 3 I get 1 So before when I picked 6 And I added 3, I got overflow But if instead I pick Negative 3 up through 3 Then I can add 3 to Negative 2 and get the right answer If I could pick differently That gives us 2's complement So if I choose my labels that way By picking An equal number of negative numbers Positive numbers And the 0 as the labels For my representation Then I get 2's complement Now again, because fundamentally The arithmetic we do on that circle Is correct mod 2 to the n Sorry, I'll stop in a second Because it's correct mod 2 to the n That means I can add numbers in 2's complement In unsigned and I'll get the correct answer Using the same piece of hardware So I'll stop there and we'll go over it again on Friday Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Thanks Now I have the highlighted you\",\n",
       " \"It'll go till the end of next week, because we have Monday off for Labor Day. So we'll start talking about the C programming language. I'll tell you why in a few slides. But I'll give you an introduction today, maybe start talking about expressions and operators. We might get through all of that, or we might not. If we don't, we'll pick it up on Wednesday. After that, we're going to start looking at C programs in class. So I have a bunch of those. I've already actually put them up on the links page for you. So let me just flip over there briefly for you so you can see it. So if you go down to the bottom, so this is the one linked off my home page. If you go down to the bottom, PowerPoint likes to take control of my laptop and forbid me from letting you see anything else. So these links way down at the bottom are links to programs. You can also get a handout, which I plan to give you copies next Wednesday once I think we're going to actually start doing them in class. So this is a PDF handout with all the codes printed out. So if you want to look at them, you can use that. If you want to compile them, you can use the links directly to the programs and download them and compile them wherever you'd like. They should be reasonably portable C code. So I meant to ask this question last time. So this will apply before we have another lecture because my office hours, remember, Tuesdays 1 to 3. So historically, I've held them in Zah's. Now that we have the new building, we could have them closer. So here are some photos that I got off the web. So this one by Bill Sanders is the Daily Byte. So that one I think maybe it's OK for me to use. There was one from Pinterest of Zah's. So this is the place I've been going for a long time. It's a cafe down on Wright Street just west. I'm sorry, it's on Green Street just west of Wright. This is the Caribou Coffee at 4th and Springfield. And I used to hold them there until ECE students said, why are you so far away? Why don't you go back to Zah's? Because it used to be near our department building. So I moved back to Zah's. And this is not the lab in the basement of DCL, but it looks a lot like it. It is one of our labs somewhere. So it's cold and lonely. And if you want, you can sentence me there. Somewhat seriously, your labs are due the next day. So if you want me to be in the lab, I can be. So let's just go through them. How many people would prefer Zah's? Oh, but now let me tell you something before you vote. So Zah's and Daily Byte, I never asked Caribou, but I think they'd be OK with it. Certainly these two, I've asked them. And you don't need to feel obliged to eat there, or drink there, or do anything. If you want something, great. But I asked Daily Byte the other day. And I've asked the owner of Zah's, who's told me in the past he doesn't care if people don't buy anything. So don't feel obliged to buy anything if you come. OK, so sorry, Zah's? OK, so maybe 10 to 12. How about Daily Byte? OK, it might be hard to find seating there, but it's looking like 20. OK, how about the basement? OK, it's looking smaller than Daily Byte. OK, and Caribou Coffee? OK, all right, that's the smallest. So I think we're going for Daily Byte. So we'll see how it goes, because quite honestly, I mean, any time you put any flat surface out there, there's an ECE student on it within a matter of seconds. So if we're too crowded, then I think we might have to not do it there. But we'll see how it goes. I will go there next week and try to keep them there. So I'll change it on the wiki. All right, so so far, you learned to represent information with bits. For the last couple of weeks, we've been talking about different ways to represent information, manipulate some of that information, arithmetic, things like that. Now our class as a whole is going to teach you how to design a computer. So we're going to teach you everything you need to know to build a computer, design a computer, a fairly simple one, but a computer. So computer instructions are pretty simple. So once we get there, you'll see computer instructions can do things like add two numbers together, copy some bits from one place on the chip to another. Not many programmers are writing those kind of instructions. So if you look at all the people writing programs, very few of them these days, according to my colleagues, still DSP people, but signal processing people, that is, are writing instructions. But for the most part, not very many people are writing instructions. Most people are writing high-level languages. So since about 1954, when scientists came up with this idea of a formula translator, people have been trying to bridge this semantic gap between human problems, like how to make a peanut butter sandwich, and instruction set architectures. So how do you get a computer to do something that you sort of think you know how to do as a human? And how do you make that an easy process? So as a result, there are now thousands of computer languages. And most of the programs in the world, of course, are written, most of the programs that run, most of the programs written. I think whatever metric you choose, most programs are written in these languages, meaning that the people writing the programs are not using instructions. They're writing in some higher-level language, like C, or like Java, or C++. So before we move on and start talking about how to go from bits and transistors up into gates, we're going to take a week and talk about the language C. So what's the point of that? Why go all the way up there and then come back down? So I mentioned at the start of class, in the predecessor classes, we found that a lot of the students, about 20%, it was going too fast. So students especially felt, and honestly, I measured it many times, and it wasn't quite true, but students really felt that they were at a big disadvantage if they hadn't programmed before. So it took them time to get used to programming, and people would feel like, well, this is not fair. I need to quit and start over because I don't like where I'm going with this grade in this class. And so we had about 20% of the people who would drop out of the class and take it again later. So that was not a very satisfying feeling. So we thought, well, let's switch the material around. So the class you're in now, we're doing mostly digital design, but we wanted to give people more time to absorb programming, more time to absorb just the mechanics of programming languages. So honestly, this part of the class, I think I did mention earlier, is not as integrated into the point system as maybe it should be. So you might notice, well, OK, we've got some stuff on the first midterm. After that, we'll have a homework problem a week using C. And you think, well, one part of one homework problem every week, homework's only worth 15%. You might feel like, I don't need to do that. I can safely skip that part. We discourage you from doing that, because the whole point was to help people that haven't programmed before just kind of absorb this idea slowly. So if you haven't programmed before, please make sure you do all of these, even though it might seem like work per point is not quite as much as it could be, because there's a lot of other material that is also important. So that's why it's in there. So what are we going to do? Start simple. So we'll have you making some small modifications to programs, and we will have you reading examples of programs so that you can see what programs look like, get a feeling for how they're written, before you go and write anything bigger, which you'll do in 220. We'll actually do some programming at the end of this class. So to be clear, in this coming week, today, and the next two lectures, we're not going to teach you how to program. So programming means taking some human task and expressing it in something like assembly code or computer language like C or something like that. And we're not teaching you that yet, later. So what are we teaching you? So right now, we're trying to teach you how to express certain types of tasks, usually things like mathematical formulas, some of the digital design ideas we'll talk about in the lecture, formally enough that you can get a computer to do them. So we won't show you how to teach a computer to make a peanut butter sandwich. I'm not sure they know how to do that yet. But we will teach you how to do things like print a truth table and some other concepts that will become more familiar in the next couple of months. So we'll also teach you how to read and interpret simple formal expressions of computation in C, so to look at simple programs and understand what they're doing, and also how to use a compiler. So we'll connect these skills to the material that we're learning. And also, we think that this will help you learn the skills, because you'll have to learn how to express them formally enough that a computer can do them, which is pretty formal, pretty rigid. Computers are not smart. And also, to just help you realize that computers can help you. So in most of your careers, you're going to be using computers on a daily basis. Most EE careers, as well as almost all computer engineering careers, you're going to be using computers on a daily basis. And you, as an Illinois graduate, will have the skill to get the computer to help you. So you'll know how to say, well, this thing I'm doing is really systematic. Let me get my computer to do it for me. That's what programming is, basically. All right, so computers don't know how to program. You'll start learning that skill in part four of the class. I did want to mention, by the way, in the old class, and ideally in 220, this compiler idea, the idea of translating something in a language like C into instructions is easy enough that, in fact, in our old class, 190, the students wrote most of a compiler as part of that class. Or they could. There was one machine problem one time where they ended up writing a compiler. They had also written an assembler that semester. So they could take a subset of C and go all the way to binary instructions and run those in the simulator for the LC3 processor. So it's easy enough that students could do it in one semester. So they're not very hard things. Of course, that's not to say they were outwriting, say, Visual Studio or something. It was a fairly simple form of a compiler. But we'd like you to learn that and be kind of that level in a year. But that's after 220. OK, so let's talk a little bit about C. So the C programming language was invented by Dennis Ritchie when he was at Bell Labs in 1972 to simplify the task of writing the Unix operating system. So how many of you use Unix? OK, so you know you use Unix. OK, so for those of you who didn't raise your hands, how many of you use Windows? Windows is based on Unix. How many of you use Mac OS? Mac OS is based on Unix. How many of you use, what's the other popular? How many of you have a phone with Android? Yeah, Unix. How about iOS? Unix. Linux? Unix. OK. If you don't have any of those five, maybe you don't use Unix. All of those are based on Unix originally. So they're all derivations of Unix. The original Windows was not, but as of Windows NT, everything after that is based on a variant of Unix originally. All right, so that's how important Unix is. But when he was writing this language, the whole idea was he wanted to write something that would allow him to take advantage of the hardware. So C is a fairly transparent mapping from the C language down to typical ISA. So easy enough, as I said, that 220 students, at least in the former class, could write a compiler for it. So the C compiler converts a C program into instructions. And this was around for 17 years before it was standardized. So there are lots of different variations. It became standard. As you'll see, there's still some machine-dependent parts of the C language. So we'll talk about those as we go through. OK, so here's the program. Let's take a look at a little program. So first thing I want you to notice, up here, we have a definition for a function main. The int means it returns an integer to its complement number. So when your program runs, what it does is it just executes this one little piece of code called main. Now, you can write other things. We're not going to tell you much more than main. All the programs here in 120, you'll just write main. So your program will execute main. And when it's done, it'll terminate by returning a number, an integer. So that's the first thing to notice. The next thing I want you to notice is you can break this main into two parts. The first part are called variable declarations. So when you want to use bits for something, you say, hey, I need to have a set of bits. And it's going to have this type integer. We'll go over this in more detail through the rest of the lecture. But it'll have a type. That's a two's complement number. And I want to name it answer. And I want to set it equal to 42. So you'll have some variable declarations. And then down here, you'll have a sequence of statements. So all the program does, when you start it, and you start it by typing a command like you did in the lab or if you're on a GUI like Windows or Mac OS, you double click something. That starts a program. If you're on Android or iOS, you click something. That starts a program. So whenever you start the program, it runs through main, executes statements in order. And then that's it. It's done. So pretty simple. If you've programmed before, maybe this is really dull. Sorry for that. But if not, maybe it's too fast. I don't know. All right. So what does the program do? Again, it executes these statements in order. So let's take a look at the two here. So the first one is going to send to the monitor this string. We'll talk about how it gets that string later. But it'll basically say the answer is 42, followed by an ASCII newline character such that later printing, if there were any, would occur on a newline. And then that's it. The second statement terminates the program. So there are two statements. You do them in order that they appear in the program. Bigger programs will have many statements. Again, just execute them one at a time until you get to the end. Good programs also have a lot of comments. Even though people try to make computer languages expressive and easy to read and understand, it's very easy to write programs that are not very easy to read and understand. So we strongly encourage you to put lots and lots of comments. So what's a comment in C? It starts with a slash followed by a star, an asterisk. And it ends with a star followed by a slash. Yeah, question? Yes. Yeah, so the question is, does %d stand for decimal? The answer is yes, d stands for decimal. There's also i for integer. I don't think I mentioned that in my slides. We will go through this in much more detail. And it's going to be probably a later lecture. But we will go through printf and scanf in a lot of detail. Good question. OK, any other questions? Yeah. Yeah. There is. And we're trying to minimize the amount of syntax we make you learn in 120. So there are single line comments. They're adopted from C++ and the current C standards. And they're slash slash. So we'll try not to give you those, because we don't want you to have to learn everything all at once. But I think it should be OK to use them. Although sometimes we're asking you to compile with older standards. So I'm not positive about that. I think it's OK, though. So if you know some of these things, it's OK. Sometimes we'll ask you to use a specific set of operators for certain programs, because we want you to learn how to use them. So hopefully it'll be clear in the assignment what you're allowed to do or not do. OK, so comments can span more than one line. So you can write as many lines of comments as you want with this style of comment. The other style that someone just asked about, what's your name? I should start learning more. Sasha. The style Sasha just asked about, if you do learn it, those are single line comments. They end at the end of the line. But the C comments I'm introducing here, these continue until the compiler sees a star followed by a slash. So you can put as many lines as you want. So so far, just looking at that little program, we looked at four different elements of C syntax. So we saw the main function, which is the function that executes when your program starts. We saw the variable declarations, which specify symbolic names and data types. We looked at statements, which tell the computer what to do. And then we looked at comments, which just help us, humans, understand the program. Let's go through those and think about some of the things that tend to confuse people. So first of all, I'm calling main a function, but that doesn't mean it's a function in the mathematical sense. So you learned about mathematical functions probably in junior high or high school. And they said, OK, well, at every point, the function will have one value. And that value, it doesn't change. If you evaluate the function at the same point twice, you get the same answer. That's not necessarily true for a C function. A C function is only a function in the syntactic sense of the C language. So it's a set of variable declarations and a sequence of statements ending in a return statement. Doesn't necessarily mean it's a math function. So for example, we can write a program that returns a random number between 0 and 255. So that program does not return a unique answer. And that program does not even return a reproducible answer. So if I run it twice, I get two different random numbers. So it's not a mathematical function. Both of those properties would be needed to make it a mathematical function. So when we say function, don't try to infer things from math, because these are not math functions. They're also not algorithms. So on the first day, I think we talked about algorithms. Algorithm cannot run forever. They have to be finite. A program can run forever. Very simple, very easy to make a program that just runs forever if it doesn't do anything. That would be a very simple program that's not an algorithm. OK, let's look at variable declarations in a little more detail. So a variable declaration lets you name sets of bits. So we've been talking about sets of bits. We've been using variable names as if they were algebraic variable names. They're going to be different in a programming language. So that's going to be one thing we talk about carefully in a minute. This declaration from the sample program I showed you, int answer equals 42, says, OK, I want the compiler to make space on the chip in memory for a 32-bit 2's complement number. The shorthand for that in C is int. And I want to initialize the bits of those 32 bits to the bit pattern for 42 using 32-bit 2's complement as the data type. And I want to make use of those bits any time one of my statements in my program uses the symbolic name answer. So any time I use the name answer, I want the computer to go get those bits and use them for that number, whatever I've stored. Yeah, Eric. How do you know that it's going to be a 32-bit? So the question is, how do I know it's 32 bits? The answer is that I don't, given that it's a C variable. But the lab machines are, I'll come back to this. I actually have a slide on it. The lab machines int is 32 bits. Some older machines, it might be 16 bits. So unfortunately, C types do depend, as we'll talk about later. Yeah, William. I have a follow-up on that question. Do we assume that in our architecture, it's always been? So the question is, should you make assumptions? In this class, it's probably not going to hurt you if you're making assumptions. There might be cases where you need to know occasionally. But generally, as I'll show you in a later slide, I would recommend that you be specific in your code. Yeah. So variables in C are not algebra variables. So if I tell you in algebra, well, A equals 42, then you would say, well, OK, A is 42. Five minutes from now, A will still be 42. As long as we talk about the same problem, A is 42. A doesn't suddenly become 25. That's not true in C. Every statement in C can change the value of really any number of variables. So your variables just represent sets of bits. Those bits can be changed by the statements. So you should not think of them as something that, like a variable in algebra, continues to hold its value forever. Yeah. Can you declare constant? Can you declare constant variables? Yes, you can. And in that case, if you declare it constant, the compiler will try to keep you from changing the values. Now, in C, the C language allows the programmer to do pretty much whatever they want. So even if it's constant, sometimes the programmer can change it. Obviously, the programmer should not change it. So you can declare constants. And there are other things you can do to try to have something that people can know is not changeable. So yes, you can do that. But in general, most of your variables will not be constants. There are also, just on that topic, there are high-level languages that use what are called immutable types. And in that case, your variables don't change value. They're assigned once, and then they hold their value. The cost of using those languages performance-wise is often a factor of 1,000 to 10,000 times in speed. So if you can afford it, if your program doesn't need to do much, big deal, right? Go use one of those. Maybe it's easier to understand. If you need that 1,000-fold performance, then you need to use something that's closer to the hardware. OK, so variables in C are sets of bits. So they're not algebraic variables. I think that's a source of confusion for people when they first learn how to program, a potential source of confusion. So your bits are always going to be 0s and 1s. But you can't necessarily make other assumptions about them unless you look at the code. So by looking at the code, it might be true that, for example, something is constant. If you look back at the little example program, the variable answer is always 42. None of the statements change answer. So it is, in fact, constant. But you can't make that assumption without looking at what the code does. OK, now the other thing about variables in C, in addition to just being a set of bits, is you tell the compiler what is the data type. So C requires that you say a specific data type for each variable. Not all programming languages require that. But C does. So you need to specify a data type. And then the compiler will use that data type to interpret the statements that use that variable. So for example, if you say that you want to add answer plus some other thing, maybe you want to take two times answer. So you say answer plus answer. What instructions should the compiler generate? Well, it depends on the data type of answer. If answer were unsigned, then it would generate instructions to do an unsigned add. If it were a 2s complement, it would generate instructions to do a 2s complement addition. If it's floating point, it will generate instructions to do floating point addition. How does the compiler know what to do? It looks at the data type that you've assigned by writing the variable declaration with the type int. So given the int, it will choose 2s complement. Now, there are a few data types that are always available in C. They're part of the C language. So they correspond to the representations that we've been talking about for the last couple of weeks. So you've got unsigned representations. You've got 2s complement representations. And you've got IEEE floating point representations. So the same ones you just learned, those are available to you in actually most high level languages, but certainly in C. There are also 8-bit primitive data types that can be used to store ASCII characters. Technically, they're also 2s complement, but you can store ASCII characters in them. Now, here's the question that Eric and Raoul were asking earlier. So unfortunately, C was designed to be fast. And so C is still the case in C that if you use the primitive data types, those are tuned to your system. And so the number of bits in an int depends on your system. The number of bits in a long int depends on your system. So when you write those types, you want to be a little careful about what you assume. You probably should assume the smallest one so that if overflow is going to happen on a different system, you handle it properly. But for example, a long int could be 32-bit 2s complement, or it could be 64. And which one you get depends on what compiler you use, what system you're running on. So to be specific, there's a more modern little library where you use int32, int64, underscore t. The t stands for type. So if you look in the notes, there's a more complete list. But the ones that we'll use in class for our example codes are a small subset. So I just wanted to show you those and tell you what they mean on the lab machines. So we have character, which holds an ASCII character, or it's interpreted also as an 8-bit 2s complement number. We call it character. Write it char. There's int, which on the lab machines are 32-bit 2s complement numbers. I won't use long int. I think on the lab machines, those are 64-bit. But on other machines, they'd be 32 also. There's float, which is the IEEE 754 single precision format that you learned in class. And then there's also double, which is the double precision format, which is 64-bits, which I think I saw the other day as 11-bit of mantissa and 53-bit. I'm sorry, 11-bit of exponent and 53-bit mantissa. But you don't need to know that. It's just a bigger representation, so you have more significant figures of accuracy. Yeah? Is there anything that they've done? There is. And you know what? In fact, I don't think I use it in the examples in the slide, but we do use it in some of the assignments. Basically, if you put the word unsigned in front of character or integer, you will get unsigned instead of 2s complement. Yeah, and that is in the notes. So take a look at the notes, and it'll show you a much more complete set of types, including these types down here, int32, int64, uint for unsigned. Yeah, good question. Anything else? No? Share pointers. Yeah, we will not require pointers in 120. You'll learn those in 220. Yeah, so sorry. Let's skip that for now. Yeah. OK, so the answer is yes. So each variable also has a name, which we call an identifier. So what is an identifier? So it's a set of letters and numbers. You can actually use underscore 2, but I didn't put it in the slide. It starts with a letter, so you can't start with a number. Any length. Some compilers may limit you, so don't make it 100 characters or something like that, but it's supposed to be any length. Use words. You can have any length, and so don't put one-lettered variable names if you can avoid it, because then people will not know what you mean. If you can describe what you want in the variable name, then whenever people use it, they know what it's supposed to represent. Variables are case sensitive, so all four of these could be different variables. You could have four different variables named in this way, and the C compiler would not complain. But your professors may be upset. So please don't do that. It'll make your colleagues looking at your code crazy, too. You can do that because the difference between a couple other systems that are going. Yeah, so the compiler can tell the difference because the ASCII characters are different, and the rule in C is that they are case sensitive identifiers. So that means if there's any difference in case, those are separate identifiers. Yes? What are those now? That's an interesting question. You mean as opposed to Unicode? I am not sure what the latest C standard says. I'll try to look that up. That's a good question. Certainly for many years, they were only ASCII, but if you want to write international identifiers, I'm not sure if you're allowed to. I'm not sure. Another question? Only by name. So you can't use reserved keywords. So you can't name a variable int. I think if that's true. There's certain contextual identifiers that can help. But for the most part, you shouldn't name variables keywords. But other than that, variables are identified just by the symbolic name you choose for them. Yeah? Will? You have to start a variable name. Yeah, I think I said that. Start with a letter. Oh. Yeah, sorry. OK. So what do these look like? So let's put these together. Variable declaration is a data type. So when I put these brackets, you would replace that thing with an instance of a particular data type, and you wouldn't write the brackets. So you could put int or char or float or double. Then you put your identifier. Then you can assign an initial value to the variable by saying equals some value. So for example, here are a few examples down here. I can have an integer and choose complement. That'll have data type int, and I'll assign the value 42, for example. I can have an unsigned integer. So this kind of answers your question, even though I guess I didn't put that in my list. But an unsigned integer, so this up here is a two's complement representation. This one down here is an unsigned representation. Here I've assigned the value of 100 to that. I can have a floating point number, name it IEEE 754, so the underscore is in there is cool, and assign it the value of Avogadro's number, because I can do that with a float. Yeah. AUDIENCE MEMBER 2 If you have the unsigned, like, for one data type? Yes, so together, these two on the lab machines would be a 32-bit unsigned. Yeah, good question. Yeah. AUDIENCE MEMBER 2 What's the lower case? Does this need to be capital? I think it can also be lower case, yeah. Don't need to be capital. Yeah. Special characters. You mean the underscore? No, you can use underscore. That's the only one, yeah. Except maybe the new standards might allow Unicode, in which case I'll look it up. We'll find out. Yeah. Good question. Yeah. Yes. AUDIENCE MEMBER 3 No. Not that you can use that space. You cannot use space in identifiers. No. Yeah, you certainly cannot use space. Anything else? Yeah, other than letters, numbers, and underscores, at least the older standards will not allow anything. Yeah. No, not in C. Yeah, there are a lot of programming languages where dollar sign means evaluate or variable, and so evaluate variable. But C, no, you can't use it as part of an identifier. Yeah. AUDIENCE MEMBER 4 How about in a number? Unfortunately, no. So even if you want to type in billions or something, usually when we type such numbers, it would be either a real number in scientific notation, or it would be something that maybe we could put in hex. It's kind of rare that you would type or something with a lot of zeros. I haven't seen too many numbers like 3,879,000,000 where putting commas would be nice, but it's not allowed. Yeah, so the question is, can you add different types together? The answer is yes, but that's a little bit beyond the scope of what I want to talk about in the lectures. There's a starred section in the notes that talks about that. So take a look at that, and if you have more questions about it, come talk to me in office hours. It's a good question, but we're trying to contain the things everyone has to think about here. So the initialization is actually optional. So the following is acceptable, just data type identifier, for example, int i. So if I write that code, what's an i? i is a set of bits. What's there? It's just bits, right? Good. I'll ask you lots of questions where the answer is bits. They may be zero bits, but don't count on it. And unfortunately, if you just write a little program and you look at those bits, often they will be zero bits. But again, don't count on it. It's because of the way the operating systems work. Yeah? Will a compiler complain if you do? Sometimes. So the question is, will a compiler complain if you declare something without initializing it to a specific bit pattern and then try to make use of that unknown bit pattern? And unfortunately, the answer is sometimes. So maybe even most of the time, but not always. So if the compiler can figure it out and you tell the compiler, as you always should, that if the compiler thinks there's anything wrong it should tell you, then it will tell you. But there are some corner cases where compilers won't figure it out. And the default with a lot of compilers is that they don't warn you about everything anyway. So as a programmer, you should just always turn on all warnings. And hopefully, the compiler will help you whenever it can. All right, so statements tell the computer what to do. So in C, a statement specifies a complete operation. So it tells the computer to do something. And the function main, again, is a sequence of statements. So we have a bunch of different metaphors for executing, running, starting the program. So I might use those words interchangeably. When that happens, your computer executes the statements in main in the order that they appear. So that's the intro. Any more questions before we start talking? AUDIENCE 1 One on the bit still looking. Allocate. Well, I guess knowledge bits is regularly in, but. Nope. No pointers. Yeah. AUDIENCE 2 Can you put more than one variable in a single line? Yeah, so there is a way to do it. And I deliberately didn't show you because I want you to put a comment on every variable. So the question is, can you declare more than one variable in a single line? And you might see it. So you can. You separate them with commas. The other reason I don't tell you is because in C, when you learn new types like pointers, the declaration is a little bit strange. And so until you get used to it, it's kind of error prone. Whereas if you declare only one variable per line, you kind of make it easier to understand. So I'm trying to encourage you not to do that. But you can do that, and it'll be fine. Yes. AUDIENCE 3 Does it? It doesn't give you some one? Yeah, so the question is, does the compiler read languages line by line? To some extent, yes. I mean, there has to be a way to get through the program. But C does not have the constraints of some other programming languages where, for example, a function. We're not going to talk about functions. But there are languages where you can't make use of things that weren't above that thing you're trying to use in the file. That's not true in C. Variable declarations still do have to be above. But I would like to have you put all of those at the top of your blocks of code, even though now modern standards allow you to intersperse them. Anything else before we go on? Yeah. AUDIENCE 4 How would null be represented by bits? That's kind of beyond, did I say null? Null is a pointer value. It's all zeros. It's the all zero bits. And there's a reason for that, historically. But it's beyond the scope of the class. So ask me after class. I'll tell you. Yeah. AUDIENCE 5 Is it a semicolon? Yeah, we'll look at statements in more detail later. But essentially, after every statement, every simple statement, you would put a semicolon. So a simple statement is a type of statement. AUDIENCE 5 Is it a null? Oh, absolutely. If you leave out semicolons, the compiler will complain. Yeah. It's not optional. The compiler will not let you compile your code. Or worse, it will let you compile your code. And it'll have a completely different meaning. So you want to be careful. All right, so let's talk now, before we get into statements again and look through those in more detail, I want to spend some time talking about another syntax concept in C, which is the expression. So an expression is a calculation consisting of variables and operators. So let me give you some examples. Let's say A plus 42. A is a variable. 42 is a number. I add them together. That's an expression. I can say A divided by B. I can say deposits minus withdrawals. So all of these are fine, good expressions. The C language has a lot of operators. So we're going to focus on four types, four types of operators that you need to learn for 120. And then there's another type called logical operators that we'll introduce. But you're not required to learn them. We're not going to introduce the subtleties of logical operators. We'll leave those for 220. So we're going to look at arithmetic operators, bitwise Boolean operators, like we talked about when we introduced Boolean expressions, relational and comparison operators, and then the assignment operator. The first arithmetic, we've got addition, which is a plus, subtraction minus. Multiplication is an asterisk. So you need to use an asterisk for multiplication. Divide is a slash. Modulus, which only works for integers, is a percent sign. There are lots of other functions in the C library. So lots of other mathematical functions, sine, cosine, et cetera, square root. Those we're going to leave for 220. So you shouldn't have to use those here. If we have one occasionally, we will tell you how to use it, and what it is, and what it means, and things like that. But for the most part, you won't need to use any of those. So let's take a look at this. So let's say I declare two variables, a and b, both ints. And I set a to 120. And I set b to 42. Now, when I say evaluates to, the C compiler is going to write a set of instructions that takes the variables a and b and adds them together. So evaluates to means, well, what's the answer, what's the value of this expression after it's been computed? So what's a plus b? Yeah, 162. Good. a minus b? 78. Good. a times b? A big number. Very good. a mod b? 36. Good. I think that's right. So we've got a mod b. So there's two b's make 84. And I've got 36 left, right? OK. What about a divided by b? Oh, I'm hearing lots of twos. OK. So a lot of people have played with this stuff before. Why two? Why not 2.36 over 42 is 7 something, right? Yeah, it's an int, right? So it's going to return us an int. So some of the pitfalls of division, actually, let me start at the bottom. Dividing by an int, dividing one int by another returns an integer. So if you take 120 divided by 42, you get 2. If you take 100 divided by 8, you get some integer. It's going to be either 12 or 13. You multiply 12 or 13 by 8, you don't get 100. So when you do integer arithmetic, don't expect basic mathematical equivalences like this to work, because this one is going to give you 12 or 13. It's going to round. If you divide by 0, your program will crash. If you do an integer divide by 0, your program will crash. If you do that with floating point, you'll get an infinity. Yeah? Yeah. AUDIENCE MEMBER 2 I guess by adding a long before. By adding a what before? By adding a long, and then it's like. A long? Adding a long to the long before, it's going to get. So can you change the type? And yes, so there are type conversions. And again, that's in the starred part of the note. So take a look at that if you want to know how to do it. But we won't do it in this class. So you don't need to understand it yet. For 220, you'll need to understand it. The other thing is there are no checks for overflow in C. So if you tell the C compiler, hey, I want to set my unsigned int to 0 minus 1, it will do that for you. It's a very big number. 0 minus 1 unsigned will overflow. So you'll get for 32 bits, 4 billion whatever minus 1. 2 to the 32 minus 1. And if you did a long unsigned long int, you'd get a 2 to the 64 minus 1. Unfortunately, C behavior with arithmetic also sometimes depends on the processor. So in particular, the rounding direction for integers depends on the processor. Whatever the processor says, most modern processors round towards 0. So it's not really as bad as it sounds, because you'll be hard pressed to find a processor that doesn't round towards 0 these days. So what does round towards 0 mean? If you take 11, divide it by 3, you should get, what, 3 and 2 thirds? Instead, you get 3. So it goes downwards towards 0. If you take negative 11 and divide it by 3, you should get negative 3 and 2 thirds. It doesn't go downwards. It goes towards 0, so negative 3. So it's not rounding off. And in both of those cases, if you round it off, you would get 4 and negative 4. Round towards the closest integer. Yeah? AUDIENCE 2. Is it a finite number? Yes. AUDIENCE 2. Is it a floating point number? So floating point will produce a floating point number. And so there is rounding, because it's a finite mantissa. And so sometimes, actually in your homework, you'll need to think about that. But you will need to round. IEEE floating point has four rounding modes, down, up, towards 0, and what is the last one? Oh, round to nearest. So those are the four modes. So the default mode is round to nearest. But you can change the mode. No, it will not. It will return a floating point number that's the most accurate representation it can, modular rounding, at the 2 to the minus 23rd level for the exponent. Yeah? AUDIENCE 3. What is the percent sign? The percent sign is modulus. So it's similar to remainder, but not quite the same. I mean, when you learned remainder, it was probably elementary school. And so you probably didn't. I think we teach it in the US, at least, before you learn negative numbers. And so no one talked about, well, what is remainder when you work with negative numbers in division? But modulus is defined. But it's not quite defined the way it is mathematically. So this is not mathematical modulus. So it's defined in this way in C. So it's defined such that this expression is equal to A. So in particular, if, for example, you said, well, what's negative 11 mod 3? Then negative 11 divided by 3 gives you minus 3. Multiply that by 3, you get minus 9. So to get negative 11 back, the mod has to be minus 2. So this expression defines modulus in C. So in practice, what this means is don't use negative modulus. You'll have plenty of codes where, for building things like cyclic buffers, you want to use modulus. But if you ever need to go in the negative direction, then you want to add e plus 1 if your number is negative. Because this negative modulus will screw your code up. But this is how it's defined. So if you want to work with the definition, that's the definition. And again, it's machine dependent, right? Because the divide part depends on the machine, depends on the processor. So that's another aspect of modulus is it's not even well-defined in the language. So that was it for arithmetic, those five operators. I don't know if we'll finish these, but let me introduce the bitwise operators. So we have six of them. And four of them you know, or at least you know the Boolean operators. So AND, OR, NOT, and XOR. And then we have left shift and right shift. So in some languages, some of you may know languages where the caret sign means exponentiation, not in C. It means bitwise XOR. So if you write it, the compiler will not complain. It will also not exponentiate. It will do a bitwise XOR. So they treat numbers as bits. So here I've defined a couple of hex values. You'll notice that in C, when we write hex numbers, we put a 0 in front of the X. So this is hex notation for a 32-bit value. These are the two 32-bit values. Otherwise, they're the same numbers. So if I take A bitwise ANDed with B, then what should that give me? OK. This is why I said hex is maybe not as easy with bitwise. So you have to translate in your head to bits. Let me just tell you. So the 7 is 0111. The 2 is 0010. So if you AND those together, you just get the 2 back. So you get the 2. And then the 8 is 1000. And the A is 1010. So you just get the 8 back with bitwise AND. And you can maybe write these out in bits. It'll be a little easier. If you OR them together, you get this pattern. The hex will be much easier to calculate. So usually, if we are doing bitwise operators, it's because we care about bits. And so thinking of it in hexes is maybe the natural thing. If you get this one, maybe we can figure out easily. So not A bitwise. Well, remember, how do we negate in 2's complement? Not A plus 1, right? So if I just take not A, it should be negative A minus 1, right? So negative 121. Notice that the bit pattern, it is a bitwise NOT on all of the bits. So all the high bits became 1s, which in hex are Fs. And then if I XOR them together, I get 52. So let me stop there. And then on Wednesday, we will cover shifts. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\",\n",
       " \"I'm covering for Professor Lumetta today. I don't know where he is, but I think he's not in the country. So some of you may know me. I teach the 1 PM lecture of this class. So you might have seen me in office hours. You might know me as an academic advisor as well. So anyway, I'll try to do my best to cover what he wanted me to cover. And so these are the topics for today. So as I understand it, you did a little bit on KMAPs last time. But we'll do a few more examples and then move to the connection between the SOPs and POS to two-level logic. We'll do a kind of digression on optimization of different circuits and what that actually means. And I don't know how far we'll get into this stuff. But before we begin, let me see. I'm a little bit disoriented with these slides. Let's see. Before we begin or after we begin? OK, yes. Reminders about the exam next week. So the exam's 7 to 8.30 PM, unless you're taking the conflict. Unless you're taking the conflict, the specific time and the location of your exam have been uploaded into Compass. I believe it's where you check your grades. You'll be able to check the location and time of your exam. We'll be doing a review in class. Professor Lumetta will be back here on Monday doing a review in this class for the exam. Each of the instructors will do a review. But this weekend, on Saturday, 2 to 4 PM, there is an Eta Kappa Nu review, which is done by students as a service to other students. As such, we in the class do not endorse it, because it's whatever they decide to present. And if they are wrong, it's on them. But on Sunday, our undergraduate assistants in this class, hired by us, will also be doing a review session 2 to 4 PM, again, in this building. So all the details about that are posted on the course web page under exams. And actually, Professor Lumetta did want me to point this page out to you again. So all the details for the review sessions, the exam time itself, the contents of the exam, and practice problems, as well as links to old exams, some of which have solutions. OK. There's also the page above it, exams. So he told me that someone asked the question, what can you bring into the exam? Is that right? So it's all specified on this page. But in particular, it's a closed book exam. No calculators or other electronic devices. What you can bring is one letter-sized sheet of paper with handwritten notes on both sides. And so there are a number of things that you might want to jot down on those two sides that you can bring to the exam. Yes, Rahul. Has there been a requirement for the writing? Well, you can not bring a piece of paper as well. And you will not be forced to have a piece of paper. So yes. OK. Any other questions, though, about the logistics of the exam? Yes. No calculators? Yeah, no calculators on this test. So for the homework, there were definitely some questions that required a calculator. You can expect that similar questions on the exam will be set up so that you don't need to raise 2 to the 10th power is fine. 2 to the 16th power or something like that. Yes. The exam will be printed with one-sided. So we encourage you to use the back sides of exams. And as general advice, if you have scratch work, you can note it down in the sections where it is so that the grader can find it. Otherwise, it's lost and we cannot grade it. There should be enough space on that to do your work. All right, yes. The ASCII table will be provided to you if necessary. So you don't need to. That's one thing you don't need to put on your age sheet. That would be a waste of space and a waste of time to handwrite it. Thank you for asking that. Yes. How many questions? Can I answer that question? OK, I can ask that question. There are six problems on the test. And you have 1 and 1 half hours. Maybe the last question. Yes. How about the hexadecimal values? Hexadecimal values are pretty easy to remember. But that's certainly a good thing to put on your age sheet, because it's also something easy to get wrong. All right, very last question. OK, so back on that ASCII table, how many questions? I think we gave both, both characters. And the ASCII table includes both characters and hexadecimal. Yeah, yeah, it does. You will be given a table that you can use in the way that a question would want you to use it. So that sort of thing is pointless to memorize and also pointless to write down on an age sheet. We'll provide it to you. OK, so good, good. I hope that clarifies what you need to prepare for the exam. OK, so back to slides. Let's see what's up next. OK, so you did cover KMAPs. At least, you had an introduction to KMAPs. And the goal of a KMAP, a KMAP is just a tool. KanoMap is just a tool to basically minimize Boolean functions. A Boolean function is just another way of expressing a logic circuit made of AND, OR, and NOT gates. And so the way this tool works is that given a KMAP, you're trying to look at the ones in the grid and group them together in a minimal number of loops. And each loop should be as big as it possibly can so that you cover all ones. And the result will be an optimal sum of products expression according to, in some sense, the area that such a circuit would occupy. So let's do a few examples. That's what Professor Lumetta wanted me to do. He actually pointed me towards his tool. But the tool is good because it generates random examples. But I also don't like making mistakes. So I've prepared examples that I know exactly how to do ahead of time so that I won't be caught by surprise. And these are actually the examples that I present in my section. So I just pulled up an example here. So let me just make sure. And I guess I'm going to have you propose how to do this. Not Rahul, because he was at my lecture. And he saw this exact example. Just to make sure that you are where I think you are. So here is a four variable function. And this is the K-map for it. So I hope you understand that a K-map is no different from a truth table. A four variable truth table has 16 rows. And those rows are represented as 16 cells here. So remember, I'm trying to cover all the ones using loops of allowable size, loops that have dimension of powers of two. I cover all the ones with as large loops as possible, using as few loops as possible. So what's a loop I could draw? Could someone describe that? Yes. AUDIENCE 1 Right. These middle two columns. So that is an allowable loop, because it's 4 by 2. So that 4 by 2 dimension means that it can be represented by a product term, a product of literals term. And so any loop that covers ones is called an implicant. And this one is a prime implicant, because it doesn't get any bigger than this. If you make it any bigger, you start to include zeros. So for example, this little guy here, these two together, that's also an implicant. But it's not a prime implicant, because it can grow to this big one. It can be totally covered by the bigger one. So is there another implicant that I should identify here, right up here in front? AUDIENCE 2 That top left corner you have there. ARIJIT SINGH Right. The two ones in the top left corner. All right. So that's definitely an implicant, because it covers one. But is it a prime implicant? No, this one can grow. You can grow it to the square, which is an allowable size. So you can grow it to the square. Can we grow the square any bigger? So it's not right to grow the square to a 2 by 3 rectangle. That's not an allowable size. Yes, question? Right, OK. So this is great. So these are my notes. So this is new stuff for you guys. I mean, you probably saw this in a different form with hypercubes and stuff. But basically, so I did this example in my section where if you start out with the function, you guys probably already know how to fill out a truth table. Row by row, you figure out where the 0s and 1s goes. So to fill out the corresponding k-map is no different from filling out a truth table. But there are shortcuts with the k-map. So if we're looking at, say, this term, imagine this was empty. In my class, this would have started out empty, an empty grid. Not b, not d. This term turns to 1 if b is 0 and d is 0. That's exactly when this turns to 1. So b is 0 corresponds to the two, to the, so this is a, b over here. This is a equals 0, b equals 0, a equals 0, b equals 1, and so on. So this row has b equals 0. And this row has b equals 0. So that's the b equals 0 case. But I also need d to be 0. And it turns out d equals 0 is this column corresponding to that 0 and this column corresponding to that 0. So the overlap of those two is this 2 by 2 here, the four corners, which is if you wrap it around, it's a 2 by 2 square. So in this four variable grid, if you have a product term of two elements, you're going to get four 1's. That corresponds to four 1's, either in a 2 by 2 grid or a 1 by 4, like an entire row or an entire column, four by 1. And so for similar reasons, every kind of product term that you get is going to end up with a shape that has, that's one of these sizes. So no 3's, basically, when you, so. So that's why, when we're going the other way, we have to make sure we draw loops that correspond to these sizes so that we get terms like this. And that example should show you that wrapping around works too. And so why do we want, we want the biggest ones, we want the biggest loops that we can make, because the biggest loops use the fewest literals. You can see this big loop here is just one literal, whereas the small loop, which is just two 1's, uses the most literals in the end. And you want the fewest loops altogether, because each loop corresponds to a term. So you want to minimize the number of terms and the number of literals within each term to make a simplified expression. OK, so back to the example. So yeah, what remains now is to, so both of these are prime implicants, right, because they cannot grow any bigger. We also check whether they're essential. I don't know if this was brought up, but an essential prime implicant is a prime implicant that has certain cells in it, certain 1's in it, that are not covered by anything else, right? So this one is essential, because it has these two 1's, which are not covered by the other prime implicant, right? So this one is needed, and this one is needed too, because this covers a bunch of 1's as well. So now it's a matter of me writing down the terms that go with this. So how about we start with the biggest one? Can anyone tell me what term I should write down that corresponds to making all these 8 1's? OK, a few people called it out. It's z, right? So if you're not catching on, let me tell you why, right? So the 1's in here, they don't depend on w and x, because you can see w and x can take all different values in here. And it doesn't depend on y, because y is 0 or 1. But what it does depend on is z. z equals 1 for this entire column and this entire column, right? So this is represented by z. Now, this one is a different shape. It's 2 by 2. And if we look at this, these ones belong to the w being 0, right, these two rows, intersected with the y's being 0, so these two columns. Gives you those four 1's over there. So let me come back to your question. So I'm going to say, or w equals 0 is not w and not y. So not w, not y gives you this square. And now, if you all them together, you get all these 1's, right? Because either this is true, either z is true, giving you all these 1's, or not w, not y is true, giving you these 1's. So you still have your question? No, no. So in strange situations, I have an example about that one, and I'll show you that. So I had this example, the same grid on the left and the right. And it turns out that there are several prime implicants here, right? So this cannot grow any bigger. This cannot grow any bigger. But nor can this one, or this one, or this one. So those are the five prime implicants that can be drawn in this pattern. But to identify the essential ones, only this one and this one are essential, because this one has these three 1's uncovered by anything else. This guy has this one uncovered by anything else. The others are not essential, because the green one in the middle is covered by, you know, the one on the left in the green one is covered by that one. The one on the right is covered by that one, right? So if I only take the essential prime implicants, I just get this and this, I still have some 1's uncovered. So I have to look at my other prime implicants and try to cover those two 1's as efficiently as possible. As you can see, I would just use the green one. Yes, question? Yeah, I don't. Yes, I mean, yes, you are looking for. No, no, that's also wrong. Kind of hard to put into words. And to even think about implicants, essential implicants, prime implicants, blah, blah, blah, it's a little bit overkill. If you do enough examples, you'll get a hunch. I think my next example, so maybe I'll make this my last example, shows you that overlap is actually good sometimes. You want overlap sometimes. And other times, overlap is wasteful. So that's probably not a good way to think about it. All right, so here's another example. Again, four variables. Can anyone tell me one of the prime implicants? All right, I think you answered the question before, but I'll let you do it again. OK, good. Four corners is a favorite, right? Because it's one that favorite, and when I say favorite, when exam questions are made, it's a favorite. So four corners is a two by two pattern. And this one cannot grow any bigger. And then another, I mean, clearly, these ones need to be dealt with somehow. How should I group those ones together? Yes. The entire row. So let me come back to this overlap question, right? I could just do these two, no overlaps. But this can grow bigger. And if I grow it bigger, it does overlap with the other one. But bigger is better in this case, because when you have a larger loop, you express it with fewer literals in the and expression, right? So we're about to write down what this is, right? So what is, this is true if w equals 0 and x equals 0, right? So actually, that's not w, not x to make these row of ones. If I just wanted to specify this to these two, I'd say not w, not x, z, right? Because z equals 1. But I don't need that z there. So in this case, I want to make it bigger. So looking at overlaps is not really helpful. So that gives me that row. And then the four corners, if I look in terms of rows, that's when x equals 0, right? So not x. But I also have to intersect that with the first row and the first, and the last, sorry, first column and last column. So z equals 0, not z. So there's a lot more to say about k-maps. But I think that will come later. We'll talk about don't cares. Actually, I think that's on the schedule for Wednesday after the exam. So you'll get a lot more practice with k-maps. So hopefully, you understood what I'm talking about today. You'll get much more practice with this. So don't stress out too much. Yes? Could that be a not w or not a w? There's definitely other ways to write this. So let me emphasize that this is the minimal SOP expression. There are POS expressions. There's a way of doing minimal POS expressions by looping the zeros. I'm not sure if that was covered in this class. I haven't covered it in my class yet. So by looping the zeros, you can think about things in exactly the dual way, like a complementary way, and get a minimal POS. And sometimes, a minimal POS will be more efficient than the minimal SOP. And sometimes, there'll be a minimal way, which is neither POS or SOP. And k-maps are not going to help you find that. So yeah, there's a lot more subtlety to this than even what I'm showing you. But this is a handy tool to get a minimal SOP or a minimal POS. OK, yeah, I don't want to do the next example. Oh, I should point out that our notation is slightly different. So I noticed this with Professor Lumetta. So what I would write here in this example is, what would I write? I'll write BD here and AC up here. But Professor Lumetta does, like he indicates that the B is 1 in these two rows. So that's why I know the B comes first. And the D is 1 in these two rows. So the D comes second, and likewise for the C and the A. So just a difference of notation. The industry doesn't do k-maps. K-maps are a teaching tool. And they're really fun to make questions about. They're really fun to solve, too. But k-maps don't really extend well to more than four variables. And if you were designing something in industry with four variables, you probably need to find another job. That's not interesting. What are the programs that you can do? There are. So the way to do it in industry is to use software. And you'll learn a lot about that in EC 385. Like, you'll be designing more complex stuff. I don't actually know a lot about what it's. They don't do it optimally. They use heuristics, because it's a really hard optimization problem. So they do good enough instead of perfect. And they may use the hypercube as some kind of data structure underlying all of that. OK, so where are we? Did we cover this? We covered this. No? Where are we? Oh, OK. So SOPs, so k-maps, what I just showed you, gets you a minimal form, which is an optimal SOP expression where we care about the area. We're trying to minimize the area. But minimizing the area of the circuit is not the only possible metric. We could also minimize for the speed of the circuit. So the speed of the circuit, let me see if that comes next. So apparently, you've already learned that the speed of a circuit has to do with the number of gates between any of the inputs and the outputs, so the maximum number of gates along the chain from input to output is a rough approximation for the delay. And actually, we're going to assume that the complement operation does not require a delay. There's a reason for that, which you'll see in a few weeks. But we usually get, if we have x, we usually have not x somewhere else in the circuit. So we don't need to create it with a gate. It's already there somewhere. So if you only have only allowed one gate delay, what functions can you implement? I guess this is a question for you. So you're only allowed to use one gate, basically. What can you implement? NAND and NOR, actually, that's right. So you can implement NAND and NOR, because those are the basic gates. A NOT is kind of, you can make a NOT out of a NAND and a NOR. So that's what's being said here. A one-input NAND is a NOT. A one-input NOR is a NOT. So very simple, very simple functions. So a single NAND is a kind of a trivial SOP expression, because a single NAND, does that make sense? A single NAND is an SOP expression and a POS expression. What's meant by that? Let me write that down somewhere so I can make sense of this. I just noticed that that's kind of a weird thing to say. A NAND, what is a NAND? That's a NAND. I kind of disagree that this is SOP or POS. Anyway, not. I'm not sure what he means by that. OK, perhaps I'll skip over this slide. I'm not really sure what the message is. All right, all right, but most functions, I think this is it, this I believe. Most functions cannot be expressed as a single NAND or NOR gate. OK, so I think we dealt with a very simple case and made some claims about it, which I wasn't sure about. But how fast is an SOP expression? How many gate delays in an SOP expression? Because remember, if you think about the expression itself, it's a sum of product terms. Each of the product terms is an AND gate. So you have a whole array of AND gates for each of the product terms. And then you OR them together. So it's actually only two delays, a bank of AND gates, all connected to an OR gate. So it's two gate delays, an AND followed by an OR. And any NOT gates, we just ignore, because we assume we have the complemented inputs for free. So it's just two gate delays. But if you remember, when we talked about CMOS, AND and OR were not fundamental. The fundamental gates that we had were NAND and NOR. So is it right to say that they're two gate delays? Because it might be a little bit more than that. So let's explore that question. If we have an SOP expression and we can only implement it with NAND and NOR, how many gate delays does it take? So two gate delays with AND and OR. How many gate delays with NAND and NOR? Well, it turns out that we're going to have to do a little bit of math here. You're going to have to use a formula called De Morgan's law. And we'll see this a lot in this class, which says that NAND is actually, so AB, the NAND of A and B is actually the OR of NOT A and NOT B. So you can replace the NAND operation with an OR operation as long as you invert or complement the inputs before you use them. Conversely, a NOR operation, which is OR followed by a NOT, is the same as using AND with complemented inputs. So you first complement A, complement B, AND them together. This is the same thing as NOR. So if you want to prove this, it's pretty easy. Why don't I actually do that? So let's prove one version of De Morgan's law. OK, so I'll make a truth table out of this. So what I want to do is prove that A NAND B is the same as NOT A OR'd with NOT B. And all I have to do is, by brute force, look at every single case. There's only four cases here, because A and B can only take four different combinations of values. So we know that the meaning of NAND is you take A and B and complement it. So A and B would be all 0's with a 1 here. So NAND would be all 1's with a 0. What I want to show is that you get the same pattern in this column over here. So I'm going to do some intermediate steps here. NOT A is just the opposite of the A column. NOT B is the opposite of the B column. And now I'm ORing these together. So an OR is equal to 1 if either or both of the inputs is equal to 1. So you can see that the first three are 1 here, because we've got 1 OR 1, 1 OR 0, 0 OR 1. And it's only here that you get a 0. So this is a proof that A NAND B is the same as this. This is a proof of De Morgan's law. We just checked every single case. So that's what he's talking about here. You can do the other proof. You can do the other De Morgan's law proof. And you can actually do this for more than two variables as well. So the NAND of three inputs is just the OR of the complemented inputs. All right, so why are we doing this? We're trying to compare ANDs and ORs to NANDs and NORs. We're trying to establish a relationship. And so this math tells us that there is a relationship. And this is just what I just said. Actually, I should be doing this. This is what I just said. NAND is the same as OR on the complement of inputs. NOR is the same as AND on the complement of inputs. So what's neat is that we can express this graphically. This is a little complicated. But AND can be turned into NOR. This part is NOR if we complement the input. And OR can be converted into NAND if we complement the inputs. These bubbles kind of mean complement. So these are not real symbols. You wouldn't see them in a circuit diagram. Just for convenience, we're just putting little bubbles on the input right there. If we have an SOP expression, it can be written as a bunch of ANDs, a bank of ANDs, remember, all connected to an OR gate. And we said there are two gate delays, right? With two gate delays in this one gate here, one gate here. But we want to turn all of these into NANDs or NORs because NANDs and NORs are fundamental in terms of the underlying transistors. So what can we do? Is this animated? Right, we're going to use De Morgan's law. And what we can do is we'll look at the OR gate. And we know that OR gates can be replaced by a NAND as long as we invert the inputs. So we've got these little bubbles here into a NAND gate. So we've got a bank of AND gates, some extra inverters, and a NAND gate. But what is an AND gate followed by an inverter? That's a NAND itself. So you can basically slide these bubbles over to here, that one there, that one there. And what you end up with, I think this is an animation as well, is a bank of NAND gates followed by a NAND gate. So what you have is you've converted the AND OR structure into a NAND NAND structure. And this is still two gate delays. And this is two gate delays based on NANDs. And NANDs are simpler than ANDs and ORs in terms of underlying transistors. So that's a neat thing. And you'll be expected to really understand that. Right, right, so this was the punchline. We can build any SOP function. Instead of using ANDs and ORs, we just use only NANDs. We use only NANDs to build the entire structure. And it's still two gate delays of NAND. Yes? AUDIENCE MEMBER 2 We don't need NORs. We don't need NORs to. We just use NANDs. Yeah, it turns out that our construction didn't use NORs. Now, if you start with a POS instead of an SOP, so I don't know if this is off topic now. But if you start with a POS, then you start with OR gates here and an AND gate there. And then you would convert the AND gate here into a NOR. And then you would get NORs. So a POS becomes NOR logic. An SOP becomes NAND logic. I'm sure you'll explore this, if not in class, in your homework. You'll be doing these conversions. Right, and that's exactly what comes next. So great question. So you can use two levels of NAND to build an SOP expression. You can do exactly the same thing for a POS expression, two levels of NOR. And so any POS expression also requires two gate delays, NOR and NOR, assuming that the complemented inputs are free. They don't cost any gate delays. And as I said, later in the class, you'll see why they're considered free, because we'll get them for free. OK, so how do you make a POS expression using a minimal POS expression? We've talked about using k-maps to find minimal SOP expressions. So what we did before was we tried to make big loops with ones in them, and that led to a minimal SOP expression. If you start with the same k-map, you can look for zeros and try to make big loops out of the zeros, just the same operation. And each of those loops will correspond to a max term. A single zero corresponds to a max term, but a loop will correspond to a sum term. So do we have examples of that? OK, maybe I should do an example here. Agree? I don't see an example coming up. So let's go back to this and see if I can do a good example here. So let's look at this picture again. So suppose I want to loop the zeros together optimally. I'll do this a bit quick. Here's one loop that we could do of zeros to cover zeros, and here's another loop to cover zeros. So I think this is the optimal way to cover the zeros with two loops. So the question will be, if I want to write f of x, y, z as a product of sums, what is the sum that goes with this loop? Well, it's actually a pretty trivial sum. This becomes 0 when x becomes 1. This becomes 0 when x becomes 1. I have to get this right. Sometimes I get confused. So I think that's a sum term x. Or is it not x? I'm confused. I haven't prepared this. I'm going on the fly. AUDIENCE MEMBER 2 Yeah, and then x plus a sum can be a rule. Right, x equals 1 makes this 0. And so I should do not x to make it 1. I'm a little confused. Let me see whether this gets to the right answer. So if x is equal to 0, this becomes 0. And it makes the whole thing 0, because I'm going to multiply it with other stuff. So actually, you have to go and find the value of x and then invert the term. When you find the sum terms, there's like one more step of thinking than finding the product terms. You've got to invert a little bit. So this one, for instance, is 0 when w is equal to 1. So I need a not w in there, not a w, but a not w. Or when z is equal to 1. So that's not z. And so this is the product of sums expression. So it's a little bit harder to think about. I think you'll get practice with it on the homework, and you should also reason about it. But actually, we haven't learned Boolean expressions yet. But if you could factor this expression, you would get this expression. Turns out that you can. You'll see that soon. So they're actually the same. It turns out to be really easy to see that this is the same as this, as long as you can factor out not x. OK, so that was an example. I'm sorry that I didn't prepare that one, so I wasn't that clear about it. Let's see. But this warning here is exactly what was tripping me up. The max term has all variables complemented relative to the min term. And so the same, in other words, the sum term has all variables complemented relative to the product term as well. So if you have a box corresponding to min term ab not c, that's equal to 1 when a equals 1, b equals 1, and c equals 0. If you take the or of those same variables, but each complemented, that is equal to 0 in the same place. So the same cells correspond to min terms like this, but max terms with the complemented inputs. That's the tricky part and the part I was tripping on. OK, how am I doing? I'm actually really slow, but that's OK because Professor Lumetta is ahead of everyone else. So to find the POS form, create loops, find the prime implicants and essential prime implicants. It's just around the 0s instead of the 1s. And then build up your POS expression by multiplying those sums together. Make sure that you don't forget to complement the literals because of the duality between SOP and POS. And then each loop is a sum, and you multiply them together. Again, examples are the best way to understand this. So what gives a better area? SOP or POS? Well, it depends on the function. So if we go back to the example that I had, which one is better? I guess I would say this one is better. This one requires an AND gate, an AND gate, and an OR gate. But this one requires just an OR gate and one AND gate. So this one is slightly better than that. But in general, it totally depends. There's no general rule. It depends on the situation as to which one is better. And in fact, neither may be the best. Neither of them may be the best. There may be an entirely different solution that is better than the SOP, the minimal SOP, and the minimal POS. So this brings us to this topic of Pareto optimization. And as you can see with the star here, it's not actually going to be tested in this class. This is just additional information. So it's kind of good that in the last seven minutes, I can kind of basically describe the idea quickly. So what happens in this situation when you have a task to do and you come up with a bunch of different solutions? How do you decide which ones are better than the other ones? So in this scenario here, you're an intern. You're designing some hardware to execute dense neural networks, whatever they are. So you're trying to optimize your design. And you have two metrics. Let's say your boss says, it's got to be small. And so you have a score for size, 1 to 100, where 1 is the smallest, 100 is a large size. And you have a delay as well. And so the delay can have a score from 1 to 100. Smaller numbers are better. In both metrics, smaller is better. So if you have a design called x, let a of x be the area and d of x be the delay. So if you have two designs, how do you choose between them? What's more important, area or delay? Well, yeah, it depends. I don't know which one is better. So it depends on the context, whether area is more important or delay is more important. So one way to handle this, and I'm just going to kind of skip through most of this, is to create a weighting factor to weight whether area is more important than delay or not. So make a function like this and try to optimize this function. But that's going to depend on the context. It's going to depend on your engineering judgment. But how do you pick the weighting? So it depends on judgment. And you may not be, even if you are the engineer working on this, you may not be the one to have the judgment. That might be like a more of a managerial call than like an intern's job. So what do you do if you don't know what's better? So if you only have two options, just tell your manager both of them and let your manager decide. But what if you have like 10,000 different options? You've created them algorithmically. You have different parameters that you can change. And it just becomes a huge number of possibilities. Do you report all of them to your manager? No, you're going to have a pretty annoyed manager. So what can you do? So I think some of them you can rule out immediately. So suppose you have a design x and y where the area of a is better than the area of y. And the delay of, sorry, the area of x is better than the area of y. And the delay of x is better than the delay of y. So what does that tell you? y is out of contention. So x is better. And so in this context, what we say is that design y is dominated by design x. In particular, it's Pareto dominated by design x. So this is just an example with two metrics. If there are n metrics, then y must be worse than x in all dimensions to be Pareto dominated. So yeah, as we said, anything that is Pareto dominated by another solution can be discarded. And only the designs that are not Pareto dominated by other designs need to be retained and presented to your manager. The remaining designs form what's called a Pareto curve. And if you take some econ classes, you'll also learn about this concept of Pareto. So if this is the space of all designs, and I guess, let's say, this is the area score and this is the delay score, the ones towards the origin are better than the ones away from the origin. But in particular, if we look at solution p, we can see that p dominates all these points. So if you found a solution p, those can be discarded. And so if you do that with all the points, what you'll find out is that you get left with these several possibilities that are not dominated by each other. You can see this is the Pareto curve that you get. So they all represent different trade-offs between minimizing area and minimizing delay. And so these are the ones which need further consideration. So the point is, in many design environments, whether it's hardware design or any kind of design problem, the designer undertakes this exploration task. So there are a bunch of parameters, area, speed, for example. You generate a bunch of solutions. And then you trim your solutions by using Pareto dominance. You throw away the ones that are definitely worse than some solution. And then you show your boss the surface, the Pareto. If you have three dimensions, like area, delay, and power consumption, instead of having a single curve in two dimensions, you'll have a surface in three dimensions, a surface of possible good solutions. OK, so I think the next topic is Boolean properties. I'll let Professor Lumetta take it from there. Are there any questions in the last couple of minutes about the exam or about what we talked about today? Yes, Rahul. So architecture design today always goes to a smaller area and has more or less decreased Boolean, right? Are tools not equal? How can they get smaller and smaller? OK, so you're asking how do things get minimized? I mean, there are a lot of different ways and a lot of different, like, the transistors can get better, the designs can get better, and so on. But I think we shouldn't just restrict ourselves to area and delay. There are questions of reliability or verifiability, like does this thing actually work? So the cost, right? How much money you want to pay your engineers to make sure they do a good job? How many engineers do you want to hire? So there are a lot of considerations. It's very complicated out there in the real world. All right. When is the undergraduate advising for the test? Oh, the review sessions are, there is one tomorrow at, there's one tomorrow at 2 to 4 PM in 1013 ECEB. And that is done by Eta Kappa Nu, so it's not official. And then there is the official undergraduate session on Sunday, same time, same place, 2 to 4 PM, 1013 ECEB. And then, of course, on Monday, you have your lecture again for review. So there's plenty of review sessions. And down the bottom, it actually says that for the Sunday session, the UAs will be talking about the fall 2013 exam. So you can practice that exam. After you practice the exam, you can look at the solutions, and then you can come and ask questions about it in the review session as well. Can I be recorded? So if you want to. Sure. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.\",\n",
       " \"the comparator design, and then we'll go through that design and analyze it in terms of area and delay and think about optimizing it. We'll do a little bit of algebra, come up with a better design. Then I want to take that design and think about what we can do. So the design we're working on is an unsigned comparator, right? So we put in two unsigned numbers and it tells us A and B, tells us whether A is less than B, equal to B, or greater than B. So then I want to think about, well, how would we build a two's complement comparator? And so the answer we don't want is we'll start over, do a bunch more K-maps, and so we'll see what we can do. That's probably about as far as we'll get today, hopefully. But one thing, the midterm grades are posted, so we finished grading them on Saturday. The standard plan, by the way, is the Saturday after the midterm, we're going to all sit down and grade. So it's kind of a standard process, so you can expect your midterm grades to be done by that Saturday and up, usually by the afternoon, if not by the evening. So those have been up a couple days now. I will send a few emails related to that. I mean, generally people did well. I want to maybe talk with a few people, make sure people feel like they're on track for getting a grade they're happy with in the class. But feel free to talk to me about the same during office hours, tomorrow 1 to 3. I may extend them a little bit, but I'm not quite sure which direction yet. I think my next meeting's at 4, so maybe at least I'll stick around a little longer if people have questions tomorrow afternoon and over in Daily Byte. All right, so I wanted to review, since we had the whole weekend to do other things, so I wanted to review the design we were working on. So remember, when we compare as humans, we write the numbers down, line them up, and then start on the left because the left side's the bigger side, and so as soon as we find a difference, we're done. But of course, when we're designing a digital system, it's not so easy to just have the wires suddenly give us an answer, so the information will flow all the way to the end, and then we'll look at the wires at the end, and that'll tell us the answer with what's A related to B. So it doesn't matter for the digital system which way we go, right, because the amount of time it takes, the logic is going to be the same. So I thought, well, let's just design the other direction. Our choice will actually affect our logic, so you can do different approaches, and sometimes that'll affect your logic. Sometimes it might be easier, other times it might be harder. But our comparator here in class will go from least significant to most significant bit. So this was our bit-slice abstract model. So we have two bits coming in. Remember, there are two bits because there are three possible answers, right? So for all of the less significant bits, we can say, well, A was less than B, is equal to B, or A is greater than B. So in order to encode three different answers, we need at least two bits. So we've got two bits coming in. Similarly, our answer of whether with this extra bit in the front, A is less than, equal, or greater, we need two bits to encode that answer, pass those usually to the next bit-slice, but at the end, we'll have our answer. And then we get one bit of A and one bit of B into this bit-slice for bit number M. And then we talked about, well, how do we actually choose the representation? There is no natural representation, right? If I said, OK, everyone pick their favorite, or pick what you think is best, and then we looked at them all, there are 24 different ways to assign these three different messages to these four different bit codings, right? And I'm sure that none of them would have a better, a bigger distribution or bigger number of students than other ones, right? Well, maybe you'd pick this one, because you've seen it already. But other than that, there's no real reason to choose one over the other inherently, except a little bit. So if you look at this, there is some symmetry here, right? So the equals case, I chose a pattern where the bits are equal. The less than and greater than case, I chose a pattern where the bits are different, right? So there is actually a little bit better advantage. If you look at symmetries and try to reflect those symmetries of the answer in the bits, often your logic will end up being a little simpler. Because we did this, you'll see that the one-bit solution that we calculated initially will also show up in the full solution. So I'll call that out for you as we look at the designs. But you'll see the one-bit solution, the circuit for that one-bit solution, appearing in the general solution as we solve the problem more generally. All right, so this was our single-bit solution. So I said, well, for the end bit, we don't have any extra bits to look at. And so those are implicitly equal. So let's start with this easy problem, or easier problem, of saying, well, what happens when we have one bit of A and one bit of B? What is the meaning of the answer for that? So of course, if we have 0 and 0, those are equal. We'll have 1 and 1. A is equal to B still. Here, A is 0, B is 1. These are unsigned, again. So A is less than B. And then 1, 0, A is greater than B. We code that with our representation. And those are the bits that get passed out for the first bit slice. Now, of course, the real bit slice we're going to build for the first bit slice will look like this. And so we'll feed in zeros to that bit slice in the real design. But we just wanted to calculate this answer. And that gave us this circuit diagram, where the minterms here, these are, sorry, let me go back to that. Each of these functions, remember, Z1 and Z0 is a minterm, meaning that it has 1, 1 in its whole truth table, one output of 1. And the minterms are A, not B, for Z1, and A prime B for Z0. Sorry, I should say that as AB prime for this one, and A prime B for that one. Now again, those two are the ones that say that A and B are not equal. Those are the minterms that say A and B are not equal. So for example, if you wanted to build a simpler comparator that simply told you whether the two values were equal or not, then you could OR these two together, and it turns out that would just be an XOR gate. And so an XOR also tells you, well, are the two input bits equal or not? Not equal, you get a 1, equal, you get a 0. Okay, so now we're ready, hopefully, to solve the more general problem. I won't flip back to the representation because it's actually here for you. Okay, so we've got the, on the left side are inputs. We have A and B, one bit of the current number. Remember, this is the most significant bit, right? So we're getting input from the less significant bits. So A and B are the most important bits to look at at this point in the number. C1 and C0 encode the answer for all of the lower bits. And so when I say the representations reproduced here, 00 means A equals B for the less significant bits. 01 means A less than B. 10 means A greater than B. And 11 should never happen. All right, so let's go through these. So this is one quarter of the truth table we have to write out in order to understand the design. So I want you to kind of get a feeling for what's going on here. So in order to find the answers, we have to look at the meaning. So we have to use the representation that we chose to decode C1 and C0 into a human meaning. We have to then calculate the right meaning for the output. So given this meaning and these bits A and B, what should we tell the next bit slice, A relative to B? And then we have to use the representation a second time to encode the answer. So when you're picking a representation, the relationship between that representation and the resulting truth table in KMAPs is not going to just be trivial. You're not going to be able to say, oh, well, if I change it a little bit, that'll make my KMAP easier to solve. It's not, unfortunately, quite that easy. You have to go through it twice in order to get the truth table, and then you have to take the truth table, put it into the KMAP. So it's often not easy to see. So that's why with something like 24 different choices, often it's better to say, hey, computer, go look at all the answers and find the best one for me. So for something this small, 24 is a tiny number. Even thousands or millions are usually pretty tiny for a computer. So they can solve those kind of problems. If you get a much bigger design, something like you'll see with the LC3 microarchitecture, we have many, many bits. A computer can't solve it. And that's where you really need human intuition about symmetries, different kinds of information that don't have to be related, where as a human, you break those into pieces. You give the pieces to the computer to solve the small problems, and the computer can do a good job with the small problems. But you can imagine if you had, instead of four rows of your truth table, if you had 32, sorry, not on this one, but on the representation, if instead you had 32, well, then you have 32 factorial different ways to assign your representation. Even a computer is not going to explore 32 factorial ways for you, not in your lifetime. So the human intuition helps you in real designs. In this kind of design, we could just hand it to the computer. But I want you to understand how it's done. So remember, in our bit slice, we have four inputs. We have to look at one bit of A and one bit of B. And we also have input from all of the rest of the lower, less significant bits, telling us the relationship of A and B for those bits. Now, any time you have input bits, you have to consider all possible patterns. So with our truth table, all I've done here, sorry, wrong way. All I've done here with our truth table is say, well, I can only fit a quarter of it on a slide. So the quarter I'm going to fit is the quarter where A and B are both zero. And we'll have three other slides. I don't want to show you the answers. We'll have three other slides where A and B are zero, one, one, zero, and one, one. And then we'll go through all possible values of C1 and C0. Yeah. Yes, yes, that's right. So remember the information flow. I don't think I have the big picture in front, but we'll look at it later. There will be n copies of this bit slice. So all of the copies down here, or at least less significant bits, will do all of their computation. We'll decide whether for all of those less significant bits, A is less than, equal, or greater to B. And we'll tell this bit slice through these two wires. Yeah. Yes. And that's part of filling in the truth tables. So hold on to that thought. Any other questions before we go forward? Okay. All right. So Mohamed points out that C1 and C0 we probably only care about when A and B are equal, right? Because A and B are the most significant bits in our design. So since we're passing from least significant to most significant, the only time we should care about the inputs are when A and B are equal. I'm sorry, the inputs C1 and C0, when A and B are equal. There's one caveat to that, which let me get to the non-equal slide before we look at what it is. All right. So help me out here. So if I get A and B are zero, and C1, C0 tell me A equals B to the right of me, what message should I pass? Zero, zero. So actually, I just want you to tell me meaning first, and then we'll encode it. But yeah, A equals B, which is going to be zero, zero. So what if I get zero, zero for A and B, and then I have A less than B for the less significant bits, what message should I pass? A less than B. Good. How about this next line? A greater than B. And so you see, basically what A and B are, since they're equal, I have to rely on what's what the less significant, the relationship between the less significant bits, which is encoded in C1 and C0 for me. So I want to pass the same meaning then because my bits, A and B, were equal, didn't change the answer. So I'm going to pass the same meaning. How about this last one? It never happened, right? This is not a human pushing buttons for us, right? This is not our hand-held computer, hand-controlled computer, thumb switches, right? This is a bit slice. It never produces one, one. So we don't have to worry about this case. So we don't care. All right. So then we can code it. Over here, we already have the encodings, right? So this one, A equals B is going to be what? 0, 0, right? Good. What about this one? 0, 1, 1, 0, XX. Good. All right. So this is a quarter of our truth table. We've got three more slides to go. So this is the A equals 0, B equals 0 case. So let's then do the A equals 1, B equals 1 case. Is there any difference? There's not, right? A and B are the same. So we have to take the answer that our less significant bits gave us as encoded in the C1 and C0 inputs and just pass that along to Z1 and Z0 using the same representation. And so we just forward those bits. So A equals B, A equals B. A less than B, A less than B. Good. A greater than B, A greater than B. What's this one again? I don't care. Good. And then the bits are the same. It looks exactly the same, right? Outputs are exactly the same as the last case. All right. So now what about this case? A equals 0 and B equals 1. So when A equals 0 and B equals 1 and the less significant bits are all equal, what relationship do these have? A less than B, right? Because this is the most significant bit, B starts with a 1, unsigned number, remember. B starts with a 1, B's bigger. Doesn't matter what the rest of the bits are. B's bigger. And that's where you'd stop comparing as a human. So A less than B. So if it doesn't matter what the rest of the bits are, well, A less than B will also send A less than B, right? Not because of this, but because B is 1 and A is 0. And even though these bits, A is greater than B, well, this is the leading bit. So A less than B. What about down here? Don't care. We could say A less than B, but we don't need to, right? If we put out a different answer here, it doesn't matter because this case won't happen. So somehow this answer enables us to get a simpler logic. Let's take advantage of it, right? So this is the caveat that I mentioned in answer to your question, Mohamed, that even though we know the most important bit tells us A less than B, we also know that this should never have happened, so I don't care what answer I put out. And so this is the one that overrides because it doesn't matter in this case. It should never happen. So I can take advantage of the flexibility. Now I don't actually even know if putting x's here gave me a better function, but I want to make sure if it can that it does. xx. Yeah, don't care. Yeah. I mean, we could put 0, 1 here, but that just means there are three functions. Well, 3 times 3 is 9 functions, so we're not considering for A that was 9. OK. So always output A less than B for valid inputs. And so the valid inputs is the caveat. All right, good. And what about A equals 1, B equals 0? A greater than B, right? So A greater than B, A greater than B, A greater than B. Don't care. Good. And those are all coded the same. All right, so now we have our truth table. I'm not going to walk through copying the k-maps. I'm just going to pop up the k-maps with all the values. Is that OK? All right. Oops. I mean, we can go through and copy it, but this is what you should get. So what I've done here is I've put A and B on the top. I put C1 and C0 on the side. And so these are essentially the same as our truth tables, except that the bottom two rows, of course, are flipped. And then the order we did the truth tables was 0, 0, 1, 1, 0, 1, 1, 0 on the slides. Where are the loops? Right side. That's what I picked first, too. What is that one? A, B0. Good. AB prime. OK, so AB prime. What else? Bottom right corner. Hey, look, that's what I picked, too. OK, what is that one? I'm hearing different answers. So OK, right side is A, right? And then bottom is C1. So AC1. OK, good. And then what else? So bottom left two, except you can go this way, too. Wrap around. OK, so we're going to wrap around. Good. A little messy looking, I guess, unless drawn by hand. Tell our students at Microsoft that we need wrapping default arc things. All right, so what is that one? B0, C1. Good. So this is sort of a majority function. I hesitated to call it this, but it's a majority function if you count B prime as a valid input. So if two of these three are equal to 1, then Z1 is also equal to 1. So if we write that out, AB prime plus AC1 plus B prime C1. If any two of those are 1, then Z1 is 1. Yeah, so the question Mohammed's asking is, should you make the loops as big as possible? So in the presence of X's, you need to change the original rules for finding prime implicants. You do need to find prime implicants, right? So you need to make them as big as you can. Circling X's is OK. Circling 0 is still not OK. So make them as big as you can, choose as few as you can, and always cover all of the 1's. You do not have to cover X's. So the changes, I put them on a previous slide when we introduced X's, but make the loops as big as you can, cover all the 1's, and don't need to cover X's. So that's the rules we've applied here, and that gives us this minimal SOP form. Yeah. Is this one unique? OK, so that's a good question. Did I make any choices? So when I went up here, I could not go left. Left. I could not go right. I could go down. I could go up, and I did go in both directions, so I didn't make a choice. For this one here, I could not go left. I could not go down. I could go these two directions and I went in both, so I did not make a choice. And then I had this one left. I could not go this way. I could not go that way. I could go this way and that way. I went involved, so I made no no choice. So since I made no choice in any of these and I'm done, then yes, it's unique. Any other questions? Yeah. It's not that they're unknowns, it's that we don't care. And so we're allowed to leave them as zeros. So in particular, we do not need to circle this x, right? And so in this case, we have a good answer without circling that x. Circling the x would not have bought us anything, right? Adding this row here of four x's would not have gotten us anything because we wouldn't include any ones, right? So including the ones is the important part. You're allowed to include x's, but you don't need to. Anything else? No? Okay. All right, good. So we got another function to do, z0. So what are the loops? Vertical one? Okay, good. What is that? a0b? Okay. And what else? Two squares. Which one did I pick first? There's one. What is that? a0c0. Okay. And then the other squares where? In the middle. That's bc0, people are saying. Okay. So same kind of thing, right? Three values, one of which is a prime, but if two of those three values are one, then z0 is one. So you notice these are symmetric, hopefully. Actually, let me put them side by side. So notice the symmetry both in the circuit diagram, but also in the algebra. That symmetry is there partially from the problem, right? That a and b, we're just comparing them, so there's no reason to think that a is any different than b. If I swap them, I'd still get an answer. It would be the opposite sense. But also because of the way we chose our representation. If you chose an asymmetric representation, the symmetry would be broken and you wouldn't see it in your design. But here we chose a symmetric representation where when the two are equal, we have the 0, 0 pattern, and when they're not equal, if a is bigger than b, we have one of the non-equal bit patterns, and when a is less than b, we have the other non-equal bit pattern. So the symmetry shows up in our answer. So that's a nice design. A lot of gates, but this is what we get out of our computation. We could stop here. If we were to give you something like this on a homework or exam, this would be a fine answer. I'm going to take it further and do some analysis because I want you to understand how you do trade-offs and how you think about these things, but this would be a fine answer. You can go implement it this way and this would work just fine. Any questions on this? OK. So hopefully people feel like they followed along and could do this themselves. All right. So, oh, yeah, yeah. So I did want to call this piece out for you. Notice this thing in the middle. Because we're doing information flow from less significant to most significant bits, the most significant bit, of course, is the most important, as we talked about when we did the truth tables, right? So if you look at this, this is the same functionality that I got when I did one bit without considering what was happening with the, you know, when there were no lower bits. So this is my circuit diagram for one bit, and it produces the same answers and those answers, if this AND gate produces a one, Z1 is one. If this AND gate produces a one, Z0 is one, right? So that single bit core is still there. It's just that in order to handle the other cases when we have less significant bits giving us information, we need this extra logic. But the single bit core of just comparing A and B is still there. One bit of A and B, I mean. Yeah. How would I represent them, sir? Symmetry? So the symmetry will actually come out in the form. So you can see that here, the A's and B's have opposite complementation. So if you look at this term, A and B prime, this term is A prime B, right? And then the C1 and C0 are also symmetric in the sense this one has C1s and this one has C0s. So the symmetry comes out in the algebra as that. But just like we talked about duality where you replace AND and OR, you replace 0 and 1 with each other, here you replace, if you replace A and B with one another and you replace C1 and C0 with one another, and you get the other expression. So that's where it comes out algebraically. Yeah. So that's a good question. So the question is that Daniel's asking, is it possible that an asymmetric representation gives you a more efficient design, whether better area or better delay? It's certainly possible. I think if you have to pick and you don't want to explore both, I would tend to favor the symmetry. I think it's reasonably good intuition. I think it's possible, but I think of just sort of geometric arguments, like if you have a fixed perimeter and you want to make optimal size area, you end up with a square. So making things asymmetric usually ends up making half of it more complicated and not simplifying the other half as much. So the balance tends to be not as good. But it's certainly worth exploring, certainly in simple designs like this, where it takes you a few minutes to go do it. Yeah. It's a good question. Yeah. So I just wanted to call it out so that you see that once we've decided on the symmetric representation and the use of the least significant bits passing information to the most significant bits, that this logic for calculating the single bit solution is still part of our answer. That it's sitting there because the single bit solution is the thing that dominates the answer. So when we filled in the truth table, we said, well, if A is 1 and B is 0, then the rest of the bits just don't matter. Because clearly if the leading bit of A is 1, the answer is A is bigger than B, if B is 0. So that single bit answer here is also logically dominating this bigger system in the sense that if this output's a 1, z1 is 1 regardless of what these gates do, because it's an OR gate. And if this one down here says B is bigger than A, A is less than B, z0 is 1 because this is an OR gate. So that's how that human meaning gets interpreted in the logic. Easier in the area delay power sense or easier in the human? Yeah, so I think you get benefits both directions, right? Yeah, you can't stop. Yeah, that's right. Yeah, so there's no, you can't look at one bit and then suddenly give the answer out of two different wires, right? Someone has to know which wires to look at. So you have to flow the information to the end. So you'll have to carry it forward. So the truth table calculations will be different ones, but more or less the same. Okay, good. So here's what we've got. So let's go through and use our heuristics to analyze area delay. So how many literals do I have here? All right, so remember literals. So it's a little tricky because when we talked about literals before, we only had one output. So the way I want to count literals is just to look at this diagram and say, well, whatever's going into the first level of gates is a literal. So here's a copy of A, here's a copy of C1, here's a copy of C1 and so forth. So how many inputs do I have on my first level of gates? I have six gates, but how many inputs total? 12, right? Two input gates everywhere. So 12 inputs, so 12 literals. And if you look at the equations here, it's going to match, but later it won't quite match. Let me flip back to the equations. So if I asked you to count literals here, you'd also get 12, right? You'd say, okay, count literals A, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12. Later, we're going to reuse some of our expressions, so it won't be quite the same. But here, 12 inputs to our gates from the inputs, right, directly from the inputs. So those are the literals. How many gates do we have, not counting these inverters? Eight, right? So eight operations. And so that gives us an area of 20 from our heuristic. So keep that in mind. Every bit slice costs us 20 area, because later we're going to do a different design we're going to want to compare. Add 12 to 8. Remember, our area heuristic was literals plus operators. And when we do that graphically, it's number of connections from the inputs, possibly through inverters, through the first level of gates, plus the total number of gates. All right. Yeah, Eric? Yeah. So the question is, if we were able to find things like XORs, would that decrease speed or area, and possibly mean decreased delay and increased speed or something? So it may in some cases. And so the thing is, you have to go through the different representations and work it out and figure out the balance, right? Figure out which answer looks best. And that's why I said for 24 solutions, just have a computer calculate them all and find the best one for you. I actually did this all on paper after I picked my representation based on symmetry the first time. So I think the representation I gave you is one of the optimal ones in that sense. But in general, it's worth exploring a few different options that you think might be promising if you're doing it by hand. That's a good question. All right. So let's analyze delay. So to do this, I want to start with Z1. And then maybe I'll tell you now, I'm going to remind you this is symmetric. So if we do for Z1, you're going to get the same answers for Z0, right? So let's just do Z1. So what's the number of gate delays? Again, we decided not to count inverters. So we're just going to go from A to Z1. Two, right? So there's a path that takes two. And I think probably all the paths take two. So two gate delays from A to Z1. What about C1 to Z1? Also two, right? There's another there's a path from C1 to Z1 with two. Good. What about C0 to Z1? Yeah, zero would actually be a little misleading. It doesn't matter, right? It doesn't have any impact on Z1. So let's just say it's not relevant. Zero, we could get confused later. We could think that until I have C0, I can't calculate Z1, which is not true. So in this case, it wouldn't have any effect. But you don't want to have that constraint when later you're trying to glue pieces together and figure out delays. So it's not relevant. What about B up to Z1? Two also, right? So this one does go through an inverter. So if we're going to count that, it might be a little slower. But we'll count it as two. We're going to ignore the inverter. Same way we talked about when we introduced the ideas. All right. And again, the delays to Z0 are symmetric. So if you went and did the same exercise, you would get A to Z0 is two, ignoring the inverter. C1, not relevant. C0, two. And B, two. So here, this is what the comparator is going to look like when we glue it together at the low end. So we're putting zero and zero to say that these are equal. Initially, A and B are equal. And we're going to say A and B are available at time zero. So if at time zero, zero gate delays, I put A and B on my inputs, then when can I expect to see my outputs? So we'll use the calculations we just made to figure out for the bigger system when the answer will become available. So A and B are available at time zero. I'll just mark those as zero. So those meet available at time zero. What about these zeros on the right? What time are those available? Yeah. Those are just constants. So those are just wired to ground. Yeah, negative infinity, effectively. So these are always available. From the point of view of the system, these are available when I turn the power on. So we'll just call it negative infinity. So forever. So that's what we have so far. Now what we need to do is use the timings we just calculated to let this information flow through the system and figure out when are these intermediate values going to become available? Yeah. This one? Why is what? Why is C zero? So C zero, let's look at where it goes. So it goes into this gate. Let me delete that. It goes into this gate and into this gate. These gates go both into this gate, and that gate changes Z zero. None of that information affects Z one. I'm sorry? I'm sorry, I still can't hear you. Yes, yes. None of the changes affected by C zero make their way up to Z one. The other way to do this is to go backwards from Z one and to look at the gates that affect it. So the gate, the OR gate that produces Z one is only affected by the top three AND gates. And those top three AND gates are fed by A, C one, B, and I think that's it. So those three variables are the ones that affect it. In fact, most tools would define what's called a cone of logic. So they'd start at the output and they'd go backwards and they'd figure out what variables affect that output. And that backwards cone is called a cone of logic. You don't need to know that. Okay. All right, let's roll forward. All right, so we need to use those delays we found for one bit slice to calculate the times for these intermediate C values between the slices. So remember that all the A and B bits are available at time zero. So what matters most in that input to output analysis is going to be C getting to Z. All of the A's and B's are available at time zero, even if it's bit number N minus one, those come in at time zero. So the thing that's going to be slowest, and we care about the slowest thing, is C to Z. So we found, just to remind you, we just looked at it, but C one to Z one was two gate delays, C zero to Z zero, two gate delays. So when is this first set available? So this is bit slice zero. Now these are available at negative infinity. So that's probably not the thing we care about for this first bit slice. So when will these be available? I'm sorry, these are not input values, these are timings now. So these are available at zero gate delays, at time zero. Yeah, so that's the question, is how long does it take for this comparator bit slice logic to process A and B starting at time zero, and these arbitrarily far back in time? Two, right? So if you remember, the A input going to C one, and also A to C zero, B to C one, B to C zero, those are all two. And so both of these outputs will be available after two gate delays. So I'm going to draw an arrow saying, well, the information is flowing from here, that's one of the longest paths, and that'll take two gate delays. Two gate delays for each of those. But what about the next one? What about these variables on the left coming out of bit slice one? When do those become available? Four, why? Yeah. So even though A and B are available at time zero, so if we think about the paths from A and B over to here, that only takes two gate delays, that would make these available at two. But from here, these answers are not here until time two. So these answers are two plus two is four. Good. Okay, so let's generalize that. So the C upper script zeros out of bit slice zero are available at time two, which means two gate delays. The C ones are available at time four. So what do you think about C n minus one? Two n, good. Okay, so our whole system takes two n gate delays. If you build a 32 bit comparator, it'll take 64 gate delays. Can we do better? Probably. But you should ask that. So we have two metrics, right? So can we do better in area? Can we do better in delay? And maybe we can do better in both. Can we reduce delay? Maybe. Actually, without not using a bit, we can go to bigger bit slices, right? Do two bits at a time from A and B or more. That could make things faster. But if we keep a bit slice design, it's actually pretty hard. Bit slice with one bit is actually what I mean. Why is that? Because if you want to reduce from two gate delays to something less than two, how do you implement a function with fewer than two? You've got to implement the function with one gate. So unless you get really lucky and your representation lets you implement both of your functions with one gate, then you're not going to have one gate delay per bit slice. You're going to have two, two level logic. So it's actually pretty hard to beat two. Again, if you do two bits at a time, you might be able to do that with two level logic. And that really means you're going to get down to n, right? Because you've only got half as many bit slices as you do bits. So you can do two for each, and then you've got overall n gate delays. But using the bit sliced approach, dealing with one bit at a time, which is much simpler, it's difficult to beat the delay. ARIA, on the other hand, that I'll go with your maybe answer. So let's do some algebra. That looks fun. I know you all love it. So here's what I want you to do. Here are our equations from before. So all I did is copy these. I'm sorry, copy this one. So first, I want to pull out C1 using distributivity. So I've got the AC1, B prime C1. So instead, I'm going to write A or B prime times C1. So that's our first step. And then I want to say, well, you know this A plus B prime factor, I could use a NAND gate for that. In particular, I could write A prime B complement it. So all I've done is I've applied De Morgan's law. So I said, I want to complement this thing. So complement the A, get A prime. Complement the B prime, get B. And then complement that AND. So now I have Z1 is AB prime plus A prime B quantity primed ANDed with C1. And then I gave you the same equation, same manipulations for Z0 right down here. So why did I do that? So here, you see AB prime. Here, you see AB prime. If I calculate AB prime with a gate, I can now reuse that gate's output in two different equations. Similarly, here I have A prime B. Here I have A prime B. If I calculate that expression with a gate, I can then use that gate's output in two different places. So I can reuse my gates to calculate these two output variables by manipulating the algebra a little bit. So maybe I can reduce the number of gates I need. So someone had a question? Yeah, De Morgan, generalized De Morgan's and applying duality and then swapping all the complements are the same thing. This is just one application of De Morgan's laws. This is just applying it once. So you don't need the full power of duality. Any questions? All right. Here's what that looks like, except I made it into NANDs. So I turned it all into NANDs. Why did I do that? Because if you use AND or OR, you actually get extra inverters that are not really there. And so I didn't want you to count the wrong sort of diagram that had gates that didn't exist in the real implementation. So this is how you would implement those equations using NAND and NOR, which is what we have to do in CMOS. Now probably you look at this and you say, I don't know that this represents those equations. I certainly do. In fact, every time I come back to it, I confuse myself before I get it. So I wrote it up for you. So first of all, I wanted to point out, though, here's your single bit core again. So those two factors we pulled out, those are actually the two min terms we produced for a single bit. So all we need to do is produce those two answers. Is A bigger than B or is B bigger than A from that one bit? If so, that's going to basically drive all of our answers, just like in our last solution. I did a funny thing, which I clipped it before the inverter on the NAND gate. So the single bit core had AND gates in it. These are NAND gates. So we're actually inverting our terms before we use them in the rest of the circuit. That's not a big deal. So here, let me try to convince you. So this thing down here now forms A prime B. So A comes through this inverter, goes in there. B is here. So A prime B. And then it's a NAND gate, so A prime B inverted. We're going to take that and put that in this NAND gate up here. That's also going to have C1 coming in. So out of that NAND gate, we're going to have A prime B prime ANDed with C1 and then primed again. Happy? This one on the middle left, this is producing A with B prime. And it's a NAND gate, so we'll complement it after that comes out, after it's ANDed. We're going to feed that one into this NAND gate along with this expression. So what we'll get is this thing ANDed with that thing and then complemented yet again, which looks like that. So there's our AB prime primed there, ANDed with this thing there, and then the whole thing complemented. So I'll apply DeMorgan's one time. So I'll take this prime here, and I'll change this AND into an OR. And then I'll complement this one, which will just take that prime away, and complement this one, which will take that prime away. I'll get that. But that's what we wanted to implement, right? So fortunately, this diagram is symmetric, so I don't have to show you that nasty algebra again. So you should convince yourself that you think this is right, because obviously, if you get the circuit wrong, it doesn't really work. It's just some random circuit. All right, so let's analyze this new design. So you can already see, geez, got a lot of gates there, a lot of maybe delays worse. On the other hand, it has fewer gates than the other one, so maybe area is better. So let's think about it. So how many literals? So here, I want to be careful. Literals, again, anywhere where one of these or its complement goes directly into a gate, I want to count as a literal. So how many literals do I have? Six. Good. There they are. So this NAND gate has one literal coming in. This one has one literal, and these have two each. So six literals total. How many operators? Also six, all NAND gates. Good. So my area is 12. Area is 12, right? Six plus six is 12. So smaller area. Last time was 20. Smaller area. How about delay? A to Z1? Two? Is it really? You sure? How about that path? Three, ignoring the knot. What about C1 to Z1? Two. Yeah, let me make a comment here. So be sure on A, be sure that you're looking at the longest path. What matters is the slowest path. So there are paths that are only two. If I go this way, it's only two. But what matters is going to be the longest one. So I'm drawing you examples, but the examples are always one of the longest paths. I'm not just picking a path randomly and measuring it. So two for C1. Good. And what about B? Is it three? Did I mess it up? I think it's two. Oh, three. Sorry. Yeah, it's three. I messed up my memory. All right. So three also. There's no inverter on that path. The reason I keep pointing out the inverter is if you go and read the notes, the notes count the inverters. So they're going to be off by one relative to the slides in class. All right. So you might think, well, gee, is that 50% true? Three instead of two? Well, let's go here again. So actually, let me go here and make sure. So A to Z1 is three. B to Z1 is three. C1 to Z1, only two. Okay. And it's symmetric. So the Cs to Zs are two. The As and Bs to the Cs are three. So what about this first set of outputs? When does this come available? So same path from zero, add three, we get three. What about this set? As and Bs are done here at zero. So you add zero to three, you get three. So certainly no earlier than three. These are available at three. The delay is not three to get to here. The delay is two. Three plus two is five. So you take the bigger of three and five, you get five. These are there at five. Same slide with numbers change slightly. Three, five. So when will these become available? Two and plus one. So all we did for the overall design, even though the A to B paths, I'm sorry, the A and B to Z paths got 50% longer, the C to Z paths stay the same. And those are the ones that add up as we go through bit slice to bit slice. Those are the ones that add up to this two number here is the C to Z paths. The extra one, three minus two, is here. So if we did a different design where A to Zs became 10, this would just become plus eight. As long as the C to Z paths are fast. So the full calculation is for every input that matters, you add the delay. So A to C1 is plus three. So zero plus three is three. Zero plus three is three. And three plus two is five. And then you take the biggest. So three, three, and five, the biggest is five. We're actually at the end of the hour. So I don't want to keep people over time. We'll look at this briefly again and then finish up the discussion on Wednesday. But we can talk more offline if you want to be satisfied today. Thanks. Transcribed by https://otter.ai Edited by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai Transcribed by https://otter.ai\",\n",
       " \"So we will include, I wanted to go over, there's a homework 7 has a problem on it where you need to have some notation. I wasn't going to introduce, actually the notation on the homework is wrong too, but it'll tell you the right stuff and how to do it. So, and then use the wrong notation that they use in the question. Then we'll talk about serialization. So this will move into part 3 of the class. So midterm 2 material ends up here and then we'll look at serialization and do a couple of examples. We may finish these, they may go into next Monday. There's a feedback survey online. I know a lot of people have taken it. I haven't announced it yet, so I don't know what fraction of you have taken it, but it's open until Monday night at midnight, so please do take it. Basically just feedback on various resources in the class and what you find useful and what you think could be improved and things like that. And I'll read all your long answers. Short number stuff we'll just summarize, but I'll tell you what we find from that survey once we've done the stats on it and stuff. All right, so here's the midterm reminder. So Tuesday, 18 October, the conflict exam. If you need a conflict, please let us know through the wiki by Monday. And otherwise, it's the same. Coverage is up through, is basically part 2 of the notes, plus since we didn't do reading, writing, truth tables from part 1 of the class, that's on part 2. So that's the topic coverage. We'll do a review session just like we did last time, so not the Monday next after this weekend, but the one after it, the 17th of October. We'll have a review session in the same style, so come prepared with questions. So I wanted to spend a little time going into more detail. So what we did on Monday was we built what are called sequential feedback circuits, where the output of some gate goes back directly to the input. So instead of having pure combinational logic, you have a feedback loop, and this one in particular is a gated D-latch. It's one of the ones we did, and we just look for stable states, right? So I think that's pretty much all you need to know, but there's some notation that helps you do a little more. So let me walk you through that and kind of show you how it works. And you'll need to do this approach on homework 7, problem 1. So I want to start by just imagining the feedback loop here. There's actually only one we need to cut, so it looks kind of like two, but if you cut this one, then rename this output from Q to Q+. It's usually Q star, but in the homework problem it's Q+, so leave it there. And then Q is still an input, and at that point what you have is combinational logic, right? So you have inputs over here, D and right enable, the data input and the right enable input, and then you have Q as an input, and everything else is combinational logic to produce Q+. P is actually just an intermediate value of your combinational logic. So that is now combinational logic after cutting one loop, so combinational logic circuit. So after I actually erase it, maybe it'll be a little easier to see. I mean, imagine that bottom right NAND gate is shifted to the left. Now it's just a combinational logic circuit to produce Q+. So let's write a truth table for that. So we've got D, right enable, and Q coming in. We've got Q+, and P coming out, and we've got a bunch of NAND gates that are kind of a pain to analyze. So let's start from P, the intermediate point, and calculate this one. So P is NAND of Q and R bar, so that's Q, R bar, handed together and then inverted for the NAND gate. So if we then apply De Morgan's Law, we have Q prime plus R bar inverted again, and then R bar is coming out of this NAND gate, so we can just invert the inversion again, and write that as D prime, this input up here, handed with right enable. So P is Q prime plus D prime times right enable. The reason I wrote it that way is so that we can then fill in the truth table easily, and you can see there are two colors. So the Q prime, all the zeros in Q imply ones in P. So first we can write those in, and then anywhere we still have a D prime and right enable. So let's see, D prime is up here, right enable is down here. So these two lines here, the third and fourth lines, will be ones also. This one's already a one, but the D prime right enable also makes this P output a one. So everything that's not a one is then a zero. So just read off the equation, it's SOP form, so we'll just fill it in one term at a time with ones, and then fill in the rest with zeros when we're done. So now we have P, then we can go back and fill in Q plus. So Q plus is S bar handed with P, and then inverted, just like that. And we apply De Morgan's, we get S bar complemented again, or with P prime, and then if we have this complemented, that just cancels that inverter there, so we have D handed with right enable, or with P prime, is Q plus. So first term there, D and right enable is down here, that gives us these two ones. The P prime, where is it? So this zero, this zero, and this zero, but this zero is already covered, so we get two more ones from the other zeros of P, and then the rest is zero. All I'm doing is filling in the truth table, it's just this circuit's a little bit nasty, so I wanted to walk you through the process once of analyzing it. All right, so now we have this truth table that gives us Q plus and P in terms of D, right enable, and Q. Sometimes we call this kind of thing a next state table, because it tells you what's going to happen within a gate delay or two for the sequential feedback circuit. So let's take a look at this. Now what we did is we analyzed stable states, right? So we actually just went through the feedback loop until it's stabilized. You can do that pretty easily with this table by simply comparing Q with Q plus. If they're the same, that's a stable state. The system won't change anymore. So if you go look for those states, you get these six. So 0, 0, 1, 1, 0, 0, these are different, so it's not a stable state. 0, 0, 1, 1, 0, 1, not a stable state, 1, 1. So you got six stable states. And then we could use those stable states to come up with the truth table that we wrote down on Monday for the gated D latch. So if you take these, you get this truth table where I've condensed two groups of two into a single row of the truth table by saying, well, I don't care what D is. This line here, for example, could be D of 0, which is up here, 0, 0, 0, 1, or down here, 1, 0, 0, 1. So Q plus has gone away in this table. So these are just the stable states, the summary of stable states of the system. And that's what we had on Monday. With this bigger table, you can also then make a more compact truth table. So, for example, if you look at the rows where right enable is 1, so these two and these two, you might notice, then, well, what is Q plus, or compact next state table, I should have said. So Q plus is 0, 0, just like D. Down here, Q plus is 1, 1, also just like D. So in this case, Q plus is just D. So whenever right enable is 1, Q plus is D. So what about right enable equals 0? What's Q plus? Just Q? Let's see. These are the purple ones, so 0, Q is here, and Q plus is the same. And Q is here, and Q plus is the same. So yeah, that's right. So Q plus equals Q. So we could write this short table here where we say, well, the only dependence is actually right enable. And then we write Q plus in terms of the other input variables. So you saw something like that on Monday also, but we could write it this way, having derived it from our next state table here. So this is another next state table because we're again writing Q plus in terms of inputs. Now, you might have noticed, if you look carefully, that in these unstable states, not this one, but this one, we don't always have that P is Q prime. They're not always complements of each other. And of course, they should be for this particular design. The reason is that these unstable states actually are just transient. So once you go into these unstable states, by changing the input, actually you then move into another state. In some systems, they may oscillate forever. So we might give you something where some of these systems, they just go from one state to another and they go on forever. But in some cases, they might actually stabilize by moving from an unstable state, these uncolored ones here, into a stable state. So let's take a look at what happens with these two. So for this first one, we start at 0, 1, 1 for Q, but we're going to go to 0, 1, 0. And 0, 1, 0 is just above it right here. So we can draw that that way. So if we start in this state where Q was initially a 1, then by setting D and right-navel to 0 and 1, we'll force Q to 0. Once Q goes to 0, it's stable. And similarly down here, if we start with this input combination where Q plus is then going to change to a 1, that will move to the 1, 1, 1 state after Q is changed and will then be in this stable state. And you'll notice in those states, P is always Q complement. So in the gated D-latch, the two outputs are always Q and Q bar. You could imagine a system where that wasn't true. And if you look at this next state table with all of the logic, it might be a little confusing, so I wanted to explain that also. It's only the stable states that matter in terms of what you'll see coming out of the first one. Eric? Yes. Yeah, so they could oscillate between multiple states. I mean, if it goes to the same state, that's a stable state. So if it goes to another state and then that second state comes back to the first state, that would be oscillation. I'm not sure I understand the questions. Toggle between Q and D. So this is the same circuit we looked at before. This is a gated D-latch. So I can store a bit in it. I can build flip-flops out of it. It's the same circuit. I didn't change a circuit. I just changed how carefully I analyzed it. Yeah, so all we did on Monday was we simply looked for stable states. We didn't do all this detail. But when you have a different design, and in particular, the homework asks you for the next state table. So I didn't show you how to do that. Either one of these is fine. If you want to condense it like this, this is also a next state table. The idea is to map inputs, maybe some of the inputs, if that's possible, or all of the inputs into Q+. So the thing that tells you Q plus is a function of inputs is your next state table. Yeah, not really. Unfortunately, that's why the notation here should be Q star. Sequential feedback circuits are not clock synchronous. These are the latches and flip-flops that we're building clock synchronous designs from. So the plus notation usually means the discrete time. But in the homework, it uses Q plus to mean next state of a sequential feedback circuit. So you need to use the notation in the homework. Yeah, the only reason I showed you this was the homework. I mean, you need to know how to do this for the homework. You need to know how to find the stable states generally for the class. But analyzing sequential feedback circuits gets a lot more complicated, too, if you have more than one feedback loop, because then more than one bit can change, and actually either of them could change first if you think about all of the paths. Yeah. Yes, that's right. So if Q and Q plus are the same, that means it's stable. It's not going to move. You could certainly create such a circuit, not in this circuit. Yeah, that's a good question. So P, remember, in the way we broke this up, P is an intermediate variable, and Q is actually the feedback loop. There's only one feedback loop. So if the value of the feedback loop doesn't change, no input to the circuit changes. P was just an intermediate value. Yeah, so again, if you go, let me go back to the drawing. So there's actually only one loop in the circuit. So once we break that loop, if Q plus gives us the same original value that we assumed as an input, there's no change to any of the inputs. And so since there's no change to the inputs, there's no change to the outputs, and that means it's stable. Yeah, that's why. And P is just a side effect. P is just one of the variables you calculate in the middle of that combinational logic. And that has to do with the fact that if you look for cycles in the original design, there's one. And if you break that, there are none. In some designs, you could have more than one. And if you have more than one, you've got multiple bits to look at that might change. And if any of them change, you have to look at actually all possible paths, because any of them could change first. That's why we don't go very deeply into this. Most people, honestly, are not going to use this in their careers, I mean, not use sequential feedback circuit analysis. Unless you're designing the standard gate libraries or working in a company that does custom logic, you're very unlikely to design this kind of stuff. We just want to make sure you understand the ones that you will use every day, which are latches and flip-flops. Okay, so hopefully that won't pose a problem on the home page. Okay, so let's talk then about serialization of bit-slice designs. So if you think back to our bit-slice, we could generalize it a little bit with an abstract model. So bit-slice, it computes something based on p-input bits. So we had a bunch of different examples. We had a ripple-carry adder, where each of the bit-slices took one bit from A and B. So it might be p equals 2, or a comparator was the same thing, or if the one you did in the homework was an even-odd checker, you took one bit. So some number of bits from an operand or multiple operands, and produces some number of outputs. Each of the bit-slices might produce one output, might produce two, might produce zero. So there's some number of output bits per bit-slice. And then there are n bits passed from bit-slice to bit-slice. So in the ripple-carry adder, it's just one bit, the carry information. In the comparator, it was two bits. In the power-of-two checker we did, it was two bits. In the even-odd, I think, in the one you did in your homework, it was one bit. So you can generalize and just give those names. And then to handle n bits, we previously said, okay, let's just take n copies. Or if we had a – in the power-of-two checker we did in class, we took two bits for each of the bit-slices. So then n over 2. But now we know how to store bits. So instead, we can go back to – I think Sasha asked this question a week or two ago. Well, couldn't we store some bits in flip-flops and then use the same piece of physical hardware to compute the next slice? So we're going to go to the other extreme. So in this case, we're going to have one copy of the bit-slice. So this is a serial design. We'll copy the bit-slice, and we'll use flip-flops to store those n bits coming out. And then we'll just feed them right back into the bit-slice and use the next bit. And we'll keep doing that for n cycles, and that will give us the answer for an n-bit operand, or a set of n-bit operands. We'll call that a serial design. So it's not quite that simple because, well, what about the first bit-slice? So if all I do is I wire my flip-flops back up to the inputs, well, what's in the flip-flops when I turn the machine on? Bits? Probably bits. And actually, I know I told you it could be metastable, right? So it might not even be bits in this case. But let's just say bits. So there are bits, and that's not what we want, right? So when we designed our bit-slice designs, we said, well, we're going to put some fixed representation. So the adder, we usually feed a carry-in zero. So we want to use a subtractor, then we'll feed carry-in one. But we know there's some bits, particular bits, not just random bits, that we want to feed into the first bit-slice. And also, what about the last bit-slice? So in the Power of 2 checker, the bit-slice didn't actually produce the answer. It produced three different messages. And we had to use extra logic. It's simple, just an XOR gate. But we needed extra logic to calculate the answer. So we might need output logic. So here's a picture putting it all together. So there's our bit-slice. Here's the M flip-flops. We'll also latch the output bits. So every time, say, this is an adder, it computes one bit output, we'll put in a flip-flop. So some other logic can look at it in the flip-flop. And we'll bring these back over here, but we'll run it through some selection logic that allows us to say, well, this is the first bit, so we'll take our initial values and feed that into the bit-slice. Or we'll take the flip-flop values and feed those into the bit-slice. Once we're all done, the last bits out of the bit-slice, we can put through some output logic and compute the answer. So this is the general model of a serial design. So, okay, I guess I walked through it. So this output logic, then, is the same as the bit-slice design. So we already designed that for the bit-slice design. We just take it from the side of the bit-slice design, we just copy it into this design. Not very hard. F equals 1 means first bit. So usually these things will be 0s and 1s. Usually we don't need to allow them to be real inputs, they're just 0s and 1s. What do we need here for selection? Yeah. So, I mean, we need to choose between the initial values and the flip-flop values, right? So what components should we put there? Yeah, we could put muxes there. Muxes would do just fine. I'm actually going to optimize it a little more than that, but muxes would be a great answer. They would do just fine. So we could do muxes. We can optimize because it will be 0s and 1s. So let's optimize a little bit. The m flip-flops are going to store their bits into the selection logic, or feedback into the selection logic. So let me call those b sub i, and let's call the m bits produced for the first bit slice c sub i. So then we can say, let's assume a 0 in place of b i for the first bit. So let's say we have some b i, and we want to put a 0 in for the first bit. So when f equals 1, we want a 0, and then we can write a truth table. So when f equals 1, we get a 0. When f equals 0, we want to feed in the b sub i from the flip-flop. Yeah. Yeah, so b sub i is the bit coming back from the flip-flop. So between bit slices, we'll be feeding the flip-flop bit b sub i, and that's when it's not the first bit. So this truth table says, well, when it's not the first bit, take the flip-flop bit. When it is the first bit, let's say there's a constant 0. Yeah. So if we write this out, we can say, OK, well, the only non-zero term here is the f equals 0, so f prime times b sub i, and I could write that as a NOR gate, and then we just have one NOR gate. So pretty easy logic. Again, if you just put down a MUX, that's fine, but you can optimize your MUX away for one gate in this case. Similarly, if we say, well, when the first bit comes in, what if we assume a 1 bit instead? We can write that same truth table. So now for 1, we get 1. For 0, we still get b sub i. Now we'll actually use a POS form, so the only place we get a 0 is the f equals 0. So this is POS form for that, and of course, that comes out to be a NAND gate. So we still need that extra inverter, but one inverter and one gate. So we can optimize our MUXes down a little bit. So let me then walk you through an example. So we have this general model, and we have four parameters. We've got, I guess, five parameters, n bit operands, p bits of input from operands, q bits of output produced, m bits between slices, and at the end, we've got r bits of final output that are not on this diagram but produced by the output logic. So I wanted to see what the real size would be as opposed to abstract size. Yeah, it would be the same, right? A register is built out of flip-flops. It would be fine. I use an m bit register that's m flip-flops. Okay, so I mean, the other thing about the register is in this design, in the serial design, we want it to load every cycle. So having that extra load capability is a little bit of overkill. We don't need it. All right, so here's the parameters for the comparator. So this is just bringing up the old diagram of the comparator bit slice. So we had two bits coming in. So p equals 2. We have zero bits going out, so q equals 0. We've got n bits between bit slices. So m equals 2. Sorry, this is overloaded m. This was bit slice number m. But the number of bits between bit slices is 2. And then the number of bits for the final output was also 2. We needed to know, well, is a greater than, equal, or less than b. So we needed two bits of final output, too, so r equals 2. So this was then the representation we picked for those bits passed between bit slices. So which value should I be passing into the least significant bit for the comparator? Which assumption should I make going into the starting point, the first bit slice? 0, 0, right? We just assume a equals b when I haven't looked at any bits. So we'll pass in 0, 0. That'll be our initial values. So when we put this together, this is what we get. So I took just the general model. I plopped down the comparator bit slice here. We said m equals 2. So here are two flip-flops. We'll call them b1 and b0. The output logic was a no-op. Actually, I can walk through this. So input-output, there were two of them, a and b, right, one bit of each of the values being compared. No output flip-flops since q equals 0. So there's no extra flip-flops down under the bit slice. We had m equals 2. So those are those two flip-flops. z1 and z0 outputs are just latched into b1 and b0 flip-flops. This is initialized to 0 when f equals 1. Remember, that was a single NOR gate. So if f equals 1, both of these NOR gates output are 0, and we get c1, c0 equals 0, 0, just like you said we should. If the f equals 0, then we get the b1 complemented output, and we take that into the c1 input, because it's complemented here, and then the NOR gate complements it again. And then down here, we get b0 inverted coming out, going through the NOR gate gets inverted again, so b0 goes into c0. And then the last thing, this output logic does nothing. It's just empty box, because we didn't need to do anything extra in the case of the comparator. So that's our comparator design. So then let's think about, well, how does this compare? Actually, let's walk through and make sure we understand how it works. So what I've done here is just written down discrete time, right? So cycle count. So in cycle 0, these are inputs, f, a, and b. These are the bits of our numbers. Remember, we start with the least significant bit. So these are the least significant bits of a and b. And what's going to happen then is those will produce, let's go back and look at the diagram for a second. So we'll put f, a, and b, and then from those, we need to be able to calculate c1 and c0. And then we've also got b1 and b0 coming back into these gates over here. So maybe we need to know what those are first. And then we'll produce z1 and z0, which will go into b1 and b0 in the next cycle. So what's in b1 and b0 in cycle 0? Why should there be 0? Bits. Good answer. There are bits. We don't know what's in there. There's just some bits. We just started using this thing. There's going to be 0s or 1s in our flip-flops, but we don't know what they are. We don't know whether it's 0 or 1. We can, but you don't want to assume that this thing has never been used before. It should continue to work no matter how many times we use it. So whatever's left in there, you'll see at the end, we don't leave 0s in there. That's a good question. So that's my next question. What are c1 and c0? So your claim is they're both 0? So we can look back. So f equals 1, and we don't know what b1 and b0 are. So if f equals 1, what is c1? Can we know? So f is 1, and so what's c1? 0, right? So yes, in that case, it's not f. Not true if it's f equals 0, though. All right, so f equals 1 forces c1 to be 0 and c0 also to be 0. They're both NOR gates. So we don't need to know what was in b1 and b0. If we set f equal to 1, we're guaranteed c1 and c0 are both 0. So we don't care what was in those flip-flops the first cycle. And we shouldn't have to care. Otherwise, we would need to take another cycle to force them to 0. And that would take an extra cycle to do the computation. All right, so now we have all of our inputs to our bit slice. So now we do what the comparator does to calculate z1 and z0. So which one of these is bigger, a or b? b. OK, so you may or may not remember. The representation for that is z1 equals 0, z0 is 1. That says a less than b. That was our representation. Those two then get latched into b1, b0 in the next cycle. So only in cycle 1 do these values appear in the flip-flops. So that'll be important when we get down to the end. Because only after four cycles in the fourth cycle, starting counting from 0, will we be able to see our answer. So the answer is delayed until all of those four cycles have completely passed. It's discrete time, means a little bit of delay before you get your answer. Yeah. That's right. That's right. Yeah, OK, so we've done that copying. So now we need to decide, well, what inputs do we want to put into the comparator in cycle number 1, which is the second cycle? So as Rahul just said, f should now be 0 for the rest of our computation. There's only one first bit. We can do as many bits as we want. The way we do it, we put f equals 1 one cycle, and f equals 0 for as many as we want. You can do a 1,000-bit comparison with this thing if you'd like. We're only going to do four in class. All right, so here's some numbers. So f equals 0. Let's say the next two bits are 1 and 1. So what, in this case, will c1 and c0 be? 0, 1, right? Because since f is 0, basically b1 and b0 just get copied to c1 and c0. That's how the NOR gates work, the selection model. And so let's see. So this one says a less than b. a and b are equal here. So what should the answer be? I think 0, 1, right? So a is less than b. And then you've got bigger bits that are equal. So a is still less than b. OK. Yeah, this is a little tricky, because it implies actually doing the representation mapping twice in your head. So if you don't remember the representation, don't worry too much. We'd normally give it to you on a piece of paper. OK. So those then, 0, 1, get latched again into b1 and b0 flip-flops. OK. They're already there, but now they're copied again from the z1, z0 outputs into b1 and b0 in cycle 2. So here's cycle 2 inputs. Now we've got 1 for a, 0 for b. c1 and c0 are what? 0, 1, right? Those are just the same as b1, b0 when f is 0. OK. So in this case, remember the smaller bits come in first with our comparator design. So now the biggest bits, a is 1, b is 0. So which is bigger? a is bigger now. So 1, 0 means a is bigger than b. OK. Those get copied down. Yeah. Yeah, that's right. That's right. Yeah. Yeah. So the question is, will we ever be able to get z1, z0 both 0 again? And no, of course, once they're not equal, they can never be equal again. And so once you've got 0, 1, or 1, 0, you will continue to have 0, 1, or 1, 0 until you build up to 0, 1, or 1, 0. And that's the question. So what's the question? What's the answer? So the answer is, yes, you can. 0, 1, or 1, 0, you will continue to have 0, 1, or 1, 0 until you're done with your computation and start the next one, only when they match in all the bits. OK. So we'll copy those down for cycle 3. Put our inputs. In this case, I wanted to make it flip again. So now b is bigger. All right. So these get copied again because f is still 0. So b1, b0 go straight to c1, c0. And then what should z1, z0 be? 1 again. Good. Those two bits now get copied for cycle 4 into the flip-flops. Those are now our answer. So if you have a 4-bit, two 4-bit numbers you're comparing, after four cycles, you'll be able to see your answer on the outputs of the flip-flop. But you have to wait four full cycles because these flip-flops don't latch these values until the fourth cycle starts. Remember, they latch on the rising edge. That's why we can just write cycle 0, 1, 2, 3, 4. Yes. You mean to reduce it? You have to compare. Yeah. So in a serial design, we could do what we do as humans if we were going the other way. Right. If we were going the other direction, starting from the most significant bit, then in the cycle that we saw a difference, we could stop comparing. Yeah, so that's a good point. So in a bit-sliced design, we couldn't do that. And so the direction didn't make a difference. Yeah, but in this design, we can. As soon as we see a, we could put an OR gate on these two. And as soon as we see the OR gate produce non-zero, that means we know there's a difference. We know what the difference is. We can stop and see which direction this is. Yeah, that is one advantage of doing this serially. You could stop early, which I didn't actually point out in the slide. Good question. OK. Yeah, so remember that the flip-flops take the value on their D input at the rising edge of the clock and then store that new bit. Right. And so even though these outputs might be ready in the middle of one of these cycles, they only appear on the outputs of the flip-flop at the start of the next cycle after the rising clock edge. So that's why we have discrete time. You can assume that the outputs of the flip-flops hold that value for one complete clock cycle and that they don't change. But that implies you have to wait for the fourth clock cycle if you're doing 4-bit operands. And similarly, if you're doing 100-bit operands, you have to wait for the 100th clock cycle after the start of the next cycle. Absolutely. We'll go through in detail. So the question is, is this slower than the bit-sliced comparator I think you meant, right? And yes, it will be much slower. Yeah, it's a good question. It will be smaller but slower. Yeah, so you might be able to shortcut it in some cases. So the analysis is going to be a little harder. It'll depend on what data you put in. Right. Yeah, in this case, it's definitely slower. It depends what you want, right? Yeah, so it is a trade-off. And as always, when you have more than one metric, it depends on the context. If you're trying to put many, many of these on a chip, then you probably need them to be small. If, on the other hand, you want speed, you probably don't care as much about area. And so you probably try to use the faster design. And the context will tell you which one is a better choice for you. All right, so let me fill in some of these. So we don't know what comes in in the fourth cycle. We assume we're done with our computation. So let's say, well, I don't care about those. I put a 0 here because actually the b equals 0, b1 equals 0 implies that c1 equals 0, regardless of f. But these are actually unknown bits. So we don't know what's there. We could, in fact, start in cycle 4 a new comparison. So we can do back-to-back comparisons without having any extra time in between. We could put f equals 1 in initially and put a and b values for a next comparison. So we can use the comparator without an extra spare cycle in the middle. But from the point of view of our computation up here, we don't care what those values are. And we don't know what these values are. So put question marks around those. Well, they will if you put f equals 1. f equals 1, just like up here, f equals 1 forces those two to be 0. We didn't care what the bits were. Here, they're not 0. Here, they might not have been 0. f equals 1 forces c1 and c0 to be 0. That's why we're allowed to start a new comparison. All right, so let's take a look then at area first. And then we'll do delay. So what do we have? We've got one bit slice. We have two flip-flops. And then we have two NOR gates for the selection logic. So here's our bit slice design. We had two input NAND gates and two inverters. So six two-input NAND and two inverters for the bit slice. What about the flip-flops? So here's a flip-flop. We had two latches. And inside those latches, we had four two-input gates and an inverter. But actually, we can flip the sense of the inverter. If we instead use NOR gates instead of NAND gates in this latch, we don't need this inverter. So that one is actually, we can get rid of it. In fact, commercial designs will actually be smaller. So we'll assume the design we looked at. But if you really went and looked out at what people use in standard gate libraries, they're not as big as the design we did in class. You can do this kind of thing at the transistor level with fewer transistors. So here it would, because we've got a common clock. And so we would need to actually have the inverse clock to make sure the two were different. We wouldn't normally ship around both the clock and the inverse clock. If they're coming out of flip-flops. Yeah. Yeah. So now that we've seen where things come from, why they're free, we might start counting when we know they're not going to be free, when we'll need it. But in this case, we can absorb the inverter into the latch by using NOR gates and latch. Yeah. Oh, that's fine. Yeah. It would cause skew, and it would also just cost area. So the real counting, you want to just count anything that you would physically need to use. And so here, you don't need it because you can change the design of the latch to be an SR latch with NOR gates. Yeah. Well, I mean, it goes away, so it doesn't. Yeah. But that would be another issue if we're really adding logic. It would potentially introduce skew. Yeah. OK. So yeah, it's a good set of questions. I mean, real flip-flop design, people actually do add timing sometimes to give the illusion that you don't have to do it. They add timing sometimes to give the illusion that you don't have to wait for the signal to be latched. So we're going to assume that it takes four gate delays of stability before we can copy when we do the delay analysis. I'll explain that when we get there. But people usually shift that by adding delay inside the flip-flop. All right, so here's our count. So six two-input NAND, two inverters, 16 two-input gates, and four inverters. And so if we add that up, we've got 24 two-input gates and six inverters. So that's our serial design. So here it is down here, independent of N. It doesn't matter how many bits we're going to use. We've got the same number of gates there. Whereas if we do a bit-slice design, every bit-slice had six two-input gates and two inverters. So those are multiplied by the number of bit-slices. So those are about equal when N equals 4. And for N bigger than 4, the serial design is still there. For N smaller than 4, the serial design is small. So for any reasonable N, if you wanted to compare 16- or 32-bit numbers or 64-bit numbers, the serial design will be substantially smaller. But the serial design is also going to be a lot slower. So why? We just saw it's fewer, right? More gate delays. Yeah, you're also going to wait for the clock cycle, right? So this may not be the thing that determines the clock cycle, right? It might be some other logic. So this might be very fast compared to the clock cycle. But that doesn't matter. You still have to wait for N clock cycles. So let me put all the reasons. So one reason is all of the paths matter. So when we talked about the bit-slices, we said, well, only the slice-to-slice paths matter because all of the A and B bits come at time 0. That's no longer true. Those A and B bits are fed in one per cycle. They probably come out of flip-flops. So they're not coming at time negative infinity or time 0. They're coming at the start of the cycle. So the paths from A and B out to the Z1, Z0 outputs, now those matter more. That's one issue. Second issue, selection logic and flip-flops, those are not free either. There are gate delays inside those. And those count too. And we have to pay for those. And then the last one is, again, this may not be the slowest component in the system. The clock can't go faster than your longest combinational logic. So if this one happens to be the longest one, well, that's fine. Then only factors 1 and 2 will matter. If there's something else that's slower, your clock will run even more slowly. And as a result, your serial comparator will have to be slower because it has to go clock cycle by clock cycle. So let's look at each of these in a little more detail. So I guess I kind of said all of this. The paths, other than the slice-to-slice paths in our bit-slice design, only added constant time because all the A and B bits arrived at time 0. And so we looked at that in the first bit slice. And then even by the second bit slice in this design, they were not relevant anymore. Whereas the slice-to-slice paths, every time we went Z1, Z0 to C1, C0, we had to pay that for each bit slice. So that was the thing we multiplied by n. Now in the serial design, again, A and B are coming at the start of the cycle. So we have to make sure we pay for them to get all the way to the flip-flops. We have to wait for them to get to the flip-flops. The flip-flops and the selection logic take time to store values and to produce values. There are gate delays on both latches. And the selection logic sits between the flip-flops and the bit slices. So the clock cycle has to be long enough to account for all of those. And then finally, the longest path, I said this a couple times now, longest path through combinational logic will determine your clock speed. There's just one clock. So whatever that longest path is is how fast you can drive your clock. In practice, what engineers are going to be doing is going and identifying the complex or important parts of the circuit. Often in a computer, it might be the adder, because you do a lot of arithmetic. But they're going to figure out what those are and try hard to make them fast or split them up into several cycles. So if you look at floating point units, for example, they'll be fully pipelined, meaning that you can put a new set of operands every cycle. And then they'll go through and take many cycles, say eight cycles or more, to compute the answer for one set of operands. So engineers will work hard making sure those things work well and making sure they're not limiting the clock cycle, although at the end of the day, they may still be the things that limit the clock cycle. So even if a serial logic design only needs a tenth of a clock cycle, it doesn't matter. You still have to use n clock cycles to compute n bit operands. You can't make the clock go faster for this. Well, you could have separate clock domains, but typically people don't want to pay for that. Yeah. People have tried that off and on for a long time and have asynchronous circuits, and it's fairly difficult to get them to scale in any useful way. People are starting now to do separate clock domains for different parts of the design, partly because they can then turn them off independently, more than that they can necessarily change the clock speed independently. Although in the multiprocessor chips, having your processors run at different speeds is also useful, because the slower clock speed will still get some work done, but will be low of power consumption. Yes. Yes. Good question. So let me come back to that in a future slide. The question is, can't you put more than one bit slice and do a serial-like design, or maybe put two, three, four, et cetera? And yes, of course you can. So that will, let me come back to that. These are two extrema. Good question. My feeling is it's more the complexity is unmanageable than that it's, I mean, I've seen it in the research literature at least two or three times in the last couple of decades, and never did industry take off with it and do anything really exciting. I mean, there are a handful of academics that get really excited about it and do some interesting stuff, but you've got to be able to manage the complexity to the point that engineers can use it in a big design process, which is difficult. OK. So all right. So let's go through and analyze this delay. So we can count gate delays or bit slice for the selection logic. So what about the flip-flop? So let's just assume that it takes four gate delays of stable D input before the rising edge. So let's say we need that D input to be stable for four gate delays before the rising edge comes in order to guarantee we get the right value latched, and then four delays after the rising edge before the output shows up. So we'll just pick the number four. You could pick different numbers and do the same analysis. So let me show you the picture. So this output here will become available four gate delays after the rising edge. So if we start at the beginning of a cycle, this B1 will not be available until four gate delays later. That's what I mean. And similarly, if the D input arrives at time N, then we have to hold that for four more gate delays until N plus 4 before the next rising edge. So those are the two folds. Are we able to measure gate delays much? In terms of clock cycles, usually gate delays are much shorter than clock cycles. Usually not, because gate delays are an abstraction. The process variations will give you huge swings on how long things really take. Yeah, I mean, the accurate time measurements, the first thing to do would actually be go down to the transistor circuit level and do SPICE simulations. But that's beyond our class two. All right, so let's assume rising edge arrives at t equals 0. So now we're using time and gate delays again. So we're going to calculate gate delays for the minimum number of gate delays for one clock cycle. So these things, the q's and q bars, become available t equals 4. So we said we'll wait four gate delays after the rising edge. So at t equals 4, we get these outputs, b1 and b0. Let's just also assume f, a, and b, those are going to come from somewhere. So let's assume they come from some other flip-flops. So they also become available at four gate delays. So all of these inputs at four gate delays. This thing here, well, you've got f coming in at 4. You've got these coming in at 4. One more gate delay for the NOR gate. So you get the c inputs to the bit slice at five gate delays. So then let's go back to our bit slice. So this is just a slide from when we were analyzing it. So a to z1, we had three gate delays, ignoring this NOT. Remember that the a input is going to come from a flip-flop. We already paid four gate delays for that. So let's assume we already have a prime. b, we've got three gate delays. And c to z1, we've got two gate delays. So when we add that up, these are available at time five, but the path to the z outputs is only two gate delays. So that's 5 plus 2 is 7. a and b are time four. The path to z1 and z0 are three gate delays. 4 plus 3 is also 7. So we get z1 and z0 at time seven, seven gate delays. And then we have to wait four more gate delays before the flip-flops will actually latch those. We assume we need four gate delays of stable input before they can latch the value. So that means we've got 11 gate delays. So if you think back to our analysis of the bit slice design, we needed 2n plus 1 gate delays for n-bit operands. For a serial design, we've got our clock cycle has to be at least 11. And then we need n clock cycles. So we have at least 11 n gate delays for the serial design. And that means we're at least 5.5 times slower. And we may be even slower if some other part of the system sets the clock speed. So this was Sasha's question. So let me go through this briefly, and then we'll end. So these are simple designs, meaning the complexity is low. We said, look, let's just focus on a bit slice. So we're in this space of pretty easy-to-do designs, but we're still at two extrema. One is small but slow. That's the serial design. The other is fast but large. That's the bit slice design. You can build anything in between. Put two bit slices per cycle. It's very easy to do. Just put two side by side. And then n is probably easier if it's even then. If you put three, it's easier if it's a multiple of three. Probably you're going to want 16, 32 bits anyway. So putting four 8-bit slices, that's not hard to do. You'll get a smaller than fully bit slice design. You'll get a bigger than fully serial design. And it'll be basically points in that trade-off space as you use more bit slices, it'll get bigger but faster. So we can also optimize more than one bit slice. We can take two bit slices and just think of it as one function and maybe even get it into two-level logic, and then that'll also be a faster and smaller design. So you can optimize in that sense too. Yes, that's why it'll be a bigger design than serial, but it'll be faster than serial also. And it'll still be smaller unless you add n, for whatever n you want, it'll still be smaller than bit size. Yeah, you can optimize that function. So instead of saying, well, how do I do one bit, you could say, how do I do five bits or 10 bits? And I can solve that as one problem. And that'll be a better design. Yes, to some extent, the tools will help with that. OK, so let's stop there. And if you want to ask more, we can just come down afterwards. Because it's over time. I want to keep everyone. OK. OK. OK. OK. OK. OK. OK.\",\n",
       " \"Okay, I think it's actually three o'clock now, so let's go ahead and start. So today, I want to review a little bit, I think maybe I kind of sped through the first derivation of two's complement, so I'll back up and start that again, and then also do, in addition to the graphical derivation, we'll do an algebraic derivation. So I'll explain why we're doing two when we get there. Then we're going to talk about overflow for two's complement. So you've seen unsigned addition, you know that a carry out means overflow, meaning that the answer we get is wrong. That's what we mean by overflow. We may get to Boolean logic and go through a little bit of that today, otherwise we'll continue that next week. I had a post-lecture thought on Wednesday, someone had suggested that in the range, I think it was 100 to 131, that we should say 42, and I just completely failed to realize that 42 is 100 base square root 42, so that was good. So these things, oh, I meant to take it out of my bag. They're not connected. Oh, shoot. No. Ah, technology. I have to follow the rules. Let me use this opportunity to take this from my bag and show you. Here we go. So you can buy this thing for $18 if you'd like. It'd be working now. Still not working, huh? Okay. Sorry, I may end up wandering back and forth. You can buy this thing now for $18 in the ECE supply center, which is, you know, walk over to that side, turn left, go down to the end of the hall. Remember this is free online, so if you're happy looking at it on a computer screen somewhere or on your mobile or something, if that's comfortable for you, you don't need to pay for it. If you do want a hard copy, you can get it for $18, or you can print it yourself, too. It's always hard to gauge whether you will save or spend more money if you use your print quota to print class notes, but you have your options. I want to try one more time. Yeah, there we go. Okay. So remember, we decided we were going to try to use the same piece of hardware. So we've got a piece of hardware. Someone's designed to add unsigned numbers, just like base 2 arithmetic, right, adding two base 2 numbers. But this piece of hardware adds two numbers, and what it produces is the correct answer, mod 2 to the n. So we saw that the sum that comes out, the bit pattern that comes out, will be the correct answer, mod 2 to the n, and we wanted to develop a representation for signed integers that also allows us to use that same piece of hardware, and then we'll be able to use that one piece of hardware to add both signed and unsigned numbers, and that will be the 2's complement representation. So you might wonder, well, what is 2's complement? Where does that come from? We'll get there. So here's a circle. What you see around the circle inside are bit patterns, and outside you see decimal values. So this is a way to represent the, or to show, to illustrate the 3-bit unsigned representation. So the bit patterns are inside, the numbers they represent are outside. And if I use this circle idea, then I can think about addition as simply starting somewhere, and if I want to add, I'll count around clockwise. If I want to subtract, I'll count around counterclockwise. So for example, if I start at 4 and I add 3, I'll count around 3 spaces around the circle, and I'll get 7. So that's addition using this circle abstraction. And the answer is always correct, mod 8. So if we had started at 7 and added 4, we would go around 1, 2, 3, 4 spaces, and we'd get 3, which is not correct, but it's correct, mod 8, because 3 equals 11, mod 8. So if we want to subtract, we'd go the other way. And I said, well, OK, the circle, because arithmetic with unsigned addition is simply arithmetic mod 8, or 3-bit unsigned, rather, we can also use this as a way to illustrate modulus. So we'd go around the circle, we'd write down the numbers, just like we did, but we could keep going. So we could keep writing 8, 9, 10, 11. And if we did that, what you'd see is that each of these groups around the outside of the circle are just a bunch of numbers that are all equal mod 8. So you pick one, 2 and 10, 2 equals 10 mod 8. Remember being equal mod 8 means that I can add or subtract some number of 8s and get the other number. So I can also go in the counterclockwise direction. So I'm basically mapping the whole integer line onto the circle. And so I'll get 8 different groups, and each one will have an infinite number of integers. The overflow then happens because we can't have a representation where one bit pattern means all of these things. And the representation, remember, can't be ambiguous. Computers are not going to be able to guess which one was the right answer. So we have to pick one label. And when we pick a label, if it doesn't correspond to the correct answer, well, then that's where the overflow comes from. But we don't have to pick the labels we picked for unsigned. We don't have to pick 0 to 7 in this case. So we could pick some numbers in the positive direction, so say 1, 2, 3. And we could pick some numbers in the negative direction, say negative 1, negative 2, negative 3. And then we could try some addition. So we could go from negative 2, add 3. Again, corresponds to just going around the circle. So three steps. So negative 1, 0, 1. And you'd see that negative 2 plus 3 is, in fact, 1. Now, of course, we're going to get overflows, and the overflows will be different. So if, for example, we said, well, what's 2 plus 3? So we'd start at 2, and we'd go 1 space, 2 space, 3 spaces. And we'd say, oh, 2 plus 3 is negative 3. Well, that's not right. So we still have overflow problems. It's just that now we have a representation for signed integers. And we can use that using the same approach to arithmetic, in particular, the same hardware device to do the addition. So this is one way to derive 2's complement. So you want to know, well, what's the bit pattern for negative 3 in 3-bit 2's complement? Well, there it is. So you can get all of the bit patterns for 2's complement by doing it that way. So the general scheme, if you want to do it graphically, is outlined here. So you draw your circle, and there's a bigger circle in the notes, but you don't really want to draw the circle. But it's a good way to understand it. You draw your circle for n bits, 2 to the n points. You start at 0 at the top. You write your unsigned bit patterns clockwise around the circle down to the bottom. Those are your positive. Well, you write the bit patterns all the way around. You write the positive numbers around the right half of the circle, negative numbers around the left half of the circle. There's your 2's complement representation. So, yeah, question? So what is this 1, 0, 0 going to mean? Let me come back to that later. Good question. So the question is, well, I didn't label this thing. So what should we label it? Let me come back to that at the end. Good question. OK. So that's our approach. We can also do it algebraically. So why do I want to show you both ways? So it turns out that most students will understand the graphical approach or they'll understand the algebraic approach. They'll feel more comfortable with one or the other. They're completely mathematically equivalent, I assure you, 100%. If you understand one, it's good. You're done. You understand why we do 2's complement the way we do. So don't worry if you don't understand both. If you understand both, that's great. But I do want to show you the other one because some students will understand this one better than the graphical one. Let's do some algebra and see if we can find a way to get the same answer by doing algebra. So in algebra, remember that the adder is going to produce some bit pattern, which we're going to call sum. So if I add two bit patterns, A and B, then I get the answer sum. And that sum will represent the value A plus B, but only mod 2 to the n. So it might not be exactly the right pattern because I might not be able to fit the pattern A plus B into n bits. But it'll be equal mod 2 to the n. So when we define n bit 2's complement, the first step is, well, let's define the positive numbers. So we'll define 0 up to 2 to the n minus 1 minus 1. And those will look exactly like unsigned. So half of our bit patterns will turn into positive numbers. And those will be exactly the same representation as they were for unsigned. And then the problem is, how do we find the bit patterns for the negative numbers? So let's see what we can do. What do we need? What problem do we need to solve? So for every number that we have, let's call it a number k. So k is in this positive range I just talked about, from 0 up to 2 to the n minus 1 minus 1. So for every positive number, we have to find a bit pattern that's going to represent negative k. That way, we can represent for every positive number we have, we can represent its negative value also. So somehow we have to find that bit pattern. The bit pattern has to have n bits. So if we look at that bit pattern as a base 2 number, it has to be from 0 up to 2 to the n minus 1. And if it's bigger, it won't fit in n bits. So it's no good. And then we have to pick the pattern in such a way that if we take any integer m, and we add m to negative k, then that's the same as adding this bit pattern we're going to pick to represent negative k, p sub k. So if those two are equal, mod 2 to the n, then the bit pattern k will give us the right answer when we plug that bit pattern into this piece of hardware that someone built for us, that does unsigned addition. The other constraint, so let's say we find a good bit pattern. If that bit pattern is the same bit pattern as a positive number, then we have ambiguity. So the bit patterns we find, they can't be the same bit patterns we've already used to represent positive numbers. So remember, we used all of the bit patterns starting with a 0. We used all 0s means 0, 0 followed by anything else means a positive number. So whatever bit patterns we pick, they better start with 1. So now to solve this problem, we'll do some algebra. So we've got a property up there, I just copied it. So that's what we need to solve. So let's subtract m from both sides. And remember that addition and multiplication distribute across the modulus operation. So we can just say, OK, subtract m from both sides. I can subtract m from both sides of the equation inside, and this will continue to hold. So subtract m from this side, I get minus k. Subtract m from this side, I get p sub k. And negative k equals p sub k mod 2 to the n. So then I want you to remember that, well, 2 to the n equals 0 mod 2 to the n. If I add 1 2 to the n to 0, I get 2 to the n. So those two are equal. And then I can add those two equations. So on the left, I'll get minus k plus 2 to the n, or 2 to the n minus k. And on the right, I'll get pk plus 0, which is pk. So 2 to the n minus k equals pk mod 2 to the n. That's what we need to solve. Turns out there's one easy solution to that, which is just to say, well, why don't I just pick the p sub k, where p sub k is actually equal to 2 to the n minus k. It just has to be equal mod 2 to the n. But let's just pick the one where it's actually equal, period, not mod 2 to the n. Now in that case, we have k running from 0 up to 2 to the n minus 1 minus 1. So if you plug that in, you'll see that that means the patterns we have are at least as big as 2 to the n minus 1 plus 1, and no bigger than 2 to the n minus 1. In other words, they're all n-bit patterns, and they all start with 1. But those are all the patterns, the bit patterns, we didn't use for the positive numbers, and we didn't use for 0. So those are all free patterns. So now we have an algebraic definition. We're done. Negative k is represented by this pattern 2 to the n minus k. So that's an algebraic definition for 2's complement. It's fully equivalent to the graphical derivation. If you do it one way, the other way, you'll get exactly the same answers, and you'll have the 2's complement representation. Having done it this way, you can then use the same piece of hardware to do addition, subtraction, et cetera, for 2's complement and unsigned values. Oops. All right. Ready for the name? You can tell. OK. So let's do some sanity checks. So if I take negative k and I negate it, negative negative k, I better get back the same answer, right? I want to make sure, in fact, I do. So what's the bit pattern for negative negative k? So we said, well, negative k is given by 2 to the n minus k. So we can substitute once. We can replace negative k with 2 to the n minus k, and that gives us this expression here, negative quantity 2 to the n minus k. And then we can substitute again, because we should just be able to negate that parenthesized value. And what we'll get is 2 to the n minus the quantity 2 to the n minus k, which then we can just cancel the 2 to the n's, and we'll get k. So that gives us the right answer. So that's good. I mean, if it didn't give us the right answer, that would be kind of disturbing. That would mean something's wrong with the representation mathematically. OK. So let's do that. So when I want to calculate negative k, how do I do it? Well, I go calculate the bit pattern, 2 to the n minus k. So one way to do that is you line them up and you subtract. You can do it that way if you want. I don't like doing it that way. It's painful. It involves a lot of borrowing. You've got a bunch of zeros there. You've got to do all these borrows. So instead, remember that I can write 2 to the n as 2 to the n minus 1 plus 1. So how does that help? Let's write that down. So we're going to calculate 2 to the n minus 1 and then subtract k and then add the 1 back in. So for n equals 5, what is 2 to the n minus 1? Well, it's 1, 1, 1, 1, 1, 5 ones. For n equals 20, it's 20 ones. For n equals 100, it's 100 ones. So now the subtraction is a heck of a lot easier. It's easier to subtract in decimal from 9, 9, 9, 9, 9 because you never have to borrow. So here in binary, we subtract from 1, 1, 1, 1, 1. We never have to borrow. All I have to do is say, well, if I have a 0, I put a 1. If I have a 1, I put a 0. It's called the ones complement. Adding one more gives you the twos complement. Engineers are so funny. Yeah, it's not a funny joke, I know. But that's where twos complement comes from, at least in my urban legend version. So if you want to remember, it's the ones complement plus 1. Wow, no one laughed. I'm sad. Even at my funny laughing. All right, now you're laughing. Good. So I want to just mention this because you will hear a lot of terminology. In engineering, engineers try to be precise. We try to say exactly what we mean. We define things mathematically. We mean precise things about what we're working with. Unfortunately, once those terms get out into sales and marketing and just general use, they tend to get abused and misused. And so this term, it comes from different places. But we'll try to be consistent in the stuff we give you, assignments, exams, things like that. You will hear the phrase, take the twos complement. And by that, people mean negate a bit pattern. We'll try not to say it that way because people do get confused, especially when they're just learning between the twos complement representation and negation. So taking the twos complement as a negation operation, you can take any bunch of bits and you can apply this negation operation we just talked about. Now whether or not the bits should be interpreted as a twos complement number or not, that's up to a human. Bits are bits. The computer doesn't know what the bits are. So it's up to you as the human to say, well, these bits are twos complement number. And so it's OK to negate them using twos complement representation. So we'll talk about when we want you to do something like calculate the ones complement and add one, we'll say negation instead of take the twos complement. And for clarity, I suggest you try to do the same. Otherwise we might have some confusion when we talk. Is that what? Will the two add up to zero? So if you add k to negative k, will the two add to zero? Yes, they absolutely will. So if you add ones complement, then they will add up to 1, 1, 1, 1, 1, however many ones in your representation. Because everywhere you have a 1, you have a 0 and the other and the negative. So ones complement actually was a computer representation. And you have to go back and replace the 1, 1, 1 pattern with 0 because that's 0. So it makes, again, the hardware more complicated. We don't really talk about it in the class, but it is another way to do negative numbers. Good question. Yes, Eric. Yeah, so, OK, so the question, I want to repeat it so it's on the video. The question is, you know, am I saying it's different because there are many ways to negate but twos complement is a particular style? Yes and no. Twos complement is a representation. It's a way of saying, for some decimal value, how do I come up with a bit pattern? And so I want to keep that away from operations like negation using that particular representation. So yes, what you said is correct, that negation on a different representation is done differently. So if we just sit down and randomly assign numbers to bit patterns, negation would involve looking at whatever table we drew. Here it's more systematic because it's designed to be simple so that the negation process is systematic. And negation only applies for twos complement, the way we've defined it. But I'd like to use twos complement only to describe the representation for signed integers that we've just talked about. So that's why I just find it confusing to use it as a verb, say, take the twos complement, because I found students have gotten themselves kind of tangled up in differentiating between operations on bits and the representations, which is just a question of how you represent using a bit pattern a particular decimal number. Any other questions? Okay, good. Okay, so let's do an example. So as you know, I like 42. You may remember that 42 in 8-bit twos complement, as well as unsigned, is represented by this bit pattern 00101010. And so to negate that number, to calculate negative 42, first we'll complement the bits. So I will take 0 and replace it with 1, 0 with 1, so forth. So this is the ones complement of that bit pattern. And then I'll add 1 to that, and that will give me this answer here, where I've negated the bit pattern and gotten the twos complement representation for negative 42. So there's an example. And if you wanted to, you could add these two up. I don't have it drawn for you. But if you wanted to add these two up, then what you'll see is that you get zeros in every position and that the 1 carries out. So and that high 1, of course, will be thrown away from the n-bit representation. So you get all zeros with a carry out if you add k to negative k for any k, except 0. But negative 0 is the same. So how do we convert between twos complement and decimal? For any non-negative number, it's the same. The representation is the same. The bit pattern is the same in unsigned twos complement for all of our non-negative values. And so converting from decimal to twos complement for those numbers is identical. You can go either direction, do the same process we talked about earlier in the week. What about negative numbers? So one way to do it is if you've got some decimal d less than 0 that you want to find the bit pattern in twos complement, first convert negative d. So that'll be a non-negative number. It'll actually be a positive number. And then negate the resulting bit pattern. So take the answer you get and just negate it. And that'll give you the bit pattern for d, which is, again, negative. If you want to go the other direction to convert a twos complement bit pattern into decimal, well you can start by negating the bit pattern. That'll give you a positive number. And then you can convert that to decimal using the unsigned approach. And then the answer is minus d. So if you calculate decimal d, the answer is minus d. So that's one way you can do it. Students usually find this way easier. And you can see the polynomial up here. And you might think, I don't want to write polynomials. But let me just walk you through it. And then you'll see the answer at the end. I just want you to understand why the approach works. So let's say we have some negative number, negative k. And we want to calculate the bit pattern. I'm sorry, we've got the bit pattern. We want to calculate the value negative k. We know it's negative because the first bit is a 1. So how will we do that? Well, the bit pattern is going to have the value 2 to the n minus k, as we talked about. So we can write our polynomial, which you might remember from a couple days ago. And we know that a sub n minus 1 equals 1, right? Because that's how we know it's a negative number. So if we plug that in, we've got a 2 to the n minus 1 over here. And we could subtract this 2 to the n from both sides. That'll give us this equation down here. This part of the polynomial is identical. The only thing that's changed, so on the left, we no longer have our 2 to the n. And then on the right, we have 2 to the n minus 1 minus 2 to the n, right? In other words, this thing is minus 2 to the n minus 1. So I can replace that then. I know, again, a sub n minus 1 is 1. So I can say minus a sub n minus 1 2 to the n minus 1. So now if you look at this polynomial, it looks exactly the same as the one we used with place value for unsigned, except that we put a negative sign on this leading bit. That's the only difference. So if you want to calculate the value of a 2's complement number, you can use this equation. Instead of counting the first bit as 2 to the n minus 1, count it as negative 2 to the n minus 1. And that'll give you the right decimal answer. So that's the way people mostly prefer, it seems, rather than doing it as I explained on the last slide. I do want to point out, this way also works when a sub n minus 1 equals 0, right? So for non-negative numbers, this thing is 0. And so this term just goes away. And then what you're left with is identical to the unsigned equation. So either way, you can use this approach, where all you do is negate the first bit's value to calculate the value of a 2's complement bit pattern, whether it's positive or negative, doesn't matter. That make sense? Kind of, yeah. And if you want to go through the algebra, make sure you understand it. It's fine. But this approach definitely works. I just wanted to illustrate why. Yeah. Yeah, sure. Let's go over to Notepad then. Good idea. So the question is, can I show an example? So let's write up a random, somewhat random. There's 8 bits, huh? OK, so our place values then are 128, so rather negative 128. That's 2 to the 7th. And that didn't work. Sorry. See what I'm doing. Oh, wow. I think it's because I'm on HDMI. OK, so I will then turn that on. And this will not work well on the little grim. Sorry about this. This is not the best. We'll try to make it big enough for you. Let's just do 6-bit. It's kind of the same. And I think it'll save me space on the board. So hopefully, everyone can see it. Can you see it on the right side? You can see it? OK. So we've got 111001. So the place values here are 1, 2, 4, 8, 16, and instead of 32, negative 32. So we've got negative 32 plus 16 plus 8. The 4 in the 2 places are 0, so we don't add those. So we've got negative 32 plus 16 plus 8 plus 1. So let's just add up the positive parts. So 16 plus 8 is 24 plus 1 is 25. 25 minus 32 is negative 7. Question. So again, that was, I guess I didn't need to turn this off in that case. Ah, OK. It comes back only when I do PowerPoint. That was what we derived as this equation for interpreting two's complement bit patterns as decimal. So by this derivation, we showed that we can plug in this equation. Then that'll give us the value negative k of a particular pattern. The negative k on the left, if it's positive, is just the positive part. We don't actually negate it or anything. This equation on the right will give you the right answer for both non-negative and negative two's complement bit patterns. But here's an example. This is negative 7. And had we gone the other way, so maybe I'll try to do it on the right. So 111001. You can see this over there? So let's take one's complement, so I get 000110. And then I'll add 1 to that. And I'll get 000111. And then if you look at this pattern, this is the 4's place. That's too small. This is the 4's place, the 2's place, and the 1's place. So you add those up, you get 7. So again, negative 7. So regardless of which way we do it, we get the same answer. I think most people find this way simpler, in my experience. So it's OK if you didn't follow the algebra. I'd encourage you to go back and understand it. So the question is, are we going to ask you to prove this, or do we just want you to know why it works? I just want you to know why it works. So let me come back to you in a second. So there's a guy named George Polia who used to teach at Stanford, who has a math dictionary, really. And he thought that the way you learn math and the way you become good at math is to see different mathematical techniques, and then to pull those out of your toolbox and use them. So I will try to expose you to different approaches, different proof styles, different ideas in mathematics that underlie what we're doing in digital design and digital systems. We won't, for the most part in this class, ask you to do a lot of proofs. Honestly, a lot of the optimization and things like that will be automatically done for you these days by computer-aided design tools. But we want you to understand how they work. So there's a certain amount of things that you'll see in the next few weeks, but not proofs. So this one, we just want you to know why this particular equation works. OK, and sorry, someone here. Yeah. So first of all, if I just draw some bits for you, you have no idea what it means, which is something that hopefully came up in discussion section yesterday. But if I tell you it's 2's complement, then you can look at this bit and say, oh, it's negative. So 1 means negative. 0 means non-negative. Yes, yes. So if we go back, I put down my little clicker, sorry. If we go back a slide or two. So negate the bit pattern. We did that. Convert to decimal, we got 7. Answer is negative 7. Yeah. Yes. Yes. That's right. First bit will tell you whether it's actually negative or non-negative. 0 starts with a 0 also. Good question. OK. Anything else? Yeah. Yeah. So if the number starts with 1, that means it's negative, then you can do it either way. You can negate the bit pattern, convert to decimal d. That's what we did over here. So the number started with a 1. So we took the 1's complement, added 1. That gave us the negated bit pattern. Calculated the value of this negated bit pattern is 7. And the answer is negative 7. Or we can simply plug into the place values with the first place value negated over here and add up these numbers. Instead, we'll get the same answer. So either approach works. Next slide. Oh, the top part? OK. So if you have a number, so let's say that we wanted to do negative 42. Actually, I did it already. Where did I do it? Let's go backwards. I did it here. So if you want to know what negative 42 is, you start by calculating 42. And then you negate it. And that gives you the answer. That was all. That make sense? OK. I'm sorry, I can't hear you very well. Yeah. So the question is, is there a reason that the process works this way in base 2? This is not human base 2. I mean, in human base 2, we write a negative sign. This is a particular representation that we chose to use the mathematical idea of modulus to define. And because of the way we defined it algebraically or graphically, you get the same answer. That's why this process works for negation, basically. If you look at the algebra, well, because we defined it to work for negation, mod 2 to the n. By definition, that's why it works. OK, yeah. There is not. There is not. So no negative 0. Yeah. OK, yeah. So there are resources available online. Also, the lectures are being videotaped, and the slides are online. So all of those resources, thanks for pointing that out. I mean calculating the bit pattern for the negative value of what's being represented. So here, this bit pattern represents 42. So if you want to calculate the bit pattern for negative 42, you would take the ones complement and then add 1. And that would negate the value of the bit pattern and give you a different bit pattern. All right. Let's move forward. What did we see? That one worked. OK, so now back to your question. So you said, well, what about that last bit pattern? What is that? So what should it be? Should it be 2 to the n minus 1? We could make it be 4, the 3 bit, 2's complement. Maybe negative 2 to the n minus 1. Could be negative 4. We could just say, just leave it undefined. So what do you think it should be? Yeah, negative 4. Why? Starts with a 1. Good answer. So that's why. So it's a little imbalanced. But in 2's complement, the 1 leftover bit pattern is always negative 2 to the n minus 1, because that way, this simple approach of, well, just look at the first bit, and that'll tell you non-negative or negative still works. If you chose another answer, it wouldn't work. If you chose to make it 4, you would have to look at all of the bits to tell, well, is it positive or negative? So instead of doing that, we always choose, or rather, 2's complement is defined for that to be negative 2 and 2 to the n minus 1. So I added a couple of these in today. And I guess I can't flip and show you the tools, because I'm on the wrong interface here. So sorry about that. If you want to practice conversion, there is the online tool that will give you instant feedback. It will let you do as many examples as you want in 2's complement as well. It will also let you do this extension I'm about to show you. And so all of these things, you can go play with the tool, get experience, get feedback on whether your answers are right or wrong. So sometimes we might need to take one bit pattern in a certain size representation, say n bits, and extend it to an n plus k bit representation. So we might have, for example, 5 bit unsigned, and we want to create 10 bit unsigned. So how do we do that? So if I have a 5 bit unsigned number, and I tell you I want the same number, but I want the 10 bit unsigned representation for that number, how would you find that? Yeah. Yeah, exactly. So add some leading zeros. We based it on base 2. We based the whole representation for unsigned on base 2. And we had to add leading zeros already. So if you want a bigger set of bits, we'll add some more zeros. Not so hard, right? OK, good. Good answer. Zero extension. We have a name for it. What about 2's complement? Ah, good. So Eric says it depends on the leading number. So for non-negative values, that's the right answer. Let's do it one case at a time. So non-negative values, 2's complement is the same as unsigned. All the non-negative numbers are the same. So we just add k more leading zeros, just like we did with unsigned. So that's easy. What about negative values? What do we do there? OK, let's do some examples. So I was going to do these on Notepad, so sorry, that's not going to work. So negative 5 has this bit pattern, 1, 1, 0, 0, 1, 1. We'll do something concrete. So we have these two 5-bit patterns. So let's see, 1, 1, 0, 0, 1. Is that right? 0, 1, 1. OK, so this is negative 5. So how about the 8-bit 2's complement representation of minus 5? OK, so let's do that. So to get 5, I'll go to this 1's complement, and then I'll add 1. So this is 5. And then you just told me I can convert positive values by adding zeros, right? And then I'll convert back. And I have to add 1 again, right? So this is negative 5 in 8-bit 2's complement. Anyone notice anything? I just added some 1's. You understand why that's going to be the same every time? Yeah. Yeah, so basically, going around the top of the circle into the negative part, negative 1 is always going to be the all 1's pattern, right? And so forth and so on. They're always going to have the same ending bits. Here, the other way to think about it is when I go back and I add my leading 0's, those just become leading 1's when I negate again. My leading 0's become leading 1's. So negative 5 is 1, 1, 1, 1, 1, 1, 0, 1, 1, just as we just derived. And negative 10, what do you think? Good. 1, 1, 1, 1, 0. So what about this space? It's just for us. Computers don't have those spaces. All right, so that was just to make it obvious on the slide. So how do we convert? We take the sine bit and we copy it. It's called sine extension. So if you want to extend from a smaller representation, smaller 2's complement representation, to a bigger one, you take the sine bit and you copy it. If you want a bigger one, you take the sine bit and you make k extra copies of it. You want to go from n to n plus k. All righty, so now we need to start thinking about arithmetic again. We know how to do overflow checking for unsigned. We decided, well, we do the operation. We add two numbers together. We get a carry out. That's going to be an overflow, because we have to throw that carry away. We don't have space for it. So what about 2's complement? When I add two 2's complement numbers with n bits each, how do I know if it's right or wrong? Let's go look. Supposed to be base 2 addition, supposed to work exactly the same way. Let's take a look. So here's the first example we did with unsigned. So let's do it again. So I have 14 on top. I've got 4 on the bottom. Those are also the representations in 2's complement. So let's add them up. So 0 plus 0 on the right. Good. 1 plus 0, 1. 1 plus 1, 0 carry the 1. It'd be really embarrassing if I made a mistake. All right. 1 plus 1 plus 0, carry the 1. OK, 1 plus 0 plus 0. Good. OK. So when we did our unsigned, this gave us the right answer. And if you look at that as unsigned, you say, OK, well, that's 18. And then you're happy. So what is this in 2's complement? It's not 18. 18 you can't represent. So it's negative 14. So something went wrong. So we had an overflow, even though we didn't have a carry out. So carry out is not going to tell us quite overflow with 2's complement. Now I want you to notice something. The arithmetic is exactly the same. We didn't do anything different than when we added these bit patterns. And of course, that has to be true, because we defined this representation so that we could use the same process to add numbers. So if someone asks you, well, can you add this in 2's complement? Now can you add it in unsigned? Well, you probably don't need to do it twice. It's the same. How you interpret the answer, though, is different. So here, if we interpret the answer as 2's complement, the answer is wrong. So this is an overflow. All right, let's do another example. So this was the second example we did. This one overflowed for unsigned. So in unsigned, this was 14 plus 21. And I said, oh, you should remember that that equals 3. So I've kind of given away what we're going to get. But let's go ahead and do it. So 0 plus 1 is what? 1. 1 plus 0? 1. 1 plus 1? 0 to the 1. 1 plus 1 plus 0? 1 plus 0 plus 1? 0 to the 1. And yeah, that one's a carry out. But we've got to throw it away. No space. So what we get is 0, 0, 0, 1, 1. And when we interpret that as 2's complement, what was on top was 14. What's on the bottom is minus 11. 14 plus minus 11 is 3. So it was right. So no overflow. So we had a carry out, but we didn't get an overflow. So carry out is not overflow for 2's complement. How do we tell? How do we know when something's gone wrong? So I claim that if I add 2's complement numbers, and one of them is negative, and one of them is non-negative, that never overflows. That's my claim. Ready for the proof? Good, get to work. Yeah, Eric. Yes, that's a very good way to prove it. So Eric suggests that one way to prove it is that if you look at the range, and you then contain one number to be in the positive range, and the other number to be in the non-negative, and the other number to be in the negative range, and then you look at the possible range for the sum, those will always be representable answers. And yeah, that would be enough proof for this claim. That's right. Good, quick answer. So once you do it, you can go see if my answer in the notes is correct. So everyone else should prove it to themselves, and then go read it. So, very good answer. So let me give you a long definition, again without a proof. So if I add these two numbers where the sign bit is A and the sign bit is B, and I get the answer sign bit is S, I claim the following. And so let's make sure you believe me, at least in these two cases. So if the two add ends, A and B, well, A and B are the sign bits. But if these two things I'm trying to add are both non-negative, and then the answer I get is negative, that's wrong. You believe that, right? If I add two non-negative numbers, I get a negative answer, that can't be right. What if I go the other way? So this second case down here, the two add ends are negative. I add two negative numbers, and I get a non-negative answer. Also wrong. So I think people agree with those. The hard part of this proof is actually the other direction, showing that if my answer is wrong, it has to be one of these two cases. So again, proof's in the notes. You should figure it out, and then go read that proof, and check that I got it right. That's a lot of words. Engineers hate words. I was going to joke you should say this five times quickly for me so you remember it. I won't put you through that. All right, so there's a more concise way to write that using Boolean algebra. So I'll explain what Boolean algebra is in a minute, but this is how we would write overflow. So overflow is equal to not A and not B and C, or A and B and not C. So A, B, and C were the sign bits. So what do these ands and ors and stuff mean? So they're Boolean operators. So what is Boolean algebra? So these Boolean operators were invented by a guy named George Boole to reason about logical propositions about 150 years ago, a little more. Originally, they were operating on true and false, but we're digital system designers. So what are we going to operate on? Bits. Good. Everything is bits. Zero is false. One is true. Be careful not to confuse these operators with English words. They don't mean the same thing, and it's easy to do. So do not confuse them. The meanings are not the same. They happen to be English words, but the meanings are not the same. And I don't think we're going to get through them all today, but I'll emphasize that as we go through them. So I think we can go through this brief. Actually, maybe I'll give you examples here. So there are four that I'm going to tell you about. So the first one is AND. AND is the all function. So you can have any number of inputs for an AND, and the output is a 1 if all of the inputs are equal to 1. Otherwise, the output is 0. So that's how we define the AND function as the all function. Yeah, so let's say you're operating on four different operands. If any of the, I'm sorry, if all of those operands are 1, then the output of the AND function is also a 1. And otherwise, it's a 0. So it only gives a 1 if all of its inputs are 1, if all of the operands are 1. The OR function, that's similar to how we usually use AND in English. That's one reason it's confusing. OR is going to be different. So OR, you should think of as the any function. So we'll have some number of inputs, some number of input operands. And if any of them is equal to a 1, the output will be a 1. So that's the OR function. So this is very different from English. If I invite you to my house and I say, oh, would you like some coffee, tea, milk, or orange juice? And you say, yeah, all of them. I might think you're a little rude. Usually, people mean, yeah, would you like to pick something to drink? Not, hey, why don't you just take all the liquids in my house? So in English, sometimes people say that English is exclusive OR. And by that, they mean, well, you should pick one of. But we have an exclusive OR in Boolean logic, and it doesn't mean one of. So exclusive OR, let me jump down here. Exclusive OR is the odd function. So exclusive OR, XOR, as we usually call it, returns a 1 if an odd number of the inputs are 1. So when you have two inputs, that's sort of similar to English OR. But for more inputs, it's not the same. So XOR is the odd function. And then finally, we have the NOT function. And NOT is simply the logical complement. So if you say NOT of 0, that's a 1. If you say NOT of 1, that's a 0. So I want to show you the truth table. So this thing is going to help us understand different Boolean operations. There's another tool that you can use to familiarize yourself with truth tables if you want. You can go play with them. But this is truth table. This is what it looks like. So you can see on the left, we have the inputs, A and B. And underneath those, we have all the possible combinations of those inputs. So for two inputs, we have four different combinations, four bit patterns. And on the right, we have space to write the output for a particular expression, for a particular Boolean expression operating on A and B. So usually, we list these in binary order. So we'll start with 0 and then 0, 1, 1, 0, 1, 1. So what we'll do, I think, starting on Monday, is go through each of those four Boolean functions and build up the truth table for them. So quick question? OK, I'll leave this up. So thanks. I'll let everyone go. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\",\n",
       " \"Okay, so let's go ahead and get started. A couple of administrivial things to start. So we will, so there's this feedback survey. So if you haven't done that already, please try to do it before midnight. Today we will finish off our serial comparator. I have a few more comments to make. I'll do another example, somewhat faster for Power2Checker, and then start in on finite state machines. So most of today will be an example to introduce the tools that we use to design finite state machines. And then we'll do counters and things like that on Wednesday. So I know there's some FSM problems on the homework. So sorry for being a little late in that regard, but I like this ordering better. I think it's better to understand the serial stuff because it's a little simpler. So that's the plan for today. I wanted to remind you we have a midterm. Today's the last day to sign up for conflict on the wiki. So if you haven't done that, you have a conflict with this time and date, please do that. There's also, so section 2.8 of the notes plus reading, writing, truth tables from last time, since the other lecturers haven't done that yet. There are the notes on the wiki, they have a lot of extra content. So things like T flip-flops are not part of the class. So if you're looking at those, do ignore that extra content. And if you need to know if something's included, look at note section 2.8. That'll give you all of the learning objectives for this part of the class. So in the notes, every part of the class has basically two pages of learning objectives for that quarter of the class. We'll have a review section next Monday. So a week from today, we'll do what we did for the first midterm, go through topics of your choice and review. So come prepared with your choice of topics, and we'll vote on them. Okay, so I wanted to take a little bit of a review. So this was our serial comparator. We adapted from the general model, so we initialized it to 0, 0 when f equals 1. And then we had our single bit slice here. The outputs of the bit slice got stored in the two flip-flops, and then those are cycled back to execute on the comparator in the next cycle. And you've got one bit of A and B operands coming in each cycle as well. And then we just look at those two outputs from the bit slice as our answer, A less than, equal, or greater than B. Yes, so the serialization, it just means that it's operating over time, rather than simultaneously in parallel. So the bit slice design, everything happens, and then there is gate delay, but it's logically inside of, say, a clock cycle, whereas this design is operating over many clock cycles, using the same hardware. So something in between, where, say, you had two bit slices, would be a mixture of the two. Okay, so then we compared area and delay. And so the area gave us that the serial design was smaller for four or more bits, and that was because it was constant size, kind of the flip-flop, so you needed to have a few bit slices in the bit slice design before they were equivalent. But n equals four is pretty small, so generally the serial design will be smaller. On the other hand, the serial designs are slower for several reasons. One is that all of the paths matter, right? So when we look at the A and B paths to the inter-slice outputs, usually we can ignore those in a bit slice design, because all of the bits from A and B show up at time zero, whereas in a serial design, every clock cycle we get a new bit of A and B, so we have to count those. The flip-flop and selection logic, of course, have gate delays inside those, and then whatever is setting the clock speed for the system might be slower than our serial comparator or serial anything, so that's another aspect there. So when we did the side-by-side comparison, we found that the serial design was going to be at least five and a half times slower, maybe even worse, depending on what sets the clock speed. Okay, so this is kind of where we left off on Friday. We said, well, those are two extrema points, right? You can do one bit slice and use that fully serial. You can do n bit slices and use that effectively fully within a clock cycle, but you can do anything in between two. You can do two bit slices, three bit slices, whatever, and you can also optimize, right? So you can say, well, let me go do a single function that compares two bits at once. So if you look in the notes, there's actually one of those designs. We did a design in class, actually, where we looked for powers of two, two bits at a time. So the more bits you look at, the better your design will be, both in area and delay, but the trade-off there is complexity. If you try to look at a two 32-bit numbers and write down the Boolean expression for which one is bigger than the other, it's going to take you a little bit of time. So higher complexity, more likely to make a mistake when you try to build it, but in return, you get better area and better delay. So I wanted to give you one practical example where people have done this kind of trade-off in practice. So there was a generation of Intel processors, I think around the turn of the millennium, around P4 generation, that actually internally, it was still a 32-bit machine. So the processor word size, most of the operations were 32-bit operations, but they actually made the adders 16-bit adders, and they made them clocked twice as fast as the rest of the processor. So typically, that was around 3 gigahertz. So the adders would then go 6 gigahertz. And the reason they did that is they were starting to include these multimedia operations in the design of the processor, and the multimedia operations needed smaller word sizes. And so you could actually use these adders to do two different 16-bit adds at a rate of 6 gigahertz, or you could take two 16-bit adders or even one 16-bit adder and run it for two cycles to do back-to-back adds, bring the carry back around just like we did in our serial comparator with the output of the bit slice. And you could actually do a single 32-bit add in one clock cycle at 3 gigahertz. So people do play these games in practice in real systems where they trade the speed versus the size and do things in between. Now, those 16-bit adders were not your ripple carry adder. They were tree adders just as the 32 and 64-bit adders are today. But same sort of idea, that you can break the big adder into little adders and use them serially. So I wanted to do a second example of serialization. So this was our generic bit slice model. So just to remind you quickly, we're working on some n-bit operands. We've got p bits of input into our bit slice from the operands, and we produce q bits of output. And we've got n bits in between slices. And then at the end, we have some answer that takes r bits. That's not shown in the slide. But we have some output logic that takes the last n bits out of the last bit slice and produces our r bits of answer. So in class, we did this power of two checker where we looked at two different bits of the operand a in one bit slice. So we've got two bits of a coming in here. We've got two bits between the bit slices. Remember those. I'll show you the representation in a minute. But we needed to keep track of whether we'd seen zero ones, one one, or more than one one, because a power of two has exactly one one bit, as you may remember. I think you played with that in discussion too. So p equals two here. Output bits down here is zero. All we want to know is the answer, to the power of two or not. So we don't produce any output operand with bits coming out of the bit slice. And then m is two from bit slice to bit slice. But at the end, we just want to know yes or no. Power of two, not power of two. So we just need one bit for that. So we used an XOR gate in our design to get that final answer. So this was our representation. We said, OK, zero zero means no one bits. Zero one is one one bit. One one is more than one one bit. And one zero was not used. So when I initialize my bit slice design, what should I pass in as constant values to the first bit? Zero zero, right? I don't have any one bits yet. I just started looking. Good. So we want to initialize to zero zero. So actually, the design is going to be similar to the serial comparator in the sense that our initialization values are both zero zero again. So we're going to just use two NOR gates again for our selection logic. Here's the power of two checker bit slice that I showed you a minute ago. Since m equals two, we have two flip flops here. I guess I can actually go through it. So two input operands, p equals two, zero output flip flops since q is zero. Two flip flops to store the bits of m as they come out, the m bits of output. These again are initialized to zero and f equals one. And then finally, the output logic to get the answer was to take these two outputs from the power of two checker, XOR those together. If that's a one, then we have a power of two. And if it's not, we've got no power of two. Just to flip back a second to the encoding, the representation. So if you take XOR of these two bits, if you don't have any one bits, then that's not a power of two. If you've got one one bit, that is. And then if you've got more than one bit, one one bit, XOR of one and one is zero. So that's also not a power of two. So that's why we're able to use this XOR gate over here at the end. So let's just do a quick answer. This looks more or less the same because I'm doing another four cycle input. Here n equals eight because in each cycle we'll take two bits of the number. So in cycle zero, we start by marking the F input as one and then A and B equal to zero for the first bits of the number. What are these? What should these values be? Bits, good answer. Yeah. So we don't know what those are. And we don't care. Why don't we care? Won't they affect our other logic? So if F equals one, what are C1 and C0? Zero. It doesn't matter what these are. And that's important. So when F equals one, C1 and C0 are both zero. So now we can calculate what Z1 and Z0 should be. So this says, OK, we've got A and B are both zero. We didn't see any one bits before. So how many one bits have we seen? Zero still. All right. So those Z1 and Z0 then in the second, I'm sorry, clock cycle number one get latched into the flip flops. And so those will appear in B1 and B0 in clock cycle number one. So again, I want to emphasize discrete time. So we only think about clock cycles. So once we're in this realm of serialization and finite state machines, we're doing fully clock synchronous sequential circuits. So we have discrete time measured only in cycles. Things change cycle by cycle on the rising edge. So cycle number one, we have zero, zero. Let's say we put in zero, zero, one. So F is zero. And now we have two more bits of the number zero and one. So what are C1 and C0? Zero, zero. When F equals zero, the NOR gates just copy these two outputs into C1 and C0. And so what should Z1, Z0 be? One, zero. I thought it was zero, one. But yeah, so this is the representation for having seen one, one. OK, you don't really need to memorize that, except you do, sort of do to answer the question. So sorry about that. So the zero, one then gets latched into the flip flops in the next cycle. So in cycle two, the flip flops will have zero, one. So they'll have that for the entire cycle. So let's say that we put zero, zero, zero during that cycle. So C1, C0 will be what? Zero, one. Good. And Z1, Z0? Zero, one. Again, same thing, because we get no more zeros. So the representation is basically counting the number of one bits. No more ones, I should have said. So the Z1, Z0 values get latched into the flip flops. And then in cycle number three, those will have zero and one in them again. Put in zero, one, zero. C1, C0 is what? Zero, one. Good. And Z1, Z0? One, one at this point, because we saw another one. Now we have more than one, one. So our Z1, Z0 output is one, one. That gets latched into the flip flops. And now in cycle four, we don't know, we don't care what F, A, and B are. We might start doing another power of two check, but it doesn't matter. We don't care because we're going to look at these two values through the output logic and get our answer. So we don't know what these values are either. It depends whether we're actually trying to start a second power of two check. So we don't know these values and we don't care about those. So in order to use this, you have to create a system that delivers the bits at one cycle at a time. So yes, from the point of view of designing it, yes, you assume that they're serialized. Good question. So if I take XOR of B1 and B0 at the output, what I get is zero. So these eight bits do not form a power of two. And I can put them in any order, but these were, actually it doesn't matter whether they're low or high. Yeah. Yeah so that's a good question. The XOR is just wired up to these two outputs, right? So at every cycle, we're going to get an answer. So we could actually just check and see, you know, do we see a power of two? In fact, if we wanted to, we could look for this one, one pattern and say, well, at that point, we know it's not a power of two, right? So yes, we will get the XOR every cycle. And if we wanted to, we could make the thing stop early, right? We could look for saying, well, when have we seen more than one one bit? At that point, we know the answer, so we could just stop. So I'll do the timing analysis, assuming we don't do that stopping early. But you could do it with this kind of design. Yes, yes, that's right. So the A and B inputs actually represent two bits from a single operand of n bits. So this takes only n over two bit slices. That's why n is eight, but we've taken only four cycles. Yes. Yeah, absolutely. So the question is, could I have done a three, four, 10 bit, single bit slice? Yes, it would be more complicated this way. And I think in discussion section, you did a one bit checker, whereas in class, we did a two bit checker. So you can go the other way too, in this case. Okay, so let's analyze our area. So we've got a bit slice, two flip-flops, two two-input NOR gates for selection logic, and a one two-input XOR. So flip-flops, same size as before, so we won't go count them again. This was our design. So just pull up the bit slice design. So you can see we have three two-input gates, one, two, three of them. And we have two three-input gates. So I'll count them as number of inputs. So that's our total. So if we add those up, we have three, let's see, three two-inputs in the bit slice, 16 two-inputs in the flip-flops, and then two more in the selection logic. So that gives us 21 two-input gates, two three-input gates, four inverters, and a two-input XOR. So that's our area. I'm being a little more detailed now. We're actually changing it into transistors to do the comparison. So two input gates have four transistors, right? So that's 84 transistors, 12 transistors, eight transistors. And this one is even, so we'll just ignore that one. In the bit slice itself, we only need N over two bit slices, right? So we need three N over two, two input gates, that means six N transistors, and three input gates, another six N transistors, and this XOR. So if you do it, it actually is equal at N of nine, but we have to do two bits at a time. So the serial design is smaller for N, 10 more. Yeah, Mohamed? So if you remember, three or four weeks ago, we looked at how you actually build Vanden Oor gates. There are two transistors per input, one P-type, one N-type. So a two-input gate will have four transistors, an inverter will have two transistors. So if you want to go more detail like this, you can count transistors instead of using our heuristic, which was an estimate of transistor count anyway. So either way is pretty accurate. All right, so let's see. So let's look at timing then. So a rising edge arrives at T equals zero gate delays, and then we said we're going to wait four gate delays after the rising edge before we assume the output is ready to look at from these things. We'll assume the same up here, just as we did before. So assume these inputs up here come somewhere from flip-flop. So those are all available at time four gate delays. This thing here then has to go through selection logic. That's one extra gate delay. So that's now available at time five. Now, to know how long the paths through this power of two checker are, go back to our design, and basically everything was two. Everything's two gate delays from the input side to the output side. So if we go back here, so these things up here, these are available at four. So the A and B paths to the Z outputs, well, that's going to be four plus two is six. But the Cs are only available at five gate delays. So five plus two is seven. That'll be the time at which our Zs become available. You have to look at the longest path, as always. And then finally, we decided we're going to wait four more gate delays before the next rising edge to make sure we've got enough time to get the value through the first latch. So we said four before and four after the rising clock edge in the flip-flop. So if we use that timing, we've got at least 11 cycles between the rising edges. And then we've also, for whatever we're using this answer for, we need to realize that it's actually five gate delays before we get the answer. The answer comes at 12 gate delays after the rising edge of the last cycle. So let's see. So the serial design, then, we've got n plus one gate delays in our bit-slice design. That's just pulling that out of the notes. For the serial design, we have at least 11 gate delays for the clock. We have to have n over two cycles. Remember that we're processing two bits per cycle. Yeah, that's just a number we chose. We chose the same number as we did for the serial comparator. There is some amount of delay implied. A real flip-flop might be a little smaller, but you need something to compare. So I wanted to quantify, so I just picked four. That's a good question. All right. So we need 11 gate delays, n over two cycles. So we've got at least 11 n over two gate delays. So it's at least 5 and 1⁄2 times slower, maybe even slower if this is not the thing that sets the clock speed, which is probably the case. So that was it for our second example session. So you can design them different ways. We assumed that the input to the flip-flop had to be steady for four gate delays before the rising edge, and that the output would appear four gate delays after the rising edge. Yeah. Oh, yeah. You know what? I'm sorry. That actually should be 16. That's a good point. Yeah, that's a typo, because until this output becomes visible, it can't go into this. That's right. That's a good point. Yeah, so this would be actually five gate delays into the next clock cycle before the output could be used. Yeah, thank you for pointing that out. That's good. Yeah, Eric? It doesn't. What it means, so the rising edge can happen when this input to the flip-flop has been stable long enough, which is 11 gate delays. But whatever is using this answer has to be aware that it takes four gate delays before these are visible, which we assumed also. We assumed these inputs were only available at t equals 4, that they came from flip-flops. But this one is actually not available to t equals 5, because after the flip-flops, we've got some extra logic. Five into the next cycle. So four for this part, and one for that part. Yeah, that's right. That's right. So the next power of two check could be starting, and these outputs at the same time are being fed to the output logic, which is then consuming the answer for the last one. In parallel, in clock cycle four, where the M was. All right, so let's talk about finite state machines. So a finite state machine is just a model of a system, and it assumes that the system moves amongst this finite set of states based on some external inputs, and then it produces some external outputs. So we'll do a concrete example shortly, but typical examples would be things like, you know, bill coin operated vending machines, vehicle control systems that are looking at, say, road conditions, or watching how fast your tires spin to decide whether to turn on your anti-lock braking system, computers executing programs, things like that. Actually, the computer, the heart is a finite state machine, as you'll see. So what is it in terms of math? Well, it has five pieces. So we have a finite set of states. We have a set of inputs. We have a set of outputs. We have a set of transition rules that tell us, given any state in any set of in any given input, where do we go next? Right? What's the next state? And then finally, we have expressions or methods for calculating our outputs. Now we're going to, of course, build finite state machines as digital systems. So everything we do has to be mapped to bits. Thank you. Everything's bits, right? So states, bits, inputs, bits, outputs, bits. This is tricky. Ready? Transition rules. Boolean expressions. Thank you. Outputs, calculating outputs, I should say. More Boolean expressions, right? The rules take your current state ID, which is some bits. Those are input bits. And your, sorry, more input bits to these Boolean expressions, which are the inputs to the system, and create a next state ID, which is the outputs of these Boolean expressions. And so it says, well, what state do I go into, given my current state and my input bits? And then the outputs, of course, are Boolean expressions. We're going to assume, and I'll tell you this several times, but we're going to assume that the outputs are only a function of our current state. Now, in general, they could also be a function of our current inputs, but in our class, we'll assume they're not. So we implement finite state machine as clock synchronous sequential circuits. So that means discrete time, right? So cycle by cycle, things will change. So in each cycle, the finite state machine will look at its current state, look at its inputs, and move to a next state. Every cycle, regardless of anything else in the world, it'll just keep going, chugging along state to state. So given any state and any combination of inputs, a transition rule from the given state to a next state has to be defined. A digital system, it's going to go somewhere. Next cycle, there are going to be some bits in the state. So that has to be completely defined. Self loops, which means transitions from a state back to itself, that's okay. A state can stay in itself, but we need to say explicitly, under these inputs, the state stays put. It doesn't go to a new state. So we have to completely define it. Regardless, what we build will go somewhere, right? There will always be bits. So even if you say, oh, I don't know, I don't care, whatever you build will have some, will have bits there. And so it will pick an answer for you. So let's do an example. So here's my example. You've probably seen one of these. How many of you have seen one of these? Most of you? Okay. I don't mean a key. Yeah. So Yale Pat, one of the authors of your textbook has a great, has a great joke that he plays on a lot of people. So he pulls out an Intel processor in a block of plastic. And he says, you know what that is? And everyone looks at it. I don't know, is that a P4? He's like, no, that's a key chain. So yeah, so this is a key, but it's also a keyless entry system, right? So it has some buttons on it. And when I walk up to my car, I don't have to put the key in the lock. It has a little protocol for me with these buttons here, which hopefully will help me figure out today so I can use my car. So what I want to do is start with a list of states. So when I walk up to my car, probably the car is locked. At least I hope my car is locked now. So, you know, we can make this list of states. I'll call this an abstract list of states. The meaning of my first state is, well, the car is locked and I'll give it a name. I'll call it locked. So in that case, the driver's door will be locked and the other doors will also be locked and the alarm hopefully is off. So alarm is not on. So now maybe I'll do something and my door, the driver's door will unlock. So we'll have another state. So this means a new state in the system. So when I walk up and I unlock the driver's door, then I'll make another state. Driver's door unlocked is the meaning. I'll call that driver. And in this case, driver's door will be unlocked. The other doors still locked and the alarm is not on. And then, so you've played with these? Who's played with these? What happens if I keep pushing unlock? All of them will open, right? Okay, good. So I have a third state. All of the doors are unlocked. I'll call it the unlocked state. Driver's door still unlocked. Other doors also unlocked. Alarm not on. And then we need one more state, which is if I get scared, someone walks up with a big stick or something, there's a little red button there. And if I get scared, I'm scared to push it because someone will get mad at my car and hurt it. So if I push this button in theory, I'll move into this state, which is the alarm is going off. And that's supposed to scare away an attacker or something. So we'll call that the alarm state. Oh, so now I don't know what to do. What should I do? Should I lock the doors or unlock them? Really? I mean, is that better? So what if I'm running? I mean, the only place to hide is my car. Oh, I can't get in. So I mean, it's not really clear, right? Well, you can't leave it. Well, if you leave it as a don't care, whatever you build is going to make a decision. Could be the worst case. Driver's door is locked. The rest are unlocked. So you don't want to do that. All right. So I'm going to go with the unlocked answer. I'm sorry, with the locked answer. I tend to think that's a better answer. But my point is, this is a design decision. So you as the engineer, you have to make a choice. Your choice might actually make a difference, right? And in some cases, I think in this case, it's unclear enough that both answers might be the right answer in certain conditions, but you've got to pick one. So as an engineer, there are going to be a lot of design decisions. You can build anything you want, but realize when you're making a decision, because maybe later you'll say, well, I made this decision, we could change it, right? And go back and change the system. Okay, so we'll make those locked. And now the alarm, of course, is going to be sounding. So those are our four states. So this is a list of abstract states. This is what we get when we sit down and think, you know, I could probably build a finite state machine to control this thing. Let me start thinking about the states I want. So this is just an informal list, right? We call it an abstract list. So in particular, we could just list the states, right? We could just write down state names. The human meaning is useful if your state names are too generic. It's useful to make sure you know what you're talking about in those states. Outputs is also optional. But if you map each state to an output, that means your output only depends on the state. Now in this class, we'll always assume that. In general, it's not going to be true. In industry, people won't necessarily just make that assumption. But in our class, outputs will depend only on the states, not on the inputs. So it doesn't matter what buttons I'm pushing, what matters is just the state. The buttons will change the state, which can then affect the outputs. Okay, so we specify transitions using something called an X state table. So let's do an abstract one first. So usually in this part of the design, we just go through and figure out, well, what do we want to be able to do? What's a normal operation? So here's my keyless entry system. And let's just kind of think about it. So normally, I walk up to my car, and I want to open it, right? So I push the unlock button. So that'll tell me, well, if I'm in the locked state, and I push unlock, where should I go? I should go to driver, right? Okay, so that's one of my transitions. And so there's an abstract X state table. It says, well, if I'm in the locked state, and I push the unlock button, I go to the driver state. So what if I'm in the driver state, and I push the unlock button? I go to unlock. Okay, well, that's now my car is all open. So I'll get in, I'll drive somewhere, then I'll get out, and I want to lock it up. So whatever state I'm in, if I push the lock button, what should happen? Go to lock. Okay. And then last, if I get scared, doesn't matter what state I'm in, if I push the panic button, what should happen? The alarm goes off, right? Good. So that's my abstract next state table, right? So what's the problem with this? Yeah. I don't know. My table doesn't tell me. So it's incomplete, Daniel was saying, right? It doesn't tell me everything, right? So some of the transitions that I might want to know about are not defined by that table. And that's okay right now. Eventually, the system that we're going to build is going to be a digital system, and it's going to answer all the questions. So we should be careful. But this table is incomplete, meaning it doesn't specify transitions like the one Daniel asked about. It's ambiguous, right? So what happens if I push lock and panic? Which one do I go to? I can only go to one, right? And it's actually, I mean, that part is actually inconsistent, right? Because I can't go to both. So but it says I go to both. So it doesn't make any sense. Right now, it's just an abstract next state table. What we need to do next is make it complete, make it a real design for a digital system. So we're going to have to specify those things and answer all of the design questions. So we need to make design decisions. It's good to do those early if we know about the decisions we need to make, right? So don't put it off. If you know you're going to need to make a decision, do it early, because your digital logic will define answers for you. So do them early. And then when you're done making decisions, when you're done implementing, go back and see, well, what actually happened if you did leave any don't cares? Make sure that any don't cares you left are actually acceptable decisions. Because if they're not, you can fix it. Whereas if you just assume they were, it might lead to problems. So we can represent the same information as that next state table using an abstract state transition diagram. So let me show you that. So here are four states. We draw them as circles. We put their names inside. And then we start drawing arrows between them. So our first entry in the table was, well, if I'm in locked and I push unlock, I'll draw an arrow, take me over to driver. So in this graph, I represent that as an arc labeled with the input. So similarly, if I'm in driver and I push unlock, I go down to unlocked. I said from any state, if I push lock, I go to locked. So you can see here is our first self loop. So the black lines are the third element. This was the first, the second line of the table. This is the third lines, all four of these arcs. And then the last line of our abstract state table, our next state table, was the panic button. That in any state, I go from along the red arrows into the alarm state, including another self loop down here. Same information, also incomplete, ambiguous to some extent, and inconsistent. I actually broke some of the inconsistencies, I guess, because I made these self loops instead of just leaving them open. Oh, no, it doesn't, because it doesn't say what happens if you push both lock and panic at the same time. Yeah, so that's a good question. So Mohammed's question is, well, why don't we just do what we've done before with the glue logic and prohibit more than one input? That's one answer. I'll use actually a prioritization scheme, but we do need to do something to make this a real system. We could leave it open, probably not the safest thing. We can make decisions like one button at a time, or we'll ignore your buttons, or we can make a decision like prioritization. We will need to do something. Good question. Yeah. I'm sorry. Yeah. So that's a design decision that we haven't answered yet. So the question is, wouldn't pushing lock and panic lead to the alarm state only if we choose to make it so, or we happen to have it be so? There's nothing in this diagram that says if you push two buttons, what happens? So panic is a button. So if we push lock while we're in the alarm state, according to this diagram, we turn the alarm off. Yeah, and that's already a design decision too, right? That we'll come back to briefly later because one other question is what happens if you push unlock while you're in the alarm state, which is not answered here. Yeah. Okay. Yeah. So this diagram, just like the previous one, is the same information, right? It leaves the same questions unanswered and leaves the same ambiguities and inconsistencies. There's no difference. Just this is a graph that was a table. Same information. Okay. So exactly the same information. Neither is complete. So now what do we need to turn this into? Bits. I love bits. I'm sorry. All right. Time for bits. So how many bits do we need for the state? Two. Good. Four states. Log, brace, two or four, rounded up is two. Okay. So we'll call them S1 and S0. S stands for state. So we've got two bits of state. We'll call them S1, S0. What about outputs? There are three of them, I think. So we've got driver's door. We'll say one means unlocked. So zero means locked. Remaining doors, which will be R, and alarm, where one means your alarm is sounding. What about inputs? Three? Do you have a question? Okay. So unlock button, one means you pushed it. Some human pushed it. L, lock button, one is pushed. And P for panic button. So three bits of input. Okay. So now we can pick a representation and rewrite our list. So here's a representation. The order in this list doesn't matter. So all I've done is I've rewritten my list of states with the representation and with the output bits mapped into the correct meanings of the output bits themselves. Okay. So I have the lock state, which I'll represent as 00. S1 is zero. S0 is also zero. DR and A, both of these are locked and the alarm is off. In the driver state, I'll pick 10 as my representation. The driver's door is unlocked. The rest of the doors are locked and the alarm is off. Same things down here. Just transcribing into bits according to the meanings that we decided on the last slide. So the order doesn't matter. This is sort of a KMAP order, right? So it'll make life a little easier if we copy these things into KMAPs. So you may realize, of course, that the representation itself does matter, right? So your representation will affect the logic that you need. So for example, if you go to try to map these three functions from S1 and S0, then depending on how you pick your representation, you'll have more logic or less logic. So there is something in that. And also the next state tables, we'll have to calculate the next state from the current state and the inputs. There again, the logic will matter. The representation will matter to the logic. Okay. We'll talk more in maybe the end of the week or even next Monday about how to pick. So we're going to introduce a little more notation. So we're going to put pluses after S1 and S0. What that means is the value in the next clock cycle. So remember, we're feeding logic into the flip-flops, into the D inputs. Those we're going to call S1 plus and S0 plus. Those will be the value of the state in the next clock cycle. So most of the design work is then, after we've gone through all of this process and made the system fully digital, is then just going to be solving for S1 plus, S0 plus in the outputs, building that logic and plugging it together. So those are the examples you've seen in the homework. In the homework, you're just asked to analyze them. But it's basically just some finite state machines where you're calculating the next state as a function of the current state and the inputs, and then the outputs as a function just of the state. So we will typically use binary order in the tables I'm going to show you next. We're going to use gray code order on our axes just for ease in copying the K-maps. So here's a table. Where should we start? Didn't answer some design decisions, right? Okay. So back up for a minute. Let's go answer some design decisions. So let's do these early. I mentioned this before, but we've got a bunch of decisions that we haven't answered yet for our system. So before we start filling in tables, we should answer those questions. So for example, what happens when the user presses more than one button? That we kind of hinted at. This actually, someone asked as well, or asked a similar question, what happens when the user presses unlock in the unlock state? So sometimes you'll be able to list most of these questions. Sometimes you might miss some. Things may come up later. Design decisions are going to shape your design. So you should try to make them early. They can actually conflict with one another. You might make one decision, write it down, come back later and say, well, I can't make both of these decisions the way I want to. I have to pick one or the other. So it's good to resolve that kind of stuff early and not leave things until you forget about them. So let's go through and answer all the questions we can. So we're going to start by prioritizing the buttons. So we know there's three buttons. We know we haven't thought about what happens when more than one of them is pushed. So now we're just going to answer. So we're going to say panic has priority. So if you push the panic button, you're done. Whatever happens when you push the panic button is going to happen. The other buttons are ignored. If you didn't push panic, but you push lock, then we're going to do what happens when lock happens. So we're just going to second priority on lock. And then unlock is only going to matter when you don't push the other two buttons. So that's our priority scheme. So now we can go fill in our table. So here are the panic states. So let me look at this table. This is the next state table. You can see that on the left, I have the current state, which is my two bit S1, S0. And then across the horizontal axis, I have eight columns, one for each possible combination of the unlock, lock, and panic button inputs. And so these four columns here, these two and these two, are all with the panic button pushed. So where should I go if the panic button is pushed? To alarm state, which is 01. So I just fill those in. So now I'm half done with my table. Make sense? Okay. So that's that. Let's go for lock button. So lock button, see all of the ones ending with one are the panic button. So these, I didn't push the panic button, but I pushed lock. Over here, I didn't push either one. Over here, I didn't push either one. So what should happen if I push the lock button? Go to 00, the lock state. So then I can fill in those. So that's good. That was easy. So what if the user doesn't push anything? Yeah, it would probably stay in the current state. We didn't actually specify that, did we? We never said, well, if they don't push anything, we're just going to stay put. We probably all kind of thought about it, but we didn't say it. So it's really kind of a design decision. Probably most of us would have all agreed on, but it's worthwhile making it clear too. So let's all agree, if you don't push any buttons, stays in the same state. Actually, later in the semester, we'll say maybe after five minutes, we should turn the alarm off. And we'll talk about extending this design to do that kind of thing automatically. Question? Okay. All right. So what transitions did we define for unlock? Well, there was one up here, right? So if it's locked, you said we should go where? Driver. Okay, that was, I think, one, zero, right? What about from driver? Unlocked. That was one, one. What about these two? More design decisions? Okay. So what should happen? Maybe just stay unlocked if it's already unlocked, right? So here's a slightly more important one. What happens if you push unlock when the alarm is sounding? Oh, sorry. This is our earlier design decision. Sorry, a little typo in the notes. We still have a design decision to make, but it's not this one. So the question is, should we unlock the car or should we assume that people are still panicking and maybe they hit the wrong button? I mean, they need to be able to turn the alarm off, but do we want them to do that automatically for any button or do we want them to push the lock button only? And so I kind of felt like, well, why don't we make them push the lock button? At least then they're cool and collected, right? If they're just hitting buttons, maybe unlock should not also turn the alarm off. So another design decision, but what it results in is from alarm, we stay in alarm. So if you push unlock, it doesn't turn the alarm off. And then similarly from unlocked, we stay in unlocked. Do you have a question? No. Okay. Sorry. All right. So now we're done. We've got our table. So you know how to fill it in from here, right? The rest is KMAPs, expression, and logic. So just to walk through it a little bit. So we would start by expressing S1 plus and S0 plus in terms of our five variables. So you can go look in Wikipedia, do five variable KMAPs if you want to, or you can play the trick we played with our letter checker. And you can say, well, let me just pick one of these variables and split this up into two four variable KMAPs, right? And then I can put those together with AND gates, or I can put them together with a MOX, right? There are lots of ways to build it. But basically need to build those five, two, five variable functions. Then I'll go express DRNA, the output bits, in terms of my current state. Those will be substantially simpler. So I'll build all of those combinational logic functions, take the S1 plus and S0 plus expressions from this table back here, and feed those into my flip-flops, right, to the D inputs of my flip-flops. And then I'm done. That's it. So you should do that as an exercise. We used to make that a homework problem. I don't think it'll be a homework problem this time. But you should be able to do that, right? It's basically combinational logic at that point. You've been doing that for several weeks now. And this will be a little bit more of a challenge, but it should be doable. So this is the last step in all of our finite state machine designs, doing things you already know how to do. All right. So I want to show you a couple more things before we end for the day. So we can also redraw our state transition diagram. So a complete state transition diagram has the same information that we just put into the complete next state table. So it's defined in terms of bits. So what it's going to look like is this. So we'll have our states annotated with both the state ID as well as the outputs. So we've got the state ID in front of the slash and the output bits after the slash. So often, we'll just put 0s and 1s. So it'll be implicit that the bits before the slash are the state bits, and the bits after the slash are the output bits. And the order of outputs has to somehow be known. So there has to be some order you've decided on, or maybe you write it on the side of your graph or something, so that everyone knows the first bit is D, second bit is R, third bit is A in our case. The arcs then are going to be annotated with input combinations. So for us, that's the unlock button, the lock button, and the P button. Sometimes people will write those in some order. Sometimes people will just mark them with the bits. And then again, you need to realize you should put them all in the same order, and you should say what the order is somewhere. So let's actually do that. So here are four states. So you can see now, instead of just having the name of the state, we actually have the state ID bits, and then the three output bits for all four of the states. And then we can start to annotate our arcs. So remember we said, well, when you push unlocked, this was our first rule, transition rule, in the abstract next state table. When I push unlock, and I don't push lock or panic, so now it's explicit. When I push unlock but not lock or panic, I go from locked to driver. Similarly, when I push unlock but not lock or panic, then I go from driver to unlocked. When I push unlock but not locked or panic, or I don't push anything, then I'll stay here. Now in order to save ourselves a little time, often we will shortcut this kind of notation. So I could write this input bit here as x00. So in this case, I've got a don't care for my u input. So what that means, I could have the 000 pattern or the 100 pattern, and both of those will come back to the unlocked state. So I'll mention in a minute or two, you have to be a little careful with that notation. But you can shorten the number of bit patterns you have to list. Turns out when we get over here, we're actually going to have six different patterns. So I'm going to start using the shortcut notation on this diagram. In the notes, it's got all the patterns listed for you. So if you want to see it in the notes with all the patterns instead of the shortcutting, that's fine. Okay, so look at the notation on all of these locking arcs. So you can see that I don't actually care about the unlock bit on any of them. So unlock doesn't matter on these three. Also for this one, unlock doesn't matter so long as I'm pushing lock. So if I'm pushing lock but not panic, I'll go to the locked state from any state. Similarly, I've got 000 listed up here. That was the self loop when I don't push anything in the lock state. So in this full complete state transition diagram, you need to have all possible arcs. But you can use the shortcut notation, as I'm showing you, to reduce the number of arcs you really have to draw. Otherwise, you'd have eight times four, 32 different arrows, which is a little hard to follow. So these things can get messy if you're not careful. All right, so this is the last one here. Most of these are XX1, which means I don't care about unlock, I don't care about lock, as long as panic is one, I'm going to go down into the alarm state. So XX1 here, XX1 here, XX1 here. Here on the left, it's actually six different states, XX1 and X0X. So if I'm pushing panic, it doesn't matter, I stay in the alarm state. Similarly, if I'm not pushing locked, I'll stay in the alarm state. Not pushing lock, I'll stay in the alarm state. So that's actually six different states. Each of these is, I'm sorry, six different input combinations. Each of these is four. So we have to be a little careful, right? Because there's actually, in that notation, there's actually overlap between these two patterns. But that's okay, because they're going to the same place. So if we're not careful with the input abbreviations, we might end up with a diagram that's still incomplete, we haven't covered everything, or even inconsistent, meaning we've got arcs going in different directions with the same input combination. So be careful how you use these abbreviations. The example I wanted to show you, the last one we looked at, was this labeling, and the patterns X01, 001, and 101 both match each of these patterns. And so that's okay in this case because they both go to the same next state. If they're going in two different directions, that would not be okay. That would be inconsistent. We wouldn't know where to go in our state of the world. So that's it for today. Thank you, and I'll see you on Wednesday.\",\n",
       " \"logic. And now it's 3 o'clock. So I'm going to get my magic device out. So what we're going to do today is wrap up the new comparator design, and then do a two's complement comparator, and then do another bit slice design to check whether a number is a power of two, an unsigned number is a power of two. And we'll do two bits at a time with that one. We may or may not get into talking about building with abstraction. So the first thing there will be a subtractor, and then doing something to check whether an ASCII character is an uppercase letter, and then looking at multiplexers. So that'll carry us basically through the end of the day on Friday, and then next week we'll start doing sequential logic. All of this is what's called combinatoric logic, combinatoric design. So far, through the end of this week, we haven't talked about how you store bits. So next week we'll talk about how you actually store bits on the chip. So on Monday, we'd looked at this, and there were a few people that asked me afterwards. So I wanted to just make sure everyone understood what we were doing. So we did path to path, input to output for each of the inputs here that matter. So remember, C0 doesn't affect Z1. But for each of the inputs that affect Z1, we calculate the gate delays from input to output. And then we went to this diagram, and I just showed you the answers. So let me also show you a table. So what we're really doing at each of the steps in this slide is this whole table. So the inputs for bit slice 0, the one on the right, are available at time 0 for A and B, and at time negative infinity for C1 and C0. To calculate when we get Z1, we then have to go through each of the inputs, add the delay from input A to Z1, which is plus 3 for A, plus 3 for B, plus 2 for C1, and not relevant for C0. Add those to the time A, B, and C1 become available to get the minimum time that Z1 will be available. So then we take the max over these three, and that tells us when we'll get Z1 out of bit slice 0. Similarly, for Z0, we add the delay from A to Z0, B to Z0. Each of those is also 3. We get 3 and 3. C1 is not relevant to Z0. C0 is plus 2, but negative infinity plus 2 is negative infinity. So the maximum here are also 3. And so that's where we got these numbers, the 3 and the 3 for the first bit slice. And then similarly, there's another table for bit slice 1 where you say, well, A and B are both still available at time 0. C1 and C0 are now available at time 3 for bit slice 1. So 0 plus 3 is 3. 0 plus 3 is 3. 3 plus 2 is 5. So now that's where we get Z1 coming out of bit slice 1 at time 5. Same reasoning for bit slice 1, Z0. So that's where these numbers in the blue circles came from. So I know at least a couple of people were confused about that. So I wanted to go through the detailed process and make sure you understand how we get those. We do have to think about all the paths and take the longest one across all of the possible paths. Make sense? All right, so that's just a little bit of review and a couple of new slides. I put those back into the ones I posted, too. So I think those are up if you look on the video lecture now and today's lecture, but also in the slides you can grab online. So overall, we found that compared to the original design, we reduced our area by about 40%. Each of the bit slices was area 12 as opposed to area 20. And we increased delay overall by one gate delay. So it took us 2n plus 1 instead of 2n. So a pretty good trade off. But you might wonder, well, can we do better than that? So we played with algebra for a couple minutes. We got a better design by 40% area, about the same delay. It's not quite as easy. So for example, you can design a slice that looks at two bits at a time of A and B. So I actually did that in the notes for you. So if you want to look at that, you can go look at section 246. That'll give you better delay, because generally you can reduce things to two-level logic. Now at some point, you'll have too many inputs, and you'll have to go beyond two-level logic. Too many inputs to a gate, I mean. But you can do two. And so you can get basically delay two for two bits instead of delay two for one bit. So overall, you'll cut your delay in half for the whole design. And it doesn't get too much bigger. And you're handling two bits, so you only need half as many bit slices. But of course, it's a much more complicated problem. So then you can go all the way to the extreme and say, well, I want to do a 32-bit comparator. Let me just write down the Boolean expressions. I've got 64 bits of input. I'll go solve a 64-input KMAP. Maybe not. You'll do a lot of algebra, and then you'll get answers. Those answers will give you a better design. It'll probably be smaller and faster, but it'll be a heck of a lot of work. So there's a trade-off between human work and complexity of the design, which you're probably going to make some mistakes if you really try to do that for 32 bits. And then you'll have to go figure out where you made mistakes, versus better area and delay. So those are the trade-offs. So let's do a 2's complement comparator. So is this the same as unsigned? So for unsigned, for example, we have this 4-bit unsigned number 1, 0, 0, 1 is greater than this 4-bit unsigned number 0, 1, 0, 1. Is the same true if it's 2's complement? No, why? So 1, 0, 0, 1 is negative. This is non-negative, so this one has to be less. So should we just start over? Throw it out, start over. I like doing K-maps anyway. It'll be more K-map fun. Let's try a little harder. So what if the 2's complement numbers we compare are non-negative? Can I just stick them in an unsigned comparator and get the right answer? I can, because they both have a leading 0. That'll get equal. And then the rest is just like the unsigned representation. So maybe we can just look at the sign bits and figure something out. So let's make a table of sign bits. So here's the four possible combinations. I put a sub s for a sign bit, b sub s for b sign bit. I interpreted those meanings for you here. And then I put in the solution you already found, which is, well, if they're both non-negative, just put it into the unsigned comparator. You're done. All right, so how about this line? So if a sign is 0, b sign is 1, which one's bigger? a, right? Good. And if a sign is 1, b sign is 0, which one's bigger? b, good. And if both of them have sign 1, which one's bigger? Really? I don't know. It's too hard for me to figure out in my head. All right, so maybe you guys figured this out in your head already. But for people like me, they're a little slower. I've got some more slides. So to me, maybe that works. But are the rest of the bits you can just compare? Let's make sure. So remember our simple rule for translating 2's complement numbers into decimal. We said, well, the value of a negative 2's complement number, actually this works for all 2's complement numbers, is this place value here for the leading bit is negative. So negative first bit times 2 to the n minus 1. So if a is negative, then a n minus 1 equals 1. And if we interpret those same numbers as unsigned, those same bits as unsigned, what we'll get is the 2's complement value plus 2 to the n. So for an unsigned number, this is plus a n minus 1. So we'll have 2 times this difference between the 2's complement value v sub a and the unsigned value v sub a plus 2 to the n. That's actually by definition of 2's complement. So either way, you want to remember that. So if we do what people suggested and we just feed those two negative numbers in, well, what happens? So we end up comparing v a plus 2 to the n with v b plus 2 to the n, and we get an answer. So let's say that answer, for example, is less than. Well, we can just subtract 2 to the n for both sides here. So if this is true, so is that. And it didn't matter whether the operator in the middle was equal or greater than or less than. Same operator, we can subtract 2 to the n for both sides. So whatever our unsigned comparator says, that's actually the right answer also for the 2's complement. So some people already saw that, but I wanted to work through it to make sure it was clear. So we have the right answer for 2's complement, and the same result holds for equal and greater than. We'll fill that into our table. So are we done? Can we just put these two unsigned number, I'm sorry, 2's complement numbers into the table? Yeah. Yeah. Yeah, so these middle ones, are these right for unsigned? Is this what we get out? No, if I put these unsigned leading bits, do I get a greater than b? I get a less than b, right? But for unsigned, this is a leading 1, the leading 0, well, that one's bigger. b is bigger. For 2's complement, a is bigger. So it's the wrong answer. So how about we just flip those two bits? Why don't we just cross the wires? So on the sign bits, just flip them. Is that going to work? So if we do that for these middle cases, for a is 0 and b is 1, the sign bits, we feed in 1 for a and minus 1, and 0 for b. So we just cross the wires. And our unsigned comparator, of course, is going to produce a greater than b. You look back here, you say, well, that's what I wanted. And for this case, a is 1 and b is 0. We flip the wires. So we get a is 0, b is 1. And that'll give us, for unsigned comparison, well, b is bigger. So a less than b. And that's what we wanted. So what about the other two cases? So when you design it, if you want to build a 2's complement comparator, you simply put the a bit into the b input and the b bit into the a input. It's just wires. Just like you want on your protoboard. You just say, OK, swap them. No, just for the sign bit. Only for the sign bit. Yeah, the rest we're going to compare as is. What about a equals as equals bs? Did we just break those? Why not? They're the same. Either they're both 0, and you put this 0 in over here and this 0 in over here. They're both still 0. Or they're both 1, you put a 1, this 1 over here, this 1 over there. They're both still 1. So it doesn't make any difference. So that's it. So in other words, if you want to choose complement comparator instead of an unsigned comparator, you take the unsigned comparator design and you put the b sign bit into the first bit slice, the highest, most significant bit slice in the a input, and vice versa. And that's it. That's now a choose complement comparator. Yeah, Nathan? What would be the point of that? So probably it would be implemented in the library. Actually, you would write a comparison operator in system barrel log, which is somewhat like C. And so the comparator that got instantiated would be the unsigned one if the things you were comparing were unsigned, and choose complement if it were choose complement. And so the difference would simply be those two wires would be swapped in the choose complement. So in terms of our original diagrams, it depends whether it's visible to someone doing programming. So if you had a compare instruction, for example, and you had two different compare instructions, you could implement that with two different comparators. You would probably do something more like what's on this slide, which I haven't described yet. So what about just using one comparator to do both kinds? What do we actually have to do in order to make that work? Well, so in order to tell the comparator what kind we want, we need some kind of signal. So let's make up a signal. We'll call it s. And that'll let us select between choose complement, which will be s equals 1, and unsigned, which will be s equals 0 comparison. So in that case, I claim that all you need to do is XOR s with the most significant bits, the sign bits of a and b, and that'll give you the right answer. So if you tell it, OK, I want unsigned comparison, and the sign bit you XOR with s, well, s is 0. So then it'll go in unchanged. So clearly, that one works. And then I claim if you XOR for choose complement comparison, you XOR both of the sign bits with 1, you also get the right answer. So I'll let you figure out why. It leverages the flexibility in the design. So if you solve this with a truth table, and you don't put any don't cares, which you kind of have to do because you actually do care about every answer, then you'll get a more complicated design than this. So you might want to just work through it and see why it works and what we're taking advantage of. All right, so power of 2. So I wanted to do one more bit slice design for you. So let's think about how we do a power of 2 checker. So how can we check whether an unsigned number is a power of 2? What is a power of 2? Yeah, Mohamed? What does it look like? Yeah. Yeah, only one bit is on. Power of 2, 2 to the n, then that's a place value in binary, in base 2. So one of our bits will be a 1. So here, for example, for 5 bit unsigned, these are the five powers of 2 you can write in 5 bit unsigned. So you can see there's 1, 2, 4, 8, and 16. And all of them have 1, 1 bit, which is 2 to the n for some n. In order to check whether an unsigned bit pattern is a power of 2, we need to know, well, is there 1, 1 bit in that number? So I claim we can do this as a bit slice design. So if I ask this question, so is A, which is all of these bits, a power of 2, how many answers can you give? Two, right? It would be yes or no. So here's a trick question. How many bits do you need to pass between slices? I'm hearing 1s and 2s. 2 is right. Why? Answer only takes 1. Is this a power of 2? You can't say, well, maybe. Say yes or no. So the question you need to ask, though, is if you look at the rest of the bits, so if I have a number that has n bits in it, so this is n minus 1 bits here. So if, for example, these bits are a power of 2, can the whole number be a power of 2? Actually, I put the wrong answer. It says no. It could be a power of 2. This would have to be a 0. So if this were a 0 and this is a power of 2, the answer is yes. So sorry, my slide's wrong. But you could tell. So if I told you this is a power of 2, then by looking at this bit, you could say yes or no. If it's another 1, the answer is no, because that'll mean there's a 1 here and a 1 somewhere in here. And you know that's not a power of 2. Whereas if you get a 0 here and this is a power of 2, the answer is yes. So you know the answer. So what about this case? So if I tell you these lower bits are not a power of 2, can you tell me whether with the extra bit it is a power of 2 or not? You can't, right? Because you don't know what these bits are. You just know they're not a power of 2. So it's impossible for you to answer that question. So you need more information. So let's figure out what else do we need to know. So imagine we just finished n minus 1 bits. So the answer's coming out of a bit slice. So under what conditions can our number a be a power of 2? So I claim there are two cases. So one case is for our bit slice is a 1. And in that case, what do we need for the rest of the bits? They need to be 0s, right? Because a power of 2 has 1, 1. So if we've got the 1, everything else had to be 0. And if we've got a 0, the rest has to be a power of 2. So we need answers to both of those questions in order to be able to pass the next answer out of our bit slice. So we need to know whether the rest of the bits form a power of 2, this question. But we also need to know, so that was our original answer. But we also need to know the answer to this question down here for number 1. Is the rest all 0s or not? If I tell you the answers to both of those questions, then you can tell me for the 1 bit you get in this bit slice, 1 or 0, whether the answer is a power of 2 or not. Yeah, Eric? AUDIENCE 1 5, 8. Yeah, so remember, we're trying to build a bit slice design. So we have to make a decision based on 1 bit and the rest. So we want to ask, how do we actually prove an inductive step? So remember, when we do bit slice designs, this is proof by induction. So we need to be able to look at 1 bit and then the rest. And so the question is, well, what possible answers do we need summarized out of the rest in order to make our decision and do that inductive step? And so there are two possible cases for a 1 bit. And for this case, we need the answer to this question. Are the rest of the bits all equal to 0? And for this case, we need the answer to this question. Are all of the rest of the bits a power of 2? So if you tell me both of those answers, then I can design the bit slice that answers the question. Yeah? It is. And that's our inductive step. If we assume that we can answer this question, then we can answer this question. Wow. So yes. And I will not fall into the trap of going down to n minus 1 and proving it. We'll assume it works. Yeah? About the bit top, does it have a power of 3? Yes. The remaining bits form a power of 2, which means there's exactly one 1. Any other questions before we? Good. OK. So the yes cases actually don't overlap. So the yes cases are everything's 0, and everything else is a power of 2. There's no overlap there. Everything being a power of 2 means there's one 1, and all 0s means 0 1s. So those two don't overlap. The no cases, we actually don't have to do anything else to further separate them. So all 0s, again, means no 1 bits. Power of 2 means one 1 bit. And the other possible case is there's more than one 1, which means no to both of those questions. If there's more than one 1 in the rest of the bits, it's not a power of 2, and they're not all 0. So we're done. So those are the three cases we need. We need to convey one of these three answers. In all of my bits, there's 0 1 bits, one 1 bit, or more than one 1 bit. And if I convey that information as input to my bit slice, my bit slice then can convey the same information to the next bit slice. So three possible answers or messages. So we need two bits. Make sense? All right. So here's a representation. Is this the best one? I'm not really sure. I didn't compare them all by hand. So others may be better. It's a pretty good one. So what is it? So no 1 bits, we're going to call 0 0. One 1 bit, we're going to call 0 1. More than one 1 bit, we're going to call 1 1. And I'm not going to use this 1 0 pattern. I mean that if you pick a different way of putting these messages into these 4-bit patterns, you might get a better, smaller, faster design. Probably not faster, but maybe smaller. All right. So let's think about the bit slice that we're going to build. So we're going to actually look at two bits at a time. So let's call those A and B. These are bits of our number A, but I'll just call them A and B inside the bit slice. The inputs from the previous bit slice, we're going to call C1 and C0, just like we did in the comparator. And then just like we did in the comparator, we'll call the output Z1 and Z0, just to distinguish our inputs from the outputs. Both will use the same representation. So the input meaning and the output meaning will use the same representation. The direction for this doesn't actually matter. We just need to know, is there a 1 bit, 1 1 bit somewhere in there? So it doesn't matter whether we start at the big end or the little end and go either direction. It's OK. So let's fill in a truth table. So we'll start with a case of the two bits from the number being 0. And we've got four possible cases. So if we see C1, C0 is 0, 0, that means there are no 1's in the rest. 0, 1 means there's 1, 1. 1, 1 means there's greater than 1, 1. And 1, 0 should never happen. So in the case of A, B equals 0, 0 and no 1's, what message should I pass? No 1's, right? Because there are no 1's that I see. And before me, there were no 1's. So there's still no 1's. What about if there was 1, 1 in the rest? Also 1, 1. The 0, 0 adds no new 1's. So we just copy the message over. What about this one? Also more than 1, 1. Oops, sorry, wrong order. More than 1, 1. And this, of course, is don't care. We should never see that input pattern. So we don't care about the outputs in that case. So we can then fill those back in. And of course, we're just copying the bits, since the meanings are the same, from C1, C0 to Z1, Z0, except for here, where we don't care what the outputs are. So we'll get a little bit of flexibility in designing our bit slice. All right. So then the next quarter of the truth table. So if we've got a 0 on A and a 1 on B, and the meaning is no 1's, what message should I pass? 1, 1. I've now seen 1, 1. What if I saw 1, 1 before, and I got a new 1 in B? More than 1, 1. Good. Hopefully, I got the right order, but I feel like I didn't. I didn't. OK, sorry. What about this last one? Still more than 1, 1. No matter how many 1's we see, there's just more than 1. That's all we care about. So we don't keep track of whether it's 2, or 5, or 100 1 bits. It's not a power of 2. It never will be. So more than 1, 1. So we can fill in the bits. So 0, 1 for 1, 1. 1, 1 for that. XX, 1, 1. Is this case any different than the last one? It's not, right? A and B are just two bits out of the number. It doesn't matter which one is a 1. So if I flip through these, I've got exactly the same truth table as I did for the previous slide. Exactly the same message is out. What if I see A and B both equal to 1? They're all greater than 1. All this message out, except for don't care. All right, so that's the design. We can copy that into KMAP. So here's the first one. I liked POS for this. So let's do a POS solution. So where are the loops? Yeah, we're going to do the 0's for POS. So let's see. So how about this one? Where should I? Just up, right? I can't go down, can't go right, can't go left. So I'll just go up. I can do a square. Oh, the next one you want to do is square, yeah. OK, so what is this factor here first? OK, so remember when you read POS factors, you want to complement, right? So this would have been C1 prime in an implicant, but in a POS factor, it's going to be C1. And then that would have been A prime B prime, but here it's going to be plus A plus B, because we want to complement the literals in the POS factor. So C1 plus A plus B. What about this one? I guess I should have let you say what that was, but someone already said it in front. So there is another POS factor, right? We need to cover this 0, and so we can go left and we can go up. So we'll go both directions at once and get this purple square that wraps around. OK, so I hear a few people saying C0 plus A. And what other? Four corners. Let's see. So I've got one more 0 to cover. I can go right and wrap around. I can go up, get this x. You can actually do both at the same time, right? So good, four corners. What is that one? OK, so I'm hearing some C0 or Bs, right? Good. All right, so we got those three POS factors. So there's Z1. Those three POS factors. Yeah, so I wanted to mention, I didn't mention this before, and I didn't put it in the slides, but when we're solving POS, you can also think of this as Kyle somewhere, probably. There he is. As Kyle reminded me in office hours, you can think of this, if it makes it easier for you, think of this as F complement. What is this one? Z1 complement. So imagine replacing all the 0s with 1s and all the 1s with 0s, and then solving that as SOP. If you do it that way, you get Z1 complement, which you can then apply generalized DeMorgan's and get the POS form. So that's actually fully mathematically equivalent. So if it makes more sense to you, by all means do it that way. So in other words, replace 0s and 1s, then these 0s become 1s. Circle the 1s with the same rules, and then just apply generalized DeMorgan's to complement what you get. Yes? Except if you circle 0s, do remember to change it into this form. The generalized DeMorgan's will change it into this form. So you can either do it by hand after circling 0s, or you can solve the complement function and then do it with generalized DeMorgan's. That's why I say it's mathematically equivalent. But I think sometimes it might make more sense one way than the other to some people. So I think it's equally valid to understand it either way. Equivalent. That's why I wanted to mention it. All right. Here is z0, k-map. So this one looks remarkably attractive for POS, right? But we'll do SOP. So what are the loops for SOP? Yeah, so we got that 8 in the middle. Good. What else? Yeah, the other middle. Sorry, that was c0. Oh, I didn't do them in the right order. Sorry. OK, we got that one. What is that one? A. And what is this one? B. Good. Actually, if you solve this min term and extend it up to here, you'll get exactly the same form for POS. So in this case, you'll get the same answer, regardless of whether you solve POS or SOP. So this is z0, c0 plus a plus b. And notice that if you write those down side by side, this thing here, you can actually get by adding these two factors together. So you can say, well, z0 is c0 plus a or c0 plus b. So we can reuse those gates. That's kind of nice, a little simpler. So here's the design. It has something new. So the new part is not NOR NOR. You should hopefully remember that when I have a POS, I can just write this as NOR NOR. So that's all these NOR gates are up here, is a NOR NOR design for z1. But this NAND gate down here, if you think about, well, what is that? These are the two factors I called out. If you do DeMorgans on this one, you push the inverter through, you get an OR gate. And that then cancels these two inverters here. So you've got OR followed by OR. But that was what we wanted. So if you do NOR followed by NAND, it's just like an OR gate. So all right, so let's analyze this. So how many literals do we have? Seven, right? Coming in there. OK, and then how many gates? Five. So good. So then we've got a total area of 12. And so remember, though, we're handling two bits of the number. So since we're handling two bits of the number, for an n-bit number, we only need n over 2 bit slices. So the total area is going to be just half of 12 times n, so 6n. What about delay? So two gate delays on all paths. So the total delay through our system, again, we only have n over 2 bit slices for n bits. So the total delay is what? Is just n. So up here in the title, I put the overall total. Yeah, exactly. We're handling two bits per slice. So we only need n over 2 slices. Yeah. So you mean this? Sorry, let me go back. You mean this part down here? OK, so if you look at this structure, so just ignore the upper two gates. If you just look at these three gates down here, this NAND gate by DeMorgan's is equivalent to an OR gate with complemented inputs. So imagine you replace it. You've got an OR here, and you have inverters here and here. Slide those inverters down, they cancel the inverters there and there. So now you have OR gate followed by OR gate. It's just an OR gate. So now you have C0 OR A ORed with C0 OR B, which was this expression here, which then is equivalent to what we wanted. Anything else on this? Yeah. Why I can split the bits apart. I don't understand what you mean by split the bits apart. Sorry. So remember when we did our design, don't remember how far back, I said that I would take two bits out of the number. So I'm building a bit slice that handles two bits. And so that's why if I have n bits, I only need n over 2 bit slices to handle all n of them, because each of the slices handles two. Yeah. So how do you split them? A OR gate? It's algebraic. So you look at the design, and you try to spot common factors. So that's all I did. I mean, I didn't really even have to manipulate it. When we solve the k-maps that way, it's almost obvious. I didn't know you could do that. But and and OR. Yes. Yeah, I mean, you can start by drawing this design in just and and OR. And then when you change it to and and OR, I just cut to the chase and showed it to you. Yes. Is it n plus 1 over 2? Sort of. OK, so the question is, well, what if n is odd? Then you need n plus 1 over 2 slices. So if you had 5, n equals 5, you would need three slices. But what can you do with the extra slice? So you can simply, knowing how this works, you can set one of the bits to 0. And that will give you the right answers. Good question. Yeah. What if you have 5, 0, and then you have n over 2? Mm-hmm. That's what you would do. Yes. Yeah, so again, both area and delay, we only have n over 2 slices because we have n bits. Each one handles 2. So you would keep your n over 2. Mm-hmm. And you keep n. Yes. Yeah, that's right. So you would take your n bits. You would feed 2 into the first bit slice, feed 2 into the second bit slice. Yeah. Yeah. So remember that if I just pick one of these a and b inputs and I put a 0 in, that doesn't affect my answer. Right? Yeah, so I just take the bit slice where I don't have another bit of n to feed it and I put a 0. Then I still get the right answer. Yeah, that's very much dependent on what we're trying to do. So if you had something, a design that didn't allow you that kind of simple answer, you would have to also design something to handle one bit. And you'd have to use that one to handle the odd. And yes. All of them? Typically, yeah. Typically. But usually, it's not a big deal to try to handle two bits at a time. Trying to do three is a little weird, because then you probably also have to do another design in most applications. All right, so we don't get an answer. We said we're going to build a power of 2 checker. Out comes this two bit thing. It has some representation. And we say, well, wait a minute. We want to know is it a power of 2 or not. We don't want to know are there zeros, are there more zeros, are there ones. We want to know is it a power of 2 or not. So we just produce this count. It's 0, 1, or many. We want yes. So I'm going to call that p equals 1, or no, p equals 0, power of 2. So if you look at the representation, which I guess I didn't copy up here for you, but if you look at the representation, from that representation, the two bits coming out of the last bit slice, you can simply connect z1 and z0 with an XOR gate. And that'll be p. So if z1 XOR z0 is equal to 1, that means it's a power of 2. And if it's not, if it's 0, that means it's not a power of 2. Where's my last representation? Maybe here. All right, there. So 0, 0, look on the input side. It gives a full representation. 0, 0 XORed together is 0. That means no ones. That's not a power of 2. 0 XOR 1, that gives 1. That's because there's 1, 1. That is a power of 2. And 1, 1 XORed together gives 0, also not a power of 2. We never see this one. This one would also say power of 2, but it's never generated. OK, so let me skip ahead to the slide. Sorry, pulled that up before. All right, so that adds one extra gate delay. So the real design, including getting the answer out at the end, is n plus 1 gate delays. All right, so let's think a little bit about building using some of the components we've already designed. So you can always go down to the expression level, down to the KMAP level. Maybe you can't always use KMAPs if you have a lot of variables. But you know what? You know the underlying algebra. So if you have to, you can do that. You can get your computer to do that. But it takes a lot of time. And it's not very robust. So if you make a change to what you want to do, then you have to redesign the whole thing and do all that work again, as opposed to making some high-level change. And maybe that's a little easier. So you know how to do that process. But you rarely actually need to do that level to get a satisfactory solution. So a lot of the time, the things we're working on, you don't need to get the optimal answer. You just need to get an answer that works, because other parts of the system are going to be slower, are going to take most of the area anyway. And so you just need an answer that works. Get it very simple, get it correct, get it designed, and put it in. So instead, we can take an approach where we say, well, let's use abstraction. We know how to build things like adders, comparators. Let's just put some things down and get the answer out. And then if our part is the thing that needs to be optimized, we can go back and optimize. So we can use extra level of logic to describe our functions intuitively also. There are also CAD tools. So the tools you'll use once you get into 385, to some extent, the ones you're already using, the mentor graphics tools, can also help you with your designs. So they can do low-level optimizations for you. Often, they can do it better than you can, not because they're smarter than you. It was just some engineer, probably not even an Illinois engineer. So probably you could do a better job. But it'll take you a lot of time, whereas a computer can go look at a whole bunch of stuff really, really quickly and find the best answer out of all the things it looks at. So it might take less than a second, whereas you could spend a month looking at all the possible ways to do it. You'd find a better answer, but it still took you a month. It took the computer a few seconds. So it's probably not worth your time in most cases. So context is important. So if you go talk to your mechanical engineering friends and they say, oh, I just got a 0.5% boost in internal combustion engine efficiency, they're probably going to win some major awards for that. That means that everyone in the room's gas consumption just went down by 0.5%. That's actually a big deal, because that's a fairly established field, and that's a big number for them. They don't get that every year. They don't get that every decade. So in our field, engineers spend a lot of time doing things like improving the designs of arithmetic units and memory, because those are the things we use a lot of, and we use them very fast. And so if you can improve those designs a little bit, it'll matter. Or doing things like improving CAD tools' ability to optimize. So now all engineers who use the CAD tools get that benefit. So it depends on context. Oops, sorry. There's a famous computer scientist, Tony Horae, or Hoar, I guess. I'm not quite sure, actually. Never met him. But he said premature optimization is the root of all evil. So sometimes this gets over-interpreted. So the interpretation that you'll see a lot is don't spend optimizing something that's likely to change. So if you're doing a prototype, don't go optimize as much as you can, because then, well, gee, we need something slightly different. Well, throw away all your work and start over. So don't spend time on that. Or something that really doesn't contribute much to the overall system goodness. So if you optimize something that contributes 1% of the time, no matter, even if you make it go infinitely fast, you still have 99% of the time. So be careful about spending your time on stuff that just doesn't matter overall. The flip side of this is don't ignore scaling issues when you're choosing algorithms. So for example, let's say I decided, hey, I want to return your midterms to you. So one algorithm I could use is, well, I've got 95 people in the room. So I'll start over here. And I'll say, here's test number one. Is this your test? No. Sorry. Is this your test? No. Is this your test? No. And if I do that, then I've got roughly 95 squared questions to ask. Instead, I could alphabetize them and have you line up in alphabetical order. And that's actually easier than it sounds, because you can compare it locally. So there are better algorithms. So don't ignore scaling issues. And then also, don't design in a way that prohibits or inhibits optimization. So usually, what that means is you think of things and you build abstraction boundaries. What I'm building is an adder or a comparator. How I then implement it, it doesn't matter. If I need my adder to go faster, instead of a ripple carry adder, I can go do a tree-based adder. So if you define clean abstraction boundaries, then that enables later optimization. If you mix everything together, it makes it very hard to go figure out how to optimize it later. All right. So let's do a little example. So let's start with a subtractor. So how do we subtract as humans? So let's say I ask you to do this subtraction. What would you do? Well, you take the 10's complement, right? The 9's complement and add 1. So the 9's complement would be 8, 9, 9, 9. 8, 2, 1, 9, 9. That one plus 1. 8 plus 1. OK, help me out here. Let's add it up. 5 plus 9 is what? 4 carry the 1. 1 plus 4 plus 2? 7. 3 plus 1? 4. 2 plus 9? 1 carry the 1. 1 plus 1 plus 9? 1 carry the 1. We don't have room for that digit, right? That's the right answer. Yeah? OK. I don't know. Maybe your elementary school didn't teach you that way. It's not my fault. But you probably did that in your homework, right? You probably said, oh, I got to subtract. You can use that from now on for your decimal subtraction if you want to. Actually, one day, I mean, maybe some of you have children now. But one day when you have children, I actually suggest you not teach them that way. Because they're going to confuse a lot of people. All right, so you probably did that approach in your homework, right? Where you said, OK, well, I'm going to take the ones complement of that number I'm supposed to subtract, add 1 to it. I'll add that together. And that'll give me the a minus b that I want to look for. Because somehow, taking the subtraction process we did learn in elementary school and mapping that to base 2 is just kind of a pain. And this is easy. So instead of mimicking human subtraction, let's use an adder, right? We have an adder. We know how to build it. Let's just use one. So here's an adder. And I made some changes. And I think we still have time to finish this in a few minutes. So here's our design. So we have our adder in the middle. That's the core. And we want to calculate a minus b. So we want our adder to produce a minus b. So we're going to modify the inputs to perform the subtraction. So let's take a look at how we modified them. So first one is a. So a is not changed at all. a just comes straight into the adder. b goes through this box I've called ones complement here. So what is that? It's a bunch of inverters, right? Good. So there's n inverters in there. For each bit, so remember this is n wires. So for each wire, I put it through an inverter. And then I put it into b. Yeah, so that's the third change. So the third change is cn, you may notice here, is a 1. When I change the carry in to a 1, all that does is add 1 overall. So now what is this adder computing? Well, a added to the ones complement, so not b bitwise, plus 1, which is a minus b. Yeah. Mm-hmm. So what happens if the user does a minus a negative number in 2's complement? Remember that negating in 2's complement works for both positive and negative numbers. So not b plus 1 is negative b in 2's complement regardless. Regardless of whether b was negative or positive or 0. Yeah. Good question. What about the carry out? Let's think about this for unsigned. So remember that our 1's complement, you can think of the value as 2 to the n minus 1 minus b. Remember when we first talked about negation, I said, well, when you want to negate something, you can think of this 1's complement as 2 to the n minus 1 and then subtracting b. So we obtain d, this thing down here. You can say, well, what I did was I added a to the 1's complement, which is 2 to the n minus 1 minus b plus 1. So the minus 1 there and the plus 1 there cancel. So d comes out as a minus b plus 2 to the n. But what is the carry out? Well, the carry out is the 2 to the n. So if I see a 2 to the n coming out, that means that this number, a minus b plus 2 to the n, was at least as big as 2 to the n. So in other words, if I get the carry out, c out equals 1, then that means this number here, a minus b, was at least 0. So in other words, a was at least b. a is greater or equal to b. Whereas if I don't see the carry out, so c out equals 0, that means this number d is less than 2 to the n, which means that a minus b is less than 0, or a is less than b. So in other words, if these are unsigned, if I subtract b from a, and b is bigger than a, then I get some unrepresentable number. It's a negative number. So I can't represent it with an unsigned bit pattern. So this is an overflow down here. And this one, if I subtract unsigned b, which is less than a, then I get some non-negative number, which I can represent, because it can't be bigger than the numbers I can represent since I did a subtraction. So this means no overflow. So in other words, the carry out here is an overflow indicator in the opposite sense for subtraction as it is for addition. Remember, for addition, if we got a carry out for unsigned addition, that meant overflow. Now if we get 0 carry out for subtraction, that means overflow. Carry out of 1 means no overflow. Yeah. Yeah, there's a similar set of equations you can use. And in some sense, it's opposite. It's in the notes explicitly, but I didn't do it in the slides. So you can flip to this section of the notes, and it's there for you. And the derivation is there. Yeah. Good question. Yeah, for choose complement, just like unsigned was relatively easy. We just look at the carry out. Here, we also just look at the carry out. Choose complement, you have to do more work. So we looked at the sign bits. It's the same sort of thing. Good question. All right, I think that's it for our first. Well, OK. I wanted to also give you the control signal thing. So if we want to build one that does both, then we need to have some way to choose, do you want to add or do you want to subtract? So we can, again, add this control signal s. Maybe s is 0 for addition, 1 for subtraction. So then we need to modify our adder inputs with s. What should I do for a? Just a, right? Don't need to do anything for a. What about b? b. So remember, I want to do one's complement for subtraction, but not for addition. If I do complement, then I'll be adding. When I say add, I'll get a plus b prime. I don't want to do, not quite that simple. Has to depend on s. XOR. So if I XOR all of the bits of b with s, when I do addition, I'll get b unmodified. When I do subtraction, I get not b. Good. What about cn? Just s. When s is 0, I get a plus, this one is just b, plus 0. a plus b. When I do s equals 1, I get a plus not b plus 1. a minus b. Good. OK, that's it. Thank you. See you Friday.\",\n",
       " \"end of the class. Yeah. OK, so let me go ahead and start. So today we're going to, I wanted to cover a little bit again the use of the heuristics, because I know it was a little confusing with the complemented literal. So I'll clarify that, and then also show you circuits implementing the three functions, which I think will help make it a little easier to do the counting. It's really pretty easy to use the heuristics, but I think maybe the first few times you do it, it's easier to look at the circuits. So I'll just put those up. Then we're going to spend some time on Boolean terminology, and that will help us understand the question that someone asked, how did I get from the big long construction of f to the shorter construction? But I'll do that algebraically, which is really not very fun. So that'll be the first step. And then I'll show you Karnaugh maps, which are a graphical tool that'll make it a lot easier. So that's probably where we'll get to today. I don't know if we'll finish Karnaugh maps, but maybe. Two-level logic, most likely Friday. Professor Vardain will give that lecture. Remember, none of this material this week's on the midterm. So midterm material ended last week, so just so you know what's on the midterm. Another reminder, next Tuesday, you had to have signed up already for the conflict. So hopefully, if you need the conflict, you already did that. The coverage, same as before. One thing I do want to point out, so I know some of you will go and look at the wiki and read the notes that are connected to the lectures there. There's unmarked content. So there's extra content there, but it's not marked. So in the notes you can get from the store or online for free, all the extra stuff is marked with stars. And there's a summary, section 1.6, that tells you exactly what you're supposed to know. In those notes, they're not marked. So use section 1.6 to help you if you need. So based on what you said, previous lectures I know all have Hamming codes. So I think after two years ago, I think we moved it to, so two years ago, we taught Hamming codes now. And that's what I was joking about a little bit two weeks ago when I said they took a lecture out. But we moved it to the back. Midterm, how did that happen? September 15. OK, so maybe they waited another semester to move it then. I wasn't teaching that semester, so I'm not quite sure. And they moved it. I thought they were supposed to move it in the fall. Actually, spring 15. But yeah, question? Yeah, so the rules for what you get to bring to the midterm, I think, are posted. They should be posted on the midterm page. But are they not there? Well, let's go take a look. Let's see, how about this one? Go to Wiki. Go, probably under Syllabus, right? Should be here. Well, this is where I would look for it. All right, let me ask them to post rules. Because we haven't actually talked about that. When I've been teaching the class, generally there has been one single page, handwritten notes, both sides. And I presume they kept that policy. But let me check, because we want to have the policy be consistent in the classroom semester to semester. And I'll ask them to put that up on the Wiki. Oh, OK. Sorry, I forgot to tell PowerPoint. I wanted you to see the Wiki. There's nothing there, so at least I didn't spot anything where I would have looked for it. So let me ask them this afternoon. Oh, it doesn't want me to go forward, OK. All right, so let's go back a step, just to review the area heuristic quickly. So the idea was you count literals. Whether or not they're complemented doesn't matter. And the idea was to get an estimate of transistor count. And then for the delay heuristic, I just want to be clear this time. So for now, just ignore complemented literals. Don't count them as delays. That'll be easier. And in a few weeks, you'll understand. Sometimes you might want to actually count them. But for now, just ignore them. Make it easier. So here was our first function drawn out as a circuit. So you have the three AND gates and the OR gate there at the end. And then you can see I've labeled them all. And there's two complements going in. So I put inverters, but just ignore those in our counts. So to count area, first we'll count literals. So the number of literals is just the number of inputs to the AND gates. So you can just count them up and see there are nine. And then actually, the number of operators here is also quite easy when you draw it this way. It's basically just the number of gates. So how many gates are there? Four, right? Good. So that's the number of operators, three ANDs and an OR. So that's what we get. What about delay? So now, remember, the delay is the longest path, again, not counting the inverters, from the left side over to the right side. So all the paths go through two. So the gate delay is two gate delays through any path on this one. Good. Whoa. That was impressive. I can't even click that fast. Maybe I've been practicing with my handheld computer. All right, there we go. So this is the second expression. So this one takes a couple of AND gates and an OR gate. And if I ask you to count literals, what do you get? Four, right? Good. What about operators? Three, good. OK, and what about gate delays? Two also, right? All paths. All right, and then this was the third form. So here you've got just two gates. How many literals? Three, right? And I guess I gave the answer to the gate, so I'll just click through that. What about gate delays? Yeah, so remember, it's the longest path that matters. So there might be different length paths. The one that matters is the longest one, because you're going to have to wait for all of the different paths to finish changing. So in here, there's a couple of paths of two and one path of one. So we look at the two. OK, so I tweaked this slide a little bit. So now they all have the same gate delays. Otherwise, everything's the same. So ignore the input inverters. All the designs are the same for delay. So just try to simplify that. All right, so now I want to spend a little time just going through and introducing some terminology that we'll use to help us understand how to optimize Boolean expressions, and then also how the KMAP actually works to allow us to just do a graphical approach. So one thing is a literal, which I've already used. So hopefully you remember, it just means a variable or its complement. So maybe we've got three variables. Maybe we have 10. A literal is just any of those variables or its complement. A sum uses our notation, our plus in place of or. It just means a bunch of things or together. So it doesn't matter what those things are. Anything we want, or together. So the final operation is an or. A product, similarly, we use multiplication to represent and. So a product is just a bunch of things anded together. So again, it doesn't matter what they are. A bunch of things, last function is an and. So a midterm, hopefully you'll remember this idea from the logical completeness construction. We constructed a function with 1, 1 in the truth table. And I said, well, that expression of the product of all of the literals, each variable or its complement appears once, exactly once. We call that a midterm. It produces exactly 1, 1 in the truth table. So that's a midterm. There's a corresponding idea called a max term. So a max term produces exactly 1, 0 in the truth table. So instead of a product, it's a sum. And then each of the variables or its complement appears exactly once. So for example, if you had inputs a and b, you could have a plus b prime, or a prime plus b, or a plus b. If you have three variables, all of the variables have to appear exactly once. So you could have these examples down here. And if you think about what this looks like in a truth table, and you go right down a truth table for any of these with the appropriate number of variables, you'll see there's exactly 1, 0. So those are max terms. Sum of products form, we call this SOP usually. And it has a specific meaning. So it's not just a sum of products. It's a sum of products of literals. So it's an or of a bunch of and terms of literals. So down here are some examples. So the function of f we had before, a b plus b c, that is an SOP form. This is also an SOP form. Each of the things in the sum is simply a product of literals. This one down here is not, because it's a sum. But then if you look at this one, it's not a product of literals. It's a product of a, which is a literal, and also this thing. This is not a literal. So this bottom one is not an SOP form. And then there's the opposite, which is POS, product of sum form. Again, the little catch there is, remember, it has to be of literals. So it's just a product of sums of literals. So here are a few examples. Here you've got a plus b. That's a sum multiplied by another sum. So it's a product of those two sums. Each of those sums, just literals. Same thing down here. Each sum is just literals. This is a sum of one. So it's OK to have a sum of one literal in a POS form. Similarly, I think I, yeah, if we go back here, this is a product of one literal. So that's OK too. But this kind of thing is not OK. This is a product. The last function is d times this thing here. And this is a sum. But this thing here is not a literal. The bc is not a literal. So the last one there is not a POS form. The reason I want to spend some time on SOP and POS is, really, the thing we'll use to optimize our expressions will be k-maps. And the forms that are produced by using a k-map are going to be SOP and POS. So these are the forms you're going to use most of the time in the class. There's also something called a canonical SOP form, and of course, canonical POS on the next slide. Or I guess I put it right there, which is a sum of minterms. So it's not just a sum of products of literals, but it's the sum of products of minterms, or a sum of minterms, where every variable appears exactly once. So this is the form we get out of the logical completeness construction, the thing we did yesterday to come up with f originally. Do you know what canonical means? No. It's a math term. It means unique. So the value of canonical forms, so often you'll see in different areas of mathematics, you'll see canonical forms. The point is, if I have things that I can write in lots of different ways, like the expression f, you saw three different ways. If you think about it, you'll realize, well, I can construct an infinite number of ways. I can always add extra terms that don't change the expression, and I can add an infinite number of those. So there are an infinite number of ways to write it. Wouldn't it be nice if there were some way that we could write it down, I could write it down, you could write it down, we could put them side by side, and if we just glance at them, see that they're exactly the same? So a canonical form is a unique form that allows us to do that sort of thing. Now, honestly, with Boolean expressions for 10 variables or something, you might have 400 or 500 different minterms or maxterms. So they're too big. And even inside computers, there are things called binary decision diagrams, which outside the scope of our class, but computers don't use canonical forms internally either. They're just too big. They're too bulky, and people try to find more efficient ways to represent the functions, and yet be able to compare them easily. But it's a useful idea to have an approach that's unique, and a way to write it in a way that's guaranteed to be unique. We do have to pick an ordering on the variables. And so if you change the ordering on the variables, then you move your terms around. It's not exactly the same. So those are canonical forms. You won't use them very much. What does a arrow b mean? You know this from math? a implies b. So a implies b. So if a is true, b is also true. That's what implies means. So what if a is false? Is the implication true or false? So my mathematician friends tell me if a is false, a implies b is always true. So that's just the definition of implication. So the only time you care about b is when a is true. If a is false, the implication is true. So that's the mathematical definition, and that's how we'll use it, as you'll see in a second. But it also means that these kind of funny statements are true. So don't score above 125%. So if the premise is false for all of the x, then the implications are true. So that's the definition of mathematical implication. So I just wanted to make sure that if you didn't know that, now you know it. And otherwise, if you knew it, now you remember it. The way we're going to use it is on functions. So I'm going to say a function g is an implicant of another function f on the same set of input variables, if and only if g implies f. In other words, every output of 1 in g's truth table has to also have an output of 1 in f's truth table for the same input combination. Now, if g has a 0, f doesn't matter. It's only when g has a 1, f also has to have a 1. So that's what I mean by the g implies f. And we'll do a couple examples in a second. So this is a notion of implicants. Now, in digital design, we actually only talk about products of literals as implicants. So there are lots of possible functions. Remember, maybe 2 to the 2 to the n on n input variables. That's a lot. We're only going to look at products of literals. So it would be far fewer functions. But the implicants we care about are just products of literals. So any time I say implicant, you should assume I mean product of literals. So how do we simplify functions? So here's an idea. So as a first step, we can say, well, if I can find an implicant of g, then maybe I can take out one of the literals. And if I still have an implicant of g, my function will have fewer literals, but it'll still be correct. It'll still be the same function. So here's our original form of f that we got out of the logical completeness construction. And you can see that this term here by itself is an implicant. So if I say, well, if this equals 1, is f 1? So if a b prime c is equal to 1, then f is also 1, right? Because the way we get f is we OR that value together with some other values. If you OR 1 together with some other values, what do you get? 1, right? So good. So this is an implicant. Can I cross out any literals and still have an implicant? Maybe not so easy to see, right? OK, so let's do a truth table. So here's a truth table. We've got a, b, and c, all eight combinations on the left. We have f in this column. And we have the a b prime c with each of the literals removed and the functions written out in these three columns. So take a look and tell me, is b prime c an implicant of f or not? Why not? Yeah, there's that 1 there in b prime c. And if you look over in f, it's a 0, right? So b prime c does not imply f. So that we can't do. We can't cross out the a. What about a c? It is, right? It has two 1's. So here's a 1 1. You look over in f, and there's a 1. Here's another 1. There's a 1 also. So a c is, in fact, an implicant. So b prime c is not. a c is an implicant of f. What about a b prime? Also not. Why? There's this one here. OK, good. So because there's a 1 somewhere in the truth table of a b prime, and there's not a 1 in f, it's also not an implicant. So in this case, we did find that we can cross out the b prime. So we can cross out the b prime, and we're left with a c. And so we can rewrite f as a c plus a b c prime plus a b c. That's a little better, right? We got rid of one literal. And then you can go do the same thing. I won't force you to look at all the truth tables. But if you look at the second one, you'll find you can cross out the c prime. And if you look at the third one, you'll find you can cross out b, or you can cross out c. You can't cross out both. But let's say we pick b. Then we'll get this function down here, a c plus a b plus a c. You say, well, the two a c's are the same, so let me just cross one of those out. And that gets me to what we had before, a b plus a c, or a c plus a b. If you then ask the same question, you go write all the truth tables, and you say, well, can I cross any of those literals out, the answer will be no. So for a c, you can't cross out either. For a b, you can't cross out either literal. So let me give you one more definition, which is if I have an implicant g of f, and I can't cross out any of the literals, I'm going to call that a prime implicant. And it means I can't cross out any literals and still have an implicant. So in this case, a c and a b are prime implicants of f. So that's pretty easy, right? This has a lot of algebra. So you just write your function as the sum of prime implicants. That's SOP form. Want to do one of those? Good luck. Yeah, so that's not really that pleasant, right? You don't want to have to write a whole bunch of truth tables and go poking around, trying to see if one thing is an implicant of another. So instead, what we're going to do is actually develop a graphical tool that will make our lives much, much easier. So all you have to do is look at a bunch of squares and draw circles around them. And that will help you identify those prime implicants without ever having to write down a truth table. So it's actually one that was designed almost 70 years ago. So Karno maps. So we have this approach that we just looked at. But it wasn't very fun. At least, I didn't think it was very fun. Anyone here think it was fun? You can still do it that way. You liked it? OK. You can do it algebraically. Everyone else would do this, I think. So it's not so easy. Easy to make mistakes, too. So let's try a different approach. Let's start with functions of one variable. And let me ask you, so how many implicants are possible? I mean, if I just have a function of one variable, how many different implicants might I have for that function? Remember, there's only four functions, right? And we only want products of literals. So someone name an implicant? A. Good answer. Hey, that's the one I chose first, too. What else? Not A. Good. What else? 1. There it is. OK. 1 is the product of zero literals. So we count it. So we've got three. OK, that's not so bad. If you think about a function on one variable, we can represent the domain of that function as an n-dimensional hypercube. So in this case, it's a one-dimensional hypercube. And each of the vertices in the hypercube will correspond to one combination of the inputs. So I'll draw this for you in a second. But the function f will have one value for each vertex. So if you take your truth table, you write it out. n variables input, you've got 2 to the n rows. Your hypercube has 2 to the n vertices. There's a one-to-one correspondence between your vertices in your hypercube and the outputs of f. The rows in the truth table. So here's a one-dimensional hypercube, a line segment with two vertices. So we can split it in half and say, OK, on the left, we'll have a equals 0. On the right, we'll have a equals 1. And the three implicants then correspond to the two vertices and the edge. So on the right side, we've got the a implicant corresponding to that vertex. On the left side, we have the a prime implicant. And then the edge corresponds to the implicant 1. So there's a one-to-one connection between the features of the hypercube, very simple hypercube right now, but the features of the hypercube and the implicants that are possible on that one variable. So if we write the values of f next to the vertices, we can see which implicants of these three possible implicants are covered with 1's. So which implicants actually imply our function f. So instead of drawing the hypercube, we'll draw two boxes. So you can think of those boxes as representing the vertices of the hypercube. And the left box will be a equals 0. The right box will be a equals 1. And each of those boxes corresponds to a vertex of the hypercube. But they also correspond to a minterm. Remember, a minterm is what gives you 1, 1 in the truth table. And each of these boxes is a vertex or an input combination. And so when you write f into those boxes, they correspond to minterms. So what do we do with that? So then we can mark implicants. So we can say, well, let me take a 1, and I'm going to draw a loop around it. And that means that implicant is an implicant of f. Because here, this implicant corresponds to a, but the function f has a 1 there. So a actually implies f. So it is an implicant of f. But it's not prime. So to know whether it's prime or not, I want to think about making that loop bigger. In other words, can I grow it outwards so that it holds more 1's inside? So the answer is yes. And if the answer is no, that means it's prime. So you'll see this a few times. But we can grow this one to contain the other 1 that's next to it. So let me grow that. So once we have the loop that covers both of these, now it's the whole K-map. So it has to be prime. We can't make it any bigger. We can't circle any more of the boxes inside of our loop, because there are no more boxes to circle. So this is a prime implicant of f. And in this case, we can just say, oh, OK, so now f is 1. That's the function that we wrote into our K-map. So you might think, well, that's a function on one variable. I actually know all those functions. The K-map thing maybe is not so helpful. I don't know. Maybe you'll feel excited. All right, let's look at two variables. So if we do two variables, how many implicants? How many minterms? Four, right? Rows of the truth table. So let's put those down. So we've got ab, ab prime, a prime b, and a prime b prime. Those are the four minterms. What about on one variable, one literal? How many? So there's a, a and a prime, b and b prime. So four more. And then, of course, we've got 1. So it seems we have nine. If you think about the hypercube, so first let's split it up. So we'll split a again horizontally. So a equals 0 will be on the left again, equals 1 will be on the right. And we'll split b vertically. b equals 0 will be on the top. b equals 1 will be on the bottom. And then we've got four vertices, four edges, and a face. So those are going to correspond to our nine implicants. So let me draw those for you. So the upper left, a equals 0, b equals 0, well that corresponds to a prime b prime. Then there's ab prime, a prime b, and ab down on the lower right. So those are the implicants. I'm sorry, the minterms, those correspond to the vertices. The implicants with a single variable correspond to the edges. So there's a prime, there's a, there's b prime, there's b. So those four correspond to circling two of our vertices or correspond to an edge, if you rather think of it that way. And then there's one face, which corresponds to the implicant 1. So if you've got all of the vertices filled with 1's, then you have the implicant 1. Of course, we're going to draw this as boxes again. So in our Karnaugh map, we have four boxes now. Each of the boxes, again, corresponds to a minterm, one input combination, and corresponds to a vertex of a hypercube. So it's a one to one mapping between the hypercube and these boxes. Question? Yeah. That's a very. Yes. Beyond, you can use K-maps easily up to four variables, so it's not going to go that far. With a little moderate pain up to about six variables. I mean, I've done them, I think, on six variables before myself in certain cases. Beyond that, you really want to fall back on algebra. So if you want to use the algebraic approach, it's the same math underlying it. So hopefully, once you understand this, you could go off and do the algebra. There's a theorem called Quine-McCluskey, but really, 462 is the place to learn much more about it. Yeah. So this is just some function that we're trying to represent. So whatever the function is, remember that each of the boxes corresponds to one input combination. So often, what we'll do is just, if you can fill it from an expression, you can do it that way. Otherwise, you can take a truth table and simply say, well, for a equals 0, b equals 0, here's the output value of my function. For a equals 1, b equals 0, here's the value for my function, and so forth, and fill it in. Yeah. There is not. No. Yeah, so 0 is not considered to be an implicant. Yeah. Yeah, it's, I mean, the function 0 should automatically be an implicant. Mathematically. But as I said, in digital design, we only consider products of literals to be implicants. And so you can't multiply any literals. Even 0 literals is considered to be 1. Good question, though. Because mathematically, the answer should be yes, but not for us. All right, so the problem's a little more interesting now. What we want to do is find the biggest loop. So why do we want the biggest loops? Well, remember, if the loop can't grow, that means it's a prime implicant. So we want to make our loops as big as we can make them. So make the loops as big as we can. They have to have power of two edge lengths. Now here, it's either 1 or 2. When we get to more variables, we'll see that there are certain sizes we can't have. The reason has to be 1 or 2. 1 corresponds to a vertex, or a vertical, if you think horizontally, a vertical slice, which would be an edge going vertically. And 2 would correspond to a bigger feature of the hypercube. And together, those loops have to cover all the 1's. So we want to take those different prime implicants, OR them together, and get our function. So if we get loops that cover all the 1's, then that will allow us to get our function back in a fairly simple form. So this is our strategy. So let's try it out. So we're going to start by picking a loop and circling it. So let's just pick this one up here. And as soon as we circle it, we know, OK, well, that minterm, because we circled a 1, is an implicant of G. Is it a prime implicant? Not. Why? Yeah, so I can grow this loop. If I look down, I say, well, I can't include this 0, so I can't grow downward. But if I look to the right, I can make the loop bigger by growing it out to the right. So let me do that. So it's not a prime implicant, because we can grow it. So let's grow it. So that loop now represents B prime. So one thing you'll want to be able to do is learn to read these loops off. So I've annotated the KMAP in the most helpful way. But in some of our notes and other homework problems and stuff, we may not draw these extra markings for A. We may just give you the numbers. But here, you can see this one down here is B. So the implication is this one is the B prime implicant. The B prime is also an implicant of our function G. Is it a prime implicant? So remember, if we're going to grow it, we have to grow the whole thing. There's only one direction left. So if we grew it downwards, that would include the 0. We're not allowed to include a 0. So in this case, we can't grow this loop anymore. You can never cover a 0, because then the function you would get out of that loop would not be G. It would have more 1's. All right, so the answer is no, we can't grow it. Eric? I had to start somewhere. Oh, I had to start somewhere. I will tell you how to choose later. But for now, you've just got to start somewhere. I'll come back to that later, because sometimes it matters. But here, it doesn't matter much. What's the next one? Well, we'll do that one next. OK, we've got this one left. So we have to cover that one. Otherwise, our function from this loop will not have this particular 1. All this implicant will generate are these two 1's. So we need a second loop. So let's circle that bottom 1 now. So that's the midterm AB, which is also an implicant of G. But is it a prime implicant? Why not? You can grow it up, right? We can't go left, but we can grow up. OK, so let's grow up. What we have now is the implicant A in that second loop. And that one is a prime implicant of G, because we can't grow it to the left. So we now have two loops, each of which is a prime implicant. And so we can write down those two together with an or in between them and get G out. So these two loops cover all of the 1's. So we can write G equals B prime plus A. Are you excited? OK, you're not excited. So we'll have to keep going. We're going to go to 10 variables. No, I'm kidding. All right, so guess what's next? Three variables. So how many implicants? Yeah, here's some big numbers, but yeah, that's right, lots. OK, so let's do it a different way. So I said that there's a one-to-one mapping between these implicants and features of the hypercube, right? 3D hypercube's a cube. Let's count features. So here's the cube. Let me split it up. Same way for A, same way for B. C, the bigger square, is going to be the outside. It's going to be C equals 0. And then the inner square is going to be C equals 1. So there's our square. So now let's count. So how many vertices? Eight? Eight corners of the cube. How many edges? 12, good. How many faces? How many cubes? Good. So that adds up to 27, right? OK, so now I think some of you said that already, I know. But I had to figure it out. So you notice a pattern? When we had one, we got three implicants. When we had two, we had nine implicants. When we had three, we had 27 implicants. Sounds like 3 to the n. Why should it be 3 to the n? So if you think about, well, what are we calling an implicant? It's a product of literals, right? So if I'm going to say, hey, there's a product of literals, I can then ask, well, what about the variable A? What are my choices for A? Yeah, so A, A complement, or not there. Three choices, right? So three choices. Include it, include the complement, don't include it at all. So for every variable, we have three choices. If we have n variables, 3 times 3 times 3, n 3s multiplied together gives us 3 to the n. So if you have n variables, you have 3 to the n literals, and 3 to the n features of your hypercube. So that's why, once you get to 4, it's actually a pretty complicated problem. Even three variables, it's sometimes difficult to look at an expression and just say, ah, I know how to simplify that one. If you spend a lot of time practicing Boolean algebra, maybe you can do it. But probably a little easier to use the K-map. But how are we going to map this cube thing into squares? So let's see. So look at the top half up here, and let's try to put that in some order. Let me do that by just drawing lines straight down, and I'm going to write the values of a and c down here on the bottom. So the upper left one is 0, 0. The next one, going to the right and ignoring the vertical dimension, is this one. a is 0, still c is 1. So ac is 0, 1 there. How about this one here? 1, 1. And how about this last one? 1, 0. Good. OK, so we have this order down here. This is called a gray code order. A gray code means one bit flips at a time. It actually wraps around. So you can see if you look here, 1, 0, and then around on the other side, 0, 0, one bit has changed at every step. So those connections represent the edges of the hypercube. So each adjacent ac pair shares an edge, and then the last edge wraps around in this horizontal mapping. So there's four edges. The top face is all four of those. So if you then use that to map into boxes, what you get is this gray code. And your loops can be one box wide. That means they're a vertex. It could be two boxes wide. That means they're an edge. Or they could be four boxes wide. That means it's a whole face. It can't be three boxes wide. Three boxes do not correspond to any feature of the hypercube. So when you look at your K-map, and you've got two variables in one dimension, first of all, you're going to use gray code order. So here's a picture. So you can see on the top, we've got the variables A. A is on the right, C is not A is on the left. And then C is inside is 1, and outside is 0. But you can see there's gray code order across the top for A and C. And if you think about what these mean, any adjacent boxes will map into an edge of the hypercube, including adjacency of wrapping around. And then if you pick all four, that's the face of the hypercube. So let's find a way to solve this particular H. So again, we're going to start by circling a 1. So we'll solve this K-map by doing the same process as we did before. So there's our first 1. So that's the minterm A prime, B prime, C. So is that a prime implicant? So with three variables, there are three ways we can grow. So you've got to look in all three directions. Here to the left, there's a 0. Can't go that way. Here to the right, there's a 0. Can't go that way. Here below it, a 0. Can't go that way. So we can't grow it. So this one is prime. But we've got more 1's. So let's pick another 1. Let's say I pick this one here. So that one is A prime, B prime. I'm sorry, A prime, B, C prime. So you can read the variables off, just like you do in the truth table. So A is the left one in those two. So A prime, B is a 1, and C is 0. So C prime. Is that one prime? Why not? Yeah, so remember it wraps around. So I can grow to the left here and wrap around. Let's grow that. So now it wraps around. So that new loop is the implicant B, C prime. It's an edge of our hypercube. So is that one prime? Yes. But can't I pull this one in? Yeah, that would be 3 wide, right? And 3 is not allowed. That does not correspond to an implicant. So you can do it in a, if you get confused, you might circle 3. But then when you try to figure out, well, what's the implicant? There's no answer. There's no implicant for that. So this one's prime. So that one we'll leave alone now. But we still have one more 1. We've got to circle it. That one's A, B, C. Is that prime? Why? Grow it to the right. OK, good. Let's grow it. We go. So that's A, B. Is that prime? OK, so I think we've got all the 1's covered. So that's a prime implicant. So the 1's are all covered. So then our function is just the sum of those three loops. So we had the first one we wrote was A prime, B prime. I'm sorry. Yeah, A prime, B prime. I copied that wrong, didn't I? No, no, no, I got it right. B prime, C. Yeah. OK, yeah, this one is A. So it's A prime. B is 0. So it's B prime. And C is 1. So it's C. That was right. This one that spanned around, that wrapped around, was B, C prime. And then the one we just circled was AB. So together, those three give us our function H. Now hopefully you're excited, because that was probably a lot easier than playing with the algebra. OK, so let's go on to four variables. It's a little hard to draw the hypercube. Not impossible, but probably not worth the time. The K-map's not so bad. Basically, we do the two variables in each of the two dimensions now. And we'll use gray code order in both dimensions. So we'll have, again, no three box loops. So in both dimensions, you can circle 1. You can circle 2. You can circle 4, but you can't circle 3. So in both dimensions, any of those combinations is fine. Your goal is to come up with a minimal number of loops of maximal size. So if you succeed, it turns out that, oh, and they cover all 1's. You have to cover all the 1's. And of course, your loops can't cover 0's, as you know. If you do, that result will be optimal amongst SOP expressions by our area heuristic. So the same area heuristic that we said, we're going to use this to measure the area of your circuit, this will give you the best answer for that heuristic. Now, POS expression might be better. K-maps don't really help you spot XORs. So you might be able to use XORs and come up with an even more efficient circuit. But this will give you a pretty good answer. So this kind of comes back to your question, Eric. So sometimes you'll go through this process. And you might find, well, after I've filled all the loops in, I've got a loop that I don't really need. It's actually everything inside of it is covered by other loops already. You can get rid of that loop. As you get more experience with this stuff, you'll actually start to look around for the loops that you know you're going to have to have. And the way you do that is when you pick a 1 to start a new loop, if you've got choices, if you have something actually like the, I don't want to go all the way back there, but if we had started with the corner in the example, what I'll do is draw it on the board. So if we start here in the corner, that means we could grow in either direction, but we can't grow in both. And so I have to make a choice. So choices are bad. Pick the ones where you don't have any choice first. If you pick the ones where you don't have any choice, those you're going to have to include. So as long as you start by doing those, you'll find yourself less often in the end having to go back and take away some of your loops. So the final thing I wanted to say there is sometimes there's more than one optimal form. So don't worry too much if your answer is different, because for some functions, there's more than one right answer in terms of optimal SOP forms or optimal POS forms. So here's a four-variable K-map. I'm not going to solve this one now, but let's see. What's time? Yeah, let's go play with one in the tool. So I will switch over and tell my laptop to let you see what I'm doing. Get out of the wiki. So down here, there's this Karno Maps tool. And so we want to be excited. So let's do four variables, solving K-maps. So here's a random K-map that it just came up with. So help me out. What should I circle? Circle. Yeah, let's start with the top left. That's a good idea. So if I start with the top left, then which way should I grow that? Grow that to the right? So I can grow it once to the right. Can I grow it again? So let me erase this one, and I'll put the whole one there. Can I grow it up or down? No, that one's prime now. So then let me go find another one to cover. How about this one here? I'm going to do that one next. Can I grow it? Which way? Some people said down, some people said up. OK, so down would be here. OK, so let me grow that up. Is that fully grown now, or can I make it bigger? OK, good. And maybe you want me to do that square there next? OK, now we can do that. So this one I can grow in two directions, that way or that way, and I can actually do it both at the same time. So let me pull that one. What about this one here? To the left, OK. So I'll pick that. How about this one? Yeah, I can go right. I can actually go down also, right? Yeah, so either one of those will be OK. So let me pick the less obvious one. Maybe what I'll do is pick both of them for you. So I can go down, and I can say check answer. Oh, it doesn't like me to pick that one. Hmm. What did I do? Oh, yeah, I can make a square. Good point. There we go. Yeah, that's much better looking. That has one fewer literal, right? Because every time you grow it, you're getting rid of a literal. It's the same thing you're doing algebraically, except it's a heck of a lot easier. At least do this for me. I assume it will be for you, too. OK, so there's a good answer. How do you read this? So there's a good question. So for each of these loops, you would then need to read off the literal, right? So let's take this last one that we did. So because it's all outside the b equals 1 region, that means there's a b prime in it. So these two rows are b equals 1, and the other two rows are b equals 0. So since it's spanning those two rows, we have b prime. h varies, because h is equal to 1 here and 0 up there. So h does not appear in this particular loop. m also does not appear, because it's 0 here and 1 here. And d is equal to 0. d is 1 on that side and 0 on this side. So this is d prime b prime. And if you want practice reading literals, there's actually a couple ways to do it. But you can go back to KMAP Implicants and say you want to identify literals. So here, it's just pulled up an example. So d g prime n. So where is that? So every time you have a literal, it's going to cut the size in half. So the literal 1 would be all 16 boxes. If you had one variable, that would be eight boxes. Two will be four boxes. Three will be two boxes. So that's the first step, is just to realize, OK, this is two boxes somewhere. It's inside of d, so down here on the bottom. It's inside of g, so on the right. And it's g prime. So d g prime and then n prime. So n is here. So n prime is these two. So let me go mark those. And if you get it right, it'll say green. And if you get it wrong, say I say, oh, I like this one, it'll say, no, you're wrong. So it'll say green or black, depending on whether you get it right or wrong. There. So you can practice your implicants with this tool. There's a bunch of different ones. You can do expressing, too. So with this one, what you have to do is check whether these implicants appear are circled over here. So there's always something extra. So and then you just say yes or no, if it appears or not. So you can practice your mapping from the K-map to the algebraic form. And then if you really want to do the whole thing, you can also, you don't necessarily need to use this tool yet. But if you go to here, this tool is actually doing combinational logic design. So it allows you to copy, although it has x's in it, which we haven't talked about. That'll be next week. It allows you to copy the truth table into the K-map. But because the tool's exercise is logic design, you can also just go over here and say, no, do that for me. And then it allows you to solve the K-map. Because again, it's a logic tool. So you can say, no, I know how to do that. Do that for me. And it'll just solve it for you. And then the next thing is you should write down the expression. And so you can figure out what you think the expression is and then tell it, OK, what should the expression be? And it'll tell you. So if you want to double check, you can do it as in the other tool I showed you earlier, where you're answering is this implicant there or not. Or you can do it this way, write down your answer and then have the tool automatically generate the answer so that you get the same answer. So a bunch of tools you can use to help you learn how to solve K-maps. Thanks. I'll see you Monday for a review session. Oh, Verdin is teaching on Friday.\",\n",
       " \"comment on that briefly before we talk about material. So we are splitting up the midterms to come up with rubrics. We're gonna grade Saturday the 24th, so you should see your grade on campus hopefully that evening. But I looked through about 20 exams on my problems, which were two of the six, and people were doing pretty well. So I think overall we were pleased, or at least I'm pleased so far. So I think people did well. I was a little surprised other people's rooms I think left a little earlier than mine. So that I was worried about that, it seemed like maybe it was too long if we designed it for 45 minutes. And we hit the 50% mark at about 827, which seemed a little too late. That 50% of the people had left my room by about 827. So, but other rooms they said were leaving earlier, so maybe it's okay. But I think that a lot of people were probably just... Yeah, yeah. No, so the comment is that a lot of people were probably just hanging out and checking work. So yeah, I understand that. But on the other hand, when I've done two hour exams designed for one hour in the past, usually they're not staying to the very end. They're staying a little extra and then moving. But we'll see. I think people did well is the main message. All right, so today we're gonna go over Boolean properties. I'm gonna start with duality and use that to kind of look at a few things. So we'll go through several results of the duality property of Boolean algebra. Then we'll take a look at what we call don't care outputs, which are outputs of functions where we don't care what the answer is for various reasons. So I'll give you examples of those. And then I'll actually do an example using don't cares and seeing that we need to be careful about when we say we don't care. So, yeah, I know that's great. Okay, we'll come back to that in real detail later. All right, so I wanted to just review and then maybe ask you a question. Professor Veridan said that he wasn't quite sure that you got one point in the notes. So I'll ask you after I kind of get you back into the speed of things with these couple of slides. So hopefully you remember and you've done several K-maps by now, or maybe you just put off K-maps and studied for the exam. But if you remember K-maps, your goal is to pick a minimum number of loops of maximum size that together cover all ones, that'll give you an optimal SOP form for amongst SOP expressions by our area heuristic for four or fewer variables. Sorry for all the caveats, but if you really go to bigger variables, then these two metrics are not quite equivalent. So it's not really optimal. But for the K-maps, it will have you solve their optimal in the area heuristic. So what you won't see is you won't be able to compare directly with POS or XOR. So XORs will not come out of K-maps directly. You'll have to identify them yourself. And POS to do that, hopefully you remember you draw loops around zeros instead of drawing ones, you make them as big as you can, you cover all the zeros. And then when you calculate the POS factors for the loops, don't forget that the variables, the literals are all complimented relative to the implicants you would get for an SOP form. So hopefully that made some sense. Unfortunately in the tools, it's sort of when I wrote the K-map tool, I deliberately left out POS thinking, well, the goal is not to have you do tons of exercises with both just to understand that you can do both. And SOP is kind of the main one just to get some experience with optimization. But then on the midterm, sometimes we'll ask about POS and sometimes we'll ask about SOP and we tend to go back and forth. So if you want more experience, you can actually go to the layout tool, the logic design tool, and that will give you K-maps where you can do POS solutions and the K-maps will be marked properly. So use that tool instead. And you can also say skip step and it'll show you how it'll be marked, but you can do it and then check the answer and they'll tell you whether you got it right. So use that tool if you want experience with POS. So one question, Professor Verdean said he wasn't sure that people understood why a single, if you have a function, which is a single NAND gate or a single NOR gate, do you understand why that's both POS and SOP form? Yeah, more or less. Okay, good. I mean, we can draw it and then the trick is to just use DeMorgan's to move the inverter across the gate and then it's either a single product of several sums or it's a single sum of several products of single literals. So one gate is basically both POS and SOP, one CMOS gate. All right, so Boolean algebra has this kind of cool property called duality. So the dual of an expression we can find as follows. We can go take the expression and look for zeros and ones and swap them. So if you see a zero, you replace it with a one, you see a one, you replace it with a zero and then look for ANDs and ORs, swap AND with OR, swap OR with AND and that gives you what we call the dual. All right, let me give you an example. So up on top is an expression. So to find the dual, you just do the swapping. So replace one zero with one, one with zero, OR the pluses with multiply AND with OR, vice versa. And what we get is this thing down on the bottom. All right, so the dual of the top is down here on the bottom and then if you say, well, what's the dual of the dual? Well, of course, if you swap again, you get back the original expression. And all we're doing is swapping zero and one, swapping AND and OR. So the dual of the dual is the original expression and that's where the term duality comes from. All right, so there's two aspects of the same thing. Mohammed, come here. Yeah, that's a good question. Let me answer that on an upcoming slide. Why do you care about this, right? It's kind of, hey, that's cool, but who cares? Yeah, Eric. Yeah, so literally, if you look at these two, right, the AND here becomes an OR, the OR becomes an AND, the one becomes a zero, the zero becomes a one, the AND becomes an OR. Everywhere you see an OR, you write an AND, everywhere you see an AND, you write an OR, zero becomes one, one becomes zero. Make sense? We're good, except why do we care? Okay, so before we get to why do we care, one or two more slides. So be careful, don't change the order of operations. So I picked that previous expression kind of carefully and put lots of parentheses in it. But if you write something like this, do not just replace AND and OR, do not just swap those two. You need to add the parentheses so that the BC operation happens first. Okay, if you change the order of operations, that is no longer the dual. So be careful with that when you're taking a dual. So why do you care? So three reasons. Well, let me explain them briefly, and then we'll go back to each of them in more detail. So first of all, when you look at a CMOS gate, actually the network on top of p-type MOSFETs and the network on the bottom, those are actually dual Boolean expressions. Okay, so when you build a gate, you're using dual Boolean expressions, and I'll show you a non-NAND-NOR gate a little later by simply taking the dual. So that's kind of useful if you wanna build a more general gate structure out of MOSFETs. It's also a quick way to complement any expression. So I'll show you a complicated expression, and then simply use duality to find the complement instead of recursively applying De Morgan's rule, which is both error prone and painful. And then finally, this principle of duality. So let's start with that one. The principle of duality says that if I write down an identity or a property of Boolean algebra, then the dual of that identity or property is also true. Well, if it's false, it's also false. If it's true, it's also true. So it has the same logic value. So we're gonna use that in a little while to basically expand all of the different Boolean properties by simply taking their duals to find new properties. And you'll see a lot of the ones that you've already know intuitively are actually duals of one another. So we'll use that in a few minutes. Okay, so the second one on that list, generalized De Morgan's. So let's say we have this expression F, and I wanna find F prime. And so I wanna find the complement of my expression F. So one way to do that is we'll say, okay, so I put the prime on the outside of F, and then I apply De Morgan's, and then maybe I have to keep applying De Morgan's over and over again until I get rid of all of the different steps inside of F. So that's kind of painful. Or we can use the generalized version based on duality. So write the dual form, swap the variables and the complemented variables, and that's it. So that's it. So if you can write the dual, and then you can go through and, if there's a variable, you can add a prime to it. And if there's a variable complement, you can cross out the complement, then you're done. So a little easier than rewriting each step through De Morgan's laws. So here's an example. That's a nasty looking one, right? If you want, you can do this by hand to verify that I got the right answer. So what's F prime? Anyone? Yeah, it's not that fun looking, is it? Okay, so first we'll write the dual. So here's the dual. All I did is I took the ands, I replaced them with ors. I color coded the parentheses so you can kind of line them up visually, but it's all the same, right? Ands become ors, ors become ands. There are no zeros and ones. And then I go through and A becomes A prime, B becomes B prime, L prime over here becomes L, right? So the second step is to just complement all the literals, either from uncomplemented to complemented or vice versa. So then we're done. That's F prime in a fairly nice form, right? Without lots of extra complements on anything. Yeah. Yeah, so remember the variables or the complements are the literals. Did you mean there are no zeros and ones? Okay. It's okay, it's not a bad question. Anyone else have a question on this? So at least I think this is relatively easy compared to going step by step, right? So if you go step by step, then first you would, let me make sure I can parse this. You've got this big expression here. So you'd apply DeMorgan's to this big and, and you'd get A prime or B prime for complement of this thing, right? Which then if you kept going, you'd eventually get this, right, but you'd have to go step by step. But you can do all the steps at once using the dual form. Yes, yes. So when you take the dual form, you do have to swap zeros and ones. So normally we very rarely write equations with zeros and ones. We'll do that in a few minutes for our properties, but most of the expressions you care about don't have zeros and ones. No, you'd change the variable. That's a good question. Yeah, only the variable. Yeah, so if you think about, if you said F prime, you'd have to swap the variables. Yeah, so if you think about, if you said F equals zero, and then you take the dual, you'd get the dual equals one. And then if you complement it again, you'd get F prime equals zero, which is wrong. Yeah, so zeros and ones, you complement when you do the dual. So you don't complement them again, which may be what you were thinking about before. I'm not sure. Okay, so once you get familiar with this, you can just skip the middle step and just write it out. And as you go, change the variables to the complements or vice versa, and change and more. Be careful again about the parentheses. Don't let the order of operations change. All right, so this then, I kind of find the coolest part. So if you look at the CMOS gate structures, the type of the network of MOSFETs on the top, the P types on top, the N types on the bottom, those two are actually duals of one another. So let's think about the N type, and let's assume that we've got a gate where we've got four N type arranged in parallel. So the output is connected through four parallel N type MOSFETs down to ground. So in that case, if any of those four transistors is on, then the output is zero. So those transistors, let's say, are controlled by inputs A, B, C, and D. So Q, the output is zero if any of the transistors is on. In other words, if A or B or C or D, then Q is zero. So Q then, of course, is that value complimented, right? So Q is zero when any of those is true. That's a NOR gate, a four input NOR gate. So think about the, sorry, think about the P type on the same gate. So if you've got them in parallel on the bottom, they're in series on the top, right? So those connect Q up to VDD, but in order for the connection to be made, all four of those transistors have to be on, right? So when are they on? Well, they're on when each of the inputs, A, B, C, and D are equal to zero, right? Having those equal to zero is what turns a P type on. So in other words, we have to have A prime, B prime, C prime, D prime, and that's Q. But those two are the same, both in NOR gate. So you can actually derive the output for a properly formed gate by looking at either of the two. And what I want you to notice then is that A, B, C, D form, looking at it this way, here I have A, B, C, D prime, A, B, A, or B, or C, or D complemented. And if I were to then take the dual of A, B, C, and D, and I get A, B, C, D, and if I were to switch those, I get A prime, B prime, C prime, D prime, which is the same expression I get if I derive Q from the P type transistors instead of the N type transistors. So we can get this equivalence two ways. One is by just deriving from the forms, but the reason that works is because the networks of transistors are actually the duals. So in this case, the duality comes from the structure of the networks and the complements come from the use of P types versus N types, right? That the P type transistors turn on when we put the opposite value in from the N types, right? P types turn on with a one, N types turn on with a zero. So that's where those two come from. So we can make use of that. So this, sorry, this is the explanation I was just giving. So the dual form is actually built into the gate design, right? So the upper and lower networks around the output are actually duals of one another. And the flipping of the complements comes from the use of P type versus N type. So let me give you an example of that. So here's kind of a strange looking gate, right? You look at that and you say, wow, what does that do? So you can, again, derive it from either expression. If you look at the bottom, for example, then Q goes down to ground if A or B is on and C, right? So A plus B and it together with C and then complemented because going down to ground means Q equals zero. You can get the same expression by going upwards and saying, well, Q is equal to one if A prime, B prime or C prime, right? And you'll find, of course, those are the same, but the dual, if you were to instead say, well, what's the dual of this expression, not with a complement, but what's the dual of this expression? Well, it's A and B or with C, this one down here. And if you look at the P types up here, you've got A and B over here or with C over here. And so that's the structure of the P type network. So you've got the duality between the P type network and the N type network. And that ensures that you don't have a short, right? So if you think about, well, what happens if I don't make them duals, right? I can put transistors wherever I want. Generally, if you're not careful, if they're not duals, you have a pretty good chance that there's some input combination that will give you a path from VDD down to ground, right? Which will destroy your chip. All right, so that was the third use of duality. You have a question? Yeah. Yeah, that's where I got this one here from the N type network down on the bottom half. So the parallel construct is an or, right? Because Q is connected to this dot here, if A or B. Right, so if A or B, then one of these transistors will be on and Q connects electrically down to this point here. Now to get to ground, this transistor also has to be on. So we end the A or B with C. And that says this transistor is also on. So if we have A or B ended with C, then Q is connected to zero. And so in order to get the actual value of Q, we have the complement. Yeah. Okay. Forward or backward? Okay, this one? So remember that the, so the dual structure comes out of the networks. Okay, so this one is parallel, right? And this one is serial, okay? The complements come out of the N and P types. So in order to turn a transistor on for an N type, you put the value equal to one. For a P type, you put it equal to zero. And so for all of these four transistors to turn on, A prime has to be true, B prime has to be true, C prime has to be true, and D prime has to be true. Because these were derived from the P type transistors. I didn't draw this one, so let's look at this gate. So here, for example, if you look up at the P types, I have chalk, okay. If you look up at the P types, then what you have is A prime and B prime, right? Because in order for this connection on the left from Q up to VDD to be electrically connected, these two transistors have to turn on. To turn on, A has to be zero and B has to be zero. So this is A prime, B prime. And this path here is C prime. So if either of those two paths is on, I get an electrical connection. Sorry, I think I cut off from the left. So this is what I get if I write the value of Q from the P type network. And this one here that I've written is from the N type network. But you can see if I apply De Morgan's to Q equals A plus B, and it was C, was it? So remember, I would take the dual, so I would get A, B, or C, and then complement all the variables. That's the same thing. Well, I applied generalized De Morgan's. We could also apply it one step at a time, if you'd rather, which would give you an intermediate step of A plus B prime, or with C prime. And then when you apply De Morgan's again, you'd get this one. Yeah. You mean if you wanted to produce a gate that had the complemented output? Yeah, so you could imagine, if I have to write Q in a form that has only uncomplemented literals, because those are N type MOSFETs, and then with a complement at the end, I can't express any arbitrary Boolean function that way. So I don't have complete freedom, actually. So what you would typically do is, if you really needed, say, this function here without the complement, we'll put an inverter after it. So you could build it by playing the trick of swapping N type and P type, but that would give you problems because of the way they work, as we talked about when we first discussed MOSFETs. Well, so the things you can build with MOSFETs are the ones where you have a complement outside an expression formed of uncomplemented variables. So those are the things that you can build directly. You can build all functions, of course. It's, I mean, NAND and OR are both logically complete, and so I can build anything with MOSFETs. But to build a gate directly, the expression I get has to be of this form. Does that make sense? Okay. Okay. All right, so this was just an example of the kind of thing you could do. So one question you might wonder is, well, why don't we do more of this, right? If you want to build an adder or some other circuit, why don't we go down all the way to that level? Now, let's take a look at the area and speed. So the function here that we just derived requires six transistors and one gate delay. You saw the diagram. There are six transistors, and it's one gate delay, because it's basically a gate, a gate-like structure. So six transistors and one gate delay. Now, if instead I said, oh, I want to build this out of NAND and OR, well, then I would have to do this. I could write Q equals A prime B prime complemented ANDed with C complemented. That would be a two-input NAND to produce this value, and another two-input NAND to produce Q. So I could use two two-input NANDs. So each of those two-input NANDs is four transistors, and it's two gate delays. So eight transistors and two gate delays. So it's bigger and slower. Well, gee, why don't I just go down and optimize? Most of the time, people are not going to do that. They're just going to use NAND and NOR or even higher level. When you get into a class like 385, you're going to find you're actually writing something like C. You use a language called system Verilog to describe your hardware. You'll say, hey, I want to add some numbers together. Go produce an adder for me. So in fact, people aren't even getting down to the level of gates much anymore. So why not? Why not go optimize? Well, the problem is the more time you spend optimizing, breaking that abstraction boundary, the more likely you are to make a mistake. The more likely, when you make any change, that you've got to then go redo a lot of your work. So it's a big cost of human productivity and often a small advantage in size and area. To the extent you can get your tools to do it, your computer tools, then the computer tools will do some of this kind of optimization for you. But in general, that abstraction boundary, saying, well, I know how to build gates like NAND and NOR. Give me a library of those gates. Let me plug them together. Or give me a library that includes an adder. And I just want to be able to put an adder or some of the other components you'll see in a few weeks. People are usually working at the higher level in order to be more productive. You have a question? So that's the reason. Generally speaking, if you're willing to go down and optimize by hand, you're going to get some benefit. But remember, a typical processor has billions of transistors. So if you look at every transistor for five seconds, you're not going to finish in a useful product time. Yeah, so certain companies do do custom logic. So companies like Intel, Apple, and Samsung together do custom logic. For the most part, almost no one else does. A couple of networking companies. But for the most part, other people use standard libraries in designing their hardware. Yeah. Not terribly a lot. System Verilog has a little more object-oriented capability. Also what's known as high-level synthesis. So the ability to describe things in a more flexible way at the possible expense of not being able to synthesize them. So I'm sure people who use them every day would argue vehemently that one is just nicer than the other. But practically speaking, you can do pretty much anything in either. System Verilog is a newer language. And also it gives you this high-level synthesis benefit, which has some advantages and some disadvantages. Kind of similar to this, actually. I'll share it. That I'm not sure. Let's take it offline. And I'll see if I can find ways to get you something to play with. OK. Anything else? No? Yes? All right. Oh, we have plenty of time. Good. OK. So let's take a look at some Boolean properties. So these are the easy ones. You probably already know them intuitively. But they're kind of useful to commit to memory if you haven't. Because when you take a look at a circuit, as you'll end up doing several times in our class, many times in our class, being able to analyze it quickly is useful. So we'll ask you to look at something and tell us what it does, and being able to just go through. So for example, you probably remember that if you OR one with some variable, out comes a one. So any time you have an OR gate and you put a one in, you get a one out. Similarly, this is the dual over here. So if I take the dual, I get 0, 0. And I get OR replaced by AND. So it says, well, if you take AND, and you AND something with 0, you get 0. So those two properties are actually duals of one another. Similarly, if you AND something with 1, you get that something. If you OR something with 0, you get that something. Those are also duals. If you OR something with itself, you get it back. If you AND something with itself, you also get it back. If you AND something with its complement, you get 0. If you OR something with its complement, you get 1. So all of those properties, relatively simple properties. But if you memorize them enough that you can spot them quickly, then you can start crossing out pieces of circuit and thinking about what happens in partial cases. So they're kind of useful properties to memorize, and they're pretty simple. De Morgan's laws are also dual forms. So there are two De Morgan's laws. So if you write one of them, you get A or B complemented equals A prime B prime. And if you then take the dual of that, you'll get the other De Morgan's law. And so they're just duals of one another. So I won't walk through that one. So what about distributivity? You probably remember this from algebra. So if I say, well, if I take some number A and I multiply it by a sum, B plus C, well, I can distribute the multiplication over the addition. So I get A times B plus A times C. That also works as Boolean algebra. So and distributes over or. So here's kind of a weird thing. So what if you take the dual? What happens if you take the dual of this distributivity law? Or distributes over and. So that's kind of weird. It's not intuitive. So if you're trying to manipulate Boolean algebra, you'll want to remember this. I don't think you have to manipulate Boolean algebra much, but this is what it would look like in our usual algebra. This is just wrong. But in Boolean algebra, it's right. So because of duality and because of the way Boolean algebra works, you can actually take this or and say, OK, A, B plus A, C. I'm sorry, A plus B times A plus C is the same as this expression here. You distribute the or over the and. All right, so one more property called consensus, which is just kind of non-intuitive. If you have intuition looking at this, good for you. I'll show you graphical reason to try to give you some intuition. But I find it a little bit difficult to understand. But basically, the way it works is if you have two terms where you've got two variables and then the other variable is a complemented variable, and then you've got a third term, which is those two variables added together, you can just throw that one away. You can just cross it out, and you get the same expression. So on the right, all I've done is I've taken the two left terms and then dropped the right term. So this is called consensus because when these terms are true together, this one is implied. That's where the term consensus comes from. The consensus of these two terms implies this term. So I find it non-intuitive algebraically, so I'll show you KMAP. So the green ones are the two terms that we're using on the left. So AB is the vertical green loop here. A prime C is this loop, the green loop down here. And BC is the black loop. So you can see, well, if I put ones for those two loops, then this loop is also true. It's also an implicant. So that's consensus visually. Using it algebraically, you've got to spot the matching between the variables and their complements. But at least, hopefully, after this, you understand why it works in the algebra. I don't. But you've got some expression. In general, it could be more than a variable, but it's B here. It could be an arbitrary expression, another arbitrary expression, C. And then ANDed with those two, you've got a variable and its complement. And then the third thing that you need, the thing that you're going to cross out, is the two expressions B and C ANDed together. Yeah, B and C can be expressions. And I think A and A complement could also be expressions. A could be an expression and complement. Anything? Yeah. OR distributes over AND. So you know the principle of duality. And you take this one, and you get the dual. How it actually works is here you've got an OR that you would normally apply after the AND. And instead, you take the OR across each of the factors in the product, and then you multiply those ORs together, which is what you get on the right. So you take A ORed with B, A ORed with C, and multiply those two together. If you had BCD here, there would be A plus D. Make sense? Yeah, it's somewhat non-intuitive, of course, because you would never do that in our normal algebra. Yes, yes, yes. The principle of duality says that if you have an identity, which means an equation, or a property, and you take the dual of that, it has the same truth value. Yeah. Yeah. Yeah. So the A's have to match, except this one is complemented. And then this B and this C have to show up here. So you can have variables. You can replace A, B, and C with arbitrary expressions, but those will be harder to spot. We're not going to have you do a lot of hand-based Boolean algebra optimization. These days, the CAD tools will do it for you. But if you write the next generation of those tools, you need to understand this stuff, because you're going to have to write programs that use these optimizations to manipulate the expressions internally to the program. Yeah. I mean, the underlying math is, yes. So what's done these days is there's something called binary decision diagrams that try to split the space somewhat optimally. So you look at your function. You try to pick something that will divide it well, evenly. So you pick one of your variables, and then you say, well, this is the best variable to look at first. And then you do the same thing recursively. So those are what's used in modern commercial tools to talk about functions and to compare functions. And it's well beyond the scope of the class, so don't worry if you don't. OK. So this was the consensus illustration. And consensus, of course, has two forms. You can take the dual. So if you take the dual, you'll get this one down here, which I won't show you a K-map. But you can do that one, too. So that's it for Boolean properties. Yeah, I think the main ones to learn, duality is useful in the practical sense of designing gates and also taking the complement of arbitrary expressions, generalized DeMorgans. But I think the short identities for analyzing circuits, just knowing that if you put things together, you've got a 1 with an and. Well, you can ignore that input. 0 with an and, a 0 comes out, those kind of things. Those will help you analyze circuits quickly. Some of the others are just useful for doing algebraic optimization or equivalence. All right, so let's talk about don't-care outputs. 15 minutes or so, a little more. So sometimes we don't care. So we've got a function. We don't care whether a particular input combination generates a 0 or a 1. So when would that be the case? So in some cases, we may say, well, that input combination can't happen. So for whatever reason, it's just impossible to get that input combination. So the output doesn't matter because we're never going to generate it. Our system will never generate that output. So who cares what it is in the equation? Sometimes also you'll get designs where your hardware is part of a bigger system. And you know that if you get that particular input combination, whatever your system outputs is ignored. So who cares what you output? It doesn't matter. So there's a couple of common cases where we don't care what the output is. So what good is that? In such a case, we can mark the output as an x, which means don't care. So instead of writing a truth table with 0's and 1's on the outputs, we can put x's. And that says, well, either 0 or 1 is OK. Now be careful because whatever you actually build will not generate an x. Hardware does not generate x. It generates 0 or 1. So whatever your design ends up being, it will generate 0's or 1's. So you need to make sure before you go putting x's that it's OK to have any combination of 0's and 1's for those outputs. Because if some combinations are not OK, you actually do care. So why is this useful? So more choices means a better answer for pretty much any choice of metric. So say you optimize a KMAP for some function f. And then you say, well, maybe I don't have to use f. I could use g or h or j. So the best answer amongst those four is always at least as good as the answer for f. Because you could always just say, OK, I'll pick f after all. So you're never going to get worse. You might not get better. But in general, you can get better. And you can never get worse if you look at more functions. So using an x actually means that you're looking at many functions. Each of those x's gives you two choices of functions. You could pick the function that has a 0 in place of the x or the function that has a 1 in place of the x. So if you have n x's, that means you're picking from 2 to the n possible functions. So if I put 4 x's in, I've got 16 functions I'm picking from. And I'm going to pick the best of those 16. So often, that's going to make my logic simpler. So that's why instead of saying, well, I don't care. Let me just put a 0 or let me just put a 1, instead by putting an x, I can get better answers. Let me show you how that works. So here's an example of a function. And what I've done is I've filled in the answers I care about. So I filled it. I've partially specified my function. I put some 0's and 1's in. I say, I need to generate this function. And I don't care what the outputs are here. So let me put in x's there. So actually, let me show you what happens if I do something different. So if I put in 0's, say, OK, I don't care, but I'll just put 0's. Then let's solve this K-map. So what do I get for this K-map? What loop should I circle? The 1, 1 loop? Let's see if I did that one first. Yeah, 1, 1. I thought I understood, but maybe I didn't. I circled that one first. 1, 1 at the top. Yeah, bottom left wrapping around is the other one, right? Good. So we've got those two. And I think we're done. OK. So that gives us a b forward with b prime c. Yeah, that's not too bad. You might say, OK, that's a nice function. It's too challenging, a few gates. But we didn't have to pick 0's. We could have picked other values. So what if we pick a 0 and a 1? Let's put a 0 and a 1 there. So now what do we get? Let's solve. So we still get that one. We still get that loop. And then the one on the bottom goes all the way across now. So now our function f is just a b plus c. So we got rid of a literal. So if instead, I mean, again, I didn't care about these two outputs. So if I picked a 1 here instead, well, then I'd have 1 fewer literal. I saved myself a couple of transistors. Better answer. Well, so instead of going through all four possibilities, here there's only four. If you had more unknowns, I'm sorry, more don't cares, then you'd have to go through lots of functions. Instead, let's write x's into our K-map. So now we're going to have slightly different rules. So the rules are going to be I want to still grow my loops as big as I can. But instead of only covering 1's, I can also cover x's. x's can be 1's. So I can also grow a loop to cover x's if I want to. And I still have to only cover all the 1's. I don't have to cover x's, because x's could be 0's. So that's the modification to our rule. Grow loops as big as we can, possibly including x's. Just still cover all the 1's. And the same thing if you wanted to do a POS solution. Grow loops as big as you want around the 0's. You're allowed to include x's, but you don't need to cover the x's. You only need to cover the 0's for POS. So same set of rules. So now if we solve this function, now we're actually able to grow out to the left for this loop. So instead of just this loop here, now we can include these two x's. So it's gotten bigger. And then on the bottom, we can also include this whole row. So what's the answer? Well, b plus c. And that's the best of those four. So instead of drawing four different k-maps, solving them all, and then comparing, I can just write x's into my k-maps, modify my rules for solving it slightly. And then I'll get the best answer amongst 2 to the n. And here is 2, 2 x's. Yeah. Yeah. So that's a good question. So what actually happens to the x's? Because as we talked about earlier, whatever you implement will generate 0's and 1's. It will not generate x's. So the x's, if they're inside a loop, those will become 1's with the function. If they're outside all of the loops, they'll become 0's. Yeah. Yeah. So if you solve the k-map optimally according to these rules, and technically, you'd have to look both for POS and SOP forms, because those are not necessarily optimal relative to one another. But if you simply solve it following these modified rules, you will get the optimal SOP form. And if you solve it following the modified rules for 0, you get the optimal POS form. Yes, but you're doing it in a way that you make your loops as big as possible without adding extra loops. Yes, yes, yes, yes. So the modification is grow the loops as big as you can. You're allowed to include x's. So it's the same rules. You're allowed to include x's, but you don't need to cover them. So hopefully, that's clear. The tool does allow you to practice and check your answers. If you feel like you're not sure, go play with it. Do a couple examples. Any other questions? And we'll actually do a couple more examples in class. OK, so yeah, so you'd ask, well, are they 0's or 1's? It's a good habit to put the 0's and 1's in place of what you got, and make sure that that answer is, in fact, OK. So these two become 1's, because they're inside of a loop. We didn't have any x's that are outside of all of our loops, so none of the x's in this solution become 0. And we also don't have any context for this example. I just said, here's a function I want. Now, if you have a bigger context, you should evaluate this full solution in that context and make sure that it's actually OK. So let's do an example. I'm getting hungry. Let's have some ice cream. The example in the notes has lychee, but I couldn't find lychee. I was a little disappointed, but pistachio's pretty good. So you guys like ice cream? OK. We'll do an ice cream dispenser. I expect this to work by EOH, by the way, so I can eat ice cream at EOH. All right, so three buttons, inputs. So we're going to have mango. We're going to have three kinds. You can pick mango. You can pick pistachio. Or you can pick a blend. And there'll be three buttons for you to push. You pick which kind you want. And then out will come the control outputs for the actual mechanical dispenser, which will be two bit unsigned numbers that say the number of 1 1 cups of mango. So it could be 0, 1, 2, or 3 1 1 cups. And the number of 1 1 cups of pistachio. So we'll design using this set of inputs and outputs. And we'll build the logic in between those two. So let's write a truth table. So help me out here. So what happens if I push M, I want to get 1 cup of mango. So what should I write for CM and CP? Remember, it's the number of 1 1 cups as an unsigned number. So what should CM be? Yeah, so when M is 1, so down here, 1 0 0, CM should be 1 0, I think. We want two 1 1 cups, so 1 cup of mango. What about pistachio? How much pistachio should come out when I pick mango? 0. OK. So second case, I push B, the blend. I want to get 1 1 cup of each. So where's blend? So blend, there. 0 1 0. So I push the blend button. How much mango should I get? 0 1. How much pistachio? Good. All right. And then the third option, I push P, the pistachio button. I want to get 1 cup of pistachio. So let's see, that one's here, right? 0 0 1. So how much mango? 0. How much pistachio? 1 0. Good. And then the fourth one I have to worry about, well, if I don't push any buttons, no ice cream should come out, right? OK. So that's the 0 0 0. So what mango I should get? 0 0. And pistachio? Good. And what about the rest? Hmm. Tough. You know, I just don't care. All right, I don't care. Who cares? Fill in with x's. I don't care. Yeah. Oh, very good question. Let me come back to that. All right. Yeah, see, this is the problem with trusting the human, isn't it? All right, so we can copy these to KMAP. So let's start with CM. So to copy to KMAP, I put these in an order where the last two variables are across the top, and then the first variable's there. So we're going to copy. Well, let me just show you the order. So we're copying these blue ones, the high bit of CM. So the first row is a 0, so that goes in the upper left. And then we're going to copy to the right. Now, this one's gray-coded. So instead of going here, which is 0 1 1, we're in binary order over here. So 0 1 0 is actually on the far right. So we'll say 1, 2, over to here, and then back. So 0 0, 0 goes there. The x goes in the 1 1 slot. So you want to get used to this so you can do it quickly, copying from truth table to KMAP. Remember that your truth table's typically in binary order. Your KMAP's in gray-code order. So you've got to make sure to switch them, otherwise you get the wrong answer. All right, so for the bottom, we've got 1 xxx, the 1, and then the x's are just filling the rest. So what's the answer there? Solve that one for me. Yeah, let's do SOP. Good question. In this case, it's actually the same, I think. Yeah, OK. So M, right? But my loop is SOP. OK, so the high bit of the mango output is just the mango button. Good. Not even a gate. Sorry. I'm so excited about my ice cream. All right, so let's do another one. So what about the low bit? So now I've highlighted the low bits there. So if I just copy this over, here I've got 001x. So I'll fill that in, 001 on the right side, x in the 1 1 slot, and then 0xxx, 0xxx. So what's the solution? B, like that? OK, good. OK, so the low bit is just the blend button. Hey, I don't even have a gate yet, just some wires. That's nice. We can do pistachio, high bit, 010x, 0xxx. Answer? B. OK, and then the low bit of pistachio, 001 on the right side, x, 0xxx. Solution? B again, huh? Good. So there's our design. Very easy design. The x's made our life so easy, we don't even have to have a gate. Just take the wires, connect M to CM1, connect B to both of the 0 output bits, and P to CP1. We're done. Very nice, very cheap. So what happens? Mohamed, you asked this question. What happens if a user presses M and B at the same time? Bad human. Who cares? The janitors care. You're going to find out. So we'll put that in. Let's say we put that in. What comes out? Well, a 1, a 1, a 0, and a 1. So we're actually getting a 1, 1 in our mango control. So ideally, what that means is, well, 3 halves of mango and 1 half of pistachio. So maybe it overflows the cup. That's a good case. We hope that what happens is it overflows the cup. Now, unfortunately, the person who designed the mechanical dispenser may have assumed, well, they shouldn't be giving me a 1, 1. So something bad actually could happen if you give them a control that they don't expect. Mechanical systems may not be that flexible. So if you send the 1, 1, ideally, yeah, it just spits out too much ice cream, and someone has to get a mop. But worse things could happen. So we do care. Using don't cares when some human's driving is just not a good idea. You've got to be careful. Don't assume that they're going to follow rules. So how can we fix this? So one choice is we could pick specific outputs. So we said, well, let's just pick 0's. You push two buttons, you get nothing. You push three buttons, you get nothing. So instead of saying x, we'll say 0's everywhere and just fill in all of our k maps. And then we can solve that. We'll have a bunch more gates. And that'll give us one answer. Another way we can do this is to actually add some logic in between the inputs and the outputs to do what Mohammed suggested initially, which was keep the humans from pressing more than one button. So actually a few choices there. Here's one of them. So what this one does is any time the human presses more than one button, it forces all the outputs to 0. So this dotted box is just some extra logic between our inputs on the left and our outputs on the right. So nothing has changed except I put a little logic device here. And you can see that this AND gate up here produces a 1 only when the human pushes mango, but does not push blend, and does not push pistachio. And similarly, these two produce 1 only when the human doesn't push another button at the same time. So that's one choice is to add what we'll call glue logic. But we're running out of time. So let me come back and go through this in more detail on Friday. But the main point is make sure that you don't care. Don't assume humans will do things. If you're working with another piece of logic, make assumptions. If you're working with another piece of logic, you You You you you\",\n",
       " \"I've got some examples. OK, so let's get started. So today we're going to spend the whole day doing examples of finite state machines. So we'll do one quick one, which is a two-bit grade code counter just to familiarize you with this process we talked about at the end of the day on Wednesday for designing finite state machines. Then we'll do a slightly more complicated one. Color sequencer has some don't cares in it, so we'll look at that one. And then I think maybe about half or maybe even more, we'll talk about the finite state machine that you're going to be building in the lab. So you've already been kind of playing with that for a couple of weeks, several weeks now. And you'll be building it in the next week and a half to two weeks. More examples of finite state machines, section 3.3 of the notes has examples. Probably we won't cover most of those. There's actually more examples in 3.2 also. So if you're looking for examples, you want to make sure you understand it, look at those. Also under midterm 3, review materials, there's a whole bunch of old test questions for which I wrote answers. So I think it's kind of down. Scroll down a little bit, and it says old EC 190 exam questions on finite state machines mostly. So you can get lots of examples there with solutions. Of course, I recommend you solve them and then look at solutions instead of doing it the other way. All right, so another reminder. Here's the midterm. You've seen this slide many times now. The review session we'll do on Monday in class, so come prepared with questions or topics anyway and questions. So I just wanted to then remind you of other resources. So there are still online tools for this part of the class. You can practice your skills, watch the review video, or also Professor Jaramillo's. Attend any of the three lecture times, assuming the fire marshal doesn't get mad. Go to office hours, and there is this Eta Kappa Nu review session, which is Saturday 2 to 4 PM in 1013 in this building. Same caveat as yesterday, so I will go over that. Same as last time, too. All right, so this was the six-step process that we talked about using for designing finite state machines. So we start out by developing the abstract model, spec the IL, input and output, complete the specifications since we're building with digital systems, any input combination, any state will go to a next state. There will always be outputs. There's never any blanks or anything like that. Everything's built out of bits and Boolean expressions. Once we finish completing the representation, making whatever design decisions we need, we'll pick a state representation. I gave you some ideas of how to do that. Now you'll see some examples. And then we'll calculate logic expressions and then implement with flip-flops and gates. So those were the six steps. So let's go ahead and use that approach to design a fairly simple counter, a two-bit gray code counter, using this methodology. So what's our abstract model? Well, it's just a counter that goes through four states. So start in one state, go to the next state, go to the next state, go to the next state. And it's a counter, so go back. So that's good enough for an abstract model. We've got four states. The inputs, then, well, it's a counter. There are no inputs, so we're done. The outputs, well, we said it's a gray code counter. So let's go through a little gray code. So we'll start at 0, 0, then 0, 1, then 1, 1, then 1, 0. Then we'll start over. So a two-bit gray code counter. Completing the specification, well, there's no inputs. So every state here has one outgoing arc labeled with nothing because there are no inputs. And the spec's actually already complete. So there's nothing to do, no design decisions to make, or anything like that. We know the outputs. I didn't write them in here yet, but basically, this is count A, count B, count C, count D. So next step, then, is, well, what do we want for a representation? So any time our output bits are unique, that is, every state has a unique pattern of output bits, one choice is, well, let's just use the outputs as the state ID. Now, sometimes that's maybe not the right thing to do. If you have 500 outputs, but you only have 10 states, well, you only need a few flip-flops, right? So to say, well, I'm going to have 500, that's kind of silly. But usually, it's not going to give you such a bad answer. In this case, it's actually optimal. We've got four states. We need two flip-flops for the state. And we've got two outputs. So we can use the same two bits that we have for output as we use for our internal state. What that implies is we have no output logic. So for each of these states, remember, the state's on the left. The outputs are on the right. So you can see they're always the same by design, by choice. And so the outputs are simply S1 and S0. So that's why this is a useful approach. When you need to generate output bits, you do it without output logic. Now, all we have to worry about is the next state logic. So from this design, this is a complete state diagram, complete state transition diagram. So we can just go ahead and write a truth table from this. So let's write our truth table. So from 0, 0, where do we go? 0, 1. And then 0, 1, we go 1, 1. And then from 1, 0, where do we go? 0, 0. Good. And 1, 1 to 1, 0. Good. So now we have our truth table. And you can see, sorry, I put this one up. You can just basically read these off. I'm not going to bother with k-maps for this example. So S1 plus is here's a 1 and here's a 1. You can see it matches S0. So it's just S0. And S0 plus is what? Not S1. OK. So those are our next state equations. They tell us the state of the system in the next clock cycle. Remember, that's what the plus means. So discrete time, next clock cycle. If the system state is currently these values, in the next clock cycle, it will have these values. So we can design it by just implementing the next state logic, which is just wires. So S1 plus is S0. Here's S1 on top. So the D input comes from here, which is the S0 output. So next state will be S0 for S1. And the next state for S0 is S1 prime. So here's S1 prime coming out, going into the D input of S0. So just hook two flip-flops together with a couple of wires and you have your two-bit gray-proof counter. So that was a fairly simple, easy example just to get us started. So now I want to do another example, same process. So I put a review slide in here, but I mean you saw it a couple of minutes ago, so I won't spend much time on it. So what's a color sequencer? So imagine that you have this LED that will be one of eight colors. So you get a three-bit input, red, green, and blue. And based on your three-bit input to your LED, it produces one of these eight colors over here. This is actually what old computers used to use about 25 or 30 years ago for their color displays, was eight different colors. That was a long time ago, before you were born. So let's build it. Now you can get an LED that does that instead of a computer. Let's build a color sequencer that cycles through a set of these colors. So imagine we've got this light, and our FSM will basically drive these output bits, R, G, and B, to produce the colors on the LED. So what's our abstract model? Well, again, it's a counter that's going to go through five colors, in this case. So like this, say we start in red. I get to pick the color, sorry. We go to green, we go to cyan, we go to white, we go to blue, and then we're done. So that's our color sequencer. So we want to design a finite state machine that just goes over and over through these five colors. So you can imagine you put it out in front of the building. Oh, wait, someone beat us. OK, so they did something like that. You can do this in the lab if you want. You can put it inside that thing. All right, so what are the inputs? Well, it's a counter. So we're staying with simple examples. So outputs, we're just going to use the RGB code. So we're actually told what we need to do to produce these colors. So the outputs we need, say for the blue state, will be 001. So we'll just inherit those bits for output. So let's add those. So red was red, green, blue, 100. Good. Green's in the middle, right? 010. Cyan is green and blue, so 011. White is all three, so 111. And blue, red, green, blue, 001. OK. All right, so now we have our outfits labeled on our states. So what's next? There's no inputs. So when we say, well, let's complete our specification, there's nothing to add. Every state has already all of the arcs leaving that state. There's no decisions to make or anything. They've already been made, rather. So our spec is complete. Now we can pick a state representation. What do you think we should use? Maybe the same thing, right? We've got unique output patterns here. You know, if I picked green down here, if it went twice through green, then we couldn't make this choice. Because then our outputs are not unique. And of course, the next state from green would have to be one next state. So if we had two similar colors, or identical colors, rather, on our loop, we could still build that finite state machine. But we couldn't make the choice of having the outputs also be our state IDs. But it didn't do that. So let's go ahead and make that choice. So the outputs are unique. So we'll use them for our state IDs. So we'll add them in. So red, we'll add that in. Green, add that in. Cyan, white, and blue. So now this is a fully specified finite state machine state transition diagram. It's got all the bits on it. And we can map it again to a truth table. Question? Yeah. Do you need to pick up the output patterns? Yeah. So remember, in the machines we're going to look at, it's always state bits followed by outputs. And I probably should have put it somewhere near this diagram. But the outputs in this case are red, green, and blue. And the state bits are always going to be largest bit. So it'd be S2, S1, S0. But that's a good question. Yeah, there's no implicit order necessarily for the outputs. So make sure that you label your diagram somewhere. I know I left it out here. It was kind of in the previous one. Yes? How are we going to do this? How are we going to change it? You'd have to have two states with separate state IDs. So the question is, what if I did make, let's say I change this to green. I can no longer, the output bits have to be 010 to drive our RGB for both of those green states. So I can't have 010 for two different states. I would have to actually pick a different state ID for one of those two green states. So it's only the fact that these are unique that allows us to do this. So time to fill in our truth table, or next state table in this case. So let's see. Let's do it the easy way this time. So from 100, we're going to go to 010. So 100 go to 010. Where do I go from 010? 011. So I'll fill that in up here. And then where do I go? 111. So where was 011? Here, right? OK, good. And from 111? 001 down to here. And then from 001, I go to 100. What about 000? We don't care. Good. I don't care either. What about 101? OK, me too. 110? I care about that. No, I'm kidding. All right, so we don't care. Good. OK, so we'll fill those in. And now we can copy to KMAPs. So we'll start with S0. So here's a KMAP for us. So the same order as always. So I put S1, S0 on the upper one so that I can copy horizontally. But remember, grade code order in the KMAP is binary order in the truth table. So we're going to go first, second, hop over here for third, and then go back for the fourth. So X011, X0, hop over one, and put the other one there. And then 0XX1, so 0X, hop over X, and put the one there. What loops? A square over this one, right? OK, good. What is that? S1? OK, good. So S0 plus is just S1. That's easy enough. Good, I like that. All right, let's go on to S1. So fill in our KMAP again. So read them off for me. X0, hop over, 1, 1. OK, and the next four? 1XX0. OK, good. Loops? Hmm, is there a square? Oh, there is, yeah. Oh, that's better than my answer, sort of. All right, that's not my answer. You get another answer? Ha ha ha. Let me show you my answer, and then we'll. I like that one. You're right, the square is sort of better than that one. But I can add this one. And then I get this thing. The square is better, but that's an X0. So the square might be better. Yeah, the square might be better. Yeah, the square could be better. All right, so we'll have this one for the S1 plus, S2X or S1. What about S2 plus? So do the same old thing, copy KMAP. So read them off. X1, 1, 0. X1, 0, yeah. Sorry, don't switch them, because I put them in the hopping order here. And then 1. OK, and the next row? 0, X, X, 0. Good. OK, what do we have there? Just the two on top, right? I actually, yeah, I think you, sorry, I wanted to go back and look if it were unique. So do keep in mind if we're making choices. I kind of made a weird choice last time with the XOR. But I think actually that one might be unique if you want the way you were going. But I'd have to look at it again to verify that. OK, so here we have, sorry, I should have let you read this one off. It's S2 prime, S0, right? So S2 prime on top, and then S0 to isolate these two from the outer ones. I'm going to rewrite that as a NOR gate, because I'm going to map this into CMOS. So this is one NOR gate where I take S2, OR it with S0 prime, and then take the complement of that. So that's a NOR gate, right? So if I draw this thing, I have one NOR gate for S2. Remember, it took S2 here and S0 prime down here. And it NOR'd those together. And that's S2 plus. S1 plus was S2 XOR'd with this one here, which is S1. And then S0 plus was just S1. So it comes down this way. So that's our implementation, three flip-flops, two gates. Yeah? How do you get from 5 to 20? So not one that I know off the top of my head, because I think I have extremely limited Arduino programming experience. In general, you can, as I put this, so with hardware or software, generally speaking, most of the programming languages are what we call Turing-complete, which means that you can express any computation. So if you think back to the first day of class, we said that computers are all the same. What that really means is that a computer that's able to, if we can map it systematically from one computer to another in terms of its capabilities, which is generally true of all the computers we build, but not necessarily all of the programming languages, we say that computer is Turing-complete. Most programming languages are Turing-complete. So you can define your language any way you want, and then figure out how to map it. Now, hardware is actually a little more difficult than that, because you have lots of space and speed constraints. So it's very easy to write a language that is hard to map to hardware. And so, for example, most high-level languages, it's very difficult to build hardware from those. So I think the Arduino language is more constrained, but I couldn't tell you the exact mapping off the top of my head. I'd have to look it up. OK, so this is an implementation. So excited? You probably want to go to the lab, get your protoboard out, right? Takes a while. Being a surveyor? Yeah, good. You know what to do, right? Going on. Don't care. Bits? Yeah, they're bits. They're bits. Good answer. What did happen to those don't care states? We left those don't care states lying around, and we didn't check what happened. So let's take a look. You can just plug into equations. If they find that easier, it's fine. It's the same. I'm going to plop up our K-maps. There was our K-map for S2 plus. What do those x's become? All zeros, right? Because the only loop is this one up here. The x's are outside all of the loops. That means they're all zero. Good. So the x's become zeros for S2. So let me write that as this. So we've got these three unknown states. So one of them is 0, 0, 0. And that's going to go to 0 something something. We've got 1, 0, 1. That's going to go to 0 something something. We have 1, 1, 0. That's going to go to 0 something something also. Good. So we figure that one out. What about S1 plus? Where are those x's going to go? This one is what? This is 0. What's this one? 1. And what's this one? 0. Good. So we've got one of them going to a 1. The 1, 0, 1 state goes to a 1. So now we can plop up these three again. We've got 0, 0, 0 goes to 0, 0 something. 1, 0, 1 goes to 0, 1 something. And 1, 1, 0 goes to 0, 0 something. So let's take a look at S0. Where are those x's going? How about this one, this one, and this one? Good. So we again have one x, different x this time, going to a 1. So if we fit those into our final next state equation, we've got 0, 0, 0 goes to 0, 0, 0. 1, 0, 1 goes to 0, 1, 0. And 1, 1, 0 goes to 0, 0, 1. So what comes after 0, 0, 0? And what comes after 0, 0, 0? When you were kids, did you ever play that game where you write I shouldn't say that. You write something mean, and you say, but if you're not that thing, then read the other side. And then you write the same thing on the other side. And you see how many times your friends flip it over. Yeah, so OK. So let's add those states. So there's black. It has a self loop. There's violet. It goes to green. There's yellow. It goes to blue. So violet and yellow, maybe we don't care so much. We turn it on. If the flip-flops start in that state, in one cycle, it's just going to fall into our state. And it's just a light. So then OK, fine. But if it starts in black, it's going to stay in black. If we turn it on and the light is black, light's going to stay black. And it's not ever going to change because of our finite state machine design. So what can we do? So we're going to have to add some way to initialize. We can pick some specific hardwired initial state. Picking zero maybe is not the best choice here, because that's black. Stay black. There's an easier way to design that FSM. We can use muxes. So we can say, OK, let me put a mux in front of every flip-flop. And then I can put an initialization bit in. And then I can choose, using one input to control all three muxes, do I want to force my finite state machine to display a specific color in any cycle? So I can always put it in whatever state I want, using those muxes. Or I could just pick one signal and force the system into the loop. So for example, I could add a NAND gate to the S0 flip-flop input so that it was S1 prime init prime NANDed. So this would be an active low init signal. And that would, let's see, when that's 0, a NAND gate would force that to 1. So that would force S0 to 1, which I think would push us back into the loop. So we'd go here, here, here, or there. And all four of those, cyan, white, violet, and blue, all of those fall into the loop. So if we were to add that initialization gate, one gate, then we could force the system eventually into the states that are valid. So the other thing we could do is just go back and say, well, now, let's go back to our k-maps. And let's pick specific ways to fix this problem. So go to 0, 0, 0, and change one of them to something that isn't 0, and then solve again. That may take a couple of iterations, because you're going to change the loops, and you may just create new problems with new loops. You can also just choose specific next states for all of them. So you say, well, let me just design the complete system. Both of those approaches are going to add logic. So regardless of whether you just try to think it through of, well, could I limit it to one gate somehow, or could I just go back to the drawing board with my k-maps and play around with it till I get it right, doesn't really matter. At some point, you have to go back and add some way to push it into a valid state. So just be careful with the don't cares, because if you end up in a state that goes in a loop outside of the loop you want, you may never get back into the loop you want, depending on the design. Any questions on this one? Seemed pretty straightforward and understandable. I expect you all to go build this in the lab. Yeah, so in this case, I picked a specific solution. So knowing the design, I looked at the design. I said, well, if I can push it into one of the states that ends in s0 equals 1, then from those four states, let's see, cyan, white, and blue are already in the loop. Violet, we know, once I turn initialization off, will go to green. And so it'll also be in the loop. So if I can force s0 to be a 1, then I can push it into the states that I know work. So what I did is I said, well, how do I force s0 to be a 1? Originally, I had s0 plus equals s1. So now this is init low, active low. So if you put a 1 here, then you get s1 prime prime. So it's still the same thing. I didn't change the actual functionality of the finite state machine by adding this NAND gate, because I switched s1 to s1 prime. So now that flows through. It gives me the same answer before when init is 1. When init is 0, this and in here is 0. Complemented, I get a 1, s0 plus is always 1. So it's an active low initialization signal. So this one is custom tailored to our design, which enables me to use just one extra gate. Anything else? Where we are in time. OK. Still enough time. All right. So let's look at the lab machine. I want to tell you a little bit about it first. So your task is to control this coin-operated vending machine. We'll have inputs produced by coins. So as you put coins into the physical machine, which will be about yay big on the table, then it will produce inputs for your finite state machine. The outputs then specify, well, should the machine accept your coin or send it back to you? And then also, should a product be released? Unfortunately, we couldn't get the products into the lab, so you can't buy anything. But there is a signal that you have to generate. So the design is pretty simple, right? Because you're going to be building this out of TTL chips. So we didn't want you using 20 or 30 or 100 chips. We wanted to limit it to a few chips. So that's why it's a fairly simple design. What's the point of this? So Doug Jones and I designed the class. So Doug's view was that he wanted everyone here to understand the connection between the real world of building stuff with wires and chips and the paper world of lines and boxes. So he wanted to make sure all of you understood that connection and the way to do that is get your hands onto something real and build it to represent, or rather, build the thing that you've represented on paper as a finite state machine. My point of view is I want to make sure that you understand that the knowledge you're getting in this class actually will enable you to go out and do real world stuff like sensors and actuators, right? So finite state machine, you can go build a vending machine, like a real one for ELH for fun. Or you can build a robot. You can do lots of stuff with sensors and actuators. So Doug Jones designed the original finite state machine. The derivation in this in the slide is a little different from the ones in section 3.4 of the notes. So read both. And if you understand one better than the other, that's OK. They both end up with the same design. So that's what you have to implement in the next couple of weeks. Chris Schmitz, who you may know from 110 or something else, he did the original prototype hardware. So he did that for us. He worked for a first few semesters. Vlad Kendutenko, who's also taught this class many times, helped the design as it scaled. So he redid some of the design. As we had more and more students, we had fewer people to help with issues in the lab. And Professor Jaramillo and Casey Smith, who's the instructional person in ECE, did the current design to eliminate basically all of the issues. Actually, one remaining issue, which is these are optical sensors. And I'll try to remind you later. But please keep the shades down, because otherwise, the people with benches near the window will get light coming into the optical sensors from the sunshine. And that can make noise. And so it might not work for them because of the sunshine. So just be careful working near the window and try to keep the blinds down. But that's the only remaining issue that we know about. So here's the physical system. So you can see there is the coin slope. So you put the coin in. And it rolls down. And there's a gate here that your finite state machine controls. So it can either drop down. And then the coin comes down here and is accepted. Or it can stay up. And then the coin rolls through and falls out the other side. That means the coin was rejected. So those are your two choices. Here's the interface ribbon cable to your protoboard. The optical sensors are here. But let me zoom in in a second. So these will produce your clock signal and your T input, which is which type of coin. This gate is controlled by your A output. So let's zoom in a little bit. So you've got two optical sensors. One is for the clock, which is here. And one is for the type of coin. We're only going to put two types of coins. So one is a dime. For those of you who might not be familiar with US currency yet, the dime is a very small one. It's worth $0.10. And a quarter is very big. That's the other coin. So when the dime rolls through, it will hit the clock. But it will not hit this T. The optical sensors generate a 1 when they're blocked. So when the dime rolls through, it will generate a clock high and then low. So will the quarter. But the T signal will only be generated by the quarter. So in order to know whether you have a dime or quarter, you look at the T signal when the clock edge goes up. So I'll show you that in a second. We've also got LEDs on there. So when clock T and your accept input are high, or output are high, LEDs will light up on this board here. And this is the place that the coin rolls by. So here's a dime in action. So you can see the dime rolling there. So dime rolling into the machine, you can see that it's hitting the clock signal there. So the clock is high and that LED is lit up. On the other hand, T is low. So the T sensor is up here, remember. So it's still optically stable, connected to the other side. And here is the dime's timing. So what I want you to notice here is the T signal just stays low. The dime doesn't hit it at all. The dime's too small to block that sensor up there. So T stays low. The clock signal, on the other hand, goes up for a little bit. And then once the dime passes this optical sensor, it drops back down. So we'll talk a little more about the clock in a couple of slides. So here's a quarter. So a quarter is going by now. And you can see that clock is high again. But in this case, T is also high because the quarter is blocking this upper optical sensor. So down here is a quarter's timing. So you can see that the T signal goes up first. So T is going to be stable on the rising edge of your clock, which is important because, of course, you're going to use positive edge triggered D flip-flops. And so you will sample T on the rising edge of the clock. You can see here for the quarter, it's a 1. And over here for the dime, it's a 0. So that's the T input to your finite state machine. So the clock's a little weird. So the clock is not a square wave. It's generated by an optical sensor only when the coin rolls in front of it. So how big is that pulse? Well, it depends. If you shoot the coin in, it'll be narrower. If you let it roll slowly, it'll be wider. Humans can't make the coins go fast enough to matter. So don't worry about that. But it's not periodic. The cycles in our clock are defined by when you put the coins in. They're not periodic. It's not a square wave. Yeah. So asynchronous is always with respect to something. So this is a clock signal. And your finite state machine is synchronous with respect to this clock signal. It's just your clock signal's kind of strange. Most clock signals, they're periodic. They're square waves even. This one is aperiodic. I mean, you get a cycle every time you put a coin in. Yeah. And it will change synchronously with respect to your coin insertion. So coin insertion will give a rising edge. And your finite state machine will take one transition. So it's exactly the same from the point of view of everything we've talked about with clock synchronous sequential circuits. Nothing to worry about there. Good question, though. All right. So yeah, I was just kind of going through this. It's sufficient for our needs. You work with these positive edge trigonometry flip-flops. And so because the way their optical sensors are positioned, t is stable. It'll be 0 for a dime, 1 for a quarter when the clock edge rises. So you get the right input. I should mention, by the way, I meant to say it, but all the work that Professor Jaramillo and Casey did also means you can more or less get this entire thing working at home and then bring it in and just test it in the lab. We do recommend that you test it in the lab. There shouldn't be any issues. So if you have it working at home, it should work in the lab as well, unless you're sitting in the sunshine. So be careful about that one. But all right. So let's talk then about the finite state machine. So what's a sequence recognizer? We actually built one already or designed one already. It was even just Wednesday. I think it was Monday. We developed a 0-1 sequence recognizer. It looks for a pattern of bits in a serial input. So remember, we talked about machine models. It was Wednesday. And we looked for a 0 and a 1. So we can think of the vending machine that way as well. So for the lab, we can treat the sequence of coins as a serial input. We get 0 for dime, 1 for quarter. So 0's and 1's come in. And then the sequences that we want are 0-1 and 1-0, because in the machine, we're looking for totals of $0.35. So part of making it simple was to use this combination of coins, only two types of coins, total of $0.35. So you always have to have one dime and one quarter. So you can put the quarter in first or you can put the dime in first. But you're going to get either a 0-1 or a 1-0. So if t is our serial input, we have to produce a product release output, p equals 1, whenever we see 0-1 or 1-0. Actually, it's a little bit, it's not quite the same. But if we use this process, we'll get the right answer. Because if you, actually, no, maybe it is. Yeah, I take it back. It is correct. If you put a bunch of quarters in, then after the first quarter, it'll reject those. And then you eventually have to put a dime in, in order to get the product, because it has to be $0.35. So at the end of a bunch of quarters, you put a dime, then you've got a bunch of 1s and a 0. So that 1-0 at the end will be recognized and produce a product. All right, so we're going to use this following process to build a sequence recognizer. So we're going to start from a start state. And we're going to then build out the sequence for each of the sequences we care about by just adding one state per bit. Then we're going to complete it by saying, well, for each of the states, what do we want to happen if the other type of coin is put in? And for the end states, well, what if we put any coin after the end state? And then finally, we'll take a look and try to get rid of states, try to make it a little narrower. And then after we've designed that abstract model, we'll come back and assign state IDs. And that'll complete the lab, or rather, that'll get the lab to the point that you have to do the rest of the design, as you know. All right, so I wanted to make this a little clearer in the slide. So what I'm going to do is I'm going to use 0, I'm sorry, a black arc for the dime, and a red arc for the quarter. So that's the T input. And then for the outputs, which will mark states with slash AP, A is accept. So if you have an output of 1, that means the last coin that came in is accepted by the machine. It's kept by the machine. And if you have a 0, that means the coin gets sent back and the machine doesn't hold it anymore. P releases the product. And so if you send an output of P, that means you've collected $0.35 and you should give them whatever you're selling. I know what you can buy for $0.35. All right, so in the beginning, there's a start state. So then we're going to go through the dime sequence first. So if we send a dime and then a quarter, well, in our state diagram, we're going to add a state for that dime. So this black arc, again, means I put a dime in. And then I'll be in this dime state. So this one, I left the outputs unknown. This one, I need to accept that dime, but I'm not ready to output a product. I've only taken $0.10. So then when the quarter comes in, well, that'll be a red arc. So this means quarter. And that'll go to a state I'll call paid one. And there, I need to accept the quarter and then also output a product because I've gotten the dime and the quarter. So the other way this can happen is I put a quarter followed by a dime. So I'm also going to add states for that sequence. So those will be going down. So here's a quarter state. So first, I put the quarter in. It's a 1, 0 sequence. So here's the quarter. And again, accept, yes, and then put a product out, no. So the next state, then, I'm going to call paid two. I'll accept the coin, and I'll put a product out because I've gotten first a quarter, then a dime, $0.35. Now, remember, this is noted as AP. So A is accept. So you want to accept the dime but not put out a product. So all of these are AP. So these two, you accept the coin, but you don't have enough money yet. The paid one and paid two means they've paid fully. So you still have to accept the coin in order to have the money, but then you also give them the product. Yeah, so that's a good question. So eventually, we will merge those because we don't care. We don't need them to be separated. So you've already noticed that. And once you get experience with this process, you could do that too. The basic process is for every sequence, you just write down a string of states, and then you worry about merging them back together. So right now, we're just following this fairly simple process of every sequence I want to recognize, make a separate state for it. That doesn't always work because you may have sequences that share subsequence. And then, of course, they have to share states from the start state. So for example, if we said 001 and 0001, those two start with 00. So we can't split on one common input. We'd have to go to the same state for the first 0 and the second 0. So here we are. So what's next? So now we need to complete our specification, our transitions. So what happens when someone puts in two dimes? What should we do? 00, right? So reject it. And don't put out a product, obviously. You didn't get any more money for rejecting the coin. OK, so where did we go? So we've had one dime. We should accept the first dime, right? So we've got the first dime. And then from dime, right now we have a quarter arc. So now we need a black arc out of dime. And it should go to a new state that has AP equals 00. So like that, right? So reject D for dime. Yeah, rejected. All right, so what about three dimes? What about four dimes? Five dimes? Keep looping, right? We just keep sending the dime back. The user keeps putting it in. We keep sending it back. The user enjoys that. They can do it all day. Good design. All right, so eventually, so why don't we just finish this one up? What happens if we're sitting in that reject D state and someone puts a quarter in? What should we do? Go up to paid, right? So that kind of finishes the sequence. So let's do that. OK, good. So we've now got, the way to look at this is every state should have a red arc and a black arc coming out of it, right? Because every state, you could put a dime or a quarter next. So this one's done. This one's done. Let's see. Those are the only two that are done, right? OK, so let's do the same thing next for quarters. So if we put two quarters in, we want to reject the second one, right? So we'll have reject Q. I don't know how to pronounce that one. But again, it's reject the coin, and we don't have enough money, so we're not going to give them a product, right? And then if we give us more quarters, again, keep sending them back. And what happens when we get a dime? Go over to paid two. That finishes our quarter, then dime sequence. OK, good. So let's see. So these three are now done. So now we need to finish up these other four. This one doesn't have any arcs going out. So what's left to specify? The paid? OK, so how about that one, right? So from paid, I shouldn't have told you what I did. If I put in a dime from paid, I'm sort of just starting over, right? I've already just given out a product. I just got a new dime. That's now $0.10 I'm storing. So I just go to the dime state. So draw a black arc over there. Oh, what if I put a quarter in paid? Go to quarter. Good, OK. What about, let's see, what about down here? Where should I go for a dime? OK, and what about quarter? Quarter, OK, good. I think we're done now, actually, because I realize these also were finished already. So that's it, huh? So there, OK, yeah, there's our complete step two. All of the states have two arcs coming out of them. So now we can take a look and merge things. It suffices when you want to merge to find a couple of states with identical outputs and identical next states. Sometimes you can merge more, but it's harder to verify. So let's take a look. So what do you think I can merge? OK, you guys are too fast for me. But dime and quarter have the same outputs, right? It only matters next state, actually. Outputs and next state. So they have the same outputs, but the next states go different places, right? So they can't merge those. Let's see, similarly, let's see. Something has the same outputs. That's OK. Oh, paid and start have the same outputs. All right, paid one and paid two, good. So there's paid one and paid two together. What about merging and start? Because you can see now they have the same. This one's unknown. Paid goes here and here, but start also goes to the same places. Can I merge those? You don't want me to, OK. So I'm going to merge them anyway. The issue is when you turn it on, if you force it into this start state, then p equals 1, you might think, well, so when I turn it on, I get a free candy bar? That's something you should know about. You should try that. That never works. But in our design, it made it a little simpler to do that. So we're going to just merge start and paid together. It does have this strange side effect, but it made the lab machine a little easier. So for an educational thing, we just decided to go ahead and do that. So there's the five-state abstract model. So now we need to assign states. So what we're going to do is instead of the output approach, which actually you can see doesn't work here, because we have our two reject states that are different, and we've got our two dime and quarter states that are also different, but the same outputs. So clearly, we can't just label things with outputs. Aside from the fact we've only had two outputs, so we have five states. So let's instead use human information. So what I want you to think about, you've got the sequence of coins. And let's call the last coin we put in t0. So t is either a 0 for a dime or 1 for a quarter. And t minus 1 is the one before that. t minus 2 is the one before that, and so forth. So I want to define the state bits as follows. So s2 is just t0, whatever I put in last. s1 is going to be a 1 if out of the coins I put in before the last coin and since the last time I paid, I released a product rather, there is at least one quarter. And similarly, I should say dimes. Sorry about that. If one or more dimes are inserted before the last coin and then after the last product release, then I'm going to have s0 equal to 1. So this will record earlier quarters. This will record earlier dimes. And s2 will record the last coin. So let's fill this stuff out. So for a dime, if I'm in the dime state, that means since the last time I sold something, I've gotten exactly one dime. So what was the last coin I got? A dime, right? 0, good. Did I receive any quarters? No, so no quarters. What about dimes other than the last dime? There's only one, right? So the dimes you need. So the dime state needs to be 0, 0, 0. So here's a little state table or state ID table over here. So dime will be 0, 0, 0. What about quarter? What's the last? So if I'm in the quarter state, that means what have I received? One quarter. Anything else? I can't have received anything else. So what's the last coin I received? Quarter. So what about any extra quarters? No, so 0. What about dimes? OK, so 1, 0, 0. Fill that in over there. So now we have two state numbers. So this is a fine strategy, but if we end up with the same state IDs, we're going to have to change something. We can't have the same state IDs. But let's see what we get. So for a reject dime, what does that mean? We've seen at least two dimes to be in reject dime. And we haven't seen any quarters, because as soon as we see a quarter, we'll go let them get a product. So we've got two or more dimes. So what's the last coin we've seen? 0, a dime. What about have we seen any quarters? No, so this one should be a 0. And have we seen extra dimes? Yes. OK, so we got 0, 0, 1 for reject d. So those are still unique, so that's good. What about reject Q? Last one's a quarter, right? And what about the next bit? Extra quarters, right? And what about the next bit? 0, good. No dimes at all for a reject Q. All right, so 1, 1, 0 is our state, state ID for reject Q. Now paid is a little trickier, because what's the last thing? Since we merged these states, now what's the last coin? Let's just pick one. Let's say it's a quarter. So what's the last coin in that case? Well, it's a quarter. We just made that assumption. So what about S1? Extra quarters, 0. We don't have extra quarters. Oh, I'm sorry. 0, yeah, yeah, 0. What about dimes? 1. We might have even extra dimes, right? It might be they put a dime in six times and then put a quarter in, but that's OK. That means the same thing there. So we could use 1, 0, 1 for paid, but what if we did the other assumption? What if we had a last dime? Then what's S1? So S1 is extra quarters, right? So had at least one quarter. And what about S0? 0. So 0, 1, 0 could also be paid. That's OK. We can have two bit patterns if we want to. Turns out it's convenient in this case to use both bit patterns. It doesn't matter. It is two states in the finite state machine. So in our abstract model, we were able to reduce it to 1, but we've got to use three bits. So we've got eight possible bit patterns, eight possible states. There's not really any value other than simplifying logic to making those kind of things don't care. So if it simplifies the logic to make both of these states mean paid, that's equally useful. So in the lab design, both of these are going to be paid states. So I ended a little early. So the rest of the design is up to you. So you remember, I'm sure, having to go through and actually draw k-maps and solve this, and then you'll be building it. I think there's a spread out due date from the 25th through the 28th or something, so a couple of weeks. So enjoy your weekend, and do bring questions on Monday so we can have a fun review session. Thank you. Yeah, this is for lab 9. Yes, thanks. I mean, it's really all the labs, but in the sense you'd be doing metrographic stuff in A10.\",\n",
       " \"Hello. Lab 9, I think, what is it, due by Thursday or something? Friday. So today we're going to just pick up where we left off with memory and look at bit slices, how they work, look at coincident selection, which will help us reduce the amount of logic we need for decoders and other things like that. Talk a little bit about tri-state buffers, which we'll use to allow ourselves to have multiple outputs connected to the same wires and then choose which output drives those wires. Obviously, we can't create short, so we only have to have one at a time. And that's what the tri-state buffer will let us do. Look at how we do bigger and wider memories. So take multiple memories and put them together to build memories with more bits, either more bits per address, wider addressability, or more addresses, a larger address space. Then we'll start talking about how we can implement something like a C program using a finite state machine. So we'll walk through an example of that. And it'll illustrate how we actually build a computer. So that'll take us through. I don't think we're going to get done with this today, so I think it'll be at least halfway through Wednesday, if not all of today and Wednesday for those two topics. So just to get back up to speed after the weekend, just do a little review. So remember, with the memory, we wanted to do two different operations. So one is read. So we tell the memory, here's the address we want. We had, in our original design, we had 2 to the 16th name. So we give it 16 bits and say, here's what I want, this address. And out come the bits on these data outlines. And then we can also do a write, where we say, here's the address I want, and here are the new bits. So we said it was 32 bits wide in the original design. And then, of course, we have to tell the memory, do we want to read or write in a certain operation. So this is what the symbol looks like. You can see the things I just talked about. Data comes in here for a write, comes out here for a read. Read or write, write enable is here. This was the address lines. And then we also had this chip select. And we said, well, if chip select is high, that means the memory is going to do something. And if chip select is zero, that means it's basically just turned off, doesn't do anything. So that was chip select. This is a static RAM cell, so double inverter loop to store a bit with active logic. When we turn on the select line, then these n-type MOSFETs connect the bit and allow the bit stored here in the double inverter loop to drive these bit lines. And then when we want to do a write, we force these bit lines to take on the values we want to store. And we turn the select line on. And then we wait for that double inverter loop to switch over and store the bit we're trying to push in. They would, and that's, I think, just a balancing act to make sure that it's a little easier and the shorts are even shorter loop. So yeah, good question. And then this was the last one we looked at last time and went kind of quickly through it. So what I've done here is taken the cell from the previous slides and turned it sideways. So now the select lines run vertically. There's cell 0 select line here, cell 1 select line here. There's 16 different cells, each with its own select line. But you can see the bit lines now run horizontally. And all of the 16 cells share the same bit lines. So we're only going to look at one bit at a time, read one bit at a time, or write one bit at a time out of this bit slice. We only have one pair of bit and bit inverse wires, the bit lines for those. So just to give you a little bit of annotation, so the cells are rotated, I just said. All of the cells are sharing these two bit lines, B down here, B prime up here. And analog logic, like the sense amps and things like that, to drive the bit lines and read the bit lines are down here in this little box. That's analog, so look at how it's actually built. So I also want you to notice that now we're going to use this decoder here to control the select lines. So four bits of the address, the address might be bigger, and we'll see how we can do that shortly. But four bits of the address would go into this 4 to 16 decoder, and the cell that we want out of these 16 would have its select line activated. All the others would not be. So only one of these select lines will be active at any time. And this decoder's enable input is how we'll use the chip select. So if chip select is turned off, the decoder's enable is turned off, and that means none of the cells are turned on. If chip select is 1, then the address chooses which of these 16 cells is activated by activating its select line. All right, so let's look at how a read would happen in the bit slice model. So remember, for a read, we set chip select to 1, we set write enable to 0, set the address bits, and then we'll wait for the data to come out. So we set chip select to 1, so now our decoder's enabled. We put the write enable equal to 0 over here on the read write logic. We put the address in on the address port here, and then one of the select lines becomes active. I just picked one of the cells. Let's pretend address is 0. So now this cell select line is activated by the decoder. Now, that means that since we're doing a read, the cell's double inverter loop inside will drive these bit lines, and the stored bit changes will go down the wires towards this analog logic, at which point this logic down here will read the bit off of the bit lines and send it out to data out. So that's a read. So in this logic, remember that reads and writes act differently. And so the write enable semantically means if we want to do a write, we set write enable to 1. If we want to do a read, we set it to 0. So when we tell this logic down here, write enable is 0, that's telling it, OK, don't do anything to the bit lines. Just wait until the logic comes down from the cell, as opposed to writing to the bit lines. So that's a read. And so we're going to do a read. And we're going to do a write. And we're going to do a read. And we're going to do a write. And the logic comes down from the cell, as opposed to a write, where you'll see in a second, we're going to push the bit lines to whatever logic we want, whatever value we want to store. Yeah, so for each operation, you can read one bit or write one bit. And you can't do both at the same time. And you can't read or write more than one at a time either. Yeah, Eric? Yeah? The dual inverter loop? Uh-huh. So this double inverter loop is exactly the same thing we used in a latch. So it's bistable. You can store a 0 on the left and a 1 on the right, or a 1 on the left and a 0 on the right. Yes, that's right. Yeah. Yeah, so when you connect these two, if you're doing a read, then whatever this inverter drives, whether it's 0 or 1, will go down this bit wire. Whatever this inverter drives, which will be the complement of this inverter, goes down the bit prime wire. So we must have a 0 on the left and a 1 on the right. But it's not a 0 on the right. Yeah, this double inverter loop is bistable. There are two stable states, just like when we looked at the latch. It's exactly the same. Make sense? OK. Why do they need to be in one? Let me come back to that. Someone had asked earlier about timing last week. And it's a similar answer. So I'll talk about it in a little while. For now, think about it as we just have to wait long enough. OK, so let me skip through the read. Is that the read? OK, so that's the read. All right, so actually here. So memory is not clocked. There's no clock in this system. It operates asynchronously with respect to other logic. So basically, it takes some amount of time. And the person who designs the memory needs to figure out, well, how long is that? And then in the data sheet, it'll say, you must wait this long. And then the system that you build to use memory has to wait at least that amount of time. So you can translate that to your system's clock cycles and round up. And that'll work. But it's not synchronous. It's not a clock system. So a couple of different approaches. So the designer specifies a minimum wait time in the data sheet for a read to happen. Or the way it's done in Patent Patel is the memory can also have another output, say, a ready signal that says, OK, I'm done now. Now internally, this option is still done this way. The designer has to know how long it takes. And then they'll just generate the ready signal when the bit is there. But that ready signal is another way it can be done. This is a little bit of an aside. You may hear about SD-RAM. So you may go say, hey, I want to buy some RAM for my computer. Oh, I can get SD-RAM. And oh, what does that mean? No matter, told me it's all asynchronous. It's still true. What SD-RAM is is the interface between memory and your computer is clocked. And that allows us to transfer bits back and forth between memory and the computer faster than with an asynchronous interface. The internal cells are still not clocked. So the cells inside an SD-RAM chip are not clocked. Yeah. To some extent, yes. The asynchronous interface, you always end up kind of waiting for the next cycle. And so if instead you pick a cycle time that's a multiple or a fraction of your chip speed, then overall you can transfer data back and forth faster. So the interface is clocked. The chip itself is, I'm sorry, the memory cells themselves are not. Again, you don't need to know this. I just worry that you'll go out and see it and then you'll feel confused about synchronicity around this. All right, so this is a write. So we've got our bit slice. We set chip select again to 1. We set write enable now to 1. So we're going to do a write from this read and write logic. And that means it's going to force the bits down those two bit lines. So set the address. There we go. Set the address. So the bit to write comes in here on data in. And the address cell select line is going to be activated again. So this one will be activated just like last time. But now instead of reading the bits out of that cell, the read write logic, knowing this is a write, is going to hold these bit lines at fixed values. And that will force the inverters inside here to flip to the state that matches the bit lines. So now they're going to store that bit. And that's the end of the write. So once again, we have to know how long that takes. And we have to wait long enough. So the designer has to figure it out, specify, here's how long you wait for a write to finish. And then when you use it, you have to wait the appropriate amount of time. It's not clocked. So the activated cell will store that bit in cell 3. Good question. So does data in matter when write enable is 0? It doesn't. It doesn't get used for anything. And we'll talk about it later. We can actually reuse it. So real chips will reuse it and match safe pins. But let's save that topic for 10 or 15 slides. Logically, yes. Logically, yeah. And you can think of it that way for our class. It's kind of similar to the gated D-latch, but it forces it over. Right. No. It does briefly, but it's an analog design problem. So we talked about that a little bit last time. It's outside the scope of our class to do analog design. And even when we look at it, you really have to understand transistor sizing and timing and transistor-level circuit simulation. So it's well beyond anything we have to worry about here. You should just know they're analog circuits. And so at some point, you'll learn how to do those. But it'll be probably junior year, at least, before you know how to design it. What do you get out? Nothing. Yeah. So that's a good question. So what comes on data out for write? Nothing. And again, I'll come back to that later. But we're going to figure out, well, could we actually just share those sets of lines? Because for read, we're using one set. For write, we're using the other set. Why do we have two sets? Yeah. Yeah. Let me leave that till we come back. Because in practice, I mean it's disconnected electrically. But I need to show you how. So yeah. OK. That's handled by read-write logic. You simply put the bit in. Mm-hmm. Yes. No, it actually does use two wires in practice, the way I showed you the SRM cell looks. Yeah. It could. I mean, that was the question that was asked at the start of today. Could we just use one bit line? You could. But then electrically, you'd end up probably burning more energy. It gets back into the analog design question. So you'd save a transistor, but you would end up being less efficient and slower. So all right. So again, two approaches for writes. Remember, designer says how long. Or similar to Pat and Patel, you have a ready signal. Your write finishes. It says, OK, r equals 1. No. No, this is all the analog logic we talked about in my little box. Yeah. All right. OK. So here's our bit slice. So this is 16 by 1 memory. Number of bits is larger. And this balances speed against size. So you can have 1,000 cells in a bit slice. And it'll be slower because you have very long bit lines. And when you read, that little double inverter loop has to drive that long wire. And so it takes longer. On the other hand, if you have 1,000 instead of 16, that means, well, you've got this one copy of this logic over here shared across 1,000 bits instead of shared across 16 bits. And so the longer you make them, the slower they are. But the more efficient they are in terms of space. And so smaller, but slower. So the other cost is this decoder. I mean, it looks like a small box here. But how many gates are there in an end-to-2-to-end decoder? Roughly 2 to the n, right? Because you've got one AND gate to drive each of these wires. And they're 2 to the n wires. Remember, it's minterms. So if you have n inputs, 2 to the n outputs, you've got roughly 2 to the n gates, plus some more. But roughly 2 to the n. So that's a lot. So let's think about that. So if we have more than one bit slice, let's say we stacked a few of these. And I'll do that in a diagram in a second. We could have, let's say, a bit slice of a bit that's a little bit larger than the other. I'll do that in a diagram in a second. We could share those select lines. But then how would we decide which bit slice is active? Put another of these, right? Put another decoder. But what does that mean in terms of our decoder area? Well, so let's say you've got a million cells, 2 to the 20 cells. So 2 to the 20 cells, one big decoder, that's 2 to the 20 gates. If instead, I did it in two dimensions, and I said, OK, in one dimension, I'll use 2 to the 10 gates, sorry, 2 to the 10 decoder. In the other dimension, I'll use 2 to the 10 decoder. And then where those wires cross, that'll be one cell. Well, that'll give me two decoders with about 1,000 gates each, so about 2,000 gates, compared to a million gates. So much, much smaller decoders if I use two dimensions. Well, so the problem is the cell really only has a couple of things that can be shared that way, right? So there is actually more hierarchy in real chips than two levels. But in order to generate the signals to those little pieces, you end up putting more gates down here and there anyway. So you can spread your gates out, but you end up using about the same. Yes. I told you I'd show it in a second. All right, so here's 4-bit slices, right? So let's just take a look. I mean, the savings on the decoder is not going to be very dramatic, because this is only 6 bits of address. But here are 64 cells split up into 4-bit slices. Each bit slice has 16 cells in it, just like they had before. We now have a 6-bit address, right? So 2 bits of our address will decide which bit slice. And 4 bits of our address will decide which of the cells in one of the bit slices. So we can take a look at how that works. So here's our 6-bit address. 2 bits over here, 4 bits down here. So let's look first at a write. So chip select is 1. Write enable is 1. So just like before. So set the address bits. So some of our address bits will go up here, right? And so what that means is now, let's see. So write enable is going to go into this decoder as our enable signal. And so one of the 4 outputs based on these 2 bits of the address, the upper 2 bits in this case, will go out and feed the write enable signal on one of the bit slices read-write logic. So all of the other bit slices will think they're doing a read in this design. But we don't really care that much. So they're going to all do reads. But this one here will do a write. So this one will do a write. The other 4 address bits go down here. This line is then activated. So 3 of these bit slices in this design will do reads. This one that I've highlighted here will do a write. So the bit to write comes in. The bits are held at a fixed value. And that cell there then stores the data in there, but only that cell. All of the other cells, there might be some bits coming down these wires. Those basically will just get ignored. Yeah. Oh, I mean, typically in a CAD tool, you'll say I want a memory. And someone will actually have optimized memory variants for you. Yeah, memory optimization, there are tools that will do it for you. If you really need to go and do it yourself, there's several academic papers and things like that that you can do. Oh, yeah, yeah. Intel does their own by hand. And so does IBM to some extent. Maybe not anymore, but it's a long time. OK. So let's take a look now at a read on our 4 by 16 design. So this is really a 64 by 1 memory. 64 addresses, 1 bit each. But we've split it into two dimensions. So chip select is 1. Write enable is 0. Part of the address, again, goes down here. So one of the select lines is activated. Let's say we know, I haven't highlighted it yet here because it doesn't actually use this decoder. It uses this MUX down here. So this cell, again, is activated. Its bit will flow down these bit wires. And then the output will come out of the Q output and go down to the MUX. Now, these other bit slices are also going to produce a bit, but we're going to ignore them. So using this MUX, we'll look at the other addresses, pick out the bit that we wanted, and that will come out to data out. So the MUX will handle the output side for us. You might think, well, wait, there's a little triangle thing. What is that? OK, so what's the triangle thing? It's called a tri-state buffer. So why? There are three rows in the truth table. So the only thing that you might not understand about this truth table is it's called a tri-state buffer because there are three rows in the truth table. What does Z mean? Any idea? Means high impedance. So it means, in other words, it's electrically disconnected. So the input and the output are electrically disconnected when the enable input is 0. And what that means is we can have this connection between in and out. And if enable is 0, this outside can be actually driven by some other gate, by some other logic, and it won't create a short. So it's electrically disconnected when enable equals 0. So how can that happen? So here's a diagram. This is not going to look like one of the other gates because this is not always producing 0 or 1. Before, when we built gates out of transistors, we always wanted to produce 0 or 1. We never wanted to have it just be left floating for the output. This one is going to be left floating. So let's take a look at how that happens. So what happens when enable equals 0? So you put a 0 there. Yeah, cool. High impedance means electrically disconnected. So it just means it's turned off. The transistor is turned off. It's like an open switch. Let me show you in this diagram, and then maybe I think that might clear it up. All right, so enable is 0. So what's the voltage here? What's the 1, right, after the inverter? So is this on or off? Good. And then down here is a 0, right? This is just the wire. How about this one, on or off? Good. So you see what happens when we set enable to 0, right? Basically, out is disconnected from ground. Out is disconnected from high voltage. Out is just floating, not connected to anything. That's what I mean by the Z, high impedance. So you can't cross either of these two transistors easily. OK, what about when enable equals 1? So that's 1. What's here? 0, right? OK, so on or off? How about, let's see, down here is a 1, on or off? OK, so what does that look like now? Is it a short? You still have two transistors, right? So this is an inverter, right, with these two transistors. That's an inverter. There's another inverter, inverter, inverter. So after this inverter is in prime, after that inverter is in again, right? So copied into out. Make sense? Yeah, sometimes people get confused, and they think a tri-state buffer is just like a 1n-type MOSFET or something, but that's not true. So it takes a bunch of transistors to make this work. It has to be active logic. You want to drive out using either high voltage or ground. Right? All right, so tri-state buffers, what do they let us do? It means we can actually wire outputs together. So that means we can have one set of outputs and have something like what I'll call the distributed MUX. So say we've got four groups of n signals. So there's something producing n signals over on the left side of the chip, another thing producing n signals at the top, another on the right side, another on the bottom. We could use a MUX. That'd mean we have to take n wires from each of those, bring them all into the same place, so 4n wires. And then we'd have to decide which of the four we wanted. And then we could take the answer and send it everywhere with n more wires. So 5n wires, a lot of wires if n is big. So instead, what we can do with tri-state buffers is send four control signals. Now, those will be one hot. Obviously, we can only pick one of the four sources. So one of those will be a 1. The other three will be 0. But any of them could be a 1. So those will go to the tri-state buffers. That's four wires that go everywhere. And then we'll have n wires that send the answer out still. But instead, those n wires just circle around the chip. So it's n wires going to all four of the things. We'll call those n wires a bus. So now we have n plus 4 instead of 5n wires going everywhere. So those enable wires mean that only one of the four values actually gets written to the wires that go everywhere, the bus. So in some sense, they're acting like a distributed MUX. So these four control wires go to the tri-state buffers. And only one group of n signals gets written to the bus at a time. So if you look at the LC3 computer data path in Pat and Patel, first shows up in chapter 4, you'll see that it actually uses a bus. And it uses tri-state buffers to decide what gets put onto the bus at any point in time. So that's one use of tri-state buffers. Now, for our memory design, the other thing we can do, to generalize this a little bit, data out is gated with tri-state buffers. So whenever you have a memory in our class, then the output is only going to appear on the output when you're doing a read. So if you're not doing a read, those output wires are floating. So that means any time your chip select is 0 or your write enable is 1, in either case, you're not doing a read. So your output will float. Now, technically, that means your input and your output wires can be the same wire. You're only looking at the inputs when you're doing a write. You're only using the outputs, connecting them to some ground or high voltage, when you're doing a read. So why not just use the same wires? In fact, most chips did that. Most chips would have a data bus, basically a bunch of pins going into them. And you would use the same pins on the chip for reading and writing. It's actually a lot of bits. A lot of pins. So it was important to do this. So we use the same bits, same pins. When we do a write, the pins are accepting bits to store. When we do a read, the tri-state buffers write the bits from the memory cells onto those pins. Why don't we just use separate wires? So the reason is because pins are a very limited resource compared to transistors on a chip. So in the last 30 or so years, the number of transistors on the chip has gone up by a million fold or something like that, maybe more. The number of pins has gone up by about a factor of 10 or 20. And then the number of pins you can fit, physical pins, onto a chip is tiny compared to the amount of data you can pump in and out of the chip. And so if you're not using your pins efficiently, if you just say, well, I don't really need to use these sets of pins at the same time, you might say, heck, I've got lots of pins. You don't have lots of pins. So that's why. And you didn't have lots of pins 20 years ago either. All right, so building a memory of more addresses. So let me give you this thought problem, and then I'll show you how it's done. So let's say we've got two memories, and each of them is 2 to the k, so k-bit address to the k addresses by n, n-bit addressability, so n bits at each address. How can we put those together to have a bigger memory with more addresses, so 2 to the k plus 1 address? So first, just verify, well, if I've got 2 to the k by n-bit memory, that's 2 to the k by n memory cells, the little double inverter loops. And so I have enough, because if I have twice that many, I can treat that as 2 to the k plus 1 times n, which is what I need for this memory. So we have the right number of memory cells. How do we wire it up? It's actually pretty easy. So the one thing that's a little tricky over here, we're going to need a little decoder to handle the chip select signal. So we're going to put chip select into the enable. So if chip select is 0, the decoder will output all 0's. So you see that 0 goes to chip 0's chip select. 1, I'm sorry, I'm giving them names. This will be 0 on the left, 1 on the right. 0 goes to this one's chip select. 1 goes to this one's chip select. So if the external chip select is 0, both chips are not selected. On the other hand, if external chip select is 1, then one bit of the address is used to decide which of these two chips is going to do something. Only one of them is going to do something at a time. So only one of these two memories is active at a time. So what that means is we can just say, well, we'll take the data in and just copy it to both. We'll take the right enable and just copy it to both. We'll take the data out and just merge them. Remember, they're tri-state buffered, so that's safe. So we don't have to worry about that. We'll take the address bits, all but the one k that we used for this decoder here. The rest of the address bits we'll also copy to both chips, and we're done. One of them will do a read, one of them will do a write. Which one? Well, it depends on the high bit of the address. You'd have to put muxes down here, right? Yeah. Yeah. I mean, yeah, n 2 to 1 muxes. Yeah, that's right. And some extra delay there, too. Yeah. It's controlled by chip select and right enable, right? Yeah. Inside those memories, yeah. Yeah, which in the bigger diagram, there was a tri-state buffer already in there, right? Sure, yeah. Yeah, that's not a bad way to view it, because it is like a switch. It's electrically disconnected when you turn it off. Yeah, although you can also have switch styles. Like the one in the lab is a 0, 1 switch, the way we've wired it up. So just be a little careful how you think of a switch, yeah. The way we drew it with transistors, where it's open or closed. Yes. OK, one more question. So what if we wanted instead to take two memories and make something with more bits for each address? So again, two memories, same size, but instead of twice as many addresses, I want twice as many bits at each address. So same argument down here. Well, I've got the right number of memory cells, so should be doable. It's actually a little easier. We don't need any extra logic. So we can just hook them up like this. So the address goes to both. So both of them are going to be active at the same time. You can see chip select is going to both of them also. Write enable also. Data in, we've actually split up into two groups of bits. We now have 2n data inputs, and we have 2n data outputs. So the top half of those will go to one chip. The bottom half will go to another chip. Down here, half will come from one chip. Half will come from the other chip for the data outputs. Now, you can mix and match these bits any way you please. If we ask you this problem on an exam, and we'll probably ask you, please don't make complicated patterns. But as long as the pattern you use up here matches the pattern down here, it doesn't matter. So when you write bits, you use the same way of taking those bits here and putting them into the chips as you do when you get bits back out of the chip. It doesn't matter what mapping you use. In practice, people do look at more complicated mappings for performance reasons. But that's something you'll learn maybe in 4.11. So if you go out to Micron's site, I think the biggest one you'll get for a chip is about 8. Last time I looked, it was about 8, so 1 to 8. And then you build. So there are different questions. So that's the memory perspective is at most 8, and typically 2 or 4. But from the processor's perspective, most instructions in architectures, which we'll start talking about next week, will be byte addressable. So any individual byte in memory has a name for it. There were processors people tried to build in the 90s where you could only talk about 8 bytes of memory. And pretty soon, they figured out that there was far too much software that wanted to do byte addressable memory. And so they had to add that as an extension. Anything else? All right, so I just want to make sure you understand. So write, then you'll take the bits, split them up. Both of these chips will write at the same time because write enable will be 1, chip select will be 1. So both of them will write half of the bits into their cells. When you want to read it back out, chip select will be 1, write enable will be 0. The address will be the same. So we'll collect the two sets of bits from those two chips and then put them together on wires. And those will be the bigger answer. Yes, to some extent, in the coming weeks. The question is LC3 instructions, probably, mapping to logic. Yeah, we'll look at that. So that's it for memory. What I want to spend the rest of today and probably all of Wednesday on is developing a finite state machine that will implement a little piece of code. So you can do pretty much anything with a finite state machine. So let's take a piece of C code. And we'll use components to store the variables. So by store, I mean probably registers, flip-flops, things like that. So the variables in the C code will become registers, counters. We'll also execute the statements. So any time we're moving bits around, that'll be something we do based on the finite state machine. We do comparisons. We'll use a comparator, things like that. But we use other components to execute the statements. And the finite state machine is going to use those components by having the outputs of the finite state machine act as control signals for the components. So we'll have a bunch of components. We'll put them together. We'll call it a data path. And then we'll have the finite state machine state say, well, what should the components do in every cycle in order to basically execute this little piece of C code? Yeah, right? Oh, it was the other way, right? You were given the C code. And you were asked to draw transitions. This is a little more direct in the sense that a lot of software basically is a finite state machine. And so you can do that exercise for almost any piece of software. It's just that the state in software can be arbitrarily complicated. The state of this code is pretty small. So it'll be a little easier in that sense and a little harder in the sense we're building hardware from software, going the other direction. All right, so here's the piece of code I want to do. So what this is going to do is find the smallest integer amongst 10 integers. So if you look at this code, you should know how to read everything except that. So what does that mean? Some of you might know. But there's no reason from our class you should know what this means. So let me explain it. So this variable declaration creates 10 32-bit choose-complement numbers. So it's a variable declaration. It says, I want 10 of them. And so they are then named. It's called an array. They're then named values 0 through values 9. It's a software analog of a memory. So we said, oh, we're going to have a bunch of values. We need names for them. Let's name them 0 through 65,535 as bits. In C, we can name them as decimal, value 0 through value 9. But that's all it's doing. It's saying, OK, I want 10. So we get those 10. The first array element is used here. So we'll take the first one and copy that into min. We have to assume that this was filled up by someone else. So assume someone's written 10 numbers into those. Whatever element is accessed here depends on index, the variable index. So again, values goes from 0 to 9. So the variable index will have values somewhere between 0 or 9. And which of the elements in values, the array of values gets accessed, depends on the value of index. So it can be read. It can be written. So let's assume, before we execute our code, that somehow these 10 numbers get filled in. So something's going to provide our finite state machine with 10 numbers. Our finite state machine then will go through and find the smallest of those 10 numbers. So the first step then is to copy the first array element, value sub 0, into min. So we'll start by saying, well, if we just look at one of them, it's obviously the smallest one. So I'm not going to answer that now, because building that into the finite state machine would mean that we have to then build all I-O and things like that. So we'll just assume that someone's going to put these into something the finite state machine can access. And in the next couple of weeks, maybe three weeks or so, you'll see how the LC3 is built. And then you'll know how to answer your question. All right. So here's a loop. So if you look at this loop, you should know how this works. You start at 1. You check if index is less than 10. And then you increment index for the update. So the values in that loop, index will start at 1. And the last iteration, index will be 9. So it's going to run from 1 to 9. And then inside here, in the loop, we're checking whether the entry indexed by the IDX variable is less than the current minimum, and then replacing it if it is. So we go one by one through the 10 values, through the second through 10th, and check if it's smaller than our current minimum. And if it is, we copy it into our current minimum. So at the end, the variable min holds the smallest of the 10. Make sense? Someone? Yeah. Sorry, Kyle. Yeah, IDX++ is equivalent. We just didn't teach it in our class. So I just wanted to keep the syntax we taught. Min and the value IDX are equal. I'm sorry. I don't understand the question. Oh, yeah. If they're equal, then they're equal. It doesn't matter whether you replace it or not. So in software, you want to minimize the number of instructions that need to be executed. And so executing instructions that have no effect on the value IDX, that's not a good idea. So you want to minimize the number of instructions that need to be executed. And so executing instructions that have no effect, you try to reduce that. So software-wise, it's slightly better performance. In terms of what we're going to get, it's not going to make any difference. It does nothing. Yeah. This is the array element numbered by index. Remember, they're numbered 0 through 9. And index holds a value from 1 to 9. So min starts out as the first value, meaning value sub 0. And then you compare it with the other values. And if one of the other values is smaller, you replace min with that particular number. Yes, and we'll do that. The index variable, yes. So let's draw a flowchart. So we start down here. First thing we did was initialize min to value 0. I'm using colors for the statements here. So this was gray was our initialization. The green is our for loop. So the first initialization in the for loop was index set to 1. And then check if 10 is greater than index. And then if that's false, we're done. Of course, it's not false the first time. It's true. So again, those green things are part of the for loop. The blue is part of the if statement, and then the body of the if statement, the then case. So ifs checked whether min was greater than value sub index. And if that was true, it copied value sub index into min. Once that was done, it went to the update of the for loop. If the if condition was false, we also came down to the update of the for loop, after which we went back up to the test. So there's a flowchart for that code, color coded with statements. So this is just a step towards figuring out how we'll actually organize our finite state machine states. So before we go there, though, let's think about how we're going to turn that flowchart into a finite state machine. What component should we use? So we need an array. I said that an array is the software analog of a memory. So what do you think we'll use? We need 10 different values. We could use registers. We need 10 registers, and we need to be able to name them. Let's use a memory. So then we can use a memory, and we can name them 0 through 9, just like we did in the code. We can name the 10 values 0 through 9. What about the other variables? Registers, counters, stuff like that. What about the if statement? Sorry. So we have to do this comparison. Let's use a comparator. In fact, I'm going to use the serial comparator, not because it's better or anything, but just because I want to remind you that we can build these state machines where one state is actually representing a bunch of states, like we did with keyless entry, where the alarm state became a bunch of states counting the timeout. So here, the state that uses the comparator is actually going to be a bunch of states. It's executing a serial comparator for 32 bits. So just show you the hierarchy of an FSM again. So in order to execute a serial comparator, we have to feed it one bit at a time. So I have shift registers for that and a counter to count 32 bits as they go into the comparator. All right. So what are the rules about implementing state machines? So if I'm going to implement a state machine, well, my states have to be executable in some fixed number of cycles. So I have to figure out how to take this flow chart and break it apart so that I can execute the pieces in one cycle or 10 cycles or at least some predictable number of cycles. I can't just say, ah, just put all the flow chart in one state and I'm done. I could, but it wouldn't be very effective. So that's related to how many components and what kinds of components I use. So if I use very simple components, it's going to take me several cycles to do anything. If I use very complicated components, it'll take me more area, but things might be faster. So for example, I could say to you, well, I need to compare 10 numbers. So go build a 10 operand comparator. It's doable. You can sit down. You can write the equations out. You can solve the k-maps. Well, maybe not k-maps. But you can do a 10-input comparator. And it just spits out the biggest number. It's one big combinational logic. Then it's a very easy finite state machine. One state. Execute comparator. Done. So probably we're not going to do that. We could do that. Different design point. How we pick our components. What we did when we said, OK, we want a memory, registers, counters. How we actually pick them will affect how we design our state. So in practice, we'll go back and forth. When I actually designed this, I went back and forth. I said, well, what if I put these down? Then here's my states. Oh, but that's kind of annoying. So let me go add some more components. Now that's too complicated. So you go back and forth. But this design is all done. So I'll present it as if it were easy, but it's not. You often have to go back and forth as you see how things work. All right, so how do we pick states? So we're going to break the flowchart into pieces. Not every flowchart box is going to become a state. So I'll give you an example in a second. Well, actually, example's here. So in our flowchart, the first few steps were to initialize min. We said, OK, let's set min by copying the first value from the memory into min. We also need to initialize index to 1. And then we do the first comparison. Well, we don't really need to do that in our finite state machine. We know 10 is greater than 1. We're done. So we can do all three of those in the same cycle. So in other words, this part, this part, and this part, we're going to make into one finite state machine state. So now the colors indicate the state. So this is something we'll call the init state. And it'll perform these three boxes the first time. All right, so we can also join some other states. And we can do that by leveraging what we call predication. So what does predication mean? That's actually just an English word. We use it in the same sense when we design things as engineers. So predication means that something only happens under certain conditions. So the English sentence, well, if you give me an apple, I'll give you a peach. You only get the peach if you give me an apple. That's the predicate, if you give me an apple. And if you satisfy that predicate, then you get the peach. We can use that in a logical sense, for example, by saying, well, we get the output from a comparator. And then we can use that output from the comparator to decide, should a register load a new value or not? The way we change the register min is to load a new value into it. So we can use that comparator output to decide, should min load a new value or not? That means we can perform that action in the same cycle that we increment index. So what does that look like in a flowchart? Well, we have these two pieces down here. We had copy values of index into min. That'll now be predicated by the output of the comparator. And then increment index will put both of those into one finite state machine state that I'll call copy. Now we have two states. So now let's step back for a minute and say, well, we've got this finite state machine. How's it actually going to get used? It's going to go in and find the minimum of 10 numbers. But we said, well, something has to fill up those 10 numbers. So something's going to fill up those 10 numbers. And then it's going to execute our finite state machine. And then the finite state machine needs to just kind of wait around again while that thing, whatever it is, reads out the answer. And then maybe later it'll put 10 more numbers in and execute our finite state machine again. But we need some kind of wait state. So let's create a wait state. So during steps 1 and 3, our finite state machine is just waiting there. And then we'll have a start signal that says go to start step 2. So that'll be an external input, start, for our finite state machine to go actually do its thing, run through the flowchart. So where are those? So this was the done, the finish. So start will now be this wait state. And done also, whenever the finite state machine is not executing the code, it'll be sitting in this wait state. And that'll give the external logic time to fill the memory, read the answer out of the min register, and so forth. The last piece then is the if statement. So sometimes, even though it looks easy in a flowchart, it's not so easy to do on the data path. So in our data path, we said, well, we don't have a serial comparator. It has to be fed by shift registers. We need to put values into those shift registers first. So it takes time, takes a cycle, to put a value into a shift register, even if you do parallel load. We also need a counter that's going to measure 32 cycles. So we need a preparation stage. So we'll go and create a prep state in which the finite state machine copies min into the shift register A, copies values of index into shift register B, and resets the counter, all of that in one cycle. And then we're going to have a compare state that will execute for 32 cycles where we run the serial comparator. And then when the counter counts up to 31, we'll have some counter. It'll count up to 31. And the finite state machine will move to the copy state that we already showed. So here's that last bit of the flowchart. You notice I've broken it up into two colors because we're going to have a prep state, and then we're going to have a compare state. All right, so let me finish by just showing you this abstract state diagram. I'll just flip through it, and then I'll walk through it. So this is now what we have. We have a wait state. The finite state machine sits around there until it sees the start signal. When you see the start signal, you go to init. That takes one cycle. Then it goes to prep, where it actually prepares to do a comparison with the second element of the array. Comes down to do the comparison, runs this thing for 32 cycles, and then goes to copy, where it might actually copy the second value into min. That would not be the end of the loop. So it would go around this loop here, the yellow, blue, green, yellow, blue, green. It would do that nine times to compare the other nine elements. And then when it's finished, the smallest number is in min, the register min. So it would go up to wait and finish. And then some other logic could come out and read the smallest number. So we'll go over this again and then finish up the design on Wednesday. Thanks.\",\n",
       " \"Went through it quickly, so I want to make sure you understand the idea of sticking some glue logic in to clean up the inputs. Then we're going to start talking about using an approach to design in which we break off one piece at a time. And we'll start with a ripple carrier and just use the human intuition of how we do base-2 addition to design the hardware. And then we'll generalize that and think about how we can approach these problems by basically using induction to prove that the answers are correct. So we'll talk generally about bit-sliced designs. After this, we'll start working on a comparator. I don't think we'll get there today. I think it'll be not till Monday. Couple comments before we start. I mentioned last time, midterm one, we're going to sit down and grade it tomorrow. After lecture on Wednesday, I took my, we're doing a rubric generation. So I had 20 exams. So I graded 20 exams. I think it was Wednesday night. Might have been Thursday. The average, maybe I should let you guess. So I didn't pick this. But somehow, my responsibility for creating problems on the exam totaled a certain number of points. Yeah, 42. I was surprised. I didn't pick it. Anyway, so from 42% of the exam, about 5% of the students, so not great statistics, I'd estimate kind of 80% to 90% average. So the big swing there is that other people's problems may be easier or harder than mine. But mine on average were about 80% to 90% given only 5% sample. So there's a little bit of swing there too. So overall, you did quite well. So ice cream. So remember, we started thinking about how we build an ice cream dispenser on Wednesday. And I said, well, we have three input buttons, MB and P for mango, blend of mango and pistachio. It doesn't sound that appetizing on a Friday afternoon. And pistachio. And then each of the two outputs, two unsigned numbers, two bit unsigned numbers for a number of half cups of each type of ice cream. And we realized by putting in a bunch of don't cares, we could just design it with wires. But the problem with that was humans are not nice about following rules. So if they come up and push two buttons, then our ice cream dispenser would at best spit out two cups of ice cream instead of one. And at worst, actually might destroy something. Because some other engineer might have assumed that, well, we agreed you wouldn't send one one. Only 0, 0, 0, 1, and 1, 0 were supposed to be meaningful patterns. So I shouldn't have to deal with 1, 1. So we did actually care in that case. So the solution was, so now I'm going to slow down a little bit because I think I went through this too quickly last time. So the question is, well, how do we fix that problem? And one answer was, well, don't put in don't cares. So pick some bit values that you know are not going to affect anything. For example, pick all 0's. So you push two buttons, you get no ice cream. You push three buttons, you get no ice cream. That's one answer. You'll get some more complicated k-maps, and you could build your logic. And then you're guaranteed that regardless of what the user does, nothing bad happens. So don't use don't cares is one answer. Another approach, and this is the one that I wanted to show you, they're actually kind of equivalent in this case at the end of the day. But you can think of it differently. Well, let's take the inputs, and let's put some logic there to guarantee that the assumptions we made that the user will only push one button or zero buttons are actually true. So how can we do that? So that basically prevents the humans from ever putting a bad combination of buttons, from ever producing a bad combination of inputs. So how can we do that? Here's one way. So we could say, well, any time a user presses more than one button, the outputs we'll generate for them will actually just be all 0's. So let's create a little piece of logic that takes the three button inputs and produces three output bits that look like the buttons, except that if the user presses two or three buttons, they all become 0's. So how do we do that? Well, for the case of the mango button, you can see the yellow and blue networks are B prime and P prime. B prime is the blue one here, and P prime is the yellow one. And you can see those both go into the AND gate along with M. So the output of this AND gate says that the user pushed mango, and they did not push blend, and they did not push pistachio. So if this output here for the mango is 1, that means they only pushed mango. And so the only way you can get a mango output is by only pushing that button. Similarly, if you look at the second AND gate here, it's taking the yellow input, which is P prime, and the green input, which is M prime, along with B. And so that output of that AND gate says, well, they pushed the blend button, and they did not push the mango button, and they did not push the pistachio button. So again, the blend output now, after this dotted box, they could have only pushed blend by itself, no other combination. And then finally, for the pistachio AND gate down here, you can see pistachio is going in there, but we also have M prime in the green network and B prime from the blue network. And so this AND gate says that the user pushed pistachio, they did not push mango, and they did not push blend. And so the only way you get a 1 out of that AND gate is if the user only pushed pistachio. So by adding these three AND gates and a few inverters, we can clean up our inputs and guarantee that, in fact, a human, even if they push a bunch of buttons, they can't affect the system. The inputs that we see coming out of the dashed box are always, at most, one button at a time. So this is one choice. And we can think of this as some glue logic in between our inputs and the way we process those inputs, which is just with some wires. So these wires over here are equivalent to the previous design here. And so I just kind of smashed them together to fit it all in the diagram. But they're fully equivalent to the previous design. And so you can think of this as, well, all we did was add a little logic in between our inputs and how we use those inputs. So that's one strategy. Another common strategy would be to choose a priority. So there's six different ways to do that. I think there's one in the notes, so you can take a look at that. But what does it mean by priority? Well, you simply say, well, one button is more important than the others. So for example, if you push pistachio, just ignore the other buttons. You're going to get pistachio. So you push pistachio with blend, you get pistachio. Push pistachio with mango, you get pistachio. Push it together with both other buttons, you still get pistachio. That'll be the high priority. I think I'd rather do mango. And then second priority would be mango, for example. Again, you can pick any order you want. You can design the logic any way you want. But you just guarantee that what your logic sees is always at most one button is kind of the point. So any of these approaches is fine. In this case, mango might override blend, but it would be less important than pistachio. So you pick a strategy. You can also combine these approaches. So there are many ways to solve the problem. All of them are fine. All of them involve kind of design decisions. So you as the engineer have to decide what's going to be the most sensible thing for some human who pushes these buttons. Maybe it's better to just not give them anything and make them figure out that they should only push one at a time. Maybe it's better to just give them some ice cream and send them away. That's up to you as the engineer. But it's bad to let the system do something unexpected or unknown. So in the case of our ice cream dispenser, if you work it through, you'll probably get about the same answer, if not exactly the same answer. Solving it with a priority from the original KMAPs or solving it with forcing things to zero from the original KMAPs versus thinking of it as glue logic. And in general, you will get variations in area, speed, power. Right here, we only had wires. But if you put extra levels of logic, it will be slower. Whereas if you solve the KMAPs directly, you'll get SOP or POS. You'll get two-level logic. It'll be faster. So in general, you'll get variations. But maybe cleaning up your inputs is a little easier to understand. So you get an abstraction benefit, possibly at the expense of speed or area. So they are conceptually different approaches to the problem. All right. So that was it for the ice cream example. Anyone want to ask anything about that before we start adding? All right. So finally, weeks ago, I said, well, what if you had some hardware device to do addition? And in the meantime, since that first discussion, we've actually gone and filled in. I know the truth tables for adding. I'll walk through it again in a minute. So I think you know mostly how to do this. And probably, you could do it without my showing you. But let's walk through and do it. So we're going to do it based on the human approach. So remember, we write down numbers as binary numbers. And we add them just like we do in base 10, except it's binary. So 1 plus 1 is 10, and you have to carry. But in general, this approach of, well, let's start with a human design will often give you a pretty good design. So you can start that way. It's usually pretty easy, because if you know what you're doing as a human, turning that into logic should be pretty straightforward compared with making up something abstract and trying to figure out the details. And it often does lead to a good design, because humans are pretty smart. The way we do addition was the result of thousands of years of thinking about, well, what's the best way to teach kids how to do this efficiently kind of thing? So usually, the way we do things is not a bad way to do it. So you may remember this slide. This is just an example slide from the first time we talked about binary addition. So we did it before. 0 plus 0 is 0. 1 plus 0 is 1. 1 plus 1 is 0. Carry the 1. 1 plus 1 plus 0. 0. Carry the 1, and so forth. So we got that. We got the right answer. We were happy. And now, we need to put some labels. So in order to build a system that'll do, say, 5-bit addition, we're going to need labels. So I've already called this number A, called this number B. This will be our sum S. And then up here are going to be our carry bits. Now, this is a digital system. So when I was doing base 2 addition by hand, I was kind of lazy. When the carry was 0, I didn't go right to 0. But there's no blank bit. So those things, there's no blank bit. Those carry bits are going to be 0s, not blanks. And so just fill that in. Make sure we know that. There's also this carry bit here. So if we're going to design one piece of logic that adds one column, well, that piece of logic also needs a carry. And it can't be a blank. So we're just going to assume that we're going to put a 0 into the lowest, least significant bit carry. So just flesh out our human approach with the details that we usually just don't bother to write down. I mean, if I'd asked you, oh, what's the carry here? You'd say, well, it's 0, right? Obviously, I left it blank. But there's nothing obvious to a computer. All right, so two extra assumptions. For the least significant bits, we're going to set c to 0. And for the other bits, the carry input is going to come from the next least significant bit. So this is just adapting our human approach to digital systems. So let's spell that out. So we've got inputs and outputs for this full adder. So a full adder is going to add one bit. The name is historical. There was a half adder that added two bits. And then if you put two of those together, you could add three bits. But a full adder will have three inputs. So there's going to be one bit of the number A, which we'll also call A, one bit of the number B, which we'll also call B, a carry input from the next least significant bit, or 0 for bit 0, which we'll call C in. And a full adder will then produce two outputs. So one is the carry out, which will go to the next most significant bit, or if this is the most significant bit, that'll be the carry out that tells us overflow for unsigned or just carry out for just complement. And then one bit of the sum S. So those are the inputs and outputs for our full adder. So here's our full adder the way we might draw it. So you can think of it as a bit slice. You can think of it as a full adder. But here's a picture of it. So it's got two inputs coming in. Those will be the m-th bit of A and B. So this will be one bit slice for the m-th column of our addition. We'll get the carry. I put it as a superscript here to differentiate it from the in and the out. But otherwise, putting it a superscript doesn't really mean anything. It's just the m-th bit of the carry. The m plus 1-th bit of the carry is an output. And some bit m is also an output. Yeah. So the question is, do you have to pass the carry? It gets passed from the left. So the one coming in is from the one less significant digit. And the one going out is to the next most significant digit. But if you're all the way at the end, then I can go back to the yeah, here. So if you're this last bit here, so in a five-bit addition, we would have five of these full adders. So the last one will produce the carry out of the whole adder. That make sense? OK. Anything else? Yeah. Yeah, so for unsigned, the carry out is the overflow, as you might remember. In order to calculate the overflow for 2's complement, we would need to add some additional logic to our adder. And in practice, most adders in real processors would have that extra logic, and it will give you an overflow bit as well. In the LC3 design in the textbook, they didn't bother to add it. So you can calculate it other ways. It's just a little more onerous. We won't add it to our design. It's one extra XOR gate. All right, so here's our design. So now in order to implement this bit, we're going to use a KMAP, of course. And first, we'll fill in our truth table. But we need to add A, B, and C in, and then produce S and C out. So let's go ahead and do that. So let's calculate our outputs. Again, the inputs are A, B, and C in. The outputs are C out and S. I've written these so that we can just add the two numbers and then get a 2-bit sum. And then the high bit will be the carry, and the low bit will be the sum output bit. So we solved this a few weeks ago. Let's go ahead and do it again. So if I do 0 plus 0 plus 0, what do I get? 0, 0. Yeah, 0, 0, 1. 1. 0, 1, 0. Good. 0, 1, 1. Yeah, 0 carry the 1, right? 1, 0, 0. 1 and 0. 1, 0, 1. Yeah, 1, 0. So carry is 1. 1, 1, 0. Sorry, I jumped ahead. And then 1, 1, 1. 1, 1. Good. So everyone remembers how to do this, hopefully. So then we can copy over to the KMAP. I don't remember if we've done this before in class, so let me just remind you. In our truth table, we're generally going to write binary order. In our KMAPs, we're going to write grade code order. And so the order of filling things in, if you're copying, here I put the two ladder variables there on the top. So B and C go this way. So reading downwards, we're first going to go across the KMAP. If you write the variables in different order, you would go down first. But in this KMAP ordering, we'll go B and C first, and then we'll do the second row as the second half of the truth table. And then the binary to grade code, since only this direction has two variables, we're going to go here, here, and then jump over to this one, which is the 1, 0 case of BC, and then fill this one last. So that said, we can just read them off. So 0, 0, 0, 1, and then fill them in. So 0 goes there, 0, and then we'll skip over, put the third 0 there, and then the 1 goes in the 1, 1 position. So make sure you get this, because every time you create something, if you make a mistake copying from your truth table to your KMAP, you're only going to catch it after you've solved the whole KMAP. You go back and you say, is my logic right? Did I get the right expression? Does it work? And the answer is no. And so then you'll go back and realize, oh, shoot, I forgot to flip these. I'll have to start over, basically. So just be careful when you're copying. So C out on the bottom is 0, 1, 1, 1. So we'll fill it in the same order. Even though the 1s, you could swap them. It doesn't make any difference. But just do things in the right order. Make sense? Question? Yeah. So remember, in a truth table, we're just listing all possible input combinations. C in is an input. Yeah. Yeah, yeah, we have to consider all possible combinations of inputs. And the A, B, and C in are inputs. And so we've got, in binary order, 0, 0, 0, 0, 0, 1, all the way through 1, 1, 1. Yeah, remember, in the truth table, to the left of the line, typically, is our inputs. And to the right of the line are the outputs. All right, so there came up a question. All right, so there came out, so we can go ahead and solve this one. So let's find loops. So where do we have loops? 1, 1. Good answer. All right, there's a 1, 1. So which one is that? B, C, N. Yeah, OK, here's another loop. Which one is that? A, C, N. And which one is this? A, B. So you can write that down. That's called a majority function, by the way, because we've got three inputs. And whenever two of them are 1, then the output is 1. Check that. It's not terribly important you know that. But if you're interested, it's called a majority function. So that's our carry out. For the sum, we're not going to do a KMAP, because it's not so easy. I'll show you in a second. But it's not easy to just immediately know you've got an XOR coming out. So I wanted to remind you that when you do the sum, the output bit, the low bit, is the odd function of the number of inputs. So if you're adding 0's and 1's, it doesn't matter how many you add. The answer you get for the low digit depends on whether they're an odd number of 1's in your sum or not. Here we've got three. So whenever there's an odd number in those three, we'll get a 1. So you can check that assertion. So here it's even. You get a 0. Here it's odd. You get a 1. Odd, 1, even, 0, so forth. But we write that as A XOR B XOR C. That doesn't come so easily out of a KMAP. So here's the KMAP. Just for your own benefit, I mean, we're not going to really expect you to do this. But if you ever notice it, you can write it, which is if you see this kind of checkerboard pattern, and they'll vary depending on what particular XOR combination. But the full checkerboard means XOR of all the variables. So here you see a checkerboard. And the answer is A XOR B XOR C. Checkerboard of 0's and 1's. OK, so we can design our full adder. So what I've done is just done the majority function up top with the C out coming out of that. So you've got the A ended with B on top, A ended with C in here, and B ended with C in from this one, or those three AND gates together. We create C out. And then S is just one XOR gate with A, B, and C coming into it. Yeah. Yeah, so for example, if you flip the 0's and 1's, that would be XNOR. So it would be an XOR gate followed by an inverter, for example. You could also have a partial checkerboard where you had 1 1 0 0 0 0 1 1. And that would be an XOR of not all of the variables. And again, you don't have to recognize those. That's why I put the stars up here. If you're interested or you want to be able to pull the XORs out. OK, so I wanted to also, so this was our circuit. I wanted to show you in CMOS what this looks like. So typically in CMOS, we will build the XOR gate. And make that kind of a primitive, just because it takes a handful fewer transistors. So typically, those would be available as gates built out of transistors, kind of like we did the strange gate yesterday. If you want to see how that works, you can go to the tool and build it yourself. I would suggest doing the two input, because the three input is kind of a pain. But the two input's not so bad. And then you can check that you got the right answer. But again, it's not something you need to do. But if you're interested in seeing why you get fewer transistors, you can do that. So all we need to do for the top part, remember that any AND OR circuit, any SOP circuit, we can just replace the ANDs and the OR with NAND gates. And we get the same circuit. So that's all I've done here. So this is the CMOS implementation of the full ladder. Yeah. Yes. What? So OR AND becomes NOR NOR. So remember, yeah, I could pull up this other slide deck. But remember that the first step is to replace this OR gate with DeMorgan equivalent, which is complemented inputs and outputs of an AND gate. So you have an AND gate here with a complement on the output. That's an AND gate. And all the inputs are complemented. You then slide those inverters down to the other AND gates. And those become NAND also. So it's because DeMorgan's law is this OR gate is complemented inputs AND followed by inverter, if that makes sense. And if you look back, I think, to last Friday's lecture that Professor Verdaen gave, those slides will illustrate that for you. Any other questions? Yeah. So again, it just takes a few fewer transistors in CMOS to do an XOR out of transistors. And so typically, because of that savings, people will make the XOR gate available built out of transistors as opposed to built out of NAND NOR. So that's the answer. I didn't want to illustrate that for you. I mean, it's going a little too far into the details of how gates are built. But you can do it in the online tool if you're interested. And again, I would do the two-input version. I myself did not bother with the three-input version. I did do the two-input. It's fine. All right, so we have this one-bit adder that we just designed using what we learned in the last week or two. So then how do we actually build an adder for n bits? So when we add stuff, we add one column at a time. And one of these adders, these full adders, is going to add one column for us. So all we need to do is then hook them together. So we'll feed 0 into the carry input for the least significant bit. The carry out of the most significant bit is the adder's carry out. And then for the other signals, we'll connect C out to C in for adjacent bits. Then we'll take A and B and divide them up. And then feed one bit of each into each of the full adders and collect the bits of S from the full adders. So let me show you that. So here is a chain of n full adders with a dot, dot, dot in the middle, since we don't know what n is. But you can see we're feeding a 0. Is this big enough to see in the back? Can you see this? OK. You're feeding a 0 into the carry in of the first one, the 0-th bit. And then between them, we're taking carry out, feeding it to carry in, all the way down the chain. And then the output here is the carry out. You can see A of n minus 1 and B of n minus 1 going to the bit slice and so forth, all the way down to A sub 0, B sub 0. Those are the least significant bits of A and B. And then down here, S sub 0 comes out, S sub 1, all the way up to S sub n minus 1. So this is the most significant bit on the left, least significant bit on the right. So all we have to do is take n copies of our full adder, wire them together, and now we have an ended adder. So this is a ripple carry adder. Why is it called that? The word ripple is referring to something like a ripple on a pond. So you throw a rock into a pond, and you see these ripples spreading out from where the rock hit the water. And they move kind of slowly. So the carry information is moving kind of slowly between bit slice to bit slice, until finally it gets over here. So the speed of this ripple carry adder is not great. It's a simple design. It's an easy to build design. In practice, we use actually tree adders that are significantly faster than a carry adder for when you get to 32 bits or 64 bits. So we may get to look at that at the end of the class. But for now, it's a perfectly good way to build an adder. You can also think of it as a bit sliced adder, because for each of the bits, we have just the same piece of logic. And we just copy it. You want a 10-bit adder, just make 10 copies. You want a 20-bit adder, 32-bit adder, 100-bit adder. Make the appropriate number of copies, wire them together, and you're done. So fairly simple design. Loop, you mean to speed up the carry? Yeah, so let me move forward a couple of slides. So let me move forward a couple of slides. Let me show you first what an n-bit adder would look like in a circuit diagram. So once you build the n-bit adder, doesn't actually matter how you build it. You can represent it this way. So you've got this sort of funny-looking B thing. Typically, you've got to label it as an adder. The n bits, you see the input with a crosshatch n. That means n bits wide. So n bits of A, n bits of B, they're added together. Sometimes people just put a plus. The sum is n bits wide. The carry in is one bit, no crosshatch. Carry out is one bit also. So there's a shape. You can also then, sorry, illustration of the crosshatching. You can also then hook them together. If you have an n-bit adder and you want a two-n-bit adder, you can simply put them side by side. Again, the implementation doesn't matter. Once you've got the adder implemented, you can put two of them together pretty easily. You can also, as Sasha mentioned, do this virtually in software. So if you take the carry out bit of one physical adder and then somehow manage to put it back as the carry in, so instead of putting the carry in as a zero for the second part, you can add the next higher sets of bits and then continue that as often as you want. So in a typical processor, you might have a 32- or 64-bit adder. But you can use that to add arbitrarily large numbers. So you can write software libraries that will do arbitrarily large or even quasi-infinite arithmetic by simply dynamically using the adder to keep adding the bits until you finish for as much as you need. So usually, in practice, you would use that to check whether there was overflow. And that would go into a carry register. So I mean, at this point, we haven't seen how to store bits or anything. That's another week, week and a half out. So at the end, right now, all we know how to do is build combinational logic. So there's a signal coming out, and we can look at it as humans. But in a real design, you would end up storing that somewhere. And then, for example, software could look at it and see if there was a carry out. Did that answer your question earlier? OK, good. Yeah. OK. AUDIENCE MEMBER 2 Yeah, you're getting the right guy. You're getting the right guy. Yeah. Yeah, so the question is, well, wouldn't it be better if we had a smaller adder and reused it over and over again? It's smaller, but slower. So actually, this trade-off is something we'll spend a fair bit of time on in about a week and a half to two weeks. So we will look at it in detail at the circuit design level. But you can then do the same thing at a broader level. Yeah. Happened if you start with 1 instead of 0. That's a good question. What does happen? So what difference would it make if you put a 1 in? So you would still get a plus b plus 1, right? Well, the answer would be a plus b plus 1. So I mean, if what you want is a plus b, then it's 1 too high. But what if you wanted a plus b plus 1? Then it's the right answer. There's a reason I mentioned that, but I won't tell you why now. The crosshatch, I'm sorry. Yeah, this thing? So this means that there are actually n bits of signal coming in from that wire. So b is actually n bits wide. a is n bits wide. The sum is n bits wide. Yeah. Yeah, so your typical processor will have either 32 or 64-bit adders in it. But they will not be implemented as ripple carry. They'll be implemented as tree-based adders. Yeah, yeah, yeah. So what I showed you is not really the way you build an adder. It's a simple way to build an adder. Not in practice, really, anymore. OK, so now that we have an adder, I want you to think about what we did. So how many of you can add two-digit numbers? OK, come on, raise your hands. I know you can do it. What about five-digit numbers? What about 5,000-digit numbers? Yeah. Does it matter? Does it mean that? It doesn't matter, right? Does it matter if I just say some finite number of digits? You can do it, right? You think you can do it? OK. Yeah, I mean, I can make it arbitrary, right? So I can make it infinite. You wouldn't want to do it, but you can do it. Have you ever seen a proof you're correct? How do you know you can do it? What kind of proof? Proof by induction, maybe? So I think when you learned to add, probably you hadn't seen proof by induction, right? You were probably in elementary school, and probably no one said, let me show you the proof by induction so you don't get worried about digits, right? They probably just said, look, it works. You can tell. You can keep adding digits. It's OK. But if you really wanted to prove it, well, what do you need? You need to know how to some base case, right? So hey, I've memorized an addition table, and I verified it for one-digit numbers, and it works. So I'm good. That's my base case. And I know that if I can add n-digit numbers, then I can show based, for example, in place value that I can do one more column, and then I can add n plus one-digit numbers. And I'll get the right answers. And so you could prove both of those, and then you'd have a proof by induction that, in fact, addition works for arbitrary finite number of digits. Turns out it doesn't work so well for infinite digits, but that's a different story. So when we designed a ripple caryata, we kind of also assumed proof by induction. I didn't prove it to you. I just said, well, we'll just base it on the human approach, and you think the human approach works, so should this thing that we're doing, right? Well, you could prove it by induction. We know how to add a bit. We made a truth table, binary addition table. It's very simple, just four cases or eight cases if you want to do three bits. And we went through that a couple of times. Given that we can build an n-bit adder, we then have to show we can build an n plus one-bit adder by attaching one more full adder, a one-bit adder, to our n-bit adder. So those two steps are also something that I think if I put it on your homework, you would come back having done it and say, OK, great, I've proven that I can do arbitrarily large adder design using ripple carry approach. So in 220, so one reason I want to mention this, one is to get you understanding that for these bit slice design, we're basically just doing proof by induction. So any time you have a problem where you can prove it works by induction, you can do a bit slice design and design a small piece of logic for one or two bits or four bits or whatever, and then put a bunch of copies down, and that'll work. You need to make sure that that's an applicable approach or a useful approach for your problem. But when you can do that, it's a simple approach. The other reason I mention it is in 220, you're going to write software that does what's called recursion. So the recursive functions are going to call themselves. A lot of people end up finding this confusing. So it's the same thing. So you say, well, there's some base case. We call them stopping conditions in software, for which you know the answer. And so you need to have that base case. And then you say, well, given that you can write a function that works for input of size n, you have to prove that you can write a function that works for input of size n plus 1 by handling whatever the extra 1 is and then calling the function recursively for the n. So it's exactly the same thing mathematically, but it tends to confuse people. And I think the reason that it tends to confuse people is there's this assumption in the inductive step. So when you write the inductive step, you say, if you assume that I can do this for n pieces of something, n bits, n's, problem size, and software, whatever n is in your proof by induction, you have to assume that it works. And it's kind of weird when you say, well, I'm trying to design something. Well, just assume it works. But I haven't designed it yet. But you have to assume it works. So I think that throws people sometimes, especially when they get into software, everything's a little more abstract. Sometimes also in the bit-sliced design. The proof works if you assume it works and you show that you can add one more step. You don't have to solve the problem for n. All you have to solve it for is if n works, n plus 1 also works. Yeah. Yeah. No? How would you actually apply this for the ripple carry adder? So I mean, you would have to do, I think, the actual proof would be based on something like place value. So you'd talk about the value of an n-bit number. And then you would say, well, n-bit numbers have this range. And I know that the addition works. That's the assumption, is that I can add any n-bit numbers and get the right answer. Then I can say, well, if I put one more bit on front of my two numbers, can I prove that given this worked, that I get the right answer with a full adder? And that's the thing. You have to assume that n works. You don't have to make n work. You just have to assume it works. And then if you do the inductive step, it will work. Everything will work. So that's sort of this strange leap of faith you have to make that your answer works before you actually design it. So you have to sort of mentally get comfortable with that in order to finish your design. Because if you can't get yourself started, well, of course it doesn't work. If you don't design it, it doesn't work. But you do have to, as part of your design, assume that it will work for a smaller number of bits. And of course, don't forget the base case. If you leave the base case out, it's not going to work. All right, so I wanted to just mention that, because you will do some bit slice designs, and you will do recursive software designs in 220. So remember this. So what is bit slicing? So bit slicing is a hardware approach that is basically like induction. So it means we're going to break off a small part of the problem, say one bit, like we did for the adder, one bit of each input, or a few bits is fine. And then we're going to solve the whole problem by using the solution for the remaining part. So we'll take one little piece and solve it, and then use the solution for the remaining part. And that's essentially a proof by induction. So if you can prove that given only a small part of the input along with the answer for the rest, but you can get the full answer, then you're done. So in hardware, there's a little bit of a complication in the sense that we need to be able to express that answer for the rest concisely. So if we can't express it in a small fixed number of bits, then the number of wires we need from bit slice to bit slice will grow. And if the answer somehow takes n over 2 bits, well, then we can't design one piece of logic, because as we add more bit slices, n over 2 gets bigger. So sometimes we might be able to do it logically, because we just know the answer. We might be able to do it mathematically. But in a hardware design, we need to be able to do it by expressing the answer using a small number of bits. In the adder, it's just the carry bit. The only thing you need to know about the solution for less bits is the carry. And that will give you enough information to calculate your sum. So what kind of problems can we do? Addition, subtraction, comparison, we'll do next. Check for a power of 2, check for multiples, do pattern matching in inputs, bitwise logic operation. So a bunch of different things we can use this kind of approach. There's probably more, but these are the ones I could think of and that I've worked on before. When can't we use it? So any time the answer depends on all of the other bits. So for example, if I say, oh, do a prime number recognizer. Well, nothing you can tell me about these last five, well, at least I don't know how to do it. Nothing I can tell me about these last five bits will tell me whether with some extra bits on the front, this is a prime number. And you need to be able to do that. You need to be able to say, well, given the other bits, is my number a prime number looking at only one bit? If you wanted to do a bit slice design for a prime number checker, for example. So that's an example of where I don't think you can use a bit slice design. So what do you want to generate? So I mean, if you're just adding two numbers, you can use an adder, right? And then get the next one out. Yeah, so that would be fine for bit slicing. I mean, you can use an adder to generate that as long as you're doing the feedback logic to get back the two in the sequence and generating the next one in the sequence. Yeah. Anything else? Yeah. So remember that when we designed two's complement, we designed it deliberately to use addition mod 2 to the n, which was what we got out of unsigned. So the adder and subtractor are basically identical for two's complement and unsigned. And in fact, in order to do the subtractor, and this comes back to what we were talking about with a carry-in of 1, if you think about, well, is there a way I could trick my adder into doing subtraction? I think you've already done it by hand. A lot of you have done it by hand. But think about how you can use your adder to do subtraction. Yes, negate it. But you don't have to add 1. You can put a 1 on the carry-in. Yeah. Anything else? Might be the end. Where am I? No, I still have more slides. Killed my PowerPoint. Sorry. Oh, darn it. Oh, darn it. Oh. OK. Maybe we'll talk about the comparator today. All right. So let's spend a few minutes getting started on a comparator. And then we'll finish this up Monday. So next thing we'll do is compare two unsigned numbers. Now, here it's going to make a difference. And we'll figure out how later, whether it's unsigned or choose complement. But for now, let's just start with unsigned. So which one's bigger, top one or bottom one? Top. Top. How'd you know? Ah, OK. So you started which side? You started on the left. OK, so humans go that way. Why? Yeah, so once you get to, say, 0, 0, say that's the same, one line. Ah, so you can just stop. You don't even need to look. You're done. Yeah, so when we build hardware, they can't just stop. I mean, you've got wires. The wires don't just say, hey, I'm going to turn now because I know the answer. So they can't just stop in the middle. The information is going to flow from one end to the other. And the output wires on the end are going to give us the answer. So it doesn't actually matter for the hardware design if we go the human way or we're going to go the other way. So in our design, we're going to go the other way. It doesn't matter which way we go because we're going to have to go through all the bits in the hardware. We can't stop early, at least not in this kind of design. Once we talk about sequential state and things like that, you'll see there are ways for bigger designs to stop early in some cases, but not in wires. So we're going to design from right to left. We'll look at the least significant bit first. So how many answers are there? So there are three, three possible answers. So if we have numbers a and b, we've got three outcomes. We can say a is less than b, a is equal to b, or a is greater than b. So in order to decide the answer for n plus 1 bits, what do I need to know? Well, I need to know what's the answer for n bits. And then I need to know one bit of a and one bit of b. So here's an example where we can use bit slice. Because if you tell me for one fewer bit, for the less significant bits, which of those sets of bits is bigger and which is smaller, and then you tell me one bit of a and b, then I can tell you with that extra bit which one is bigger, or are they equal. Everyone agree with that? So we should be able to build a bit slice design. So what do we need to do? So how many bits do I need to pass from slice to slice? Yeah, right, because there are three possible messages. You need to know a greater than b, a equal to b, or a less than b. I can't condense that into two answers. Because if your bits are equal, well, then you need to know what the answer used to be because it's the same. So if your a and b for one bit are 0, 0, for example, then the answer depends on the lower bits. And you need to pass along any of those three answers. And how many bits do we need to encode three answers? Two, right? So you need two bits. So here's a figure showing an abstract slice model of our bit slice. So we're going to have two bits coming in from a less significant bit. We'll call them c1 and c0 m minus 1 bits. This will be the mth bit slice. So they'll get a sub m and b sub m for the numbers a and b. And then they'll produce outputs c1 m and c0 m, which internally, just to differentiate these two, we're going to call z1 and z0. So the inputs of what's happening from the less significant bits, we'll call c1 and c0 internally. And then we'll produce z1 and z0 to tell the next bit or to give the final answer, well, is a less than, equal, or greater than b. Well, so if the only thing we need to know is a less than, equal, or greater, we don't need n bits of output for anything, right? We just need one of those three answers. So in this case, yeah, it's a good question. In general, for something, your bit slice design may or may need some kind of outputs at the bottom. For a comparator, you don't need anything. For an adder, you need one bit for the sum. If, for example, as we sometimes do on homework or as we might sometimes do on even exams, we can say, well, out of the bottom, we want you to produce the minimum or maximum of a and b. So if we say minimum only, then you need one output wire. If we say minimum and maximum, you need two separate output wires. Ah, very good question. Good question. I thought of that, too. How do we represent the answers? Got three answers, right? a less than b, a equal to b, a greater than b. They're a natural representation? They're not, right? It's just three answers. Pick any representation we want. So our choice will affect the amount of logic we need. So here is a pretty good choice. Actually, after I designed the one, this is from the notes. After I designed this, I realized, well, I probably should have thought of this beforehand. But I went back and considered all the different choices I could have made and made sure I wasn't somehow doing something that was bigger than it should have been. So there's a pretty good representation. If you're doing the extra C exercises, the optional ones, you'll get to design your own with your own representation and your own direction in software. But software is not so bad, because even if your logic is a little bigger, it's a few extra characters of typing, as opposed to working out lots of area and things like that. But here's a pretty good representation. So we just say, well, OK, the a equals b, we'll call 0, 0. a less than b, we'll call 0, 1. a greater than b, we'll call 1, 0. And then the last pattern, we've only got three messages. So we're not going to use it. So you have actually a fair number of choices. You have these three messages, and you have four different bit patterns. So how you assign them is completely up to you. Yeah, exactly. So as Mohamed points out, now that I've said not used here, I can assume safely this is not a human. They're not going to go pushing lots of buttons or anything like that. The lower bit slice will never generate this pattern. So I can put don't cares whenever I see 1, 1 coming in from the lower bit slice. Good point. OK, so let's see. I'm not sure we'll get through this one. Let's see if we can do one bit. So let's solve one bit. So in this case, there are no less significant bits. So let's just think about A and B. So if A and B are the same, then what's the answer? You already know the, you already know the. All right, fine, I'll just skip ahead. You know the representation. So the meaning, though, are A equals B for 0, 0 and 1, 1. And then if 0 and 1 for A, B, then A is less than B. And 1, 0 is A greater than B, because these are unsigned. So the encoding is 0, 0. What about the 0, what about this row? 0, 1, good. What about the next one? 1, 0. And the last one? 0, 0, good. So this is one bit. So then we can go solve that. I want you to notice that these are minterms. So if you look at Z1, this is a minterm, just a 1 in one row. Z0 is also a minterm. So if I draw a circuit for that, all I need to do is generate a minterm. I don't need to go do k-maps or stuff like that. This structure is going to be kind of the core of our comparator logic. So here we're generating A0B for Z1 and A0, I'm sorry, AB prime, you said that way, and A prime B for Z0. If all you wanted to do was compare A and B and say equal or not equal, you could OR these two together. That would be an XOR. And so these are the two minterms that you need for XOR. And if you XOR A and B, or one bit of A and B, that'll say equal if the XOR gives you a 0, and not equal if the XOR gives you a 1. So if you OR these two outputs together, it's just like an XOR. But this will be the thing that lets us know is A greater than B or A less than B on a one-bit basis in the full design. So let me stop there, and I'll finish it up on Monday. Have a good weekend. Yeah, let's just, yeah. Oh my god. OK. OK. OK. OK. OK. OK. OK. OK. OK. OK.\",\n",
       " \"So we're going to pick up where we left off, talking about expressions and operators in C, talk about basic IOs, so printf, scanf, and then talk about statements. Hopefully, you had a chance to take a look at the email that I sent out, I think it was yesterday. So we have an online automatic feedback tool for programming. And what we're hoping is people will play with it. It's used in 220, so if you get familiar with it, it'll help you in 220 also. But it's basically a computer tool that will help you find the bugs in your code. So I can tell you more about it if you're interested in office hours. But we have an undergrad who's doing his thesis, creating exercises for 120. And so those are available to you. Has nothing whatsoever to do with your grade. If you don't want to do it, don't do it. Signing up doesn't commit you to anything. So if you think you might want to play with it, sign up. We encourage you to do it because it's supposed to help you. But if you don't want to, that's OK too. But I do encourage you to try. All right, so let's see. Daniel was somewhere here usually. There you are. You asked this question about Unicode in C identifiers. So I went and looked it up. Apparently, it's been in the standard since 1999, but compilers still aren't really quite well supported. So if you use these flags in the lab, standard C99 and F extended identifiers, you can use this type of code. So this one everyone understands. How many Spanish speakers are there? OK, do you know this word? Manana, yes, I think I guess. And how about Chinese speakers? Anyone speak Mandarin? OK, can you read this identifier? Yeah, it's ming tian. So not exactly what you might want. So if you want to use it to change regular text like the commented versions into universal character notation, which are the things you can compile, there are tools that can do that. There's some instructions on this web page using Perl. But in 120 assignments, use ASCII. Please don't put UCNs. All right, so do a little bit of a review before we dive in since it's been five days since we talked. So we're going to cover four types of operators in our class. Arithmetic operators, which we already finished, bitwise Boolean operators, relational comparison operators, and the assignment operator. We're also going to take a look at logical operators briefly. A couple of the online exercises that use them. So if you want to do all of the online exercises, you'll need to remember what they mean. But you shouldn't need to use them otherwise in the class. So these are the bitwise operators, bitwise and, or, not, xor, and then the shifts we hadn't talked about yet. So let's go ahead and I wanted to put actually one slide with and to show you these things written out in bits. So we did the and last time, but it's maybe easier if you translate the hex into bits, or maybe harder since you have to write 32 bits down. But essentially all the bitwise and is doing is going one at a time through each of the pairs of bits, taking the and bitwise for each pair, and producing that and, and then that's the answer. So if you expand 120 in bits, that's the top line. 42 in bits is the second line here. If you and those together, you get the bottom line, which evaluates to 40 or 28 hex. So that's what it's doing for you. All right, so left shift. Left shift is basically shifting all of your bits to the left. So what does that mean? It's like multiplying by 2 to the n. So if you shift by n bits, it's like multiplying by 2 to the n. So for example, if you declare a equals 120, and b equals this hex number, and you shift left by 2 for a, then let's see, that would be 2 to the 2 is 4, so you should get 480. And in fact, you get 480. So with this pattern b, if we shift by 4, that will shift 4 bits to the left, so we'll get four 0's on the right side. And then the f on the left will fall off. So the shift will overflow. So it turns out we get kind of what we'd expect. Instead of 6 f's, we have 5 f's. There's an extra 0 on the right. And we've lost the high bits by shifting them off to the left, because we can only have 32 bits in the answer. That number is actually smaller than the original b value. And so that's an overflow. It's not multiplied by 16, as you'd like it to be. So shifts can overflow. Shifts by 32, by the way, are not defined in C, so be careful how you shift things. I forgot to mention that, but it shouldn't come up. So what bits appear on the left when you're shifting right? So shifting right just means take your bits, move them down towards the small end. But what bits should I put in the high part? 0's? Yeah, so in this case, I want to get divide by 2 to the 2, or 4. So I should put 0's in. That'll give me 30 in 2's complement. What if I want to shift this bit pattern 4 to the right? Should I put 1's or 0's on the left? You sure? So which one is it equal to? Is that negative 256, or is it this big number here? I didn't tell you the type, right? I just wrote some bits. So it depends on the type. Well, it's bits. I didn't tell you the type, right? I can make that an unsigned or a 2's complement. So if it's a 2's complement number, it represents negative 256, in which case, if we wanted to divide, we'd like it to divide by 16 and get negative 16. We'd insert 1's for that. If it equals this big 4 billion number, divide by 16, you've got 268 million some odd left. We should insert 0's. So how does the compiler decide what looks at the type? So if this were not just a bit pattern, but were a type, and yeah, it's true. If you type that bit pattern in, the compiler will assume 2's complement. But if you put it in a variable, the compiler will use the type of the variable. So if you have a 2's complement representation, it will do what's called an arithmetic right shift, which means copy the signed bits. If you have an unsigned int, unsigned representation, it will insert 0's when you do a right shift. Yeah, question? AUDIENCE 2. Yes, int is 2's complement. Yeah, if you want unsigned, say unsigned int, as I've written down here. I'm going to do the unsigned int. OK, so right shift then will use the type and end up dividing by 2 to the n. Now, of course, that can overflow or underflow too. It's always going to round down. So if I take a up here, negative 120, and I right shift that by 2, divide by 4, I should get what? Negative 120 over 4? You get negative 30, right? So you can see it's put some extra 1's in up at the top. And if you look at the bit pattern, you'll see that it's basically just shifted it by 2. What if I shifted by 10? It's like dividing by 1,024. So I'll be getting, it's a 2's complement number, and it's a negative 1. So I'll be getting 1's in at the left. So what am I going to end up with? Negative 1, right? So it'll be all 1 bits, which is negative 1. So you can think of that as divide by 1,024. That gives you negative 120 over 1,024. Round that down. That gives you negative 1. So I didn't wait for you to tell me. OK, if I shift this bit pattern 2 to the right, I put 0's in at the left because it's unsigned for b. And I get this bit pattern here, where I've just taken the bits and shifted them 2 to the right. If I shift 10 to the right, I get more 0's on the front. So it's just moving bits left or right in the bit pattern. Yeah, Eric? AUDIENCE 2 When you're getting those, you're looking at the dust, and it's not supposed to be. They're just binary form. Yeah. Yeah, so to know why these are the right answers, you will have to mentally translate from hex to binary, and then do the shift, and then translate back from binary to hex. Yeah, yeah. So I don't expect you to be able to do this in your head. The reason I put the decimal values up here is to make sure you understand it is dividing by 2 to the n. Had I written these as decimal, it would also make sense, except that would be a huge number. So at least I wouldn't be able to do it in my head. Good question. OK. Usually with shifts, we're thinking about bits. We're using our numbers to represent bits. You can use it for multiplication. It's slightly different than right shift. It's slightly different from division, because most division will round towards 0, and right shift will round down. Yeah, question? Yeah. Yeah, that's right. It doesn't matter. So if you think about the representations, it never matters. To multiply by 2, whether you have a positive or negative number for a 2's complement, you put a 0 on the right side. And the same for unsigned. I mean, there's no negative unsigned. OK, so that's it for the shifts. We also have six relational operators. So less than, lesser equal to, equal to, not equal to, greater equal to, greater than. You can't put spaces in these. One thing that's a little strange in C, in order to do a comparison for equality, you have to put two equal signs. So you'll see later, one equal sign means something different. It means the assignment operator in particular. So you need to not put spaces in these, and remember that to compare for equality, you need two equal signs. In C, anything that's 0, 0 bit pattern is false. Anything that is not 0 bit pattern, anything else is true. The relation operators evaluate to 0 if they're false, and 1 if they're true. But in C, anything that's not 0 is considered true. That'll come into play when we look at logical operators. So if I make these declarations, so I make two integers, a negative 120, b 256, and I say, well, is a less than b? So clearly, if I define them this way, yeah, of course, negative 120 is less than 256. But if you were to then put the same bit patterns in using an unsigned representation, then they would look like this in hex. You'd say, well, of course, this one on the left is much bigger than that one on the right. So if I compare less, it should be false. So again, like shifts, a C compiler will take the type that you declare of the variable, and it will use that to make the decision. So even though the bit patterns might be the same, the outcome might be different for a relational operator, depending on whether the type is two's complements or unsigned. OK. OK. So that's it for relational operators. The last operator is the assignment operator. So you can change variable values with the assignment operator. So for example, you could say, well, a equals 42. That's an expression. What that expression does is it takes the bit pattern for 42, and it overwrites whatever bits are currently in the variable a with the bit pattern for 42. So you can write any expression you want on the right-hand side. You could, for example, write a plus 1 on the right-hand side. That'll take the current bit pattern of a, add 1 to it, and write that new bit pattern, the sum, back into a. So it'll increment a by 1. So any expression you want on the right side is fine. On the left side, not so much. The C compiler cannot solve equations for you. So if you say, well, a plus b should be 42. Go figure it out. The compiler will say, I don't know how to figure anything out. I'm a computer. It'll actually say that much more cryptically. But that's what it's really trying to tell you, is I have no idea what you want. Am I supposed to change a, change b? So you can't write things like this in C. So you get a compilation error. So for our purposes in EC120, the left-hand side of the assignment should always be a variable. So just take a variable, put it on the left, right-hand side, any expression you want, including the current value of the variable, like a equals a plus 1 is OK. All right. One pitfall with this, because it looks like algebraic equals, people often accidentally, when they want to do equality comparison, they write 1 equals sign instead of 2. So if you do that by accident, so let's say that you want to compare a to 42, you're supposed to say a equals equals 42 to do that comparison. But let's say you make that mistake and you say a equals 42. Sometimes the compiler can figure out, you probably didn't mean to do that and give you a warning. In which case, go fix it. But it's probably better to get in the habit of not writing your comparisons that way. So if, for example, you write your comparisons with 42 on the left, and you say 42 equals equals a, it's the same comparison. But if you make a mistake, you'll get 42 equals a. The compiler will say, I can't do that assignment. That will always happen. So if you put the expression for an equality comparison on the left, the compiler will always tell you there's a mistake. And you can always fix it. So it's just a good habit. I started doing it relatively recently. But I'd suggest you get in this habit, too. I will try to make all my examples follow this rule. All right, then the last operators I want to show you, and again, you can tell by the stars, it's not something critical to our class. You will use it in 220. There's actually some subtleties we won't talk about here that you'll also learn in 220. So logical operators, so and, or, and not. They're different from bitwise. And I'll explain that in a minute. But they just operate on truth values. So remember, 0 is false. Anything else is true. So the logical operators will look at their arguments. And they'll say, well, is it 0 or not 0? If it's 0, that means it's false. If it's not 0, that means it's true. And they'll return, they evaluate again, either to 0 for false or 1 for true. So for example, if I declare a couple of variables, a and b, 120 and 42, then I can write these logical operators. So 0 is greater than a, or 100 is less than a. True or false? So is 0 greater than a? So 0 is not greater than a, right? a is 120. Is 100 less than a? Yes. So if I or those two together, I get a true, right? OK, good. And what about the next one? So is 120 equal to a? Yes. So does it matter what the other one is? It does, right? It's an and. Good. And is 3 equal to b? No. So what's the answer? Good. So what about this one? Here, it says compare a to b, and then complement the answer, the 1, because a is not equal to b. All right, so is 0 less than a? Yes, is 0 less than b? So is that and true? And then a complement it, so what should I get? 0, good. And then the last one is b plus 78 equal to a? I think so. OK, good. Good. You know how those work. So here's a task for you. Here's a C expression. Think about what the answer is. You ready? It's a tough one, I know. Did you get 7? You didn't get 7? I hope you get 7. So I'm pretty sure everywhere I've talked to people from everywhere around the world, the rule for precedence on multiplication and addition is the same. So hopefully it's the same everywhere. But usually we're told, OK, you do your multiplications, then you do your additions. So this one is relatively clear. It should be, hopefully. If it's not, you can add parentheses and C code too. That'll be fine. So the order of operations is called precedence. Which one comes first is called precedence. So here's another one. Excuse me. Sorry about that. Here's another one for you. You're 1.67? Is it someone's birthday? OK. Maybe it's a divide by 0 error. So if you do the 2 over 3, you get a 0. 10 over 0 is divide by 0. Maybe it's 1. You do the left one first. If you can't tell, and honestly I don't think there's any way, I don't think anyone's ever written this in elementary school or high school or college. No one writes that kind of expression. Don't look it up. Add parentheses. It won't even tell you how to look it up. Seriously, never look it up. You could, but then your code, no one else will understand it either, right? Because they won't know the order either. So if you don't know the order, put parentheses. That way your code is readable. Never go look up precedence orders. If it's not obvious, and I think probably the only one that hopefully is common enough is this multiplication versus addition. Maybe that one is not even obvious. OK, any questions on operators or expressions before we shift gears a little bit and talk about I O? All right, so we're going to look at input and output. Input's going to come from the keyboard. Output's going to go to the monitor, which means basically a terminal, like you've been using in the lab. And so you can send ASCII text out. You can read ASCII text in. Those are the basic I O operations. Later, not in our class, but later you'll learn how to manage graphics and things like that. So to control input and output, we use two functions. When you want to use those functions, you have to put this line at the top of your C program that says, well, I want to use the standard I O functions. So just put that line there. If you want to understand it, there's some starred section in the notes that'll talk a little bit about the preprocessor, but you don't really need to understand it at this point. You'll have plenty of time to play with it in your time here. So this directive tells the C compiler basically, hey, I want to use these standard I O functions, which I'll tell you about shortly. So to write text onto the display, we'll use a function called printf. So the f stands for formatted. So the first thing you have to put is your desired format inside quotation marks. So for example, you've got this function call down here. It says printf, parentheses, close parentheses over here, semicolon. Here is an example inside quotes. What that does is it sends the string or the characters between the quotation marks to the monitor. So it'll print out here is an example. It will not print the quotation marks. If you want special characters, so for example, if you want a line feed, you need to tell, well, it's not easy to put those between quotes because then your code looks funny. And so you need to mark those special characters with this escape character, the backslash. So for example, the line feed. If you want the output to start on a new line, you need to print an ASCII line feed character. In order to do that, inside the quotes, you put this backslash n. And that will tell printf that you want to print an ASCII line feed. So if you want a backslash, well, you have to put two backslashes. Two backslashes will become one. The first backslash says, OK, there's some special ASCII character coming. And then if you put another backslash, that's one backslash printed out. But backslash n will give you a line feed. You can put as many line feeds as you want in your format string. So for example, if I print this format string up here, the output will appear here. I've also stuck a backslash in just to illustrate it. So it comes out on three lines. And it actually has a backslash n at the end. So if you do another printf, that will start on a fourth line. Now, what if you want to actually print some variable values or some expressions? So for that, we use what are called format specifiers. So here, I've included three of them in my format string between the quotes. They're all %d in this example. So all of the format specifiers will start with a percent sign. The d stands for decimal. So it will print an integer, a two's complement number, in decimal for you. So here, I've just written some expressions separated by commas after the format between quotes. And so each of those expressions will be evaluated. So 6 times 7, of course, is 42. That will then be matched up with the first format specifier here. And it will be printed as decimal number 42. Second, %d will match the next expression in the comma-separated list. So 200 plus 17 prints as 217. And then the last one here will match this expression, 32 bitwise anded with 100. And so that will end up being 32. And so what it'll print out is this line down here. And at the end, you can see there's a line feed. All right, so what are the other format specifiers you can use? So if you want to print an ASCII character, you've got %c. The %d is what you just saw. Take an integer, two's complement number, print it as decimal. So ASCII decimal representation of the number will go out to the display. If you want a double, print it as scientific notation. You can print it as a decimal. And then the last one is %d. So you can print it as a decimal. Print it as scientific notation. You use %e. If you want to print it as decimal, use %f. If you want a percent sign, %%. These are all, by the way, in the notes. So I'm going kind of rapidly through the format specifiers. So that's a bitwise and. So if you think about what are the bits in 100, you've got the 64's place, the 32's place, and the 4's place. So this one is a power of 2. So this is just the 32's place. So if you write them as binary and you line them up, there's one bit, which is the 32's place, that's on in both numbers. So the and takes that bit and turns it into 1. Everything else is zeroed out. So the answer is 32. I know that would be a logical. So 1& is bitwise. 2& is logical. So if you were to put a logical operator here, 32 is not 0. So it's true. 100 is not 0, so it's true. True and true would be true, so you get a 1. But bitwise will give you bitwise and. So those are different operators. Good question. That's right. So if you do not include percent d's, some compilers will give you a warning. But the compiler will not prevent you from compiling your code. It'll just warn you that you've got extra expressions. Those expressions will be ignored. I'll mention that a little later. If you were to evaluate these expressions and put the answers in quotes, then yes, whatever string you, whatever material you put there is going to be printed. But if you want the compiler to evaluate expressions, here you could do it in your head in advance and simply write the numbers. But imagine these were the values of variables. Then you can use variables in those expressions, which you won't be able to calculate in advance. Yeah. AUDIENCE MEMBER 2 You don't count h? You're wrong, I think, on both counts. So let me go forward. So x is for hex. I don't think h will do hex. And I'm almost positive that b will not do binary. Printf implementations differ. So I'm not, for example, sure what the Visual Studio printf will do versus GCC. These are all standard. And pretty much any system you use will implement these. But there will be extra ones available on different systems. So as far as I know, there is no binary. You have to write that yourself. At least no standard binary printout. There are standard hex printouts, which are x and uppercase X. Sorry, if you want something printed as unsigned, you can use %u. And then if you want to see more, look at the man pages on a lab machine. And that'll give you the full definition for printf on the lab machine. Any other questions? So let's take a look at a couple of issues. So one pitfall, if you want any spacing, you have to include it in your format. So if you print %d%d%d, and then these three expressions, they just happen to be numbers this time, what will print is shown down here. There's no spaces. You didn't tell it to print spaces. It didn't print spaces. So your numbers are all jammed together. If you want spaces, you have to include them in the format string. So be careful about that. Anything that isn't a special ASCII character or a format specifier will print exactly as it appears between the quotation marks. So whatever you want, you can put there, and it'll just come out as part of your output. But you can put a dash in your format string. That's fine. You mean backslash? Yeah. OK, so backslash is two backslashes. So you can see up here, we have two backslashes between text and has. And when it prints, it comes out as one. So if you want a backslash, it's two backslashes. If you want a percent sign, put two percent signs. Out will come one. Sense? That's right. That's right. So if you write %%f, that will print as %f. It will not be interpreted as a format specifier. Yes, so if you don't end your format with a %end, then the next time you print something, it will come on the same line immediately after it was printed by the first printout. And that's useful sometimes. So you'll see a lot of programs in our class where you print a prompt. Please enter some numbers. So if you don't want the numbers that they typed to appear on the next line, you don't put the backslash n. And then it will appear on the same line when they type it. So it's a useful thing to be able to do. Yes, float is a single precision. Yeah, so I didn't mention it here. Actually, when you use a floating point expression in a printout, the compiler will implicitly convert it to double. And then the printout will treat it as a double. You don't really need to worry about it too much. It'll be automatically done transparently for you. And that conversion, there aren't too many ways it can confuse you, so I didn't mention it. But yeah, observation. When we see scanf, you have to explicitly tell it whether you want float or double, because there it matters. All right. So that's one pitfall. Another pitfall is passing the wrong kind of expression. So here, what I've done is I've said in my format, well, I want to print an integer and a floating point number. And then I passed a double and an integer. So I passed them in the wrong order. Now, the output is actually system dependent. But it's generally not going to be what you want. So my laptop, I think it was printed both as zeros. And clearly, that's not what whoever wrote this code wanted. Compiler may be able to warn you, but be careful about it, because sometimes it won't. If you pass too few or many expressions, if you pass too many, again, compiler may be able to warn you, it's not so bad, because it'll just ignore them. And then if you look at what's printed, you'll say, well, where'd my expressions go? And then you'll realize you didn't have enough format specifiers. If you pass too few, it will print bits. It will go find whatever should have been there to print. And it will take them. They will be bits. And it will convert them. So the behavior is unspecified. May be able to warn you, may not be able to warn you. So again, be careful. So that's it for printf. When we want to read input, we're going to use a function called scanf. So this will let you type things into the keyboard. The way it works is it won't actually read anything until you push the Enter key. So you can type as much as you want. You push Backspace. And then eventually, push the Enter key. And then scanf will get some things to look at. The f, again, stands for formatted. scanf also takes a format in quotation marks and a comma-separated list, this time of variable addresses. So you can put as many variables as you want separated by commas. All of them you need to put this ampersand in front of the variable name. So this operator, we're not going to talk about other than to tell you to use it in scanf. What it means is here's the address of the variable. That's where scanf has to put the bits that it gets by converting whatever you type into, say, a choose-complement number. So it has to put those bits somewhere in memory. The address of A is the memory location where it stores those bits. Yes, you need to put ampersand in front of every variable name. So if you had two or three of them, you would put ampersand A, ampersand B, ampersand C, separated by commas. Yes. So the %d means decimal interpreted as choose-complement. So you type in some decimal number in ASCII, and it translates it to choose-complement and stores it in whatever address you've given it here, which here is the address of the variable A. So A will now equal whatever number you typed in decimal. There is no scan function, so it'll simply give you a compiler error. Yeah, scanf is. There are other functions, but scan is not one of them. So you need to use printf. scanf reads from the, yeah. So you would first call printf, and that would give the prompt. And then you would call scanf, and that would allow the computer to read from the keyboard. Yes. Yeah, good question. So what happens if the human does something wrong? So let me come back to that, because I have a slide on what the return values are. So when you make a function call, it's like an expression that evaluates to something. So I'll tell you what they evaluate to when you call printf and scanf. Good question. All right. So scanf is going to ignore the whitespace that you type. So for example, if I ask for two integers here, A and B, and the user could type 5 space 42, and that would be fine. And A would become 5, and B would be 42. Or they could type 5, Enter, 42, Enter, and the same thing would happen. So scanf will ignore extra spaces, extra tabs, and so forth and so on. If you put other characters in your format string, the user has to type them exactly. So this is rarely useful. I mean, maybe if you want them to enter a time and you want to insist that they type a colon, maybe that's OK. But if you put something like this, where I've put these brackets in here, then the user actually has to type those brackets exactly like this. So they can put some spaces. Actually, if they put a space using this format, scanf will ignore those characters, because the space does not match that less than sign. And so then B will be unchanged. So it actually will not process the input as you would like. So it's rarely useful to put extra characters in. So this is a list of conversions. They're very similar to printf. The difference is that if you want to convert to a float, you use %f. If you want to convert to a double, you use %lf for long float. So that's the major difference here. You can use unsigned. You can use hex. Yeah, Rahul? AUDIENCE MEMBER 2. Ld is a long int. Yes, ld is a long int. And lld is long, long int. You mean if you did not put the ampersand on? Yes, then it would take the value of a as the memory address, which means it will write to some random memory address, which is kind of outside the scope of our class. But writing bits to random memory addresses, you can tell is probably not a good thing. Yeah. That's right. That's right. Yes. So for every format specifier you put in your format, you want to have one expression in the comma-separated list of expressions. Just like on the printf, when you told it you wanted to print an expression, you have to give exactly the same number as you have in your format. Now, these are simply variable names. I just decided to make them capitals because I thought it was easier to see on the slides. They can be any variable name. Yes. They have to put a space anyway to separate numbers. But putting a space between the format specifiers makes it actually a little more flexible. So it's probably a good habit to put spaces between your format specifiers in scanf. The resulting input will be a little more flexible. But for example, you can't type 542 with no spaces and expect the computer to understand that you meant 5 and 42 as opposed to 54 and 2, or 542 and I'll type something else later. So you do have to separate them with spaces already, even if there were no spaces in the format. Yeah. No. And so that's one case where you might want to put that literally in the string, that if you want them to type 0x or to be able to type 0x, you'd have to have that explicitly in your format. This will simply take the ASCII characters and treat them as hexadecimal if you put percent in. So it's %s for a string, but that's outside the scope of our class because you need to understand pointers and memory. And so you'll learn that in 220. Actually, you'll learn about it at the end of our class, but you'll learn about it in C in 220. So yeah. All right, so let's see. Same pitfalls as printf, match format specifiers and ordering to variable types, match number of specifiers to the number of addresses, and don't forget to write the ampersand. Because otherwise what will happen is, as Daniel said, it will interpret your variable value as an address, and then it'll write to some random memory location, which is not a good thing. So what do these things return? So this is what Sasha had asked about earlier. So when you call printf, it returns the number of characters printed. So whatever output it translates to, it will count the number of ASCII characters it sends to the display, and it will return that number of characters for you. So it'll tell you how many characters are printed. It has uses, but probably not so much with this particular call. So rarely will you see someone actually using it in code. With scanf, on the other hand, you should always check the return value. So scanf returns the number of conversions that were made. So for example, if you ask for two things and the user says hello, you ask for two integers, the user says hello, it can't figure out how to convert hello to a two's complement number. And so scanf will fail, and it will return minus one. If you type something like 42 space hello, it will convert the 42, and then again, it will fail trying to convert hello to the second number. And in that case, having converted one number, it will return the value one. So if you want to check that the user typed the right thing, you can simply compare, and we haven't talked about this if statement yet, but this is something we'll talk about hopefully before the end of the day. If scanf does not evaluate to the number two, so if two is not the answer returned by scanf, then something went wrong. So scanf should return the number of format specifiers that you asked for. If it returns something else, the human did something wrong. There are more graceful ways to help the human fix that, but the easy way for our purposes for 120 is to say, well, if they do something wrong, end the program. Tell them to run it again. So most of the code you'll see will be this simple in terms of how we handle errors. Does that answer your question? All right. OK, so I want to try to cover statements, and then on Friday, we'll look at code examples. So I'll mention I do have handouts. Feel free to take one if you want to look at the code in advance. It's on the links page, too, if you'd rather look at it just online. I do want you to have a handout in class on Friday. So if you take one, please bring it back so that we have enough. I think there should be enough, as long as people aren't taking two or three or something. And it is online, too. And the codes are online if you want to compile them, so you can play with them as much as you want. So remember, I said last week, a statement tells a computer what to do. So let's look at the kinds of statements. We've got three kinds in C. So a statement can actually consist of other statements, which can consist of other statements. So a big C program will have many very deep, recursively nested statements. But for the little ones we'll look at, they'll be fairly simple. So the three types of statements, you have what's called a null statement, which does nothing. So it's just a semicolon all by itself. A simple statement, I'll show you some more kinds in a few slides. But one kind is just use an expression, follow it with a semicolon. So for example, A equals B. It's an expression. But I want to do an assignment, put a semicolon after it that says, OK, my statement is done. Go do the assignment for me. Printf, it's a function call. It's also an expression. So expression followed by a semicolon makes a statement, simple statement. You need to have a semicolon. I think someone asked on last week, what if I leave the semicolon out, the compiler will complain. Compiler will say, I can't compile this for you. All right, and the third type of statement is a compound statement. And this is a sequence of statements. So you might think, oh, that looks a lot like my main function. In fact, it is. The body of main is simply a compound statement. So you have a list of statements, a sequence of statements that execute in order. So you can put whatever you want. So here I said, OK, radius will be 42. My variable c, which is maybe circumference, I'll calculate as the 2 times pi times the radius. And then I'll print that out. Inside a compound statement, you can actually have additional variable declarations. If you want to, you'd put those above the statements. So you can have variable declarations at the start and then statements inside. But we won't use that often in our class. So didn't want to put too much detail. So how do these execute? So there are three things to think about. One is a sequential execution. So the function body of main is a compound statement. And they execute in order. So if you have three statements, the first one executes first in the order of appearance in the file. The second one executes second. And the third one executes third. And when the program is started, all the program does is execute the statements in main in order, in the order they appear. And then the program is done. So here's another one. You actually saw this one already. But I want to make sure you understand it. So you can also introduce what's called conditional execution. So this illustration is a flow chart. The way it works is you're going to execute the statement. The first thing you do is you evaluate an expression. So there's some expression you evaluate. And that will either be true or false. Remember, true is anything that isn't 0. False is 0. If it's true, you'll have what's called a then statement, which is a block of code corresponding to when this expression is true. And you'll execute that statement. If the expression evaluates to 0, it will instead execute what's called the else statement. So I'll show you how this looks in C. But basically, it's just a choice. Do you do the then or do the else? So here's how it looks in C. So you use what's called an if statement. You put if. You put the expression you want to evaluate here. And then if that expression is not 0, the code that you execute will be between these braces. And you put the else keyword. And you put another pair of braces. And if the expression is false, then this code down here will execute. You can put any expression you want. And you can also leave off this else if you'd like to. So you can't leave off the first block, but you can leave off the second block and the else keyword. So how do you do that? That's a comment. That's a comment. Yeah. So how do you know that? So that's just how the C language is defined. So the C language is defined to follow what we call this. This is called a flow chart. So what the C compiler does is it translates this piece of C code into instructions that execute this flow. So it says, OK, first calculate the value of the expression. And if the value is 0, go down to the else statement. If the value is non-zero, go to the then statement. And so those statements are arbitrary code. They're compound statements. So you can put whatever code you want there. Does that make sense? Yeah. So you don't always have to put the else. You can say if expression, do something. And if the expression is false, don't do it. Don't do anything. Just fall out of the bottom and keep going with the next statement. So here's an example. So I could say, well, I want to calculate the inverse of a number. But if that number is 0, I don't want to divide by 0. So first I'll check. Well, is my number not 0? And if it is, I will say inverse equals 1 divided by number. Otherwise, I'm going to print an error message. So that's what this little if statement will do. The test is up at the top here. 0 is not number. If that's true, in other words, number is not equal to 0, then I calculate inverse. Otherwise, I say, oh, something went wrong. Yeah. Well. Is that part of the question? It doesn't really matter. If they're ints, it's not terribly interesting. Yeah, so if they're ints, this will generally come out with inverse equal to 0, right? So if they're floats, they wouldn't cause divide by 0. But you would get an infinity, which maybe is also not what you want. So you can maybe think of them as floats. Yeah. Yeah, so the thought was to set the variable value and then to use it later. So we'd also, I mean, I'm showing this one statement in isolation. You'd have inverse equal to something else later. You could add the printf inside, as you said. So there are lots of things you could do with it. I just wanted to show you how we use if. Good question. Yeah. Yes. Yeah, so this is a style thing. So any time you have a compound statement, you should increase your level of indentation by whatever your standard is. I usually use 4. A lot of people use 4. Some people use 2, 2 spaces. Some people use 8. And it doesn't really matter what you pick, but everyone on whatever team is working on a program should use the same style. The compiler will not give you an error, but we will mark off points. It makes it really hard to read your code. It makes it very difficult. There are actually tools that will automatically indent it for you. So if you're worrying about it, you can run it through an auto-indent tool. But they'll also do things like decide whether to put braces on or things like that, rewrite your C code for you to make it look nice. OK, any other questions? All right, so here's another example. So let's say I've got a variable size. This is an integer, let's say. And I want to make sure size is not bigger than 42. So here I don't have an else. If 42 is less than size, I'm going to change size, and I'm going to tell the user, hey, I changed size. So I'll print out size set to 42, and I'll assign 42 to size. If size was already less than 42 or equal to 42, I don't need to make any change. Another way we could use an if statement. Yeah, so in this case, there is no else block. So if this condition is false, it simply comes down to whatever is the next statement after the if. I wanted to give you an example with and without an else. OK, then the last statement I want to look at is this iterative statement. So if I want to do something more than once, and the number of times doesn't have to be defined. The way I'll decide to stop is I'll have an expression. So if I want to do something more than once, I can have this structure here. So first I'll have an initialization expression. Then I'll have a test expression. The computer will produce instructions that evaluate the test expression. And if it's false, I'm done. If it's true, I'll evaluate what's called the loop body, then execute an update expression, and then go back up and do the test again. So I'll go around this loop as many times as is necessary until this test expression becomes false. Now, that can be infinite. So if you write a loop badly, it just will never finish. Sometimes that's what you want. You might want a program that never stops. So for example, you probably don't want your operating system to say, you know what? My loop finished, and I'm just going to do nothing now. I'm moving on. So an operating system or an online service or something, you would have an infinite loop as the main construct. Just say, OK, keep paying attention to people and doing what they ask. So you can do that easily with a loop. You just make sure the test expression never becomes false. Here's what it looks like in C. We're only teaching you one, but I'll show you another one. So this is the for loop. So you've got your initialization on the left. So you have four open parentheses, initialization expression, semicolon, test expression, semicolon, update expression, close parentheses, and then a compound statement for your loop body. So just to make sure you understand how the flowchart works, I wrote it out as just a list. So what happens is first, the computer evaluates init. After it evaluates init, it evaluates the test expression. And if that test expression evaluates to 0, then it's done. It skips to the end of this list, and it moves on to the next statement. Otherwise, if the test is non-zero, that means true, then it evaluates the loop body. It executes the loop body. It's a compound statement, so it'll do a bunch of statements if you put a bunch of statements in there. Then it will evaluate the update expression after it finishes the loop body. And then it will go back to step 2 and evaluate test again. And go around 2, 3, 4, 2, 3, 4, 2, 3, 4 until test evaluates to false. All right, here's an example. So if I want to print the multiples of 42 from 1 to 1,000, I'll start by setting n equal to 1. Then I'll check that n has not gotten bigger than 1,000, because I only want to go up to 1,000. My update, you'll notice, increments n by 1. So inside this loop, the first time we execute this loop body, n will be 1. And we'll continue to execute this loop body 1,000 times until n is 1,001, at which point this test will be false and we'll finish. So for every value of n from 1 to 1,000, we'll check is n mod 42 equal to 0. That would mean n is a multiple of 42. So if it's true, we print that number n using %d followed by a character term. So this loop will print all the multiples of 42 from 1 to 1,000. Very important set of numbers. Yeah? AUDIENCE MEMBER 2. Do you need to define the number of multiples of 42 for a given test? Yes, but that's beyond the scope of stuff I want to talk about. Yeah, yeah, let me not. Ask me afterwards, and I'll tell you why. OK, so one more loop. We're actually going to do this loop in class on Friday. So a while loop, basically it's the same thing, but we don't specify the init or the update. So we don't want you to have to learn this in EC 120, but you might see it. So maybe just look at these slides. We'll go through the Fibonacci loop as a program on Friday. So this will come back. And feel free to take the handout if you'd like to. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\",\n",
       " \"We're going to pick up where we left off. We just introduced Boolean functions. So we're going to look at that, go through, make sure you understand them all, do truth tables for them, and then talk about logical completeness. I think we'll get pretty far through fixed and floating-point. Not sure we'll finish that all today. On Wednesday, we'll wrap up representations, and then on Friday, we'll start talking about C programming. So that's kind of the look ahead for the week. You have a lab due Wednesday, shortly after class. So if you haven't looked already, please look soon. I decided because one of my colleagues told me that some of our students, particularly freshmen, kind of got panicky a little bit last year, or last semester rather, and so I will go hang out in the lab tomorrow for office hours. So I know a couple of you asked me, and normally I'm at Mia Zaw's on Green Street, but instead I'll go sit in the lab. So, you know, if you were thinking of coming to office hours, it would be a good chance to do the lab. It's like 12 pages of reading. So, you know, it's a lot of reading. It's not actually that much work, I think. How many of you have done it already? Just out of curiosity. Oh, awesome. Good, good, great. So, you know, if you're one of the people in the room and there's feeling like, wow, I haven't done this and I'm feeling panicky, hopefully you can make it tomorrow to my office hours, sit down, do it, and I can help you out if you're having problems. Otherwise, there are lots of office hours. So look on the schedule on the wiki, and you can find other people. Okay, so a couple reviews. So we talked about four functions on Friday. We talked about the AND, which is the all function. So if all of the inputs are 1, it outputs a 1, otherwise a 0. We talked about OR. If any input is 1, it outputs a 1, otherwise outputs a 0. We talked about NOT, which is just complement. Put in a 1, get out a 0, put in a 0, get out a 1. And we talked about XOR, exclusive OR, and how it expands, which is the ODD function. So if an odd number of inputs are 1, it outputs a 1, otherwise outputs a 0. So those are the four we looked at. And I introduced this idea of a truth table. So again, a truth table is just a way of writing down a Boolean function. So we write down the inputs on the left side of the line. We write all the combinations, usually in binary order, given the order we've listed the variables. And then on the right side, we can put the outputs for each of those lines. Okay. So last time I kind of bungled my my management of my display. So this time, let me just go show you. So again, this is the easiest way I know to find things. It happens to involve going through my website. But there on the F16 link, you can find all of these exercises. And down here, there's lecture videos and lecture slides and stuff like that. But just to remind you, there's these tools here. And so if you want to practice practice unsigned or practice twos complement, you can change the number of bits. If you really want to challenge, you can go to 16. I don't think there's really that much practical utility in doing that kind of long example. But if you really want to make sure that you can do that repetitive translation stuff, you can play with 16 bits or you can do it with as few as four. You can see at the top, there's also a floating point. So when we talk about that today, you can play with that. There's also bits, which are the four functions that I told you about just a second ago, the Boolean functions. And you can make sure you understand applying those to sets of bits. You can also go do things like extend. So if you want to sign extend, twos complement pattern, make sure, you know, just copy the sign bit, right? So it's basically just copying. But just to make sure that you understand all the material, there's a lot of different exercises in here. If you feel uncomfortable with anything, it'll give you instant feedback. Let's see if I can get this one right. Kind of embarrassing, wasn't it? Oops. Okay, looks like I got it all right. So if on your mobile, you can push the button on your, if you're typing on your laptop, you can push the button with the mouse or you can push enter. It'll highlight the ones you got right in green. If you put something wrong, again, it'll show you what you got wrong. So let's just go put a couple wrong. So those will show up in gray and you can go back and check them. So you can do as many exercises you want. Just make sure you understand how things work. So let me switch back to PowerPoint. All righty. So those are the exercise tools. All right. So now let's go through our four functions and I want you to help me kind of fill in these truth tables. So let's start with and. And I'll also give you some more notational knowledge and how to draw gates and stuff like that. So let's start with and. So what's zero and zero? Good. What's zero and one? Good. One and zero? Good. One and one? Good. So with two inputs, they all have to be one, meaning both of them have to be one. All right. So this is the and function. We don't usually write it out with words, right? We'd like to be a little more concise with our Boolean expressions. So usually we'll use this multiplication notation from normal algebra. Okay, so if I write something A times B, it means A and B. Okay, there are other notations people use in mathematics. It's called a conjunction. So if you end up taking a math logic course or something, you'll see that notation. We also use gate diagrams. So this is an and gate here. There are two features that distinguish it from other types of gates. So when you start drawing gates, if you're drawing them by hand, make sure that you try to get a flat input and a rounded output and then people will know you mean an and gate. Okay, so that's that's and. So what about or? Let's go through and do the truth table first. So remember or is the any function. So zero or zero? Good. Zero or one? One or zero? One or one? Good. Okay, so you guys know these pretty well, it seems. So we also use algebraic notation. So for or we use plus. Okay, so multiplication is and, addition is or when we write Boolean expressions. Again, math terminology or math notation, it's called a disjunction. It's written with that little B there. And or gate, again, two distinguishing features, rounded input, pointy output. Okay, so if you draw things, just make sure that you get those two sides right and then people will be able to tell what it is. If you scribble it so quickly that we can't tell if the back of the input side is round or straight and you scribble the front side so we can't tell if it's pointy or round, then we won't know what it is. Just do it carefully enough that you can tell those two things and then people can tell what you're trying to draw. All right, what about not? So not zero? Not one? Good. Okay, so a bunch of ways we write not. We'll stick to usually the first two. So we'll put a prime when we don't have any video graphical writers handy or chalkboard. Often we'll write a bar over it. So the bar or the prime means complement not. There's also mathematical complement, which is this little thing here. So you might see that in some texts. The not gate is a triangle in an inversion bubble. The thing that actually does the not part is the circle. Okay, so if you see it without the circle, that's actually just a buffer. Okay, so it just repeats the signal that's used for performance reasons in circuits. So it's the circle that does the inversion and sometimes people will draw circles all by themselves. So in the book, in the Pat and Patel textbook, you can find still a few diagrams where there are inversion bubbles on the inputs to gates. So those are actually nots and if you built it, you'd have to have a gate for each of those little circles. And they'll fix that in the third version, but the third version, they're trying to save you money because the publisher wants them to produce versions. I really shouldn't say this too much on video. Anyway, so when the third version comes out, those will go away. But for now, if you're looking at the current edition, they still have some of those inversion bubbles on inputs. All right, what about XOR? A, zero XOR zero? Good. Zero XOR one? One XOR zero? One XOR one? Good. All right. So usually we just write that a plus sign with a circle around it and it looks like OR when we draw it as a gate, but it has two lines on the input side. Sometimes the inputs will cross the first line. Sometimes they won't. It doesn't make any difference. Those mean the same thing. So that's an XOR gate. To generalize, use the definitions that I gave you. So AND is the all function, OR is the any function, XOR is the odd function. We just looked at two inputs. If you want to use more inputs in order to make them commutative and associative, they're defined this way. Okay, so let's do an example with three input XOR. So it's the odd function. So what's zero XOR zero XOR zero? Good. Zero zero one? Zero one zero? Zero one one? One zero zero? One zero one? One one zero? And one one one? Good. So again, if you look at these, I mean, I think people are mostly following along, but it is the odd function, right? The number of ones on the left, if it's one or three, you get an output of one. If it's zero or two, you get an output of zero. And you can generalize to four or five, ten input XOR if you'd like. I won't draw the truth table. All right. So there's another way that we generalize these functions, which is by pairing up bits. So a lot of instruction set architectures on computers, and even starting maybe Friday or the day after Labor Day next Wednesday, you'll start to see these operations in the C language where you can take two sets of bits and do a Boolean operation on them. So for example, we might write something like this here, C equals A and B, where A is an n-bit number, bit pattern. B is an n-bit bit pattern. And what we mean by this A and B, where I've written it out with the word, is to take those bits, line them up. So you take A sub n minus 1, B sub n minus 1, you AND those together using a two input AND, that produces C n minus 1. You do that for all of your values of I, and what you get is this number C, where it's a bitwise AND between A and B. So this is what you typically use in a computer where you've got names representing sets of bits, and then you might AND whole sets of bits together. So it's another way to generalize the idea of the Boolean expressions, or the Boolean functions that we've talked about. Be careful not to mix the algebras. So when we talk about bitwise operations, we usually use the words. The reason is that it can get confusing, because when we talk about sets of bits, we can do things like plus. We talked about how we define addition on unsigned and two-complement numbers, and if we use plus to mean addition, then having plus also mean or gets very confusing very quickly. So when we talk about bitwise operations, try just to use the words. When we're talking about Boolean expressions, plus will mean or, and multiplication will mean AND. So try not to mix those, otherwise people will not understand what you're trying to do, or worse, you'll get confused as you try to derive something. I thought about going back and showing you another tool. There's another truth table tool. A lot of that is actually not things you need to know until after the first midterm, but the first tab in there will help you fill in truth tables. So if you feel like, OK, I want to get some exercise looking at Boolean expressions and filling in truth tables, there is a tool that will help you do that, give you the same sort of feedback, same interface, basically. And that's just the next tool down, two tools down. OK, so now I have a question for you. So how many different functions exist on n bits of input? So I only showed you four, right? And after class on Friday, people came up and said, well, what about this function? What about that function? I said, well, those are all nice functions. So how are you going to find that answer? So let's start with n equals one. How many functions are there for, let's say, I have an input a. How many functions can I define on a? I'm hearing a bunch of different numbers. Let's name them. So what can I define on a? So I hear a zero, right? So I don't care what a is, the answer is zero. So that's one function. And one, that's two functions. What else can I do with a? Zero and one don't depend on a. There must be functions that depend on a. Not a, and then just a by itself. So I think that's it. So you've got four functions. OK, I'm running out of fingers, so we're going to have to do this another way. So what about n equals two? How can I figure out how many functions there are? There are four on n equals one. For n equals two, try this. So here's a truth table. Got some function c as a function of f on a and b. I'm sorry, f is the function, a and b are the inputs. So instead of writing values, let me give those outputs names. Let's call them c sub i. C zero, one, two, and three. Now depending on how I pick c zero, one, two, and three, every combination gives me a unique function. So if I were to put four zeros, well that's the zero function on two inputs. If I were to put four ones, that's the one function on two inputs. Every combination I pick gives me a different function. It's a one-to-one mapping between choices and functions. So how many choices do I have? Sixteen, right? So I've got two choices for c zero. The choice of c zero doesn't affect my choice of c one, so I also pick c one. Each of these is just a bit, right? Zero, one. So I get two choices for c zero, two choices for c one, two choices for c two, two choices for c three. I multiply all those choices out. Overall, I have sixteen two-to-the-four different ways I could fill in this truth table. Each truth table is a different function. So there are sixteen functions on two inputs. So what about three? Good. So let's write our truth table, and we'll call the outputs d sub i, and we've got eight of them. For each of them, we have two choices. So two times two times two, I'm going to lose count, eight times. So two to the eighth. I want to point out that's two to the two to the three, right? Eight is two to the three. Four to the n. Maybe. Yes, you can do four to the n. All right. So can we generalize that to n bits? Please don't make me write a truth table. All right. So what do we do? So without drawing the truth table, n bits means two to the n rows, right? If you were to write a truth table on n bits of input, it's got two to the n possible input combinations, right? And so for each of those rows, we have an output variable. We have two choices for that output variable. So you multiply all those twos together, you get two to the two to the n, or four to the n is another way to write that. So two to the two to the n functions on n bits. But I only showed you four, right? Yeah. You have a question? Okay. Eric? So you said that you can have two to the n possibilities of putting those bits together. Two to the n rows, yeah. Two to the n possible ways to have input. But there's only eight outcomes in each of these. Yeah, so here n equals three, right? So what's the total possible outcome? When n equals three, we have eight rows. There are eight different patterns, right? And when n equals four, we would have 16 rows. n equals five, we'd have 32. If we did n equals 10, you'd have 1,000 rows in your truth table. You'd have 1,000 variables to define your function. 1,024. That's just the rows of them, what about the others? So for each row, you have one of these variables, and for each variable, you have two choices. So you multiply all those twos together. There are two to the n of them. So you get this one. That's where that comes from. You're all one. Yes, each output, you choose zero or one, and all of those choices specify a unique function. Yeah? So is this a row, column expression that we did before? No, it might take us a minute to work it out in our head. Yes? So a four to the two? Yes, yeah. Yeah, so you can massage this algebraically as you like, right? So two to the two is four, and you should know that if I have this power to a power, that you can actually do the first one. And then if you plug in a specific value of n, you can also do the other one. They're associative. Do the two to the n one, which we did already on the previous slides. OK. OK, so now the hard part. So I only gave you four functions. Got a lot of paper? I can see the headline now, Illinois professor single-handedly destroys rainforest. All right, I can't have that. So your alternate homework. Instead, you can understand logical completeness. It's your choice, really. But I'm not sure you really want to use that much paper. All right, so I have a claim. If you give me enough two input and, two input or, and not functions, I can compose those mathematically to make any function you want on any number of variables. Do you believe me? Really? Why? Why do you believe me? I'm a professor. The functions, you can set them up back to back where you can keep it. Yes. That's long logic tree. Yes, yes. So the question is, how am I going to do this? We're going to have to be able to put the functions together mathematically. In math, we call that composition. So we put the output of one function into another. I'm actually going to show you the proofs using gates. So we're going to draw it as circuit diagrams, but it's equivalent to mathematical composition of functions. Yeah. So you're saying that those three functions, if, like, let's say I want to do some kind of actually use any of these three functions, and I could get that. Yes. So the question is, I'm saying, regardless of what function you want to implement, no matter what the function is, I claim I can do it with just these three functions. And yes, that's absolutely right. And so I'll come after I show you how. So the proof will be what we call by construction. So in other words, I will show you a way, regardless of what the function you want to implement is, I will show you exactly how to do it using these three kinds of gates. A way to do it. It won't be the best way to do it. This is just proof of concept proof. But it will be a way that you can always build any function. So we'll come back to why that's important after we walk through the details. Let's start the proof. So here's a diagram. So you remember, hopefully, this is the AND gate. So if I hook these together, what do I get out of the right side? So ABC, right? A and B and C. Good. So it's a three input AND, in other words. And if I have three inputs on the left, I put three values into that gate formation, what comes out is the AND of those three variables. So out of those two, two input ANDs, I produce the three input AND. So what about this one? Yeah, four input AND, right? So I've shown you how to build a three input AND. Take one of those three input ANDs, hook it together with one more two input AND, now I have a four input AND. So you probably remember proof by induction from high school or something like that, right? With like AB? Oh, you have to do AB then? Ah. So does it matter what order you do? No, because AND is associative and commutative. So you could reorder these and do the diagrams a different way and you'd get the same answer. OK, so you remember proof by induction? What do I need to prove? OK, so what I'm hearing is if it's true for some N, then I have to prove it's also true for N plus 1. Is there something else I need to prove? Yeah, I better have a base case, right? So I have an example from Yale Pat for showing why if you forget your base case, your proof doesn't work. But I'll skip that one because I think people remember, got to have a base case. So here's our proof by induction. So by induction, we've got base case of N equals 2, for example. You want a two input AND? Well, that you gave me already. So I'll take one off the shelf and I'll put it down. There's your two input AND. That's the base case. You want a bigger, more input AND? We'll do the construct we just did. So we'll start assuming I know how to build an input AND. I'll take one of those. I'll hook together one more two input AND down here. And that will give me my N plus 1 input AND. So that's our proof by induction, that for any finite number of inputs, it can give you that AND gate. Happy? OK. Yeah, you should believe me when I prove things. I don't believe it just because I say it. I occasionally make a mistake. All right. So a couple comments. So first of all, the functional form is here. So if you want to see it algebraically, you can write it that way instead of drawing circuit diagrams. But this is not a practical way to build bigger gates. So don't go back and say, OK, now I know how to build 10 input AND gates. This is not the right way to do it. I just want to show you that it can be done so that later we can talk about, well, once we have this logical completeness idea, now we know what we need to build at the technology layer so that people at higher abstraction layers can make use of any function they want. So I'm kind of giving you a hint at why it's relevant. But it's not practically the right way to approach the problem. It's just a proof right now. OK, so now I can simplify my claim. So before I said I had to use two input AND, two input ORs. But I just showed you how to build those arbitrary input ANDs and ORs. So now I just cross out the two input because all I need to prove is that with arbitrary number of, well, finite number of input AND, finite number of input OR, and not gates, I can build any function. For OR, it's the same idea. Just go through the same proof structure, replace AND with OR. So let's start by thinking about functions that produce 1, 1 in their truth table. So a whole bunch of rows, maybe. I might have 10 inputs, 1,000 rows. One row produces output of 1. So that's a tiny number of functions, a very small number of functions. But let me start with those, and I'll show you how to build those. So each of these functions, exactly one combination of inputs will produce a 1. Any other combination of inputs produces 0. So let me give you an example. So here's Q. Here is one row here. All the other rows produce 0. But tell me, when is Q equal to 1? Yeah, so you just say, well, I mean, the inputs have to be here, right? So A has to be 1, B has to be 0, C has to be 1. So B is 0 when not B is 1. I need that expression to be true. So if I write Q equals A B prime C, then that's the function. That and is equal to 1 whenever A is 1 and B is 0 and C is 1. So any time you have this subset of functions, I can just use one and gate and maybe some not gates and build the function for you. So to build an arbitrary function, we need one more step. So the first step is, well, look at the truth table. And for every row, build the and function that produces the 1 for that row. For every row that produces a 1, I should say. Yeah. AUDIENCE MEMBER 2. What's the problem with the 1? So that's a good question. So if you plug it in, remember this is an and function. So all of them have to be 1. And so A has to be 1. So A can't have any other value. B prime has to be 1, which means B has to be 0. So B can't have any other value. And C has to be 1. So C can't have any other value. So if they have any other values, this combination produces 0. Yeah. So again, it's an and function. So remember, and means all. So all of these have to be true when I use an and. So for each one of them, that constrains that input to one value. And each input appears exactly once. So there's a name for this that you'll learn later. If you want to learn it now, it's fine. It's called a minterm. It's the thing that produces a 1 for exactly one row of the truth table. And it's a product of all of the inputs or their complements. All right, so we'll produce those minterms. So for every combination where we produce a 1 output, we'll produce that and. Then we'll take all those ands, and we'll put them all together into one big or gate. That's our function. That's it. So that gives us what we call a sum of products, because the or is a sum. We use plus notation for the or. And each of the things that we're adding together is a product. It's an and. So we use multiplication notation and algebra for that. That's a really inefficient way to build a real system. We'll talk about that in about a week and a half, how can you do a better job. But it always works. So in other words, if I give you those gates, you can build anything. And that's kind of the point of logical completeness. So we say that the set and or not is logically complete, because as we showed, you can build any function on any number of inputs using only those three. If you want to show that something else is logically complete, you don't have to go to these lengths. If you can show me that given some set of functions, you can build and, you can build or, and you can build not, then you're done. You don't have to show anything else. So for example, when we talk about circuit technology and the CMOS devices that we use today in all digital electronics, not all, but almost all, what they actually produce is the NAND function and the NOR function. So the AND gate followed by a NOT gate is kind of the natural thing to build in those technologies. Turns out that NAND all by itself is logically complete. So it may be something to think about. How can you take NAND, two input NAND, and build and or and not from that? Because that one function all by itself can build anything. Yeah, question? It's NAND. NOR is also logically complete. So this stands for not and. And it's A and B complemented or by DeMorgan's law, that. They're the same. That one function, you can build anything. Yeah? Can't you just plug in the NAND to make it NAND? First, you have to show me how to build an inverter with NAND. Yes, I mean, it's not very hard to build. But that's how you would prove that NAND by itself is logically complete, not to go through the whole constructive thing again, but just to show you can get these three. All right, so why do you care? So imagine you're working on a new device technology. Maybe it's based on DNA. Maybe you're working with Ogitsa Milankovitch. Maybe it's based on new semiconductors with John Dallasassie. Maybe it's based on carbon nanotubes with Joe Leiding. Maybe you're still finishing your degree. That would be really embarrassing for me if you're working on new technologies, like before you finish your Illinois degree. So no, I'm kidding. You have lots of opportunities here, all these technologies. So let's say you're doing that. What do you need to do to make your technology useful? Well, what you need to do is you need to be able to build AND, OR, and NOT. If you can build AND, OR, and NOT, then people who are designing circuits and components and computer architectures, they can take what you've got and build everything on top. If you can't provide those three functions, then how can they use it? So that's the abstraction. If you can provide those three functions, you can build anything, any function. If you can't build those three, then it's going to be a lot harder to use. So that's the abstraction boundary. So the technology has to be able to provide those. Again, lots of opportunities here for new technologies, lots of people working on cool stuff. Think about it in your four years here. OK. So actually, in the notes, if you look online, the slides that I posted, I did three input XOR. But someone asked me after class about this function. So I thought, OK, let's just put this one in the lecture. Like I said, any function is fine. So someone said, well, what if I want a function where I have some number of inputs, and exactly one of those inputs has to be a 1 to produce a 1? So we'll do that on three. So let's write the truth table. So actually, I just make it pop up. So get a feeling for what you think it should be, and I'll make it pop up. So again, if output's a 1, if and only if exactly one input is 1 or true. So here's what I thought was the answer. So if you have c equal to 1, but a and b is 0, you get a 1. If you have b equal 1, but a and c is 0, you get a 1. If you have a equal to 1, but b and c is 0, you get a 1. Anything else, you get a 0. So let's go through and follow our constructive proof. So what is the function that produces that yellow row up there? Yeah, so a prime or a prime b prime c, right? Good. OK. What about this row? a prime b c prime? OK, good. And one more row with 1, right? What about that one? a b prime c prime. OK, good. So those are the only ones with 1, right? So for each of those, we produce this minterm, this product of the literals. We call the individual inputs literals, or they're complement, or also called literals. So we produce these three functions, and then we OR them together. So if we OR them together, we get our function. So you can follow these steps for any function you want, and that will give you the function using only AND, OR, and NOT. So now we're ready to start thinking about, well, how would we actually build that adder we talked about in the first couple days of class? We can do any Boolean function we want. Addition is just a Boolean function. You take some bits, bit pattern representing an unsigned or two's complement number, take another one, and you spit out the sum. It's just Boolean algebra. So now you have a way of thinking about how would you actually build that using just AND, OR, and NOT. Any questions on that before we play the floating point? Yeah. So those plus signs, won't that be the AND? OR. Plus is OR. Yeah. So yes, these are ORs, and the multiplication notation is AND. So this is A prime. So A prime means not A. B prime means not B. C means just C by itself. Those are ANDed together, and then the output of that AND is ORed with the output of these two ANDs. And it has the same precedence as your normal algebra. So the AND happens before the OR, which is also actually important that I should have mentioned. Yes. Yes. So if I were to write this for you in your normal algebra, you would multiply before you'd add, right? So same thing. All right, so let's go forward. All right, so in binary, we have a binary point. I know internationally, people sometimes draw this as a comma. So sorry if this is not the way you'd normally write your decimal point. So if I want to write down pi, for example, I would have that period there. And then after the period, I would have 1 for the tenths and 4 for the hundredths and so forth. So if I write binary base 2 in human terms, well, I can have a binary point. After the binary point, I have the 2 to the minus 1, so the halves place, the quarters place, the eighths place, and so on. So that's pretty straightforward. So let's say that I'm not happy with integers. We've talked a lot about how we represent integers. What if I want fractions? What if I want real numbers? What do I do? Well, one thing I can do is I can use what's called fixed point. So I say, well, in the middle of my representation, I've got a binary point. You can just pick something. It can be supported by software. It can be supported by hardware. It can be supported by both. It doesn't really matter that much. It's relatively easy to do it this way, because everything is still a power of 2. And so it turns out I can use the same adders and multipliers as long as I line things up properly. And sometimes maybe I'll even do that in software. So there have been a lot of generations of processors that just did all of this stuff in software to have fixed point representations. Some signal processing and embedded processors have hardware support for fixed point. So it's a fairly simple extension, again, just based on human notions of representations for binary. So we could do that. So do we need anything else? Or is that good enough? Yeah? Is irrational hard? Yeah, irrational is hard. But the thing is, part of the reason it's hard is there's so many of them. And so we kind of have to make do with an approximation, because to represent irrationals well, one could argue we need infinite number of bits. So that's not quite true. There's some substantially more complicated representations. Actually, I was talking with another professor, John Tallon, about them a few nights ago, because in his mathematical physics class, he's introducing people to them. There's something called continued fraction representations. People have tried to put those in hardware. They're fairly complicated to build hardware. And so what we tend to do is approximate. So what you'll see is an approximation. Good question. Yeah, that's a good point. So we do need negative numbers. So we could probably add a sine bit, kind of the way we did with two's complement. Or we could do sine magnitude fixed point. Yeah, that's a good question, though. Yeah? What about our repeating fractions? Yeah, so repeating fractions, we could try to come up with a representation that handled them well. There's a little bit of that that's natural. If you think about translating just decimal to binary, then some numbers that are finite will become infinite in the other one, because of the primality of the factorization. So people haven't, I think, come up with a representation that focuses on trying to represent repeating fractions. But it would be an interesting thing to do to see if there'd be any leverage. Yeah? That's just not a good idea. Yeah, yeah. So if you mean just having more range, we could throw more bits at it. Or we could think about, well, is there a way with the same number of bits we could get a bigger range of possible numbers? So let's think about all of those. And we'll roll forward and kind of see what floating point gives us. So let me just start by saying, well, what's the range of 32-bit two's complement? You guys know it, right? Everyone knew that? If I say, OK, write down on a piece of paper? OK, good, I'm glad you did. I usually write it this way. I don't remember. I remember 4 billion. The rest is a blur. But I think, I'm sorry, 2 billion. Yeah, 4 billion for unsigned. So let's write some banking software. So forget all this real number stuff. Let's just do banking software. And I say, OK, I'm going to store one 32-bit two's complement number to represent pennies in your account. Anyone have more? No? All right. So we're done. Got our banking software. Let's say you have a friend who has more. Well, OK, 64 bits. There's not that much money in the world. So we're still done. So what about chemistry? Anyone in chemistry? OK, good. So you got chemistry homework, right? You probably want to use a computer instead of going to the lab and being dangerous with chemicals. What's Avogadro's number? 6.0. OK, that's what I had, too. But well, so 10 to the third is 2 to the 10th. So that's about 80 bits. OK, so who's got Avogadro's number to 80 bits? That's 24 significant figures. The ones in chemistry, you know this one, right? No? What are we going to do? What are we going to do? OK, we've got to give you some homework. I should let you go early, because this is going to take you quite some time. Maybe we can just be close. Maybe we can just make up some bits for the other lower bits. Who's going to tell you you're wrong? Not the chemists, right? All right, so what about quantum mechanics? Anyone have quantum mechanics? OK, so some of you do. What about Planck's constant? Anyone have that one yet? OK. You should use Ergs, because Ergs are cool, and all the physicists use them. So yeah, those have to go after the binary point. It's a small number, right? So we'll need 90 bits after the binary point. Oh, that's 24 digits for Avogadro's number. So do we really need 170 bits of precision? Do we need, what is it, 51 significant figures of Avogadro's number to do our chemistry? Probably not, right? But it would be nice if we could represent both of those numbers. So I think people mentioned a bigger range of numbers, maybe with the same number of bits, maybe 32. So small numbers and big numbers. So what can we sacrifice to do that? Well, let's think about what we do as humans. I mean, we've already done it a few times in these slides. We have this notion of scientific notation. So we say, well, what we care about is maybe 5, 6, 7 significant figures. And we have an exponent. But we don't just write all the rest of the digits just because it's a big number. We don't write all the zeros just because it's a small number. We put it in this handy scientific notation, which has three parts. There's a sine. There's these significant figures, which I'll call them antissa. It refers to the precision, right? More digits means we know the answer better. And then we have this exponent. So let's make a representation that has those three pieces. So that's what we call floating point. So Belval Kahan at Berkeley really is the author of this floating point representation. Prior to the standardization, there were lots of different floating point methods in different computers. And they had lots of different numerical problems. So actually, IEEE floating point is really well thought out. And that's mostly due to Kahan. So pretty much every modern computer implements this. Well, any modern computer that supports floating point will implement IEEE 754 standard floating point. So this is what single precision looks like. It's got 32 bits. It has a sine, which of course is one bit. It has an exponent, which it uses eight bits. It has an antissa. Remember, those are the significant figures. You've got 23 bits for that. It's about six digits. So what does a bit value represent? So let me ask you a question first. So what are the values of that digit? Can it be anything? Maybe 0 to 4, 1 to 7? What can that digit be? Remember, canonical form is something it's not supposed to be, right? It's not supposed to be 0, because you can change the exponent. You can change the exponent. You can change the exponent. It's not supposed to be 0, because you can change the exponent. So remember, you're supposed to not have 0. You can have anything 1 to 9. So you can change the exponent if you had a 0 there. Just move it around so that you've got canonical form, unique form. All right, so what about in binary? Same question. Now binary. I'll give you the answer. Not 0 is the answer. But that means it's just a 1. OK, so now how many things do I need to represent one value? How many bits? 0. It's always a 1. I don't need any bits to represent that 1. So the leading one is implicit. So now we can go on and look at how we interpret this number. So if I have these bits, I can plug it into this formula, and that will tell me the number. So negative 1 to the sine. So if sine is a 0, that means it's positive. If sine is a 1, that means it's negative. This implicit 1 here, remember it's implicit. It doesn't take any actual bits in the number, because implicitly there's going to be a 1 in scientific notation in binary. Then the mantissa bits, all 23 of them, multiplied by 2 to the bits of the exponent interpreted as unsigned minus 127. So we can go all the way from about negative 120 to about positive 120. 2 to the negative 120, 2 to the positive. It's about 10 to the 38. Plus or minus. Yeah. Can you explain that again? Sure. Ah, yeah, yeah. So here in decimal, the answer was not 0. So we changed the exponent to make it be not 0. The answer is also not 0 in any other base, because you can always shift the exponent. But in binary, that has a further implication. If it's not 0, it must be 1. And if there's only one thing to choose from, you don't need to store any bits to represent what that leading digit is. It's always 1. There's always a 1 there. Now, there's one caveat that I'll show in the next slide. But the general interpretation is, yes, there's always a 1 there. Yeah. Why is it precocious? It's a biased offset. It's so that you can have big and small exponents. So if you want something like Planck's constant, you need a very small exponent. If you want something like Avogadro's number, you need a big one. So you want to be able to represent big and small. So this just means my 8-bit unsigned value in that exponent field is going to represent big exponents and little ones. And the choice of 127 is to make that balanced. That's why. Yeah. What's the name of that exponent? It's unsigned. It's unsigned. It's actually, there's a different name for it. So if you go read the standard, it's called a biased offset or something. But if you look at it as 8 bits and you translate it into decimal as an unsigned number, then you can subtract 127. And that'll give you the right answer. It's not two's complement. So yeah. Yeah. For doubles versus quotas, what are doubles basically? I know that you have 14 points of precision. I don't remember. I'd have to look it up. So if the double, you have 64 bits in total. One is the signed bit, obviously. And then the exponent and the mantissa split the other 63. I don't remember exactly how. And then there's actually now a standard quad, which is 128 bits. Yeah. Yeah. How would a standard quad work in terms of like? Yeah. So which bit corresponds to a half depends on your exponents. But the first bit of the mantissa in order appears after the implicit one. And so you would just take the bits here and write them out. And that would give you the binary scientific notation form of the number. Yeah. So going back and forth on paper is relatively easy. If you can put something in binary, and we'll do some examples. If you can put it in binary scientific notation, you basically just copy the bits into the 32. Yeah. OK. All right. So the one caveat, well, a couple. IEEE supports infinity, not a number. You don't need to know most of this stuff. The one thing you do need to know, so it's here in the notes if you want to look at it. You don't need to use it, though. The one thing you do need to know is that, of course, we need a 0. And 0 does not start with an implicit 1. So we need to be able to represent the number 0. That's the bit pattern of all 0's. And that was not accidental. So if you have a floating point number that has all 0's in it, it's the same 0 representation as unsigned in 2's complement. It's all 0's. But the denormalization is kind of beyond the scope of the class. So I'll put it in the slides for you. And yeah. It's still the implicit. No, no, no. I mean, 0 can't have an implicit 1. If you write the number 0 in scientific notation, you have to put a 0. So that's the exception to the rule. So the all 0 bit pattern is 0 in floating point. So how do you get the 0? The representation is well-defined. So we've just agreed on it. So now, if you were to go out and build hardware, you know what to do. Yeah, yeah. So that's a good question. But all representations that computers are going to use have to be defined in advance and agreed upon. So this is the one exception. I mean, there's also denormalized numbers. But that's beyond the scope of the class. All right. OK. So conversion. So you can do this in the tool, too, if you want to practice it. But it's not actually too hard. You convert to binary, change to scientific notation, and encode each of the three parts. So we can do an example. The integer part, you know how to do. We've done that already. The fractional part is actually equally easy. So you can write the polynomial in the other direction. So it would be these inverse powers of 2 is our fractional part. And then you think, well, if I multiply f by 2 and I multiply this side by 2, the only way this side can be bigger than 1 is if this term is 1. Because all of these, there's a quarter, there's an eighth, and so forth. So the only way for the right side to be bigger than 1 is for a negative 1 to be 1. So all you have to do is multiply both sides, multiply your number by 2. And every time you get a 1, that's a 1 bit. And every time you have something less than 1, that's a 0 bit. So let me walk you through an example. So let's say this number, it looks intimidating, but I promise we won't have too many bits. So we have that number. First, we write 5 in binary. We get 1, 0, 1. Now we need to convert that fraction. So multiply it by 2. We get something less than 1. So a negative 1 is 0. Subtract 0. Multiply it by 2. Still less than 1. Another 0. Subtract 0. Multiply it by 2. Still less than 1. Same thing. Keep going. Eventually, we will get something bigger than 1. So that tells us a minus 5 is 1. And then we'll subtract the 1 off of both sides. So we'll get half left. And then we'll multiply by 2 and get 1. So a negative 6 is also 1. And then we're done. So that's our fraction in binary. So we would give you shorter problems on exams if we were to give you something like this. And we certainly wouldn't give you something where you had to look at all 23. That would just be mean. All right? You don't want to do that by hand. You want to teach your computer to do that. And I promise the tool is also like 4 or 5 bits. So even if they look intimidating, if you work it out on paper, it's just a few bits. All right. So one last step. So we've got it in binary. So change it to binary scientific notation. And now this 1 here is implicit. These are the bits of the mantissa. Then you've got a bunch of implicit 0's after that. So the other remaining bits are 0's. This is our exponent. So into the field, we have to put 129. So then 129 minus 127 is the 2 that we want. And there's our mantissa with 15 more 0's. So that's it. Yeah. This one I think I'll save, because I want to make sure you understand it. Floating point's a little weird. It's not associative. So we'll talk about that on Wednesday. Thanks. 1 to 3 tomorrow. Oh, I stole my mic live. It doesn't matter. 1 to 3 tomorrow. Oh, I stole my mic live. It doesn't matter. It doesn't matter.\",\n",
       " \"So we're going to do another review session. Same rules as last time, so hopefully people have thought about what they want to talk about. Anyone want to throw out the first suggestion? Eric? Okay, sure. One comment quickly on that is that essential prime implicants are not, that name is not required knowledge. And I know it showed up on some of the previous midterms, but you don't need to know what that means. We do ask sometimes whether the solution to a particular KMAP is unique or not. And so we can talk about that. But knowing what's an essential prime implicant is not necessary. Mohamed? Okay. Okay. And, yeah, Daniel? I'm sorry? Decoders. Okay. And then? Actually, let me. Adders. Okay. Some of these are pretty specific, so they won't take much time. Anything else people want to throw up there before we vote? See if there's anyone. Okay, we'll give both of you one last chance. Go ahead. Okay, Mohamed, what were you going to add? You mean the canonical ones? Okay. All right, so this is a long list, so let's do voting quickly so we don't spend too much time on that. So you can vote for as many as you want. Essential prime implicants? Two. N-type MOSFETs? About 20. Decoders? Oh, lots. Oh, my goodness. Okay, 50. Timing diagrams? A lot. 40, let's say. DeMorgans law? Maybe about 15. Matters? 15. Functions of MUXes? About 30 to 40. Analyzing sequential feedback circuits? Lots again. 45, I think. Canonical SOP, POS? Three. Okay, so let's start off with decoders then. So, decoder basically gives you minterms of the input. So, the way it works, you would put in some number of wires. Let me draw it the way they've been drawing it in other sections. The way we drew it was like this. These are the same. So, basically, you're taking in some number of select wires, and those select signals you can think about as having some kind of coded value. And you want to know which one of those coded values is held, and so you create an output for each possible bit pattern. So, for two bits, you've got four possible bit patterns. So, each of those wires on the outside, on the right side, carries a one if and only if the bit pattern coming in matches that particular number. So, 0, 1, 2, or 3 are the four possible bit patterns interpreted as unsigned. The enable then just enables the decoder to output a one at all. So, if enable is zero, the decoder outputs all zeros. So, enable equals zero means that all outputs are zero. And enable equals one means exactly one output is a one. Because the bit pattern can only match one of the four possible bit patterns. So, this is a decoder's useful primarily in implementing logic where we need to know which of those four bit patterns was being carried. For a three-day decoder, for example, which of the eight possible bit patterns was being carried by the inputs. So, a lot of things like vending machines or memories will make use of them. We can also use them for implementing arbitrary logic functions by just using OR gates to OR together the minterms. Remember, these are minterms, right? So, matching a particular bit pattern is the same as a minterm. So, each of these outputs correspond to a minterm. If you wanted to know how to build them, then you can just build the AND gates corresponding to the minterms. So, you can say, well, here's an AND gate that takes enable along with S1 prime and S0 prime. And so, this would be the zero output. And then the AND gate that takes, I'll just draw enable linked up. The others I'll leave along with S1 prime and S0. This would be the one and hook up enable to all four of them. This would be S1, S0 prime. That would be the two. And then S1, S0. That would be the three. And so, that's how you would implement a decoder. You would basically generate all the minterms with AND gates. If there were an enable input, AND it together with all of the minterms. And then each of those AND gates would give us one output. Yeah. Yeah, so the outputs, the labeling of outputs on a decoder is usually using the unsigned representation of the input values. So, usually the inputs we would name something like select and it'd be S1, S0. Or for five bits, it would be S4 down through S0. And then the output labels would be the unsigned values. So, if you had a 5 to 32 decoder, they'd be labeled from 0 to 31. And each of those outputs would correspond to the five bit pattern represented by S4 through S0 as an unsigned number. If you then wanted to make different functions, it's not terribly interesting with a 2 to 4 decoder. But if you wanted to make XOR, for example, how would I do that with, say, another OR gate down here? But which minterms does XOR have? Yeah, 1 and 3, right? So, I'd pull off the 1 and 3 outputs and OR those together and that would give me XOR. Yeah, 1, 2, sorry. What about OR? Yeah, so OR should be true for this minterm, this minterm, and this minterm. So, again, 2 to 4 decoder is not terribly interesting. It would be easier to just pull S1 and S0 directly. You can do any function using, by the way, the canonical SOP version, right? Because the canonical SOP is the sum of minterms. So, if you write any function of S1, S0 as a sum of minterms, then you go find those minterms or the outputs of the decoder together that will give you the function. Anything else you want to talk about with decoders? Yeah, this is no longer really used that much in practice. You know, if you were building something out of TTL and you had a decoder and you wanted an arbitrary function, maybe you'd use it. But these days, it's easier to just build a function. Yeah, Mohammed? This is the decoder. Yeah, this is how the decoder is built, these four AND gates. I didn't draw the NOT gates to complement these, but this is the decoder. So, let me put a box around it. Sorry, I added more logic. That's the decoder. I zoom this. So, those AND gates are the decoder. All right, so let me do... It was not on the topic, so let me see what happens timing-wise. Okay, so next up then was supposed to be analyzing sequential feedback circuits, but let me instead, because timing diagrams I think will be brief, just talk a little bit about timing diagrams. I mean, really, I know there have been a couple of questions on timing diagrams. Oops, these are not all... There have been a couple of questions on timing diagrams on some of the previous exams. You need to know what a timing diagram is, so what it's, you know, you should be able to recognize one, for example. Most of the stuff we're going to do, you wouldn't draw any significant timing, certainly in this part of the class, because we're assuming clock synchronous sequential circuits, so everything operates on a clock signal. And I don't think we've ever... I mean, I'd have to go back and look through the old exams, but usually we don't ask you to reason about gate delays and things like that on a timing diagram. So it would really just be mapping out the kind of thing you did in the homework where you would draw the clock cycles, right? And you would represent what's going on in the different signals from clock cycle to clock cycle without more information than that in the timing diagram. So, you know, it's the kind of thing we also did in lecture where, for example, if you had a binary counter... Let's just make it easy, so we'll give Z1 and Z0 outputs. And of course, there's a clock input, so here's the clock. Then the clock should be a square wave, at least as best I can draw a square wave. And so then if your counter is starting at zero, you might say, okay, so, you know, when do the value... You know, draw the rest of Z1 and Z0 for a two-bit binary counter. So when should Z1 and Z0 change? Yeah, the rising edges, right? So the first thing would be to go mark the rising edges. Here's one, here's another one, and so what should change at this first rising edge? Z0, right? Because it's a two-bit binary counter, so it should go from zero to one. So Z1 will stay fixed, Z0 will go up to one. Okay, what happens at the next rising edge? Yeah, so we'll go to the one-zero state, right? So that'll go up, this one will go down. What about here? Z0 goes up, Z1 stays up. And what about... go back to zero. And now we're back in the original state, right? And so this is just going through the four counting states. So this is zero, zero, zero, one, one, zero, one, one, and then we go back to zero, zero. And then we go, I guess, to zero, one, right? Skating flip-flops. You mean of the ripple counter sort? You mean something like that? To D or to clock? Okay, so yes, there's certainly... It's certainly possible because we talked about registers and things like that for you to have flip-flops running on a common clock. So these flip-flops inside of this counter, for example, are running on a common clock, right? So all of these transitions, if I were to draw the inside of that binary counter, those are two flip-flops running off the same clock. And then, of course, the D inputs are going to be expressions of the counter. Now, this is finite state machine design, right? So it's later. But we did do registers, right? So we did shift registers, we did registers with parallel load. So those topics can be on the exam, topics of finite state machines. Was there anything else people want to talk about with timing diagrams or can we move on? Okay. All right. So let's look a little bit at analyzing sequential feedback circuits. So... What is a sequential feedback circuit? So if I have a... If without using a flip-flop, I take the output of one of my circuits, and I link it back and make it into an input as well, we call that a sequential feedback circuit. So, for example, a latch is a sequential feedback circuit. So... If your output's connected back to your input and there's no clock signal in the design, then that's a sequential feedback circuit. So the one we looked at in class, what we started with, was the R-bar S-bar latch, which looked like this. And then we built that up and all the way up through a gated D-latch, and then we went to a D-flip-flop based on this storing a bit design. You can also build SR latches out of NOR gates. These are the common designs in CMOS. Instead of NAND, you use NOR. So this is an SR latch. So if you think about the functionality here... I'll label it Q-bar, although if you turn both of those on, they'll both be zero. So here, these are active high inputs, right? So since it's a NOR gate, if I put a one in on the R input, that will force the NOR gate output to zero, so Q will be zero. So they have the opposite input sense from the R-bar S-bar latch on the left. So this was our Q, and let's see which way did this work. So if I put this as zero... Would both latches give the same outputs? Both of these can store a bit, but the input sense... These are active low inputs, these are active high inputs, and you'll notice they're swapped relative to Q. Active high means that in order to take the human action represented by the name, so if you want to set the output bit, which refers to Q, on the left, you make the S-bar input to zero to set Q to one. On the right, you make the S input equal to one, which means active high, to set Q to one. All right, so really all we want you to be able to do is analyze stable states. So there are a couple ways you can do it. There's the simple way and the harder way. So since we already did the circuit on the left, let's do the one on the right. So you can say, okay, so for R and S, I can look at what is Q. Let's give this name P, actually. So if I set R and S to zero and zero, does that tell me anything about Q or P? No, right, because those are NOR gates. So if I put a zero, I mean, think of it as OR followed by NOT. If I put a zero into an OR gate, I need to know what the other input is, right? Zero or whatever is whatever. So for both of those zero inputs to the NOR gates, I don't change anything in my circuit. So then we could start the way we did in class and say, okay, well, let's just say there's a zero in Q. What does that imply about P? So the bottom gate then would have two zeros going into it. It's a NOR gate, so out will come a one, right? So P is one. In that case, Q, I'll put a little implication arrow here, means P is one. And if P is one, what does that imply about Q? Q is zero, right? So it also goes back. You want to go around the loop because not all of these will be stable. So if we're just looking for stable states, make sure you go all the way around the loop, around the feedback loop, and check. So this state is stable, but what if we had instead guessed Q equals one? What is P then? Zero. So in that case, if Q equals one, then the bottom gate is a NOR gate. It has a one coming in from Q. NOR gate has a one. It gives a zero output, so P is a zero. And then what is Q, given P? It's a one. Top gate now has two zeros going in. So those are stable states. So this thing will store a bit when R and S are both low. What if I set S to one? What can you tell me about Q and P? What's P? It's zero, right? Because that NOR gate on the bottom now has a one coming in from S, so P is zero. So what is Q? And that's why we call this S active high, right? It's setting Q to one when you have S input of one. What if R is equal to one and S is zero? So Q is zero, right? Because the upper NOR gate will output a zero. And then P is what? That's why we name it R, and it's active high. So if I set R to one, Q is reset to zero. And we'd want to avoid this state, just as in the latch on the left. We said, well, we don't want to set them both to zero. Here we don't want to set them both to one. What output do we get if we do that? Zero, zero, right? Q and P are both zero. So we don't want to do that because then the actual value, once we stop trying to force both of them to zero, we can't depend which of these we lower first. And so we don't know what the final answer will be unless we analyze the timing carefully, which is a pain. So we try not to use this one this way. No, it would be, so if you write this as next state table, then Q retains its state, right? It's able to hold a bit. So you put Q plus equals Q in the notation of the homework, yeah. So if you wanted to rewrite this, you could say RS00, Q plus is Q, 01, Q plus is zero, I'm sorry, one, 10, Q plus is zero, and then 11, and then it's zero, but P is not Q bar, so you've got to be careful. Okay. So the more complicated way that I showed you in class will also work. Usually we're asking you, though, for stable states, so you then have to go through your truth table and find the ones that are stable. So remember that when we did it in class with a more complex circuit, we had to look for the rows that were stable by identifying the rows with Q equal to Q plus. One one is a stable state, but the outputs are both zero. So the outputs are both zero, which means that when you let RS go down, the bits that's actually stored depends which one goes down first, right? And so unless you really understand the timing of your RNS signals, you won't know what bit is stored after you've raised both of them. And worse, if you lower both of them at the same time, you can encounter metastable states where the thing actually oscillates after you've lowered RNS. There is no unstable state in this design, but if you, for example, had, I think there was a, let's see, where did I put it? Here's XOR, and let's run that through, I don't know, a NAND gate or something. If I do something like this, so it's unstable if this thing is a single inverter, right? And so since that's an XOR gate, if I put A equals zero, then that's basically a wire from its other input to its output, right? So if I say A equals zero, then that implies, let me call this, oh, this is P, then that implies that Q equals P, right, from that XOR gate. But then looking at the other gate, if, let's see, if I put B equals zero, I'm sorry, B equals one down there, then P equals Q prime. But I can't satisfy both of these at the same time, right? So if I look at A and B and I say zero, one, then this is unstable. Does that make sense? Right, because if you look at these two inputs now, on the top one, that XOR gate is just forwarding its other input to its output, and the bottom one is inverting its input, so you have a loop of one inverter, effectively. If you have a loop of one inverter, it's just an oscillator. Yeah, this just keeps inverting the one value, and it keeps oscillating. Yeah, so that's why that kind of thing is unstable. In the two latch designs, there is no unstable state. There's the possibility for metastable state, but that's not something that our analysis will show you. Yeah, mm-hmm. So we might ask you to identify the stable states, or we might ask you to identify which states oscillate or things like that. Yeah. No, no, no, you won't have to analyze the oscillator, but you might have to identify which states might oscillate. Right, so we don't use SR latches or R bar S bar latches. We don't use the two states where you both try to set and reset at the same time. So we can build extra logic around that so as not to use those states. If you had something that had an oscillating set of inputs, you could build around it so as not to use that particular input combination. And these kind of things are not really that useful in practice, but they let you think about, well, how do these things work and identify oscillation. So we might ask you that kind of question. But we won't ask you to tell us what happens after a certain amount of time with oscillations, for example, because the detailed timing questions are beyond the course. But knowing that it'll oscillate, you should be able to do. Anything else on this one? All right. Okay, so here is our list. So we have decoders, timing diagrams, analyzing sequential feedback circuits. So implementing functions with MUXes. Oh, and so I guess we did have MUXes on there. Okay, so the general question I remember was how to implement a function with a MUX. So let's say that you have some function f of a, b, and c. Okay, so there's the truth table. So f will have some values. If I want to implement this with a 4-to-1 MUX, then, for example, I can put in a and b. So let's call those s1 and s0. And I want this output to be f. So the way I want you to think about this is, well, if a is 0 and b is 0, then I can simplify my truth table, right? So if a is 0 and b is 0, I'm going to pick the 0 input of the MUX, and I'm going to forward that wire to the output f. But if a is 0 and b is 0, the only thing I need to look at is this part of the truth table right here. That needs to go into this input here. And if a is 0 and b is 1, similarly, that needs to go there. And this part, where this is going to maybe get a little messy, needs to go here. And this part needs to go there. But really, all you need to do is figure out, well, for these four little mini truth tables, what functions do I need? Clearly, they're only functions of c. But if I implement those four functions, and I put those four functions in as my four MUX values, that MUX will put together these four pieces of my bigger truth table into one big truth table. Right? So let me fill in some bits, and then we can figure out what functions to put there. Actually, it's only one bit input, right? How many functions are there again? How many different functions do I have to pick from? There are four, right? So let's put them all. Here's one. Here's another. Here's another. Here's another. So what goes into the – what function is this? It's a zero. What's this? What's this? Not c. What's that? Okay. So if I want that particular f, then up here, let's see, you said zero. What is this one again? c. Not c. 1. So I think there was something in the homework about what if I gave you one MUX and one inverter? This input two is where you would use that one inverter. If you have a function of four variables and you want to implement it with a four-to-one MUX, then you also need a little bit of luck. Oh, was it? So I've asked that question on homework, but of the form of can you do it and if not, prove that you can't. And I think XOR is – if I remember correctly, XOR suffices to show that you can't do it, but I'd have to think about it a little more. Yeah, and generally you won't be able to. You have four values left based on two variables, and so generally you won't necessarily be able to do it. You have a little bit of freedom in how you break up this truth table, right? So I just picked B and C. You can pick any two, right? So you've got three different choices here. With four variables, you have six different choices, right? So maybe one of those six choices you could actually implement, whereas the other five choices maybe you can't. So you need to do a fair bit of thinking before you decide it's impossible to do this function. Whereas the reason I'm thinking XOR is because XOR is symmetric under that set of choices, right? So you just show that you can't do one of them and then you're done. Really? Someone asked that on the exam? That's kind of mean. Right? Yeah, so bit-sliced adder, if you know the bits, plug it in. Yeah, wasn't that one on the homework? Okay. So maybe in the interest of time, I'll skip that one because you guys have homework solutions, right? Yeah. Anything else on this? Okay. All right. So let's go back to our list. And we have just done this one. So MOSFETs and networks for gates. So let's take a look. I think Mohamed, you asked this. Did you want to go over n-type, p-type functionality or just the networks? Okay. Yeah, yeah. All right. Okay. So generally, I mentioned this in class, but the n-type and p-type are duals. So we can read these off just as functions. The reason they need to be duals is so that we guarantee there's no shorts. So at least in a gate that will always produce either a 0 or a 1, they will be dual networks. So let's talk about why. So if F is equal to some function of uncomplemented literals, then primed. So why do I say uncomplemented literals? Remember that the n-type MOSFET, what we use it for is to connect to ground. So either it's directly to ground or it's through some other n-type MOSFETs going to ground. The reason is that in order for this thing to turn on, we need a voltage between the input and this side. And so by connecting this side of the circuit to ground, we guarantee that this thing will actually stay on until it brings the other side down to ground. If we try to use this connecting it to VDD, then the transistor will actually turn itself off before it pulls the output up to high voltage. So we only use n-types to connect to ground. What that means is that if we're feeding our input variables into the n-types, well, that means in our function, they will not be complemented. So whatever we built here, unless we've got inverters in front of it, whatever we built here will be our uncomplemented literals. And then if that function holds, output will have a path down to ground, which means that f, the function, is then complemented. So the kind of things we can build would be the ones we looked at. So if you want an inverter, you would just put one of these. So if this is your output, for example, and this was, say, f, then this would be f equals a prime. You could put more than one. So you could say, OK, let me do two of them. And this would be f equals a or b prime. Because here, if I turn on, sorry, I left my connection out there for b. But if I turn on a, well, then f has a path to ground. If I turn on b, f has a path to ground. So either a or b, f has a path to ground. In that case, f equals zero. Did I do that right? Yeah. Yes. So let me get to the p-type. So I just want to make sure people understand the relationship here. So the way we make constructs here is and constructs, down here, which would look like this. So this would be f equals a and b complemented. Because in order to get to ground, we have to turn on a and turn on b. But in all of them, they're uncomplemented literals. So what about the p-type stuff? So the p-type stuff, f is going to be some function of only complemented literals. And why is that? Well, for a p-type, remember that we're connecting it to high voltage. And so if we connect a p-type to high voltage, that means that it can actually, it's looking for a voltage from the side on the right, those two terminals, the source and the drain, to the gate. And so by connecting this to high voltage, that means the transistor will stay on until it pulls the other terminal up to high voltage. And so that transistor will turn on when a equals zero. And so that's why in our function written from the top network, all of our literals will be complemented. So that one I've drawn with just the one p-type is, of course, the inverter. And so in that case, we have f equals a prime, which is the same here and here, these two. And if I want to draw the complement of this one, then I would draw it as this way. And then if I were to derive that, I would get f equals a prime b prime. So if I derive that from the top network, I get f equals a prime and b prime. And that gives me f. If I derive it from the bottom network, I get f equals a or b value complement. And if you look at those two expressions and apply generalized De Morgan's law, you see that they're equal. So this one is equal to that one by De Morgan's law. So I can do the same thing for the other gate. But more generally, these two expressions need to be equal. So the p-type expression and the n-type expression must be equal. So if I write the n-type expression, remember, I get some uncomplemented literals with a prime on the end. If I then apply generalized De Morgan's and I push that prime through all the way down to the literal level, then I've swapped all my ends with ors. And instead of uncomplemented literals, all of my literals will be complemented. So if you remember in class, we did that as a two-step process, which is to apply generalized De Morgan's, you take the dual. And then you apply, you replace, or maybe I should say swap, literals and uncomplemented literals. So in this case, this duality is in the structure of the network. And the swapping comes from the use of n-type and p-type. So the n-type on the bottom turn on when the input variable is high. The p-type on the top turn on when the input variable is low. And so in the gate structures, the dual structure is in the two networks. And so in order for these two equations to be equal, I need this relationship. But I can get that relationship algebraically by applying generalized De Morgan's. And again, the dual structure is inherent in the topology of the network. So parallel and serial are duals of one another. But you can generalize that to any function and use the principle of duality to get the structure. And then the swapping is because the n-type and p-type. Let me do an example. That will be specific to the problem, but I want to stick to this one until we finish it. All right, so let's do an example. So let's say that you have something like this on top, let's say. Sorry, let me start over. Okay, so what is F here? Yeah, so we have to have the top one on, right? So that's A0. And then what about that middle part? Yeah, B0 or C0. And then the bottom, D0, right? Okay, so we can just write it down. Now I claim you can just take the dual. So the dual here, remember how to take the dual? Swap and and or, swap zeros and ones. There's no zeros and ones, right? So we just swap and and or. So I'm going to change the ands to ors and change the or to and. What that'll give me is A. I'm going to leave off the complement. So A or B, C or D, right? And I'll put the complement outside. Okay, so this dual form gives us then the structure of the bottom network. So it says A or B and C or D. So the ors are represented as parallel structures. So there's A. There's B, C. There's D. And I claim that if you go fill in the 16 row truth table that you'll see that this is compatible. There's always exactly one path from out either to high voltage or down to ground. So all I did is I took the dual and then I built the dual structure down below. Yeah. Yes. Yeah, so generalized DeMorgan's, remember, you take the dual and then you flip all the literals and complemented literals, which you can see here at the top. I already did that by hand. Yeah, Daniel? The second expression is the complement of the dual because only because I added the prime at the end. The dual, technically the dual expression has all of the literals the same way. So the actual dual is this. The dual structure down there tells us the network structure. The bottom two expressions are equal. And they're also the two values. So if you read this one off, you'll get the bottom expression. So of course you want those to be equal. Yeah. The bottom two are exactly the same. They're both equal. And if you read the top network, that's where we got the middle one. And the bottom one is what you would get if you read this one off. So the prime comes from using the n-type and the dual nature comes from construction of the dual networks. You get one cheat sheet just like last time. What did the person who wanted to talk about DeMorgan's Law, I mean I would write them down if it's hard to remember them, I guess. Which is those. Yeah, and we also, I'm sorry, we actually do give you the properties list. So these will be there. So you don't even need to read it. Write it on your cheat sheet. Very little. So I mean you need to know how to do K-maps and read SOP, POS, stuff like that. But actually manipulating Boolean algebra is not a skill that's useful these days. Yeah. Yeah. So two things about that. Perfect induction is the fancy name for brute force. So it means write a truth table, fill it in, 0, 0, 0, 0, 1, 1. Good. Yeah, that's perfect induction. Yeah, I don't know who made that name up. Do you need to know how to simplify Boolean expressions with Boolean identities? No, not for our class. Yeah, Mohamed? On the p-types, yeah, because remember that they're always connected to high voltage. The p-types are always used in the upper half of the network. And basically if the input is low, then they'll turn on. So you can always put an inverter, but I mean then logically that's an inverter. Yeah, yeah. So just think of the way the current has to flow. So if you can get a wire, if they're in series, that's an AND. If they're in parallel, that's an OR. Yeah. In this setting. I'm sorry? Sorry, I still can't hear you. Yeah. Taking the dual and then swapping literals and complement is generalized to Morgan's law. So if you want to take the complement of a big nasty expression, you can just take the dual and then swap also literals and complement literals, and that'll be the complement of the whole thing. Okay. Bring any other questions down here. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay.\",\n",
       " \"Okay. So I think it's three. Hope everyone enjoyed the midterm. Sorry, I didn't ask for your help. Yeah, mine were problems four and five. So you've got fun with multiple choice and fun with LC3. So, all right. So I want to finish up. So we'll do a little more review since it's been, I guess, five days since we looked at this program. So we'll go through the last few slides that we saw and then finish up the coding of the letter frequency code. So that'll be our last program. I'm not even going to change it into bits for you. You can find the bits on the website if you really want to see the bits. But that program technically we sort of did in binary. Then we're going to talk about assembly language and then what you can do in assembly language and things like that. And I'll talk about assemblers and how they work. That may take all of today. I have this think-pair-share exercise. Originally I had it above the assemblers, but then I thought, really, do I want to see binary code? Probably not. I'm tired of it. So I'll put it down here. And if we get to it, we'll do it in assembly and that'll be slightly easier. All right. So this was the problem, just to remind you what we're trying to solve. So we said, OK, what if we have a string? String is a bunch of ASCII characters terminated by a null. This is a zero in ASCII. So we count the occurrences of each letter regardless of case and count the number of alphabetic characters. And then we decided on this high-level algorithm where we go initialize 27 bins to zero for a histogram. And then we go through the string once. We look at each character in the string and figure out, well, is it a letter, uppercase or lowercase, or is it a not letter? And we go find the right bin and increment it. So we did a breakdown. I didn't keep the flowchart around or anything like that. It's available online if you want to see it. So we had decided, well, the string will stick at 4,000 hex. The start of our code will be 3,000 hex. And then the histogram will run from 3,100 hex up to 3,11a. This is 1a is 26. So 1 to 26, a to z. And then the non-alpha bin at 3,100. And then we had these registers assigned during the counting part of the code. So r0 has a pointer to the histogram, meaning this value. r1 is a string pointer that goes from character to character in the string, starts at 4,000, goes until we find the end of the string. And that lets us load individual memory elements, the characters in the string, into r2. r3, r4, and r5, you remember we needed to identify the boundaries in the ASCII table where the letters start and end. And so we had ASCII constants in here that we've mentioned as we went through what they are. And then we had r6 as a temporary register. And so those were our register assignments. Those you would put in comments. So if you look at either of the versions in the website, you'll see this is all listed out in comments. So you don't have to try to remember it. And this is where we had gotten to. We had actually done a little bit more of this. But this was our last comparison to say, well, is the character we're looking at, which we had converted or were about to convert into a number from 1 to 26 for the lowercase letters, is that character greater than capital Z? So is it a letter or not? I guess actually we'd already converted it. So we'd ruled out these three, and we're just trying to do this last separation. So we're trying to compare with lowercase z. So we wanted to subtract lowercase z. We had already subtracted this back quote, so hex 60. And we also had a back quote minus lowercase z in r4 already, because it's the same as at sign minus uppercase Z. Both are negative 26, because there are 26 letters regardless of case, of course. And then we're going to throw away the results stored in r6 so that we can keep the number of 1 through 26 for the lowercase letters, because that was what our increment alphabetic bin assumed we had in r2 to find the right alphabetic bin. So we wrote that instruction. We said, well, take what's in r2, add it to the r4, which was back quote minus little z, add those together, throw away the answer, but set the condition codes. So this is like calculating original character minus little z, throwing that answer into r6. So under what conditions, then, did we have a lowercase letter? So if I subtract little z and my original character value was, say, exactly equal to little z, that'll give me a 0. And if it's anything smaller, what will that give me? Negative, right? And then what if it's over in this green region? Positive. Good. So a lowercase letter, then, would be the negative in the 0 case, right? So then we can branch on negative or 0 to increment the letters histogram bins, but we've already got that code, right? So we're just going to branch to it. Now one thing we talked about, but I want to make sure people all understand, when we write that code, we have to make sure that we write it in a way that it can be used for the uppercase and the lowercase letters independently. And so the assumptions we made with that code were the assumptions of the registries we already had. So we made use of the fact that r0 held the histogram pointer, but we also assumed that r2 had a number from 1 to 26, which corresponded to the letter that was read from the string. So for the uppercase character, uppercase A, capital A was a 1, capital B was a 2, and so forth. For the lowercase character, we've got exactly the same relationship, but with the lowercase characters. So at this point in our code, if we had an uppercase T, sorry, a lowercase T in the string, that happens to be letter number 20. So r2 will have the number 20 coded as 2's complement. So the bits for the number 20 and 2's complement. So then we can just branch to that code, because we designed it to be reused that way. So the branch condition then is what? We just derived it, right? Negative or 0, right? And then we could figure this offset off, because it's up in the code we've already written, but I'm too lazy to put all the code on one slide. So instead, we'll just leave it blank. We could go do our fun counting exercise on paper. All right, so here's what we have left. So if that branch is not taken, we know that this is not a letter. But we've also written that code, right? So what can we do? Just branch to it, right? In this case, we could say BRP. The condition codes are still set, but just for a force of habit, we'll just use an unconditional branch, because we always want to go there. We happen to know what the condition codes are, but it doesn't really matter. We don't need to use them if we don't want to. We know we always want to go. So we'll do an unconditional branch, and again, we could figure out this offset, because it's code we've already written, but I'm going to leave it blank for now. All right, so those were the five regions. So now we're out of our review. So those are the five regions of the ASCII table. We've classified and counted all of the letters, all of the non-letters. Now we just need to go back and incur what? I'm sorry, we finished this box. Now we just need to point to the next character. So remember, the next character is in what register? Remember R1? So how do I point to the next character? Remember, it's just in consecutive memory locations, right? So what LC3 instruction? Just an add, right? And what arguments? I didn't ask this on the midterm, so now no one remembers. R1, R1, 1. OK. I'm tired after the midterm. All right, so now we're done with counting, right? And now we can actually just branch back to the top of the loop and get ready to look at the next character. The pointer to the next character is all ready, so we can just go to the top of the loop, load it into R2, and start again. So in that case, you do another unconditional branch. And again, you could fill that instruction in, but I don't want to. So we do need a halt. So at the end of the program, when we're done, we find the null. We need a halt somewhere in our code, right? Now, we would branch to that from the start of the program where we saw the null character down to here to stop the LC3. We do need to have that. We also need some data. So here was the number of histogram bins, a negative at sign. I just wrote these out as characters. We'd have to, of course, code them as bits. But I just wanted to remind you the values, logically. And then this 4,000 was a place we stored the pointer to the beginning of the string. So we need all those data in memory as part of our program. So again, the full program is available online. We're about to talk about assembly. There's both a binary version and assembly version. It's the same code, but one is in assembly, one is in bits. So please do take a look at those, play with them, make sure you think they're right and that you understand them. And if you use it, actually, the assembly example has an example string coded into it, which is not at 4,000. But it'll work just out of the website. You mean why not put it at the beginning of the code? It doesn't matter that much. Yeah, it really doesn't matter that much. I think a lot of... Doesn't matter that much to me. There are people, including a number of companies, that have a strong dislike for having any kind of terminal flow control hidden in the middle of your code. And that's actually, I have a dislike for that, too, for real terminal flow control. Because then someone who's trying to understand your code might not realize that this thing can stop right in the middle and I have to understand that. So they're trying to look at it as the whole thing. If the thing is very big, it might take them a while to realize, or they might just fail to realize it can stop in the middle. And so people tend to put the end at the end. And some companies will tell you, if you write code that doesn't have that, we're going to get mad at you and tell you to rewrite it. Yeah, no, not so much. It's really just for code clarity, code readability issues. Yeah, yeah, it's not parallel processing issues. Yeah, it's just a question of where you have to look to know which part of your code is going to run. Right? So is the bottom of your code going to run or not? Do I need to read the middle in order to answer that question? That's what the question is. All right, so leave the rest for you, all the counting, all the bits, all the fun, really. Okay, so now we can move on and talk about assembly language. Everyone's really quiet today. Were you happy with the midterm? Yeah, okay. I know, I'm sorry, I didn't ask for help. I'll do it again on the final. All right, so let's review our programming process. So step one, we have to figure out all the instructions, right? You have to sit there and think and think and think, figure out the instruction sequence. Step two, the fun part, map the instructions and the data to memory addresses, right? We started at 3,000, so we go to the top and we write 3,000, 3,001, 3,002. It's really a lot of fun. Step three, take those addresses and calculate the offsets, right? Often by counting. I mean, what more fun could you have with programming? And you fill in the relative offsets as bits, right? You can translate those counts into bits and then fill them in. So step one is hard, right? We're not going to get a computer to help us. So I don't know, maybe some of you get bored. I really enjoy the counting myself. When people get bored, right, they start making stupid mistakes, right? So if I were to tell you, okay, you know, homework 12, let's just change it up. Homework 12 is going to be a go by hand and actually count the letter A's in Pat and Patel. Probably everyone would get it wrong, right? Even if you tried, you would get it wrong, right? You're like, oh, page 300. Okay. So you get bored with that stuff. So instead, since it's so easy, well, we're not going to be able to get computers to do this part for us, right? Computers are dumb. They're not going to be able to do that. But this stuff down here that's basically just counting, I mean, surely a computer can count, right, or subtract or whatever, right? So let's figure out, could we get a computer to do these parts for us and just leave this part for ourselves, for the humans? So here's a typical real programming process. So the programmer actually will write something in a high-level language, right? So something like C or Java, JavaScript, whatever. Well, maybe not whatever, because then I'm going to put a compiler on that. Not all of those are compilable languages. But you would then take that language, that program in that high-level language and feed that into a compiler, and that would actually produce assembly code. Okay. So when you run GCC on your C code, in fact, that produces assembly code internally, and then it runs the assembler on that assembly code. So that's the next step. The compiler will do that for you by default, but the real program, the compiler, is simply calling another program to do that. Yeah, Eric? No, usually it will detect any inability to translate to assembly code and not generate the assembly code. Very rarely, there would be a bug in the compiler if it generated bad assembly. So the compiler is designed to take this program and produce this program. And if it's unable to do that, it should tell you that. It should tell you it's unable to do that translation, not produce broken assembly. So if it produces broken assembly, that's a bug in the compiler, which sometimes they do, right? Compilers are not bug-free any more than any other piece of software is bug-free. So you get your assembly code out of your compiler, and then you feed that into an assembler, and your assembler produces your binary program, which then, in order to get pulled into memory on the computer, usually is pulled in by what's called a loader program, takes your binary off the disk, puts it in memory. Once it's in memory, the operating system can transfer control to your program and let it execute. So this is your typical programming process. Yes, there's also a symbol table, which I didn't draw in this process. I mean, in the starred notes in section one of the class, there's a more complete diagram. This is a simplified diagram. So this is kind of the core that we've looked at so far. All right, so down here, this is where you did labs 10 and 11, right? So you said, OK, I'm going to go write some binary. I'll write zeros and ones. This is today. We're going to talk about what assembly code looks like and how an assembler works. And then labs 12 through 14, one of which I know you're doing tomorrow, but the next few weeks also, you'll be writing bigger chunks of LC3 assembly code. So you'll make use of what we're seeing today and understand how it works to replace you, basically, in steps two and three, right? So you don't have to do the counting anymore. And then in EC220, you'll actually start writing substantially more C code. So you'll actually do a little bit more. I should have said there's some EC220 in here also. So the very first few weeks of the class, you'll do more LC3 assembly programming. But then after that, you'll do purely C programming. If you take 391, you will have to learn x86, because in order to write an operating system, you have to make use of some assembly code. But you won't have to write binary for x86. If you really enjoy pain, you can. I don't recommend it. All right, so here's assembly code. It's a line-by-line format. So the assembler is just going to look at one line at a time. And the line format looks like this. So there's a label, an opcode, operands, a semicolon before a comment. These pieces here, the label and the comment are optional. You can also have blank lines. So you can leave blank lines. You can put a label by itself on a blank line, a comment by itself on a blank line, those two together on a blank line. With any instruction, you will have an opcode and operands. And then you can put these extra optional things as well. So the label is a symbolic name for a memory location. So we'll come back to that a few times. But it's an ability for you to make up a name using letters and underscores and numbers and say, OK, I want to name this particular memory location. And then I want to be able to use that name in order to reference it, say, with a branch or with a load. So instead of having to calculate offsets and know where things are, the assembler can do all those things for you by your being able to give names to memory locations. The opcode, then, is a mnemonic. So instead of writing 0001, now you can write add. So it'll be a lot easier to write your code because you won't have to remember the opcodes. You mean data? Yeah. So normally, because of the LC3 in particular, you would put it at the end because it starts your PC at the start. In other assemblers, you could do it either way. But typically, people will put the code first and then the data down at the bottom. If you look at the output of a compiler, sometimes it will associate some data with functions, and so they'll interleave them. But typically, when it's assembled, those two will be separated into different regions of memory. I see. I see. Yeah. OK. So here are a couple of examples. Do you understand that one? So there's a label over there. There's an opcode. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's a label. And then there's an opcode, operand, and there's a comment. So what does that do? Yeah, it's infinite loop. Mohamed? OK. You were just going to answer. OK. OK. Yeah. So this is just an infinite loop, right? So how about this one? What do you think this does? Yeah, it does a load of what? Yeah, whatever bits this branch is, those bits get loaded into R3. This label here references this memory location. So this says, well, take the bits in this memory location and pull them into R3. Now, if you really put it in this order, this one would never run, right? So labels name memory locations. So there's a name of a memory location. It's mentioned over here. This is the one that defines it. These are uses in the operand cases. And so you can use it as a target for your branch. You can use it as the offset of your load instruction or your LEA or whatever. So assembly language also supports a couple of things called directives and pseudo ops. Even in the book, they treat these as the same thing. I treat them slightly differently, but most of the world doesn't. So don't worry too much if you don't learn my meanings. But I'll use them this way. So directives are basically they provide information to the assembler. So we'll look at a bunch of examples. But they tell the assembler, well, here's something that I want you need to know in order to assemble my code. And that's provided by the programmer, of course. And pseudo ops are basically just shortcut notation. So there's something you want to do. And so rather than typing a bunch of bits or whatever, there's a shorter way to do it just to make it easier to write assembly code. So we call those pseudo ops. So let me give you examples. So first, we'll do directives. So the.orig directive, all of the directives in pseudo ops start with a period. So.orig, for origin. This tells the assembler, where do you want to start your program? So instead of putting one address like you do in binary, you put a.orig directive at the start of your file. You can put comments above it, but you can't put any instructions above it. And there can only be one of these. So you say, well, here's the start of my program, for example, 3,000 hex. And you have to do that once, again, before any actual bits, any lines that would generate bits. At the end of your program, you put a.end. So second directive,.end. This one you should be careful with, because the assembler, when it sees it, it says, OK, I'm done. You told me I'm done, so I'm done. You put other stuff after it, it's done. It doesn't read it. So I mean, here's an example where you really wouldn't want to put this in the middle. This is not the same as halt. If you put.end in the middle of your code, half your program simply will not be assembled. And you can look at it as much as you want, but nothing you write there will be flagged as an error. You can put the multiply instruction down there. It won't get it. Nothing will happen. Yeah, so the assembler will stop reading your code. It's not the same as a halt. So if you don't put a halt, you just say.end, the LC3 will keep running through whatever bits are in the memory after your program. It'll keep going. So you have to tell the LC3 to halt by putting a halt trap. Don't expect.end to do that. Yeah. OK, so let me stop you before you finish your question. So if you branch over the end, so the assembler is just taking your assembly code and producing bits. And so you can certainly say branch 100 memory locations forward and not write that part of memory, not write that many more instructions and end your assembly file, at which point that program is going to branch off into some other part of memory. If you put bits there, that's great. Then it'll do that. That would have to be in a separate file that you would load separately into the simulator. But if you put a.end, it just stops reading your file. So if you've only put five more instructions, it will not write anything in that 100th memory location. Even if you put after the.end, even if you put 500 more instruction-like lines, it'll ignore those, even if they're valid. Yeah. Yeah, I mean, this is really just telling the assembler this is the end of the file. And you really shouldn't try to use it in interesting ways. It simply stops reading the file. Yeah. I mean, LC3, because it's an educational architecture, there's really not much support for having different chunks go in different parts of memory. You can do it by hand in the simulator. You can say, oh, load that file. Now load this file. Now load that file. But it changes the PC every time to the start of whichever file was loaded last. So it's really kind of a pain to do things that way. And it's not meant to be used that way. Most real assemblers, you would actually have another step in the process that I didn't show you called linking, where you would take multiple object files and then build them into a binary. That's in the more detailed version if you want to see it. I'm not quite sure what you mean. No. No, the problem is just that the software infrastructure doesn't, we don't have a file format that allows you to specify multiple non-contiguous regions of memory. Yeah, it's purely no one bothered to build it. It's all software. Software support. It's not there. Okay. All right. Third and last directive, blank words. Blank word directive says, okay, skip some memory for me. Leave them blank. Now, you know there are no such things as blanks. They're bits, right? What are those bits? You should think of them as bits. What they really will be will be probably zeros. In fact, they will be zeros because they'll go in the binary file and they'll go as zeros. So that's an unfortunate thing. You should think of them as not being filled with zeros because some assemblers will not put zeros there. And so if you use those other assemblers, you could get burned by this, right, if you assume they're zeros. So when you say something is blank, you should assume that it needs to be initialized if you want it to be zeros. So what can we use that for? Well, remember, for example, when we let a user type a number at the keyboard, we wanted to put that number in memory. We just need a place to put it, right? We don't need that place to be initialized to any value. We're going to overwrite those bits anyway. So for that, we could use one blank word, make that memory location with a blank word instruction or blank word directive rather, and then store the answer that they typed into that memory location. So that's the kind of thing for which we'd use the blank word directive. So some pseudo ops. So what if instead you said, well, sometimes I want to put certain bits, right? So when we did that typing in a number code, we wanted negative ASCII character zero, right? Because we wanted to use that to convert from digit zero to number zero and to complement digit one to number one and so forth. So what we can use in that case is this pseudo op called dot fill. And that'll let us write one specific 16-bit value. So for example, we can write dot fill hex FFD zero, and that'll write these bits FFD zero into the next memory location for us. So if we put that directive in our assembly, we will get one memory location filled with FFD zero. So if you want other numbers, you can put dot fill whatever. Ah, so remember that the assembler is just looking line by line. You tell it where to start, memory location 3000. And as it goes line by line and sees instructions, it just puts them into consecutive memory locations. So we'll look at that process a little later. But whatever the current memory location is, when it sees this pseudo op, it will drop those bits into place. And that's all. Yeah? Did I say, I'm sorry. Okay, I screwed up. Yeah, you see, remember I mentioned cut and paste bugs? It's a cut and paste bug. I cut and paste my slide and forgot to fix it. Sorry. Thank you. I'm sorry. By next, I just mean whatever it's currently writing, right? So the assembler is just going to generate a bunch of bits, right? So whatever place it is, when it sees this pseudo op, it will simply stick those bits in. So that's what I meant by next. Yeah. Yeah, so bear in mind, I'm the only one who uses this as a difference. But pseudo ops are just shortcuts for actually generating bits of some sort, right? Whereas directives just tell the assembler something. They don't generate bits. So the blank word is supposed to just skip some memory locations. It's not technically supposed to generate anything for them. The easy way to do that is to generate zeros, which is why that's what it does in practice. But conceptually, it's just supposed to skip. Yeah. So it doesn't necessarily correspond to an instruction. This for example, these bits are not an instruction, right? This is a trap op code, but a trap instruction has to have zeros here. So it doesn't need to correspond to an instruction. It can be any bits for fill. And so when you have pseudo ops, some of them will correspond one to one with instructions. For example, I already sort of mentioned the halt pseudo op, right? And halt will correspond to trap 25, one trap 25 instruction. So some of them do correspond one to one. They're just shortcut notation, that one in the sense that you no longer need to remember 25 hex when you want to halt, you can just say halt. Okay, so I leave this one too. Look at that. I left them all. Okay, sorry. Cutting case errors. String z pseudo op tells the assembler to write a null terminated ASCII string. So for example, you could write the string hello. And what that would do, you can also include things like backslash n for carriage returns, et cetera, and it will turn those into carriage return characters for you. But it takes these characters one at a time out of the string and store them in consecutive memory locations. So each seven bit ASCII character will get zero extended to 16 bits stored in one consecutive memory location. And then we'll put one more memory location filled with a null, which will be a 16 bit zero after it's zero extended. But ASCII null is seven bits too. All right, so don't forget strings, he always writes the null. So the number of characters is number of characters plus one. So for example, how many memory locations? One, seven. Seven, right? So there's three letters in the word, three periods, and then one more for the null is seven. How about this one? Maybe five, right? Three for the letters, one for the question mark, one for the null. How about this one? Good, okay. Occasionally, we ask you to calculate things like this, so you should know how to do it. So the LC3 assembler also supports pseudo ops, they got it right here, no cut and paste here, for trap instruction. So the three that you know are getC, which is trap 20 hex, out, which is trap 21 hex, and halt, which is trap 25 hex. So you don't need to remember those numbers anymore, you can just use them. Oh, yeah. Of course you can have a computer do that. But that wasn't what I wanted you to do for your homework. So now I can assign it, right? Okay. Yes. Good point. All right. So what's the advantage? Why do you want to use this stuff? So let's pretend that we're going to write our letter frequency program with assembly now. You can actually get this code, but I sort of want to just pretend that we're writing it to sort of highlight how much easier it is as you write it. So let's get started. So the first thing is we'll start our code at 3000. So this is not really that significantly easier, right? Before you just had to write 3000 as binary. Now you can write it as hex, big deal. But you know, maybe I don't know if the initialization stuff, I just haven't wrapped my mind around it yet. Let me just leave some comments in the code. It doesn't matter because the assembler is going to do all the counting of how long that is, right? So I don't care. Even if I have branches that cross over this stuff, for example, from my initialization code, I have to load the number of bins for my data at the end. It doesn't matter how far away that is, the assembler will figure it out for me. And if I change the answer by fixing bugs in the other code, it'll figure it out again. And I don't have to count. I don't have to do anything. So I can just come back later to write this initialization code. Yeah. Yeah. So the question is, are you still limited? Well, there are LC3 instructions, right? So the assembler doesn't change the LC3 ISA. It can only produce LC3 instructions. And so if somehow you get to the point where you tell the assembler, produce something that doesn't work as an LC3 instruction, what do you think it'll do? We'll come back to that one. I'll let you answer it later. Okay. So let's write the counting part. So here's our counting part. Remember the first thing we did is we read the first character, or rather the character pointed to by the string pointer into R2. So it was offset zero. We used an LDR. Remember we need to come back to that eventually. So we can just make up a name. So just make up a name before we write any more code. I'll call it count loop. Okay. So if we find a null, we need to go to the end of the string. So should I leave this blank and come back and count it later? Let's just make up a name. I can just make up names now. It's kind of nice. I can just go down and write that code, in fact. I can just go write that code. It doesn't matter how many instructions it's going to take me to write the rest, because the assembler will figure it out. And if I get it wrong and I have to fix a bug, the assembler will figure it out again. And I just don't even have to care. So as long as I make up a name here and I use the same name down here, it's fine. So much easier. All right. So label represents an address. So I do want to make sure you understand this. So this instruction, this LDR, is at this address. What is this address? The assembler is responsible for figuring that out. We don't need to care. It's an address. It's some address in memory. The assembler will figure it out, and the assembler will make use of it. Same thing here. This label is at some address in memory. When the assembler is going to generate this instruction, it needs to know how far is this away. So it can calculate an offset. But that's its job, not our job. Yeah, it's sort of similar to C identifiers, except it's not case sensitive. So you can, you can, I don't remember if you can start with an underscore. So start with a letter, not a number. I think you can use letters, numbers, and underscores. But I think you probably want to start with the letter. That's right. That's right. Yeah, so done represents an address. But here we need an address to do the offset calculation. So normally if it were us, the humans, calculating it, the way to do that is say, well, what address is BRZ? What will the PC be? Well, it'll be BRZ's address plus one. What address is this at done? Then I would subtract or count one way or the other to get done's address minus PC address, which is branch address plus one. And then get that offset and then put that into the instruction. Okay, yeah. Possibly. I'll show you how. Yeah, the question was, will you ever be asked to make a symbol table? Possibly, yeah. I mean, look, the assembler's not doing anything harder than you've done 20 times in your head as we went through code, right? So it's really not hard. All right, so what's next? We wanted to compare with capital A so we can write some code. This was the code we wrote to do that. Again, we have a branch. This was in the case where it was capital A or bigger. Well, again, just make up a name. And then we can put that code down there, or we can just wait till later to write it. It doesn't matter. As long as before we invoke the assembler, we've written this label somewhere, that's good enough. Okay, so once we find out, once we do the branch, sorry, I probably could have deleted that. Once we do the branch, we're going to reuse this code. We may not realize that. We didn't say that the first time we were writing the code. We could always come back and add this label. But that was our code to increment the non-alpha bin, right? So we had this instruction to read the non-alpha bin, add one to it, write it back. And then we had to branch. And again, just make up a name. Every time we need to go somewhere, we want to just make up a name. It's good enough. We do have to make sure the names match. So when we get around to writing the other piece of code, we have to make sure that the names are identical. Otherwise, the assembler is not going to figure it out for us. But what about data? So after the code, we had to write things like, well, the number of bins was 27. And that sign is this. The string start. Oh, look at this thing. What does that mean? So this thing here that says fill string. Yeah, so this is an address, right? So here's the address down here. I don't want to need to know. I just want the address of this string in memory to be stored here so that I can load it into a register without an LEA, with an LD. So here's my histogram. I made the histogram be just part of my program now, just a bunch of blank words, place to store my histogram. So now that we have an assembler, this kind of stuff is easy. Before if I said, oh, well, I want to put my histogram at 3138. Oops, my program's too long. I clobbered it. Now I've got to go change it. Now I've got to go change a bunch of other stuff. It's such a pain. Right here, I let the assembler figure it out. It doesn't matter. I've got a name for it. Some other piece of code wants to use my histogram, use the name hist. It'll find it. OK. Yeah. A blank word just skips 27 memory locations. Well, whatever you ask. So here we ask for 27. So remember, we needed 27 bins for a histogram. So this says, leave me 27 memory locations. I'm going to do something with them. The first one is named hist. The others are hist plus 1, hist plus 2, hist plus 3. I think it was the limit, hist plus. Yes. A string would be the address hist plus 27. That's right. Yeah. Yeah. And that's something you should know how to do is figure out, well, how many memory locations will each sudo op or instruction take? So this one, for example, would take 1, 2, 3, 4, 5, 6, 7, 8, 9, one for the null. And so if you had another label under this one, it would be string plus 9. Yeah. Yeah. Yeah. So I'm going to do something with this. It is certainly possible. But if you put that, that would be blank words equal to the address here, which would probably be a fairly large number of blank words. I mean, as long as it's, yeah. Oh, you mean a copy of this value? Yeah, no, there's no easy way. Yeah, no easy way in this LC3 assembly. All right. So how do assemblers work? Same way we do for this purpose. We can do other things. The assembler just does this one. Yeah, so you can write code to do it. But I believe Daniel's question was, can you write the code in such a way that they're both initialized to the same value without copying the value in your code? And I don't think there's an easy way to do that. Okay, so step one, figure out the instruction sequence. Step two, map instructions and data. So this will be the first pass of the assembler. The way the assembler is going to work is it's going to look at the program twice. The first time, what it's going to do is just go line by line and say, well, this instruction is at this memory address. Next instruction is at that memory address plus 1, and so forth. Just write the addresses next to it. Then it'll fill in the offsets. How will it do that? Well, it'll look at the addresses it wrote next to the bits, going through the program again, the assembly program again, and calculate all the offsets and write the bits of the instructions. So a two-step process. So here is the first part of the code. I chopped up the comments explaining things, and then there's a lot more code underneath. But this is the first part of the assembly version of the letter frequency code. So you can see we can start counting. This would be the first pass. So you can see up here it says orage.3000, right, dot orage 3000. So we'll start there. And the assembler will say, OK, here's an LEA. Well, that LEA is at 3000. OK, good. Here's the next instruction down here. This is just a comment. Next instruction is at 3001. Here's the next instruction. Guess where? Yeah. You guys are good at the counting. Are you sure you want an assembler? All right, 3003, right? So keep going. When we get down here, we see there's a label. So whatever the current count is, right, the place this instruction would go, that's the value of that label. OK, so hfloop, this was histogram fill loop, is at 3004. So what the assembler is going to do in its first pass, in addition to all this counting, is build a table called a symbol table. So here's the symbol table, I left some of it out because it's a little big for this program. Here's a symbol table for that code, right? So you can see hfloop's at 3004, countloop's at 3000c, non-alpha, 3010, blah, blah, blah, blah, blah. Histogram's down here at 3028. And that should be plus 27 to string, 27 decimal, which is what, 1D? Did I get it wrong? Yeah, yeah, these are in hex. So yeah, 1D maybe. Anyway, OK, so that's our symbol table. So in the second pass, what's the assembler going to do? Well, it's going to start counting again at the beginning, right? So I see the dot origin 3000, say OK, start at 3000. There's LEA, R0, hist. I say, wait a minute, what is hist? Well, let's go look it up. We have the symbol table from the first pass, right? So in the second pass, when it needs to generate the bits for this LEA, it's going to say, well, I've got to go look this symbol up in the symbol table. So where is hist? Ah, so it's down here, right? So 3028. So go back here. Hist is 3028. What's the PC when this LEA executes? 3001, right? So then what's the offset? X27, good. And that's it. Now we have enough. Now we can write the bits. Or rather, the assembler can write the bits, and we don't have to. Yay. OK, so what happens if the assembly file has a mistake? Oh. Yeah. Good luck. Yeah. So, Cassidy, really? I had you going with that one, really? All right, so yeah, you get to fix it, right? I mean, it can tell, yeah, this is not going to work. And it just says, error. And then you go fix it. So what kind of things can it detect? So in the first pass, it can tell if you put bad mnemonics. So if you get excited, and you say, multiply! No, sorry. LC3. Or bad operand. You say, I want to use R42. Or you say, I want to add 1,000. Right? No, out of range, sorry. Not going to work. What about labels? So is this code OK? This code should be OK, right? Just that this label that I want to go to is down here. So what? Right? Oh, it is a memory location. I don't have to have code there. It's OK. It's a memory location. This branch is forward. So in the first pass, when I get to this line, it's not in the symbol table. This label is not in the symbol table, because in the first pass, we haven't seen this line yet. So there's no label in the symbol table. So in the first pass, you can't say, oh, there's no such label, because maybe it's just down further. So you can't have that error. So it reads the file in order. You may not find it when you go look, if you look in the first pass. But that's OK. Right? Yeah, you're going to have a second pass. So in the first pass, you cannot detect undefined labels, because they might just be lower in the file, might be branching forward. What about this code? Ah, so, well, so then you're trying to make it do something smart. So, I mean, maybe these are maybe a little confusing, because I didn't put anything in between. So this probably, this should come up to the same address, right? You might think, oh, that's OK. But it's not OK. The computer's not that smart. Normally, if you have two definitions, those are going to be different addresses, right? Most often, they would be different addresses. And the LC3A and the assembler is not going to make a choice for you. So it'll just say, well, you've got multiply defined labels. So if, when you go to the symbol table, you find the symbol already there in the symbol table, that label appears twice, and it just generates an error. So how do you architect your things to get this? Usually not completely for all label types. There are local label types in some assemblers. Yeah, yeah, but not in LC3 assemblers. OK, so multiply defined labels, the last first pass error. All right, what about the second pass? What can go wrong? We saw one already, right? We decided we couldn't find, so find hist. Where's hist? Oh, it's not there. We had a typo, right? We got down to the bottom and wrote histogram instead of hist. Those are kind of similar, right? Won't the assembler just say, ah, you probably meant this. No. So it'll just make an error, right? So if the label's not defined, it'll find out in the second pass. It'll say, well, where is this label? Look in the symbol table. It's not there. So it's an error. There's nothing it can do. But what else might go wrong? Error. OK. You already asked about this, Emily. We've got offsets. Yeah. So what's wrong with this code? Yeah, this is just taken out of the middle. So imagine I put a.origin and a.end. Not a whole program, just a little piece of snippet of code from the middle. How about this? Bad, bad style. All right. So if I asked you to turn this into bits, what would you get? So yeah, bits. Very good. Good answer. Perhaps even involving 42 in hex. All right. So this LEA should not be a problem, right? Because PC is pointing here. And so the offset will be down to here. What about this stop? So that's 4200 plus 1, 4201 ahead. But PC points here. Only 4200 ahead. So you just put the offset 4200 into the branch. Yeah, you only get 9 bits in a branch, right? So is there such an instruction? There's not, right? So that's bad. So the LEA would need more than a 9-bit offset. Question? Yeah. Yeah. Yeah, so what you have to do is you have to use jump instead. And so you'll have to, I'm not sure I would call it elegant, but that's the only way to do it in LC3, which is to branch over a jump and then use a jump. You may have to load a register first. You might even have to put the data next to it if your data is very far away also. But load the stop address into a register and then jump to that register. So generally, but the assembler is not going to do that, right? That's rewriting your instruction sequence. I think they're in their habit. You could chain branches together to avoid using a jump, but I would recommend that you don't do that, that you use jumps instead. You never have to do that. Jump can go anywhere, sorry. No, this is a label, right? But the assembler can't figure out how to insert an offset that's too big into the instruction. The assembler does, and if the count is too big, too bad, right? It can't fix the problem for you. Here, it can do the counting, but the answer is 4200 hex for this branch. Sorry, this should say the branch, not the LEA. The LEA is fine. Yeah, so the branch offset is broken, right? The branch offset is going down to this stop label, and this is 4200 memory locations. So that would have to be an offset of 4200. You can't fit an offset of 4200 into 9 bits. Yeah? You could put the name like, don't do. I wouldn't be able to do. Or like, not do. Oh, no, there's no local labels in LC3 assembly. Okay, any other questions? I think we're slightly over time, so if you have a quick question. So I think it says label out of range or address out of range or something like that. Yeah, yeah. Okay, there's a summary. I'll leave that up. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay.\",\n",
       " \"to build logic gates. We may get to optimizing logic expressions. Otherwise, we'll start on Wednesday. I'm pretty sure we're not going to get to Boolean terminology. Someone pointed out that my factorial code also had a bug. So whoops. But also, Professor Verradin will guest lecture on Friday. I won't be here, so he will lecture in my place. I noticed, unfortunately, I didn't notice during the lecture, but the mic cut out very shortly after the start of the lecture on Friday. So unfortunately, there's no sound in the video. So sorry about that. If I find time, I'll try to re-record those in Personify and post them for you. But the slides are there, so you can look at those. So before we get started, I wanted to remind you that our first midterm is coming up real soon now, a week and a day, 7 to 8, 30 PM. Location, check the wiki. If you need to take the conflict, you need to sign up by today. So please do that through the wiki. The coverage is basically everything in part one. So if you look at section 1.6, it gives you a list. The exception is truth tables. You don't need to be able to read them or write them. I know you can all do it, but the other classes didn't do it, didn't cover that in class. So it won't be on the exam. Whoops. Yeah. When I went on, did you get checked in? So it points you to Compass. And I didn't follow it to Compass, because I think it uses your, so you followed it and it didn't go there yet? Yes. I forgot that that's what it's called. OK, so it should be up tomorrow, hopefully. Yeah, sorry it's not up already. We have the rooms. I think Professor Jaramillo will do assignment by name or something to, or maybe by section to room. And so I think he just hasn't posted it yet. It'll certainly be there before Tuesday. OK, so next Monday, we won't have class. So you're not obliged to come. We will have a review session. So here's how it'll work. You suggest topics. I will write down a list of topics on the board, and then I'll have you all vote on the topics. And then I will cover them in decreasing order of popularity until we run out of time. And then it'll be on the video. So if the mic stops working, tell me, because I've actually lectured in this room plenty of times with no mic, and my voice is loud enough. So I just don't even notice. I just talk louder, and everyone can still hear me. I think everyone heard me last time, right? OK. All right, so other resources, practice online tools, watch the videos. There are actually two videos. Attend any of the three lectures, assuming there's space in the room. That is, can't override the fire marshal. Can't be unsafe. Go to office hours. There is an Eta Kappa Nu review session. Eta Kappa Nu is the Electrical Engineering Honor Society. The only problem, we can't vouch for them. So if they make a mistake, I'm not saying they will, but if they do, it's not, sorry, nothing we can do about that. So if we make a mistake, and then that affects your test score, then we'll give you points back. But we can't do that for them. All right, so but usually it's probably worthwhile. So how can we build gates? So the first thing we did is we said, well, we've got electrons. We can measure voltages. Give us a bit, right, binary digit. Then we said, well, let's look at representations based on bits, based on electrons here and there. Then we said, OK, we can do functions on bits with Boolean algebra. But we kind of skipped over the device level. So today we're going to start looking at, well, how do you take devices like CMOS transistors? I'll tell you what CMOS means later. I'm sorry, CMOS gates, MOSFET transistors, and build these Boolean functions out of them. So that's what we're going to start looking at today. But first, I want to run something by you. This is just so exciting. I had a really great idea. They call it a torch. Just point it at you, and it'll light you up. It'll be so nice. You can point it at the podium. It'll light up. No, just it's a light. I mean, you see, it's a lamp. It's not a laser. Actually, Nick Coloniak gave a talk, and he had a visible light LED that was still under the danger level. But you didn't know that when he said, see, look how bright it is. And he said, oh, don't worry. It's safe. Thanks, Nick. So good idea? What do you think? What? But you want me to do what? Like this? But people already make those. I can't patent that. They call it a flashlight. You've never seen this? All right. I don't know. All right, I had another idea. Here's another idea. You like switches? A bunch of switches together. A lot of switches. It'd be good. How many of you play video games? See, this will be great. Good exercise for you. And when you want to change your bid, you just flip a switch. Be the hand-operated computer. Sound good? Good idea? Yeah? OK, we're going to do that? OK, you don't like that. I know some of you didn't like it. Some of you liked it. I got to say, if you want to be a video game champion, it's all in the training. So if you don't want to do the hand-operated computer, I understand. But we do a voltage-controlled switch. Then one switch can control another switch. And that switch can control another switch. So we can put two billion switches all together in one circuit. So that's a really cool idea. I'm getting tired just thinking about that thumb thing. Let's take a little break. So the person who invented that cool idea a long time ago, 70 years ago almost, John Bardeen and Shockley and Bertain. One of them's a manager, but you can read about that if you want. But they invented it at Bell Labs. Four years later, John Bardeen joined our faculty, also the physics faculty here. Got a Nobel Prize a few years later. After that, maybe another 16 years, they got a second Nobel Prize for BCS theory of superconductivity. This is where electrons pair up and act like bosons, allowing them to move without bumping into things. His first PhD student then, Nick Koloniak, invented things like the visible light LED. So all the lighting you see all over the world basically stems back to one of our faculty members, Nick Koloniak, who I mentioned a few minutes ago. He also invented things like laser diodes for CDs and DVDs, if you have ever used those, and dimmer switches and other things like that. Here are some of the things that he was awarded. You can find a much longer list on the web if you want to look. Nick's first student, I think it was his first student, Greg Stillman, also joined the ECE faculty, invented things like avalanche photodiodes, elected to the National Academy of Engineering. This is actually the most prestigious honor for an engineer in the US. It's basically being called to serve the country as an advisor, as an engineer. He founded the MNTL lab, which is just right next to us, and was its first director. His first student, Milton Fang, also joined the ECE faculty and burned the terahertz transistors. So very, very fast, much faster than your typical computer these days. Also the light emitting transistor, both of these were done with Nick Koloniak and the transistor laser. And he just retired actually this fall. So you could have worked with him had you come last year. Actually, he's still around doing research. But not just faculty, so just to mention one of our students, how many of you are going to get a BSEE? The others are BSEE, right? OK, people don't want to raise their hands today. I know we've got more E's than that. Anyway, so but now you're feeling shy because I'm putting Kilby up there. All right, so he got his BSEE in 1947. 10 years or so later, he invented the integrated circuit at Texas Instruments. He also invented things like the thermal printer and the handheld calculator, National Academy of Engineering, and of course, Nobel Prize for physics. So now you know why we expect a lot of you. Yes. Yeah, seriously. I'm not kidding. OK, so all right, so that was just a little bragging break so you know more about Illinois history. So digital electronics today is based on MOSFET. So what's a MOSFET? The material is metal oxide semiconductor and the technology is a field effect transistor. So the voltage basically turns the transistor on and off. It's a voltage controlled switch. So there are two kinds which are named after the charge carrier. So there are electrons. So if the electrons move, it's called a negative type. And if the absence of electrons, which we call holes, move, it's called a positive type. I think not too many of you have taken quantum mechanics, right? So a few of you. So if you think back to, I think probably most of you have high school chemistry. So if you think about what happens when you have valence electrons, you can put two in the same orbital, and one is spin up and one is spin down. And if you have one absence, then it acts kind of like a positive charge. And if you have an extra one in your orbital, it acts like a negative charge. So it's the same sort of idea that in semiconductors, you have energy states. And if some of the energy states are empty, they act like holes. So if the holes are moving around, it's a p-type. If the electrons are moving around, it's an n-type. Just a way to remember p and n, positive or negative charge carrier. So how do these things work? You can learn a lot more in EC 440, I guess 340 now, if you want to take that class later. But I guess all the EEs will probably take it. But CompE is an elective. So an n-type MOSFET turns on when the voltage between the gate on the left here and the other terminals, it's a symmetric device. But between the gate and the other terminals exceeds a threshold. So if the voltage is smaller, the transistor turns off. And then current cannot flow between the other two terminals. Historically, they were called source and drain. But that implies a direction. And this, again, is a symmetric device. So we need two voltages. We're going to do binary digital systems. So we need a ground. And that's our binary 0 value. And we need a VDD, which today is about 1 and 1 half volts. That's our high voltage, our binary 1. It used to be about 5 volts. Actually, the stuff you'll play with in the lab in maybe about five to seven weeks will be 5-volt TTL chips. But on modern processors, it's usually about a volt and a half. So we can use these binary voltages to control, say, an n-type MOSFET. Now, remember, it only will turn on when the gate voltage is high. So the voltage has to exceed a threshold. So if we put 1.5 volts, and then one of the other terminals has 0 volts, as you see on the left here, the current can flow. And then the top terminal can get pulled down to 0 volts. So to turn on an n-type MOSFET, you put high voltage, binary 1 in, on the gate. And then if you have one of these connected to ground, then the other side will come down to ground as well, because the transistor will turn on. This is circuit terminology. You say the circuit's closed or open. I'd prefer to say on and off. I find it less confusing. But either one is fine. So this one, when we put 0 volts on the input, remember that in our binary voltage system, the full range of voltage is only 0 to 1.5. So you can't have anything lower than 0 over here. And so you can't exceed the threshold. So essentially, whenever you put a 0 onto the gate of the n-type MOSFET, it will turn itself off. So p-type MOSFET, the voltage goes the other direction. So if the voltage from these terminals on the right to the gate terminal exceeds a threshold, then the p-type will turn on, which means current can flow between the two terminals on the right. And if the voltage is smaller, it turns off. So the voltage just goes the other direction. So here's the same diagram with the p-type. So in order to turn it on, we need to put our ground voltage in on the gate. You'll notice, by the way, that there's this inverter bubble thing here on the p-type. I'll explain how that will help you. Remember which one is n-type and which one is p-type and how they work in a minute. But if you put 0 volts on the gate and you have high voltage on one of the terminals, the p-type transistor will turn on. And this high voltage can pull this terminal up to high voltage as well. If, on the other hand, you put high voltage on the gate, then you're not going to have any current. Remember that the whole range of voltages here is 0 to 1.5 volts. And so you can't get a higher voltage here to turn the transistor on. And so the p-type will always be off if you put 1.5 or a binary 1 on its gate. Yeah? So that's when? Yeah, so as soon as you get a voltage with the p-type, if the voltage from this point to that point is greater than a threshold, and the threshold is, say, about 70% or 80% of the high voltage, so maybe 1.2, 1.3 volts. So if the voltage difference is sufficient, then this acts like a wire between the two terminals, just like down here. And if the voltage difference is below that threshold, which it always will be if you put high voltage on the gate, then it acts like an open switch. It's turned off. You will not learn. This is the level of detail we'll cover in the class. The question is, will you see PNP junctions? If you want to learn more about transistors, then 340 is the class. So they'll cover semiconductor devices, basically, and give you a lot of detail on this. You'll see a little bit more. You'll see an ID curve, current versus voltage curve, in 110. So you'll see a tiny bit more in 110. OK, so the drawings will actually help you remember how they work. So you notice on the p-type, we have this inverter bubble on the gate. So you should just remember that that means if you put a 0, it turns on, whereas the n-type, you don't have the inverter bubble, the little circle. So n-type turns on if you put a 1 on the gate. P-type turns on if you put a 0 on the gate. Might not be so helpful to remember the names, because at least for me, they're sort of opposite of the binary digits that you'd put onto them to make them work, because they refer to the charge carriers. Yeah? Yes, this is an illustration of the on and off of p-type. And two slides back was on and off of n-type. OK, so how do we actually build gates? So to build gates, we're going to use what are called complementary structures of p-type and n-type MOSFETs. So we'll have an equal number of each type of MOSFET. On the top, we'll put our p-types. The bottom, we'll put our n-types. We say that digital systems are based on CMOS, complementary MOS. So pretty much every digital system you'll see, except for some high-speed networking equipment, will be based on CMOS. So all of your cell phones, all of your computers, most network routers. What does this gate do? So here's the simplest one. We put one p-type on top, one n-type on the bottom. What does it do? So let's go through and analyze it. So let's start. Write a truth table. So first, we'll put in voltages, and then we'll change them later to 0s and 1s. So start with a equals 0 volts. So what about the top transistor, on or off? It'll be on, right? p-type has a 0 volts on the gate, so that'll be on. What about the bottom one? Off. OK, so now we have basically a connection going from Q, the output, up to VDD. So now, remember I said, well, if one of the terminals is at 1.5 volts and the gate's at 0, it can pull the other one up. So this will pull the output up to 1.5 volts. We'll write that in the truth table. What about the other case? So if A is 1.5 volts, we put the labels on. Top transistor? Off. Bottom transistor? On. Good. So now we have a path down to ground. So here, the n-type is pulling Q down to ground, down to 0 volts, by just connecting it through its two terminals, because its gate input is 1.5 volts. So it's 0 volts. So now let's convert those voltages into our binary values. We get those. So it's a NOT gate, right? Yeah. No. I'll just throw it. So you'll see the bottom transistor is on. Top one's off. So the bottom transistor acts as a wire. So now this is ground down here, this little triangle. Sorry. Yeah. So it's changing? Yeah, it's connecting the output Q to ground, when you put A as 1.5 volts under these two transistors. The top one turns off. The bottom one turns on. Creates a wire to ground. Yeah. Yeah, so the p-type MOSFET, so it's not a gate. This whole thing is a gate. But the p-type MOSFET has the circle on the input. MOSFET is metal oxide semiconductor field effect transistor. You don't really need to know. Yeah, transistor. Good answer. Yeah. OK. All right. Yeah, we won't quiz you on that. Although I used to give out candy when teaching the networking classes. There's so many TLAs. Because no TLA, right? Yeah, good. Three letter acronym, exactly. There's so many TLAs that I told my networking class, well, if I give you an acronym and you challenge me and I can't tell you what it means, I'll give everyone in the room candy. And they actually got me a couple of times. It was fairly embarrassing. I'll give you the same deal, because I shouldn't do that to you either. But you have to remember. I won't remind you. Yeah. Yes, yes. So this thing down at the bottom is a general symbol for ground. Yes. And this up here is a general symbol for high voltage. So ground, high voltage. Yeah, this up here is high voltage. And this is ground. Yeah, sorry. Forgot, you might not have seen those. OK. So that's our NOT gate. And of course, we draw it like that. This is how we actually implement an inverter with two MOSFETs, one P-type, one N-type. Let's do a little more complicated gate. So let's go through and analyze this one. So we'll start with A and B equals 0. So there's A. So what about that top transistor, on or off? Off. Good. Bottom one? Off. Off. Good. OK, let's put B's labels. It's also at 0. We're going to do the first row of the truth table first. So what's this upper B transistor? On. And the bottom one? Off. Good. OK, so path then goes from Q where? Yeah, up to VDD, right? OK, so we get a 1. Good. Seem to follow that? Seem like it. OK. Feel free to ask questions. So let's see. Here, the A value is the same, right? We're going to look at the 0, 1 row, the second row. The A value is the same. So it just left the markings on A. You already told me the answer is there. So let's just change B. So B will have 1.5 volts. So what about B's upper transistor? Off. Good. And the bottom one? On. So now where does Q connect? Down to ground, right? Good. OK, so what's the answer? 0. Good. So now I'm going to skip a row of the truth table because I just want to change one bit. So I'm going to go down to the 1, 1 row. So now B is the same, right? B is still 1. So I've left the B markings there. So now let's put A markings for 1. So 1.5 volts. So top transistor? Off. Bottom left? On. OK, so Q still actually now has two paths down to ground, right? So that'll still be ground. And then let's do that last row. Here again, from the bottom row, A is the same. It's still 1. So I'll leave those markings. And we'll put the B markings for 0 back. So you already solved this, but let's just go through it again. The upper B transistor? On. And the bottom one? Off. Good. OK, so we still have a path down to ground. It's still 0. So what is that? Not put together with OR. Yeah, so not put together with OR, right? OR it together, and then invert the output of the OR. That equation. So that we call a NOR gate. It stands for not OR. And it looks like this. So you can see it looks like an OR gate with an inverter bubble on the front. Yeah. Yeah. How? Oh, it doesn't matter. It's just two ways to go down to ground. They're just electrically connected. Yeah, the thing you have to worry about, rather, when you design gates, is you want to make sure you never have a path from high voltage down to ground, at least for any long length of time. Because if you do that, current will flow very quickly, and your chip will melt. So you need to make sure that you never set up your transistors in a way that it's possible for current to flow directly from high voltage to ground. Yeah. But in this case, having two paths to the same voltage, that's OK. It actually will just go down to ground faster. It has less resistance to ground. OK, that's an OR gate. One more. So let's do this a little more easily. So let's just say A equals 0. So I won't even tell you what B is here. So let's just look. What happens if A equals 0? So what's the top transistor going to do? That one's on. The other A transistor? Off. Do I need to look at B? I don't, right? Because I have a path already from Q up to VDD. So any time A is 0, Q is what? A 1, right? Good. Now, what about B equals 0? The same, right? The circuit is symmetric. It has the same behavior for A and B. Let's just walk through it. So we'll put 0's in B, top transistor on, bottom one off. There's a path, right? So also, 1, 0 gives us a 1. So then we have one last case, which is A and B are both equal to 1. So what about A? What about that top transistor? Off. Bottom? On. And then B, also 1.5 volts. Off and on. Good. So we've got a connection down to ground now. All right? What is this gate? An AND. Good. And it looks like that. AND gate with a bubble on the front. So you do the AND, and then you invert the output. I'm sorry? Can you combine it with a NOT gate? Yes, you can combine it with a NOT gate to get an AND gate. So you can take the NAND and put a NOT on front if you want to build an AND. In most of the systems we'll design, actually, you'll see that usually you have more than one level of gate. And so you end up using pure NAND or NOR most of the time, whenever you can. Because otherwise, you're using more transistors than you need to. Yeah, you can make an AND gate by just adding an inverter on the front. OK, so there are some rules. Same number, one side's parallel, at least for NAND and NOR. One side's parallel, the other's serial. I'll explain duals maybe the end of this week or next week. But for now, it's enough to know the parallel versus serial construct. So I'm going to switch over to the tool, and then maybe you can help me out. Let's see. Yeah? I think you had a question earlier that I asked. OK. Do you want to ask now, or I can switch back? Good question, but let me come back to that one, actually. Yeah. I have to convince my laptop. PowerPoint doesn't like you to look at other things. OK, so now we're going to go down to the CMOS gate layout tool. And you'll see that I actually pre-wrote. Wait for that to go away. So why don't we do the NAND? OK. So there's a NAND gate with two inputs. You can check it by saying, hey, I think this is a NAND gate with two inputs, and pushing check answer. And it'll put it all green, meaning it's correct. You can go click on these rows, and it'll put the values at each of the junctions. But let's extend this and make this three inputs. So actually, here is a three input NAND exercise. We can check answer. And so at least one of those is wrong. If I have three inputs, well, it's not even paying attention to C. So what do you suggest I do to make this a three input NAND gate? Yeah, so add one p-type and one n-type controlled by C. So where should I put them? You can put the C. Hm. Up here somewhere. So up here somewhere? Right. Hm. See this thing turned to S? It means short. This is what you don't want to do. I didn't do what Rahul said yet. This is not his fault. But I connected the top through C. And so now, I actually created a path from high voltage down to ground, in this case here, where I've got 1, 1, 0, and A, B, and C. Yeah. Yeah, because I didn't protect the bottom to connect to ground. So now I have to do the other half of what Rahul was saying. And I will snip off this ground, add another n-type down here, connect those up, label that C, connect the other side to ground, and then check answer. So hopefully, you understand this side is in series. If you wanted three, you put three. If you want four, you put four. Four is about where it gets a little too slow. And so typically, gates will scale to about four inputs. And then you'd want to use multiple gates. But you can generalize these if you want to. If you want to play with it, you can go to the tool and make sure you understand it, build whatever you want. You can actually ask the question you asked there, Daniel, also. Maybe what I'll do is just reload it. It's easier than trying to delete everything. But for example, if you put the n-type on top, then you'll get these things, L and H, which if you look down in the legend here, you'll see stand for soft 0 and soft 1. So if you think about the way these things work, usually people ask this question, so it's good you asked it. But if you think about the way these things work, remember, for example, the n-type up there, the voltage has to exceed a threshold for it to turn on. And so if A is at high voltage, then it will turn on so long as the other side is not at high voltage. Once it comes within the threshold of high voltage, it will actually turn itself off. And so the output there, the thing that comes out the other side, is actually a little lower than high voltage. I think I misquoted before. The threshold is usually only about 20% or 30%. And so what comes out here is about 70% or 80%. And we call it a soft 1. And that soft 1 will be then slower in pulling up the next gate up to high voltage. And if you keep building things this way, eventually they just won't work, because they won't be able to exceed the threshold voltage. So because of the way MOSFETs work, typically we're not using this kind of approach often directly. Instead, we build with NAND and NOR. This is how you would build NAND and NOR if you wanted to. But people rarely do this in practice for that reason. Yeah? How many NORs do you want in each? Yes, they're complementary structures. So you've got at least one of each. So there's no gate that has fewer than two. The NOT gate's the simplest. Yeah? OK, yeah, so this was actually a comment also along the lines of your question, Daniel, that if you swap them, you do get these soft 0s and soft 1s. Coming out, they don't quite work properly. Does that answer your question? OK. All right, so what I want to do next is take a look at a function and think about what we can do to get a nice way to express the function. So let's see. Well, kind of hard to understand that probably at this point. So let's start by doing something we know. So when we did the logical completeness proof, we went and we looked at each of the lines with a 1, and we wrote down a Boolean expression for each line. And then we ORed them together to get the function. So let's do that. So here's a row. How do I write a function that gives me that row? Yeah, a b complement c. Remember that we've got each of the variables. So this one is a 1, so we'll have a. 0 will give us b NOT. And c will give us c. So that'll be a b prime c. So what about this row? a b c prime. Good. What about this row? a b c. Good. So if we take those three and we OR them together, we get f. So it turns out I could also write f is a b plus a c. So you can verify that if you want. The ones where a and b are on are these two down here, the bottom two. And of course, you have ones there. And the ones where a and c are on are the bottom one, and then the sixth one down from the top, or the third from the bottom. And of course, those are both 1 also. And together, those two sets give me all three of the rows with 1. So that's the same function. And if you remember distribution, distributivity, well, this, if I have a times b, then that'll give me that term. a times c, that'll give me that term. So all three of those are the same. Which one's the best? Yeah. How did you do that? I just made it up for now. I just said, hey, I just happen to know what this is. I'll show you a way later. Good question, though. Yeah. OK. That's one way to count. Good answer. Yeah. I was about to say, yeah. OK. So you also like the third one. Sorry, but we didn't agree on a metric. If we don't agree how to measure things, then all answers are wrong, right? It's the same sort of game you can play with, add the numbers between 1 and 3 or something. So until you talk about a metric, it doesn't really make sense to say what's best. And there are actually quite a few metrics people care about. So in digital design, usually they care about the first three at least. What's the area? Because that'll be the cost of fabbing the chip. So how big is it? How fast does it go? If it's very slow, maybe it's not worth making. Got to be competitive. Power energy consumption, if your battery on your cell phone is only going to last half an hour, you're probably pretty unhappy. So all three of these are important. Which one's the most important depends on the context, depends what you're trying to do. And as an engineer, you're usually going to have to balance between them. Yeah. Will you give anybody a hint? Not necessarily, no. So in our class, we're only, we'll talk about it more in a few minutes. In our class, we're going to talk mostly about area and performance. And you can trade those off pretty well against each other. And the last one is complexity reliability. So we'll talk about all four of these a little bit. But we need to use heuristics. So why are we using heuristics? And what are heuristics anyway? So in practice, actually making a measurement, saying, well, look, let's just build all the designs. And then we'll go measure them. That's kind of expensive. So in particular, if you were a cell phone manufacturer and you want to create a new cell phone and you need to do some chip fabrication, that process with all the engineering costs is about $50 to $100 million. If you're going to sell 5 million of those cell phones, yeah, big deal. That's OK. A few dollars per phone, yeah, we could cover that. If you're not going to sell a few million of those, you're not going to be able to afford it. Just building it, just the mask cost, the thing that allow you to fabricate the semiconductor chips, will cost you a few million dollars these days on the high-end processes. So instead, we want to make a guess before we go build something. So we'll use something called a heuristic, which allows us to estimate a measure. So what makes a good heuristic? Well, you'd like it to be reasonably accurate. But maybe more importantly, you want it to be monotonic relative to the real measurement. So if I get a bigger number out of the heuristic, I should get a bigger number out of the real measurement. And as long as it had that monotonicity property, probably a reasonably good heuristic. So let's take a look at a couple of heuristics for our class. So here's one for area. So take your expression and count up the number of literals. Literals are variables or they're complements. So count up the number of literals, and then add the number of operations, not including the complemented literals, so just ands and ors, or other operations would be fine, too. So why does that work? Why is that a good heuristic? So if you think about what we just saw with gate design, every time you have an input to a gate, it's going to be two transistors, one n-type, one p-type. So you get kind of a transistor count. Operators and operators, if you have an AND gate feeding into an OR gate, same thing. That output to the input, two transistors in the OR gate. You're basically transistor counting. Wires also take space, so this is not the best heuristic in the world. But it's a pretty good one for just looking at an expression and figuring out how big it should be. So let's go ahead and calculate area heuristic for those three forms of F. So what about the first one? How many literals do I have? So you have to count all of them. So this term alone counts for three. So just having A twice, those are going into different gates. So each of those will cause two transistors, two transistors, two transistors. So just literally count the number of letters. You get nine, right? How many operators? So here, it's a little trickier. Don't worry about the number of inputs. So for example, this OR is one three-input OR. And the ANDs for the minterms, those are one three-input AND each. So you have four, right? Three ANDs and one OR. So total, about 13. What about the second expression? How many literals? Or how many operators? Three, right? Two ORs and one, I'm sorry, two ANDs and one OR. So total, seven. And then the last one? Three literals, two operators. Good, so five. So from area point of view, our heuristic tells us, OK, that last one is probably the best. Fewest transistors. Now, a second metric you might care about is speed. So here's a way you can estimate speed. You look at, here we only have one output. But in a bigger system, you might have many outputs. You look the longest path in terms of how many gates from any input to any output. Don't count complemented literals if they're free. Sometimes they might not be free. So you kind of have to know what you're using the system in. Why does this work? Your gate takes time, right? For currents to flow across wires, they're not instantaneous. It takes time. So the time it takes one gate to change its output, we call a gate delay. It'll change with a semiconductor process. It gets faster over time. But it'll always be finite. It'll always take some amount of time. So we'll call that time a gate delay. And if we count gate delays in our design, we can estimate the speed at which we could use that system. So let's do that again for our functions here. So in the first one, we have maybe these complements. So that could be one. And then going into the ands, and then that goes into the ors. So two or three. Yeah. What's the operation? The operation? You mean the area? Yeah. Correct. Yeah. So basically, an and consisting of any number of terms, of any number of factors, is one. Same thing for an or. So the ors are a little trickier to figure out. But any sequence of terms with pluses between them is one. So that would be a multi-input or gate, basically. Yeah, here we leave out the complements. You'll see in about maybe three weeks that often these are free. So often, if you have a, you'll also have a prime available on a different wire. So that's why. But I know it's not clear now why, but just don't count them because they're usually free in most digital systems. So here in the first one, we had three minterms. Each of those requires an and gate to calculate it. And then we have one or to bring together all three. So three ands and an or. This one is two ands and one or. This one is one or followed by one and. So let's go now count delays. So here we've got, in the first line, again, two or three. So we've got the ands, we have the or, and then we might need to calculate complemented literals. So let's just say two or three. Here, we have just and followed by or. There's no complements, so definitely two, whether they're free or not. And then the last one, we have an or followed by an and, so again, definitely two. No complements either. So here, these last two designs are the best for delay. Yeah, so we're just counting gates. So I thought about drawing them for you, which will make it easier to just point at physical gates. But the B plus C, for example, is one or gate. That output of that or gate goes into an and gate. The output of that and gate is F. We have two gate delays. Similarly for the bigger ones. So the simple heuristic is you simply count the number of gates along the longest path. So you're just counting gates, and you just say it's gate delays. In real systems, if you want more accurate estimates, things with fan in or fan out above four will be slower. But we don't need to worry about that for our class. Yes? AUDIENCE MEMBER 2 So the two and gates can execute in parallel. So it's the longest path from any input to any output. But one path will go through one and gate from A. The other path will go through a different and gate. But both paths will only have two gates on them. So there's the second equation. So for anything on this side, basically, it'll be through two gates to get to F. So in this case, we have a clear winner. Yeah? AUDIENCE MEMBER 3 I mean that one's the first one? Yes. AUDIENCE MEMBER 3 One or? Yes. AUDIENCE MEMBER 3 If they go through the other one? Yes. So three three input and gates, and one three input or gate for the first expression. AUDIENCE MEMBER 4 What are the time delays? For the gate delays, the complements would be the third one. And so if they're free, it's two. And if they're not free, it's three. But these expressions don't have anything complemented. So they're two, regardless of whether or not the complements are free. OK. In this case, we have a clear answer. The answers are not always that simple. If you want a simple expression where you have to choose between speed and area, just look in section 211 of the notes. And there's an example there done out the same way, where one is faster and one is smaller. So you have to pick. We'll see a lot more of that kind of trade-off later in our class, too. And in practice, we're going to be a lot more of that kind of trade-off later in our class, too. And in practice, this is the kind of thing people have to do all the time. So there's a starred section I took from one of our former PhD students' PhD thesis, showing trade-offs for computer processor architecture designs. So you can see the graphs. And you can see the kind of things people do in the research. It's a starred section, right? So don't feel obliged to read it. But if you're interested in thinking about how you do this kind of stuff, there is a little bit in there on that. OK. Another question? Yeah, go with one. Two slides back. OK, so remember when we talked about the complemented literals, I said you should count the complements if they're not free. So if they're not free, you have to use an inverter. An inverter is a gate. So that's a gate delay. So draw this one then. Oh, this one's bigger, huh? OK. OK. So what are they? A, B prime, C, and then A, B, C prime, and then A, B, C, right? And this is F. So this is the first expression. So you can see now the inverters take a gate delay. So if those are free, if the complemented inputs are free, I don't have to pay for the inverter. So that would be two. If the complemented inputs are not free, I have to invert the A and B inputs. I'm sorry, B and C inputs. And that'll take a gate delay. Yeah. Is it a diagram? No, because that's an assumption. So in this diagram, it's not free. In the diagram, I drew them explicitly. If they were free, then I would simply connect C prime to here. So I mean, I can change the diagram to explain it. But that diagram assumes they're not free. Yeah. It's not sure. Yeah, so the question is, can you break your complex circuit into pieces and analyze each of the pieces? Absolutely. Yeah, so as you'll see, even in a week or two, we're going to start to build components. And so often, people will design pieces. In fact, most designers are using a standard gate library. So they're not really going down to transistor level and optimizing. A couple companies, Intel, Samsung, Apple, actually do custom logic these days. But almost no one else does. And even beyond that, when you get into 385, you'll be writing something C code-like to design your hardware. So you'll say plus, and that'll pop down an adder for you. Yeah. Would you like to talk about the C++? In office hours, if you want to. OK, so power and complexity. So I just wanted to talk briefly about these. You'll notice the stars at the top. It's beyond the scope of our class to talk about power consumption. It's too complicated to throw into 120. But if you're interested, when current flows, current flows when you switch your transistors on and off. Current has to flow to bring the voltage at the output down or up. And so that consumes energy. Goes through there, burns heat in the resistance. And you can estimate the number of times that happens in a simulator and use that to estimate your power. So that's what a lot of the design tools do for you. In 385, you'll see that, and you can play with it. Complexity, the fourth measure I mentioned, is kind of hard to measure. No one really has a quantitative way to do that. So it's usually based on experience. It's based on people knowing how hard will it be to make this work. In practice, we just have a couple minutes left. In practice, there's a lot of funny stuff in the industry. So for example, a lot of the Intel processors had what were called chicken switches. So they implemented, for example, multithreading, parallelism in their processors. And then they released them, but they were worried it would break. So they didn't turn it on. So they just left them off. A year or two worth of processors, they just had it turned off. And everything was ready. It had all the logic circuits. It had all the transistors ready to go. Just they were scared that it would break, and then they would lose a lot of money if a customer is getting angry. And so they turned it off. So there's a lot of that, actually, in the real industry. And a lot of that is just based on whether people think it's going to work and whether they think it's going to be viable to actually develop it and test it and make sure it works in the hardware. So I'm sorry? Oh, of course they tested it. And they found that it wasn't reliable enough for them to turn it on in the product. And they wanted to get the product out the door. Yes, of course they tested it. Yeah. Yeah, they always test it. Don't worry. There's actually a lot more testing in hardware because bugs can be in the design, but bugs can also be in the fabrication process. All right, so let me stop there, and we'll pick up on Wednesday. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks. Thanks.\",\n",
       " \"Iawn, mae'n mynd i'r rhan fwyaf o'r gwrthwyneb hefyd. Mae'r adswyth oliau ac aliadu haethiad chyda dim lle Dewis Aelodau y Gallfrin yma roedd y rhan fwyaf o edrych ond nid yr un topAsiannaf yno. Ond mae'r E illum wrth gwrth gwael ryw fath bach yn y stopash yn y meddwl, yn oerthin i'ra fân yma a meddwl fy mod ynל swyddo at yr gwaith llwyd. 40%, er mwyn ddweud y byddwn yn ddwy munud. Felly, diolch am hynny. Iawn. Felly, byddwn yn gwneud chalk. Felly, rwy'n am gynllunio'r ddau ddau byth o'r cynllun, yr holl slidau Powerpoint ar gael, felly os ydych chi eisiau gweld y rhai hwnnw nesaf, dyna'n iawn. Unwaith ddweud y gwnaethom ychydig o'r hynny, mae'n bwysig iawn, ac mae'r projectorau'n deimlo'n ddod allan, felly, yn hytrach na'n dod ymlaen ar y 20 munud arall, mae'n bwysig iawn uchwichwyl iawn. O ran a ffordd fyddwn i'n gwrthodi'r garch ymgynghoriad, ond mae ddewis g Schulder yn rhan, i chi. Byddwch yn maneiraidd iukiwch ddry KP Southwest wedi'i benodoli a fyddwch yn y phone chwbod ydych chi eisiau ein cwitho ac yn dylunio'r garch. Rynarrator fel sefydleidfa, hyd yn oed ac eisoes. Mae cyllid eu chyfleuwr drwy w Sisters nawr trwy'r syniadau rhandaddau olennol, ac mae dimelyn a gallu'r d WWE ac ymwneud â chynnal yr holl ddifrifnau ar y string hefyd. Felly roeddem yn eisiau mynd drwy'r string. Roeddem yn cael nifer o ddifrifnau gwahanol, felly un o'r ddifrifnau, er enghraifft, oedd i'r un ddifrifnau a'r ddifrifnau ddifrifnau ddim, gan fod y ddifrifnau ddifrifnau yn un categori, i'r un ddifrifnau yn y string. Felly gallwn ni sefydlu rhywfaint o sum i ddifrifnau yma. Os yw'r ddifrifnau'n cyfathrebu â'r llyfr neu'r ddifrifnau ddim, yna sefydlu sum i sum plus un, ac yna pan ydych chi'n gwblhau'r holl string, yna gallwch chi ddifrin neu gosod y sum fel y llyfr yma, neu fel yr holl lyfrau. Felly dyma'r ffordd y gwnaethom ei wneud yn ddiwylliannol fel dynion. Os edrychon ni ar y string gwaith, byddwn yn dweud, wel, os ydw i eisiau edrych ar a, byddwn yn edrych ar y holl string, gweld pa mor a'r ydw i'n ei weld yn adroddio'r nifer honno. Yr ail, os oeddem am wneud Patent Patel, ddewisom ein bod ni'n gobeithio gwneud rhywbeth ychydig wahanol yn ystod, sy'n rhywbeth fel yr ysgafn. Felly dychwelywch 27-byn histogram, ddod â'i gyflwyno gyda ddifrifnau, ac yna mynd drwy'r llyfr unwaith, mynd drwy'r llyfr fawr unwaith, edrychwch ar bob unigol, a ddewis pa ffordd o unigol mae'n ei wneud, os yw'n llyfr yn unigol neu'n llyfr ddim, ac yna addu un i'r bin cywir. Felly ar gyfer pob unigol yn y llyfr, cynyddu'r bin cywir ar gyfer y unigol. Felly dyma'r algorithm 2, dwi ddim yn eisiau ddysgu'r algorithm 3, dyma'r algorithm 1, ac yna sônoddom am y gwahaniaethau rhwng nhw o ran amser, gofyniadau gweithredu, pethau fel hynny. Rydyn ni'n mynd i ddatblygu'r un hwn. Y rheswm yw, yn y blynyddoedd, roeddwn i eisiau ddangos i chi sut mae rhai o'r control yn gweithio, ac wrth i ni wneud y decomposiad systematig, roeddwn i eisiau gallu defnyddio strwythurau ysgrifennol o ran ymwneud â chlasifio'r unigolion hyn. Felly, byddwn yn defnyddio hynny. Rydw i'n mynd i geisio dod yn ôl i hyn a gweld a oes ganddo. Oh, nawr mae'n mynd i ddod o'r amser i mi. Wel, mae hynny'n cymhwysol. Wel, dwi'n mynd i geisio siarad â phan o'r bwrd. Sori am hyn. Mae Phil Crine wedi mynd i China, felly dyma ddim yn gallu ei gysylltu â nhw. Mae Phil Crine wedi dyluni'r adeilad hwn. Na, dydy'r maic ddim yn gweithio er mwyn bod y system yn ei wneud. Felly, os nad ydw i'n siarad yn llawn, dweud wrthym i mi a byddwn yn siarad mwy. Mae'n ei wneud, mewn gwirionedd, ond pan fydd y system yn ei wneud, sy'n cymryd unrhyw 5 munud neu rhywbeth, byddai'n mynd i ddod â'r maic. Iawn. Y rhesymau y gofyn i mi ddod â'r broblem honno oedd, yn unol, roeddwn i am ddangos penderfyniad control cyflawniol trwy gweithio â'r adeiladau. A gadewch i mi weld a fyddai'n... Na, nid ydy'n mynd i'w gwneud. Ond roeddwn i'n ei ddweud yn HDMI, felly dwi'n mynd i ddod â'r un hwn yn ôl i mewn a gweld a fydd yn swycio arno i mi. Iawn, felly... oh, a oedd hwnna'r maic? Rwy'n credu bod hwnna'n maic, o'n i'n ddweud? Felly, mae ein rhaglen cyhoeddus yn rhoi'r rhan gyntaf o'r de-gwneud, o'n i'n dweud, wel, rhaid i ni gyntaf gynhyrchu'r histogram. Rhaid hefyd i ni gynhyrchu rhai rhaglenau. Felly, nid oeddwn yn siarad am defnyddio rhaglenau yn ôl. Fe wna i ddysgu sut y byddwn yn defnyddio'r rhaglenau. Mae'r hyn yn deimlo ei fod yn ail, o'n i? Mae'r peth hon wedi'i ceisio ei ddysgu, nid yma i'r hyn rwy'n gallu ei weld. Felly rwy'n credu fy mod i'n mynd i ddod â'r sgrin, a os gallwch chi ei gael i weithio, yna, yn fawr, a byddwn yn dod â'i gael yn ôl, ond, felly, byddwn yn dal i weithio ar y tro. Rwy'n ar y laptop, ond rwy'n mynd i gael'r sgrin allan. Ie, os gwnaethoch chi'i wneud yn byw, yna byddwn yn mynd i hynny, ond felly, mae'n iawn. Iawn, felly, felly, cofio'r algorithm rydyn ni'n ei ddod â'r hyn o'r decyn o'r cyflawniad cyflawniadol yma, yn y codi, y codi pseudogol rydyn ni'n ei wneud, iawn? Fe dweudwn, wel, yn gyntaf, byddwn yn cyflawni, yna byddwn yn mynd i ddod trwy, oh, mae'n ddiddorol nad wyf yn dda gyda'r technoleg. Beth wnaethoch chi'i wneud? Iawn, dwi'n gwybod. Ie, ie, yna un. Iawn, rydym yn dda yna. Iawn, iawn, iawn, iawn. Iawn, iawn, iawn. Diolch, Sir. Yw hwn yn byw? Gallwch chi fy nghyfres? Neu a allaf, efallai os fyddaf yn gysylltu â hyn, byddai'n well. Iawn, dwi'n gwybod, dwi'n mynd i'r ôl, dwi'n gwybod am y burp mentrol, ond rwy'n eisiau gofio hyn yn ddiweddar. Felly byddwn yn mynd i'r cyfnod arall, i fynd i'r ffwrdd drwy'r adnoddau. Felly, yn ogystal â'r holl rhan tri, eto y rhan o'r ddeg o'r termau, dyma'r bwlltau. Rwy'n eu rhoi ar y wefan hefyd, ond ar ysgrifennu a deall rhaglenau yn binari LC3, ac yna hefyd gallu ysgrifennu sefydliad gwreiddiol, felly ffynoneimau Van Neumann a phethau fel hynny, iawn, a'r strydau gwreiddiol o ddysgwyr. Yn y bôn, fel y dweud, pan ysgrifennwydwn yn y clas, yn y bôn, yn ddysgwyr a'r adnoddau, ond yn cael sylw ar beth yw'r pethau hynny. Yr un hon, rwyf yn gobeithio bod y rhan hwn yn rhedeg. Iawn, yn siŵr. Yn y bôn, y rhan hwn yn y cyfnod tri, y rhan hwn yn y cyfnod tri yw'r ffsm. Felly, iawn, yn y bôn, dyna'r rhan hwn yn y ddeg. Roedd y bwlltau eraill nad oedd yn y rhan tri, oherwydd mae gennym ddydd sy'n mynd o'r rhan tri o'r clas i'r rhan tri. Felly, mae'r topïau ar gyfer y cyfnod tri yn y rhan hwn, sy'n cyd-dod â'r rhan, yn unigol, yn cyd-dod â'r rhan ar y wic. Felly, roeddwn i eisiau ei roi i chi mewn clas, yn unwaith. Iawn, felly, roedd hwn yn y cyfnod tri. Roedd hynny'n algorffem trwy'r cyfrifiadau. Iawn. Iawn, felly, dyna'n ein stryd cyntaf rydyn ni wedi siarad amdano. Felly gallwn hefyd ddysgu'r cyfrifiadau. Dyna hefyd yn y codi pseudogol, iawn. Felly, pan ddysguon ni'r codi pseudogol, roedden ni'n dweud, wel, byddwn yn mynd i ddod o'r holl ffigurau yn y rhan. Felly gallwn ddod o'r holl ffigurau yn y rhan. Pan ydyn ni'n parhau? Wel, ar ddiwedd y rhan, dywedon ni ei fod yn ymdrech ar gyfer ffigur nol, Asky Null, sy'n unig yn 0. Felly, pan ddodon ni'n ddod o'r 0, mae'n golygu ein bod ni'n gwneud gyda'r rhan, ac yna rydyn ni wedi cyfnod yr holl ffigurau y gallwn gweithio. Yn ail, mae angen i ni gyfnod un ffigur o'r rhan, ac yna dal i fynd. Iawn, felly, sut ydyn ni, sut ydyn ni'n cyfnod un ffigur? Wel, mae angen i ni wneud dwy ffyrdd wahanol, iawn. Felly, byddwn ni'n mynd i ddefnyddio un arall o ddysgwyr. Un o'r pethau yw ddod o'r holl ffigur a'i gyfnod, felly, cyfnod un ffigur yn y histograff, ond yna mae angen i ni hefyd cymryd ein pwyntwr i mewn, i gyd. Mae angen i ni gael ein gysylltiad â'r nesaf o'r ffigur yn y histograff pan ydyn ni'n cyfnod y ffigur hon, felly byddwn ni'n mynd i gyfnod y pwyntwr hefyd. Felly, bydd hyn yn edrych fel hyn, dim ond un arall o ddysgwyr cyfnodol. Iawn, byddwn ni'n cael y ddwy ffyrdd hynny, ac yna gallwn ddechrau'n rhannu'r un hwn, iawn. Dyma'r un cyfartal. Sut ydw i'n gwybod os yw rhywbeth yn llyfr neu ddim yn llyfr? Sut ydw i'n gwybod pa ffyrdd i'w rhannu? Wel, rhaid i mi edrych ar y data. Felly sut y gallwn ni ei wneud? Felly, byddwn ni'n rhaid i ni ddefnyddio cyfnodau cyfnodol. Yn aml, ni ddim yn eisiau 128 o ffyrdd gwahanol, iawn. Dydyn ni ddim eisiau dweud, well, os yw'n y rhan gyntaf, byddwn ni'n ei wneud hyn, yn amlwg, byddai hynny'n deimlo. Rydym nhw'n rhannu feilydd, digwydd chi bach o raglen, felly rydym ni'n hyfyr-ifer hyfyrgyll, fel rhaid i chi leoli! Wrth ystryd y rhhaven sy'n ymddangos fel gyda gw olaf, bydd yn rostridig ymladdiadau. Onc needles pwy sydd yn gorfod cael ein groesi yn ddiweddar hyd i greum garaer bobol. Dylai dim byrwodol, treulyn energy meuddio fel gwallt, ond rydym ni'n gfrei i bob lŷ bobl hyd ac yna gwneud 140 o hneppion. Nawr, rydym am ddim lodi phelus. ymdrechion, ac hynny'n gwneud i ni ddiffygu llyfrwyr ddi-llyfr o llyfrwyr, trwy'n brifysgolio'n ffwrdd i'r regynau hwyl a'r hawl. Felly, ar gyfer gweithgaredd, os edrychom ymlaen at y ffigur, a'r ffigur mae'n llai na llyfr A, yn ASCII, nad yw hwnna'n llyfr. Felly gallwn ymdrech ag y llyfr A, capital letter A, ac os ydyn ni'n dod o'r cyfrifiad yw llai na A, gallwn mynd i gyfrifiadu'r bin non-llyfr yn unig. Rydyn ni'n gwybod nad yw'r rhan yma, oherwydd rydyn ni wedi gwneud y cymharas honno, felly beth sydd ar gael, yw'r ystod y chwe ffyrdd. Felly, byddwn yn mynd i gyrraedd llyfrau cyfrifiad nesaf. Felly beth ydyn ni'n ei wneud yw, byddwn yn cymharu gyda Z. Byddwn yn cymharu gyda Z, yn gwneud cyfrifiad o seiliedig ar Z, ac os yw'n llai neu'n unig i Z, yna dyna'r beth yw'r llyfr, oherwydd rydyn ni'n gwybod nad yw'n yma. Rydyn ni wedi cymharu y cas honno. Felly byddwn yn rhannu'r bocs sydd ar y ddra i'r strwythur cyfrifiad hwn, a byddwn yn dweud, mae'r llyfr yn fwy o'r cyfrifiad nesaf. Os yw'n ymwneud â'r llyfr, ni allan gwybod beth yw'r beth, felly byddwn yn rhoi'r bocs sy'n dweud, oh, rydym yn gwybod sut i gyrraedd rhywbeth mwy o'r cyfrifiad nesaf. Ond os yw'n llai neu'n unig, os yw'r cyfrifiad hwn yn ddifrif, os yw'r person yn llai neu'n unig i'r llyfr Z, yna rydym yn gwybod ei fod yn llyfr. Felly yna rydym yn mynd i gyrraedd y llyfr Z yn ymwneud â'r cyfrifiad nesaf. Felly rydyn ni wedi gwneud y cyfrifiad hwn. Rydyn ni'n gwybod bod y person yn y braciau o'r iaith yma. Felly yr hyn sydd ar gael yw'r tri rhegion yma. Felly pan dylem i'r rhaglen? Pan dylem i gydweithio'n ddiogel? Efallai ychydig llyfr A yma, o'r gwrthwyneb. Iawn, dwi'n gwybod. Felly rydyn ni'n gwybod bod y cyfrifiad nesaf yn y llyfr Z yn y tri rhegion. Dwi'n gofyn, a yw'r person yn llawer mwy na'r rhaglen A? Os yw, edrychwch yn ôl ar y diogram hon, os yw'n llawer mwy na'r rhaglen A, ac rwy'n gwybod nad yw'n ymlaen yma, oherwydd rydw i wedi cymryd yr holl rhaglenau hynny i lawr, yna dwi'n gwybod bod y person yn y rhegion hon. Ac os yw'n y rhegion cyntaf, y rhegion cyntaf-ddwyrain, nid yw'n llyfr, ac nid yw'n llyfr. Yn y tri rhegion cyntaf, mae'r cyfrifiadau yn llawer o bethau. Un o'r rhegion cyntaf yw llifr y histogram o 0. Felly dyna oedd y rhan yn ein codi. Ond mae'n rhaid i ni hefyd rhoi unrhyw gwerthoedd y byddwn ni'n eisiau eu rhwng-registr. Felly, gofynnwch, pan roeddwn yn tyfu mewn nifer, roeddwn i eisiau FFD 0, sy'n negatif ASCII 0, er mwyn i ni gynhyrchu'r nifer y dylwn ni ei ddysgu yn ASCII i nifer bynari, neu nifer gwlad 2, er mwyn i ni ddysgu 30 hex, cymryd y digid 0, a chael nifer o 0 i 9. Pan fyddem yn gweithio gyda llyfr, rydym yn eisiau'r un peth yw'r benderfyniadau hynny. Rydyn ni eisiau gael gwerthoedd a rhaglenau a allwm i ni ystyried, a yw hynny'n fwy nag a, a yw hynny'n fwy nag Z, pethau fel hynny. Felly, gallai bod niferau sy'n ddefnyddiol. Byddwn yn ddysgu beth maen nhw'n ymlaen, ond efallai y byddwn yn eisiau rhoi'r rhain i'r rhestrau. Felly, mae hynny'n y pethau y byddwn yn ei wneud. Beth am ddod o'r histogram? Felly, byddai'n mynd i fod yn gweithredu. Rydyn ni'n cael 27 ben, felly 26 llyfr, un ben ddim-alfabetig. Felly, byddwn yn mynd i wneud gweithredu. Felly, eto, byddwn yn eisiau pwyntio i'r histogram. Felly, byddwn yn pwyntio'r rhestr i'r histogram, ac yna'n mynd i ddod o'r benau, 27 arall, a chyflwyno'r un bob un gyda 0. Felly, unwaith y gwnawch chi ei ddod o'r ben, ddim yn mynd i ddod o'r histogram gyda 0 yn ymdrechion, ond dyma'r siart llwyth. Felly, gallwch weld y strwythoedd cyntaf rydyn ni'n ei gael, lle rydyn ni wneud 4 gweithredwyr gwahanol, un yn ddod o'r un o'r diwedd, a'r un o'r ddau. Felly, 4 gweithredwyr gahanol yn order. Dyma'r 5 rhedegau o'r tafel ASCII yma, ac yna dyma'r cyflwyno, y colwm o'r ddod o'r a'r cyfrif gyda'r lwyf yma a'r cynyddu'r pwynt ar y ddau yma. Os ydych chi eisiau edrych ar y siart llwyth hon, mae'n... Wel, rwy'n credu bod wedi'i grinio, ond efallai nad oeddwn i'n ei rhoi ar y ffyrdd erioed, ond mae'n rhaid i ni gwneud y cyflwyno i'r cyfrif. Felly, rydyn ni wedi'i rhoi ar y problem, a gallwn gwneud y cyfrif L3 ar gyfer hynny. Felly, dyma dim ond y cyfrif o'r broblem a'r algorffen rydyn ni'n ei gyrraedd, felly rydyn ni wedi sôn am hynny. Felly, dechreuwn i ddod o'r gwmpasau. Felly, byddwn yn angen strwyng. Bydd yn rhaid i'r strwyng fod yn ymwneud â memoriaeth ymlaen. Rydyn ni'n ddod o'r gwmpasau ar y cyfrifiadau, felly byddwn yn dechrau'r gwmpas ar 3,000 hacs. Pa lle rydyn ni'n eisiau rhoi'r histogram? Dwi'n medru rhoi hi ar 3,100 hacs. Nid yw'r gwmpas yn gyffredinol yn mynd i fod yn ddau'n fawr. Mae'n ymwneud â 30, 40 gwybod, neu rhywbeth fel hynny. Felly, bydd yn dechrau ar 31,000 hacs, ac yna, bydd y pen-iaith yn mewn ordd 31,001. Felly, bydd 31,000 hacs yn ein pen-iaith nid-alfa, a bydd 31,001 yn a, a bydd 31,002 yn b, ac yn y blaen. Felly, bydd hynny'n ein histogram o 31,000 hacs i 31,000 hacs. 1 hacs yw 26 o ddeg. 1 hacs. Yna, mae angen i ni asgrifio'r rhestrau hefyd. Felly, pan ydyn ni'n cyfnod, fe wnawn ni gwneud r0, pwyntor histogram. R0 yw'r pwyntor histogram. R1 yw'r pwyntor strin. Felly, bydd hynny'n mynd drwy'r strin. Byddwn ni'n dechrau ar y dechrau, ac byddwn ni'n gweithio'n rhagor rhagor ar ragor i'r ddod â'r nol. Pan ddod â'r rhestr allan o'r strin a'i roi yn y rhestr i edrych arno, a ddod â'r beth yw'r rhestr, pam ddod â'r rhestr yn r2? Dydyn ni'n dweud ein bod ni eisiau rhestr angen, ond dydyn ni ddim yn gwybod beth mae'r rhestr angen i fod. Felly, byddwn ni'n dweud, ie, r3, r4, r5 gall fod yn rhestr angen a'r r6 bydd yn rhestr amgylcheddol. Felly, pan ddod â'ch gweithio i ddod â'r rhestr, dydych chi wir eisiau gwneud ymddangos ym mhob ffordd ar y pwynt o'r papur, hefyd yn eich cyfnodau a'ch codi, er mwyn i chi ddim angen i chi gofio ym mhob ffordd. Felly, mae'n amser i chi ddod â'ch codi. Felly, mae angen i ni gynhyrchu r0 i 3100. Beth ydych chi'n meddwl y dylem ni ei wneud? Felly, gallwn ddefnyddio Ld, iawn? Gallwn ddod â 3100 mewn cofnodion yng nhw. A oes unrhyw beth y gallwn ei ddefnyddio os yw'r adroddiad hwn? L-E-A, L-E-A, L-E-A, L-E-A, L-E-A, L-E-A, L-E-A, L-E-A, L-E-A. Felly In yr 99. Ff, 100 hex minus 1. So, the PC, when this LEA executes, will be what? 3,001, right? So if we add ff, we'll get 3,100. Okay, so that'll be the instruction. We won't put it into bits. I'll leave that all for you. Actually, it's done for you in the version on the web, so you can actually download that if you want to play with it. So what's next? We need to fill the histogram with zeros. We'll actually need a couple of registers for this, so I'm going to kind of break my rule. And part of that is, well, we need more registers for this program than we have registers in the LC3. And so I need to reuse registers, but do it at a very high level if you need to do something like this. So we'll have a different meaning for the registers during initialization than we have during counting. So the ones I showed you was during the counting. During initialization, we're going to reuse R1, R2, and R6. So R1 we're going to use for a loop counter. It's going to have to do 27 iterations because we have 27 bins in our histogram. R2 will be the current histogram bin to fill, so we're going to scan along in the histogram bin, going bin to bin, putting zeros in them. So that'll be our pointer to what we want to put a zero into. And then R6 will just have a zero in it. I don't have a good way to put a zero in memory unless I have a zero in a register. So put a zero into R6, then we can store R6 to put a zero into a histogram bin. Okay, so time for you to write code again. So we need to initialize R6 to zero, R1 to 27 decimal, and R2 to 3100 hex. So let's do those in order. So how do I put a zero in R6? I can do an AND. Good. Okay, so AND, R6, R6, zero. You've seen stuff like that before, right? All right, so how about R1 to 27? Can I do plus 27? So LC3 immediate for an ADD only goes up to 16. So I could do two ADDs, and I could add 16 or 13 and 14, but instead maybe I'll just do an LD. That'll mean I have to have the number 27 somewhere. So let's just store it in memory somewhere and use an LD. So LD, destination R1. What's the offset? We don't know. So it's going to be down somewhere at the bottom. After all of our code, we can put some data in, but we don't know where that is, so let's just leave it blank for now. How do we get 3100 into R2? Yeah, I could do another LEA. That's a good idea. That's not what I did, but that's equally good. I already have it on R0, right? So how can I get it from R0 to R2? Yeah, good answer. So add R2, R0, number 0. So add R0 to 0, put the answer into R2. So that'll copy R2 into R0 for us. I'm sorry, copy R0 into R2 for us. Good. So now we're ready to actually fill the histogram bin. So we set these up already, these three registers. And what we need to do is write a 0 from the R6 register into the memory location pointed to by R2. R2 is pointing now to our histogram, the start of our histogram. So we need to take R6, write it into that memory location. Then we need to increment to point to the next bin, which means add 1 to R2. And then we need to decrement the loop counter, which is R1, and keep doing that over and over again until the loop counter, R1, gets to 0. So that'll fill all 27 bins for us. Okay, so write one 0 from R0, I should say R6, sorry, to the histogram bin to which R2 points. I'll see if I can structure that. What? STR, right, store register. Good answer. Okay. What's the source register? So you want to store a 0, but R0 doesn't have a 0 in it, right? This was wrong. This was a typo. R6. Good. And the base register? R2? Yeah. So remember, R2 is now pointing to the histogram. It has the address of the first bin in the histogram by design. That's what we loaded into it up here. This put the address of the first bin into R0. This copied the address of the first bin into R2. Each time we come back in this loop, we'll be pointing to a different bin. So R2 is going to point to one of the bins we're going to store from R6 into the address, the memory address pointed to by R2. And the offset then is 0. And so that 0 gets added into R2. R2 already points to the right place, so we don't need to change that. Actually, almost never do you need to write anything other than 0 for your offsets. There's a few times, but pretty much not very often. Okay. So next step, point R2 to the next bin. I'll use the instruction for that. Add what? R2, R2, 1. Good. And then decrement the loop counter. Use the instruction for that? Add. Good. R1, R1, negative 1. Okay. Branch backwards until we've written 27 bins. What's the condition? Branch positive. Good. Okay. Oh, so I wanted you to remember R1 started at 27, so after the 27th time, it gets to 0. Right? So if we branch positive, like you said, where? Hmm. You should be able to answer this one, right? So where's PC? I always have to count. All right. So we're going to start here, right? So here. And then we want to go back to where? 3004. So 1, 2, 3, 4, but going backwards. So negative 4. Yeah. All right. So we're going to go back up here to where we stored. Oops. Sorry about that. Yeah. So the pointer's wrong, too. So another brain-o on my part. Okay. So, yeah, it should not point here. It should point to the STR. Sorry about that. All right. So now our histogram's filled with zeros. We've written eight instructions so far. So I wanted to just make sure you understand when we write this kind of stuff. These memory addresses over here, these are just for us. These do not appear in your code, right? In fact, well, I'll come to the next point. These memory addresses are just for us, just so we have some idea where in memory our code is falling. Just a convenience. You don't actually even write these in your program when you write binary, nor when you write assembly. And so the only time you're going to see these would be in the simulator, really, or on a piece of paper. The other thing I want to make sure you understand is these instructions, well, those are not bits. And at least for now, until next week, you have to write bits. So when you write your programs, these will be bits. Next week, we'll talk about assembly language and talk about assemblers. And then you can start writing code like this and tell the computer to turn it into bits for you. But for now, you still have to think about bits. It's not quite true because I'm not going to turn it into bits for you. But in theory, you should be thinking about how to turn it into bits. All right. So we still have a little bit of work to do for initialization. So we had all these registers, and we needed to set some of them up. So we initialized our histogram. We already initialized R0. It's pointing. Yeah, so it turns out the string is stored one ASCII character per memory location. So it's zero extended up to 16 bits and then stored one character per memory location. Not in binary, so it's a pain to write a file with a string in binary. But in assembly language, there's a directive called.stringz where you just put a string in your assembly file. And then the assembler actually writes one character to memory for you one at a time. So it's actually relatively easy to do so long as you're using the assembler as opposed to writing it out by binary. Yeah, if you looked at the typing in a number code, the messages, the error messages there, you actually did those by hand in binary ASCII in order to make it realistic for what you knew. And it's relatively painful. So if you want to play with this code, figure out how to write a string in ASCII so you can do something interesting with it before you don't do it in binary. All right, so we've got these other registers, right? So we have to initialize the string pointer. We need to point that to, I think it was, 4000 hex. So we'll just take the character from the string. We'll just read that in our loop, right? These ASCII constants we'll have to set up. And then it's temporary. We don't need to initialize. So we need to initialize R1, R3, R4, and R5. Here's some code. What do you think? Is that good? Are those all loading the same value? Why not? It's all PC relative, right? Good. So somewhere in memory, I put in the real offsets for you. Real offsets meaning if you go download the code, these are what they are. But somewhere in memory, I've got four consecutive memory locations that have the initial values for R3, R4, R5, and R1 in that order. And so these four load instructions pull those four sets of 16 bits out of memory, copy them into R3, R4, R5, and R1 in that order. So just want to make sure you understand PC relative does mean something different, does mean a different place depending on where the instruction sits. All right. So finally, we're ready to actually do some counting. So we can do some counting. So let's see, what's the first step? So we said, OK, we need to check if a character is null. So before we can do that, we have to actually get the character out of the string, right? So where was the string pointer again? Remember? Yeah, so I think what we loaded into a register, right? R1. OK. So how do I go get the thing at R1? LDR. OK. So LDR. And I want to put it in R2, right? So LDR, what's the destination register? R2. And the base register? R1. And then the offsets just zero. So this will go to the address R specified by R1. So whatever R1 is pointing to, we started it at the start of the string. Sasha? Because I'll show you, I'm going to play a little trick to use one constant twice. Basically, it's because, you know, there are 26 letters in both sets. So you need one constant for the difference between those two sets. And it's the same. So you can reuse that one. All right. So this is going to go to the memory address specified by R1. We started that at the start of the string. We're going to move it forward. So we'll look at one character at a time. R1 will keep adding one to it. But every time we go get one character out of the next string location, copy that into R2. So then how do I check to see if that's a null character? Do I need to do anything? I just branch, right? Branch on what condition? Oh, sorry. Forgot they're connected. Okay. So if I get a zero, that means I found the end of the string and I can go to the end of the program. But I don't know where that end of the program is, so I'll leave it blank. All right. So now we're ready to classify our character and increment one of the bins. So the first conditional we had was, well, is the character less than capital A? So let's define R3 as negative at sign. Why negative at sign? At sign is down here. So if I subtract at sign from my letter, what that will give me if I have a capital letter is a number from one to 26. So again, if I have a capital letter, one of these, and I subtract 40 hex at sign, then I'll have a number from one to 26 left. And I can use that to tell myself, well, which bin in my histogram do I want to increment? Because remember, those are also in order from one to 26 for A to Z. So we're going to store the difference of our subtraction back into R2. Let's go ahead and do that. So we'll add R3 to R2 and write the sum back into R2. So add R2, R2, R3. So now I can check whether the character was in fact less than capital letter A. So if I subtracted 40 hex and I want to branch forward, if the character was 40 or below, what branch condition should I use? Zero or negative? So branch, ah, that's for letter. I'm sorry, I screwed this up. Oh, I'm sorry. Yeah, yeah. So this is the opposite condition. Yeah. So we're going to handle the case first, which is the non-letter case. My apologies. So your answer was correct, Mohamed, but we're going to do the other case first. Let me go back and be clear on the diagram. So we're going to do this case first. We'll write the code for this first. So we're actually going to branch in the false case. So the condition for this being true was negative or zero. And so to go the other direction, we invert that, just flip all the bits. So instead, we get branch positive to skip ahead to the rest of the calculations. So we'll branch over the code we'll write next with a branch positive. But we don't know yet how long that code is. So if I find a character that's in the left region, the non-alphabetic region, so then I'm over here. So I just need to increment the non-alphabetic bin. And that bin is at 3100 hex. And I have a pointer to that bin in R0. R0 points to the non-alphabetic bin. So I can just increment it. So increment memory location. What's the instruction? Is there one? Yeah, I've got to read it, do a load, add one to it, and then store it back. There's no LC3 instruction that'll do that in one. So I'm going to have to have several. So what's the first one? Load. What kind of load? LDR. Because here's the address. I've got that address in R0. So I can use R0 as my base register. Where should I put it? Where should I put those bits? R6. I said, OK, R6 will be my temporary. I don't want to clobber some useful value, but I need somewhere to put it while I'm adding one to it. So let's put it in R6. That's a good idea. So no instruction. So let's do an LDR, R0, offset zero, and then put the value in R6. And then how do I add one to it? Add R6, R6, one. And how do I put it back? STR. Where? From R6 to R0, base register, offset zero. So these three instructions together will go to the memory location pointed to by R0, which we know is the non-alphabetic bin, add one to it, and put it back. So that will increment our non-alphabetic bin. So now we're ready to... we're finished counting that character. We knew it was a non-alphabetic character because it was less than capital letter A. We're done with it. We just need to go point to the next character. That's some code down below. We haven't written it yet. So we need to branch. So what branch condition should I have? Just always go there, right? So branch NZP, but somewhere. Don't know where yet. So we'll leave that one blank. But one thing we can do, we can actually fill this one in now, right? So what offset should that be? I hope I got it right this time. All right, let's do our counting. So where's PC? So we're going to fill in the offset for this branch. So where's the PC when this branch executes? Sorry, I should be clearer. Yeah, 3010, right? And where do we want to go? 3014, right? Okay, so we'll start here and we'll say 1, 2, 3, 4. It worked. Yeah, so these are, when I'm writing in sort of, this is actually assembly language. So any time we're writing in assembly language, you can use human notation. So the X means base 16, the pound sign means base 10. But you don't have to put leading zeros. Now, they are all two's complement values, so you can put negative signs. You can also just put the one bit. So there are a few ways you can write it. No, this is branching forward. Yeah, this is branching forward. Okay, any other questions or if you like? Okay, all right. So now we just handled the non-alphabetic case on the left of the ASCII table. So now we can take a look and see if our character is greater than capital Z. And if it is, we'll increment the alpha bin. I'm sorry, if it is, we'll go forward and handle this other set of three sets of characters here. If it's not, if it's less or equal to capital Z, we'll handle it as an alphabetic character. And so we want to subtract capital Z, but we already subtracted the at sign. And remember, we subtracted the at sign, we stored our character back. Having subtracted the at sign, we store the result back in R2. So now in order to compare with capital Z, in order to subtract capital Z, what we have to add is at sign minus capital Z. And so this, Sasha, this is where it's going to come in that later we're going to have back quote minus little z, which is the same number because there are 26 letters in both cases. But anyway, that number, let's just put that in R4. And we're going to throw away the result. I just want to know, I want to know, is it a letter? But I want my numbers from 1 to 26 to use to find the right bin if it is a letter. So I'm going to keep the numbers 1 to 26 if it's a capital letter. And so I'll throw away the results of this sum. I'll just use the conditions I get out of it to check whether it's in this blue region or somewhere over here. All right, so we'll compare with capital Z. So we'll add R4, which is at sign minus capital Z to R2 and write the answer, the sum into R6. So add destination is R6. And then the source registers are R2 and R4. So now if the character is not a capital letter, what should my answer be? If it's not a capital letter. So if it is a capital letter, then it should be negative or zero, right? So if it's not a capital letter, it should be positive again. So again, what we just calculated was original character. This add calculates original character minus capital Z. So if that answer is negative or zero, we know it's a letter, a capital letter. If it's positive, it's something else. So branch on positive to somewhere. But we don't know where yet. We've read blank. Okay, so we know, I should have crossed this one out, results not positive, results a capital letter. So what bin should we increment? So we have in R, what is it, R2, we have a number from 1 to 26. In R0, we have the 3100 hex. Yeah, that's right, and you would not have positive. No, remember we threw the answer away. We just used the condition code. Yeah, the number in R2 is still 1 to 26. And that's important, because we want to use R2 as 1 to 26 to get the offset into our histogram. So our histogram pointer, the first bin is 3100, that's in R0. So here's a hint, R2 now holds this. Remember R0 holds 3100. The A bin is 3101. So how would you get 3101 when R2 has a 1, R0 has 3100? Just add them together? Well, what if I had 26? So the Z bin is 3100 hex plus 1A, which is 26 in decimal, so 311A. So could I do the same thing? So all the time, I take R0, I add R2, that now gives me the address of the right bin, that letter's bin to go increment. So 3100, that's an R0, and then plus R2. So R0 plus R2, oh, okay. So you said add, right? So let's add. Where do we put it? I could put it in R6, but then I'd run into problems, because I need some place, when I'm going to go to memory and add a number, I need some place to put that one. So I guess I could use R7, but I told you never to use R7. Yeah, so that's a good question. What about R2? Do I need that anymore? I mean, now I've figured out what it is, right? This is a capital letter. So I know what it is. Can I just overwrite it? I don't need it anymore, right? Once I find the bin, I'm done with that letter. So let's just overwrite it. Let's just throw it away now. We'll put now our histogram pointer, bin pointer, into R2. So now I need to increment the address pointed to by R2. Of course, the answer is no. There's no LC3 instruction for that, but you know what to do, right? So what do we do? LDR, right? Same thing we did before. Before, we wanted to point just to R0. Now we point to R2. So LDR, where should we put the answer? Remember, we need a place. We just want to add 1 to whatever's there, right? So we just need a temporary register to store this value while we're changing it, adding 1 to it. So let's put it in R6. And the pointer is R2, so that's our base register. So this will go to the memory address R2, which remember now is the correct bin for whatever letter we just saw. And it'll pull those bits out of memory, the current count for that letter. So now we want to add 1 to that, which is what? Add R6, R6, and 1, and then put it back. I'm going to put it back. STR, good. So now you can more easily maybe see the reason that I didn't want to put our pointer in R6, right? Because we need another place to keep track of the count when we're adding 1 to it. So if we put that pointer in R6, then we have to put this set of registers somewhere else, right? And we don't have somewhere else. So since we didn't need R2 anymore, we just reused it here instead. All right, good. So we're done with that one. Now we need to jump down to the code to point to the next character. So let's branch always. We don't know where yet, right? But we can fill in that offset. So what is that offset supposed to be? Good. You're getting better than me at counting. Where's the PC? 3016. And where do I want to go? Down here. So let's see. 1, 2, 3, 4, 5. Good. Okay. You were right. All right. So now we can check whether the letter is less than capital A, right? And if it is, we'll increment the non-alpha bin. And if it's not, then we have to go do some more work. So we know it's not in here. We can compare with little a. If it's less than little a, we know it's in this region, right? So how do we compare that? We already subtracted at sign. So we'll add at sign minus the back quote, right? And that will give us the same thing we had before, number 1 to 26, this time if our original character was a lowercase letter. So we'll get the same mapping for our letters as before, but now the lowercase letters will be 1 to 26. Characters down here will be 0 or negative numbers. And then up here, we'll have to figure out later whether we've got one of those. So let's see. So we'll add R5 and store it back into R2. So I'm going to store this value in R5. That was our third constant. So I'll add that offset onto R2, put it back into R2. That'll do our comparison. So under what conditions do we have a character here after that add? Yeah, so negative or 0, right? Because we're subtracting this thing effectively from our original character. So in that case, in the N and Z case, I want to increment the non-alphabet. How do I do that? Yeah, we already wrote that code. So can I just use a branch? Will they? It's a good question. I think the answer is you want to write your code so that they're not. Yeah, so in this case, we're just incrementing the non-alphabet. We don't need to know anything else about the character other than, well, it's not a letter. So this code is relatively easy to get right. For the letter code, we have to make sure that, remember, we assumed that R2 was a number 1 to 26, depending on which letter. So if we're going to reuse that code, we have to make sure the same condition holds. That's a very good question. So in this case, we met your condition, though. We know it's not a letter. And we know that all of the other registers, we never change. Our constants, our pointer to the start of the histogram, stuff like that doesn't change. So let's just branch to it. So we'll branch. What's the branch condition again? Branch NZ, right? And then we actually know where that code is, I think, but it's off the screen. I didn't want to try to cram all the code on the screen, so we'll just save it for later. Besides, I'm getting tired of counting. I'll leave that to you. All right, so one last condition. So I know we're getting very close. All right, one last condition. So these are actually pretty easy, right? So one thing to notice, we want to subtract little z. So basically, we already subtracted back quote, so we need to add this number, back quote, minus little z. But that number is the same as at sign minus big Z. Both of them are just negative 26. So we already have that number in R4. So we'll just add that number in again, throw the answer away. Just use the condition codes. But under what conditions do we have a lowercase letter? So I just calculated original character minus little case, lowercase z. Yeah, so n or z, right? OK, good. So I can, if I want to go increment a letter bin obeying Muhammad's constraint, which is that, well, we better make sure that we have the same rules for the code, which we do. R2 now holds a number from 1 to 26, just like it did before. And so that tells us which bin we want to increment. So then we can just branch to it. So we designed that code to be reusable. So this is what you were asking about. It's important that you do that, that you've got the same set of register value assumptions going into the code, regardless of which way you go into it. Very good. All right, so let's handle the lowercase letters. Branch condition was nz. Go to that. Otherwise, just leave that blank. Otherwise, we know it's not a letter. And so then we can go to the code that handles not a letter, right? Just branch unconditionally. We're done. There we go. OK, so let me stop there. And we'll talk about the rest of it on Wednesday. Sorry for the long break. If you want to just look at the code, it's online. Download it, play with it. And we'll talk about the rest of it on Wednesday. So, again, I'll see you on Wednesday. Thanks. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Byeee. Thank you. Bye bye. Bye. Bye. Bye. See you later. They're leaving me behind. Multiple characters I can't pull out of my own. Terrible. I don't know if I had enough and it went like this. It just goes and it goes. They blew me off, I went to look at the created code. I pulled some data out. There's about 10 bits in it. I figured I had enough and I pulled quite a few. But there are, what about you? We got about ten. Alright. Ok. Do you have any more words in your code? For the maximum number possible?\",\n",
       " \"So we're going to spend all day talking about control signals. I know you're probably just dying to talk about control signals over break, had no one to talk about control signals with, but yeah, all day. So we'll start by just going through the control signals in the LC3 data path, looking particularly at those that are not involved in interrupt and privilege, neither of which we talked about in our class. So maybe the subset of those that you need to know about and understand. And then we'll look through fetch and decode states and map each of those states to the control signals that need to be generated to execute those on the LC3 data path. And then we'll walk through LDI execution. LDI is one of the longest instructions, so I just figured that's the biggest example. There's another couple examples worked out in the notes, I think add and maybe one state of branch or something. On Wednesday, we'll do control unit design that may go through some of Friday. And then on Friday, we'll start if not finish redundancy and coding, error correction coding, error control coding. So but before we get started, a funny thing happened over break. Go figure. Yeah. All right, so let's go. All right, so that really happened. That was not a fake picture. I don't know why. All right, so remember that the control unit, finite state machine and a processor takes as inputs, the signals coming out of the data paths. Remember, we developed our own little, our own little finite state machine with a data path and a control unit for that to do finding a minimum in an array, right. And so the LC3 is no different. There are signals coming out of the data path that the control unit uses to decide what state to go into next. And then there are also the control signals from the finite state machine or its outputs that go to the data path to execute the RTL using the data path. So let's take a look at these control signals, the LC3 data path. It's in the notes, it's in the back of the book, you can actually get it online pretty easily as well. And we will also of course give you a figure in the test which you've seen before and you can go get it off the wiki if you want to have a copy. We're going to ignore any control signals that are associated with interrupt and privilege. So if you read through the appendix of the book, it will talk about all of the control signals. Many of those you don't need to care about because they're only used for implementing interrupts or implementing privilege in the LC3 processor. If you take 391, so these are probably going to be left out for the most part of even 220. If you take 391 though, you'll make use of both of those ideas in the context of the x86 ISA and you'll see how they're really implemented and used. So let's start by breaking up the control signals in the LC3 into five groups. One group will be the register loads. So a bunch of registers that can be loaded in any given cycle. So each of those will have a load signal and those will be our register load control signals. So we'll go through those first. Then there are bus gating signals. Remember that in the LC3 data path, each of the outputs that can go onto the bus are gated by a set of tri-state buffers. So there are 16 wires on the bus. There will be 16 wires coming out of some given output, 16 tri-state buffers all controlled by one input to decide do those 16 bits go onto the bus or not. And there are actually four sets of those. So we'll have four bus gating control signals. The third set then is MUX selection. So if you remember the data paths, I could have popped up a picture here, but there are lots of MUXs and those are mostly for making decisions about whether to pick a 5-bit 2's complement offset or an 8-bit or a 9-bit or an 11-bit. So all of those MUXs will need configuration when we want to implement some RTL. Often they need configuration, maybe sometimes they need configuration. So those MUX selection bits are also control signals. That's our third group. The ALU, of course, implements add and not. And then there's also a pass mode that some of the RTL needs to just get something out of the register file, put it directly onto the bus. It passes through the ALU using the pass mode. So there are ALU function selection control signals. So that's our fourth group. And then finally, control signals to operate the memory. And so when RTL needs to make use of the memory, we need to tell it do you want to read or write, you need to tell it, okay, enable the memory in the cycle. So there are a couple of control signals for that. So we'll break them into those five groups. So the first group then is register loads. So again, each of the register load signals controls one or more registers. So I say sometimes more. It'll make sense the grouping. So for example, the grouping I had in mind here was the condition codes. NZ and PL have one control signal, you have to load them. They all either load or they don't load. So each of those signals is set, meaning it's one if and only if the RTL for the current finite state machine state changes that register's value. So you look at the RTL and if it changes that value, set it to one, otherwise you set it to zero because you don't want that register to change unless that was part of what you're trying to implement. So let me give you some examples or just actually walk you through each of these. So load signals include the MAR load signal. Do you want to load the memory address registers down here, this next to the MAR of course. The MDR right there. The IR instruction register over here in the control unit side. So the two memory registers, instruction register. This one you haven't seen before. It doesn't actually show up in the main data path diagram. BEN stands for branch enable. So we'll walk through this in detail because we're going to see how the decode state is implemented. But basically in the decode state, the LC3 processor uses these NZNP registers to calculate a branch enable using the IR bits for the little NZNP and then the big NZNP control condition codes here. And it calculates a branch enable bit, should the branch be taken or not. It does that in decode so that in the first state of branch execution it can use that to decide whether or not to change a PC. Yeah, Eric? Yes. Yeah, the state diagram. Yes. Yes. So I'll show it in a minute, but remember that the LC3 has three fetch states and then a fourth one is a decode that then branches out into 16 different states, one for each opcode. So decode is basically looking at the four bits of the opcode and transitioning into one state for each different opcode to execute that particular type of instruction. And I'll show you, again, I'll show you that diagram as we walk through things, pieces of that diagram. Okay, so that's four of them. There are actually three more. So zoom into another part of the data path. So there's LDreg, which is the register file. So only one of the eight registers will change. So which register depends on what input you give on the DR, the destination register input. But if you want any of the registers to change, you need to set LDreg. So there's a load for the register file. There's a load for the condition codes. Typically this thing will be set whenever you're writing, doing an ALU op or a load. Remember that the condition codes are set for the loads and the ALU ops. So here's a load control signal for the condition codes. You'll notice that that's just calculated by whatever value is on the bus. It goes in through this logic and then into the condition codes and is latched there. And then the last is the load PC signal up here on the PC. So there's seven of these different register load control signals. So you might wonder, well, what are these things write? So you can look at the data path for each of the registers and see what they write. MDR's new value either comes from the bus or from memory. A lot of them come directly from the bus. So MAR, IR, the register file and the condition codes, all of their values just come directly from the bus. So whatever's on the bus will get copied into the register. You don't have any choice. If you want to write something into those, you have to put it on the bus first. PC's new value comes from a MUX, PC MUX in particular, with one MUX input from the bus. So that's this one here. So we're going to have to control that to decide what the PC writes when we tell it to write. And then finally, branch enable is just loaded based on CC and IR. Again, it's not in the data path picture, so I won't show you, but it's basically just loaded directly from CC and IR. And so there's nothing to configure. If we tell it to load, it'll look at the current values of the condition codes and the current value of the instruction register. All right. So the second group then is the bus gating signals. So again, you'll see again when I pop up the data path, but a bunch of the outputs are gated to go onto the bus. And so we need to make sure that we only send one one to each of those sets of tri-state buffers. So the tri-state buffers keep those outputs from being written onto the bus. But if we send a one enable signal to a particular set of tri-state buffers, that will put those 16 bits onto the bus. So we need to make sure only one set of 16 bits goes onto the bus. So the register loads, we only set to one, the ones that we want to change. The bus gating, we only set at most one of them to one. If we set more than one to one, we're in trouble. So let's see what they are. So you can just look at the tri-state buffers to see where they're going to be. So there are four sets there. So the first one then is the PC. So we can take the PC register and write its contents onto the bus. So that's gate PC. The MDR, so we can take the memory data register and write its contents onto the bus. So that's down here. The results of the ALU. So if we do an add or an and, or if we pass something from the register file out onto the bus, we turn on gate ALU to do that. And then the last one is gate MARMUX, which is this MUX up here, and its output is gated onto the bus. This is the thing that we use for address generation for memory operations, loads and stores mostly. But sometimes PC relative addressing too, we might make use of MARMUX. All right. So the third group of control signals then is our MUX select signals. So we've got the register loads, the bus gating, and now MUX selection. So we've got a bunch of MUXs, actually six MUXs. So the MUXs are going to be used to control, well, what value do we put in the PC? What's the destination register in the register file? What source register one in the register file? And then what's the memory address that we want to use? There are actually three different MUXs for memory address generation. One controls the source register, one controls the offset size, and then one controls whether we want directly from the IR or we want something out of the adder, out of the memory address adder. So, oh, so the other difference between these and the previous control signals is if MUXs are not used, if the output of the MUX is not used, the input can be don't care. So not the case for bus gating. You can't leave it floating because then if you end up with more than one one, you're going to get shorts. Registers, same thing. You don't want to register to change, so you're not going to leave a register load control signal as a don't care. The MUXs, on the other hand, if the outputs are just discarded, who cares what the outputs are? So we can pick anything. So we can leave their select inputs as don't cares for these MUX controls. All right, Eric. So I mean, the MUXs aren't always even connected to the bus, right? This one just goes into the PC. But this MUX's output never goes anywhere except into the PC. So if you're not changing the PC in a given cycle, this output is ignored. So who cares what it is? Make sense? Yeah. So basically, anytime you have an output that's being ignored, you don't care what the setting on the MUX is because it just pulls some random bits and then it throws whatever the random bits are away. So it's OK. Yeah, and I'll give you details of how you can check to see whether it's used. I mean, this is the example for the PC MUX. The only use is to change the PC. So if you're not changing the PC, if load PC is 0, then PC MUX's setting can be a don't care. And if you are changing the PC, you need to set PC MUX correctly to get the right value. So what can you use for PC MUX? Well, there are only three choices. You can see them there in the diagram. The encoding we're going to give you, right? So don't worry about memorizing it or anything. If you happen to have your sheet later when we figure out bits, then you can look it up. But if we want PC plus 1, this path over here is for fetch, for example, the encoding is 0, 0. If we want to take from the bus, you can see the bus comes down here. You can write that into the PC. That would be 0, 1. And then this line here is coming out of the address generation adder here for branch and jump. That's this path. And that's the 1, 0 input. 1, 1 is not used because we only have three things we need. Okay, so second MUX, the destination register is also MUXed. So there are three choices here as well. Now, if we're not writing to the register file, it doesn't matter what destination register we pick, right? So if we're not writing to the register file, if LDREG is not 1, then DR MUX input can be don't cares. But if we are writing to the register file to get the high bits of IR, the high bits after the opcode, I should say, then we put in 0, 0. If we want R7 or R6, we can put in 0, 1 or 1, 0, respectively. These are actually used for things that we didn't really cover in our class. So the only things that we're going to talk about in our class would use the 0, 0 input for DR MUX. But that MUX is there, so just to explain it. One can also pick different values for source register 1. So source register 1 is the, remember there are two registers you can read from the register file in any given cycle. So this is the left side in the diagram. So source register 1 is then used by both the ALU and the address 1 MUX. So if you are doing an ALU op, right, and then writing that onto the bus, then you need to make sure that this SR MUX setting is valid. Or if you are doing, using the address generation with this as the input, then you need to make sure it's valid. Otherwise, it could be don't cares. So you need to kind of back propagate. If you're using it in any way, then you don't want to leave it as don't care. If you know you're not using it, you can leave it as a don't care. So the choices here, 0, 0, 0 will give you IR 11 through 9. So if you look at the instruction encoding, those are the source register bits for stores. And so this is how you would set up for a store is to pull those bits out as your source register to write those to memory, write that register to memory. For ALU ops, jump, load, LDR and STR's base register, IR 8 to 6, you set 0, 1, and then I'll give you that register. And then finally, the 1, 0 setting will give you R6, which is again, nothing that we've seen. It's actually the changing privilege implementation on the LC3. So you don't need to worry about it. But it's there. Yeah, so these are all clocked. I mean, the entire LC3 data path is on a single common clock, just like all of the other designs in our class. Yeah, yeah, this is still clock synchronous state machine with a common clock, one finite state machine. All right. I mean, the thing to remember, when we talked about the, when we did the example of mapping the code into a finite state machine, I introduced the idea of RTL is that we define the RTL for the state, but the RTL actually happens on the rising clock edge. So the control unit exerts all of these control signals, and then the changes happen on the rising clock edge. So they'll be true in the next cycle. So that's why, for example, this IR somewhere, IR's here. So in the third fetch state, we're writing into IR, but we have to wait until the fourth fetch state to look at the bits in the opcode in the IR, right, the 15 to 12 bits for the opcode, because until the fourth cycle, they're not there. And in the third cycle, we copy them from MDR into IR, but then only in the fourth cycle are they present in the IR to use them. All right, so let's go back. This is the next MUX. This is actually two of the MUXs, two of the three for address generation. The third is the MarMUX, I'll show you in the next slide up there. So the first one here is choosing a source register. So this line comes from SR1, this line comes down from the PC, and address one MUX just chooses between them. So if you configure it to zero, you get PC. If you configure it to one, you get SR1. Now, obviously, if you're not using the output of this adder to write back into the PC or to write onto the bus through the MarMUX, then you don't care what this address generates, right? So you can set it to don't care in those cases. This second one, you can see several sign-extended offsets. So there's a six-bit, that's for base plus offset mode for LDR-STR. There's a nine-bit that's used for branches, and there's an 11-bit that's used for JSR, which you haven't seen. But those three different sign-extended chunks of the IR or a zero, right? And so you can see the four choices and the encodings for address two MUX down over there. Once you've decided those two values, those go into this adder, get added together and go into MarMUX, your other choice is over here for MarMUX. Yes, that should be 10 to zero. Thank you. Yeah, sorry, that's a typo. This one is right. Yeah, thanks. Okay. So on the left here is something we didn't talk about how traps are implemented. If you're interested, it's using this approach to go to this memory address basically. So you take your eight-bit trap vector zero, extend that to 16 bits, and that's your memory address. So that zero mode of this MarMUX is used to execute a trap instruction. All of the things that we know about, we didn't talk about trap implementation. So everything we know about will go through this address adder here and go out through the MarMUX. So that would be setting one in the MarMUX. And that's it for the MUX settings. So those six MUXs. All right. So notice that these two MUXs are used by both the PCMUX, so the output here of the adder gets used by the PCMUX and the MarMUX. I kind of said this already, but if either one of them is used and MarMUX is only used if gate MarMUX is one, PCMUX is only used if load PC is one. So if either of those is turned on, then you have to set these three address generation MUXs. If they're not, you just don't care. You can set them to don't cares. Make sense? Good. Okay. All right. So ALU selection bits. So we have four functions. You know three of them, of course, add, end, and not, we put in as part of the ISA. The fourth one is necessary again, so that we can pass values from the register file out onto the bus to go places like the MAR or the PC for control flow or other operations. So the ALU output is only put on the bus when gate ALU is one. If gate ALU is zero, it's just thrown away. So we can just set the ALU function to don't cares. And then finally, the memory operations. So memory only needs two bits to control it. So it needs to know, well, do you want it to operate? Right? So there's an MIO enable for enable the memory. It's actually memory and IO, which we didn't look at the memory mapped IO implementation, but this is the control signal name. So when that's equal to one, memory does something. When it's equal to zero, memory does nothing. So the read write bit only matters when memory enable is one, right? When memory enable zero, read writes a don't care. When it's a one, it's defined as follows. A one is a write, read write, I'm sorry, read R.W is one means a write, R.W is zero means a read. So that's it for the control signals. So this is just a summary of all the control signals. So we had seven different register loads with four different bus gating signals. The MUXs, there are four two bit signals and two one bit signals. So that gives us a total of 10 bits. So this is number of bits. ALU function selection, we needed two bits and memory, we had two one bit signals. So if you add them all up, you get 25. So every FSM state in the LC3, you have to specify 25 bits to say, well, how do you implement that particular state? Any questions on this before we start looking at examples? Well, you can set them to don't care. But if you're calculating logic to build a finite state machine, you've got to put bits. So just like in any other logic design, it's going to output real bits, however you build it. So in your design, you can put don't cares. The thing you build will make zeros and ones. I don't think so. I compared them before. I compared those sheets with my notes and with this. Yeah. So again, there's six MUXs, four of them are two bits and two of them are one bit. So four times two plus two times one is 10. Okay. Okay, so let's see. So let's do fetch and decode. So this was the top of the finite state machine diagram is figure C2 in the back appendix in Pat and Patel. But this is the fetch part up here, these three states, and then this is decode down here. And then after that, you go into instruction execution. So let's go through these one by one and work out the control signals that we need for each of the fetch states and for the decode state down here. And so hopefully, you remember, you will need to know this on the final, I mean, you'll have the diagram, but you needed to know it on the midterm too. So MAR gets PC, PC gets PC plus one. That's the first fetch state. So let's go think about, well, what do we need to do for the control signals to make that happen? So let's start with the registers. So which of the registers need to change? Which of these values should be one? Yeah, so LD MAR, right? Because we want MAR to change. So make that a one. What else? The PC, right? Good. Okay, what about the rest of them? Zeroes? Not don't care? Yeah, zeroes, right? We don't want the registers to just load random bits, right? So they better all be zeroes. Okay. All right. So now let's take a look at how we would implement this thing. So we want, let's see, MAR gets PC. So PC is up here. So we've got to send it across the bus down here, and then put it in the MAR, right? So it's going to have to go across the bus and go down into MAR. And then the other part was PC gets PC plus one. So here's PC, it goes through this little plus one thing here. We've got to take it through the PC mux and then put it back into PC and do both the blue arrow and the green arrow in the same cycle. So it's worth when you're trying to figure out how to set things up, just looking at the data path and maybe sketching out, well, how are the bits going to move from place to place? Because anytime you go through a mux, you've got to make sure the mux is configured properly, for example. Okay. So we've got these two bits. So what do we put on the bus? PC, right? So you can look back at the picture, right? This gate PC, you got to get the blue line to go through there onto the bus. So that better be a one. So what are the rest need to be? Zeroes. Good. Okay. So those are the bus gating signals. So which muxes matter? Yeah, PC mux. What about Marmux? No. What about this one or this one? No. DR mux and SR mux in there. They matter? You're not writing into register file, you're not using the output, right? So they don't matter. So only the PC mux. So what should PC mux be? The PC plus one, right? Which was zero, zero. So, okay, what about the rest? They're all don't cares, right? Because none of them are used. So we can just fill them all up with don't cares. All right. So what about the ALU and memory? So here's the ALU. Gate ALU is off, right? So it's not used. Memory is down here. We're not doing anything with memory, so it should be turned off. So what should the values be for ALUK, MIO enable, and read write? So let me take them one at a time. ALUK, what should it be? I'm hearing zeroes and don't cares. So remember, the value of ALU is being thrown away. And then gate ALU is off, right? So if it just spits out some random bits, so what? They're just discarded. So it's don't cares. What about MIO enable? It better be zero, right? Because otherwise, we might end up doing a write, right? Especially if we leave read write as a don't care, right? If it's a read, maybe that doesn't matter so much, but then memory won't be ready when we need it. It'll be busy finishing a read we didn't need. So let's just set that one to zero. What about RW? That's a don't care, right? Because we set memory enable to zero. So memory is turned off. No, actually, no. So this is a clock synchronous sequential design, and the clock timing has to be such that the longest combinational logic in the system is slower than the clock speed, than the clock period. And that's the limiting factor, actually, in a lot of high speed processor designs. So in a lot of your desktop or laptop, what sets the clock speed is something like the adder time or the time to do simple arithmetic operations. That's what limits it. So that's, we might, if we have time, I'll show you a tree adder, which is a faster version, it has shorter paths. And those are the those are what people actually use in real processors. Because the ones we looked at things like the ripple carry, they're too slow, right? And they're what set the clock speed. So but in most of these designs, you find your slowest combinational logic, and they don't take more than one clock cycle. If they do, you have to set it up so that it's it's managed across multiple clock cycles. So for example, a floating point unit in a typical modern design might take four or eight, depending on whether you're just adding or multiplying four or eight cycles to complete one operation. But they are usually designed in the high performance systems to accept new operands every cycle. So you can start a new addition or a new multiplication every cycle, but you still have to wait that long to get your answer back. So. Okay, so, all right, so we'd finish this one, right? So we've got we've done fetch one. I just want to make sure people notice this is not a don't care. Right? So don't get confused by that. So now we can go on to fetch stage two, fetch state two, which is this one, right? So now we have the PC and the MAR, we can go get the instruction out of memory, take its bits, put them in the MDR. So this is MDR gets M at MAR, memory at MAR. So which registers are going to change? Just MDR, right? Anything else? That's it. So all zeros, right? Okay, so those are our register load signals. So let's see. So we have MDR gets MAR. So data comes out of the memory and goes through this MUX, which is controlled by MIO enable anyway, so we don't need to do anything there, goes into the MDR. Now, you might actually notice there's this funny path through this other MUX over here. This is part of the memory mapped IO system, and we didn't talk about it. So, so just ignore that part. There's actually simpler diagrams of the data path, but this is the one I had. So I just kept this one. This MUX will be configured to forward this output back. So the path is okay. So what should be put on the bus? Nothing, right? We could technically probably leave one as a don't care, but let's not do that kind of thing. Because then we have to worry about well, so what bits go where? So we'll just set them all to zero. So nothing's on the bus. It's just floating. So what MUXs matter? Yeah, this one is set though, right? This is not in our control. This one does matter, but MIO enable, we're going to have to make sure it's turned on to get the memory output into the MDR. This path is actually what we use for stores. We set up the MDR before we write the bits into memory. But when we're fetching, we need to read memory. So that's coming through here, and it's already going to be controlled by MIO enable signal. So do any of the six MUXs we talked about, PC MUX or address one or two MUX or SR1 MUX, do any of those matter? There's nothing going on in that part of the data path, right? That's all just nothing. It's all turned off. Not turned off, but there's nothing going on. So none of them matter. So what should I do? Just set them all to don't care, right? Put all don't cares there. Good. What about ALU? ALU is not used, right? But memory has to do a read. So what should I put here? So what about ALU? Don't cares. What about memory IO enable? A one. What about read or write? Zero for read. I did them one at a time. Thanks. Okay. So these are then the settings for memory. We want to turn memory on and tell it to do a read. ALU, we don't care. It's being thrown away anyway. So that's it for the second fetch state. So what about the third fetch state? So we finished this one. We finished this one. So now we have to write RTL, well, write control signals to implement this RTL. So we take MDR, copy it to IR. So let's take a look. So what registers are going to change? Just IR, right? Anything else? It's just that it. So a bunch of zeros. So here's the data path. So MDR has got to come out across the bus, go into the IR. There we go. So what should be, which gate bus gating signal do we need to set? MDR, right? Anything else? Better make sure the rest are zero. You can never have more than one bus gating signal turned on. Okay. So which MUXs matter? None of them. Because all the MUXs are up here in this part that I didn't even show. So all don't cares, just like the second state. Okay. What about the ALU and memory? Not used, right? Memory is down here. ALU is over here. Not used. So what should these be? Don't cares here. Zero. And don't care. Same as up here, right? We're using ALU or memory. All right. So that's it for fetch. Fetch is done. And then we have one more state to do, which is decode. So in the decode state, we're calculating branch enable. And branch enable, you might remember the little n bit is IR11, the little z bit is IR10, and the little p bit is IR9. So I just took the same terminology, or rather the same RTL out of the FSM diagram out of Pat and Patel. But when we've written it, it's been little n anded with big N, little z ended with big Z, little p ended with big P. That's our branch condition. So that is calculated by some logic that's not shown in the data path and then copied into branch enable in the decode state. So which registers are going to change? Just branch enable, right? So what do we do with the rest? Zeros. Good. OK. How about, let's see. So I can't show you in the data path because there's nothing there. It doesn't show up. So just calculate directly from the condition codes in the IR. So what should I do with the bus? Just zeros, right? There we go. Zeros. Yeah, there's nothing flowing across the bus. There's some special combinational logic, takes the bits out of NZAP registers, looks at IR, does some combinational logic and writes into branch enable. So there's nothing that's going on the bus. What about mux selection? Do we care about any of them? There's nothing being used, right? So we don't need any of them. So just don't care about any of the selection bits. What about these? Yeah, so. So remember in the branch instruction, so let me get that back up. There it is. In the branch instruction, we've got encoded in the instruction, the parameters for which of the condition codes we want to consider. And we write them as little n, little z, and little p. And so IR11 is little n. IR10 is little z. And IR9 is little p. Yeah. That's part of the instruction. The IR is the instruction. Yes. So no, I take it back. Branch enable, one reason for writing it in decode is it's ready to go when you execute the, when you get into the branch execution. If it's not a branch, you don't need to look at it. So it's just like the mux selection bits. If you can calculate it, then you just ignore it. It doesn't matter. So you're actually, the LC3 is in fact calculating the branch enable for all instructions, but only using it for branch. And it'll just be garbage for the rest of them. It doesn't matter. Yeah. Yeah, it's in the control block. It doesn't appear in the data path. That's why I didn't highlight it for you. It's not there. I think there might be a separate figure in the back of Pat and Patel, but I didn't pull it out. Yeah. IR is the instruction register at 16 bits. IR is not signing. It's a long way back to a full data path. The sign extension is for the two's complement offsets that are fields of certain instructions. The instruction register itself is 16 bits, and it takes all 16 bits to represent an instruction. It's pulled out of memory. Remember, it's pulled directly out of memory through the MDR, from MDR directly into IR. It's never sign extended in the fetch path. Yeah. Okay. That's no problem. Okay. So where were we? I think we've done these, right? We've done these. All right. So what about these? So all we're doing is calculating branch enable and decode. The whole reason for decode is so we can get to, we can look at the opcode and get to the start of the execution state for the correct opcode, right? So do we need to do anything with ALU or memory? No. All right. So what should I set these to? XX0X? They're not doing anything in that state. Okay. Yeah. Yes. Yeah. So that was the question Sasha asked earlier. Yeah. So branch enable is calculated before you've decoded, right? During the decode state. So you don't know what kind of instruction it is. You don't even know if it's a legal instruction, right? Because not all opcodes are legal instructions. So you're going to calculate it every time. But it's a garbage bit. It's a garbage bit. You only use it if it's a branch. You're always going to calculate it and then just ignore it unless it's a branch instruction. Any other questions on this? Okay. So I think that's it, right? That's our four. So these are the whole table with all four fetch state and decode state and all of the signals. So that one's in the slides for you. It's not really something we need to dwell on here. Any more questions before we look at LDI execution? Okay. So let's do LDI execution. All right. So here's execution of LDI. It starts up here. These are other loads. So just ignore these two states. LDI comes down here and then goes all the way down to this, which is one, two, three, four, five states, right? So it takes five states to execute an LDI. So let's work out all the control signals for those five. So we'll start up here in the first execution state. We'll call that LDI one. And what we have to do there is take the nine bit offset. I'm just using the RTL from the FSM diagram. This is sign extended from nine bits in the IR, then added to the PC and then stored in the MAR. So what registers change? Just MAR, right? So the rest should be what? The zeros. So let's look at what happens. So let's see. We have MAR gets PC plus offset nine. So offset nine needs to come out of the IR. I don't know if you can read it, but there's a sign extension of the eight to zero bits here that will go up into address two MUX. So we're going to have to pick that sign extended version out of address two MUX, and that'll go into the address adder. So that's step one. For PC, it's going to have to come down this way and go through address one MUX. So that's this direction. So then those two get added together. PC is green, offset nine, sign extended to 16 bits is blue. Those get added together. That has to then go through the MAR MUX, across the bus, and then down into the MAR. So that's purple. So we need those three parts. We have to configure all of those parts so that this data flow works through the data path. All right. So what do we need gating? The MAR MUX, right? So up here, this thing needs to go out on the bus. So MAR MUX needs to be a one. What about the rest? Zeros, right? Again, only one gate signal should be on. If you write on the final, multiple gate signals turn on. I'm going to cross it out. So don't do that, please. All right. So what about the MUXs? Which ones do we care about? Yeah, the address MUXs, these we better set up. This one we better set up. What about PC MUX? Not used, right? PC is not changing. And that's only used if we're going to change PC. What about DR and SR1? They're not used, right? So we can ignore those MUXs, too. So those three we need to set, and then the other three we don't care about. So let's just fill in the don't cares. So those three we don't care. What should address 1 be? Does anyone remember or have the encoding? I don't even remember it. Okay. Zero. What about address 2 MUX? One, zero. Okay. And then MARMUX? Pretty sure this one's a one. Okay. But again, you know, the right thing to do here would be to look at the table, which would be in the back, right? So you should always keep the table with you. Don't try to memorize this stuff. Okay, so those are MUX selection signals, and that will implement these three lines here to move the data around. The ALU and the memory are both unused, right? So what should these values be again? XX, zero, and X, right? Good. Okay. Second LDI state is this one here. Take memory at MAR, copy the bits from memory into MDR. Does that remind you of anything? Second fetch state, right? Good. Okay. So we don't really need to do the RTL again, right? We did it already. So we know how to do that RTL. We just take the bits we already wrote, copy them into this one for the same control signals. Okay, so the control signals here were MDR changes, so we'll just fill that in. The control signals here, let's see, I think, I think nothing, right? Yeah. For this one, we weren't using any of the MUXs, so they were all don't cares. And then for this one, we have to do a read, so that's a one, read write is a zero for a read, and then ALU is not being used. So all they did was copy the bits out of the fetch to state, basically. Same RTL, same control signals. Okay, so then we're in the third LDI state, which is one, two, three, this one here. So we're going to take MDR and copy it back to MAR. Remember, LDI is the one that says, oh, I got 16 bits out of memory. Oh, that's like an address. Let me go read from that address, right? So you're going to copy MDR over into MAR and then do another read. So let's go figure out how to do that. So MDR goes to MAR. So which registers am I going to change? Just MAR, right? Good. So the rest, zeros. Okay, so here's the data path that would happen. So we're going to take MDR, copy across the bus into MAR, like that. So what needs to be gated onto the bus? The MDR, right? That has to go into the bus so we can copy it into MAR. So the rest are zeros. Which muxes matter? None, right? All the muxes are up in the data path above this little part here, and we're not using any of them. So what should these signals be? All don't care. All right. ALU and memory are not used, right? So here, XX, zero, X. All right, well, we're three-fifths done. So now we have state four. So one, two, three, four. So we're down here. This happens to be used by the other loads. So let's see, this one is LDR, this one is LD. So this is used by all three types of loads, but it's going to take memory at MAR, copy it in MDR. We did that one already, right? Same RTL. So why do we need more than one state? Eric? Yeah. Yeah. So it actually, you can come from different places and go to the same state just like these do, but what matters is actually the output path, right? So remember when we talked about merging states, we said, well, if they're the same outputs and the same next states, right? So these have the same outputs, right? The outputs, remember, are the RTL. The RTL is identical, right? But the next states are not. And that has to do with what you were saying, Eric, about setting things up for the addressing for the different modes. But unless the next states are also the same, we can't merge the states. All right. So we have to go implement this RTL again, or rather, we need to copy the control signal bits because it's the same. So let's just do that. So all we're going to do is copy from LDI2 down to LDI4. So there, that's done. Done again. Done again. Done again. All four are done. All right. So now we have one last LDI state. It's this one here. So copy MDR into the DR. So we finally have the value we've loaded from memory sitting in MDR, 16 bits. We want to copy it into the register file, store it into some destination register specified by the instruction, and set the condition codes based on that value. So what registers are going to change? So the register file, right? So I better put a one there. And what else? The condition codes, right? So I better put a one there. What about the rest? Just all zeros. Okay. All right. So then let's look at the data path. So how do these things work? So we've got a copy from MDR across the bus and store that into the register file. The only way we can write into the register file from the bus, right? So go along that blue path. And then the other half is set CC. So remember, the condition codes are always set by what's written on the bus. So this green arrow is just coming off what we've already written onto the bus, going through this little block of logic here and then being stored in the condition codes. Whatever value was being stored, it would be calculated negative, zero, or positive and latched into the condition code registers. All right, so what do we need to gate onto the bus? MDR? And then the rest better be zeros. Okay. So which of the muxes matter? Yeah, so DR is going to matter, right, because we're writing into the register file. PC mux will not matter. The address generation muxes won't matter. They're all being thrown away. And what about SR1? Are we using it for anything? No. So that's not going to matter either, right? So only DR mux is going to matter. So DR mux needs to be set to take the input from the, I think, 11 to 9 bits for the source register in the store. So that'll come with a zero, zero setting on DR mux. And then the rest of them are don't cares. So you notice we almost never use too many of the muxes in a lot of these things, right? Occasionally we'll have to set some muxes up for address generation or things like that. But often they're all don't cares. All right, ALU and memory are both unused. So same as before, XX0X. So that's it. So there's our whole table. So yeah, in order to implement an LC3 processor, you have to go through the whole state diagram and do this. But as you can see, a lot of it's pretty easy, right? So on Wednesday, what we'll talk about is then taking all of these tables with all of the RTL and thinking about, well, what are the different ways we can take those bits? We won't do them all. But what are the different ways we could take those bits and then actually build the control unit? So we'll look at a few different ways to do that. Any closing questions before I end? Okay, thanks.\",\n",
       " \"Okay, I think it's three o'clock. So today we're going to start with systematic decomposition. So try to give you a way to think about breaking problems down into pieces and do that until you get to the level of instructions. You've already done a little of that in the lab, I know, but this is supposed to be a little more systematic, hence the name. I'm going to spend some time, probably most of today, just talking about what does it mean to do a good job of designing a piece of software, mostly just to tell you that you'll take classes later, so don't worry too much now. I'll give you a couple hints of things, habits you can start to form now. Then I think either we'll start this or it'll come on Friday. We'll do another big example, calculating letter frequencies in a string. So we'll take a string and count up the number of each kind of letter, independent of case, and also the number of non-letters. So we'll spend some time thinking about how we want to do it, we'll decompose it systematically, and then we'll write the code for that. That'll be our last example, actually, in binary, and then we'll talk about assemblers next week after the review session. So review session's Monday, as you hopefully remember, midterms Tuesday night. I have actually information, so the Beta Kappa Nu review session, they move back an hour relative to last time, so it's 3 to 5 now, same day, Saturday, same place. As always, we can't guarantee that they're going to give you correct answers, but usually they're pretty good, but we can't guarantee it. And then there's other resources up here, so I think you've seen these before. You know this slide. Two more times. Well, one more time, sorry. Deadline's Friday. If you haven't done it, please do it. All right, so how do you write a program? So you've seen a few examples so far, but it'd be nice, given a task, how do you break it down? How do you turn it into a flowchart, turn it into LC3 instructions? It'd be nice if there were some systematic way to do that. How did we do it? Well, systematic decomposition is an approach to trying to program. It's basically saying, well, let's take our task and refine it. In the book, I think they refer to it as stepwise refinement. But basically, take your task and say, OK, let's break that down into simpler things. So let's start, we'll just take the main task, whatever we're trying to do in human terms, and break it apart, and then we'll take those things we broke it into, and if they're still too complicated to do with one, two, three handful of instructions, we'll break it again. We'll keep doing that until the end result is something where every little piece can be implemented with a few instructions, a few LC3 instructions. So it's actually not a bad approach to doing things. You'll see later, it's not actually terribly systematic, but it can help you think about what you can do. So I want to go through the pieces, and then show you how we map those into LC3. You've seen them all before at the start of class. So we'll talk about these pieces, three kinds of simpler tasks, and then look at how we map each one of those pieces into LC3 memory. So before we start that, I want to make a couple comments about programming in general. I talked to people in office hours yesterday. Generally speaking, you really want to get out a pencil and paper before you start sitting in front of a computer and writing code. Sitting there trying to look at bits, especially, is really painful, and you'll get yourself very confused. You really want to go in before you sit down to program, having an idea of how your program will work. And usually what that means is you drew a picture on a piece of paper, you wrote some notes about what each register holds, so you know what's in the registers, instead of just sort of making it up on the fly as you write instructions. If you have your algorithm clear in your head, and when you sit down, you've got your code in the LC3, you can simulate it when it does something wrong. I say when, not if, because everyone writes bugs. Then you can say, well, what was it supposed to be doing here? And then you can figure out why it's not working. Much easier to debug your code. In fact, this is a little bit of a forward illusion, because when you get into writing larger programs, it's very, very easy to have a bug in your code and you can't find it. Because you look at your code, you're not actually reading the code. You're thinking, yeah, this is what I meant to do there. So having someone else come in and look at your code, they look at it and they don't know what you're meant to do. They only know what the code is. So there's a practice called code reading, where you have someone else come and look at your code. And it's much, much easier for them to say, well, this is broken. Because for you, you can sit there for literally hours. And it looks right, because you're just looking at what you had in your head. But if you have nothing in your head, then it's even harder. Make sure you have a model in your head before you go sit down and do it. So draw some pictures, draw some flowcharts, think, then sit down to write your program. So when you do get ready to write your program, I would suggest, especially when you're starting out, that the first thing you do is take all of that model and write it out in English as comments. So say, well, first I'm going to do this. Next, I'm going to do that. You're going to want to put those in anyway. Because when you hand in your code or when you hand it off to someone else, we expect you to write some comments. So put the comments in first, and then write the code around the comments. You'll find it's much easier that way. Don't leave comments as an afterthought. Comments are not something you add so you can get those last five style points or something like that. You should try to do it this way. Actually, so there's a story. And I've forgotten the student's name. But it was one of Wenmei Hu's master students. So they had some tricky code that they needed added to their compiler infrastructure for x86. So the student came in, and he did his master's adding this code. It took him about a half year or a year to add the code. And then maybe about six or eight months later, he started working on his PhD. And it turned out they had to make some changes to another part of the compiler. And that didn't interact correctly with his code, his module of code that he had added. And so they said, well, can you go adjust it, make changes to meet the new interface of the compiler? He said, sure, sure. So he went back, and he looked at his code. He kept looking at his code, and he didn't have any comments. And he realized he couldn't understand his code. So he had to throw it away and start over. So don't do that to yourself. Make sure you can make some notes about what you did so that when you go back and look at your code, you can understand it. So systematic decomposition. So what do these three things we can use look like? You've seen them before, actually. So they're just the same flowchart pieces we looked at with C code. They correspond to C statements. The iterative construct you'll see is a little bit simpler. So here's the first one. So you can say, well, I've got my task. And in order to accomplish this task, I need to do several things. And I can just do them one at a time. So it's just a sequence. So I say, well, first I'll do the first one. Then I'll do the second one. Then I'll do the third one. Maybe there are two. Maybe there are five. Maybe there are 100. It doesn't matter. Just a sequence of things. So I can break the task down into a sequence of smaller tasks, each of which is easier to do. So that's first approach, first pattern. The second pattern is the conditional. So we can ask the question, well, what if in some cases I want to do one thing, and in other cases I want to do another thing? Then I can have a condition. So I can have this test condition, phrase my condition so that it's either true or false, some kind of Boolean expression, not in bits necessarily, but some kind of Boolean expression. And it either is true or false. And if it's true, I'll do this then subtask. And if it's false, I'll do this else subtask. So that's the second pattern. We can take a task and break it down into a conditional. Either of these boxes could be empty. So you could say, well, if the following is true, I want to do something. Otherwise, I don't want to do anything. That's OK. These boxes don't have to both be filled. What if you have more than two cases? You could say, well, sometimes I want to do thing one, other times thing two, other times thing three, other times thing four. Well, you can just keep breaking these things down. So you can take your else subtask, for example, and break it down into another conditional. And now I have three cases. I've got the test condition. One is true over here on the left. One is false, but two is true here. And both one and two are false here. And if I wanted four, I could also break down the then case over here. Or I could break it down, break down this case or that case. So I can just keep breaking things down over and over again and have as many different cases as I want based on these conditions. So the last one, the last approach, or last pattern, rather, is the iterative pattern. So this one you saw is the for loop in C. This one is substantially simpler. So you say, well, I want to do something a bunch of times. I want to do it until this test condition is false. So I'll test. And if it's false, I'm done. And otherwise, I'll do the thing, the subtask. And then I'll go back and do the test again. So this is simpler than the for loop. The for loop, remember, had some initialization and some update. You could add those in. You could break this first down into a sequence where you did your initialization, then add this iteration, and then take the subtask down here and break it up into whatever you wanted to do, and then an update. So you can reconstruct the for loop out of this systematic decomposition process. But your basic iteration is, well, test for something, do a subtask, go back, test it again. Keep doing it until the test becomes false. So those are the three pieces. So flowcharts are nice, but you can't just kind of cram a flowchart into memory. Memory is this linear sequence of addresses. And you know that the LC3 is just going to go address to address and execute instructions, maybe that have some control flow or something like that. But you can't draw diamonds or boxes or start things or things like that. So how do we turn a flowchart into a sequence of instructions? Let's take a look at each of these three constructs, and we'll then show how we turn each one into LC3 instructions. So sequential is pretty easy. The LC3 and fetch, it'll add one to the PC. So if you just lay instructions out in memory, then here's your tasks. If you say, OK, let me write the instructions for this first subtask, and then the instructions for the second subtask, I'll just put after the ones for the first subtask. And then for the third subtask, I'll just put after the instructions for the second subtask. The LC3, if it starts up at the top here, will simply run through first subtask, second subtask, third subtask, and we're done. So this is the simple case. So for the conditional construct, we have to be a little more careful. So of course, there's instructions associated with each of these three pieces. So we might put the test first. So we'll generate the test, and then we can generate the instructions for the subtask, for the then subtask, and put those here. And then for the else subtask, we could put those instructions down here. So what else do we need? Is that OK? Just do it this way? Yeah. So some kind of branch, right? So maybe here, I can branch on false. So I'll set up whatever NZPN bits, NZNP bits, based on my test. I'll set NZNP to the right values. So this is branch is taken, is the branch opcode. This branch will be taken if the test is false. So if the test is false, where do I want to go? I'm going to go to else, right? Good. OK, so now am I done? Why? Because you want the subtask. So if this test is true, then I don't branch, and I execute my then subtask. So that's good. Then, oh, then I'd fall through, right? Then I'd start executing the else subtask. OK, so what should I add here? Another branch. What kind of branch? I'm hearing different answers. So is there any case in which I want to go execute else after that? No. So I always want to jump over the else instructions, right? OK, so let's put 111 for safety. I mean, it might be the case that as the last instruction, you always load a negative number, in which case you could have a different set of bits here. But why bother? Don't make it dependent on this code. Just say, OK, I'm always going to branch. Where do I branch to? Down under here, so out of my instructions for this construct on the left. OK, good. So this is how I would set up a conditional construct in LC3 memory. So I need a couple of branch instructions. And if these pieces of code get too big, I can't use branches, right? I'll have to replace them with jumps. But that's something we'll worry about when you start writing huge amounts of code, which won't be in our class. All right, so then the last one is the iterative construct. And this has two blocks of code. So we can write the instructions for generating the test, write the subtask instructions. And what else do I need to add? What should I put here? So I generate the test. Should I then just go execute the subtask? I should branch. Branch on false or true? On false, OK. So if the branch condition, I'll set this up so that the test is false. If the test is false, where will I go? Down here, underneath, right? OK, good. And so am I done? What else do I need? Ah, so I need to go back from here up to this up here, right? OK, so branch, what conditions? 1, 1, 1 again, right? So always branch back up, do the test again. Only after this test is false do we jump down to the bottom, get out of this block of code. So this is how we linearize our three constructs to put them in memory. All right, so here's the bad news. So systematic, the word in English suggests that you just follow some formula. You apply some rules. You don't have to think too hard. You just methodically go and break down, break down, break down. Unfortunately, that's not the case with this, right? So computers cannot program for us. If this were so systematic, then we could just tell the computer, well, just break it down, right? Take the task, break it down, write the instructions, and we're done. But unfortunately, it's not the case. So usually, you'll have a lot of choices, which means you'll have many different ways to solve a problem, different algorithms. And you have to think about, well, maybe some algorithms are better than others. We haven't even talked about what does it mean to be better, right? What's a better algorithm? So we'll talk a little bit about that in the next couple of days. But don't worry too much. Learning to program all takes a lot of time. So this is a first class. We've seen programming for a lot of you. Don't worry too much if you're not getting the greatest algorithms out when you sit down to write your lab. It's not that big of a deal. We will try to push you to do things like loops instead of making 10 copies of something. But other than that, don't worry too much. All right, so let's talk a little bit more about good design. So a couple of things you should think about just starting off as you start to form habits of writing programs. One is, if something is simpler or feasible, then it's probably better. If you're not sure if something is going to work, don't try to do it that way. Find a way that you're sure it's going to work and write the code that way. Once it's working, then you can go do your improved design after you commit your code to some version and the working version. The other really bad thing is when you get your code working, then you think, well, I can make it better. You make it better, but you break it. And then you don't have a copy and subversion. You no longer have a working program. So always, always commit after you make your first code work. But if you have a simpler approach, it's probably a better approach. It's easier to read. It's easier to write in a way that you know your code works. So simplicity is good. Avoid making things more complicated than they need to be. Try to use clear, obvious techniques. Second bullet, you want your program to be easy to understand as well. So take the time to do things like style, structure, indentation, comments. But also organize your functionality so that it's easy to go test it. Write your code in a way that you can make sure that each piece of your code works and that you can also do system-wide testing. So I'll give you some specific examples maybe at the end of today. But think about how am I going to make sure that what I wrote actually does what I wanted. So think about that as you think about your design. All right. So here's an example just to get you started thinking. So imagine you want to do a survey. So I'm going to do a survey of n people in a room. And I want to ask them 20 questions. And they're all going to answer from 1 to 5 for each question. So then I want to take all those answers. And I want to calculate the average over the n participants. So we're doing some important public opinion poll. So how are we going to do this? So you can do this the usual way. We'll call it method one. So I make a form. And I put all 20 questions on the form with 1 through 5. You can circle. And I hand each of you a piece of paper. And then you circle your numbers. And then we collect them. So then what do we do with that? So we've got a bunch of forms. We've got maybe 80, 90 people in the room. And we've got a bunch of forms of 20 questions on them. And how do I calculate the averages? So do I iterate first over the questions or iterate first over the forms? So for example, here's a couple of ways to do it. So question first is on the top. So I say, well, for every question, I go through all of the forms. And I add up that number from each form for that question, so f of q. And then when I'm done with all the forms, I divide that number by n, the number of forms. And that gives me an average for that question, which I can then print out and then go on to the next question. Or I can do the form first. So I can make an array of all zeros, so 20 zeros. And then I'll take a form. And I'll add for each question, I'll add one number into one of my array elements. And then I'll put the form away. And I'll get the next form. And I'll go iterate over forms first. Then when I'm done, I'll take my array. And I'll divide each entry by n and print it out. And that'll give me the average of all the questions. So which is better? Well, so if I iterate over questions first, I only have to remember one sum at a time. Maybe I even keep the sum in my head. So that's nice, a little easier that way. On the other hand, if you think about just moving paper around, now I have to go through these forms, all of the forms, 20 times. So that's 20 n forms I have to get out to look up, you know, question 15, question 16. I have to look that up every time. That's kind of a pain, a lot of paperwork. But what about this other approach? What if I iterate first over forms? Well, then I have to keep track of 20 sums. I can't keep track of 20 numbers in my head. So I'm going to have to have another piece of paper that has my numbers on it now. On the flip side, I only have one form at a time. And I read the questions in order. So I get a form. I go one, two. Very easy and very fast. So there are pros and cons to both. But well, why did we have to do it that way? So here's another way we could do it. We could have 20 pieces of paper, one for each of the 20 questions. And I could say to everyone in the room, well, make sure that you come up and put a number from 1 to 5 for your vote for each of the 20 pieces of paper. So if we do it that way, then we can do this algorithm. For every form, every question, set a sum to 0. And then for each person on the form, each number written down on the form, we'll just add to our sum. And when we're done, divide by n. And then we get the answer. Then we can go to the next piece of paper. So get kind of the best of both. So one sum at a time. Each paper has one sum. And we only have one form at a time, because you just read all the answers off of one piece of paper. So why don't we do surveys that way? Which one is better? Depends what we say, better, right? So what's better about method one? I mean, why do you think people don't do surveys the second way? Why don't we just say, look, I'll post a piece of paper up here. And everyone come and put a number on there. Right? Yeah, so there's confidentiality issues, sort of. I mean, if all you're going to write is a number from 1 to 5, that's probably as anonymous as giving you a piece of paper where I can maybe even coordinate your answers. Yeah. Yeah, so more typing. OK, but we're doing all this by hand. So yeah. Yeah, yeah, so participation is probably going to drop. And I have no real way to gauge it. I've got a form with a bunch of numbers on it. So I can't say, well, you didn't actually do your form. Whereas if they make you turn in a form, I mean, we didn't say this would be anonymous. I could have even have you put your name on it. So if I don't get an answer sheet from you, I say, ah, you didn't want to participate. So there's a bunch of different things. Good answers. So easier to organize. So I can say, well, I'm going to put my name on it. And I can say, well, I'm going to put my name on it. Good things, good answers, so easier to organize. Because if I really ask everyone to line up and find 20 pieces of paper, it's pretty challenging just to say, well, did I get all of them? Are you going to remember which of the 20 you held? You probably need a piece of paper to keep track of them too. Easier to avoid cheating. So what about the person who comes down? They really think this question is important. So they write 55555. Who stops them? How do we know it was them? Participation too. So how do you know whether someone participated? How do you encourage them to participate? Because the work's all on the people now. So well, you've got to go track down that last sheet of paper. So there's a bunch of reasons that we wouldn't want to do it that way. But just out of this simple question, there are lots of different trade-offs for the different approaches. So that's kind of my point. It's not easy to know, well, what's the right way to do something? There are many, many ways to measure goodness for algorithm design. I hope you're ready. It's been a long lecture so far. Bits. No bits yet. OK, you ready? I need your help. Can someone help me out here? Anyone, just raise your hand. Who wants to help me? Yeah, Daniel. So B to C. Good. I can do that. F, good. G, good. H, like that? Awesome. That is good. That is really good. OK. Thank you. That was helpful. Is that OK? You can be assistant walking director. That's a better idea. Is it good? Can you do this? OK, teach my computer. OK. LC3 instructions, anyone? Do I look like I'm in good shape? Yes, it has to be the shortest path. I don't want to walk all around. I want to go straight to strawberry fields. I'm already hungry. Yeah, but I'm not. I'm in my office. This has to be independent of those kind of things. All right, anyone? Any ideas? Yeah. Oh, that's a good idea. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. I'm going to do that. That's debatable. Oh, so you want to just give me, for this map, you'll give me all the answers? Because I actually have the Google Maps database. If you could just fill in all the answers for that, then we're good. All right, so I have an idea. Too late. Too late if you know a good answer. So we're going to list all the paths. So this is step one. We'll just list all the paths. Then we'll measure all the paths. Then we'll pick the shortest one. Sound good? Come on. Let's try it. So we need a more complex data structure, which is, yeah, that's beyond what I want to talk about now. Let's just figure out how we do it. We can map it to LC3 later. So list all the paths. So let's see. I'm at B. If I can go to A, I can go back. Good point. And then I'm at B. If I can go to A. And then go to B, A, B, A. How long are you going to let me go here? All right. So that's maybe not that. All right, so that was a little silly of me. OK, so let's do simple paths. A simple path in math is one where you only visit any node once. So we'll only list the simple paths. So OK. Yeah, this one's infinite. The one I was showing you is infinite, right? So that would not be a path that would take us. So I won't list that. That would take me to H. Yes. So you can end up, Benny, right? Yeah, so Benny's pointing out that if I take simple paths, I may run into a dead end. So that's not a path to H. So I won't write that one down. Yeah, yeah. But I want strawberry fields today. You guys think I'm so flexible. All right. All right, so let's try this again. So I'm going to start at B. And then I'll go to, say, C. And then I'll go to F. Oh, this is good. This is good. And I'll go maybe over to E. And then how about down to L? And then M. And then N. And then G. And then H. There's one path. All right, now we've got some more paths. Thank you. OK. So it turns out, yeah, that's some bad news. Turns out that for some graph with p nodes, the number of paths is actually exponential in p. So I had another good idea. Are we good? Maybe not. You didn't seem excited. All right, so here, let's try this. This is my last try. So let's have a queue of nodes. And then we'll keep track of the best previous location. So for every node, we'll say, well, it came from some other node. And then we'll go through the queue one at a time. A queue is just a line. So we'll go through the queue and process the nodes one at a time. And we'll add any unvisited neighbors from that node to the queue. We'll just put them into the queue. So I'll show you what I mean. So here's our queue. And so we haven't put anything in yet. Here's the previous for each element of the queue. So we'll start here at CSL. And we'll put that in the queue. And it didn't come from anywhere. That's where we started. So I'll just put a little dash there. All right, so let's process node B. So where can I go from node B? So A first, right? So I'll put that one in the queue. And then D. All right. And then E. And then one more, so I can go to C. OK, so what we did to process the element is we said, well, for everywhere we can go directly by walking around one edge, we'll add those nodes to the queue, but only if they weren't already there. And so remember this caveat here. Only if it's unvisited, so only if we haven't already put it in the queue. So there was our first exploration. So B was finished. So now that's done. So let's go on. The next element in the queue is A. So let's explore node A. Where can we go from A? We can go down here, right? Yeah, we already saw D. So we're not going to add that to the queue. It's already there. We can also go to B. B is also there. All right, so we're done. Nothing to do for A. OK, so A is done. So what's next? D, good. OK, so we can go to K. So we'll put K. Now, notice that K came from D. We're processing D now. So to get to K, we'll come from D. So we'll put D down there instead of B, like we did for all these others. All right, so let's see. K, what's over here? E. So we've been there, right? Then we can go up this way to B. Been there. And then we've got one more direction, right? Been there too. OK, so I think we're done with D. D is done. And what's next? E? So we can go left to B. Already there. Go down to L. And that one's not there yet. So we'll add that in. And we'll say, well, we came from E. Coming from E to L. We can go over to F. That one's also not in our queue yet. So we'll add it in. So F comes from E also. And then we can also go up to B from E. But B is already in the queue. All right? Then we'll do C next. So from C, we can go to B. But that's there. Go to F. But that's there. So C is done. OK, next is K. Where can we go from K? To J, huh? So we'll put that one in. So J comes from K, because that's a new one. We can also go to L, right? But L's there. It's already here. And then we can also go to D. But of course, D is there. That's where we came from, K. OK, so K is done. Not too much more, but we still haven't gotten to strawberry peels. I'm a little disappointed. All right, so what's next? L? L can come from K, but K is already there. L can come from M. OK, so M comes from L. All right, and then L can also go up to E. But E is already there. All right, so F is next. So F can come from E, but it's already there. M is already there. N we can add in. So N comes from F. We can get there from F. G we can add in from F also. And then C is already there. All right, that one's done. So how about J? Anywhere we can go from J? Just K, right? We've already been there. That's how we got to J. K is already in the queue. So let's skip that one. Or rather, just process it quickly. What about M? So we can go to L. L's there. N's there. And F's also there. So there's nothing to add. So that's processed. Next one is N. Put that down. Where can we go from N? G, M, F. So there's M in the queue already. There's G in the queue already. And there's F in the queue already. So nothing extra. Yeah, Arun? Are you faking it? All right, so let's see. What's next? Process the next node. So here we go. There's F. That's already in the queue. There's N. Hey, there's H. H comes from G. I sort of made this unnaturally long. So we got our goal. So how do we get the path? Go backwards. So here's H. So let's see. So H came from G. Where'd G come from? F. Good. Where'd F come from? E. Good. Where'd E come from? E. Good. And that's our path. So we got B, E, F, G, H. Same path as before, I think. Oh, almost, I think maybe we went to C before. I don't remember. OK, excellent. So now my computer can solve this problem. So that approach is called breadth-first search. So it looks at nodes in order of distance. So it seemed like we put a lot of stuff. That's because the place we were trying to go was the furthest away in the graph. So I just kind of trimmed the graph a little, didn't put anything that was further away. But if you look at the distance in terms of number of streets you have to walk along to get from CSL at B to these other nodes, you'll notice that for each of the elements in the queue, the number of hops, as we say, or the distance to those nodes is strictly increasing. So to get to A, D, E, and C, you just have to walk along one street. To get to K, L, and F, you walk along two streets. To get to J, M, N, and G, you walk along three streets. And then to get to H, you walk along four streets. So in fact, you could take some big map database and you could run exactly the same algorithm, and you'd only look at the nodes that are at the distance you want to go. You actually wouldn't walk around the world trying to find things. You would simply look in the local area, and this would work quite well. So it explores the nodes in order of distance. So you can use it with some commercial map database, and it'll be fine. So BFS was actually invented by EF Moore, who invented also more machines and some other things. And once you've seen it, all of you could probably do this. If I give you another map and I said, well, find the shortest path here, then you could probably do that pretty easily, pretty straightforward. People used to think of it as artificial intelligence. It used to be, well, there's these great AI techniques. You can do breadth-first search. You can do depth-first search. Depth-first search, you just put the things at the front instead of the end when you add them in. But it has different properties. So what's the message? Well, finding the best algorithm for something, probably most of you didn't know how to do this. When I said, oh, teach my computer how to solve this problem, probably most of you said, well, I don't know. I know how to do it. I look at the map, and I said, go this way. But probably most of you didn't just say, ah, just make a queue. I mean, if you've seen it before, probably you did. Experience will help. Classes will help. All of the copies have to take these two classes. I know a lot of EEs also take 225. You may also want to take 374. They're both good classes. Don't worry in our class about finding ideal solutions. You'll have plenty of time to learn. And classes and experience will help you in that regard. So what can you do now? So I mentioned a couple of things earlier. Always start with a mental model. Write lots of comments. Structure your code clearly. When you're writing binary, put the spaces in so it's easy for you and someone else to read. Indentation and alignment for C and assembly code. Really, don't leave your spaces out, because if you're looking at a group of 16 bits, you're going to have a hard time noticing that one of them is wrong. It's hard enough just looking at them with the spaces. But without the spaces, it's almost impossible. Some other tips. So try to avoid repetition. It's really tempting sometimes to say, oh, I've got some other code that almost does the same thing. Let me cut it and paste it into place. You're better off kind of generalizing your code. Often, bugs get copied when you do that. Chances are good the code you're copying has a bug in it. And when you do that, you're copying the bug. And people spend lots and lots of time tracking down bugs they've already solved, because someone cut that bug and put it somewhere else too. And so they find one bug, and then they don't realize it's been cut and pasted somewhere else, and they have to solve it again later. That's also a common thing people end up doing, just because people tend to think the same way and make the same mistakes. So there's something called regression testing we'll talk about in 220 that will help you get rid of common errors. Did a question make it in there? OK. All right, another thing you can do is try to design your code to make it easier to test. I mentioned this earlier. You have finite time. And you're going to spend finite time testing your code, making sure it works before you turn it in, before you ship a product, whatever your deadline is. You don't have forever. You've got a fixed amount of time you're going to spend. So if your program is easier to test, then you'll do more testing. If your program takes a long time just to get it ready to test in a simple way, then you'll do less testing, because it's hard. It's painful. So for example, if you look in the lab, you've been playing with the simulator. There's a graphical simulator. There's a command line simulator. The graphical simulator actually just sends commands to the command line simulator. All the testing is done on the command line simulator to make sure it works. And then the GUI stuff is actually quite difficult to test. So we don't test it that way. Testing something that only has a GUI interface means that there's some human there playing with a mouse, typically. It's really slow compared to having a computer try to test a lot of things at once. So make sure that you have a testing interface that allows you to do testing really quickly. And then your code will be more solid. So we have a few minutes left. Let me get you thinking about this for Friday, because I think we'll spend most of the day developing it and writing code for it and things like that. So let me tell you what the problem is. So let's say that we want to do the following. So I'll give you an ASCII string, which is a bunch of characters in memory, sequentially in memory, terminated by a null, which is a 0 in ASCII. And I want you to go through that string and find all of the occurrences of each letter, so A to Z, regardless of case, and count up. So how many A's, how many B's, so forth. And also count the number of non-alphabetic characters. So I want to count for each letter and account for the number of non-alphabetic characters. Are you ready? We'll do systematic decomposition. There. Build histogram of letters and non-letters. And we're done. That's my part. You do the rest. So sometimes people ask me, well, what's a histogram? So let me make sure everyone knows that. Histogram is a function on a set of categories. There's one way to explain it. So here's a couple of examples. So here are the number of leaves on my favorite tree in September. And this many were green, and this many were yellow, and this many were orange, and red, and brown, and this many had fallen off. And then I measured again in October. I made these data up. These are not real data. But I measured again in October. These are both histograms. So they show you for some categories here, leaf colors, or whether they've fallen off the tree, what's the expected frequency, or what is the measured frequency of those categories. So those are histograms. So what we want in our problem is a count per letter. So for the string, how many A's? Either case. How many B's? Either case. Blah, blah, blah, blah, blah. How many Z's? So how would you do this? Yeah, Nathan? 42. Yeah, so that's one thing we're going to have to do inside. Subtract 40 hex, maybe, right? The below letter A, yeah. All right, so what I meant was, how would you, as a human, solve this problem? So let's do this string as an example. Yeah? I mean, I think whether or not the value is out of text, like, I mean, you could use random letter that has a number of hexes. Yeah, yeah, yeah. So you can, Eric's saying, you can basically check for A, and then maybe check for B, and so forth. I think what Nathan was saying is you can actually subtract and maybe use that difference from 1 to 26 as an index in the memory, for example. So there are a bunch of ways you can do it. So all of those are good answers. What I'm looking for, though, is a higher level process, right? So if I literally said, well, do this example. Give me the histogram for this example. What are you going to do as a human? And maybe we can model our program based on what we do as humans. So how many A's? Three? The string. Try this string as an example as our string. Three A's, right? OK. How many B's? Oh. How many C's? Zero. Good. How many D's? Good. How many E's? Two. Good. All right. That's enough, right? All right. So maybe something like this is probably what you did. So for every letter, set a count to zero, and then go through each character in the string. And if you see that letter, add one to your count, and then store the count for that letter in your histogram. So when I said, oh, how many A's? You probably look through the string. There's an A. There's an A. There's an A3. And I said, how many B's? You went through the string again. You went through the string 26 times or 27 times. That's a lot of times through the string, right? Here's another example. Everyone have their textbook? OK. How many A's in Pat and Patel? Everyone got that number, right? How many B's? 42. Exactly. All right. Oh, yeah. So the real question, if I had asked you to do that, let's say you were getting paid. You're getting paid to count the number of A's and B's and C's in Pat and Patel. How would you do it? Would you do it the way you did it with a little string? Would you say, let me look for A's? OK, I'm done. Let me look for B's. Or would you do it a different way? Yeah, go ahead. Can you repeat the question? Yeah, so you can go through the whole book. And then maybe I don't need to use sophisticated data structures. Maybe I can have a piece of paper with letters A through Z on them. And every time I see the letter A, I'll make a mark on A. When I see the letter C, I'll make a mark on C. But then I just go through the book one time, which is a lot faster than going through Pat and Patel 27 times, I think. Although you should enjoy reading Pat and Patel, but maybe not 27 times. So here's another algorithm. So for a longer string, maybe what we do is we set all our histogram to zeros. And then for every character in our string, we'll go through it once. And then we'll just increment the appropriate histogram bin. So if we see the capital letter T, we'll go to the T and increment it. If we see the number 5, we'll say, well, that's not a letter. We'll go to the non-alpha bin and increment it. So figuring out, well, which bin, that might be a little complicated. So we're going to have to figure that out. There's one more I want to show you. We have a few more minutes. OK, good. So what if instead we did this? What if instead we said, well, let's make the inner part simpler. I don't want to do a lot of calculation. I want to just make it easy. So let's build a bigger histogram. Let's have, let's see, ASCII has 128 characters, right? So I have 128 characters. And then what I'll do is I'll go through the string one time. And every time I read an ASCII character, I'll just say, oh, that's ASCII character number 35 hex. Let me go to entry 35 hex, add 1 to it. And so do no computation at all to figure out what it is. I'll just go add them up, whatever the index is, whatever the character is. I'll use that as an index into my array of 128 things. Add 1 to it. And then when I'm done, well, there's lowercase a and uppercase a. So I'll add those two numbers together. And that'll give me my a. And lowercase a, uppercase a, I'm sorry, lowcase b, uppercase b, add those two numbers together. Done. And then I'll add up the rest of the things that aren't letters. And that'll give me my non-alpha. So now finding the bin is easy, right? It's just, well, whatever the character is, there's 128 of them. Go to the right one. Add 1 to that memory location. But then I have to add some extra initialization. Instead of 27 bins, I have to do 128. I have to do a little extra work down here. So there's some trade-offs. It's a little more work at the beginning and the end, a little easier in the middle. But what's better? So maybe I'll leave you with this. We'll talk about it a little bit. And I'll leave you to think about it. So what is the metric? When you get into later classes, or maybe some of you have seen this, you might talk about things like computational complexity, which usually map to something like, well, how many instructions does it take? Or how much time does it take? How many cycles, clock cycles? How long does it take to run your program? That's going to have a lot of factors that change the answer. But basically, if you're looking at how many things you're doing in your program, then that's a measure of complexity. And you can measure it explicitly with number of instructions. You can measure it explicitly with number of clock cycles, wall clock time. Another way you can measure things is, well, how much memory do I need? Do I need only a few bytes? Do I need a kilobyte? Do I need a megabyte or a gigabyte? Or do I need a terabyte? Do I need to have blue waters to run this thing? Hopefully not, because there's only one of those. So if you need that much memory, maybe it's not your best approach. But those are all trade-offs. These are different ways you can measure things. So what about for our problem? Does it make a difference, do you think, for long or short strings? Certainly, probably you would approach it differently for a long string and a short string. Again, try to think about it seriously. If you wanted to do Pat and Patel, you really don't want to do that first algorithm. But if you're going to do a short string, is it really worth getting a table and saying, oh, this string starts with a T? For the short string, it's probably easy enough to just look at it a whole bunch of times and look for specific letters. So maybe the answer depends on the length of the string. What if your string is sorted? What if all the letters are in order? That's kind of crazy, right? But to make it easier, then you just count As. And when you get to the end of the As, well, then you go to the Bs, and you count all the Bs. Then you count all the Cs. You're still going through the string once, a lot easier. But why would it, you know, the string wasn't sorted, right? Except you can sort it. And you can sort things. And you can do that in linear time for this particular type of problem. So in fact, meaning time proportional to the length of the string is what I mean by linear time. So I could sort it first and then use a different algorithm. So there's always lots of different ways you can solve these problems. So let me leave you with that thought and think about what's good in these things until Friday. Thanks.\",\n",
       " \"section. Okay, so if anyone wants to chat with me, feel free to stop by. Policy update as of the trouble with the lab, not this week, but last week, your lowest two labs will now be dropped instead of just your lowest lab since AWS, I guess, killed our software right before the deadline. And then I just wanted to do a quick review because a couple of people that asked me about finding all the notes and videos and stuff like that. So if you go to Google, and if you can remember how to spell my name and type it, then you can find my homepage and then you can go down here to classes 120. Oh, sorry, it still says 198 JL. That's the original name. F16, you go there and then on this links page, you have all the online exercises, you have all of the PowerPoint slides, have all of the recorded video lectures from the class, and then the C code examples and then some extra stuff if you want it. There's also a copy of the reading notes here. So if you're looking for those, they're here. Easier to read like this. PowerPoint or PDF viewer doesn't want to do what I want right now. Anyway, so those are there. And then obviously the top thing takes you to the wiki where all the rest of the class resources are. So hopefully everyone knows how to find everything. So just do a quick review. There we go. All right, so today, oh now it's in, I look funny. I don't know why it went to that mode. Anyway, so we're gonna start by doing a checker for uppercase letters, more examples of building with abstraction, then talk about multiplexers or muxes, spend a little time on decoders. We may start sequential logic today or we may not get to it until Monday. I didn't put it on the list, but we may get there. So I want to do another example and show you a few different ways that you can you can break up problems to make them easier than going all the way down to KMAPs. So let's start with one where we say, well let's have an ASCII character, 7-bit code, C, C6, down through C0. And let's make a piece of hardware that will tell us whether that ASCII character is an uppercase letter. So you may or may not remember an ASCII A is this bit pattern which is hex 41, capital Z is this bit pattern which is hex 5A. And so how do we check? If I give you this, these six or seven bits rather, how do you tell me is this a letter or not? Muhammad? Yeah, that's yeah, exactly. That's one answer, right, is we can use some comparators. I'll put that off, I'll do it a slightly different way, but that's a good answer. Yeah, so these numbers here we're gonna have to feed into the comparator somehow, right? Yeah, good point. Okay, so we'll come back to that answer. So here's another way we can do it. Go down to truth table. Can you help me out? Is this one an ASCII character? No. Okay, what about this one? Got a lot of slides here. So let's hurry up. All right, so maybe, maybe, I mean a lot of these are zero, right? Maybe we can just skip to the ones that matter. So what if we just take our truth table and we break it up into pieces? So we got 128 rows, but most of those rows are zero, right? So let's break it up into eight of them. So each of those eight pieces of 16 rows will be one value of C6, C5, and C4, right, the three leading bits. And then we can solve each of the little pieces, the groups of 16 rows, with a kmap on four variables, right? So we could do it that way. So maybe we don't need a kmap for some of those, right? Maybe we don't need to do eight kmaps. So remember, A is this thing, Z is this thing. So what about this truth table? So C6, C5, C4 equals 0, 0, 0. What's the function? Zero, right? So you didn't need a kmap, right? You want to draw a kmap? I know kmaps are fun, so maybe we do it. No, we'll just skip it. By the way, I want to make sure you know when I write something like this, this means C6 equals zero, and C5 equals zero, and C4 equals zero. We'll write that increasingly often. So no ASCII character with those upper three bits is an uppercase letter, right? So that function is just zero. So that was relatively easy. So which of the eight functions are not the zero function? Yeah, so anytime we have C6, C5, C4 is 1, 0, 0, or 1, 0, 1, some of those are letters. All the other possible values of those three bits, those are just the zero function, right? So out of eight different kmaps, six of them are zero. We're done, right? We've got two more. So if we break up the truth table, then we can solve a lot of it pretty quickly. Well, six of them are zero. So let's call that function T4 before I'm getting out of just this number here, right? So 1, 0, 0 is four in decimal. We'll call this one T5, and that's it. So let's just do the kmaps for those two. So here's the kmap for T4. What do you think? SOP or POS? You want POS? Okay, the max term, right? So what is it? Yeah, add them all together, right? That one? Okay, okay, good. We're done with T4. So it gets pretty easy at some point. Okay, so here's T5. I claim POS is slightly better again here. So what are the loops? Yeah, I want to do POS again. Yeah, sorry. So this one here? Okay, good. What is that one? Like that? Okay, and what's the other? The two horizontal zeros? Okay, and that one's this? Good, okay. So that's it, right? Those two factors. All right, so then how do we put them together? So we've got T4, we've got T5 with six zeros. We could write down if we want. I won't write them. So T4 applies when C6, C5, C4 is 1, 0, 0. T5 applies when C6, C5, C4 is 1, 0, 1. So what should I do? All right, so what if I, let's see, so I want this one to apply when this is true. Can I write an expression for this? So I need to AND T4 with C6, C5 prime, C4 prime, right? So if I write C6, C5 prime, C4 prime, that means these three are equal to those three. Is that right? Okay. So AND T4 with C6, C5 prime, C4 prime, AND T5 with what? C6, C5 prime, C4, okay. And then do what with those two results? OR them together, right? Good. Okay. So that's my answer. So it looks nasty, but it's not really that bad, right? It's pretty small, pretty fast. It's not two-level logic. It's a little more, but we still had to do a little bit of work, right? So you already know the easier way. So this is the question we can think of it as, right? We know how to build comparators. So instead of saying, let's go build this expression, we can instead say, well, I know how to build a comparator. I know this is a contiguous range because on homework number one, we asked you some question about why did we put digits in a contiguous range? And you said, well, so you could do translation to binary numbers, right? And well, why do we put letters in a contiguous range? So you could do this kind of thing. So you need to check, well, is C greater or equal than A and less or equal than Z? If it is, well, then it's a letter. And if it's not, it's not an uppercase letter. So here's two comparators. So I built two seven-bit comparators using our bit-slice approach and just plopped them down in my diagram. Into both A inputs, I put the C, the character in ASCII that we're comparing. Into the left comparator, I'm going to put hex 41. That's the letter A, remember? And the right comparator, I'm going to put the letter Z. That's 5A. And then I have to go back and look at my representation, which I didn't rewrite for you guys. But remember that if you've got Z0 on, that implies that C is actually less than 41 hex. That A is less than B. The Z0 output is 1. And if the Z1 output is 1, that implies that the A is greater than B. So C is greater than 5A. So if either of those conditions are true, it's not an uppercase letter. So if C is less than the letter A, then it's not an uppercase letter. Or if it's greater than the letter Z, it's also not an uppercase letter. So I have a NOR gate down here that takes those two NORs them together and gives us our uppercase function. So fairly simple, fairly easy. Probably could write it down in a couple of minutes. The hard part is going back and looking at the representation to figure out what gate to put there. OK. What about this? So you know how to build adders, right? You could do it with adders. So last lecture, we saw how to build subtractors. So these are actually being used as subtractors, right? So this thing here, so what's BE for? Well, that's 41 hex, one's complement form. And so this is one's complement of 41. This is carry in of one. Remember that when we take C, this is 0 extended to be 8 bits. When we take C and we add it to not be plus 1, that gives us C minus 41. So C minus 41, if that overflows, I'm sorry, yeah, if we get the carry out, that means no overflow. If we don't have a carry out, if carry out is 0, that means that C was less than 41 hex. So if we get a 0 carry out that comes down here, goes through an inverter, changes to a 1, forces you to 0. So in other words, if C is less than letter A, capital letter A, we'll get a U of 0. Similarly over here, A4 is one's complement of 5A, I think. I put that wrong, didn't I? It should be A5. Sorry about that. So that should be A5. Yeah. Oh, wait, do we need a, let me think here. So we get this one minus 5A, maybe it's for the greater or equal. So 5A, yeah, it's inverted sense. So this is C minus 5B. And so if we get a carry out of that, it's 5B or more. So that's why it's off by 1 here. So this has to be the greater or equal to 5B. That's what the carry out means. If that's true, it's not an uppercase letter. So we're getting a greater or equal then when we flip the carry sense. And that's why this is one's complement of 5B instead of 5A. Does that make sense? OK. All right. So with these two adders, so basically each adder is checking one bound of the range, same as with the comparators. So we could build it this way too and get the same answer. So what's the trade off? Well, those are kind of large and slow compared to our first solution. If you write it down as gates and you show how many gates you need for that first expression, it's really not very many. It's pretty fast, a few levels of logic. As compared to our 7-bit comparator, where it's going to have maybe order 14, 15, plus the logic at the end, so 16 or so gate delays. So substantially slower, substantially bigger for the comparator approach. Same thing for the adders. You've got to wait for the carries to ripple through if you build them as ripple carry adders. So they're slower and bigger. On the other hand, the CAD tools can optimize a lot of that overhead away. So if you look back at the adders, we're actually throwing away the sums. So we build these adders and then we calculate the sum and then we just ignore it. So the CAD tools can look at that and say, well, you didn't use those. So any gates I use to generate those bits, I don't need those. And so it already start trimming down the design that way. But it can also do a little bit of optimization for you. The other way to look at this is, this is like XML parsing or something. If you're going to do XML parsing in your data center, which lots of data centers are doing 24 hours a day, seven days a week, 365 days a year all the time, what are those doing? Well, they're using software. They're saying, oh, compare this incoming character to capital A, compare it to capital Z, actually probably with 32 or 64 bits at a time instead of eight bits. So we're actually doing that all the time in much less efficient ways in software. So this kind of hardware, if you build something like this and if you can get it sitting and doing XML processing, for example, it's more of a complicated task than just checking characters. But it can actually be a lot faster even with a slower and bigger design than using processors. Yeah. Yeah, possibly. And that would be an argument for doing it in software. The computers you're using in software are part of the processor and you can use them for myriad other purposes. But in reality, even 15, 20 years ago with TCP IP network processing before everything was XML based or HTML based, if you looked at a typical data center, a lot of your processor cycles, so on the order of 10 to 15% of your processor cycles were spent doing this stuff. So there's actually a reasonable amount of research in what people call TCP offloading, try to process networking protocols, TCP IP offloading, networking protocols in hardware off the main processors so that you could have your processors actually run internet services instead and reduce your costs that way. So yes and no. There's benefit to it, but getting the generality you need, especially as the protocols evolve over time is sometimes difficult. So people have tried the TCP IP networking at least three times in the last 30 years. And there's some of it now I think in the industry and in real data centers. But it's hard to get right in a way that can survive for a long time. And that's partly because once you put it in hardware, you can't change it. It has to be the same. Good question. Yeah. I'm not in this class, but you can do it. Good question. Yeah. Yeah. I wouldn't ask you to do something that complicated in our class. But yeah. So we want you to understand how to do it and how to approach these kind of problems, both in the sense of if you want to go down to the level of building out of gates to know how to do those things, but also to know how to use the components that you can pull off the shelf to build things. So right now we're looking at examples of the latter. To solve problems, you can take pieces of known solutions and glue them together and do that very, very quickly and only optimize afterwards. If it's something that is too slow or too big, then you can go make it smaller and faster by spending more time on it. So we want you to understand both strategies. Does that answer the question? Okay. Another question? Okay. Yeah. Can you look ahead in my slides? Yes. Yes, we can. Hold that thought. I won't repeat it for the camera because it'll come up again. Good question. Anything else? Okay. So multiplexers. So here we go. You didn't have to hold it for long. So what if we want to take a lowercase letter? So lowercase letters are 61 hex through 7a hex. Remember that uppercase or 41 through 5a. So can we reuse our solutions? We just do what? What was it you said? That? Right. So you'll notice if you put them side by side that bit c5 is flipped. Right. So I'm sorry. I took down the representations, but they couldn't all fit on the slides. We had this answer before by breaking up the truth table. So I'll go back. The only difference here is bit c5 here is a 1, bit c5 here is a 0, c5 is a 1, c5 is a 0. Right. So flip the c5. So change c5 here, c5 here to c5, sorry, c5 prime, c5 prime to c5 c5. We're done. We've got a lowercase checker. Yeah. Oh, sorry. I thought you were raising your hand. Okay. And if you want to use the comparator for that purpose, right, then all you have to do is change these inputs up here. So change that one from 41 to 61. That means z0 equals 1 now implies c less than 61 hex. Change this one from 5a to 7a. That means that z1 down here equals 1 implies c greater than 7a instead of 5a. And then we have a lowercase checker instead of an uppercase checker. So very, very easy to just go change that answer. So what if we want to design one answer to one piece of hardware that does both? So we did that a couple of times on Wednesday. We did unsigned and choose complement comparator by XORing the sign bits with the signal s. We did that with an adder and subtractor where we put them together by again having control signal s. But what if we want to have just logic that allows us to have some control signal s that just selects between two arbitrary signals? So we'll design this logic and then go apply it to our problem here of designing one piece of hardware that checks both upper and lowercase. So if I want to do that, here's a full truth table. So I have a select bit s. It could be 0 or 1. I have two data inputs. They could be 0 or 1. And those are the eight possible patterns. And so if I have select bit 0, that pulls out d0 and I get a 0, 0, 1, 1, 0, 0, so forth. But I could probably make it a little shorter. So instead of drawing this big truth table, I know that if I select 0, I don't care what d1 is. So here we're putting X on an input, which is different than putting X on an output. This says in this truth table row, d1 doesn't matter. d1 can be 0 or 1, and Q will still be 0. So this row here then represents these top two, I'm sorry, not the top two, this one and this one here, the first and the third. The second row then represents the second and the fourth. It also says, well, if select is 0, d1 doesn't matter. If d0 is 1, Q is also 1. So we can have an abbreviated truth table. I mostly wanted to show you what it means to have a don't care symbol on the inputs. So it means that we're merging multiple lines with the same output. You have to be careful because if you have more than one overlapping set here in your rows with different outputs, then you have an ill-defined truth table. So you've got to be careful how you merge them. We're getting there. Sorry. A multiplexer is what implements this function. So this output Q is the result of a multiplexer. But I'll show you logic diagrams in a bit. We'll derive them. So it's the thing that allows us to answer this question down here. Use one control signal to pick between two arbitrary signals. So the answer, we call a multiplexer. I debated whether I should put it in the titles, but that's what we're building towards. Yes. Although I call them d1 or d0. So here in this abbreviated one, what I was telling you, unselected inputs don't matter. So remember, s is select. So the ones that are not selected, if s is 0, then d1. If s is 1, then d0. We'll mark those with don't cares. And furthermore, I could even, in this case, I could write the truth table in a really compact way. So I could say, well, if s is 0, the output is d0. So whatever, this is now an input. But I'll say, well, that output corresponds to this input. And I just have two rows. So as we go forward in the class, it'll be more and more necessary as we build bigger systems to start writing truth tables where we take advantage of these shortcut notations. So I just wanted to introduce a couple of them. So let's go ahead and solve this problem with the KMAP. So first, we'll copy. So I put d1 and d0 on the top. So we're going to go across. And then we'll just copy from q into this KMAP. So we'll start with this one and then go downwards. So that's 0, 1, another 0. But remember, we need to hop over when we copy. So 0, 1. And then 0, 0, 1, 1. So 0, 0, 1, 1. So what are the loops? So we could do this one. But if we look at this one, for example, we have to have this loop, right? Yeah. So remember, this was the example or similar to the one we used for consensus. So we don't need to have that one. But those two loops were done. So yeah. It doesn't actually matter, right? They're equivalent in this case. So you're right that I probably should take a look at that and make sure that I think that I'm, well, visually solve them and see that I think one is better than the other. If it's close, I may solve them exactly to compare them. In this case, they're symmetric. So it's going to be identical. Yeah. So the question was SOP versus POS. And they're the same here in terms of complexity. So we'll solve this one with SOP. So we'll write it down. It's S prime d0 and SD1. So I could have done that a little differently. I could have started with my small truth table and said, well, when I have S0, I get d0. So S prime, that's the min term for S. S equals 0, sorry. S prime anded with d0 gives me this row. And then S, this min term, anded with d1 gives me this row. And I OR those together. That's my function. And in that form, it's maybe a little easier to see that, well, all this is letting me do is when S is 0, I pick d0. And when S is 1, I pick d1. So this is a device, which we call a multiplexer, that allows us to pick between two signals, whatever they might be. And it will forward one of those signals, depending on our choice, which is S, to the output Q. So here's what it looks like. All I did here is implemented the logic that we had on the last slide. So this is how a 2 to 1 MUX is implemented. This is how we draw it as a trapezoid with data inputs 1 and 0. And then which of those gets forwarded to Q depends on S. Yeah. Yeah. So the question is what are we going to use this for? And the answer is, well, when we want a piece of hardware that does more than one thing, we have to tell it which thing we want to do. And so we can control which inputs it looks at using something like a multiplexer. So I'll come back and actually put that in front of our devices. But yeah. Good question. Like this? Good question. What if we have four expressions, for example? So we have 3, 2, 1, and 0. What should we do? So yeah, one answer is to use hierarchical MUXes, right? So we can start by using one 2 to 1 MUX. We'll control it with a signal. Let's call it S1 for now. And let's decide between D3 or D2 will go into this input. And D1 or D0 will go into this input. No. D3 or D2, the way I've numbered these. Yeah. Eventually. Yeah. So the next question then is, well, how do we get D3 or D2 to go into this input? Well, we're going to use a MUX, right? So how are we going to deliver two expressions? We use a MUX controlled by S0. So here on the top, we pick between D3 or D2 using S0. One of those two will go into the input to this second level of MUXes, which is just one more MUX. And here we're picking between D1 or D0 also based on S0. This choice here is based on S1. So if you think about what ends up happening, I'll look at it in more detail on the next slide, but S1, S0 is basically a two bit unsigned number that chooses between input 3, input 2, input 1, and input 0. Sorry? Yeah. Yeah. I really like it. No, no, no. It's great when you guys are predicting the slides. That means you're really on top of things. I like it. OK. Yes, you can do it with four AND gates. And each of these is a minterm, right? So if you think about what's going on here, each of these four AND gates is producing a minterm ANDed with one of the D inputs. So let's go through those. So this top one is D3 ANDed with S1, S0, which is the minterm which you could think about as number 3. It's the 1, 1 minterm. So those get ANDed together and produced by this AND gate. The next AND gate is D2 with S1, S0 prime. And that's 1, 0. That says, OK, I want input number 2. Down here, D1 ANDed with S1 prime, S0. That's 0, 1. So that gives you the D1 input. And then down here is D0 ANDed with S1 prime, S0 prime. So that gives you the D0 input. The outputs of all four of those, only one of these four minterms can be on. S1, S0 has to have one of those four bit patterns. Only one of these four AND gates will produce a 1 ever. So then you OR them together. That gives you Q. Yeah. I thought it'd be easier for you to understand if I draw it this way. I'm sorry. I forgot to include that slide. Yeah, OK. So I mean, you should know, I know actually a few people had some trouble with this on the homework. So any time you have two-level SOP, you can just literally go replace both levels of gates with NAND and it'll be the same. So I mean, if you want them to be NAND, just draw NANDs in place of these. But I didn't do it. Sorry. Yeah, sorry. So that's an interesting question. So the question is, well, could you just connect these four outputs together? Remember that these are what we call active logic. And so if you think about the way these gates are working, you are actually connecting one of them to high voltage and the other, or maybe to high voltage if it outputs a 1. The other three are connected to ground. So if you connect the outputs, you've created a path from high voltage to ground. I will show you later in the class how to do what you're saying, where you actually electrically disconnect some of the outputs from a wire, and then you can use multiple outputs to drive the same wire. But you have to have electrical disconnection, not connection to ground, which is what you get out of the gates. Good thinking, though. Okay. All right. So here's the symbolic form. Bigger trapezoid labeled with the four different values, two bits of select input, so crosshatch with the two. And of course, we could then further generalize, right? So you can build 8-to-1 MOXs. You could build them out of 4-to-1 and 2-to-1. You could build them out of AND gates. At some point, your OR gate at the end gets too big, so you'd really have to have multiple levels there. But conceptually, it's the same. You can build 16-to-1, 32-to-1, and so forth. So anytime you want to select from 2-to-the-n, where I'll name that p to make the notation down here easier, with dp-1 down to d0 inputs, we need n bits of select. The log of p, log base 2 of p. Yeah. I mean, in theory, it's infinite. In practice, usually at about 4, you'll want to put more than. It depends on the semiconductor process, but usually it's around 4. Yeah. You mean how do the CAD tools do? Yeah, so the CAD tools are actually, so there's a set of engineers who are working on the fabrication and will go and measure the fabrication capabilities and the speeds and the timings of the transistors and things like that, as well as the capacitive load of different wires. And then all of that gets fed into the CAD tools with process, semiconductor process-specific information that the CAD tools then use to optimize. So there's a lot of information that's not even available to the public. So unless you're contracting with that particular fabrication facility, they won't even give you those numbers. Those are proprietary numbers that you would get out of them. So the CAD tools are obviously designed to use that kind of information. And sometimes you'll see some of it if you're working on hardware. The rules of thumb have been sort of similar for a while, but the details are all hidden. All right. So we can use sets of MUXes also. Another way to generalize a multiplexer instead of just thinking, well, we could have bigger sets, we can use multiple, many copies of the same kind of multiplexer using the same select bits to switch between groups of bits. So for example, well, let me generalize it first. We can have an end-to-end multiplexer, which is actually M copies of N over M to 1 MUXes, each with log base 2 of N over M select bits. And typically, N over M is some power of 2. So for example, when we did our subtractor design, we said, well, we want to take B or complement B, one's complement of B. And we did some optimization there. We could have instead just used MUXes and put B into one input of the MUX, B prime into the other input, but we'd have N copies of a 2 to 1 MUX to do that. And they would all be controlled by the same select bit. Either we want all of the bits complemented or none of the bits. None for addition, all for subtraction. Now, when we talked about it, we actually did a little bit of optimization for the MUX implementation. We said, well, because we're putting B and B prime in, we just need an XOR gate. We don't need a MUX. But we could have just put a MUX down. And actually, the CAD tool probably would have figured out to replace that with an XOR gate anyway. It's simple enough logic that the tool could figure it out. All right. So let's then back up a step and think about our ASCII character checker. So let's say now, instead of just upper and lowercase, I want to check for four different kinds of comparison. So I want to say, well, let me check for control characters. Those happen to be the range 0 to 1 f hex. Check for lowercase, so 41 to 5a. 41, not 40, sorry. 41 to 5a hex. Uppercase 61 to 7a hex. And digits, 30 to 39 hex. So I want to check all four types with one piece of logic. So what should I do? Yeah, MUXes, what kind? Yeah, so a set of 4 to 1 MUXes, right? A 28 to 7, where each of the ASCII characters is compared against one of four possible lower range values, 0, 41, 61, or 30. And one upper range, 1f, 5a, 7a, and 39. Which of those four I put in is actually just controlled by the same two bits, for all 14 of those 4 to 1 MUXes. So the same two bits make my choice for me between the four different possibilities. 0 to 1f, which gives me control characters. 41 to 5a, which gives me uppercase letters. 61 through 7a, which gives me lowercase letters. And 30 to 39, which gives me digits. And then I just look down here at the output to see for the range I chose, was the answer yes or no? And I can use the same hardware. Make sense? Yeah. What are you, we're relying to give you what? I'm sorry. Ah, so the S input, right now we've only done combinational logic, right? So this is just like any other input to our logic, right? So somehow we need to tell this piece of hardware which operation we want to do. So later we'll see how we can store state, actually we'll start it shortly. But eventually we'll build full computers, and then it'll be up to us to make sure that the answer to your question gets routed to these two input bits at the right time, so that we perform the correct comparison. At this stage, probably not too much, right? At this stage, we're designing something that is usable, right? That the human can arrange to have the right two input bits. I mean, humans can make mistakes everywhere, right? So you can design an adder and they put the wrong bits into the adder, they get the wrong answer out. So in all stages of all kinds of engineering design, you have to think about, did a human make a mistake somewhere? There's sometimes other sources of error too, but humans are responsible for most mistakes. Yeah, when it seems like a computer is responsible for most mistakes, it's actually the programmer. So yeah, occasionally there are things like cosmic ray strikes, right? That'll cause bit flips that will, so there are hardware, software slash errors that come up because of nature. Most bugs are because of humans at some point. All right. So one more piece, actually, before we start sequential logic, so maybe we won't get to sequential logic today. So decoders, so it's going to be a little bit abstract. This will make more sense when we get to memory. So what if we have designed a representation with n bits? I mean, we did a bunch of them when we did bit slicing, right? But what if we have an n bit representation of something and we want to know, and we have a value in that representation, n bits, we want to know which of the values is it? So I want one signal that tells me, okay, this was the mango ice cream or this was the lychee or this was the pistachio or whatever, one signal each. So what am I going to do with that? Well, naming sets of bits. So again, when you receive memories or register files, probably three to four weeks out, we'll need this, right? This will be one of the primary components in the construction of a computer memory. So we will need to have decoders. Another one is actually generating arbitrary functions, logic functions dynamically. So this was used in old reconfigurable logic, so called programmable logic arrays, basically. So I'll show you how that works. But for many years, that was how we built dynamically reconfigurable hardware and did hardware prototyping quickly. So in other words, given a set of n bits, I want to generate a signal for every possible combination. So those signals then of course, correspond to the min terms. And so for every min term, I'll have a signal and exactly one of those will have the value one. So decoder generates all the min terms, and one of them will be one. So you might remember, we saw that in the mux, right? So there's a similar structure. So here's a decoder, two to four decoder. So it takes two input bits and generates all the min terms. Here I've added an enable signal. So in fact, for this decoder, if enable is zero, enable goes to all four of these AND gates, and so all the outputs are zero, right? If enable is one, each of these becomes a min term of S1, S0, and so one of the outputs will be a one and the others will all be zero. So this is decoder. And if you were then to be mean and ask me, well, this is not NAND and NOR and it's not too level, I'd say, yeah, it's not quite accurate, right? You're going to need extra inverters to make this a real circuit for CMOS. Because if you used a Morgan's law, you'll get extra inverters on this side, which you can easily just swap the inverted and non-inverted lines here, but I guess you'll get a bonus inverter and enable. Yeah. I'm not sure if I understand what you mean. I mean, a one input NAND gate or NOR gate is an inverter, right? If you think about the parallel versus series, they scale it down to one transistor, that's then an inverter. But unless you have two in a row, they don't just cancel. So when... Yeah. Yeah. Yeah. Okay. Yes, but I'm... Yeah, I'm not sure. I'm not sure if I understand. I mean, I can use a two input NAND and connect both inputs to the same thing. I see. But I can do the inverter with one input. I mean, I can also have three inputs or 10 inputs. It's all the same. It's all an inverter if I connect them all to the same input. Yeah. But what I can't do is when I change this to a NOR gate in order to make it CMOS, I get inverters here. So all of these will be inverted. So these two inverters will be flipped. So that's fine. It's the same cost, but I'll still have one inverter that I need for the enable. So I'll have one extra inverter in the NAND NOR design if you work that out. Okay. So this is how we draw a decoder to the trapezoid going the opposite way. So the NBIT signal usually comes in from the smaller side, not the narrow ends, but the smaller side of the trapezoid. And the outputs then come out from the other side. If the decoder has an enable signal, not all of them do, but it's pretty common. It'll come in from the narrow side. So this is a symbolic form of the decoder. I do want you to notice that this structure is very similar to the MUX. So in the MUX, we then ANDed each of these min terms with one of the data inputs, and then we ORed all the results together. But we have the same AND gates to generate all the min terms. So they're very similar in that sense. The decoder allows these min terms to be used separately. So for example, if you were building a vending machine and you wanted a bunch of products coded in some representation and each of these outputs could then control the mechanical release for that product. You'd release exactly one product based on the product that the vending machine said, OK, time to release a product. And you probably want to release one at a time rather than having your vending machine drop a random subset or something. Well so there are no 2 to the n data inputs where n is the number of select bits. So there's nothing actually getting ANDed in with the min terms other than the enable signal. So that's one difference. And the min terms are not being ORed together. So in a practical sense, the way that's used is we can compose arbitrary functions by ORing together the right set of min terms. So it's not very interesting for 2 bits, but if you built a bigger decoder like 3 to 8 or 4 to 16, you could then pick out the right min terms, OR them together, and compose an arbitrary logic function. So that's how the old reconfigurable logic was built, by composing logic functions out of min terms. And you can actually do that. So let me finish this and I'll get to your question. You can actually do that for more than one function, because you have these min term wires. So you can have one function by just ORing the right set together, and then a different function by ORing a different set together, and a third function, and a fourth function, and so forth. Whereas with a MUX, those min terms are all ORed together into one wire. So you can't then use that to construct arbitrary logic. You can use it by putting 0s and 1s to the input, but one MUX will get you one function. Whereas a decoder, you can then add OR gates outside the decoder to get you any number of functions you want. So the primary application, other than memory, was the programmable logic arrays. I'll show you, when we get in about two and a half weeks, I will show you an application which is a vending machine, which is, you pick a product and then there's internal logic that decides, am I going to actually deliver that product to you? Have you put enough money in? And so that goes to the enable of the decoder. So if the answer is no, you didn't give me enough money for that product, then nothing gets released. And if the answer is yes, then we decode the signal, and then we take each of these and send it to a mechanical release. Or you can use it for that kind of application. The primary use, though, outside of memories, which we'll see in a few weeks, was these programmable logic arrays, which have now been superseded by FPGAs. FPGAs use a different mechanism in terms of lookup tables. Oops, really? That was it? OK. We have a few minutes left, so let me give you a little start on any questions on this before I switch slide decks. Yes, so based on S1 and S0, there will be four different minterms, and it will generate exactly one one for one of those minterms. Yeah. Yeah. The enable. Yeah. Yeah, the S1, S2 would be the product choice. That's right. And then each of these lines out would control whether a different one of the four products got dropped out. So a MUX is typically used when you need to choose between different functions. So for example, when we did the add or subtract, or when we did unsigned or two's complement comparator, you can use a MUX. When you want to compare different ranges of ASCII, you can use a set of MUXs to choose which type of character you're looking for. So there will be many, many cases where we want to have the ability to choose between two things or four things, and we'll use MUXs in all of those cases. In fact, we'll see it probably Monday or Wednesday when we design registers. I see. So in a different sense. So this is giving me one signal for each pattern, whereas the MUX is unifying many signals under one wire. Right. So do I want to add or subtract? I want the answer to come out in the same place. Right. So when you want to combine things into one output, use a MUX. When you want to split something that's already been coded into individual wires, use a decoder. Yeah, it's trying to give you the ability to tell which of the patterns here was the one that was actually present on the bits. So that you can then do things with each of those individually. Go ahead. Okay. You mean if you wanted to build a bigger decoder from a smaller one? Yeah, then you have to. So the question is, can you build bigger decoders from smaller ones? You can. You do need to have decoders with enable, because if you think about, well, how could I build something with eight outputs from two of these? Well, you can't if both of these always output one, one. Right. Because in the eight, you want one, one also. If you've got one, one from each of these, then you have two ones and you can't do it. Right. Without adding some extra gates afterwards, which would be a pain. On the other hand, if you have the enable input, you can make one of the two, two to four decoders output all zeros. Right. So if you take two, two to four decoders with enable, you can build a three to eight decoder out of that with a little bit of extra logic. Make sense? Okay. I think that might be in the homework. Yeah. Yeah. So if you were, if you were really designing it in CMOS, then, you know, you need to change these AND gates into NOR. Or, I mean, you could change them into NAND, but your outputs would mean different things. All right. So let's just stop there. We'll start sequential logic on Monday. Thanks.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textbook_texts = [textbook_text.lstrip(' ').rstrip(' ') for textbook_text in textbook_texts]\n",
    "print(len(textbook_texts))\n",
    "textbook_texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split the textbook string into context-size contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893\n"
     ]
    }
   ],
   "source": [
    "from langchain import text_splitter\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.text_splitter import CharacterTextSplitter, NLTKTextSplitter, SpacyTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "# good examples here: https://langchain.readthedocs.io/en/latest/modules/utils/combine_docs_examples/textsplitter.html\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-xxl')\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(tokenizer, chunk_size=682, chunk_overlap=100, separators = \". \",)\n",
    "# texts = text_splitter.split_text(textbook)\n",
    "texts = text_splitter.create_documents(texts=textbook_texts, metadatas=metadatas)\n",
    "print(len(texts))\n",
    "\n",
    "# 250 --> 2723\n",
    "# 350 --> 1692\n",
    "# 450 chunks -> 1397\n",
    "# 682 chunks -> 893\n",
    "\n",
    "clean_meta = [text.metadata for text in texts]\n",
    "clean_text = [text.page_content for text in texts]\n",
    "# clean_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893\n",
      "893\n",
      "893\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))\n",
    "print(len(clean_text))\n",
    "print(len(clean_meta))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embed each context, and save it to a vector database, this one is hosted by Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7466ab92-037e-402d-ab9d-15dba2fa862f'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='/mnt/project/chatbotai/huggingface_cache/internal_api_keys.env', override=True)\n",
    "os.environ['PINECONE_API_KEY_NEW_ACCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import HuggingFaceEmbeddings #OpenAIEmbeddings, \n",
    "import pinecone\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load API keys from globally-availabe .env file\n",
    "load_dotenv(dotenv_path='/mnt/project/chatbotai/huggingface_cache/internal_api_keys.env', override=True)\n",
    "\n",
    "# See the docs here, (search for pinecone): https://langchain.readthedocs.io/en/latest/reference/modules/vectorstore.html\n",
    "pinecone.init(api_key=os.environ['PINECONE_API_KEY_NEW_ACCT'], environment=\"us-east4-gcp\")\n",
    "# pinecone.init(api_key=os.environ['PINECONE_API_KEY'], environment=\"us-west1-gcp\")\n",
    "\n",
    "model_name = \"intfloat/e5-large\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "pinecone_index = Pinecone.from_texts(\n",
    "    texts=clean_text,\n",
    "    metadatas=clean_meta,\n",
    "    embedding=embeddings,\n",
    "    index_name=\"uiuc-chatbot-deduped\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/kastanday/.cache/torch/sentence_transformers/intfloat_e5-large. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as CSV and Parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe from clean_text, clean_meta, embeddings\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'text': clean_text, 'metadata': clean_meta})\n",
    "df.to_parquet('./Vlad_lectures-chunk_size_682-chunk_overlap_100.parquet', index=False)\n",
    "df.to_csv('./Vlad_lectures-chunk_size_682-chunk_overlap_100.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✅ Done with critical steps, the rest is for demonstration only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Easily run simliarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code to run Pinecone search during inference.\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "# pinecone.init(api_key=\"***\", environment=\"us-west1-gcp\")\n",
    "# pincecone_index = pinecone.Index(\"uiuc-chatbot\")\n",
    "# vectorstore = Pinecone(index=pincecone_index, embedding_function=embeddings, text_key=\"text\")\n",
    "# question = \"What is a finite state machine in electrical engineering?\"\n",
    "# relevant_context_list = pinecone_index.similarity_search(question, k=3)\n",
    "\n",
    "# for d in relevant_context_list:\n",
    "#     print(d.page_content)\n",
    "#     print(d.metadata['page_number'], d.metadata['textbook_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So if I just add a flip-flop, now there's a Moore machine. I mean, this is the state bit, so I can affect the output with a state bit. Wait a minute, that's sort of delaying things. In fact, if you think back to our serialized designs, we always delay things. The output of these machines is never reflecting all of the inputs until the next clock cycle. So let's take a look at a timing diagram, but I claim it's no different from the things you've already seen, which is a factor with using Moore machines. So let's take a look at it. So what this is going to do, by adding this flip-flop here, we're actually logically splitting this one state into a 1, 1 state and a 0, 1 state. Now, the 1 and the 0 are different, because they call this one S1. So that's the high bit. So we've got three states now. And now we can put our inputs or outputs into our state. So we've got the 0, 0 state, which is 0 here and 0 here. In that case, remember, output is just S1. So S1 is 0, so output is 0. Here's a 1, 1 state. Output is just the same as S1, so the output is 1. And here's a 0, 1 state. Again, 0 is just equal to that 0 there. So now the outputs are part of the state, just like you saw when we talked about finite state machine transition diagrams on Monday. And that's because there's a Moore machine. So here, sorry, I meant to do this analysis first. Well, n is just going to S0. So if I have a 0 on my n, then S0 plus will be 0, because that just goes straight there. Similarly, n goes over to this AND gate. So if my input is 0, S1 plus will also be 0. So that's why any 0 takes me from any state into 0, 0 state. So I have these three arcs all going into 0, 0. What happens when n equals 1? So then S0 will be 1. I'm sorry, S0 plus will be 1. So if I give a 1 input, my next S0 plus bit will be 1. And let's see, S1 plus will be 1 ANDed with S0 prime. So S1 plus will just be S0 prime. So from here, I'll go to 1, and then S0 is 0, so to 1, 1. So if I see a 1 in the 0, 0 state, I'll go over here. Now, I claim that's actually my recognizer. So to be in this state, I should have seen a 0. And after that 0, I saw a 1. And that'll produce one cycle of my output 1. And that's what I wanted. I wanted to recognize 0, 1\n",
      " ECE120-2016-10-12-LEC-21-slides.mp4\n",
      "And the finite state machine will move to the copy state that we already showed. So here's that last bit of the flowchart. You notice I've broken it up into two colors because we're going to have a prep state, and then we're going to have a compare state. All right, so let me finish by just showing you this abstract state diagram. I'll just flip through it, and then I'll walk through it. So this is now what we have. We have a wait state. The finite state machine sits around there until it sees the start signal. When you see the start signal, you go to init. That takes one cycle. Then it goes to prep, where it actually prepares to do a comparison with the second element of the array. Comes down to do the comparison, runs this thing for 32 cycles, and then goes to copy, where it might actually copy the second value into min. That would not be the end of the loop. So it would go around this loop here, the yellow, blue, green, yellow, blue, green. It would do that nine times to compare the other nine elements. And then when it's finished, the smallest number is in min, the register min. So it would go up to wait and finish. And then some other logic could come out and read the smallest number. So we'll go over this again and then finish up the design on Wednesday. Thanks.\n",
      " ECE120-2016-10-24-LEC-25-slides.mp4\n",
      "Now in order to save ourselves a little time, often we will shortcut this kind of notation. So I could write this input bit here as x00. So in this case, I've got a don't care for my u input. So what that means, I could have the 000 pattern or the 100 pattern, and both of those will come back to the unlocked state. So I'll mention in a minute or two, you have to be a little careful with that notation. But you can shorten the number of bit patterns you have to list. Turns out when we get over here, we're actually going to have six different patterns. So I'm going to start using the shortcut notation on this diagram. In the notes, it's got all the patterns listed for you. So if you want to see it in the notes with all the patterns instead of the shortcutting, that's fine. Okay, so look at the notation on all of these locking arcs. So you can see that I don't actually care about the unlock bit on any of them. So unlock doesn't matter on these three. Also for this one, unlock doesn't matter so long as I'm pushing lock. So if I'm pushing lock but not panic, I'll go to the locked state from any state. Similarly, I've got 000 listed up here. That was the self loop when I don't push anything in the lock state. So in this full complete state transition diagram, you need to have all possible arcs. But you can use the shortcut notation, as I'm showing you, to reduce the number of arcs you really have to draw. Otherwise, you'd have eight times four, 32 different arrows, which is a little hard to follow. So these things can get messy if you're not careful. All right, so this is the last one here. Most of these are XX1, which means I don't care about unlock, I don't care about lock, as long as panic is one, I'm going to go down into the alarm state. So XX1 here, XX1 here, XX1 here. Here on the left, it's actually six different states, XX1 and X0X. So if I'm pushing panic, it doesn't matter, I stay in the alarm state. Similarly, if I'm not pushing locked, I'll stay in the alarm state. Not pushing lock, I'll stay in the alarm state. So that's actually six different states. Each of these is, I'm sorry, six different input combinations. Each of these is four. So we have to be a little careful, right? Because there's actually, in that notation, there's actually overlap between these two patterns. But that's okay, because they're going to the same place\n",
      " ECE120-2016-10-10-LEC-20-slides.mp4\n"
     ]
    }
   ],
   "source": [
    "# Easily run similarity search on the Pinecone index\n",
    "question = \"What is a finite state machine in electrical engineering?\"\n",
    "relevant_context_list = pinecone_index.similarity_search(question, k=3)\n",
    "\n",
    "for d in relevant_context_list:\n",
    "    print(d.page_content)\n",
    "    print(d.metadata['page_number'], d.metadata['textbook_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "s = \"What is a finite state machine in electrical engineering?\"\n",
    "# print number of words in string s\n",
    "print(len(relevant_context_list[1].page_content.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "reader = pipeline(\n",
    "  tokenizer='roberta-large',\n",
    "  model='roberta-large',\n",
    "  task='question-answering',\n",
    "  device='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "question=\"What is a programmable logic array (PLA)?\"\n",
    "for doc in relevant_context_list:\n",
    "  answer = reader(question=question, context=doc.page_content)\n",
    "  print(answer)\n",
    "  print(doc.page_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚨 DON'T RUN BELOW HERE 🚨"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delete all vectors with '.mp4' in metadata  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_filenames = [metadata['textbook_name'] for metadata in clean_meta]\n",
    "list_of_filenames = set(list_of_filenames)\n",
    "list_of_filenames = list(list_of_filenames)\n",
    "list_of_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pinecone.init(api_key=\"87823627-c1f4-48fe-9c36-3d19d3dd29bb\", environment=\"us-west1-gcp\")\n",
    "pi = pinecone.Index('uiuc-chatbot')\n",
    "\n",
    "# query for metadata matching exact filename\n",
    "res = pi.query(\n",
    "    vector=[0.0] * 1024,\n",
    "    filter={\n",
    "        \"textbook_name\": {\"$in\": list_of_filenames},\n",
    "    },\n",
    "    top_k=50,\n",
    "    include_metadata=True\n",
    ")\n",
    "res['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ids then delte\n",
    "len(res['matches'])\n",
    "ids = [match['id'] for match in res['matches']]\n",
    "\n",
    "pi.delete(ids=ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8513702ffebcddd0565c7cb8940121422c1007cb2eaee71f9f7918f25ee15d0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
