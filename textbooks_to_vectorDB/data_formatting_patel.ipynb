{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using spacy <br>\n",
    "```\n",
    "conda install -c conda-forge spacy\n",
    "conda install -c conda-forge cupy\n",
    "python -m spacy download en_core_web_trf\n",
    "\n",
    "pip install langchain pinecone-client PyPDF2\n",
    "# maybe: conda install -c conda-forge -y ipykernel=6\n",
    "# maybe: conda install -c anaconda -y notebook\n",
    "```\n",
    "\n",
    "Note: \n",
    "* Flan T5 XL max length is 512\n",
    "* Flan T5 XXL max length is 1024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Parse textbook (retain page numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages:  253\n"
     ]
    }
   ],
   "source": [
    "# pip install PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    " \n",
    "# git clone `non-public-datasets` repo\n",
    "reader = PdfReader('../../non-public-datasets/cleaned_data/patel_textbook/patel_short_and_clean.pdf')\n",
    "print(\"Total pages: \", len(reader.pages))\n",
    " \n",
    "# extracting text from page\n",
    "textbook = []\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text() #.replace(\"\\n\", \" \")\n",
    "    # skip empty pages\n",
    "    if text:\n",
    "        textbook.append(dict(\n",
    "                            text=text,\n",
    "                            page_number=i, \n",
    "                            textbook_name='Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'come Aboard/one.tnum./one.tnumWhat We Will Try to DoWelcome toFrom Bits and Gates to C and Beyond.O u ri n t e n ti st oi n t r o d u c eyou over the next xxx pages to the world of computing. As we do so, we haveone objective above all others: to show you very clearly that there is no magic tocomputing. The computer is a deterministic system—every time we hit it over thehead in the same way and in the same place (provided, of course, it was in the samestarting condition), we get the same response. The computer is not an electronicgenius; on the contrary, if anything, it is an electronic idiot, doing exactly whatwe tell it to do. It has no mind of its own.What appears to be a very complex organism is really just a very large, sys-tematically interconnected collection of very simple parts. Our job throughoutthis book is to introduce you to those very simple parts and, step-by-step, build theinterconnected structure that you know by the namecomputer.L i k eah o u s e ,w ewill start at the bottom, construct the foundation ﬁrst, and then go on to add layerafter layer, as we get closer and closer to what most people know as a full-blowncomputer. Each time we add a layer, we will explain what we are doing, tying thenew ideas to the underlying fabric. Our goal is that when we are done, you will beable to write programs in a computer language such as C using the sophisticatedfeatures of that language and to understand what is going on underneath, insidethe computer./one.tnum./two.tnumHow We Will Get ThereWe will start (in Chapter 2) by ﬁrst showing that any information processed bythe computer is represented by a sequence of 0s and 1s. That is, we will encodeall information as sequences of 0s and 1s. For example, one encoding of the letterathat is commonly used is the sequence 01100001. One encoding of the decimalnumber35is the sequence 00100011. We will see how to perform operations onsuch encoded information.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textbook[9]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Why the Book HappenedThis textbook evolved from EECS 100, the ﬁrst computing course for computerscie\n",
      "1 doing it, had its shortcomings. We decided that the reason students were not get-ting it was that th\n",
      "2 The Addition of C++We’ve had an ongoing debate about how to extend our approach and textbookto C++. \n",
      "3 and see how these structures are actually organized in memory. We moved our dis-cussion of subroutin\n",
      "4 The LC-3 is a 16-bit architecture that includes physical I/O via keyboardand monitor, TRAPs to the o\n",
      "5 under program control. Both are supported by our LC-3 simulator so the studentcan write interrupt dr\n",
      "6 Chapter 17 teaches recursion, using the student’s newly gained knowledge offunctions, stack frames, \n",
      "7 education, but we feel they are better suited to a later course in computerarchitecture and design. \n",
      "8 In both cases, students appreciated starting with the LC-3, and their subsequentintroduction to ARM \n",
      "9 come Aboard.What We Will Try to DoWelcome toFrom Bits and Gates to C and Beyond.O u ri n t e n ti st\n",
      "10 Once we are comfortable with information represented as codes made up of0s and 1s and operations (ad\n",
      "11 languages, all the while being able to comprehend the transformations requiredfor your code to execu\n",
      "12 Even the statement “Go down this street ten blocks…” can be broken downfurther with instructions on \n",
      "13 electric power generator never malfunctioned, there would have been no need forthe power engineering\n",
      "14 all the speciﬁcations associated with it. By software, they generally mean the pro-grams, whether op\n",
      "15 top computer scientists in the world, devoted 391 pages to the task inThe Artof Computer Programming\n",
      "16 done. A more precise term for this hardware is acentral processing unit(CPU),or simply aprocessororm\n",
      "17 Figure.Ap r o c e s s o rb o a r d ,v i n t a g es. Courtesy of Emilio SalguerioFast forward another\n",
      "18 c\n",
      "Figure.A microprocessor.c/circlecopyrtPeter Gudella/ShutterstockThe integrated circuit packages th\n",
      "19 They usually mean the collection of parts that in combination form theircomputersystem. Today that c\n",
      "20 be some very complicated tasks. In reality, these tasks are simple andstraightforward.The rest of th\n",
      "21 and wanted to multiply two integers, you had some pencil-and-paper workto do.This is why computers a\n",
      "22 particular Turing machine you wanted it to simulate, say a machine to add twointegers, giveUthe inpu\n",
      "23 \n",
      "DevicesFigure.Levels of transformation.computer. Most important of these unacceptable attributes is\n",
      "24 ..The AlgorithmThe ﬁrst step in the sequence of transformations is to transform the natural lan-guag\n",
      "25 All the languages mentioned thus far are high-level languages. Low-level lan-guages are tied to the \n",
      "26 The ISA also speciﬁes the number of unique locations that comprise the com-puter’s memory and the nu\n",
      "27 example, the x86’s original implementation in 1979 was the 8086, followed by the80286, 80386, and 80\n",
      "28 , Data Types, andrations.Bits and Data Types..The Bit as the Unit of InformationWe noted in Chapter \n",
      "29 ho n ew i r e ,o n ec a nd i f f e r e n t i a t eo n l yt w ot h i n g s .O n eo ft h e mc a nb ea \n",
      "30 integers have many uses in a computer. If we wish to perform a task some spe-ciﬁc number of times, u\n",
      "31 11111 31−15−0−1Figure.Four representations of integers.The ﬁrst thought that usually comes to mind i\n",
      "32 At this point, you might think that a computer designer could assign any bitpattern to represent any\n",
      "33 To accomplish that, the 2’s complement data type speciﬁes the representationfor each negative intege\n",
      "34 for 0. Withk=5, we can uniquely identify 32 distinct quantities, and we haveaccounted for only 31 (1\n",
      "35 Exa\n",
      ".3. The decimal integer value corresponding to 11000111 is−57...Decimal to Binary ConversionConv\n",
      "36 Therefore,b2=0.13=b6/uni22C523+b5/uni22C522+b4/uni22C521+b3/uni22C520Therefore,b3=1.6=b6/uni22C522+b\n",
      "37 conversion to decimal, we simply add those values where the correspondingbi=1. For example, if the f\n",
      "38 Addition still proceeds from right to left, one digit at a time. At each point,we generate a sum dig\n",
      "39 ..Sign-ExtensionIt is often useful to represent a small number with fewer bits. For example, rathert\n",
      "40 You are undoubtedly familiar with the odometer on the front dashboard ofyour automobile. It keeps tr\n",
      "41 Note that the sum of a negative number and a positive number never presentsap r o b l e m .W h yi st\n",
      "42 bits in the two source operands. For example, ifaandbin Example 2.6 are 16-bit patterns, thencis the\n",
      "43 Example.Ifcis the OR ofaandb,w h e r ea=0011101001101001 andb=0101100100100001,as before, what isc?W\n",
      "44 In the same way that we applied the logical operation AND to twom-bit patterns,we can apply the XOR \n",
      "45 theB=funreprAANDB=AORBWe can also state this behavior in English:“It is not the case that bothAandBa\n",
      "46 busyoravailable. The system could be a manufacturing plant where each unit isap a r t i c u l a rm a\n",
      "47 So we have a problem. We have more bits than we need for precision. But wedon’t have enough bits to \n",
      "48 The sign bit S is just a single binary digit, 0 for positive numbers, 1 for neg-ative numbers. The f\n",
      "49 Example.The following three examples provide further illustrations of the interpretation ofthe 32-bi\n",
      "50 Subnormal numbers are numbers of the formN=(−1)S×0.fraction×2−126We represent them with an exponent \n",
      "51 Both are associated with the same key, although in one case the Shift key is alsodepressed while in \n",
      "52 with a symbol representing its value (from 0 to 15), and we replace 212with itsequivalent 163,28with\n",
      "53 ital Logic StructuresInC h a p t e r1 ,w es t a t e dt h a tc o m p u t e r sw e r eb u i l tf r o m\n",
      "54 Figure.A simple electric circuit showing the use of a wall switch.The lamp can be turned on and oﬀby\n",
      "55 Figure 3.2c is a shorthand notation for describing the circuit of Figure 3.2b.Rather than always sho\n",
      "56  1.2 volts. 0 volts           Figure.A CMOS inverter.volts with the symbol 1, we have the truth tabl\n",
      "57 1101.2 volts0 volts1.2 voltsAB\n",
      "Figure.The NOR gate.transistors is suﬃcient to cause that transistor \n",
      "58 AB\n",
      "1    0      0     11    1      0     1Figure.The OR gate...Why We Can’t Simply Connect P-Type to \n",
      "59 Figure.An OR gate (not really!)...AND and NAND GatesFigure 3.8 shows an AND gate. Note that if eithe\n",
      "60 (e) NOR gate (d) NAND gate Figure.Basic logic gates.Again, we note that there is no ambiguity. The f\n",
      "61                                                          Figure.At h r e e - i n p u tA N Dg a t e .\n",
      "62 AB\n",
      "1,  if   A, B  is  110Figure.At w o - i n p u td e c o d e r .The decoder is useful in determinin\n",
      "63 OUTFigure.Af o u r - i n p u tm u x .The mux of Figure 3.12 works as follows: SupposeS=0, as shown i\n",
      "64   1Figure.The truth table for a one-bit adder.that must be added: one bit from each of the two opera\n",
      "65 S0S1S2S3Figure.Ac i r c u i tf o ra d d i n gt w o-bit binary numbers.are the outputs of the AND gat\n",
      "66 \n",
      "Figure.Ap r o g r a m m a b l el o g i ca r r a y .gates. In Figure 3.17, we have 23three-input AND\n",
      "67 kind of gate. That is, the set of gates{AND, OR, and NOT}is logically completebecause a barrel of AN\n",
      "68 change that value. This is the case when inputsSandRboth have the logic value1. In Figure 3.18 the l\n",
      "69 RFigure.Ag a t e dDl a t c h .latch to be set to the value ofD,b u tonlywhen WE is asserted (i.e., w\n",
      "70 Actually, the number two billion is only an approximation, due to the way wespecify memory locations\n",
      "71 D[1]D[2]D[0]Figure.A-by--bit memory.Accesses of memory require decoding the address bits. Note that \n",
      "72 \n",
      "D[1]D[2]D[0]  10 1Figure.Reading locationin our-by--bit memory.can be written in a similar fashion.\n",
      "73 Figure.Sequential logic circuit block diagram.In this section, we discuss digital logic structures t\n",
      "74 \n",
      "(a) (b)Figure.Combination locks.complete turn to the left (counterclockwise), and then continuing u\n",
      "75 C. The lock is not open, but the user has just completed R13,followed by L22.D. The lock is open, si\n",
      "76 (a) (b) (c)Figure.Three states in a tic-tac-toe machine.at w o - p o i n ts h o t ,t h en e ws t a t\n",
      "77 15 cents. The behavior of each of these systems can be speciﬁed by aﬁnite statemachine,a n dr e p r \n",
      "78 on each arc speciﬁes which state the system is coming from and which state it isgoing to. We refer t\n",
      "79 Also clearly, the number of legitimate transitions from one state to another issmall, compared to th\n",
      "80 will take on a simpler task, the design of a traﬃcc o n t r o l l e r ,a na d m i t t e d l ys i m p\n",
      "81 ..Example: A Danger SignMany electrical, mechanical, and aeronautical systems are controlled by a sy\n",
      "82 \n",
      "1Figure.State diagram for the danger sign controller.described. If the switch is turned oﬀ(input=0)\n",
      "83 First, the two external inputs: the switch and the clock. The switch determineswhether the ﬁnite sta\n",
      "84 First, let us look at the outputs that control the lights. As we have said, thereare only three outp\n",
      "85 ClockFigure.Am a s t e r / s l a v eﬂ i p - ﬂ o p .to be performed during a single clock cycle invol\n",
      "86 nal to the master latches is now 0, the state of theThus, although the write enable signal to the sl\n",
      "87 von NeumannelWea r en o wr e a d yt or a i s eo u rl e v e lo fa b s t r a c t i o na n o t h e rn o\n",
      "88 \n",
      "PCFigure.The von Neumann model, overall block diagram...MemoryRecall that in Chapter 3 we examined \n",
      "89 Figure.Locationcontains the value;l o c a t i o ncontains the value.memory location, we ﬁrst place t\n",
      "90 can perform ADD, AND, and NOT operations. Two of these (ADD and AND)we will discuss in this chapter.\n",
      "91 There are, of course, many other input and output devices in computer sys-tems today. For input we h\n",
      "92 \n",
      "OUTPUTINPUTMEMORYFigure.The LC-as an example of the von Neumann model.Memory Data Register (MDR) fo\n",
      "93 ad i s p l a ys t a t u sr e g i s t e r( D S R )f o rm a i n t a i n i n ga s s o c i a t e ds t a \n",
      "94 NOT).Data movementinstructions move information from the processing unitto and from memory and to an\n",
      "95 ..The Instruction Cycle (NOT the Clock Cycle!)Instructions are processed under the direction of the \n",
      "96 Step 2: Interrogate memory, resulting in the instructionbeing placed in the MDR.Step 3: Load the IR \n",
      "97 In the ADD example, this phase consisted of obtaining the source operandsfrom R2 and R6. In most cur\n",
      "98 We have identiﬁed two types of instructions, the ADD and AND, which areexamples ofoperate instructio\n",
      "99 instruction executed would be the instruction at M[x36CA], the address formed byincrementing the PC \n",
      "100 As has already been discussed, it is sometimes necessary not to executethe next sequential instructi\n",
      "101 state diagram would be able to control, clock cycle by clock cycle, all the stepsrequired to execute\n",
      "102 If the RUN latch is in the 1 state (i.e.,Q=1), the output of the clock circuitis the same as the out\n",
      "103 \n",
      "StopFigure.Flowchart for an algorithm that multiplies two positive integers.The program counter, wh\n",
      "104 LC-InC h a p t e r4 ,w ed i s c u s s e dt h eb a s i cc o m p o n e n t so fac o m p u t e r — i t \n",
      "105 The ISA speciﬁes the memory organization, register set, and instruction set,including the opcodes, d\n",
      "106 Fi000101 0000000001ADD R2 R0 R1where the twosourcesof the ADD instruction are speciﬁed in bits [8:6]\n",
      "107 ..OpcodesSome ISAs have a very large number of opcodes, one for each of a very largenumber of tasks \n",
      "108 bits 0011000100110000 represent the 2’s complement integer 12,592, the ASCIIcode for 10, and a bit v\n",
      "109 or 1, corresponding to whether the result written to the GPR is negative, zero,or positive. That is,\n",
      "110 \n",
      "Figure.Data path relevant to the execution of NOT R,R...ImmediatesThe second source operand for bot\n",
      "111 Figure.Data path relevant to the execution of ADD R,R,#−.completing the execution of the ADD (or AND\n",
      "112 E\n",
      "E\n",
      "stion:What distasteful result is also produced by this sequence? How can iteasily be avoided?..T\n",
      "113 Figure.Data path relevant to the execution of LEA R,#−.We shall see shortly that the LEA instruction\n",
      "114 The process of moving information from memory to a register is called aload,a n dt h ep r o c e s so\n",
      "115 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0001001 0110101111LD R2 x1AFFigure 5.7 shows the relevant parts \n",
      "116 ..Indirect ModeLDI(opcode=1010) andSTI(opcode=1011) specify theindirectaddress-ing mode. An address \n",
      "117 contents of x2110 being loaded into R3. In step 3, since x2110 is not the operand,but the address of\n",
      "118 contained in IR [5:0] (x001D), and the result (x2362) is loaded into the MAR.Second, memory is read,\n",
      "119 (xFFFB). Therefore, at the end of execution of the ST instruction, memory loca-tion x30F4 (i.e., x30\n",
      "120 sequential execution of a user program to start a sequence of instructions in theoperating system. H\n",
      "121 condition code Z is examined. If bit [9] is 1, condition code P is examined. If anyof bits [11:9] ar\n",
      "122 \n",
      "Yes!Figure.Data path relevant to the execution of BRz xD.Another Example.If all three bits [11:9] a\n",
      "123 ..Two Methods of Loop ControlWe saw in Section 4.4 in our multiplication program that we repeatedly \n",
      "124 \n",
      "x3009000011 1111111010BRnzp x3004Figure.Ap r o g r a mt h a ti m p l e m e n t st h ea l g o r i t \n",
      "125 Zc o n d i t i o nc o d e .A sl o n ga sZi sc l e a r ,t h eP Cw i l ln o tb eaﬀected, and the nexti\n",
      "126 \n",
      "xnzp xFigure.A program that implements the algorithm of Figure..Suppose we know the values stored i\n",
      "127 ..The JMP InstructionThe conditional branch instruction, for all its capability, does have one unfor\n",
      "128 request services from the operating system and continue processing after eachsuch service is perform\n",
      "129 \n",
      "x3013000000 0 0 0 0 1 1 0 0 0 0ASCII TEMPLATEFigure.Am a c h i n el a n g u a g ep r o g r a mt h a\n",
      "130 which requests the operating system to perform a service call on behalf of this pro-gram. The functi\n",
      "131 ..Basic Components of the Data Path...The Global BusThe most obvious item on the data path diagram i\n",
      "132 instruction cycle, the PC is incremented and written into the PC. That is shownas the rightmost inpu\n",
      "133 ...OPERAND FETCHIn the next cycle (or more than one, if memory access takes more than one cycle),the\n",
      "134 rammingWea r en o wr e a d yt od e v e l o pp r o g r a m st os o l v ep r o b l e m sw i t ht h ec \n",
      "135 We will ﬁnd the systematic decomposition model a useful technique fordesigning computer programs to \n",
      "136 condition is true, the computer is to carry out one subtask. If the condition is not true,the comput\n",
      "137 decomposition constructs. That is, Figure 6.2b, c, and d corresponds respectivelyto the three constr\n",
      "138 Figure.Stepwise reﬁnement of the character count program (Fig..continued onnext page.)To do this, we\n",
      "139 \n",
      "Figure.Stepwise reﬁnement of the character count program (Fig..continued onnext page.)The problem d\n",
      "140 Figure.Stepwise reﬁnement of the character count program (continued Fig..from previous page.)Figure \n",
      "141 of iterations of a loop: the sentinel method and the use of a counter. Since weare unlikely to know \n",
      "142 compared to where you want to be is totracethe program. This consists ofkeeping track of thesequence\n",
      "143 want to test the second module before you have ﬁnished debugging the ﬁrst mod-ule. If you know that \n",
      "144 ab r a n c hi n s t r u c t i o nt e s t i n gt h ew r o n gc o n d i t i o n ,a n d( 4 )n o tc o v \n",
      "145 \n",
      "15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0000000 1111111101BR n z p−3We should also note that we could h\n",
      "146 Figure.Debugging Example.At r a c eo ft h eﬁ r s tf o u ri n s t r u c t i o n so ft h eA d dprogram\n",
      "147 x3010001100 0 1 0 0 0 0 0 0 0 0x3100Figure.Debugging Example.A nL C -program to detect the presence \n",
      "148 The error in the program occurred because the branch instruction immedi-ately followed the load inst\n",
      "149 example, if the location examined contained 0010000110000000, the programwould terminate with R1=13.\n",
      "150 Each time the PC contained the address x3007, R1 contained a value smallerby 1 than the previous tim\n",
      "151 embly LanguageByn o w ,y o ua r ep r o b a b l yal i t t l et i r e do f1 sa n d0 sa n dk e e p i n \n",
      "152 Before a program written in a high-level language can be executed, it mustbe translated into a progr\n",
      "153 15 .ENDFigure.An assembly language program.the human reader. More on this momentarily. Seven lines (\n",
      "154 name ADD, AND, or LDR than by the four-bit quantity 0001, 0101, or 0110.Figure 5.3 (also Figure A.2)\n",
      "155 NOT, x1000, R4, and other character strings that have speciﬁc meanings in anLC-3 program cannot be u\n",
      "156 Another purpose of comments is to make the visual presentation of a programeasier to understand. Tha\n",
      "157 .An Assembly Language Program....FILL.FILL tells the assembler to set aside the next location in the\n",
      "158 ....END.END tells the assembler it has reached the end of the program and need noteven look at anyth\n",
      "159 .The Assembly Process..IntroductionBefore an LC-3 assembly language program can be executed, it must\n",
      "160 during the second pass, it already knows that PTR is the symbolic address ofmemory location x3013 (f\n",
      "161 At the conclusion of the ﬁrst pass, the symbol table has the following entries:SymbolAddressTESTx300\n",
      "162 Figure.The machine language program for the assembly language program ofFigure..LC-3 assembly langua\n",
      "163 ..The Executable ImageWhen a computer begins execution of a program, the entity being executed iscal\n",
      "164 Upt on o ww eh a v ec o m p l e t e l yi g n o r e dt h ed e t a i l so fi n p u ta n do u t p u t ,\n",
      "165 .Privilege, Priority, and theMemory Address Space..Privilege and PriorityTwo very diﬀerent (we often\n",
      "166 .Privilege, Priority, and the Memory Address Spacethey must quickly reach the ﬁre. In our daily live\n",
      "167 ..Organization of MemoryFigure 9.2 shows the layout of the LC-3 memory.You know that the LC-3 has a \n",
      "168 operating system and requires supervisor privilege to access. The user stack iscontrolled by the use\n",
      "169 source address is that of an input device register, is an input instruction. Similarly,as t o r ei n\n",
      "170 latter characteristicasynchronous.M o s ti n t e r a c t i o nb e t w e e nap r o c e s s o ra n dI \n",
      "171 ..Input from the Keyboard...Basic Input Registers (KBDR and KBSR)We have already noted that in order\n",
      "172 ,04 BRnzp NEXT_TASK ; Go to the next task05 A .FILL xFE00 ; Address of KBSR06 B .FILL xFE02 ; Addres\n",
      "173 carry out the EXECUTE phase of the load instructions. Essentially three stepsare required:1. The MAR\n",
      "174 If input/output is controlled by the processor (i.e., via polling), a program can\n",
      ",04 BRnzp NEXT_TAS\n",
      "175 \n",
      "INMUXFigure.Memory-mapped output.bit had to be in state 1, indicating that the previous character h\n",
      "176 ..A More Sophisticated Input RoutineIn the example of Section 9.2.2.2, the input routine would be a \n",
      "177 \n",
      "ew ne . x ; co e or new ne2A Prompt .STRINGZ ''Input a character>''Figure.The more sophisticated in\n",
      "178 INMUXFigure.Relevant data path implementation of memory-mapped I/O.Figure 9.8 (also shown as Figure \n",
      "179 2. The hardware status registers for both the monitor and the keyboard: themonitor so the program wo\n",
      "180 operating system to perform the task on behalf of the user program. The operatingsystem takes contro\n",
      "181 3.The TRAP instruction.When a user program wishes to have the operatingsystem execute a speciﬁc serv\n",
      "182 Location x04A0 is the starting address of the operating system service rou-tine to input a character\n",
      "183 \n",
      "Figure.Flow of control from a user program to an OS service routine and back.which loads the PC and\n",
      "184 The program executes as follows: The program ﬁrst loads constants xFFC9 andx0020 into R2 and R3. The\n",
      "185 ave .0F .ENDFigure.Character output service routine...A Trap Routine for Halting the ComputerRecall \n",
      "186 \n",
      ".Figure.HALT service routine for the LC-(continued Fig..fromprevious page.)rst (lines 02 and 03), r\n",
      "187 Note the hedging:almost. In the original sequences starting at L2 and L3,the STI instruction forward\n",
      "188 1111111111111111F SaveR3 .FILL x000020 .ENDFigure.The LC-PUTS service routine..Interrupts and Interr\n",
      "189 \n",
      "..Figure.Instruction execution ﬂow for interrupt-driven I/O.running program to stop, (2) have the p\n",
      "190 what is hopefully useful work, executing some other program perhaps, until it isnotiﬁed that some I/\n",
      "191 If all three elements are present, the processor stops executing the programthat is running and take\n",
      "192 that is currently executing. Recall from Section 9.1.1.2 that each program runsat a speciﬁed level o\n",
      "193 \n",
      "INTFigure.Generation of the INT signal.its FETCH OPERAND phase, we would have to keep track of what\n",
      "194 ...Initiate the InterruptSince the INT signal was asserted, the processor does not return to the ﬁrs\n",
      "195 is to load the PC and PSR of the interrupt service routine. Interrupt service rou-tines are similar \n",
      "196 processor. The condition codes are now restored to what they were when theprogram was interrupted, i\n",
      "197 for B was in the middle of executing the AND instruction at x6202 when deviceCs e n ti t si n t e r \n",
      "198 saved on the supervisor stack, the ﬁrst step is to start using the supervisor stack.This is done by \n",
      "199 .Polling Revisited, Now ThatWe Know About Interrupts..The ProblemRecall our discussion of polling: W\n",
      "200 LC-ISAA.OverviewThe instruction set architecture (ISA) of the LC-3 is deﬁned as follows:Memory addre\n",
      "201 Table A.Device Register AssignmentsAddress I/O Register Name I/O Register FunctionxFEKeyboard status\n",
      "202 Interrupt processingI/O devices have the capability of interrupting theprocessor. Section A.3 descri\n",
      "203 Table A.Notational ConventionsNotation MeaningxNumber The number in hexadecimal notation. Example: x\n",
      "204 ADDAddition\n",
      "  98 654 0DR SR1 1imm5Operationif (bit[5]==0)DR = SR1 + SR2;elseDR = SR1 + SEXT(imm5);se\n",
      "205 ANDBit-wise Logical AND\n",
      " 98 654 0DR SR1imm5Operationif (bit[5]==0)DR = SR1 AND SR2;elseDR = SR1 AND \n",
      "206 BRConditional BranchAssembler FormatsBRn LABEL BRzp LABEL\n",
      "znpPCoﬀset9Operationif ((n AND N) OR (z AN\n",
      "207 JMPRETJumpReturn from SubroutineAssembler Formats\n",
      "  05689RETOperationPC=BaseR;DescriptionThe program\n",
      "208 JSRJSRRJump to SubroutineAssembler Formats\n",
      "000 BaseR05689JSRROperationTEMP = PC;†if (bit[11]==0)PC=B\n",
      "209 LDLoad\n",
      "PCoﬀset9DR  98 0Operationif (computed address is in privileged memory AND PSR[15] == 1)Initia\n",
      "210 LDILoad Indirect\n",
      "PCoﬀset9DR  98 0Operationif (either computed address is in privileged memory AND PS\n",
      "211 LDRLoad Base+oﬀset\n",
      "  98 65 0BaseRDRoﬀset6OperationIf (computed address is in privileged memory AND P\n",
      "212 LEALoad Eﬀective Address\n",
      "  98 0DRPCoﬀset9OperationDR=PC†+SEXT(PCoffset9);DescriptionAn address is co\n",
      "213 NOTBit-Wise Complement\n",
      "  98 65432 0DRSR 1OperationDR = NOT(SR);setcc();DescriptionThe bit-wise compl\n",
      "214 RETReturn from Subroutine\n",
      "  5OperationPC = R7;DescriptionThe PC is loaded with the value in R7. Its \n",
      "215 RTIterrupt  0Operationif (PSR[15]==1)Initiate a privilege mode exception;elsePC = mem[R6]; R6 is the\n",
      "216 STStore\n",
      "PCoﬀset9SR  98 0Operationif (computed address is in privileged memory AND PSR[15] == 1)Initi\n",
      "217 STIStore Indirect\n",
      "PCoﬀset9SR  98 0Operationif (either computed address is in privileged memory AND P\n",
      "218 STRStore Base+oﬀset\n",
      "15 12 11 9 8 6 5 0BaseRSRoﬀset6Operationif (computed address is in privileged me\n",
      "219 TRAPSystem CallAsEn078111215trapvect8OperationTEMP=PSR;if (PSR[15] == 1)SavedUSP=R6 and R6=SavedSSP;\n",
      "220 Unused Opcode\n",
      "1101OperationInitiate an illegal opcode exception.DescriptionIf an illegal opcode is e\n",
      "221 Table A.Trap Service RoutinesTrap Vector Assembler Name DescriptionxGETC Read a single character fro\n",
      "222 A..InterruptsAt this time, an LC-3 computer system provides only one I/O device that caninterrupt th\n",
      "223 2. The processor sets the privilege mode to Supervisor mode (PSR[15]=0).3. If the process causing th\n",
      "224 LC-to xAs you know, the ISA of the LC-3 explicitly speciﬁes the interface betweenwhat the LC-3 machi\n",
      "225 We present here elements of the x86, a very complicated ISA. We do so inspite of its complexity beca\n",
      "226 B...OpcodesThe LC-3 comprises 15 opcodes; the x86 instruction set comprises more thanat h o u s a n \n",
      "227 Table B.Operate Instructions, xISAInstruction ExplanationADC x, y x, y, and the carry retained from \n",
      "228 Table B.Data Movement Instructions, xISAInstruction ExplanationMOV x, y The value stored in y is cop\n",
      "229 Since the result of the operate is stored in the location that originally con-tained one of the sour\n",
      "230 segmentation. In both cases, the opcode is to move data from memory to a gen-eral purpose register. \n",
      "231 Figure B.xsystem registers.The CF ﬂag stores thecarryproduced by the last relevant operation thatgen\n",
      "232 interrupts (like keyboard input, for example). If IF=0, these external inter-rupts have no eﬀect on \n",
      "233 the use of registers, a one-, two-, or four-byte displacement, and additional registerinformation co\n",
      "234 opcode byte (or bytes) speciﬁes, among other things, the operation to be per-formed, whether the ope\n",
      "235 .then added to whatever is speciﬁed by theModR/M byte.B..SIB ByteIf the opcode speciﬁes that an oper\n",
      "236 \n",
      "AddressFigure B.Addressing mode calculation for Base+ScaledIndes+disp.represented in the instructio\n",
      "237 B.An ExampleWe conclude this appendix with an example. The problem is one we have dealtwith extensiv\n",
      "238 MicroarchitectureeL C -Weh a v es e e ni nC h a p t e r s4a n d5t h es e v e r a ls t a g e so ft h \n",
      "239 4240Control\n",
      "10Control Signals(J, COND, IRD)52Memory, I/OAddr16Inst.Data,1616DataData Path2\n",
      "RINTIR[15\n",
      "240 mode is trying to access a location in privileged memory. ACV stands forAccess Control Violation. Wh\n",
      "241 Before we get into what happens during the clock cycle when the proces-sor is in the state numbered \n",
      "242 the ALU. These control signals determine how that component (the ALU) willbe used each cycle. Table \n",
      "243 \n",
      "Address of NextS t a t eFigure C.The microsequencer of the LC-.As we said, state 32 of the state ma\n",
      "244 (d)Figure C.Additional logic required to provide control signals.Several signals necessary to contro\n",
      "245 Recall our discussion in Section C.2 of the function of state 28, whichaccesses an instruction from \n",
      "246 In state 47, the trap vector (IR[7:0]) is loaded into the eight-bit registerVector, PSR[15] is set t\n",
      "247 \n",
      "otherWx otherRmem otherWx The state machine of Figure C.2 does not have to be altered to accommo-da\n",
      "248 an interrupt by asserting its interrupt request signal. Recall from Chapter 9 thatif the priority le\n",
      "249 the old PSR[15] to determine whether the stack pointers must be adjusted beforepushing PSR and PC.If\n",
      "250 from Supervisor mode to User mode. When the privilege mode changes, the cur-rent value in R6 must be\n",
      "251 by pushing the PSR and PC onto the system stack, obtaining the starting addressof the exception serv\n",
      "252 The action the processor takes is very similar to that of a privilege modeexception. The PSR and PC \n"
     ]
    }
   ],
   "source": [
    "textbook_cleaned = []\n",
    "for i, page in enumerate(textbook):\n",
    "    # print(page['page_number'], page['textbook_name'])\n",
    "    text = page['text']\n",
    "    for _ in range(3):  \n",
    "      text = text.replace(\"/zero.tnum\", \"\") \\\n",
    "                        .replace(\"/zero.tnum.\", \"\") \\\n",
    "                        .replace(\"/one.tnum\", \"\") \\\n",
    "                        .replace(\"/one.tnum.\", \"\") \\\n",
    "                        .replace(\"/two.tnum\", \"\") \\\n",
    "                        .replace(\"/two.tnum.\", \"\") \\\n",
    "                        .replace(\"/three.tnum\", \"\") \\\n",
    "                        .replace(\"/three.tnum.\", \"\") \\\n",
    "                        .replace(\"/four.tnum\", \"\") \\\n",
    "                        .replace(\"/four.tnum.\", \"\") \\\n",
    "                        .replace(\"/five.tnum\", \"\") \\\n",
    "                        .replace(\"/five.tnum.\", \"\") \\\n",
    "                        .replace(\"/six.tnum\", \"\") \\\n",
    "                        .replace(\"/six.tnum.\", \"\") \\\n",
    "                        .replace(\"/seven.tnum\", \"\") \\\n",
    "                        .replace(\"/seven.tnum.\", \"\") \\\n",
    "                        .replace(\"/eight.tnum\", \"\") \\\n",
    "                        .replace(\"/eight.tnum.\", \"\") \\\n",
    "                        .replace(\"/nine.tnum\", \"\") \\\n",
    "                        .replace(\"/nine.tnum.\", \"\") \\\n",
    "                        .replace(\"FiuslochthisknboagthrewTmbo\", \"\") \n",
    "      # print()\n",
    "    if text:\n",
    "      print(i, text[:100])\n",
    "      textbook_cleaned.append(dict(\n",
    "                            text=text,\n",
    "                            page_number=i, \n",
    "                            textbook_name='Yale-Patt_&_Sanjay-Patel--Intro_to_Computing_Systems'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why the Book HappenedThis textbook evolved from EECS 100, the ﬁrst computing course for computerscience, computer engineering, and electrical engineering majors at the Univer-sity of Michigan, Ann Arbor, that Kevin Compton and the ﬁrst author introducedfor the ﬁrst time in the fall term, 1995.EECS 100 happened at Michigan because Computer Science and Engi-neering faculty had been dissatisﬁed for many years with the lack of studentcomprehension of some very basic concepts. For example, students had a lotof trouble with pointer variables. Recursion seemed to be “magic,” beyondunderstanding.We decided in 1993 that the conventional wisdom of starting with a high-level programming language, which was the way we (and most universities) were\n",
      "\n",
      "doing it, had its shortcomings. We decided that the reason students were not get-ting it was that they were forced to memorize technical details when they did notunderstand the basic underpinnings.Our result was the bottom-up approach taken in this book, where we contin-ually build on what the student already knows, only memorizing when absolutelynecessary. We did not endorse then and we do not endorse now the popularinformation hiding approach when it comes to learning. Information hiding is auseful productivity enhancement technique after one understands what is going on.But until one gets to that point, we insist that information hiding gets in the way ofunderstanding. Thus, we continually build on what has gone before so that nothingis magic and everything can be tied to the foundation that has already been laid.We should point out that we do not disagree with the notion of top-downdesign.O nt h ec o n t r a r y ,w eb e l i e v es t r o n g l yt h a tt o p - d o w nd e s i g ni sc o r r e c tdesign. But there is a clear diﬀerence between how one approaches a design prob-lem (after one understands the underlying building blocks) and what it takes to getto the point where one does understand the building blocks. In short, we believein top-down design, but bottom-up learning for understanding.Major Changes in the Third EditionThe LC-A hallmark of our book continues to be the LC-3 ISA, which is small enough tobe described in a few pages and hopefully mastered in a very short time, yet richenough to convey the essence of what an ISA provides. It is the LC “3” becauseit took us three tries to get it right. Four tries, actually, but the two changes in theLC-3 ISA since the second edition (i.e., changes to the LEA instruction and to theTRAP instruction) are so minor that we decided not to call the slightly modiﬁedISA the LC-4.The LEA instruction no longer sets condition codes. It used to set conditioncodes on the mistaken belief that since LEA stands for Load Eﬀective Address,it should set condition codes like LD, LDI, and LDR do. We recognize now thatthis reason was silly. LD, LDI, and LDR load a register from memory, and sothe condition codes provide useful information – whether the value loaded isnegative, zero, or positive. LEA loads an address into a register, and for that, thecondition codes do not really provide any value. Legacy code written before thischange should still run correctly.The TRAP instruction no longer stores the linkage back to the calling pro-gram in R7. Instead, the PC and PSR are pushed onto the system stack and poppedby the RTI instruction (renamed Return from Trap or Interrupt) as the last instruc-tion in a trap routine. Trap routines now execute in privileged memory (x0000 tox2FFF). This change allows trap routines to be re-entrant. It does not aﬀect oldcode provided the starting address of the trap service routines, obtained from theTrap Vector Table, is in privileged memory and the terminating instruction ofeach trap service routine is changed from RET to RTI.As before, Appendix A speciﬁes the LC-3 completely.\n",
      "\n",
      "The Addition of C++We’ve had an ongoing debate about how to extend our approach and textbookto C++. One of the concerns about C++ is that many of its language featuresare too far abstracted from the underlying layers to make for an easy ﬁt to ourapproach. Another concern is that C++ is such a vast language that any adequatecoverage would require an additional thousand pages. We also didn’t want to dropCc o m p l e t e l y ,a si ts e r v e sa sad ef a c t od e v e l o p m e n tl a n g u a g ef o rs y s t e m sa n dhardware-oriented projects.We adopted an approach where we cover the common core of C and C++from Chapters 11 through 19. This common core is similar to what was coveredin the second edition, with some minor updates. Chapter 20 serves as a transition,which we aspired to make very smooth, to the core concepts of C++. With thisapproach, we get to explore the evolution between C and C++, which serves asa key learning opportunity on what changes were essential to boost programmerproductivity.In particular, we focus on classes in C++ as an evolution from structures inC. We discuss classes as a compiler construct, how method calls are made, andthe notion of constructors. We touch upon inheritance, too, but leave the detailsfor subsequent treatment in follow-on courses.An important element of C++ is the introduction of container classes in theStandard Template Library, which is a heavily utilized part of the C++ language.This provides an opportunity to dive deep into the vector class, which serves asac o n t i n u a t i o no far u n n i n ge x a m p l ei nt h es e c o n dh a l fa r o u n dt h es u p p o r tf o rvariable-sized arrays in high-level languages, or in particular, C’s lack of supportfor them.Other Important UpdatesAlthough no chapter in the book has remained untouched, some chapters havebeen changed more than others. In Chapter 2, we expanded the coverage of theﬂoating point data type and the conversion of fractions between decimal andbinary numbers in response to several instructors who wanted them. We movedDeMorgan’s Laws from Chapter 3 to Chapter 2 because the concept is really aboutAND and OR functions and not about digital logic implementation. In Chap-ter 3, we completely overhauled the description of state, latches, ﬂip-ﬂops, ﬁnitestate machines, and our example of a danger sign. We felt the explanations in thesecond edition were not as clear as they needed to be, and the concepts are tooimportant to not get right. We revised Chapter 4 to better introduce the LC-3,including a diﬀerent set of instructions, leading to our ﬁrst complete example ofac o m p u t e rp r o g r a m .Our organization of Chapters 8, 9, and 10 was completely overhauled in orderto present essentially the same material in a more understandable way. Althoughmost of our treatment of data structures waits until we have introduced C in thesecond half of the book, we felt it was important to introduce stacks, queues,and character strings as soon as the students have moved out of programming inmachine language so they can write programs dealing with these data structures\n",
      "\n",
      "and see how these structures are actually organized in memory. We moved our dis-cussion of subroutines up to Chapter 8 because of their importance in constructingricher programs.We also introduced recursion in Chapter 8, although its main treatment is stillleft for the second half of the book. Both the expressive power of recursion andits misuse are so common in undergraduate curricula that we felt dealing withit twice, ﬁrst while they are engrossed in the bowels of assembly language andagain after moving up to the richness of C, was worthwhile.Chapter 9 now covers all aspects of I/O in one place, including polling andinterrupt-driven I/O. Although the concept of privilege is present in the secondedition, we have put greater emphasis on it in the third edition. Our coverageof system calls (the trap routines invoked by the TRAP instruction) appears inChapter 9. All of the above reduce Chapter 10 to simply a comprehensive examplethat pulls together a lot of the ﬁrst half of the book: the simulation of a calculator.Doing so requires 12 subroutines that are laid out in complete detail. Two con-cepts that are needed to make this happen are stack arithmetic and ASCII/binaryconversion, so they are included in Chapter 10.We reworked all the examples in Chapters 11 through 19 to use the latestANSI Standard C or C18. We also added more coding examples to further empha-size points and to provide clarity on complex topics such as pointers, arrays,recursion, and pointers to pointers in C. In Chapter 16, we added additionalsections on variable-sized arrays in C, and on multidimensional arrays.Chapter OrganizationThe book breaks down into two major segments, (a) the underlying structureof a computer, as manifested in the LC-3; and (b) programming in a high-levellanguage, in our case C and C++.The LC-We start with the underpinnings that are needed to understand the workings of areal computer. Chapter 2 introduces the bit and arithmetic and logical operationson bits. Then we begin to build the structure needed to understand the LC-3.Chapter 3 takes the student from an MOS transistor, step by step, to a “real”memory and a ﬁnite state machine.Our real memory consists of four words of three bits each, rather than16 gigabytes, which is common in most laptops today. Its description ﬁts on asingle page (Figure 3.20), making it easy for a student to grasp. By the time stu-dents get there, they have been exposed to all the elements needed to construct thememory. The ﬁnite state machine is needed to understand how a computer pro-cesses instructions, starting in Chapter 4. Chapter 4 introduces the von Neumannexecution model and enough LC-3 instructions to allow an LC-3 program to bewritten. Chapter 5 introduces most of the rest of the LC-3 ISA.\n",
      "\n",
      "The LC-3 is a 16-bit architecture that includes physical I/O via keyboardand monitor, TRAPs to the operating system for handling service calls, con-ditional branches on (N, Z, and P) condition codes, a subroutine call/returnmechanism, a minimal set of operate instructions (ADD, AND, and NOT), andvarious addressing modes for loads and stores (direct, indirect, Base+oﬀset).Chapter 6 is devoted to programming methodology (stepwise reﬁnement)and debugging, and Chapter 7 is an introduction to assembly language program-ming. We have developed a simulator and an assembler for the LC-3 that runs onWindows, Linux, and Mac0S platforms. It can be downloaded from the web atno charge.Students use the simulator to test and debug programs written in LC-3machine language and in LC-3 assembly language. The simulator allows onlinedebugging (deposit, examine, single-step, set breakpoint, and so on). The sim-ulator can be used for simple LC-3 machine language and assembly languageprogramming assignments, which are essential for students to master the conceptspresented throughout the ﬁrst ten chapters.Assembly language is taught, but not to train expert assembly language pro-grammers. Indeed, if the purpose was to train assembly language programmers,the material would be presented in an upper-level course, not in an introductorycourse for freshmen. Rather, the material is presented in Chapter 7 because itis consistent with the paradigm of the book. In our bottom-up approach, by thetime the student reaches Chapter 7, he/she can handle the process of transform-ing assembly language programs to sequences of 0s and 1s. We go through theprocess of assembly step by step for a very simple LC-3 Assembler. By handassembling, the student (at a very small additional cost in time) reinforces theimportant fundamental concept of translation.It is also the case that assembly language provides a user-friendly notationto describe machine instructions, something that is particularly useful for writingprograms in Chapters 8, 9, and 10, and for providing many of the explanations inthe second half of the book. Starting in Chapter 11, when we teach the semanticsof C statements, it is far easier for the reader to deal with ADD R1, R2, R3 thanto have to struggle with 0001001010000011.Chapter 8 introduces three important data structures: the stack, the queue,and the character string, and shows how they are stored in memory. The sub-routine call/return mechanism of the LC-3 is presented because of its usefulnessboth in manipulating these data structures and in writing programs. We also intro-duce recursion, a powerful construct that we revisit much more thoroughly in thesecond half of the book (in Chapter 17), after the student has acquired a muchstronger capability in high-level language programming. We introduce recursionhere to show by means of a few examples the execution-time tradeoﬀsi n c u r r e dwith recursion as a ﬁrst step in understanding when its use makes sense and whenit doesn’t.Chapter 9 deals with input/output and some basic interaction between theprocessor and the operating system. We introduce the notions of priority andprivilege, which are central to a systems environment. Our treatment of I/O isall physical, using keyboard data and status registers for input and display dataand status registers for output. We describe both interrupt-driven I/O and I/O\n",
      "\n",
      "under program control. Both are supported by our LC-3 simulator so the studentcan write interrupt drivers. Finally, we show the actual LC-3 code of the trap ser-vice routines that the student has invoked with the TRAP instruction starting inChapter 4. To handle interrupt-driven I/O and trap service routines, we completethe description of the LC-3 ISA with details of the operation of the Return fromTrap or Interrupt (RTI) and TRAP instructions.The ﬁrst half of the book concludes with Chapter 10, a comprehensive exam-ple of a simple calculator that pulls together a lot of what the students have learnedin Chapters 1 through 9.Programming in C and C++By the time the student gets to the second part of the textbook, he/she has anunderstanding of the layers below. In our coverage of programming in C andC++, we leverage this foundation by showing the resulting LC-3 code generatedby a compiler with each new concept in C/C++.We start with the C language because it provides the common, essentialcore with C++. The C programming language ﬁts very nicely with our bottom-up approach. Its low-level nature allows students to see clearly the connectionbetween software and the underlying hardware. In this book, we focus on basicconcepts such as control structures, functions, and arrays. Once basic program-ming concepts are mastered, it is a short step for students to learn more advancedconcepts such as objects and abstraction in C++.Each time a new high-level construct is introduced, the student is shownthe LC-3 code that a compiler would produce. We cover the basic constructs ofC (variables, operators, control, and functions), pointers, arrays, recursion, I/O,complex data structures, and dynamic allocation. With C++, we cover some basicimprovements over C, classes, and containers.Chapter 11 is a gentle introduction to high-level programming languages. Atthis point, students have dealt heavily with assembly language and can understandthe motivation behind what high-level programming languages provide. Chapter11 also contains a simple C program, which we use to kick-start the process oflearning C.Chapter 12 deals with values, variables, constants, and operators. Chapter 13introduces C control structures. We provide many complete program examplesto give students a sample of how each of these concepts is used in practice. LC-3code is used to demonstrate how each C construct aﬀects the machine at the lowerlevels.Chapter 14 introduces functions in C. Students are not merely exposed to thesyntax of functions. Rather they learn how functions are actually executed, withargument-passing using a run-time stack. A number of examples are provided.In Chapter 15, students are exposed to techniques for testing their code, alongwith debugging high-level source code. The ideas of white-box and black-boxtesting are discussed.Chapter 16 teaches pointers and arrays, relying heavily on the student’sunderstanding of how memory is organized. We discuss C’s notions of ﬁxed sizeand variable-length arrays, along with multidimensional array allocation.\n",
      "\n",
      "Chapter 17 teaches recursion, using the student’s newly gained knowledge offunctions, stack frames, and the run-time stack. Chapter 18 introduces the detailsof I/O functions in C, in particular, streams, variable length argument lists, andhow C I/O is aﬀected by the various format speciﬁcations. This chapter relies onthe student’s earlier exposure to physical I/O in Chapter 8. Chapter 19 discussesstructures in C, dynamic memory allocation, and linked lists.Chapter 20 provides a jump-start on C++ programming by discussing itsroots in C and introducing the idea of classes as a natural evolution from struc-tures. We also cover the idea of containers in the standard template library, toenable students to quickly jump into productive programming with C++.Along the way, we have tried to emphasize good programming style and cod-ing methodology by means of examples. Novice programmers probably learn atleast as much from the programming examples they read as from the rules theyare forced to study. Insights that accompany these examples are highlighted bymeans of lightbulb icons that are included in the margins.We have found that the concept of pointer variables (Chapter 16) is not at allap r o b l e m .B yt h et i m es t u d e n t se n c o u n t e ri t ,t h e yh a v eag o o du n d e r s t a n d i n go fwhat memory is all about, since they have analyzed the logic design of a smallmemory (Chapter 3). They know the diﬀerence, for example, between a memorylocation’s address and the data stored there.Recursion ceases to be magic since, by the time a student gets to that point(Chapter 17), he/she has already encountered all the underpinnings. Studentsunderstand how stacks work at the machine level (Chapter 8), and they understandthe call/return mechanism from their LC-3 machine language programming expe-rience, and the need for linkages between a called program and the return to thecaller (Chapter 8). From this foundation, it is not a large step to explain functionsby introducing run-time stack frames (Chapter 14), with a lot of the mystery aboutargument passing, dynamic declarations, and so on, going away. Since a functioncan call a function, it is one additional small step (certainly no magic involved)for a function to call itself.The Simulator/DebuggerThe importance of the Simulator/Debugger for testing the programs a studentwrites cannot be overemphasized. We believe strongly that there is no substi-tute for hands-on practice testing one’s knowledge. It is incredibly fulﬁllingto a student’s education to write a program that does not work, testing it toﬁnd out why it does not work, ﬁxing the bugs himself/herself, and then see-ing the program run correctly. To that end, the Simulator/Debugger has beencompletely rewritten. It runs on Windows, Linux, and MacOS while present-ing the same user interface (GUI) regardless of which platform the student isusing. We have improved our incorporation of interrupt-driven I/O into the Sim-ulator’s functionality so students can easily write interrupt drivers and invokethem by interrupting a lower priority executing program. ...in their ﬁrst course incomputing!\n",
      "\n",
      "education, but we feel they are better suited to a later course in computerarchitecture and design. This book is not intended for that purpose.Why LC-, and Not ARM or RISCV?We have been asked why we invented the LC-3 ISA, rather than going with ARM,which seems to be the ISA of choice for most mobile devices, or RISCV, whichhas attracted substantial interest over the last few years.There are many reasons. First, we knew that the ISA we selected wouldbe the student’s ﬁrst ISA, not his/her last ISA. Between the freshman year andgraduation, the student is likely to encounter several ISAs, most of which are incommercial products: ARM, RISCV, x86, and POWER, to name a few.But all the commercial ISAs have details that have no place in an introductorycourse but still have to be understood for the student to use them eﬀectively. Wecould, of course, have subset an existing ISA, but that always ends up in questionsof what to take out and what to leave in with a result that is not as clean as onewould think at ﬁrst blush. Certainly not as clean as what one can get when startingfrom scratch. It also creates an issue whenever the student uses an instruction inan exam or on an assignment that is not in the subset. Not very clean from apedagogical sense.We wanted an ISA that was clean with no special cases to deal with, with asfew opcodes as necessary so the student could spend almost all his/her time onthe fundamental concepts in the course and very little time on the nuances of theinstruction set. The formats of all instructions in the LC-3 ﬁt on a single page.Appendix A provides all the details (i.e., the complete data sheet) of the entireLC-3 ISA in 25 pages.We also wanted an instruction set that in addition to containing only a fewinstructions was very rich in the breadth of what it embraced. So, we came upwith the LC-3, an instruction set with only 15 four-bit opcodes, a small enoughnumber that students can absorb the ISA without even trying. For arithmetic, wehave only ADD instead of ADD, SUB, MUL, and DIV. For logical operations,we have AND and NOT, foregoing OR, XOR, etc. We have no shift or rotateinstructions. In all these cases, the missing opcodes can be implemented withprocedures using the few opcodes that the LC-3 provides. We have loads andstores with three diﬀerent addressing modes, each addressing mode useful for adiﬀerent purpose. We have conditional branches, subroutine calls, return fromtrap or interrupt, and system calls (the TRAP instruction).In fact, this sparse set of opcodes is a feature! It drives home the need forcreating more complex functionality out of simple operations, and the need forabstraction, both of which are core concepts in the book.Most importantly, we have found from discussions with hundreds of studentsthat starting with the LC-3 does not put them at a disadvantage in later courses.On the contrary: For example, at one campus students were introduced to ARM inthe follow-on course, while at another campus, students were introduced to x86.\n",
      "\n",
      "In both cases, students appreciated starting with the LC-3, and their subsequentintroduction to ARM or x86 was much easier as a result of their ﬁrst learning thefundamental concepts with the LC-3.A Few ObservationsHaving now taught the course more than 20 times between us, we note thefollowing:Understanding, Not MemorizingSince the course builds from the bottom up, we have found that less memorizationof seemingly arbitrary rules is required than in traditional programming courses.Students understand that the rules make sense since by the time a topic is taught,they have an awareness of how that topic is implemented at the levels belowit. This approach is good preparation for later courses in design, where under-standing of and insights gained from fundamental underpinnings are essential tomaking the required design tradeoﬀs.The Student Debugs the Student’s ProgramWe hear complaints from industry all the time about CS graduates not being ableto program. Part of the problem is the helpful teaching assistant, who contributesfar too much of the intellectual content of the student’s program so the studentnever has to really master the art. Our approach is to push the student to do thejob without the teaching assistant (TA). Part of this comes from the bottom-upapproach, where memorizing is minimized and the student builds on what he/shealready knows. Part of this is the simulator, which the student uses from the dayhe/she writes his/her ﬁrst program. The student is taught debugging from his/herﬁrst program and is required from the very beginning to use the debugging toolsof the simulator to get his/her programs to work. The combination of the simulatorand the order in which the subject material is taught results in students actuallydebugging their own programs instead of taking their programs to the TA forhelp ... with the too-frequent result that the TAs end up writing the programs forthe students.Preparation for the Future: Cutting Through Protective LayersProfessionals who use computers in systems today but remain ignorant of whatis going on underneath are likely to discover the hard way that the eﬀectivenessof their solutions is impacted adversely by things other than the actual programsthey write. This is true for the sophisticated computer programmer as well as thesophisticated engineer.Serious programmers will write more eﬃcient code if they understand whatis going on beyond the statements in their high-level language. Engineers, and notjust computer engineers, are having to interact with their computer systems today\n",
      "\n",
      "come Aboard.What We Will Try to DoWelcome toFrom Bits and Gates to C and Beyond.O u ri n t e n ti st oi n t r o d u c eyou over the next xxx pages to the world of computing. As we do so, we haveone objective above all others: to show you very clearly that there is no magic tocomputing. The computer is a deterministic system—every time we hit it over thehead in the same way and in the same place (provided, of course, it was in the samestarting condition), we get the same response. The computer is not an electronicgenius; on the contrary, if anything, it is an electronic idiot, doing exactly whatwe tell it to do. It has no mind of its own.What appears to be a very complex organism is really just a very large, sys-tematically interconnected collection of very simple parts. Our job throughoutthis book is to introduce you to those very simple parts and, step-by-step, build theinterconnected structure that you know by the namecomputer.L i k eah o u s e ,w ewill start at the bottom, construct the foundation ﬁrst, and then go on to add layerafter layer, as we get closer and closer to what most people know as a full-blowncomputer. Each time we add a layer, we will explain what we are doing, tying thenew ideas to the underlying fabric. Our goal is that when we are done, you will beable to write programs in a computer language such as C using the sophisticatedfeatures of that language and to understand what is going on underneath, insidethe computer..How We Will Get ThereWe will start (in Chapter 2) by ﬁrst showing that any information processed bythe computer is represented by a sequence of 0s and 1s. That is, we will encodeall information as sequences of 0s and 1s. For example, one encoding of the letterathat is commonly used is the sequence 01100001. One encoding of the decimalnumber35is the sequence 00100011. We will see how to perform operations onsuch encoded information.\n",
      "\n",
      "Once we are comfortable with information represented as codes made up of0s and 1s and operations (addition, for example) being performed on these repre-sentations, we will begin the process of showing how a computer works. Startingin Chapter 3, we will note that the computer is a piece of electronic equipmentand, as such, consists of electronic parts operated by voltages and interconnectedby wires. Every wire in the computer, at every moment in time, is at either a highvoltage or a low voltage. For our representation of 0s and 1s, we do not specifyexactly how high. We only care whether there is or is not a large enough voltagerelative to 0 volts to identify it as a 1. That is, the absence or presence of a rea-sonable voltage relative to 0 volts is what determines whether it represents thevalue 0 or the value 1.In Chapter 3, we will see how the transistors that make up today’s micro-processor (the heart of the modern computer) work. We will further see howthose transistors are combined into larger structures that perform operations,such as addition, and into structures that allow us to save information for lateruse. In Chapter 4, we will combine these larger structures into the von Neumannmachine, a basic model that describes how a computer works. We will also beginto study a simple computer, the LC-3. We will continue our study of the LC-3 inChapter 5.LC-3stands for Little Computer 3. We actually started with LC-1 butneeded two more shots at it before (we think) we got it right! The LC-3 has allthe important characteristics of the microprocessors that you may have alreadyheard of, for example, the Intel 8088, which was used in the ﬁrst IBM PCs backin 1981. Or the Motorola 68000, which was used in the Macintosh, vintage 1984.Or the Pentium IV, one of the high-performance microprocessors of choice forthe PC in the year 2003. Or today’s laptop and desktop microprocessors, the IntelCore processors – I3, I5, and I7. Or even the ARM microprocessors that are usedin most smartphones today. That is, the LC-3 has all the important characteristicsof these “real” microprocessors without being so complicated that it gets in theway of your understanding.Once we understand how the LC-3 works, the next step is to program it, ﬁrstin its own language (Chapter 5 and Chapter 6), and then in a language calledassembly languagethat is a little bit easier for humans to work with (Chap-ter 7). Chapter 8 introduces representations of information more complex than asimple number – stacks, queues, and character strings, and shows how to imple-ment them. Chapter 9 deals with the problem of getting information into (input)and out of (output) the LC-3. Chapter 9 also deals with services provided to acomputer user by the operating system. We conclude the ﬁrst half of the book(Chapter 10) with an extensive example, the simulation of a calculator, an app onmost smartphones today.In the second half of the book (Chapters 11–20), we turn our attentionto high-level programming concepts, which we introduce via the C and C++programming languages. High-level languages enable programmers to moreeﬀectively develop complex software by abstracting away the details of the under-lying hardware. C and C++ in particular oﬀer a rich set of programmer-friendlyconstructs, but they are close enough to the hardware that we can examinehow code is transformed to execute on the layers below. Our goal is to enableyou to write short, simple programs using the core parts of these programming\n",
      "\n",
      "languages, all the while being able to comprehend the transformations requiredfor your code to execute on the underlying hardware.We’ll start with basic topics in C such as variables and operators (Chapter 12),control structures (Chapter 13), and functions (Chapter 14). We’ll see that these arestraightforward extensions of concepts introduced in the first half of the textbook.We then move on to programming concepts in Chapters 15–19 that will enableus to create more powerful pieces of code: Testing and Debugging (Chapter 15),Pointers and Arrays in C (Chapter 16), Recursion (Chapter 17), Input and Output inC( C h a p t e r1 8 ) ,a n dD a t aS t r u c t u r e si nC( C h a p t e r1 9 ) .Chapters 20 is devoted to C++, which we present as an evolution of theCp r o g r a m m i n gl a n g u a g e .B e c a u s et h eC + +l a n g u a g ew a si n i t i a l l yd e ﬁ n e da sas u p e r s e to fC ,m a n yo ft h ec o n c e p t sc o v e r e di nC h a p t e r s1 1 – 1 9d i r e c t l ym a ponto the C++ language. We will introduce some of the core notions in C++ thathave helped establish C++ as one of the most popular languages for developingreal-world software. Chapter 20 is our Introduction to C++.In almost all cases, we try to tie high-level C and C++ constructs to theunderlying LC-3 so that you will understand what you demand of the computerwhen you use a particular construct in a C or C++ program..Two Recurring ThemesTwo themes permeate this book that we as professors previously took for granted,assuming that everyone recognized their value and regularly emphasized themto students of engineering and computer science. However, it has become clearto us that from the git-go, we need to make these points explicit. So, we statethem here up front. The two themes are (a) the notion of abstraction and (b) theimportance of not separating in your mind the notions of hardware and software.Their value to your development as an eﬀective engineer or computer scien-tist goes well beyond your understanding of how a computer works and how toprogram it.The notion of abstraction is central to all that you will learn and expect touse in practicing your craft, whether it be in mathematics, physics, any aspect ofengineering, or business. It is hard to think of any body of knowledge where thenotion of abstraction is not critical.The misguided hardware/software separation is directly related to yourcontinuing study of computers and your work with them.We will discuss each in turn...The Notion of AbstractionThe use of abstraction is all around us. When we get in a taxi and tell the driver,“Take me to the airport,” we are using abstraction. If we had to, we could probablydirect the driver each step of the way: “Go down this street ten blocks, and makea left turn.” And, when the driver got there, “Now take this street ﬁve blocks andmake a right turn.” And on and on. You know the details, but it is a lot quicker tojust tell the driver to take you to the airport.\n",
      "\n",
      "Even the statement “Go down this street ten blocks…” can be broken downfurther with instructions on using the accelerator, the steering wheel, watchingout for other vehicles, pedestrians, etc.Abstraction is a technique for establishing a simpler way for a person to inter-act with a system, removing the details that are unnecessary for the person tointeract eﬀectively with that system. Our ability to abstract is very much a pro-ductivity enhancer. It allows us to deal with a situation at a higher level, focusingon the essential aspects, while keeping the component ideas in the background.It allows us to be more eﬃcient in our use of time and brain activity. It allows usto not get bogged down in the detail when everything about the detail is workingjust ﬁne.There is an underlying assumption to this, however:when everything aboutthe detail is just ﬁne.W h a ti fe v e r y t h i n ga b o u tt h ed e t a i li sn o tj u s tﬁ n e ?T h e n ,to be successful, our ability to abstract must be combined with our ability toun-abstract. Some people use the worddeconstruct—the ability to go from theabstraction back to its component parts.Two stories come to mind.The ﬁrst involves a trip through Arizona the ﬁrst author made a long timeago in the hottest part of the summer. At the time he was living in Palo Alto,California, where the temperature tends to be mild almost always. He knewenough to take the car to a mechanic before making the trip and tell him to checkthe cooling system. That was the abstraction: cooling system. What he had notmastered was that the capability of a cooling system for Palo Alto, California,is not the same as the capability of a cooling system for the summer deserts ofArizona. The result: two days in Deer Lodge, Arizona (population 3), waiting forah e a dg a s k e tt ob es h i p p e di n .The second story (perhaps apocryphal) is supposed to have happened duringthe infancy of electric power generation. General Electric Co. was having troublewith one of its huge electric power generators and did not know what to do. Onthe front of the generator were lots of dials containing lots of information, andlots of screws that could be rotated clockwise or counterclockwise as the operatorwished. Something on the other side of the wall of dials and screws was malfunc-tioning and no one knew what to do. As the story goes, they called in one of theearly giants in the electric power industry. He looked at the dials and listened tothe noises for a minute, then took a small screwdriver from his pocket and rotatedone screw 35 degrees counterclockwise. The problem immediately went away. Hesubmitted a bill for $1000 (a lot of money in those days) without any elaboration.The controller found the bill for two minutes’ work a little unsettling and askedfor further clariﬁcation. Back came the new bill:Turning a screw 35 degrees counterclockwise: $ 0.75Knowing which screw to turn and by how much: 999.25In both stories the message is the same. It is more eﬃcient to think of entitiesas abstractions. One does not want to get bogged down in details unnecessarily.And as long as nothing untoward happens, we are OK. If there had been no tripto Arizona, the abstraction “cooling system” would have been suﬃcient. If the\n",
      "\n",
      "electric power generator never malfunctioned, there would have been no need forthe power engineering guru’s deeper understanding.As we will see, modern computers are composed of transistors. These tran-sistors are combined to form logic “gates”—an abstraction that lets us think interms of 0s and 1s instead of the varying voltages on the transistors. A logic cir-cuit is a further abstraction of a combination of gates. When one designs a logiccircuit out of gates, it is much more eﬃcient to not have to think about the inter-nals of each gate. To do so would slow down the process of designing the logiccircuit. One wants to think of the gate as a component. But if there is a problemwith getting the logic circuit to work, it is often helpful to look at the internalstructure of the gate and see if something about its functioning is causing theproblem.When one designs a sophisticated computer application program, whether itbe a new spreadsheet program, word processing system, or computer game, onewants to think of each of the components one is using as an abstraction. If onespent time thinking about the details of each component when it was not neces-sary, the distraction could easily prevent the total job from ever getting ﬁnished.But when there is a problem putting the components together, it is often useful toexamine carefully the details of each component in order to uncover the problem.The ability to abstract is the most important skill. In our view, one shouldtry to keep the level of abstraction as high as possible, consistent with gettingeverything to work eﬀectively. Our approach in this book is to continually raisethe level of abstraction. We describe logic gates in terms of transistors. Once weunderstand the abstraction of gates, we no longer think in terms of transistors.Then we build larger structures out of gates. Once we understand these largerabstractions, we no longer think in terms of gates.The Bottom LineAbstractions allow us to be much more eﬃcient in dealingwith all kinds of situations. It is also true that one can be eﬀective without under-standing what is below the abstraction as long as everything behaves nicely. So,one should not pooh-pooh the notion of abstraction. On the contrary, one shouldcelebrate it since it allows us to be more eﬃcient.In fact, if we never have to combine a component with anything else into alarger system, and if nothing can go wrong with the component, then it is perfectlyﬁne to understand this component only at the level of its abstraction.But if we have to combine multiple components into a larger system, weshould be careful not to allow their abstractions to be the deepest level of ourunderstanding. If we don’t know the components below the level of their abstrac-tions, then we are at the mercy of them working together without our intervention.If they don’t work together, and we are unable to go below the level of abstraction,we are stuck. And that is the state we should take care not to ﬁnd ourselves in...Hardware vs. SoftwareMany computer scientists and engineers refer to themselves as hardware peopleor software people. By hardware, they generally mean the physical computer and\n",
      "\n",
      "all the speciﬁcations associated with it. By software, they generally mean the pro-grams, whether operating systems like Android, ChromeOS, Linux, or Windows,or database systems like Access, MongoDB, Oracle, or DB-terriﬁc, or applica-tion programs like Facebook, Chrome, Excel, or Word. The implication is thatthe person knows a whole lot about one of these two things and precious littleabout the other. Usually, there is the further implication that it is OK to be anexpert at one of these (hardware OR software) and clueless about the other. It isas if there were a big wall between the hardware (the computer and how it actu-ally works) and the software (the programs that direct the computer to do theirbidding), and that one should be content to remain on one side of that wall orthe other.The power of abstraction allows us to “usually” operate at a level where wedo not have to think about the underlying layers all the time. This is a good thing.It enables us to be more productive. But if we are clueless about the underlyinglayers, then we are not able to take advantage of the nuances of those underlyinglayers when it is very important to be able to.That is not to say that you must work at the lower level of abstraction and nottake advantage of the productivity enhancements that the abstractions provide.On the contrary, you are encouraged to work at the highest level of abstractionavailable to you. But in doing so, if you are able to, at the same time, keep inmind the underlying levels, you will ﬁnd yourself able to do a much better job.As you approach your study and practice of computing, we urge you to takethe approach that hardware and software are names for components of two partsof a computing system that work best when they are designed by people who takeinto account the capabilities and limitations of both.Microprocessor designers who understand the needs of the programs thatwill execute on the microprocessor they are designing can design much moreeﬀective microprocessors than those who don’t. For example, Intel, AMD, ARM,and other major producers of microprocessors recognized a few years ago that alarge fraction of future programs would contain video clips as part of e-mail,video games, and full-length movies. They recognized that it would be impor-tant for such programs to execute eﬃciently. The result: most microprocessorstoday contain special hardware capability to process those video clips. Inteldeﬁned additional instructions, initially called their MMX instruction set, anddeveloped special hardware for it. Motorola, IBM, and Apple did essentiallythe same thing, resulting in the AltiVec instruction set and special hardware tosupport it.A similar story can be told about software designers. The designer of a largecomputer program who understands the capabilities and limitations of the hard-ware that will carry out the tasks of that program can design the program so itexecutes more eﬃciently than the designer who does not understand the nature ofthe hardware. One important task that almost all large software systems need tocarry out is called sorting, where a number of items have to be arranged in someorder. The words in a dictionary are arranged in alphabetical order. Students inac l a s sa r eo f t e ng r a d e db a s e do nan u m e r i c a lo r d e r ,a c c o r d i n gt ot h e i rs c o r e son the ﬁnal exam. There is a large number of fundamentally diﬀerent programsone can write to arrange a collection of items in order. Donald Knuth, one of the\n",
      "\n",
      "top computer scientists in the world, devoted 391 pages to the task inThe Artof Computer Programming, vol. 3. Which sorting program works best is oftenvery dependent on how much the software designer is aware of the underlyingcharacteristics of the hardware.The Bottom LineWe believe that whether your inclinations are in the directionof a computer hardware career or a computer software career, you will be muchmore capable if you master both. This book is about getting you started on thepath to mastering both hardware and software. Although we sometimes ignoremaking the point explicitly when we are in the trenches of working through aconcept, it really is the case that each sheds light on the other.When you study data types, a software concept, in C (Chapter 12), you willunderstand how the ﬁnite word length of the computer, a hardware concept,aﬀects our notion of data types.When you study functions in C (Chapter 14), you will be able to tie therulesof calling a function with the hardware implementation that makes those rulesnecessary.When you study recursion, a powerful algorithmic device (initially inChapter 8 and more extensively in Chapter 17), you will be able to tie it to thehardware. If you take the time to do that, you will better understand when theadditional time to execute a procedure recursively is worth it.When you study pointer variables in C (in Chapter 16), your knowledge ofcomputer memory will provide a deeper understanding of what pointers pro-vide, and very importantly, when they should be used and when they should beavoided.When you study data structures in C (in Chapter 19), your knowledge of com-puter memory will help you better understand what must be done to manipulatethe actual structures in memory eﬃciently.We realize that most of the terms in the preceding ﬁve short paragraphs maynot be familiar to youyet.T h a ti sO K ;y o uc a nr e r e a dt h i sp a g ea tt h ee n do ft h esemester. What is important to know right now is that there are important topicsin the software that are very deeply interwoven with topics in the hardware. Ourcontention is that mastering either is easier if you pay attention to both.Most importantly, most computing problems yield better solutions when theproblem solver has the capability of both at his or her disposal..A Computer SystemWe have used the wordcomputermore than two dozen times in the precedingpages, and although we did not say so explicitly, we used it to mean a systemconsisting of the software (i.e., computer programs) that directs and speciﬁes theprocessing of information and the hardware that performs the actual processingof information in response to what the software asks the hardware to do. Whenwe say “performing the actual processing,” we mean doing the actual additions,multiplications, and so forth in the hardware that are necessary to get the job\n",
      "\n",
      "done. A more precise term for this hardware is acentral processing unit(CPU),or simply aprocessorormicroprocessor.T h i st e x t b o o ki sp r i m a r i l ya b o u tt h eprocessor and the programs that are executed by the processor...A (Very) Little History for a (Lot) Better PerspectiveBefore we get into the detail of how the processor and the software associatedwith it work, we should take a moment and note the enormous and unparalleledleaps of performance that the computing industry has made in the relatively shorttime computers have been around. After all, it wasn’t until the 1940s that thefirst computers showed their faces. One of the first computers was the ENIAC(the Electronic Numerical Integrator and Calculator), a general purpose electroniccomputer that could be reprogrammed for different tasks. It was designed and builtin 1943–1945 at the University of Pennsylvania by Presper Eckert and his colleagues.It contained more than 17,000 vacuum tubes. It was approximately 8 feet high, morethan 100 feet wide, and about 3 feet deep (about 300 square feet of floor space). Itweighed 30 tons and required 140 kW to operate. Figure 1.1 shows three operatorsprogramming the ENIAC by plugging and unplugging cables and switches.About 40 years and many computer companies and computers later, in theearly 1980s, the Burroughs A series was born. One of the dozen or so 18-inchoards that comprise that machine is shown in Figure 1.2. Each board contained\n",
      "Figure.The ENIAC, designed and built at University of Pennsylvania,–.c/circlecopyrtHistorical/Getty Images\n",
      "\n",
      "Figure.Ap r o c e s s o rb o a r d ,v i n t a g es. Courtesy of Emilio SalguerioFast forward another 30 or so years and we ﬁnd many of today’s computers ondesktops (Figure 1.3), in laptops (Figure 1.4), and most recently in smartphones(Figure 1.5). Their relative weights and energy requirements have decreasedenormousl and the s eed at which the rocess information has also increasedenohowcom\n",
      "FiguAd ec/circlecopyrtJoFutuShutterstock\n",
      "\n",
      "\n",
      "c\n",
      "Figure.A microprocessor.c/circlecopyrtPeter Gudella/ShutterstockThe integrated circuit packages that comprise modern digital computers havealso seen phenomenal improvement. An example of one of today’s microproces-sors is shown in Figure 1.6. The ﬁrst microprocessor, the Intel 4004 in 1971,contained 2300 transistors and operated at 106 KHz. By 1992, those numbershad jumped to 3.1 million transistors at a frequency of 66 MHz on the IntelPentium microprocessor, an increase in both parameters of a factor of about 1000.Today’s microprocessors contain upwards of ﬁve billion transistors and can oper-ate at upwards of 4 GHz, another increase in both parameters of about a factorof 1000.This factor of one million since 1971 in both the number of transistors andthe frequency that the microprocessor operates at has had very important impli-cations. The fact that each operation can be performed in one millionth of thetime it took in 1971 means the microprocessor can do one million things todayin the time it took to do one thing in 1971. The fact that there are more than amillion times as many transistors on a chip means we can do a lot more things atthe same time today than we could in 1971.The result of all this is we have today computers that seem able to understandthe languages people speak – English, Spanish, Chinese, for example. We havecomputers that seem able to recognize faces. Many see this as the magic of artiﬁ-cial intelligence. We will see as we get into the details of how a computer worksthat much of what appears to be magic is really due to how blazingly fast verysimple mindless operations (many at the same time) can be carried out...The Parts of a Computer SystemWhen most people use the wordcomputer,t h e yu s u a l l ym e a nm o r et h a nj u s tthe processor (i.e., CPU) that is in charge of doing what the software directs.\n",
      "\n",
      "They usually mean the collection of parts that in combination form theircomputersystem. Today that computer system is often a laptop (see Figure 1.4), augmentedwith many additional devices.Ac o m p u t e rs y s t e mg e n e r a l l yi n c l u d e s ,i na d d i t i o nt ot h ep r o c e s s o r ,ak e y -board for typing commands, a mouse or keypad or joystick for positioning onmenu entries, a monitor for displaying information that the computer system hasproduced, memory for temporarily storing information, disks and USB memorysticks of one sort or another for storing information for a very long time, even afterthe computer has been turned oﬀ,c o n n e c t i o n st oo t h e rd e v i c e ss u c ha sap r i n t e rfor obtaining paper copies of that information, and the collection of programs(the software) that the user wishes to execute.All these items help computer users to do their jobs. Without a printer, forexample, the user would have to copy by hand what is displayed on the monitor.Without a mouse, keypad, or joystick, the user would have to type each command,rather than simply position the mouse, keypad, or joystick.So, as we begin our journey, which focuses on the CPU that occupies a smallfraction of 1 square inch of silicon and the software that makes the CPU do ourbidding, we note that the computer systems we use contain a lot of additionalcomponents..Two Very Important IdeasBefore we leave this ﬁrst chapter, there are two very important ideas that wewould like you to understand, ideas that are at the core of what computing is allabout.Idea 1:All computers (the biggest and the smallest, the fastest and theslowest, the most expensive and the cheapest) are capable of comput-ing exactly the same things if they are given enough time and enoughmemory. That is, anything a fast computer can do, a slow computer cando also. The slow computer just does it more slowly. A more expensivecomputer cannot ﬁgure out something that a cheaper computer is unableto ﬁgure out as long as the cheaper computer can access enough mem-ory. (Y ou may have to go to the store to buy more memory whenever itruns out of memory in order to keep increasing memory.) All computerscan do exactly the same things. Some computers can do things faster,but none can do more than any other.Idea 2:We describe our problems in English or some other languagespoken by people. Y et the problems are solved by electrons runningaround inside the computer. It is necessary to transform our problemfrom the language of humans to the voltages that inﬂuence the ﬂow ofelectrons. This transformation is really a sequence of systematic trans-formations, developed and improved over the lastyears, whichcombine to give the computer the ability to carry out what appear to\n",
      "\n",
      "be some very complicated tasks. In reality, these tasks are simple andstraightforward.The rest of this chapter is devoted to discussing these two ideas..Computers as UniversalComputational DevicesIt may seem strange that an introductory textbook begins by describing howcomputers work. After all, mechanical engineering students begin by studyingphysics, not how car engines work. Chemical engineering students begin bystudying chemistry, not oil reﬁneries. Why should computing students begin bystudying computers?The answer is that computers are diﬀerent. To learn the fundamental prin-ciples of computing, you must study computers or machines that can do whatcomputers can do. The reason for this has to do with the notion that computersareuniversal computational devices.L e t ’ ss e ew h a tt h a tm e a n s .Before modern computers, there were many kinds of calculating machines.Some wereanalog machines—machines that produced an answer by measuringsome physical quantity such as distance or voltage. For example, a slide rule isan analog machine that multiplies numbers by sliding one logarithmically gradedruler next to another. The user can read a logarithmic “distance” on the sec-ond ruler. Some early analog adding machines worked by dropping weights on ascale. The diﬃculty with analog machines is that it is very hard to increase theiraccuracy.This is whydigital machines—machines that perform computations bymanipulating a ﬁxed ﬁnite set of digits or letters—came to dominate comput-ing. You are familiar with the distinction between analog and digital watches. Ananalog watch has hour and minute hands, and perhaps a second hand. It givesthe time by the positions of its hands, which are really angular measures. Digitalwatches give the time in digits. You can increase accuracy just by adding moredigits. For example, if it is important for you to measure time in hundredths ofas e c o n d ,y o uc a nb u yaw a t c ht h a tg i v e sar e a d i n gl i k e1 0 : 3 5 . 1 6r a t h e rt h a nj u s t10:35. How would you get an analog watch that would give you an accurate read-ing to one one-hundredth of a second? You could do it, but it would take a mightylong second hand! When we talk about computers in this book, we will alwaysmean digital machines.Before modern digital computers, the most common digital machines in theWest were adding machines. In other parts of the world another digital machine,the abacus, was common. Digital adding machines were mechanical or elec-tromechanical devices that could perform a speciﬁc kind of computation: addingintegers. There were also digital machines that could multiply integers. Therewere digital machines that could put a stack of cards with punched names inalphabetical order. The main limitation of all these machines is that they coulddo only one speciﬁc kind of computation. If you owned only an adding machine\n",
      "\n",
      "and wanted to multiply two integers, you had some pencil-and-paper workto do.This is why computers are diﬀerent. You can tell a computer how to add num-bers. You can tell it how to multiply. You can tell it how to alphabetize a list orperform any computation you like. When you think of a new kind of computation,you do not have to buy or design a new computer. You just give the old computeran e ws e to fi n s t r u c t i o n s( ap r o g r a m )t oc a r r yo u tt h en e wc o m p u t a t i o n .T h i si swhy we say the computer is auniversal computational device. Computer scien-tists believe thatanything that can be computed, can be computed by a computerprovided it has enough time and enough memory. When we study computers, westudy the fundamentals of all computing. We learn what computation is and whatcan be computed.The idea of a universal computational device is due to Alan Turing. Turingproposed in 1937 that all computations could be carried out by a particular kind ofmachine, which is now called a Turing machine. He gave a mathematical descrip-tion of this kind of machine, but did not actually build one. Digital computerswere not operating until several years later. Turing was more interested in solv-ing a philosophical problem: deﬁning computation. He began by looking at thekinds of actions that people perform when they compute; these include makingmarks on paper, writing symbols according to certain rules when other symbolsare present, and so on. He abstracted these actions and speciﬁed a mechanism thatcould carry them out. He gave some examples of the kinds of things that thesemachines could do. One Turing machine could add two integers; another couldmultiply two integers.Figure 1.7 shows what we call “black box” models of Turing machines thatadd and multiply. In each case, the operation to be performed is described inthe box. The data elements on which to operate are shown as inputs to the box.The rprovitherea, b(Turing machinethat adds)(Turing machinethat multiplies)Figure.Black box models of Turing machines.Turing proposed that every computation can be performed by some Turingmachine. We call thisTuring’s thesis.A l t h o u g hT u r i n g ’ st h e s i sh a sn e v e rb e e nproved, there does exist a lot of evidence to suggest it is true. We know, for exam-ple, that various enhancements one can make to Turing machines do not result inmachines that can compute more.Perhaps the best argument to support Turing’s thesis was provided by Turinghimself in his original paper. He said that one way to try to construct a machinemore powerful than any particular Turing machine was to make a machineUthat could simulateallTuring machines. You would simply describe toUthe\n",
      "\n",
      "particular Turing machine you wanted it to simulate, say a machine to add twointegers, giveUthe input data, andUwould compute the appropriate output,in this case the sum of the inputs. Turing then showed that there was, in fact,aT u r i n gm a c h i n et h a tc o u l dd ot h i s ,s oe v e nt h i sa t t e m p tt oﬁ n ds o m e t h i n gt h a tcould not be computed by Turing machines failed.\n",
      "e, f, gvTuring machine)Figure.Black box model of a universal Turing machine.In specifyingU,T u r i n gh a dp r o v i d e du sw i t had e e pi n s i g h t :H eh a dg i v e nu sthe ﬁrst description of what computers do. In fact, both a computer (with as muchmemory as it wants) and a universal Turing machine can compute exactly thesame things. In both cases, you give the machine a description of a computationand the data it needs, and the machine computes the appropriate answer. Comput-ers and universal Turing machines can compute anything that can be computedbecause they areprogrammable.This is the reason that a big or expensive computer cannot do more than asmall, cheap computer. More money may buy you a faster computer, a monitorwith higher resolution, or a nice sound system. But if you have a small, cheapcomputer, you already have a universal computational device..How Do We Get the Electrons toDo the Work?Figure 1.9 shows the process we must go through to get the electrons (whichactually do the work) to do our bidding. We call the steps of this process the“Levels of Transformation.” As we will see, at each level we have choices. If weignore any of the levels, our ability to make the best use of our computing systemcan be very adversely aﬀected...The Statement of the ProblemWe describe the problems we wish to solve in a “natural language.” Natural lan-guages are languages that people speak, like English, French, Japanese, Italian,and so on. They have evolved over centuries in accordance with their usage.They are fraught with a lot of things unacceptable for providing instructions to a\n",
      "\n",
      "\n",
      "DevicesFigure.Levels of transformation.computer. Most important of these unacceptable attributes is ambiguity. Naturallanguage is ﬁlled with ambiguity. To infer the meaning of a sentence, a listener isoften helped by the tone of voice of the speaker, or at the very least, the contextof the sentence.An example of ambiguity in English is the sentence, “Time ﬂies like anarrow.” At least three interpretations are possible, depending on whether (1) one isnoticing how fast time passes, (2) one is at a track meet for insects, or (3) one iswriting a letter to the Dear Abby of Insectville. In the ﬁrst case, a simile; oneis comparing the speed of time passing to the speed of an arrow that has beenreleased. In the second case, one is telling the timekeeper to do his/her job muchlike an arrow would. In the third case, one is relating that a particular group ofﬂies (time ﬂies, as opposed to fruit ﬂies) are all in love with the same arrow.Such ambiguity would be unacceptable in instructions provided to a com-puter. The computer, electronic idiot that it is, can only do as it is told. To tell it todo something where there are multiple interpretations would cause the computerto not know which interpretation to follow.\n",
      "\n",
      "..The AlgorithmThe ﬁrst step in the sequence of transformations is to transform the natural lan-guage description of the problem to an algorithm, and in so doing, get rid of theobjectionable characteristics of the natural language. An algorithm is a step-by-step procedure that is guaranteed to terminate, such that each step is preciselystated and can be carried out by the computer. There are terms to describe eachof these properties.We use the termdeﬁnitenessto describe the notion that each step is preciselystated. A recipe for excellent pancakes that instructs the preparer to “stir untillumpy” lacks deﬁniteness, since the notion of lumpiness is not precise.We use the termeﬀective computabilityto describe the notion that each stepcan be carried out by a computer. A procedure that instructs the computer to “takethe largest prime number” lacks eﬀective computability, since there is no largestprime number.We use the termﬁnitenessto describe the notion that the procedure termi-nates.For every problem there are usually many diﬀerent algorithms for solvingthat problem. One algorithm may require the fewest steps. Another algorithmmay allow some steps to be performed concurrently. A computer that allowsmore than one thing to be done at a time can often solve the problem in lesstime, even though it is likely that the total number of steps to be performed hasincreased...The ProgramThe next step is to transform the algorithm into a computer program in one of theprogramming languages that are available. Programming languages are “mechan-ical languages.” That is, unlike natural languages, mechanical languages did notevolve through human discourse. Rather, they were invented for use in specify-ing a sequence of instructions to a computer. Therefore, mechanical languages donot suﬀer from failings such as ambiguity that would make them unacceptable forspecifying a computer program.There are more than 1000 programming languages. Some have been designedfor use with particular applications, such as Fortran for solving scientiﬁc calcula-tions and COBOL for solving business data-processing problems. In the secondhalf of this book, we will use C and C++, languages that were designed formanipulating low-level hardware structures.Other languages are useful for still other purposes. Prolog is the language ofchoice for many applications that require the design of an expert system. LISPwas for years the language of choice of a substantial number of people workingon problems dealing with artiﬁcial intelligence. Pascal is a language invented asav e h i c l ef o rt e a c h i n gb e g i n n i n gs t u d e n t sh o wt op r o g r a m .There are two kinds of programming languages, high-level languages andlow-level languages. High-level languages are at a distance (a high level) fromthe underlying computer. At their best, they are independent of the computer onwhich the programs will execute. We say the language is “machine independent.”\n",
      "\n",
      "All the languages mentioned thus far are high-level languages. Low-level lan-guages are tied to the computer on which the programs will execute. There isgenerally one such low-level language for each computer. That language is calledtheassembly languagefor that computer...The ISAThe next step is to translate the program into the instruction set of the particularcomputer that will be used to carry out the work of the program. The instructionset architecture (ISA) is the complete speciﬁcation of the interface between pro-grams that have been written and the underlying computer hardware that mustcarry out the work of those programs.An analogy that may be helpful in understanding the concept of an ISA isprovided by the automobile. Corresponding to a computer program, representedas a sequence of 0s and 1s in the case of the computer, is the human sitting in thedriver’s seat of a car. Corresponding to the microprocessor hardware is the caritself. The “ISA” of the automobile is the speciﬁcation of everything the humanneeds to know to tell the automobile what to do, and everything the automobileneeds to know to carry out the tasks speciﬁed by the human driver. For example,one element of the automobile’s “ISA” is the pedal on the ﬂoor known as thebrake, and its function. The human knows that if he/she steps on the brake, thecar will stop. The automobile knows that if it feels pressure from the human onthat pedal, the hardware of the automobile must engage those elements necessaryto stop the car. The full “ISA” of the car includes the speciﬁcation of the otherpedals, the steering wheel, the ignition key, the gears, windshield wipers, etc. Foreach, the “ISA” speciﬁes (a) what the human has to do to tell the automobile whathe/she wants done, and (b) correspondingly, what the automobile will interpretthose actions to mean so it (the automobile) can carry out the speciﬁed task.The ISA of a computer serves the same purpose as the “ISA” of an auto-mobile, except instead of the driver and the car, the ISA of a computer speciﬁesthe interface between the computer program directing the computer hardwareand the hardware carrying out those directions. For example, consider the set ofinstructions that the computer can carry out—that is, what operations the com-puter can perform and where to get the data needed to perform those operations.The termopcodeis used to describe the operation. The termoperandis used todescribe individual data values. The ISA speciﬁes the acceptable representationsfor operands. They are calleddata types.Adata typeis a representation of anoperand such that the computer can perform operations on that representation.The ISA speciﬁes the mechanisms that the computer can use to ﬁgure out wherethe operands are located. These mechanisms are calledaddressing modes.The number of opcodes, data types, and addressing modes speciﬁed by anISA vary among diﬀerent ISAs. Some ISAs have as few as a half dozen opcodes,whereas others have as many as several hundred. Some ISAs have only one datatype, while others have more than a dozen. Some ISAs have one or two addressingmodes, whereas others have more than 20. The x86, the ISA used in the PC, hasmore than 200 opcodes, more than a dozen data types, and more than two dozenaddressing modes.\n",
      "\n",
      "The ISA also speciﬁes the number of unique locations that comprise the com-puter’s memory and the number of individual 0s and 1s that are contained in eachlocation.Many ISAs are in use today. The most widely known example is the x86,introduced by Intel Corporation in 1979 and currently also manufactured byAMD and other companies. Other ISAs and the companies responsible for theminclude ARM and THUMB (ARM), POWER and z/Architecture (IBM), andSPARC (Oracle).The translation from a high-level language (such as C) to the ISA of thecomputer on which the program will execute (such as x86) is usually done byat r a n s l a t i n gp r o g r a mc a l l e dacompiler.T ot r a n s l a t ef r o map r o g r a mw r i t t e ni nCt ot h ex 8 6I S A ,o n ew o u l dn e e daCt ox 8 6c o m p i l e r .F o re a c hh i g h - l e v e ll a n -guage and each desired target ISA, one must provide a corresponding compiler.The translation from the unique assembly language of a computer to its ISAis done by an assembler...The MicroarchitectureThe next step is the implementation of the ISA, referred to as itsmicroarchitec-ture. The automobile analogy that we used in our discussion of the ISA is alsouseful in showing the relationship between an ISA and a microarchitecture thatimplements that ISA. The automobile’s “ISA” describes what the driver needs toknow as he/she sits inside the automobile to make the automobile carry out thedriver’s wishes. All automobiles have the same ISA. If there are three pedals onthe ﬂoor, it does not matter what manufacturer produced the car, the middle oneis always the brake. The one on the right is always the accelerator, and the moreit is depressed, the faster the car will move. Because there is only one ISA forautomobiles, one does not need one driver’s license for Buicks and a diﬀerentdriver’s license for Hondas.The microarchitecture (or implementation) of the automobile’s ISA, onthe other hand, is about what goes on underneath the hood. Here all automo-bile makes and models can be diﬀerent, depending on what cost/performancetradeoﬀst h ea u t o m o b i l ed e s i g n e rm a d eb e f o r et h ec a rw a sm a n u f a c t u r e d .S o m eautomobiles come with disc brakes, others (in the past, at least) with drums.Some automobiles have eight cylinders, others run on six cylinders, and still oth-ers have only four. Some are turbocharged, some are not. Some automobiles cantravel 60 miles on one gallon of gasoline, others are lucky to travel from one gasstation to the next without running out of gas. Some automobiles cost 6000 USdollars, others cost 200,000 US dollars. In each case, the “microarchitecture”of the speciﬁc automobile is a result of the automobile designers’ decisionsregarding the tradeoﬀso fc o s ta n dp e r f o r m a n c e .T h ef a c tt h a tt h e“ m i c r o -architecture” of every model or make is diﬀerent is a good reason to take one’sHonda, when it is malfunctioning, to a Honda repair person, and not to a Buickrepair person.In the previous section, we identiﬁed ISAs of several computer manufactur-ers, including the x86 (Intel), the PowerPC (IBM and Motorola), and THUMB(ARM). Each has been implemented by many diﬀerent microarchitectures. For\n",
      "\n",
      "example, the x86’s original implementation in 1979 was the 8086, followed by the80286, 80386, and 80486 in the 1980s. More recently, in 2001, Intel introducedthe Pentium IV microprocessor. Even more recently, in 2015, Intel introducedSkylake. Each of these x86 microprocessors has its own microarchitecture.The story is the same for the PowerPC ISA, with more than a dozen diﬀerentmicroprocessors, each having its own microarchitecture.Each microarchitecture is an opportunity for computer designers to make dif-ferent tradeoﬀsb e t w e e nt h ec o s to ft h em i c r o p r o c e s s o r ,t h ep e r f o r m a n c et h a tt h emicroprocessor will provide, and the energy that is required to power the micro-processor. Computer design is always an exercise in tradeoﬀs, as the designeropts for higher (or lower) performance, more (or less) energy required, at greater(or lesser) cost...The Logic CircuitThe next step is to implement each element of the microarchitecture out of simplelogic circuits. Here also there are choices, as the logic designer decides how tobest make the tradeoﬀsb e t w e e nc o s ta n dp e r f o r m a n c e .S o ,f o re x a m p l e ,e v e nf o ran operation as simple as addition, there are several choices of logic circuits toperform the operation at diﬀering speeds and corresponding costs...The DevicesFinally, each basic logic circuit is implemented in accordance with the require-ments of the particular device technology used. So, CMOS circuits are diﬀerentfrom NMOS circuits, which are diﬀerent, in turn, from gallium arsenidecircuits.The Bottom LineIn summary, from the natural language description of a prob-lem to the electrons that actually solve the problem by moving from one voltagepotential to another, many transformations need to be performed. If we couldspeak electron, or if the electrons could understand English, perhaps we could justwalk up to the computer and get the electrons to do our bidding. Since we can’tspeak electron and they can’t speak English, the best we can do is this systematicsequence of transformations. At each level of transformation, there are choices asto how to proceed. Our handling of those choices determines the resulting costand performance of our computer.In this book, we describe each of these transformations. We show how tran-sistors combine to form logic circuits, how logic circuits combine to form themicroarchitecture, and how the microarchitecture implements a particular ISA.In our case, the ISA is the LC-3. We complete the process by going from theEnglish-language description of a problem to a C or C++ program that solves theproblem, and we show how that C or C++ program is translated (i.e., compiled)to the ISA of the LC-3.We hope you enjoy the ride.\n",
      "\n",
      ", Data Types, andrations.Bits and Data Types..The Bit as the Unit of InformationWe noted in Chapter 1 that the computer was organized as a system with severallevels of transformation. A problem stated in a natural language such as Englishis actually solved by the electrons moving around inside the components of thecomputer.Inside the computer, millions of very tiny, very fast devices control the move-ment of those electrons. These devices react to the presence or absence of voltagesin electronic circuits. They could react to the actual values of the voltages, ratherthan simply to the presence or absence of voltages. However, this would makethe control and detection circuits more complex than they need to be. It is mucheasier to detect simply whether or not a voltage exists at a point in a circuit thanit is to measure exactly what that voltage is.To understand this, consider any wall outlet in your home. You could measurethe exact voltage it is carrying, whether 120 volts or 115 volts, or 118.6 volts,for example. However, the detection circuitry to determineonlywhether there isav o l t a g eo rw h e t h e rt h e r ei sn ov o l t a g ei sm u c hs i m p l e r .Y o u rﬁ n g e rc a s u a l l yinserted into the wall socket, for example, will suﬃce.We symbolically represent the presence of a voltage as “1” and the absenceof a voltage as “0.” We refer to each 0 and each 1 as a “bit,” which is a shortenedform ofbinary digit.R e c a l lt h ed i g i t sy o uh a v eb e e nu s i n gs i n c ey o uw e r eachild—0,1,2,3,…,9. There are ten of them, and they are referred to as decimaldigits. In the case of binary digits, there are two of them, 0 and 1.To be perfectly precise, it is not really the case that the computer diﬀeren-tiates theabsoluteabsence of a voltage (i.e., 0) from theabsolutepresence ofa voltage (i.e., 1). Actually, the electronic circuits in the computer diﬀerentiatevoltagesclose to0 from voltagesfar from0. So, for example, if the computerexpects either a voltage of 1.2 volts or a voltage of 0 volts (1.2 volts signifying1 and 0 volts signifying 0), then a voltage of 1.0 volts will be taken as a 1 and0.2 volts will be taken as a 0.\n",
      "\n",
      "ho n ew i r e ,o n ec a nd i f f e r e n t i a t eo n l yt w ot h i n g s .O n eo ft h e mc a nb ea s s i g n e de0 ,t h eo t h e rc a nb ea s s i g n e dt h ev a l u e1 .B u tt og e tu s e f u lw o r kd o n eb yputer, it is necessary to be able to differentiate a large number of distinctand to assign each of them a unique representation. We can accomplishombining many wires, that is, many bits. For example, if we use eight bits(corresponding to the voltage present on each of eight wires), we can represent oneparticular value as 01001110, and another value as 11100111. In fact, if we are limitedto eight bits, we can differentiate at most only 256 (i.e., 28)d i f f e r e n tt h i n g s .I ng e n e r a l ,withkbits, we can distinguish at most 2kdistinct items. Each pattern of thesekbitsis a code; that is, it corresponds to a particular item (or value)...Data TypesThere are many ways to represent the same value. For example, the number ﬁvecan be written as a 5. This is the standard decimal notation that you are used to.The value ﬁve can also be represented by someone holding up one hand, with allﬁngers and thumb extended. The person is saying, “The number I wish to com-municate can be determined by counting the number of ﬁngers I am showing.” Awritten version of that scheme would be the value 11111. This notation has a namealso—unary.T h eR o m a n sh a dy e ta n o t h e rn o t a t i o nf o rﬁ v e — t h ec h a r a c t e rV .W emomentarily that a fourth notation for ﬁve is the binary representation01.sn o te n o u g hs i m p l yt or e p r e s e n tv a l u e s ;w em u s tb ea b l et oo p e r a t eo nalues. We say a particular representation is adata typeif there are oper-nt h ec o m p u t e rt h a tc a no p e r a t eo ni n f o r m a t i o nt h a ti se n c o d e di nt h a tntation. Each instruction set architecture (ISA) has its own set of data typesown set of instructions that can operate on those data types. In this book,mainly use two data types:2’s complement integersfor representing posi-tive and negative integers that we wish to perform arithmetic on, andASCII codesfor representing characters that we wish to input to a computer via the keyboard oroutput from the computer via a monitor. Both data types will be explained shortly.There are other representations of information that could be used, and indeedthat are present in most computers. Recall the “scientiﬁc notation” from highschool chemistry where you were admonished to represent the decimal num-ber 621 as 6.21/uni22C5102.T h e r ea r ec o m p u t e r st h a tr e p r e s e n tn u m b e r si nt h a tf o r m ,and they provide operations that can operate on numbers so represented. Thatdata type is usually calledﬂoating point.W ew i l le x a m i n ei t sr e p r e s e n t a t i o ni nSection 2.7.1..Integer Data Types..Unsigned IntegersThe ﬁrst representation of information, or data type, that we shall look at is theunsigned integer. As its name suggests, an unsigned integer has no sign (plus orminus) associated with it. An unsigned integer just has a magnitude. Unsigned\n",
      "\n",
      "integers have many uses in a computer. If we wish to perform a task some spe-ciﬁc number of times, unsigned integers enable us to keep track of this numbereasily by simply counting how many times we have performed the task. Unsignedintegers also provide a means for identifying diﬀerent memory locations in thecomputer in the same way that house numbers diﬀerentiate 129 Main Street from131 Main Street. I don’t recall ever seeing a house number with a minus sign infront of it.We can represent unsigned integers as strings of binary digits. To do this, weuse a positional notation much like the decimal system that you have been usingsince you were three years old.You are familiar with the decimal number 329, which also uses positionalnotation. The 3 is worth much more than the 9, even though the absolute value of3s t a n d i n ga l o n ei so n l yw o r t h1 / 3t h ev a l u eo f9s t a n d i n ga l o n e .T h i si sb e c a u s e ,as you know, the 3 stands for 300 (3/uni22C5102)d u et oi t sp o s i t i o ni nt h ed e c i m a ls t r i n g329, while the 9 stands for 9/uni22C5100.Instead of using decimal digits, we can represent unsigned integers using justthe binary digits 0 and 1. Here the base is 2, rather than 10. So, for example, ifwe have ﬁve bits (binary digits) available to represent our values, the number 5,which we mentioned earlier, is represented as 00101, corresponding to0/uni22C524+0/uni22C523+1/uni22C522+0/uni22C521+1/uni22C520Withkbits, we can represent in this positional notation exactly 2kintegers, rang-ing from 0 to 2k−1. Figure 2.1 shows the ﬁve-bit representations for the integersfrom 0 to 31...Signed IntegersTo do useful arithmetic, however, it is often (although not always) necessary tobe able to deal with negative quantities as well as positive. We could take our 2kdistinct patterns ofkbits and separate them in half, half for positive integers andhalf for negative integers. In this way, with ﬁve-bit codes, instead of representingintegers from 0 to+31, we could choose to represent positive integers from+1to+15 and negative integers from−1t o−15. There are 30 such integers. Since25is 32, we still have two 5-bit codes unassigned. One of them, 00000, we wouldpresumably assign to the value 0, giving us the full range of integer values from−15 to+15. That leaves one 5-bit code left over, and there are diﬀerent ways toassign this code, as we will see momentarily.We are still left with the problem of determining what codes to assign to whatvalues. That is, we have 32 codes, but which value should go with which code?Positive integers are represented in the straightforward positional scheme.Since there arekbits, and we wish to use exactly half of the 2kcodes to representthe integers from 0 to 2k−1−1, all positive integers will have a leading 0 in theirrepresentation. In our example of Figure 2.1 (withk=5), the largest positiveinteger+15 is represented as 01111.Note that in all threesigneddata types shown in Figure 2.1 , the represen-tation for 0 and all the positive integers start with a leading 0. What about therepresentations for the negative integers (in our ﬁve-bit example,−1t o−15)?\n",
      "\n",
      "11111 31−15−0−1Figure.Four representations of integers.The ﬁrst thought that usually comes to mind is: If a leading 0 signiﬁes apositiveinteger, how about letting a leading 1 signify anegativeinteger? The result isthesigned-magnitudedata type shown in Figure 2.1. A second thought (whichwas actually used on some early computers such as the Control Data Corpora-tion 6600) was the following: Let a negative number be represented by taking therepresentation of the positive number having the same magnitude, and “ﬂipping”all the bits. That is, if the original representation had a 0, replace it with a 1; ifit originally had a 1, replace it with a 0. For example, since+5i sr e p r e s e n t e da s00101, we designate−5a s1 1 0 1 0 .T h i sd a t at y p ei sr e f e r r e dt oi nt h ec o m p u t e rengineering community as1’s complementand is also shown in Figure 2.1.\n",
      "\n",
      "At this point, you might think that a computer designer could assign any bitpattern to represent any integer he or she wants. And you would be right! Unfor-tunately, that could complicate matters when we try to build an electronic circuitto add two integers. In fact, the signed-magnitude and 1’s complement data typesboth require unnecessarily cumbersome hardware to do addition. Because com-puter designers knew what it would take to design a circuit to add two integers,they chose representations that simpliﬁed the circuit. The result is the2’s comple-mentdata type, also shown in Figure 2.1. It is used on just about every computermanufactured today..’s Complement IntegersWe see in Figure 2.1 the representations of the integers from−16 to+15 for the2’s complement data type. Why were those representations chosen?The positive integers, we saw, are represented in the straightforward posi-tional scheme. With ﬁve bits, we use exactly half of the 25codes to represent 0and the positive integers from 1 to 24−1.The choice of representations for the negative integers was based, as we saidpreviously, on the wish to keep the logic circuits as simple as possible. Almostall computers use the same basic mechanism to perform addition. It is called anarithmetic and logic unit,u s u a l l yk n o w nb yi t sa c r o n y mA L U .W ew i l lg e ti n t othe actual structure of the ALU in Chapters 3 and 4. What is relevant right nowis that an ALU has two inputs and one output. It performs addition by adding thebinary bit patterns at its inputs, producing a bit pattern at its output that is thesum of the two input bit patterns.For example, if the ALU processewere 00110 and 00101, the result (oaddition is as follows:001100010101011The addition of two binary strings is performed in the same way the addi-tion of two decimal strings is performed, from right to left, column by column.If the addition in a column generates a carry, the carry is added to the columnimmediately to its left.What is particularly relevant is that the binary ALU does not know (and doesnot care) what the two patterns it is adding represent. It simply adds the two binarypatterns. Since the binary ALU only ADDs and does not CARE, it would be niceif our assignment of codes to the integers resulted in the ALU producing correctresults when it added two integers.For starters, it would be nice if, when the ALU adds the representation for anarbitrary integer to the representation of the integer having the same magnitudebut opposite sign, the sum would be 0. That is, if the inputs to the ALU are therepresentations of non-zero integersAand−A,t h eo u t p u to ft h eA L Us h o u l dbe 00000.\n",
      "\n",
      "To accomplish that, the 2’s complement data type speciﬁes the representationfor each negative integer so that when the ALU adds it to the representation ofthe positive integer of the same magnitude, the result will be the representationfor 0. For example, since 00101 is the representation of+5, 11011 is chosen asthe representation for−5.Moreover, and actually more importantly, as we sequence through represen-tations of−15 to+15, the ALU is adding 00001 to each successive representation.We can express this mathematically as:REPRESENTATION(value+1)=REPRESENTATION(value)+REPRESENTATION(1).This is suﬃcient to guarantee (as long as we do not get a result larger than+15 or smaller than−15) that the binary ALU will perform addition correctly.Note in particular the representations for−1a n d0 ,t h a ti s ,1 1 1 1 1a n d0 0 0 0 0 .When we add 00001 to the representation for−1, we do get 00000, but we alsogenerate a carry. That carry, however, does not inﬂuence the result. That is, thecorrect result of adding 00001 to the representation for−1i s0 ,n o t1 0 0 0 0 0 .Therefore, the carry is ignored. In fact, because the carry obtained by adding00001 to 11111 is ignored, the carry canalwaysbe ignored when dealing with2’s complement arithmetic.Note:If we know the representation forA,as h o r t c u tf o rﬁ g u r i n go u tt h erepresentation for−A(A/uni22600) is as follows: Flip all the bits ofA(the oﬃcial termfor “ﬂip” iscomplement), and add 1 to the complement ofA.T h es u mo fAa n dExa\n",
      "1001100000You may have noticed that the addition of 01101 and 10011, in addition toproducing 00000, also produces a carry out of the ﬁve-bit ALU. That is, the binaryaddition of 01101 and 10011 is really 100000. However, as we saw previously,this carry out can be ignored in the case of the 2’s complement data type.At this point, we have identiﬁed in our ﬁve-bit scheme 15 positive inte-gers. We have constructed 15 negative integers. We also have a representation\n",
      "\n",
      "for 0. Withk=5, we can uniquely identify 32 distinct quantities, and we haveaccounted for only 31 (15+15+1). The remaining representation is 10000. Whatvalue shall we assign to it?We note that−1i s1 1 1 1 1 ,−2i s1 1 1 1 0 ,−3i s1 1 1 0 1 ,a n ds oo n .I fw ec o n t i n u ethis, we note that−15 is 10001. Note that, as in the case of the positive represen-tations, as we sequence backwards from representations of−1t o−15, the ALUis subtracting 00001 from each successive representation. Thus, it is convenientto assign to 10000 the value−16; that is the value one gets by subtracting 00001from 10001 (the representation for−15).In Chapter 5 we will specify a computer that we aﬀectionately have namedthe LC-3 (for Little Computer 3). The LC-3 operates on 16-bit values. Therefore,the 2’s complement integers that can be represented in the LC-3 are the integersfrom−32,768 to+32,767..Conversion Between Binary andDecimalIt is often useful to convert numbers between the 2’s complement data typethe computer likes and the decimal representation that you have used allyour life...Binary to Decimal ConversionWe convert a 2’s complement representation of an integer to a decimal represen-tation as follows: For purposes of illustration, we will assume our number can berepresented in eight bits, corresponding to decimal integer values from−128 to+127.Recall that an eight-bit 2’s complement integer takes the formb7b6b5b4b3b2b1b0where each of the bitsbiis either 0 or 1.1. Examine the leading bitb7. If it is a 0, the integer is positive, and we canbegin evaluating its magnitude. If it is a 1, the integer is negative. In thatcase, we need to ﬁrst obtain the 2’s complement representation of thepositive number having the same magnitude. We do this by ﬂipping all thebits and adding 1.2. The magnitude is simplyb6/uni22C526+b5/uni22C525+b4/uni22C524+b3/uni22C523+b2/uni22C522+b1/uni22C521+b0/uni22C520In either case, we obtain the decimal magnitude by simply adding thepowers of 2 that have coeﬃcients of 1.3. Finally, if the original number is negative, we aﬃxam i n u ss i g ni nf r o n t .Done!\n",
      "\n",
      "Exa\n",
      ".3. The decimal integer value corresponding to 11000111 is−57...Decimal to Binary ConversionConverting from decimal to 2’s complement is a little more complicated. Thecrux of the method is to note that a positive binary number isoddif the rightmostdigit is 1 andevenif the rightmost digit is 0.Consider again our generic eight-bit representation:b7/uni22C527+b6/uni22C526+b5/uni22C525+b4/uni22C524+b3/uni22C523+b2/uni22C522+b1/uni22C521+b0/uni22C520We can illustrate the conversion best by ﬁrst working through an example.Suppose we wish to convert the value+105 to a 2’s complement binary code.We note that +105 is positive. We ﬁrst ﬁnd values forbi,r e p r e s e n t i n gt h em a g -nitude 105. Since the value is positive, we will then obtain the 2’s complementresult by simply appendingb7,w h i c hw ek n o wi s0 .Our ﬁrst step is to ﬁnd values forbithat satisfy the following:105=b6/uni22C526+b5/uni22C525+b4/uni22C524+b3/uni22C523+b2/uni22C522+b1/uni22C521+b0/uni22C520Since 105 is odd, we know thatb0is 1. We subtract 1 from both sides of theequation, yielding104=b6/uni22C526+b5/uni22C525+b4/uni22C524+b3/uni22C523+b2/uni22C522+b1/uni22C521We next divide both sides of the equation by 2, yielding52=b6/uni22C525+b5/uni22C524+b4/uni22C523+b3/uni22C522+b2/uni22C521+b1/uni22C520Since 52 is even,b1,t h eo n l yc o eﬃcient not multiplied by a power of 2, must beequal to 0.We iterate this process, each time subtracting the rightmost digit from bothsides of the equation, then dividing both sides by 2, and ﬁnally noting whetherthe new decimal number on the left side is odd or even. Continuing where we leftoﬀ,w i t h52=b6/uni22C525+j5/uni22C524+b4/uni22C523+b3/uni22C522+b2/uni22C521the process produces, in turn:26=b6/uni22C524+b5/uni22C523+b4/uni22C522+b3/uni22C521+b2/uni22C520\n",
      "\n",
      "Therefore,b2=0.13=b6/uni22C523+b5/uni22C522+b4/uni22C521+b3/uni22C520Therefore,b3=1.6=b6/uni22C522+b5/uni22C521+b4/uni22C520Therefore,b4=0.3=b6/uni22C521+b5/uni22C520Therefore,b5=1.1=b6/uni22C520Therefore,b6=1, and we are done. The binary representation is 01101001.Let’s summarize the process. If we are given a decimal integer valueN,w econstruct the 2’s complement representation as follows:1. We ﬁrst obtain the binary representation of the magnitude ofNby formingthe equationN=b6/uni22C526+b5/uni22C525+b4/uni22C524+b3/uni22C523+b2/uni22C522+b1/uni22C521+b0/uni22C520and repeating the following, until the left side of the equation is 0:a. IfNis odd, the rightmost bit is 1. IfNis even, the rightmost bit is 0.b. Subtract 1 or 0 (according to whetherNis odd or even) fromN,r e m o v ethe least signiﬁcant term from the right side, and divide both sides ofthe equation by 2.Each iteration produces the value of one coeﬃcientbi.2. If the original decimal number is positive, append a leading 0 sign bit, andyou are done.3. If the original decimal number is negative, append a leading 0 and thenform the negative of this 2’s complement representation, and then youare done...Extending Conversion to Numbers with Fractional PartsWhat if the number we wish to convert is not an integer, but instead has afractional part. How do we handle that wrinkle?Binary to decimalThe binary to decimal case is straightforward. In a positionalnotation system, the number0.b−1b−2b−3b−4shows four bits to the right of the binary point, representing (when the cor-respondingbi=1 )t h ev a l u e s0 . 5 ,0 . 2 5 ,0 . 1 2 5 ,a n d0 . 0 6 2 5 .T oc o m p l e t et h e\n",
      "\n",
      "conversion to decimal, we simply add those values where the correspondingbi=1. For example, if the fractional part of the binary representation is.1011we would add 0.5 plus 0.125 plus 0.0625, or 0.6875.Decimal to binaryThe decimal to binary case requires a little more work. Sup-pose we wanted to convert 0.421 to binary. As we did for integer conversion, weﬁrst form the equation0.421=b−1×2−1+b−2×2−2+b−3×2−3+b−4×2−4+...In the case of converting a decimal integer value to binary, we divided by 2 andassigned a 1 or 0 to the coeﬃcient of 20depending on whether the number on theleft of the equal sign is odd or even. Here (i.e., in the case of converting a decimalfraction to binary), we multiply both sides of the equation by 2 and assign a 1 ora0t ot h ec o eﬃcient of 20depending on whether the left side of the equation isgreater than or equal to 1 or whether the left side is less than 1. Do you see why?Since0.842=b−1×20+b−2×2−1+b−3×2−2+b−4×2−3+...we assignb−1=0. Continuing,1.684=b−2×20+b−3×2−1+b−4×2−2+...so we assignb−2=1 and subtract 1 from both sides of the equation, yielding0.684=b−3×2−1+b−4×2−2+...Multiplying by 2, we get1.368=b−3×20+b−4×2−1+...so we assignb−3=1 and subtract 1 from both sides of the equation, yielding0.368=b−4×20+...which assigns 0 tob−4.W ec a nc o n t i n u et h i sp r o c e s si n d e ﬁ n i t e l y ,u n t i lw ea r esimply too tired to go on, or until the left side = 0, in which case all bits tothe right of where we stop are 0s. In our case, stopping with four bits, we haveconverted 0.421 decimal to 0.0110 in binary..Operations on Bits—Part I: Arithmetic..Addition and SubtractionArithmetic on 2’s complement numbers is very much like the arithmetic ondecimal numbers that you have been doing for a long time.\n",
      "\n",
      "Addition still proceeds from right to left, one digit at a time. At each point,we generate a sum digit and a carry. Instead of generating a carry after 9 (since9 is the largest decimal digit), we generate a carry after 1 (since 1 is the largestbinary digit).Example.Using our ﬁve-bit notation, what is 11+3?The decimal value 11 is represented as 01011The decimal value 3 is represented as 00011The sum, which is the value 14, is 01110Subtraction is simply addition, preceded by determining the negative of thenumber to be subtracted. That is,A−Bis simplyA+(−B).Example.What is 14−9?The decimal value 14 is represented as 01110The decimal value 9 is represented as 01001First we form the negative, that is, -9: 10111Adding 14 to -9, we get 0111010111which results in the value 5. 00101Note again that the carry out is ignored.ExamWhat happens when we add a number to itself (e.g.,x+x)?Let’s assume for this example eight-bit codes, which would allow us to representintegers from−128 to 127. Consider a value forx,t h ei n t e g e r5 9 ,r e p r e s e n t e da s00111011. If we add 59 to itself, we get the code 01110110. Note that the bits haveall shifted to the left by one position. Is that a curiosity, or will that happen all thetime as long as the sumx+xis not too large to represent with the available numberof bits?Using our positional notation, the number 59 is0/uni22C526+1/uni22C525+1/uni22C524+1/uni22C523+0/uni22C522+1/uni22C521+1/uni22C520The sum 59+59 is 2/uni22C559, which, in our representation, is2/uni22C5(0/uni22C526+1/uni22C525+1/uni22C524+1/uni22C523+0/uni22C522+1/uni22C521+1/uni22C520)But that is nothing more than0/uni22C527+1/uni22C526+1/uni22C525+1/uni22C524+0/uni22C523+1/uni22C522+1/uni22C521which shifts each digit one position to the left. Thus, adding a number to itself(provided there are enough bits to represent the result) is equivalent to shifting therepresentation one bit position to the left.\n",
      "\n",
      "..Sign-ExtensionIt is often useful to represent a small number with fewer bits. For example, ratherthan represent the value 5 as 0000000000000101, there are times when it makesnse to use only six bits to represent the value 5: 000101. There is littlen, since we are all used to adding leading zeros without aﬀecting thea number. A check for $456.78 and a check for $0000456.78 are checkshe same value.at about negative representations? We obtained the negative representa-its positive counterpart by complementing the positive representationing 1. Thus, the representation for−5, given that 5 is represented as,i s1 1 1 0 1 1 .I f5i sr e p r e s e n t e da s0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 ,t h e nt h er e p r e s e n -tation for−5i s1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 .I nt h es a m ew a yt h a tl e a d i n g0 sd on o taﬀectthe value of a positive number, leading 1s do not aﬀect the value of a negativenumber.In order to add representations of diﬀerent lengths, it is ﬁrst necessary torepresent them with the same number of bits. For example, suppose we wish toadd the number 13 to−5, where 13 is represented as 0000000000001101 and−5is represented as 111011. If we do not represent the two values with the samenumber of bits, we have0000000000001101+1 1 1 0 1 1When we attempt to perform the addition, what shall we do with the missing bitsin the representation for−5? If we take the absence of a bit to be a 0, then we areno longer adding−5t o1 3 .O nt h ec o n t r a r y ,i fw et a k et h ea b s e n c eo fb i t st ob e0 s ,we have changed the−5t ot h en u m b e rr e p r e s e n t e da s0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 ,t h a tis,+59. Not surprisingly, then, our result turns out to be the representation for 72.However, if we understand that a 6-bit−5a n da1 6 - b i t−5d iﬀer only in thenumber of meaningless leading 1s, then we ﬁrst extend the value of−5t o1 6b i t sbefore we perform the addition. Thus, we have0000000000001101+1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 10000000000001000result is+8, as we should expect.ev a l u eo fap o s i t i v en u m b e rd o e sn o tc h a n g ei fw ee x t e n dt h es i g nb i tany bit positions to the left as desired. Similarly, the value of a negativerd o e sn o tc h a n g eb ye x t e n d i n gt h es i g nb i t1a sm a n yb i tp o s i t i o n st ot h edesired. Since in both cases it is the sign bit that is extended, we referto the operation asSign-EXTension,o f t e na b b r e v i a t e dS E X T .S i g n - e x t e n s i o ni sperformed in order to be able to operate on representations of diﬀerent lengths.It does not aﬀect the values of the numbers being represented...OverﬂowUp to now, we have always insisted that the sum of two integers be small enoughto be represented by the available bits. What happens if such is not the case?\n",
      "\n",
      "You are undoubtedly familiar with the odometer on the front dashboard ofyour automobile. It keeps track of how many miles your car has been driven—butonly up to a point. In the old days, when the odometer registered 99992 and youdrove it 100 miles, its new reading became 00092. A brand new car! The problem,as you know, is that the largest value the odometer could store was 99999, so thevalue 100092 showed up as 00092. The carry out of the ten-thousands digit waslost. (Of course, if you grew up in Boston, the carry out was not lost at all—itwas in full display in the rusted chrome all over the car.)We say the odometeroverﬂowed.R e p r e s e n t i n g1 0 0 0 9 2a s0 0 0 9 2i su n a c c e p t -able. As more and more cars lasted more than 100,000 miles, car makers felt thepressure to add a digit to the odometer. Today, practically all cars overﬂow at1,000,000 miles, rather than 100,000 miles.The odometer provides an example of unsigned arithmetic. The miles youadd are always positive miles. The odometer reads 000129 and you drive 50 miles.The odometer now reads 000179. Overﬂow is a carry out of the leading digit.In the case of signed arithmetic, or more particularly, 2’s complementarithmetic, overﬂow is a little more subtle.Let’s return to our ﬁve-bit 2’s complement data type, which allowed us torepresent integers from−16 to+15. Suppose we wish to add+9a n d+11. Ourarithmetic takes the following form:010010101110100Note that the sum is larger than+15, and therefore too large to represent withour 2’s complement scheme. The fact that the number is too large means that thenumber is larger than 01111, the largest positive number we can represent withaﬁ v e - b i t2 ’ sc o m p l e m e n td a t at y p e .N o t et h a tb e c a u s eo u rp o s i t i v er e s u l tw a slarger than+15, it generated a carry into the leading bit position. But this bitposition is used to indicate the sign of a value. Thus, detecting that the result istoo large is an easy matter. Since we are adding two positive numbers, the resultmust be positive. Since the ALU has produced a negative result, something mustbe wrong. The thing that is wrong is that the sum of the two positive numbersis too large to be represented with the available bits. We say that the result hasoverﬂowedthe capacity of the representation.Suppose instead, we had started with negative numbers, for example,−12and−6. In this case, our arithmetic takes the following form:101001101001110Here, too, the result has overﬂowed the capacity of the machine, since−12+−6equals−18, which is “more negative” than−16, the negative number with thelargest allowable magnitude. The ALU obliges by producing a positive result.Again, this is easy to detect since the sum of two negative numbers cannot bepositive.\n",
      "\n",
      "Note that the sum of a negative number and a positive number never presentsap r o b l e m .W h yi st h a t ?S e eE x e r c i s e2 . 2 5 ..Operations on Bits—Part II: Logical OperationsWe have seen that it is possible to perform arithmetic (e.g., add, subtract) on val-ues represented as binary patterns. Another class of operations useful to performon binary patterns is the set oflogicaloperations...AL o g i c a lV a r i a b l eLogical operations operate on logical variables. A logical variable can have oneof two values, 0 or 1. The namelogicalis a historical one; it comes from the factthat the two values 0 and 1 can represent the two logical valuesfalseandtrue,but the use of logical operations has traveled far from this original meaning.There are several basic logic functions, and most ALUs perform all of them...The AND FunctionAND is abinarylogical function. This means it requires two pieces of input data.Said another way, AND requires two source operands. Each source is a logicalvariable, taking the value 0 or 1. The output of AND is 1 only if both sources havethe value 1. Otherwise, the output is 0. We can think of the AND operation as theALL operation; that is, the output is 1 only if ALL two inputs are 1. Otherwise,the output is 0.Ac o n v e n i e n tm e c h a n i s mf o rr e p r e s e n t i n gt h eb e h a v i o ro fal o g i c a lo p e r a t i o nis thetruth table.At r u t ht a b l ec o n s i s t so fn+1c o l u m n sa n d2nrows. The ﬁrstncolumns correspond to thensource operands. Since each source operand is alogical variable and can have one of two values, there are 2nunique values thatthese source operands can have. Each such set of values (sometimes called aninput combination)i sr e p r e s e n t e da so n er o wo ft h et r u t ht a b l e .T h eﬁ n a lc o l u m nin the truth table shows the output for each input combination.In the case of a two-input AND function, the truth table has two columns forsource operands, and four (22)r o w sf o ru n i q u ei n p u tc o m b i n a t i o n s .ABAND000010100111We can apply the logical operation AND to two bit patterns ofmbits each. Thisinvolves applying the operation individually and independently to each pair of\n",
      "\n",
      "bits in the two source operands. For example, ifaandbin Example 2.6 are 16-bit patterns, thencis the AND ofaandb.T h i so p e r a t i o ni so f t e nc a l l e dabit-wise ANDbecause the operation is applied to each pair of bits individually andindependently.Example.Ifcis the AND ofaandb,w h e r ea=0011101001101001 andb=0101100100100001,what isc?We form the AND ofaandbby bit-wise ANDing the two values.That means individually ANDing each pair of bitsaiandbito formci.F o rexample, sincea0=1 andb0=1,c0is the AND ofa0andb0,w h i c hi s1 .Sincea6=1 andb6=0,c6is the AND ofa6andb6,w h i c hi s0 .The complete solution forcisa: 0011101001101001b: 0101100100100001c: 0001100000100001ExamSuppose we have an eight-bit pattern—let’s call itA—in which the rightmost twobits have particular signiﬁcance. The computer could be asked to do one of four tasksdepending on the value stored in the two rightmost bits ofA. Can we isolate thosetwo bits?Yes, we can, using a bit mask. Abit maskis a binary pattern that enables the bitsofAto be separated into two parts—generally the part you care about and the partyou wish to ignore. In this case, the bit mask 00000011 ANDed withAproduces 0 inbit positions 7 through 2, and the original values of bits 1 and 0 ofAin bit positions1a n d0 .T h eb i tm a s ki ss a i dt omask outthe values in bit positions 7 through 2.IfAis 01010110, the AND ofAand the bit mask 00000011 is 00000010. IfAis11111100, the AND ofAand the bit mask 00000011 is 00000000.That is, the result of ANDing any eight-bit pattern with the mask 00000011 isone of the four patterns: 00000000, 00000001, 00000010, or 00000011. The resultof ANDing with the mask is to highlight the two bits that are relevant...The OR FunctionOR is also abinarylogical function. It requires two source operands, both ofwhich are logical variables. The output of OR is 1 if any source has the value 1.Only if both sources are 0 is the output 0. We can think of the OR operation asthe ANY operation; that is, the output is 1 if ANY of the two inputs are 1.The truth table for a two-input OR function isABOR000011101111In the same way that we applied the logical operation AND to twom-bit patterns,we can apply the OR operation bit-wise to twom-bit patterns.\n",
      "\n",
      "Example.Ifcis the OR ofaandb,w h e r ea=0011101001101001 andb=0101100100100001,as before, what isc?We form the OR ofaandbby bit-wise ORing the two values. That meansindividually ORing each pair of bitsaiandbito formci.F o re x a m p l e ,s i n c ea0=1andb0=1,c0is the OR ofa0andb0, which is 1. Sincea6=1 andb6=0,c6is the ORofa6andb6,w h i c hi sa l s o1 .The complete solution forcisa: 0011101001101001b: 0101100100100001c: 0111101101101001Sometimes this OR operation is referred to as theinclusive-ORin order to distinguishit from the exclusive-OR function, which we will discuss momentarily...The NOT FunctionNOT is aunarylogical function. This means it operates on only one sourceoperand. It is also known as thecomplementoperation. The output is formed bycomplementing the input. We sometimes say the output is formed byinvertingthe input. A 1 input results in a 0 output. A 0 input results in a 1 output.The truth table for the NOT function isANOT0110In the same way that we applied the logical operation AND and OR to twom-bitpatterns, we can apply the NOT operation bit-wise to onem-bit pattern. Ifais asbefore, thencis the NOT ofa.a: 0011101001101001c: 1100010110010110..The Exclusive-OR FunctionExclusive-OR, often abbreviated XOR, is abinarylogical function. It, too,requires two source operands, both of which are logical variables. The outputof XOR is 1 if one (but not both) of the two sources is 1. The output of XOR is 0if both sources are 1 or if neither source is 1. In other words, the output of XOR is1i ft h et w os o u r c e sa r ed iﬀerent. The output is 0 if the two sources are the same.The truth table for the XOR function isABXOR000011101110\n",
      "\n",
      "In the same way that we applied the logical operation AND to twom-bit patterns,we can apply the XOR operation bit-wise to twom-bit patterns.Example.Ifaandbare 16-bit patterns as before, thenc(shown here) is the XOR ofaandb.a: 0011101001101001b: 0101100100100001c: 0110001101001000Note the distinction between the truth table for XOR shown here and the truth tablefor OR shown earlier. In the case of exclusive-OR, if both source operands are 1, theoutput is 0. That is, the output is 1 if the ﬁrst operand is 1 but the second operand isnot 1 or if the second operand is 1 but the ﬁrst operand is not 1. The termexclusiveis used because the output is 1 ifonlyone of the two sources is 1. The OR function,on the other hand, produces an output 1 if only one of the two sources is 1, or if bothsources are 1. Ergo, the nameinclusive-OR.Example.Suppose we wish to know if two patterns are identical. Since the XOR function pro-duces a 0 only if the corresponding pair of bits is identical, two patterns are identicalif the output of the XOR is all 0s...DeMorgan’s LawsThere are two well-known relationships between AND functions and OR func-t’\n",
      "101000011101Figure.DeMorgan’s Law.\n",
      "\n",
      "theB=funreprAANDB=AORBWe can also state this behavior in English:“It is not the case that bothAandBare false” is equivalent to saying “At leastone ofAandBis true.”This equivalence is known as one of two DeMorgan’s Laws. Question: Is thereas i m i l a rr e s u l ti fo n ei n v e r t sb o t hi n p u t st oa nO Rf u n c t i o n ,a n dt h e ni n v e r t st h eoutput?..The Bit VectorWe have discussed the AND, OR, and NOT functions performed onm-bit pat-terns, where each of thembits is a logical value (0 or 1) and the operations are per-formed bit-wise (i.e., individually and independently). We have also discussed theuse of anm-bit bit mask, where our choice of 0 or 1 for each bit allows us to isolatethe bits we are interested in focusing on and ignore the bits that don’t matter.Anm-bit pattern where each bit has a logical value (0 or 1) independent ofthe other bits is called abit vector. It is a convenient mechanism for identifyingap r o p e r t ys u c ht h a ts o m eo ft h eb i t si d e n t i f yt h ep r e s e n c eo ft h ep r o p e r t ya n dother bits identify the absence of the property.There are many uses for bit vectors. The most common use is a bit mask,as we saw in Example 2.7. In that example, we had an eight-bit value, and wewanted to focus on bit 1 and bit 0 of that value. We did not care about the otherbits. Performing the AND of that value with the bit mask 00000011 caused bit 7through bit 2 to be ignored, resulting in the AND function producing 00000000,00000001, 00000010, or 00000011, depending on the values of bit 1 and bit 0.The bit mask is a bit vector, where the property of each of the bits is whether ornot we care about that bit. In Example 2.7, we only cared about bit 1 and bit 0.Another use of a bit mask could involve a 16-bit 2’s complement integer.Suppose the only thing we cared about was whether the integer was odd or evenand whether it was positive or negative. The bit vector 1000000000000001 has a 1 inbit 15 that is used to identify a number as positive or negative, anda1i nb i t0t h a ti sused to identify if the integer is odd or even. If we perform the AND of this bit vectorwith a 16-bit 2’s complement integer, we would get one of four results, dependingon whether the integer was positive or negative and odd or even:0000000000000000000000000000000110000000000000001000000000000001Another common use of bit vectors involves managing a complex systemmade up of several units, each of which is individually and independently either\n",
      "\n",
      "busyoravailable. The system could be a manufacturing plant where each unit isap a r t i c u l a rm a c h i n e .O rt h es y s t e mc o u l db eat a x i c a bn e t w o r kw h e r ee a c hu n i tis a particular taxicab. In both cases, it is important to identify which units arebusy and which are available so that work can be properly assigned.Say we havemsuch units. We can keep track of thesemunits with a bitvector, where a bit is 1 if the unit is free and 0 if the unit is busy.Example.Suppose we have eight machines that we want to monitor with respect to their avail-ability. We can keep track of them with an eight-bit BUSYNESS bit vector, where abit is 1 if the unit is free and 0 if the unit is busy. The bits are labeled, from right toleft, from 0 to 7.The BUSYNESS bit vector 11000010 corresponds to the situation where onlyunits 7, 6, and 1 are free and therefore available for work assignment.Suppose work is assigned to unit 7. We update our BUSYNESS bit vector by per-forming the logical AND, where our two sources are the current bit vector 11000010and the bit mask 01111111. The purpose of the bit mask is to clear bit 7 of theBUSYNESS bit vector, while leaving alone the values corresponding to all the otherunits. The result is the bit vector 01000010, indicating that unit 7 is now busy.Suppose unit 5 ﬁnishes its task and becomes idle. We can update theBUSYNESS bit vector by performing the logical OR of it with the bit mask00100000. The result is 01100010, indicating that unit 5 is now available..Other RepresentationsThere are many other representations of information that are used in computers.Two that are among the most useful are the ﬂoating point data type and ASCIIcodes. We will describe both in this section. We will also describe a notationcalled hexadecimal that, although not a data type, is convenient for humans touse when dealing with long strings of 0s and 1s...Floating Point Data Type (Greater Range, Less Precision)Most of the arithmetic in this book uses integer values. The LC-3 computer, whichyou will start studying in Chapter 4, uses the 16-bit, 2’s complement integer datatype. That data type provides one bit to identify whether the number is positiveor negative and 15 bits to represent the magnitude of the value. With 16 bits usedin this way, we can express integer values between−32,768 and+32,767, thatis, between−215and+215−1. We say theprecisionof our value is 15 bits, andtherangeis 216.A sy o ul e a r n e di nh i g hs c h o o lc h e m i s t r yc l a s s ,s o m e t i m e sw eneed to express much larger numbers, but we do not require so many digits ofprecision. In fact, recall the value 6.022/uni22C51023,w h i c hy o um a yh a v eb e e nr e q u i r e dto memorize back then. The range needed to express the value 1023is far greaterthan the largest value 215−1 that is available with 16-bit 2’s complement integers.On the other hand, the 15 bits of precision available with 16-bit 2’s complementintegers are overkill. We need only enough bits to express four signiﬁcant decimaldigits (6022).\n",
      "\n",
      "So we have a problem. We have more bits than we need for precision. But wedon’t have enough bits to represent the range.Theﬂoating pointdata type solves the problem. Instead of using all the bitsto represent the precision of a value, the ﬂoating point data type allocates some ofthe bits to the range of values (i.e., how big or how small) that can be expressed.The rest of the bits (except for the sign bit) are used for precision.Most ISAs today specify more than one ﬂoating point data type. One of them,usually calledﬂoat,c o n s i s t so f3 2b i t s ,a l l o c a t e da sf o l l o w s :IFigure.The-bit ﬂoating point data type....Normalized FormLike Avogadro’s number that you learned years ago, the ﬂoating point data typerepresents numbers expressed in scientiﬁc notation, and mostly in normalizedform:N=(−1)S×1.fraction×2exponent−127,1/uni2264exponent/uni2264254whereS,fraction,a n dexponentare the binary numbers in the ﬁelds of Figure 2.3.We saymostlyin normalized form because (as noted in the equation) the datatype represents a ﬂoating point number in normalized formonlyif the eight-bitexponent is restricted to the 254 unsigned integer values, 1 (00000001) through254 (11111110).As you know, with eight bits, one can represent 256 values uniquely. For theother two integer values 0 (00000000) and 255 (11111111), the ﬂoating pointdata type does not represent normalized numbers. We will explain what it doesrepresent in Section 2.7.1.2 and Section 2.7.1.3.Recall again Avogadro’s number: (a) an implied+sign (often left out whenthe value is positive), (b) four decimal digits 6.022 in normalized form (one non-zero decimal digit 6 before the decimal point) times (c) the radix 10 raised tothe power 23. The computer’s 32-bit ﬂoating point data type, on the other hand,consists of (a) a sign bit (positive or negative), (b) 24 binary digits in normalizedform (one non-zero binary digit to the left of the binary point) times (c) the radix2r a i s e dt oa ne x p o n e n te x p r e s s e di ne i g h tb i t s .We determine the value of the 32-bit ﬂoating point representation shown inFigure 2.3 by examining its three parts.\n",
      "\n",
      "The sign bit S is just a single binary digit, 0 for positive numbers, 1 for neg-ative numbers. The formula contains the factor−1S,w h i c he v a l u a t e st o+1i fS=0, and−1i fS=1.The 23 fraction bits form the 24-bit quantity 1.fraction, wherenormalizedformdemands exactly one non-zero binary digit to the left of the binary point.Since there exists only one non-zero binary digit (i.e., the value 1), it is unneces-sary to explicitly store that bit in our 32-bit ﬂoating point format. In fact that ishow we get 24 bits of precision, the 1 to the left of the binary point that is alwayspresent in normalized numbers and so is unnecessary to store, and the 23 bits offraction that are actually part of the 32-bit data type.The eight exponent bits are encoded in what we call an excess code, namedfor the notion that one can get the *real* exponent by treating the code asan unsigned integer and subtracting the excess (sometimes called thebias). Inthe case of the IEEE Floating Point that almost everyone uses, that excess (orbias) is 127 for 32-bit ﬂoating point numbers. Thus, an exponent ﬁeld contain-ing 10000110 corresponds to the exponent +7 (since 10000110 represents theunsigned integer 134, from which we subtract 127, yielding +7). An exponentﬁeld containing 00000111 corresponds to the exponent−120 (since 00000111represents the unsigned integer 7, from which we subtract 127, yielding−120).The exponent ﬁeld gives us numbers as large as 2+127for an exponent ﬁeld con-taining 254 (11111110) and as small as 2−126for an exponent ﬁeld containing1 (00000001).Example.What does the ﬂoating point data type00111101100000000000000000000000represent?The leading bit is a 0. This signiﬁes a positive number. The next eight bitsrepresent the unsigned number 123. If we subtract 127, we get the actual expo-nent−4. The last 23 bits are all 0. Therefore, the number being represented is+1.000000000000000000000000/uni22C52−4,w h i c hi s116.Example.How is the number−658represented in the ﬂoating point data type?First, we express−658as a binary number:−110.101.−(1/uni22C522+1/uni22C521+0/uni22C520+1/uni22C52−1+0/uni22C52−2+1/uni22C52−3)Then we normalize the value, yielding−1.10101/uni22C522.The sign bit is 1, reﬂecting the fact that−658is a negative number. The exponentﬁeld contains 10000001, the unsigned number 129, reﬂecting the fact that the realexponent is+2( 1 2 9−127=+2). The fraction is the 23 bits of precision, after remov-ing the leading 1. That is, the fraction is 10101000000000000000000. The result isthe number−658, expressed as a ﬂoating point number:1 10000001 10101000000000000000000\n",
      "\n",
      "Example.The following three examples provide further illustrations of the interpretation ofthe 32-bit ﬂoating point data type according to the rules of the IEEE standard.0 10000011 00101000000000000000000is 1.00101/uni22C524=18.5The exponent ﬁeld contains the unsigned number 131. Since 131−127 is 4, theexponent is+4. Combining a 1 to the left of the binary point with the fraction ﬁeldto the right of the binary point yields 1.00101. If we move the binary point fourpositions to the right, we get 10010.1, which is 18.5.1 10000010 00101000000000000000000is−1/uni22C51.00101/uni22C523=−9.25The sign bit is 1, signifying a negative number. The exponent is 130, signifying anexponent of 130−127, or+3. Combining a 1 to the left of the binary point withthe fraction ﬁeld to the right of the binary point yields 1.00101. Moving the binarypoint three positions to the right, we get 1001.01, which is−9.25.0 11111110 11111111111111111111111is/uni223C2128The sign is+.T h ee x p o n e n ti s2 5 4−127, or+127. Combining a 1 to the leftof the binary point with the fraction ﬁeld to the right of the binary point yields1.11111111…1, which is approximately 2. Therefore, the result is approximately2128....InﬁnitiesWe noted above that the ﬂoating point data type represented numbers expressedin scientiﬁc notation in normalized form provided the exponent ﬁeld does notcontain 00000000 or 11111111.If the exponent ﬁeld contains 11111111, we use the ﬂoating point data type torepresent various things, among them the notion of inﬁnity.Inﬁnityis representedby the exponent ﬁeld containing all 1s and the fraction ﬁeld containing all 0s. Werepresent positive inﬁnity if the sign bit is 0 and negative inﬁnity if the sign bit is 1....Subnormal NumbersThe smallest number that can be represented in normalized form isN=1.00000000000000000000000×2−126What about numbers smaller than 2−126but larger than 0? We call such num-berssubnormal numbersbecause they cannot be represented in normalized form.The largest subnormal number isN=0.11111111111111111111111×2−126The smallest subnormal number isN=0.00000000000000000000001×2−126,i . e . ,2−23×2−126which is 2−149.Note that the largest subnormal number is 2−126minus 2−149.D oy o us e ew h ythat is the case?\n",
      "\n",
      "Subnormal numbers are numbers of the formN=(−1)S×0.fraction×2−126We represent them with an exponent ﬁeld of 00000000. The fraction ﬁeld isrepresented in the same way as with normalized numbers. That is, if the expo-nent ﬁeld contains 00000000, the exponent is−126, and the signiﬁcant digits areobtained by starting with a leading 0, followed by a binary point, followed by the23 bits of the fraction ﬁeld.Example.What number corresponds to the following ﬂoating point representation?0 00000000 00001000000000000000000Answer: The leading 0 means the number is positive. The next eight bits, a zeroexponent, means the exponent is−126, and the bit to the left of the binary point is 0.The last 23 bits form the number 0.00001000000000000000000, which equals 2−5.Thus, the number represented is 2−5/uni22C52−126,w h i c hi s2−131.Including subnormal numbers allows very, very tiny numbers to be repre-sented.Ad e t a i l e du n d e r s t a n d i n go fI E E EF l o a t i n gP o i n tA r i t h m e t i ci sw e l lb e y o n dwhat should be expected in this ﬁrst course. Our purpose in including this sec-tion in the textbook is to at least let you know that there is, in addition to 2’scomplement integers, another very important data type available in almost allISAs, which is calledﬂoating point;i ta l l o w sv e r yl a r g ea n dv e r yt i n yn u m b e r st obe expressed at the cost of reducing the number of binary digits of precision...ASCII CodesAnother representation of information is the standard code that almost all com-puter equipment manufacturers have agreed to use for transferring charactersbetween the main computer processing unit and the input and output devices.That code is an eight-bit code referred to asASCII.A S C I Is t a n d sf o rA m e r i -can Standard Code for Information Interchange. It (ASCII) greatly simpliﬁes theinterface between a keyboard manufactured by one company, a computer madeby another company, and a monitor made by a third company.Each key on the keyboard is identiﬁed by its unique ASCII code. So, forexample, the digit 3 is represented as 00110011, the digit 2 is 00110010, thelowercaseeis 01100101, and the ENTER key is 00001101. The entire set ofeight-bit ASCII codes is listed in Figure E.2 of Appendix E. When you type a keyon the keyboard, the corresponding eight-bit code is stored and made available tothe computer. Where it is stored and how it gets into the computer are discussedin Chapter 9.Most keys are associated with more than one code. For example, the ASCIIcode for the letterEis 01000101, and the ASCII code for the lettereis 01100101.\n",
      "\n",
      "Both are associated with the same key, although in one case the Shift key is alsodepressed while in the other case, it is not.In order to display a particular character on the monitor, the computer musttransfer the ASCII code for that character to the electronics associated with themonitor. That, too, is discussed in Chapter 9...Hexadecimal NotationWe have seen that information can be represented as 2’s complement integers,as bit vectors, in ﬂoating point format, or as an ASCII code. There are otherrepresentations also, but we will leave them for another book. However, beforewe leave this topic, we would like to introduce you to a representation that is usedmore as a convenience for humans than as a data type to support operations beingperformed by the computer. This is thehexadecimalnotation. As we will see, itevolves nicely from the positional binary notation and is useful for dealing withlong strings of binary digits without making errors.It will be particularly useful in dealing with the LC-3 where 16-bit binarystrings will be encountered often.An example of such a binary string is0011110101101110Let’s try an experiment. Cover the preceding 16-bit binary string of 0s and 1swith one hand, and try to write it down from memory. How did you do? Hex-adecimal notation is about being able to do this without making mistakes. Weshall see how.In general, a 16-bit binary string takes the forma15a14a13a12a11a10a9a8a7a6a5a4a3a2a1a0where each of the bitsaiis either 0 or 1.If we think of this binary string as an unsigned integer, its value can becomputed asa15/uni22C5215+a14/uni22C5214+a13/uni22C5213+a12/uni22C5212+a11/uni22C5211+a10/uni22C5210+a9/uni22C529+a8/uni22C528+a7/uni22C527+a6/uni22C526+a5/uni22C525+a4/uni22C524+a3/uni22C523+a2/uni22C522+a1/uni22C521+a0/uni22C520We can factor 212from the ﬁrst four terms, 28from the second four terms, 24from the third set of four terms, and 20from the last four terms, yielding212(a15/uni22C523+a14/uni22C522+a13/uni22C521+a12/uni22C520)+28(a11/uni22C523+a10/uni22C522+a9/uni22C521+a8/uni22C520)+24(a7/uni22C523+a6/uni22C522+a5/uni22C521+a4/uni22C520)+20(a3/uni22C523+a2/uni22C522+a1/uni22C521+a0/uni22C520)Note that the largest value inside a set of parentheses is 15, which would be thecase if each of the four bits is 1. If we replace what is inside each square bracket\n",
      "\n",
      "with a symbol representing its value (from 0 to 15), and we replace 212with itsequivalent 163,28with 162,24with 161,a n d20with 160,w eh a v eh3/uni22C5163+h2/uni22C5162+h1/uni22C5161+h0/uni22C5160whereh3,f o re x a m p l e ,i sas y m b o lr e p r e s e n t i n ga15/uni22C523+a14/uni22C522+a13/uni22C521+a12/uni22C520Since the symbols must represent values from 0 to 15, we assign symbols to thesevalues as follows: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F. That is, we represent0000 with the symbol 0, 0001 with the symbol 1,…1001 with 9, 1010 with A,1011 with B,…1111 with F. The resulting notation is called hexadecimal, orbase 16.So, for example, if the hex digits E92F represent a 16-bit 2’s complementinteger, is the value of that integer positive or negative? How do you know?Now, then, what is this hexadecimal representation good for, anyway? Itseems like just another way to represent a number without adding any beneﬁt.Let’s return to the exercise where you tried to write from memory the string0011110101101110If we had ﬁrst broken the string at four-bit boundaries0011 1101 0110 1110and then converted each four-bit string to its equivalent hex digit3D6Eit would have been no problem to jot down (with the string covered) 3D6E.In summary, although hexadecimal notation can be used to perform base-16 arithmetic, it is mainly used as a convenience for humans. It can be used torepresent binary strings that are integers or ﬂoating point numbers or sequencesof ASCII codes, or bit vectors. It simply reduces the number of digits by a factorofres...requiring additional bits for each student’s unique bit pattern?\n",
      "\n",
      "ital Logic StructuresInC h a p t e r1 ,w es t a t e dt h a tc o m p u t e r sw e r eb u i l tf r o mv e r yl a r g en u m b e r sof very simple structures. For example, Intel’s Broadwell-E5 microproces-sor, introduced in 2016, contained more than seven billion transistors. Similarly,IBM’s Power9 microprocessor, introduced in 2017, contained eight billion tran-sistors. In this chapter, we will explain how the MOS transistor works (as a logicelement), show how these transistors are connected to form logic gates, and thenshow how logic gates are interconnected to form larger units that are needed toconstruct a computer. In Chapter 4, we will connect those larger units and formac o m p u t e r .But ﬁrst, the transistor..The TransistorMost computers today or rather most microprocessors (which form the core of thecomputer) are constructed out of MOS transistors. MOS stands formetal-oxidesemiconductor.The electrical properties of metal-oxide semiconductors are wellbeyond the scope of what we want to understand in this course. They are belowour lowest level of abstraction, which means that if somehow transistors startmisbehaving, we are at their mercy. However, it is unlikely in this course that wewill have any problems from the transistors.Still, it is useful to know that there are two types of MOS transistors: P-typeand N-type. They both operate “logically,” very similar to the way wall switcheswork.Figure 3.1 shows the most basic of electrical circuits. It consists of (1) apower supply (in this case, the 120 volts that come into your house if you live inthe United States, or the 220 volts if you live in most of the rest of the world),(2) a wall switch, and (3) a lamp (plugged into an outlet in the wall). In order forthe lamp to glow, electrons must ﬂow; in order for electrons to ﬂow, there must beac l o s e dc i r c u i tf r o mt h ep o w e rs u p p l yt ot h el a m pa n db a c kt ot h ep o w e rs u p p l y .\n",
      "\n",
      "Figure.A simple electric circuit showing the use of a wall switch.The lamp can be turned on and oﬀby simply manipulating the wall switch tomake or break the closed circuit.Instead of the wall switch, we could use an N-type or a P-type MOS transistorto make or break the closed circuit. Figure 3.2 shows a schematic rendering ofan N-type transistor (a) by itself, and (b) in a circuit. Note (Figure 3.2a) thatthe transistor has three terminals. They are called thegate,t h esource,a n dt h edrain.T h er e a s o n sf o rt h en a m e ss o u r c ea n dd r a i na r en o to fi n t e r e s tt ou si nt h i scourse. What is of interest is the fact that if the gate of the N-type transistor issupplied with 1.2 volts, the connection from source to drain acts like a piece ofwire. We say (in the language of electricity) that we have ashort circuitbetweenthe source and drain. If the gate of the N-type transistor is supplied with 0 volts,the connection between the source and drain is broken. We say that between thesource and drain we have anopen circuit.Figure 3.2 shows the N-type transistor in a circuit with a battery and a bulb.When the gate is supplied with 1.2 volts, the transistor acts like a piece of wire,completing the circuit and causing the bulb to glow. When the gate is supplied\n",
      "Figure.The N-type MOS transistor.\n",
      "\n",
      "Figure 3.2c is a shorthand notation for describing the circuit of Figure 3.2b.Rather than always showing the power supply and the complete circuit, electri-cal engineers usually show only the terminals of the power supply. The fact thatthe power supply itself provides the completion of the completed circuit is wellunderstood, and so is not usually shown.The P-type transistor works in exactly the opposite fashion from the N-typetransistor. Figure 3.3 shows the schematic representation of a P-type transistor.When the gate is supplied with 0 volts, the P-type transistor acts (more or less)like a piece of wire, closing the circuit. When the gate is supplied with 1.2 volts,the P-type transistor acts like an open circuit. Because the P-type and N-typets\n",
      "DrainFigure.AP - t y p eM O St r a n s i s t o r ..Logic GatesOne step up from the transistor is thelogic gate.T h a ti s ,w ec o n s t r u c tb a s i cl o g i cstructures out of individual MOS transistors. In Chapter 2, we studied the behav-ior of the AND, the OR, and the NOT functions. In this chapter, we constructtransistor circuits that implement each of these functions. The correspondingcircuits are called AND, OR, and NOTgates...The NOT Gate (Inverter)Figure 3.4 shows the simplest logic structure that exists in a computer. It is con-structed from two MOS transistors, one P-type and one N-type. Figure 3.4a is theschematic representation of that circuit. Figure 3.4b shows the behavior of thecircuit if the input is supplied with 0 volts. Note that the P-type transistor actslike a short circuit and the N-type transistor acts like an open circuit. The outputis, therefore, connected to 1.2 volts. On the other hand, if the input is suppliedwith 1.2 volts, the P-type transistor acts like an open circuit, but the N-type tran-sistor acts like a short circuit. The output in this case is connected to ground (i.e.,0v o l t s ) .T h ec o m p l e t eb e h a v i o ro ft h ec i r c u i tc a nb ed e s c r i b e db ym e a n so fatable, as shown in Figure 3.4c. If we replace 0 volts with the symbol 0 and 1.2\n",
      "\n",
      " 1.2 volts. 0 volts           Figure.A CMOS inverter.volts with the symbol 1, we have the truth table (Figure 3.4d) for the complementor NOT function, which we studied in Chapter 2.In other words, we have just shown how to construct an electronic circuit thatimplements the NOT logic function discussed in Chapter 2. We call this circuitaNOT gate,o ra ninverter...OR and NOR GatesFigure 3.5 illustrates a NOR gate. Figure 3.5a is a schematic of a circuit thatimplements a NOR gate. It contains two P-type and two N-type transistors.Figure 3.5b shows the behavior of the circuit ifAis supplied with 0 voltsandBis supplied with 1.2 volts. In this case, the lower of the two P-type transis-tors produces an open circuit, and the outputCis disconnected from the 1.2-voltpower supply. However, the leftmost N-type transistor acts like a piece of wire,connecting the outputCto 0 volts.Note that if bothAandBare supplied with 0 volts, the two P-type transistorsconduct, and the outputCis connected to 1.2 volts. Note further that there is noambiguity here, since both N-type transistors act as open circuits, and soCisdisconnected from ground.If eitherAorBis supplied with 1.2 volts, the corresponding P-type transistorresults in an open circuit. That is suﬃcient to break the connection fromCtothe 1.2-volt source. However, 1.2 volts supplied to the gate of one of the N-type\n",
      "\n",
      "1101.2 volts0 volts1.2 voltsAB\n",
      "Figure.The NOR gate.transistors is suﬃcient to cause that transistor to conduct, resulting inCbeingconnected to ground (i.e., 0 volts).Figure 3.5c summarizes the complete behavior of the circuit of Figure 3.5a.It shows the behavior of the circuit for each of the four pairs of voltages that canbe supplied toAandB.T h a ti s ,A=0v o l t s,B=0v o l t sA=0v o l t s,B=1.2v o l t sA=1.2v o l t s,B=0v o l t sA=1.2v o l t s,B=1.2v o l t sIf we replace the voltages with their logical equivalents, we have the truthtable of Figure 3.5d. Note that the outputCis exactly the opposite of the logicalOR function that we studied in Chapter 2. In fact, it is the NOT-OR function,more typically abbreviated as NOR. We refer to the circuit that implements theNOR function as a NOR gate.If we augment the circuit of Figure 3.5a by adding an inverter at its output, asshown in Figure 3.6a, we have at the outputDthe logical function OR. Figure 3.6ais the circuit for an OR gate. Figure 3.6b describes the behavior of this circuit ifthe input variableAis set to 0 and the input variableBis set to 1. Figure 3.6cshows the circuit’s truth table.\n",
      "\n",
      "AB\n",
      "1    0      0     11    1      0     1Figure.The OR gate...Why We Can’t Simply Connect P-Type to GroundSome bright students have looked at our implementation of the OR gate (a NOR-gate followed by an inverter) and asked the question, why can’t we simply connectthe transistors as shown in Figure 3.7a?Logically, it looks very tempting. Four transistors instead of six. Unfortu-nately, the electrical properties of transistors make this problematic. When weconnect a P-type transistor to 1.2v o l t so ra nN - t y p et r a n s i s t o rt og r o u n d ,t h e r ei sno voltage across the transistor, resulting in outputs as shown in Figure 3.5, forexample, of 0 volts or 1.2 volts, depending on the input voltages toAandB.H o w -ever, when we connect a P-type transistor to ground or an N-type transistor to 1.2volts, because of the electrical characteristics of the transistors, we get what isusually referred to as a transmission voltage of approximately 0.5 volts across thetransistor. This results in the output of the transistor circuit of Figure 3.7 being0.5v o l t s+0.5v o l t s ,o r1.0v o l ti fAandBare both 0, and 0.7v o l t s( 1.2v o l t sminus 0.5 volts) otherwise. Figure 3.7b shows the actual voltages in the resultingtruth table, rather than 0s and 1s. That is, even though the transistor circuit lookslike it would work, the transmission voltages across the transistors would yieldan output voltage of 1 volt for a logical 0 and 0.7 volts for a logical 1. Not whatwe would like for an OR gate!\n",
      "\n",
      "Figure.An OR gate (not really!)...AND and NAND GatesFigure 3.8 shows an AND gate. Note that if eitherAorBis supplied with 0 volts,there is a direct connection fromCto the 1.2-volt power supply. The fact thatC\n",
      "Figure.The AND gate.\n",
      "\n",
      "(e) NOR gate (d) NAND gate Figure.Basic logic gates.Again, we note that there is no ambiguity. The fact that at least one of the twoinputsAorBis supplied with 0 volts means that at least one of the two N-typetransistors whose gates are connected toAorBis open, and that consequently,Cis disconnected from ground. Furthermore, the fact thatCis at 1.2 volts meansthe P-type transistor whose gate is connected toCis open-circuited. Therefore,Dis not connected to 1.2 volts.On the other hand, if bothAandBare supplied with 1.2 volts, then bothof their corresponding P-type transistors are open. However, their correspondingN-type transistors act like pieces of wire, providing a direct connection fromCto ground. BecauseCis at ground, the rightmost P-type transistor acts like aclosed circuit, forcingDto 1.2 volts.Figure 3.8b is a truth table that summarizes the behavior of the circuit ofFigure 3.8a. Note that the circuit is an AND gate. The circuit shown within thedashed lines (i.e., having outputC)i saN O T - A N Dg a t e ,w h i c hw eg e n e r a l l yabbreviate as NAND.The gates just discussed are very common in digital logic circuits and indigital computers. There are billions of inverters (NOT gates) in Intel’s Skylakemicroprocessor. As a convenience, we can represent each of these gates by stan-dard symbols, as shown in Figure 3.9. The bubble shown in the inverter, NAND,and NOR gates signiﬁes the complement (i.e., NOT) function. From now on, wewill not draw circuits showing the individual transistors. Instead, we will raiseour level of abstraction and use the symbols shown in Figure 3.9...Gates with More Than Two InputsBefore we leave the topic of logic gates, we should note that the notion of AND,OR, NAND, and NOR gates extends to larger numbers of inputs. One could buildat h r e e - i n p u tA N Dg a t eo raf o u r - i n p u tO Rg a t e ,f o re x a m p l e .A nn-input ANDgate has an output value of 1 only if ALLninput variables have values of 1. Ifany of theninputs has a value of 0, the output of then-input AND gate is 0. Ann-input OR gate has an output value of 1 if ANY of theninput variables has avalue of 1. That is, ann-input OR gate has an output value of 0 only if ALLninput variables have values of 0.\n",
      "\n",
      "                                                         Figure.At h r e e - i n p u tA N Dg a t e .Figure 3.10 illustrates a three-input AND gate. Figure 3.10a shows its truthtable. Figure 3.10b shows the symbol for a three-input AND gate.Question: Can you draw a transistor-level circuit for a three-input AND gate?How about a four-input AND gate? How about a four-input OR gate?.Combinational Logic CircuitsNow that we understand the workings of the basic logic gates, the next stepis to build some of the logic structures that are important components of themicroarchitecture of a computer.There are fundamentally two kinds of logic structures, those that include thestorage of information and those that do not. In Sections 3.4, 3.5, and 3.6, wewill deal with structures that store information. In this section, we will deal withstructures that do not store information. These structures are sometimes referredto asdecision elements.U s u a l l y ,t h e ya r er e f e r r e dt oa scombinational logic struc-turesbecause their outputs are strictly dependent on the combination of inputvalues that are being applied to the structureright now.T h e i ro u t p u t sa r en o ta tall dependent on any past history of information that is stored internally, since noinformation can be stored internally in a combinational logic circuit.We will next examine three useful combinational logic circuits: a decoder, amux, and a one-bit adder...DecoderFigure 3.11 shows a logic gate implementation of a two-input decoder. A decoderhas the property that exactly one of its outputs is 1 and all the rest are 0s. The oneoutput that is logically 1 is the output corresponding to the input pattern that it isexpected to detect. In general, decoders haveninputs and 2noutputs. We say theoutput line that detects the input pattern isasserted.T h a ti s ,t h a to u t p u tl i n eh a sthe value 1, rather than 0 as is the case for all the other output lines. In Figure 3.11,note that for each of the four possible combinations of inputsAandB,e x a c t l yo n eoutput has the value 1 at any one time. In Figure 3.11b, the input to the decoderis 10, resulting in the third output line being asserted.\n",
      "\n",
      "AB\n",
      "1,  if   A, B  is  110Figure.At w o - i n p u td e c o d e r .The decoder is useful in determining how to interpret a bit pattern. We willsee in Chapter 5 that the work to be carried out by each instruction in the LC-3c o m p u t e ri sd e t e r m i n e db yaf o u r - b i tp a t t e r nt h a ti st h ep a r to ft h ei n s t r u c t i o ncalled theopcode,A4 - t o - 1 6d e c o d e ri sas i m p l ec o m b i n a t i o n a ll o g i cs t r u c t u r efor identifying what work is to be performed by each instruction...MuxFigure 3.12a shows a logic gate implementation of a two-input multiplexer, more\n",
      "Figure.A-to-mux.\n",
      "\n",
      "OUTFigure.Af o u r - i n p u tm u x .The mux of Figure 3.12 works as follows: SupposeS=0, as shown inFigure 3.12b. Since the output of an AND gate is 0 unless all inputs are 1, the out-put of the rightmost AND gate is 0. Also, the output of the leftmost AND gate iswhatever the inputAis. That is, ifA=0, then the output of the leftmost AND gateis 0, and ifA=1, then the output of the leftmost AND gate is 1. Since the outputof the rightmost AND gate is 0, it has no eﬀect on the OR gate. Consequently,the output atCis exactly the same as the output of the leftmost AND gate. Thenet result of all this is that ifS=0, the outputCis identical to the inputA.On the other hand, ifS=1, it isBthat is ANDed with 1, resulting in theoutput of the OR gate having the value ofB.In summary, the outputCis always connected to either the inputAor theinputB—which one depends on the value of the select lineS.W es a ySselects thesource of the mux (eitherAorB)t ob er o u t e dt h r o u g ht ot h eo u t p u tC. Figure 3.12cshows the standard representation for a mux.In general, a mux consists of 2ninputs andnselect lines. Figure 3.13ashows a gate-level description of a four-input mux. It requires two select lines.Figure 3.13b shows the standard representation for a four-input mux.Question: Can you construct the gate-level representation for an eight-inputmux? How many select lines must you have?..A One-Bit Adder (a.k.a. a Full Adder)Recall in Chapter 2, we discussed binary addition. A simple algorithm for binaryaddition is to proceed as you have always done in the case of decimal addition,from right to left, one column at a time, adding the two digits from the two valuesplus the carry in, and generating a sum digit and a carry to the next column. Theonly diﬀerence here (with binary addition) is you get a carry after 1, rather thanafter 9.Figure 3.14 is a truth table that describes the result of binary addition ononecolumnof bits within twon-bit operands. At each column, there are three values\n",
      "\n",
      "  1Figure.The truth table for a one-bit adder.that must be added: one bit from each of the two operandsAandBand the carryfrom the previous column. We designate these three bits asAi,Bi, andCi.T h e r eare two results, the sum bit (Si)a n dt h ec a r r yo v e rt ot h en e x tc o l u m n ,Ci+1.N o t ethat if only one of the three bits equals 1, we get a sum of 1, and no carry (i.e.,Ci+1=0). If two of the three bits equal 1, we get a sum of 0, and a carry of 1. Ifall three bits equal 1, the sum is 3, which in binary corresponds to a sum of 1 andac a r r yo f1 .Figure 3.15 shows a logic gate implementation of a one-bit adder. Note thateach AND gate in Figure 3.15 produces an output 1 for exactly one of the eightinput combinations ofAi,Bi,a n dCi.T h eo u t p u to ft h eO Rg a t ef o rCi+1must be 1in epro\n",
      "Figure.Gate-level description of a one-bit adder.\n",
      "\n",
      "S0S1S2S3Figure.Ac i r c u i tf o ra d d i n gt w o-bit binary numbers.are the outputs of the AND gates corresponding to those input combinations.Similarly, the inputs to the OR gate that generatesSiare the outputs of the ANDgates corresponding to the input combinations that require an output 1 forSiinthe truth table of Figure 3.14.Note that since the input combination 000 does not result in an output 1 foreitherCi+1orSi,i t sc o r r e s p o n d i n gA N Dg a t ei sn o ta ni n p u tt oe i t h e ro ft h et w oOR gates.Figure 3.16 shows a circuit for adding two 4-bit binary numbers, using fourof the one-bit adder circuits of Figure 3.15. Note that the carry out of columniisan input to the addition performed in columni+1.If we wish to implement a logic circuit that adds two 16-bit numbers, we cando so with a circuit of 16 one-bit adders.We should point out that historically the logic circuit of Figure 3.15 thatprovides three inputs (Ai,Bi,a n dCi)a n dt w oo u t p u t s( t h es u mb i tSiand thecarry over to the next columnCi+1)h a sg e n e r a l l yb e e nr e f e r r e dt oa safull adderto diﬀerentiate it from another structure, which is called ahalf adder.T h ed i s -tinction between the two is the carry bit. Note that the carry into the rightmostcolumn in Figure 3.16 is 0. That is, in the rightmost circuit,S0andC1depend onlyon two inputs,A0andB0.S i n c et h a tc i r c u i td e p e n d so no n l yt w oi n p u t s ,i th a sb e e nreferred to as a half adder. Since the other circuits depend on all three inputs, theyare referred to as full adders. We prefer the term one-bit adder as a simpler termfor describing what is happening in each column...The Programmable Logic Array (PLA)Figure 3.17 illustrates a very common building block for implementing any col-lection of logic functions one wishes to implement. The building block is calleda programmable logic array (PLA). It consists of an array of AND gates (calledan AND array) followed by an array of OR gates (called an OR array). The num-ber of AND gates corresponds to the number of input combinations (rows) inthe truth table. Forn-input logic functions, we need a PLA with 2nn-input AND\n",
      "\n",
      "\n",
      "Figure.Ap r o g r a m m a b l el o g i ca r r a y .gates. In Figure 3.17, we have 23three-input AND gates, corresponding to threelogical input variables. The number of OR gates corresponds to the number oflogic functions we wish to implement, that is, the number of output columns inthe truth table. The implementation algorithm is simply to connect the output ofan AND gate to the input of an OR gate if the corresponding row of the truth tableproduces an output 1 for that output column. Hence the notion of programmable.That is, we say we program the connections from AND gate outputs to OR gateinputs to implement our desired logic functions.Figure 3.15 shows seven AND gates connected to two OR gates since ourrequirement was to implement two functions (sum and carry) of three input vari-ables. Figure 3.17 shows a PLA that can implement any four functions of threevariables by appropriately connecting AND gate outputs to OR gate inputs. Thatis, any function of three variables can be implemented by connecting the outputsof all AND gates corresponding to input combinations for which the output is 1to inputs of one of the OR gates. Thus, we could implement the one-bit adder byprogrammingthe two OR gates in Figure 3.17 whose outputs are W and X byconnecting or not connecting the outputs of the AND gates to the inputs of thosetwo OR gates as speciﬁed by the two output columns of Figure 3.14...Logical CompletenessBefore we leave the topic of combinational logic circuits, it is worth noting animportant property of building blocks for logic circuits:logical completeness.W eshowed in Section 3.3.4 that any logic function we wished to implement couldbe accomplished with a PLA. We saw that the PLA consists of only AND gates,OR gates, and inverters. That means that any logic function can be implemented,provided that enough AND, OR, and NOT gates are available. We say that the setof gates{AND, OR, NOT}islogically completebecause we can build a circuitto carry out the speciﬁcation of any truth table we wish without using any other\n",
      "\n",
      "kind of gate. That is, the set of gates{AND, OR, and NOT}is logically completebecause a barrel of AND gates, a barrel of OR gates, and a barrel of NOT gates aresuﬃcient to build a logic circuit that carries out the speciﬁcation of any desiredtruth table. The barrels may have to be big, but the point is, we do not need anyother kind of gate to do the job.Question: Is there any single two-input logic gate that is logically complete?For example, is the NAND gate logically complete?Hint:Can I implement aNOT gate with a NAND gate? If yes, can I then implement an AND gate using aNAND gate followed by a NOT gate? If yes, can I implement an OR gate usingjust AND gates and NOT gates?If all of the above is true, then the NAND gate is logically complete, and Ican implement any desired logic function as described by its truth table with abarrel of NAND gates..Basic Storage ElementsRecall our statement at the beginning of Section 3.3 that there are two kinds oflogic structures, those that involve the storage of information and those that donot. We have discussed three examples of those that do not: the decoder, the mux,and the full adder. Now we are ready to discuss logic structures that do includethe storage of information...The R-S LatchA simple example of a storage element is the R-S latch. It can store one bit ofinformation, a 0 or a 1. The R-S latch can be implemented in many ways, thesimplest being the one shown in Figure 3.18. Two 2-input NAND gates are con-nected such that the output of each is connected to one of the inputs of the other.The remaining inputsSandRare normally held at a logic level 1.The R-S latch ets its name from the old desi nations for settin the latch\n",
      "RbFigure.An R-S latch.The Quiescent StateWe describe thequiescent(or quiet) state of a latch asthe state when the latch is storing a value, either 0 or 1, and nothing is trying to\n",
      "\n",
      "change that value. This is the case when inputsSandRboth have the logic value1. In Figure 3.18 the letteradesignates the value that is currently stored in thelatch, which we also refer to as the output of the latch.Consider ﬁrst the case where the value stored and therefore the outputais1. Since that means the valueAis 1 (and since we know the inputRis 1 becausewe are in the quiescent state), the NAND gate’s outputbmust be 0. That, in turn,meansBmust be 0, which results in the outputaequal to 1. As long as the inputsSandRremain 1, the state of the circuit will not change. That is, the R-S latchwill continue to store the value 1 (the value of the outputa).If, on the other hand, we assume the outputais 0, thenAmust be 0, andthe out utbmust be 1. That, in turn, results inBequal to 1, and combined withtSequal to 1 (again due to quiescence), results in the outputaequal ton, as long as the inputsSandRremain 1, the state of the circuit will not. In this case, we say the R-S latch stores the value 0.the Latch to a1or a0The latch can be set to 1 by momentarily settingprovided we keep the value ofRat 1. Similarly, the latch can be set to 0entarily settingRto 0, provided we keep the value ofSat 1. In order forthe R-S latch to work properly, both S and R must never be allowed to be set to 0at the same time.We use the termsetto denote setting a variable to 0 or 1, as in “set to 0” or“set to 1.” In addition, we often use the termclearto denote the act of setting avariable to 0.If we setSto 0 for a very brief period of time, this causesato equal 1, whichin turn causesAto equal 1. SinceRis also 1, the output atbmust be 0. This causesBto be 0, which in turn makesaequal to 1. If, after that very brief period of time,we now returnSto 1, it does not aﬀecta.W h y ?A n s w e r :S i n c eBis also 0, andsince only one input 0 to a NAND gate is enough to guarantee that the output ofthe NAND gate is 1, the latch will continue to store a 1 long afterSreturns to 1.In the same way, we can clear the latch (set the latch to 0) by settingRto 0for a very short period of time.We should point out that if bothSandRwere allowed to be set to 0 at the sametime, the outputsaandbwould both be 1, and the ﬁnal state of the latch woulddepend on the electrical properties of the transistors making up the gates andnot on the logic being performed. How the electrical properties of the transistorswould determine the ﬁnal state in this case is a subject we will have to leave foral a t e rs e m e s t e r .: - (Finally, we should note that when a digital circuit is powered on, the latchcan be in either of its two states, 0 or 1. It does not matter which state since wenever use that information untilafterwe have set it to 1 or 0...The Gated D LatchTo be useful, it is necessary to control when a latch is set and when it is cleared.As i m p l ew a yt oa c c o m p l i s ht h i si sw i t ht h eg a t e dl a t c h .Figure 3.19 shows a logic circuit that implements a gatedDlatch. It consistsof the R-S latch of Figure 3.18, plus two additional NAND gates that allow the\n",
      "\n",
      "RFigure.Ag a t e dDl a t c h .latch to be set to the value ofD,b u tonlywhen WE is asserted (i.e., when WEequals 1). WE stands forwrite enable. When WE is not asserted (i.e., when WEequals 0), the outputsSandRare both equal to 1. SinceSandRare inputs to theR-S latch, if they are kept at 1, the value stored in the latch remains unchanged,as we explained in Section 3.4.1. When WE is momentarily set to 1, exactly oneof the outputsSorRis set to 0, depending on the value ofD. IfDequals 1, thenSis set to 0. IfDequals 0, then both inputs to the lower NAND gate are 1, resultinginRbeing set to 0. As we saw earlier, ifSis set to 0, the R-S latch is set to 1. IfRis set to 0, the R-S latch is set to 0. Thus, the R-S latch is set to 1 or 0 accordingto whetherDis 1 or 0. When WE returns to 0,SandRreturn to 1, and the valuestored in the R-S latch persists..The Concept of MemoryWe now have all the tools we need to describe one of the most important struc-tures in the electronic digital computer, itsmemory.W ew i l ls e ei nC h a p t e r4how memory ﬁts into the basic scheme of computer processing, and you will seethroughout the rest of the book and indeed the rest of your work with computershow important the concept of memory is to computing.Memory is made up of a (usually large) number of locations, each uniquelyidentiﬁable and each having the ability to store a value. We refer to the uniqueidentiﬁer associated with each memory location as itsaddress.W er e f e rt ot h enumber of bits of information stored in each location as itsaddressability.For example, an advertisement for a laptop computer might say, “This com-puter comes with 2 gigabytes of memory.” Actually, most ads generally usethe abbreviation 2 GB (or, often: 2 Gig). This statement means, as we willexplain momentarily, that the laptop includes two billion memory locations, eachcontaining one byte of information...Address SpaceWe refer to the total number of uniquely identiﬁable locations as the memory’saddress space.A2G Bm e m o r y ,f o re x a m p l e ,r e f e r st oam e m o r yt h a tc o n s i s t so ftwo billion uniquely identiﬁable memory locations.\n",
      "\n",
      "Actually, the number two billion is only an approximation, due to the way wespecify memory locations. Since everything else in the computer is representedby sequences of 0s and 1s, it should not be surprising that memory locations areidentiﬁed by binary addresses as well. Withnbits of address, we can uniquelyidentify 2nlocations. Ten bits provide 1024 locations, which is approximately1000. If we have 20 bits to represent each address, we have 220uniquely identi-ﬁable locations, which is approximately one million. With 30 bits, we have 230locations, which is approximately one billion. In the same way we use the preﬁxes“kilo” to represent 210(approximately 1000) and “mega” to represent 220(approx-imately one million), we use the preﬁx “giga” to represent 230(approximatelyone billion). Thus, 2 giga really corresponds to the number of uniquely iden-tiﬁable locations that can be speciﬁed with 31 address bits. We say the addressspace is 231,w h i c hi sexactly2,147,483,648 locations, rather than 2,000,000,000,although we colloquially refer to it as two billion...AddressabilityThe number of bits stored in each memory location is the memory’s addressabil-ity. A 2-gigabyte memory (written 2GB) is a memory consisting of 2,147,483,648memory locations, each containing one byte (i.e., eight bits) of storage. Mostmemories are byte-addressable. The reason is historical; most computers got theirstart processing data, and one character stroke on the keyboard corresponds to one8-bit ASCII code, as we learned in Chapter 2. If the memory is byte-addressable,then each ASCII character occupies one location in memory. Uniquely identi-fying each byte of memory allows individual bytes of stored information to bechanged easily.Many computers that have been designed speciﬁcally to perform large scien-tiﬁc calculations are 64-bit addressable. This is due to the fact that numbers usedin scientiﬁc calculations are often represented as 64-bit ﬂoating-point quantities.Recall that we discussed the ﬂoating-point data type in Chapter 2. Since scientiﬁccalculations are likely to use numbers that require 64 bits to represent them, it isreasonable to design a memory for such a computer that stores one such numberin each uniquely identiﬁable memory location...A-by--Bit MemoryFigure 3.20 illustrates a memory of size 22by 3 bits. That is, the memoryhas an address space of four locations and an addressability of three bits.Am e m o r yo fs i z e22requires two bits to specify the address. We describethe two-bit address as A[1:0]. A memory of addressability three stores threebits of information in each memory location. We describe the three bitsof data as D[2:0]. In both cases, our notation A[high:low] and D[high:low]reﬂects the fact that we have numbered the bits of address and data fromright to left, in order, starting with the rightmost bit, which is numbered 0.The notation [high:low] means a sequence ofhigh−low+1b i t ss u c ht h a t“high” is the bit number of the leftmost (orhigh)b i tn u m b e ri nt h es e q u e n c eand “low” is the bit number of the rightmost (orlow)b i tn u m b e ri nt h es e q u e n c e .\n",
      "\n",
      "D[1]D[2]D[0]Figure.A-by--bit memory.Accesses of memory require decoding the address bits. Note that the addressdecoder takes as input the address bitsA[1:0] and asserts exactly one of its fouroutputs, corresponding to theword linebeing addressed. In Figure 3.20, each rowof the memory corresponds to a unique three-bit word, thus the termword line.Memory can be read by applying the addressA[1:0], which asserts the word lineto be read. Note that each bit of the memory is ANDed with its word line and thenORed with the corresponding bits of the other words. Since only one word linecan be asserted at a time, this is eﬀectively a mux with the output of the decoderproviding the select function to each bit line. Thus, the appropriate word is readatD[2:0].Figure 3.21 shows the process of reading location 3. The code for 3 is 11.The addressA[1:0]=11 is decoded, and the bottom word line is asserted. Notethat the three other decoder outputs are not asserted. That is, they have the value0. The value stored in location 3 is 101. These three bits are each ANDed withtheir word line producing the bits 101, which are supplied to the three outputOR gates. Note that all other inputs to the OR gates are 0, since they have beenproduced by ANDing with their unasserted word lines. The result is thatD[2:0]= 101. That is, the value stored in location 3 is output by the OR gates. Memory\n",
      "\n",
      "\n",
      "D[1]D[2]D[0]  10 1Figure.Reading locationin our-by--bit memory.can be written in a similar fashion. The address speciﬁed byA[1:0] is presented tothe address decoder, resulting in the correct word line being asserted. With writeenable (WE) also asserted, the three bitsD[2:0] can be written into the three gatedlatches corresponding to that word line..Sequential Logic CircuitsIn Section 3.3, we discussed digital logic structures that process information(decision structures, we call them) wherein the outputs depend solely on the val-ues that are present on the inputsnow.E x a m p l e sa r em u x e s ,d e c o d e r s ,a n df u l ladders. We call these structures combinational logic circuits. In these circuits,there is no sense of the past. Indeed, there is no capability for storing any infor-mation about anything that happened before the present time. In Sections 3.4and 3.5, we described structures that do store information—in Section 3.4, somebasic storage elements, and in Section 3.5, a simple 22-by-3-bit memory.\n",
      "\n",
      "Figure.Sequential logic circuit block diagram.In this section, we discuss digital logic structures that canbothprocess infor-mation (i.e., make decisions)andstore information. That is, these structures basetheir decisions not only on the input values now present, but also (and this isvery important) on what has happened before. These structures are usually calledsequential logic circuits. They are distinguishable from combinational logic cir-cuits because, unlike combinational logic circuits, they contain storage elementsthat allow them to keep track of prior history information. Figure 3.22 shows ablock diagram of a sequential logic circuit. Note the storage elements. Note alsothat the output can be dependent on both the inputs now and the values stored inthe storage elements. The values stored in the storage elements reﬂect the historyof what has happened before.Sequential logic circuits are used to implement a very important class ofmechanisms calledﬁnite state machines.W eu s eﬁ n i t es t a t em a c h i n e si ne s s e n -tially all branches of engineering. For example, they are used as controllers ofelectrical systems, mechanical systems, and aeronautical systems. A traﬃcl i g h tcontroller that sets the traﬃcl i g h tt or e d ,y e l l o w ,o rg r e e nd e p e n d so nt h el i g h tthat is currently on (history information) and input information from sensors suchas trip wires on the road, a timer keeping track of how long the current light hasbeen on, and perhaps optical devices that are monitoring traﬃc.We will see in Chapter 4 when we introduce the von Neumann model of acomputer that a ﬁnite state machine is at the heart of the computer. It controls theprocessing of information by the computer...A Simple Example: The Combination LockAs i m p l ee x a m p l es h o w st h ed iﬀerence between combinational logic structuresand sequential logic structures. Suppose one wishes to secure a bicycle with alock, but does not want to carry a key. A common solution is the combinationlock. The person memorizes a “combination” and uses it to open the lock. Twocommon types of locks are shown in Figure 3.23.In Figure 3.23a, the lock consists of a dial, with the numbers from 0 to 30equally spaced around its circumference. To open the lock, one needs to knowthe “combination.” One such combination could be: R13-L22-R3. If this werethe case, one would open the lock by turning the dial two complete turns to theright (clockwise), and then continuing until the dial points to 13, followed by one\n",
      "\n",
      "\n",
      "(a) (b)Figure.Combination locks.complete turn to the left (counterclockwise), and then continuing until the dialpoints to 22, followed by turning the dial again to the right (clockwise) until itpoints to 3. At that point, the lock opens. What is important here is thesequenceof the turns. The lock will not open, for example if one performed two turns to theright, and then stopped on 22 (instead of 13), followed by one complete turn tothe left, ending on 13, followed by one turn to the right, ending on 3. That is, eventhough the ﬁnal position of the dial is 3, and even though R22-L13-R3 uses thesame three numbers as the combination R13-L22-R3, the lock would not open.Why? Because the lock stores the previous rotations and makes its decision (openor don’t open) on the basis of the the history of the past operations, that is, on thecorrectsequencebeing performed.Another type of lock is shown in Figure 3.23b. The mechanism consists of(usually) four wheels, each containing the digits 0 through 9. When the digitsare lined up properly, the lock will open. In this case, the combination is the setof four digits. Whether or not this lock opens is totally independent of the pastrotations of the four wheels. The lock does not care at all about past rotations.The only thing important is the current value of each of the four wheels. This isas i m p l ee x a m p l eo fac o m b i n a t i o n a ls t r u c t u r e .It is curious that in our everyday speech, both mechanisms are referred toas “combination locks.” In fact, only the lock of Figure 3.23b is a combinationallock. The lock of Figure 3.23a would be better called a sequential lock!..The Concept of StateFor the mechanism of Figure 3.23a to work properly, it has to keep track of thesequence of rotations leading up to the opening of the lock. In particular, it hasto diﬀerentiate the correct sequence R13-L22-R3 from all other sequences. Forexample, R22-L13-R3 must not be allowed to open the lock. Likewise, R10-L22-R3 must also not be allowed to open the lock.For the lock of Figure 3.23a to work, it must identify several relevantsituations, as follows:A. The lock is not open, and NO relevant operations have beenperformed.B. The lock is not open, but the user has just completed theR13 operation.\n",
      "\n",
      "C. The lock is not open, but the user has just completed R13,followed by L22.D. The lock is open, since the user has just completed R13,followed by L22, followed by R3.We have labeled these four situations A, B, C, and D. We refer to each of thesesituations as thestateof the lock.The notion ofstateis a very important concept in computer engineering, andactually, in just about all branches of engineering. The state of a mechanism—more generally, the state of a system—is a snapshot of that system in which allrelevant items are explicitly expressed.That is:The state of a system is a snapshot of all the relevant elements of thesystem at the moment the snapshot is taken.In the case of the lock of Figure 3.23a, there are four states A, B, C, and D.Either the lock is open (State D), or if it is not open, we have already performedeither zero (State A), one (State B), or two (State C) correct operations. This isthe sum total of all possible states that can exist.Question: Why are there exactly four states needed to describe the combina-tion lock of Figure 3.23a? Can you think of a snapshot of the combination lockafter an operation (Rn or Ln) that requires a ﬁfth state because it is not coveredby one of the four states A, B, C, or D?There are many examples of systems that you are familiar with that can beeasily described by means of states.The state of a game of basketball can be described by the scoreboard in thebasketball arena. Figure 3.24 shows the state of the basketball game as Texas 73,Oklahoma 68, 7 minutes and 38 seconds left in the second half, 14 seconds left onthe sfoulsball\n",
      "Figure.An example of a state.\n",
      "\n",
      "(a) (b) (c)Figure.Three states in a tic-tac-toe machine.at w o - p o i n ts h o t ,t h en e ws t a t ew o u l db ed e s c r i b e db yt h eu p d a t e ds c o r e b o a r d .That is, the score would then be Texas 75, Oklahoma 68, the time remaining inthe game would be 7 minutes and 26 seconds, the shot clock would be back to 25seconds, and Oklahoma would have the ball.The game of tic-tac-toe can also be described in accordance with the notionof state. Recall that the game is played by two people (or, in our case, a personand the computer). The state is a snapshot of the game in progress each time thecomputer asks the person to make a move. The game is played as follows: Thereare nine locations on the diagram. The person and then the computer take turnsplacing an X (the person) and an O (the computer) in an empty location. Theperson goes ﬁrst. The winner is the ﬁrst to place three symbols (three Xs for theperson, three Os for the computer) in a straight line, either vertically, horizontally,or diagonally.The initial state, before either the person or the computer has had a turn, isshown in Figure 3.25a. Figure 3.25b shows a possible state of the game when theperson is prompted for a second move, if he/she put an X in the upper left corneras his/her ﬁrst move, and the computer followed with an O in the middle squareas its ﬁrst move. Figure 3.25c shows a possible state of the game when the personis prompted for a third move if he/she put an X in the upper right corner on thesecond move, and the computer followed by putting its second O in the uppermiddle location.One ﬁnal example: a very old soft drink machine, when drinks sold for15 cents, and the machine would only take nickels (5 cents) and dimes (10 cents)and not be able to give change.The state of the machine can be described as the amount of money inserted,and whether the machine is open (so one can remove a bottle). There are onlythree possible states:A. The lock is open, so a bottle can be (or has been!) removed.B. The lock is not open, but 5 cents has been inserted.C. The lock is not open, but 10 cents has been inserted...The Finite State Machine and Its State DiagramWe have seen that a state is a snapshot of all relevant parts of a system at aparticular point in time. At other times, that system can be in other states. Wehave described four systems: a combination lock, a basketball game, a tic-tac-toe machine, and a very old soft drink machine when a bottle of cola cost only\n",
      "\n",
      "15 cents. The behavior of each of these systems can be speciﬁed by aﬁnite statemachine,a n dr e p r e s e n t e da sastate diagram.Aﬁ n i t es t a t em a c h i n ec o n s i s t so fﬁ v ee l e m e n t s :1. a ﬁnite number of states2. a ﬁnite number of external inputs3. a ﬁnite number of external outputs4. an explicit speciﬁcation of all state transitions5. an explicit speciﬁcation of what determines each externaloutput value.The set of states represents all possible situations (or snapshots) that the sys-tem can be in. Each state transition describes what it takes to get from one stateto another.Let’s examine the ﬁnite state machines for these four systems.The Combination LockAs t a t ed i a g r a mi sac o n v e n i e n tr e p r e s e n t a t i o no faﬁnite state machine. Figure 3.26 is a state diagram for the combination lock.Recall, we identiﬁed four states A, B, C, and D. Which state we are in dependson the progress we have made in getting from a random initial state to the lockbeing open. In the state diagram of Figure 3.26, each circle corresponds to oneof the four states, A, B, C, or D.The external inputs are R13, L22, R3, and R-other-than-13, L-other-than-22,and R-other-than-3.The external output is either the lock is open or the lock is not open. (Onelogical variable will suﬃce to describe that!) As shown in the state diagram, instates A, B, and C, the combination lock is locked. In state D, the combinationloth\n",
      "Figure.State diagram of the combination lock of Figure.a.\n",
      "\n",
      "on each arc speciﬁes which state the system is coming from and which state it isgoing to. We refer to the state the system is coming from as thecurrent state,and the state it is going to as thenext state.T h ec o m b i n a t i o nl o c kh a se i g h ts t a t etransitions. Associated with each transition is the input that causes the transitionfrom the current state to the next state. For example, R13 causes the transitionfrom state A to state B.Ac o u p l eo ft h i n g sa r ew o r t hn o t i n g .F i r s t ,i ti su s u a l l yt h ec a s et h a tf r o macurrent state there are multiple transitions to next states. The state transition thatoccurs depends on both the current state and the value of the external input. Forexample, if the combination lock is in state B, and the input is L22, the next stateis state C. If the current state is state B and the input is anything other than L22,the next state is state A. In short, the next state is determined by the combinationof the current state and the current external input.The output values of a system can also be determined by the combination ofthe current state and the value of the current external input. However, as is the casefor the combination lock, where states A, B, and C specify the lock is “locked,”and state D speciﬁes the lock is “unlocked,” the output can also be determinedsolely by the current state of the system. In all the systems we will study in thisbook, the output values will be speciﬁed solely by the current state of the system.AV e r yO l dS o f tD r i n kM a c h i n eFigure 3.27 is the state diagram for the softdrink machine.The soft drink machine has only three states: 5 cents has been inserted,10 cents has been inserted, and at least 15 cents has been inserted. Transitionsare caused by the insertion (the input) of a nickel or a dime. The output is asso-\n",
      "Figure.State diagram of the soft drink machine.AB a s k e t b a l lG a m eWe could similarly draw a state diagram for the basketballgame we described earlier, where each state would be one possible conﬁgurationof the scoreboard. A transition would occur if either the referee blew a whistle orthe other team got the ball. We showed earlier the transition that would be causedby Texas scoring a two-point shot. Clearly, the number of states in the ﬁnite statemachine describing a basketball game would be huge.\n",
      "\n",
      "Also clearly, the number of legitimate transitions from one state to another issmall, compared to the number of arcs one could draw connecting arbitrary pairsof states. For example, there is no arc from a score of Texas 68, Oklahoma 67 toTexas 75, Oklahoma 91, since no single input can cause that transition. The inputis the activity that occurred on the basketball court since the last transition. Someinput values are: Texas scored two points, Oklahoma scored three points, Texasstole the ball, Oklahoma successfully rebounded a Texas shot, and so forth.The output is the ﬁnal result of the game. The output has three values: Gamestill in progress, Texas wins, Oklahoma wins.Question:Can one have an arc from a state where the score is Texas 30,Oklahoma 28 to a state where the score is tied, Texas 30, Oklahoma 30? Is itpossible to have two states, one where Texas is ahead 30-28 and the other wherethe score is tied 30-30, but no arc between the two?AT i c - T a c - T o eM a c h i n eWe could also draw a state diagram for a tic-tac-toemachine, in our case when a person is playing against a computer. Each state is arepresentation of the position of the game when the person is asked to put an Xinto one of the empty cells. Figure 3.25 shows three states. The transition from thestate of Figure 3.25a to the state of Figure 3.25b is caused by the person puttingan X in the top left cell, followed by the computer putting an O in the center cell.The transition from the state of Figure 3.25b to the state of Figure 3.25c is causedby the person putting an X in the top right cell, followed by the computer puttingan O in the top middle cell.Since there are nine cells, and each state has an X, an O, or nothing in eachcell, there must be fewer than 39states in the tic-tac-toe machine. Clearly thereare far fewer than that, due to various constraints of the game.There are nine inputs, corresponding to the nine cells a person can put anXi n .T h e r ea r et h r e eo u t p u t s :( a )g a m es t i l li np r o g r e s s ,( b )p e r s o nw i n s ,a n d(c) computer wins...The Synchronous Finite State MachineUp to now a transition from a current state to a next state in our ﬁnite state machinehappened when it happened. For example, a person could insert a nickel into thesoft drink machine and then wait 10 seconds or 10 minutes before inserting thenext coin into the machine. And the soft drink machine would not complain. Itwould not dispense the soft drink until 15 cents was inserted, but it would waitpatiently as long as necessary for the 15 cents to be inserted. That is, there is noﬁxed amount of time between successive inputs to the ﬁnite state machine. Thisis true in the case of all four systems we have discussed. We say these systems areasynchronousbecause there is nothing synchronizing when each state transitionmust occur.However, almost no computers work that way. On the contrary, we say thatcomputers aresynchronousbecause the state transitions take place, one after theother, at identical ﬁxed units of time. They are controlled by asynchronous ﬁnitestate machine. We will save for Chapter 4 and beyond the state transitions thatoccur at identical, ﬁxed units of time that control a computer. In this chapter, we\n",
      "\n",
      "will take on a simpler task, the design of a traﬃcc o n t r o l l e r ,a na d m i t t e d l ys i m p l e rstructure, but one that is also controlled by a synchronous ﬁnite state machine.It is worth pointing out that both the four asynchronous ﬁnite state machinesdiscussed above and the synchronous ﬁnite state machine that controls a digitalcomputer share an important characteristic: They carry out work, one state tran-sition at a time, moving closer to a goal. In the case of the combination lock, aslong as you make the correct moves, each state transition takes us closer to thelock opening. In the case of the soft drink machine, each state transition takes uscloser to enjoying the taste of the soft drink. In the case of a computer, each statetransition takes us closer to solving a problem by processing a computer programthat someone has written...The ClockAs y n c h r o n o u sﬁ n i t es t a t em a c h i n et r a n s i t i o n sf r o mi t sc u r r e n ts t a t et oi t sn e x tstate after an identical ﬁxed interval of time. Control of that synchronous behavioris in part the responsibility of the clock circuit.Ac l o c kc i r c u i tp r o d u c e sas i g n a l ,c o m m o n l yr e f e r r e dt oa sTHE clock, whosevalue alternates between 0 volts and some speciﬁed ﬁxed voltage. In digital logicterms, the clock is a signal whose value alternates between 0 and 1. Figure 3.28shows the value of the clock signal as a function of time. Each of the repeatedsequence of identical intervals is referred to as aclock cycle.Ac l o c kc y c l es t a r t swhen the clock signal transitions from 0 to 1 and ends the next time the clocksignal transitions from 0 to 1.We will see in Chapter 5 and beyond that in each clock cycle, a computercan perform a piece of useful work. When people say their laptop computers runat a frequency of 2 gigahertz, they are saying their laptop computers performtwo billion pieces of work each second since 2 gigahertz means two billion clockcycles each second, each clock cycle lasting for just one-half of a nanosecond. Thesynchronous ﬁnite state machine makes one state transition each clock cycle.We will show by means of a traﬃcs i g n a lc o n t r o l l e rh o wt h ec l o c ks i g n a lcontrols the transition, ﬁxed clock cycle after ﬁxed clock cycle, from one state tothe next.\n",
      "10Figure.Ac l o c ks i g n a l .\n",
      "\n",
      "..Example: A Danger SignMany electrical, mechanical, and aeronautical systems are controlled by a syn-chronous ﬁnite state machine. In this section, we will design the complete logicneeded for a synchronous ﬁnite state machine to control a traﬃcd a n g e rs i g n .Figure 3.29 shows the danger sign as it will be placed on the highway. Note thesign says, “Danger, Move Right.” The sign contains ﬁve lights (labeled 1 through5i nt h eﬁ g u r e ) .The purpose of our synchronous ﬁnite state machine (a.k.a. a controller) is todirect the behavior of our system. In our case, the system is the set of lights on thetraﬃcd a n g e rs i g n .T h ec o n t r o l l e r ’ sj o bi st oh a v et h eﬁ v el i g h t sﬂ a s ho na n doﬀto warn automobile drivers to move to the right. The controller is equipped withas w i t c h .W h e nt h es w i t c hi si nt h eO Np o s i t i o n ,t h ec o n t r o l l e rd i r e c t st h el i g h t sas follows: During one unit of time, all lights will be oﬀ. In the next unit of time,lights 1 and 2 will be on. The next unit of time, lights 1, 2, 3, and 4 will be on.Then all ﬁve lights will be on. Then the sequence repeats: no lights on, followedby 1 and 2 on, followed by 1, 2, 3, and 4 on, and so forth. Each unit of time lastsonedirthelig\n",
      "Figure.At r aﬃcd a n g e rs i g n .The State Diagram for the Danger Sign ControllerFigure 3.30 is a state dia-gram for the synchronous ﬁnite state machine that controls the lights. There arefour states, one for each of the four conditions corresponding to which lights areon. Note that the outputs (whether each light is on or oﬀ)a r ed e t e r m i n e db yt h ecurrent state of the system.If the switch is on (input=1), the transition from each state to the nextstate happens at one-second intervals, causing the lights to ﬂash in the sequence\n",
      "\n",
      "\n",
      "1Figure.State diagram for the danger sign controller.described. If the switch is turned oﬀ(input=0), the state always transitions tostate A, the “all oﬀ”s t a t e .The Sequential Logic Circuit for the Danger Sign ControllerRecall thatFigFigto\n",
      "ClockFigure.Sequential logic circuit for the danger sign controller.\n",
      "\n",
      "First, the two external inputs: the switch and the clock. The switch determineswhether the ﬁnite state machine will transition through the four states or whetherit will transition to state A, where all lights are oﬀ.T h eo t h e ri n p u t( t h ec l o c k )controls the transition from state A to B, B to C, C to D, and D to A by controllingthe state of the storage elements. We will see how, momentarily.Second, there are two storage elements for storing state information. Sincethere are four states, and since each storage element can store one bit of informa-tion, the four states are identiﬁed by the contents of the two storage elements: A(00), B (01), C (10), and D (11). Storage element 2 contains the high bit; storageelement 1 contains the low bit. For example, the danger sign controller is in stateBw h e ns t o r a g ee l e m e n t2i s0a n ds t o r a g ee l e m e n t1i s1 .Third, combinational logic circuit 1 shows that the on/oﬀbehavior of thelights is controlled by the storage elements. That is, the input to the combinationallogic circuit is from the two storage elements, that is, the current state of the ﬁnitestate machine.Finally, combinational logic circuit 2 shows that the transition from the cur-rent state to the next state depends on the two storage elements and the switch. Ifthe switch is on, the output of combinational logic circuit 2 depends on the stateof the two storage elements.The Combinational LogicFigure 3.32 shows the logic that implements com-binational lo ic circuits 1 and 2.extertwo s\n",
      "Figure.Combinational logic circuitsand.\n",
      "\n",
      "First, let us look at the outputs that control the lights. As we have said, thereare only three outputs necessary to control the lights. Light 5 is controlled bythe output of the AND gate labeled V, since the only time light 5 is on is whenthe controller is in state 11. Lights 3 and 4 are controlled by the output of theOR gate labeled X, since there are two states in which those lights are on, thoselabeled 10 and 11. Why are lights 1 and 2 controlled by the output of the OR gatelabeled W? See Exercise 3.42.Next, let us look at the internal outputs that control the storage elements,which specify the next state of the controller. Storage element 2 should be setto 1 for the next clock cycle if the next state is 10 or 11. This is true only if theswitch is on and the current state is either 01 or 10. Therefore, the output signalthat will make storage element 2 be 1 in the next clock cycle is the output of theOR gate labeled Y. Why is the next state of storage element 1 controlled by theoutput of the OR gate labeled Z? See Exercise 3.42.The Two Storage ElementsIn order for the danger sign controller to work, thestate transitions must occur once per second when the switch is on.AP r o b l e mw i t hG a t e dL a t c h e sa sS t o r a g eE l e m e n t sWhat would happen if thestorage elements were gated D latches? If the two storage elements were gatedDl a t c h e s ,w h e nt h ew r i t ee n a b l es i g n a l( t h ec l o c k )i s1 ,t h eo u t p u to fO Rg a t e sY and Z would immediately change the bits stored in the two gated D latches.This would produce new input values to the three AND gates that are input toOR gates Y and Z, producing new outputs that would be applied to the inputs ofthe gated latches, which would in turn change the bits stored in the gated latches,which would in turn mean new inputs to the three AND gates and new outputsof OR gates Y and Z. This would happen again and again, continually changingthe bits stored in the two storage elements as long as the Write Enable signal tothe gated D latches was asserted. The result: We have no idea what the state of theﬁnite state machine would be for the next clock cycle. And, even in the currentclock cycle, the state of the storage elements would change so fast that the ﬁvelights would behave erratically.The problem is the gated D latch. We want the output of OR gates Y and Zto transition to the next state at the end of the current clock cycle and allow thecurrent state to remain unchanged until then. That is, we do not want the inputto the storage elements to take eﬀect until the end of the current clock cycle.Since the output of a gated D latch changes immediately in response to its inputif the Write Enable signal is asserted, it cannot be the storage element for oursynchronous ﬁnite state machine. We need storage elements that allow us to readthe current state throughout the current clock cycle, and not write the next statevalues into the storage elements until the beginning of the next clock cycle.The Flip-Flop to the RescueIt is worth repeating: To prevent the above fromhappening, we need storage elements that allow us to read the current statethroughout the current clock cycle, and not write the next state values into thestorage elements until the beginning of the next clock cycle. That is, the function\n",
      "\n",
      "ClockFigure.Am a s t e r / s l a v eﬂ i p - ﬂ o p .to be performed during a single clock cycle involves reading and writing a partic-ular variable. Reading must be allowed throughout the clock cycle, and writingmust occur at the end of the clock cycle.Aﬂ i p - ﬂ o pc a na c c o m p l i s ht h a t .O n ee x a m p l eo faﬂ i p - ﬂ o pi st h em a s t e r / s l a v eﬂip-ﬂop shown in Figure 3.33. The master/slave ﬂip-ﬂop can be constructed outof two gatedDlatches, one referred to as the master, the other referred to as theslave. Note that the write enable signal of the master is 1 when the clock is 0, andthe write enable signal of the slave is 1 when the clock is 1.Figure 3.34 is a timing diagram for the master/slave ﬂip-ﬂop, which showshow and why the master/slave ﬂip-ﬂop solves the problem. A timing diagramshows time passing from left to right. Note that clock cycle n starts at the timelabeled 1 and ends at the time labeled 4. Clock cycle n+1 starts at the timelabeled 4.Consider clock cycle n, which we will discuss in terms of its ﬁrst half A, itssecond half B, and the four time points labeled 1, 2, 3, and 4.At the start of each clock cycle, the outputs of the storage elements are theoutputs of the two slave latches. These outputs (starting at time 1) are input tothe AND gates, resulting in OR gates Y and Z producing the next state values forthe storage elements (at time 2). The timing diagram shows the propagation delayof the combinational logic, that is, the time it takes for the combinational logicto produce outputs of OR gates Y and Z. Although OR gates Y and Z producethe Next State value sometime during half-cycle A, the write enable signal to themaster latches is 0, so the next state cannot be written into the master latches.At the start of half-cycle B (at time 3), the clock signal is 0, which meansthe write enable signal to the master latches is 1, and the master latches can bewritten. However, during the half-cycle B, the write enable to the slave latches is0, so the slave latches cannot write the new information now stored in the masterlatches.At the start of clock cycle n+1 (at time 4), the write enable signal to the slavelatches is 1, so the slave latches can store the next state value that was created bythe combinational logic during clock cycle n. This becomes the current state forclock cycle n+1.\n",
      "\n",
      "nal to the master latches is now 0, the state of theThus, although the write enable signal to the slavetc h a n g eb e c a u s et h em a s t e rl a t c h e sc a n n o tc h a n g e .slave latches contains the current state of the systemcle and produces the inputs to the six AND gates ints. Their state changes at the start of the clock cycleby storing the next state information created by the combinational logic duringthe previous cycle but does not change again during the clock cycle. The reasonthey do not change again during the clock cycle is as follows: During half-cycleA, the master latches cannot change, so the slave latches continue to see the stateinformation that is the current state for the new clock cycle. During half-cycle B,the slave latches cannot change because the clock signal is 0.Meanwhile, during half-cycle B, the master latches can store the next stateinformation produced by the combinational logic, but they cannot write it intothe slave latches until the start of the next clock cycle, when it becomes the stateinformation for the next clock cycle..Preview of Coming Attractions:The Data Path of the LC-In Chapter 5, we will specify a computer, which we call the LC-3, and you willhave the opportunity to write computer programs to execute on it. We close outChapter 3 with a discussion of Figure 3.35, thedata pathof the LC-3 computer.The data path consists of all the logic structures that combine to processinformation in the core of the computer. Right now, Figure 3.35 is undoubtedlymore than a little intimidating, but you should not be concerned by that. You arenot ready to analyze it yet. That will come in Chapter 5. We have included ithere, however, to show you that you are already familiar with many of the basicstructures that make up a computer. For example, you see ﬁve MUXes in the datapath, and you already know how they work. Also, an adder (shown as the ALUsymbol with a + sign inside) and an ALU. You know how those elements areconstructed from gates.One element that we have not identified explicitly yet is a register. A registeris simply a set ofnflip-flops that collectively are used to store onen-bit value. InFigure 3.35, PC, IR, MAR, and MDR are all 16-bit registers that store 16 bits ofinformation each. The block labeled REG FILE consists of eight registers that eachstore 16 bits of information. As you know, one bit of information can be stored inone flip-flop. Therefore, each of these registers consists of 16 flip-flops. The datapath also shows three 1-bit registers,N,Z, andP.T h o s er e g i s t e r sr e q u i r eo n l yo n eflip-flop each. In fact, a register can be any size that we need. The size depends onlyon the number of bits we need to represent the value we wish to store.One way to implement registers is with master/slave ﬂip-ﬂops. Figure 3.36shows a four-bit register made up of four master/slave ﬂip-ﬂops. We usually needﬂip-ﬂops, rather than latches, because it is usually important to be able to bothread the contents of a register throughout a clock cycle and also store a new value\n",
      "\n",
      "von NeumannelWea r en o wr e a d yt or a i s eo u rl e v e lo fa b s t r a c t i o na n o t h e rn o t c h .W ew i l lbuild on the logic structures that we studied in Chapter 3, both decisionelements and storage elements, to construct the basic computer model ﬁrst pro-posed in the 1940s, usually referred to as the von Neumann machine. ...and, wewill write our ﬁrst computer program in the ISA of the LC-3..Basic ComponentsTo get a task done by a computer, we need two things: (a) acomputer pro-gramthat speciﬁes what the computer must do to perform the task, and (b) thecomputerthat is to carry out the task.Ac o m p u t e rp r o g r a mc o n s i s t so fas e to fi n s t r u c t i o n s ,e a c hs p e c i f y i n gaw e l l -deﬁned piece of work for the computer to carry out. Theinstructionis the smallestpiece of work speciﬁed in a computer program. That is, the computer either car-ries out the work speciﬁed by an instruction or it does not. The computer doesnot have the luxury of carrying out only a piece of an instruction.John von Neumann proposed a fundamental model of a computer for process-ing computer programs in 1946. Figure 4.1 shows its basic components. We havetaken a little poetic license and added a few of our own minor embellishmentsto von Neumann’s original diagram. The von Neumann model consists of ﬁveparts:memory, a processing unit, input, output,a n dac o n t r o lu n i t.T h ec o m p u t e rprogram is contained in the computer’s memory. The data the program needs tocarry out the work of the program is either contained in the program’s memoryor is obtained from the input devices. The results of the program’s execution areprovided by the output devices. The order in which the instructions are carriedout is performed by the control unit.We will describe each of the ﬁve parts of the von Neumann model in greaterdetail.\n",
      "\n",
      "\n",
      "PCFigure.The von Neumann model, overall block diagram...MemoryRecall that in Chapter 3 we examined a simple 22-by-3-bit memory that was con-structed out of gates and latches. A more realistic memory for one of today’scomputer systems is 234by 8 bits. That is, a typical memory in today’s world ofcomputers consists of 234distinct memory locations, each of which is capableof storing eight bits of information. We say that such a memory has anaddressspaceof 234uniquely identiﬁable locations, and anaddressabilityof eight bits.We refer to such a memory as a 16-gigabyte memory (abbreviated, 16 GB). The“16 giga” refers to the 234locations, and the “byte” refers to the eight bits storedin each location. The term is 16 giga because 16 is 24andgigais the term we useto represent 230,w h i c hi sa p p r o x i m a t e l yo n eb i l l i o n ;24times 230=234.Abyteisthe word we use to describe eight bits, much the way we use the wordgallontodescribe four quarts.We note (as we will note again and again) that withkbits, we can representuniquely 2kitems. Thus, to uniquely identify 234memory locations, each loca-tion must have its own 34-bit address. In Chapter 5, we will begin the completedeﬁnition of the LC-3 computer. We will see that the memory address space ofthe LC-3 is 216,a n dt h ea d d r e s s a b i l i t yi s1 6b i t s .Recall from Chapter 3 that we access memory by providing the address fromwhich we wish to read, or to which we wish to write. To read the contents of a\n",
      "\n",
      "Figure.Locationcontains the value;l o c a t i o ncontains the value.memory location, we ﬁrst place the address of that location in the memory’saddress register (MAR)a n dt h e ni n t e r r o g a t et h ec o m p u t e r ’ sm e m o r y .T h einformation stored in the location having that address will be placed in thememory’s data register (MDR). To write (or store) a value in a memory location,we ﬁrst write the address of the memory location in the MAR, and the value to bestored in the MDR. We then interrogate the computer’s memory with the writeenable signal asserted. The information contained in the MDR will be writteninto the memory location whose address is in the MAR.Before we leave the notion of memory for the moment, let us again emphasizethe two characteristics of a memory location: its address and what is stored there.Figure 4.2 shows a representation of a memory consisting of eight locations. Itsaddresses are shown at the left, numbered in binary from 0 to 7. Each locationcontains eight bits of information. Note that the value 6 is stored in the memorylocation whose address is 4, and the value 4 is stored in the memory locationwhose address is 6. These represent two very diﬀerent situations.Finally, an analogy: the post oﬃce boxes in your local post oﬃce. The boxnumber is like the memory location’s address. Each box number is unique. Theinformation stored in the memory location is like the letters contained in the postoﬃce box. As time goes by, what is contained in the post oﬃce box at any par-ticular moment can change. But the box number remains the same. So, too, witheach memory location. The value stored in that location can be changed, but thelocation’s memory address remains unchanged...Processing UnitThe actual processing of information in the computer is carried out by theprocessing unit.T h ep r o c e s s i n gu n i ti nam o d e r nc o m p u t e rc a nc o n s i s to fm a n ysophisticated complex functional units, each performing one particular operation(divide, square root, etc.). The simplest processing unit, and the one normallythought of when discussing the basic von Neumann model, is theALU.ALUis theabbreviation for Arithmetic and Logic Unit, so called because it is usually capa-ble of performing basic arithmetic functions (like ADD and SUBTRACT) andbasic logic operations (like bit-wise AND, OR, and NOT) that we have alreadystudied in Chapter 2. We will see in Chapter 5 that the LC-3 has an ALU, which\n",
      "\n",
      "can perform ADD, AND, and NOT operations. Two of these (ADD and AND)we will discuss in this chapter.The ALU normally processes data elements of a ﬁxed size referred to as theword lengthof the computer. The data elements are calledwords.F o re x a m p l e ,to perform ADD, the ALU receives two words as inputs and produces a singleword (the sum) as output. Each ISA has its own word length, depending on theintended use of the computer.Most microprocessors today that are used in PCs or workstations have a wordlength of 64 bits (as is the case with Intel’s “Core” processors) or 32 bits (as isthe case with Intel’s “Atom” processors). Even most microprocessors now used incell phones have 64-bit word lengths, such as Apple’s A7 through A11 processors,and Qualcomm’s SnapDragon processors. However, the microprocessors used invery inexpensive applications often have word lengths of as little as 16 or even8b i t s .In the LC-3, the ALU processes 16-bit words. We say the LC-3 has a wordlength of 16 bits.It is almost always the case that a computer provides some small amount ofstorage very close to the ALU to allow results to be temporarily stored if theywill be needed to produce additional results in the near future. For example, if acomputer is to calculate (A+B)/uni22C5C,i tc o u l ds t o r et h er e s u l to fA+Bin memory, andthen subsequently read it in order to multiply that result byC.H o w e v e r ,t h et i m eit takes to access memory is long compared to the time it takes to perform theADD or MULTIPLY. Almost all computers, therefore, have temporary storagefor storing the result ofA+Bin order to avoid the much longer access time thatwould be necessary when it came time to multiply. The most common form oftemporary storage is a set of registers, like the register described in Section 3.7.Typically, the size of each register is identical to the size of values processedby the ALU; that is, they each contain one word. The LC-3 has eight registers(R0, R1,…R7), each containing 16 bits.Current microprocessors typically contain 32 registers, each consisting of 32or 64 bits, depending on the architecture. These serve the same purpose as theeight 16-bit registers in the LC-3. However, the importance of temporary storagefor values that most modern computers will need shortly means many computerstoday have an additional set of special-purpose registers consisting of 128 bits ofinformation to handle special needs. Those special needs we will have to save forlater in your studies...Input and OutputIn order for a computer to process information, the information must get intothe computer. In order to use the results of that processing, those results mustbe displayed in some fashion outside the computer. Many devices exist for thepurposes of input and output. They are generically referred to in computer jar-gon asperipheralsbecause they are in some sense accessories to the processingfunction. Nonetheless, they are no less important.In the LC-3 we will have the two most basic input and output devices. Forinput, we will use the keyboard; for output, we will use the monitor.\n",
      "\n",
      "There are, of course, many other input and output devices in computer sys-tems today. For input we have among other things the mouse, digital scanners,and shopping mall kiosks to help you navigate the shopping mall. For output wehave among other things printers, LED displays, disks, and shopping mall kiosksto help you navigate the shopping mall. :-) In the old days, a lot of input and out-put was carried out by punched cards. Fortunately, for those who would have tolug around boxes of cards, the use of punched cards has largely disappeared...Control UnitThe control unit is like the conductor of an orchestra; it is in charge of makingall the other parts of the computer play together. As we will see when we describethe step-by-step process of executing a computer program, it is the control unitthat keeps track of both where we are within the process of executing the programand where we are in the process of executing each instruction.To keep track of which instruction is being executed, the control unit has aninstruction registerto contain that instruction. To keep track of which instruc-tion is to be processed next, the control unit has a register that contains the nextinstruction’s address. For historical reasons, that register is called theprogramcounter(abbreviated PC), although a better name for it would be theinstructionpointer,s i n c et h ec o n t e n t so ft h i sr e g i s t e ri s ,i ns o m es e n s e ,“ p o i n t i n g ”t ot h enext instruction to be processed. Curiously, Intel does in fact call that register theinstruction pointer, but the simple elegance of that name has not caught on..The LC-: An Examplevon Neumann MachineIn Chapter 5, we will specify in detail the LC-3, a simple computer that wewill study extensively. We have already shown you its data path in Chapter 3(Figure 3.35) and identiﬁed several of its structures in Section 4.1. In this sec-tion, we will pull together all the parts of the LC-3 we need to describe it as a vonNeumann computer (see Figure 4.3).We constructed Figure 4.3 by starting with the LC-3’s full data path(Figure 3.35) and removing all elements that are not essential to pointing outthe ﬁve basic components of the von Neumann model.Note that there are two kinds of arrowheads in Figure 4.3: ﬁlled-in andnot-ﬁlled-in. Filled-in arrowheads denote data elements that ﬂow along the cor-responding paths. Not-ﬁlled-in arrowheads denote control signals that control theprocessing of the data elements. For example, the box labeled ALU in the pro-cessing unit processes two 16-bit values and produces a 16-bit result. The twosources and the result are all data, and are designated by ﬁlled-in arrowheads.The operation performed on those two 16-bit data elements (it is labeled ALUK)is part of the control—therefore, a not-ﬁlled-in arrowhead.MEMORYconsists of the storage elements, along with the MemoryAddress Register (MAR) for addressing individual locations and the\n",
      "\n",
      "\n",
      "OUTPUTINPUTMEMORYFigure.The LC-as an example of the von Neumann model.Memory Data Register (MDR) for holding the contents of a memorylocation on its way to/from the storage. Note that the MAR contains 16 bits,reﬂecting the fact that the memory address space of the LC-3 is 216memory locations. The MDR contains 16 bits, reﬂecting the fact that eachmemory location contains 16 bits—that is, the LC-3 is 16-bit addressable.INPUT/OUTPUTconsists of a keyboard and a monitor. The simplestkeyboard requires two registers: a keyboard data register (KBDR) forholding the ASCII codes of keys struck and a keyboard status register(KBSR) for maintaining status information about the keys struck. Thesimplest monitor also requires two registers: a display data register (DDR)for holding the ASCII code of something to be displayed on the screen and\n",
      "\n",
      "ad i s p l a ys t a t u sr e g i s t e r( D S R )f o rm a i n t a i n i n ga s s o c i a t e ds t a t u sinformation. These input and output registers will be discussed in detailin Chapter 9.THE PROCESSING UNITconsists of a functional unit (ALU) thatperforms arithmetic and logic operations and eight registers (R0,…R7) forstoring temporary values that will be needed in the near future as operandsfor subsequent instructions. The LC-3 ALU can perform one arithmeticoperation (addition) and two logical operations (bitwise AND and bitwiseNOT).THE CONTROL UNITconsists of all the structures needed to managethe processing that is carried out by the computer. Its most importantstructure is the ﬁnite state machine, which directs all the activity. Recall theﬁnite state machines in Section 3.6. Processing is carried out step by step,or rather, clock cycle by clock cycle. Note the CLK input to the ﬁnite statemachine in Figure 4.3. It speciﬁes how long each clock cycle lasts. Theinstruction register (IR) is also an input to the ﬁnite state machine sincethe LC-3 instruction being processed determines what activities must becarried out. The program counter (PC) is also a part of the control unit;it keeps track of the next instruction to be executed after the currentinstruction ﬁnishes.Note that all the external outputs of the ﬁnite state machine in Figure 4.3 havearrowheads that are not ﬁlled in. These outputs control the processing through-out the computer. For example, one of these outputs (two bits) is ALUK, whichcontrols the operation performed in the ALU (ADD, AND, or NOT) during thecurrent clock cycle. Another output is GateALU, which determines whether ornot the output of the ALU is provided to the processor bus during the currentclock cycle.The complete description of the data path, control, and ﬁnite state machinefor one implementation of the LC-3 is the subject of Appendix C..Instruction ProcessingThe central idea in the von Neumann model of computer processing is that theprogram and data are both stored as sequences of bits in the computer’s memory,and the program is executed one instruction at a time under the direction of thecontrol unit...The InstructionThe most basic unit of computer processing is the instruction. It is made up of twoparts, theopcode(what the instruction does) and theoperands(who it does it to!).There are fundamentally three kinds of instructions:operates,data move-ment,a n dcontrol,a l t h o u g hm a n yI S A sh a v es o m es p e c i a li n s t r u c t i o n st h a ta r enecessary for those ISAs.Operateinstructions operate on data. The LC-3 hasthree operate instructions: one arithmetic (ADD) and two logicals (AND and\n",
      "\n",
      "NOT).Data movementinstructions move information from the processing unitto and from memory and to and from input/output devices. The LC-3 has six datamovement instructions.Controlinstructions are necessary for altering the sequential processing ofinstructions. That is, normally the next instruction executed is the instructioncontained in the next memory location. If a program consists of instructions1,2,3,4...10 located in memory locations A, A+1, A+2, ...A+9, normally theinstructions would be executed in the sequence 1,2,3...10. We will see before weleave Chapter 4, however, that sometimes we will want to change the sequence.Control instructions enable us to do that.An LC-3 instruction consists of 16 bits (one word), numbered from left toright, bit [15] to bit [0]. Bits [15:12] contain the opcode. This means there are atmost 24distinct opcodes. Actually, we use only 15 of the possible four-bit codes.One is reserved for some future use. Bits [11:0] are used to ﬁgure out where theoperands are.Exa\n",
      "s a or a as e er e con en s o reg s er o e con en s o\n",
      "\n",
      "..The Instruction Cycle (NOT the Clock Cycle!)Instructions are processed under the direction of the control unit in a very sys-tematic, step-by-step manner. The entire sequence of steps needed to process aninstruction is called theinstruction cycle.T h ei n s t r u c t i o nc y c l ec o n s i s t so fs i xsequentialphases,e a c hp h a s er e q u i r i n gz e r oo rm o r es t e p s .W es a yz e r os t e p sto indicate that most computers have been designed such that not all instructionsrequire all six phases. We will discuss this momentarily. But ﬁrst, we will examinethe six phases of the instruction cycle:FETCHDECODEEVALUATE ADDRESSFETCH OPERANDSEXECUTESTORE RESULTThe process is as follows (again refer to Figure 4.3, our simpliﬁed version ofthe LC-3 data path):...FETCHThe FETCH phase obtains the next instruction from memory and loads it intothe instruction register (IR) of the control unit. Recall that a computer programconsists of a number of instructions, that each instruction is represented by asequence of bits, and that the entire program (in the von Neumann model) is storedin the computer’s memory. In order to carry out the work of an instruction, wemust ﬁrst identify where it is. The program counter (PC) contains the address ofthe next instruction to be processed. Thus, the FETCH phase takes the followingsteps:First the MAR is loaded with the contents of the PC.Next, the memory is interrogated, which resultsin the next instruction being placed by the memoryinto the MDR.Finally, the IR is loaded with the contentsof the MDR.We are now ready for the next phase, decoding the instruction. However, whenthe instruction ﬁnishes execution, and we wish to fetch the next instruction, wewould like the PC to contain the address of the next instruction. This is accom-plished by having the FETCH phase perform one more task: incrementing thePC. In that way, after the current instruction ﬁnishes, the FETCH phase of thenext instruction will load into the IR the contents of the next memory location,provided the execution of the current instruction does not involve changing thevalue in the PC.The complete description of the FETCH phase is as follows:Step 1: Load the MAR with the contents of the PC, andsimultaneously increment the PC.\n",
      "\n",
      "Step 2: Interrogate memory, resulting in the instructionbeing placed in the MDR.Step 3: Load the IR with the contents of the MDR.Each of these steps is under the direction of the control unit, much like, as we saidpreviously, the instruments in an orchestra are under the control of a conductor’sbaton. Each stroke of the conductor’s baton corresponds to onemachine cycle.We will see in Section 4.3.5 that the amount of time taken by each machine cycleis one clock cycle. In fact, we often use the two terms interchangeably. Step 1takes one clock cycle. Step 2 could take one clock cycle or many clock cycles,depending on how long it takes to access the computer’s memory. Step 3 takesone clock cycle. In a modern digital computer, a clock cycle takes a very smallfraction of a second.Indeed, a 3.1 GHz Intel Core i7 completes 3.1 billion clock cycles in onesecond. Said another way, one clock cycle takes 0.322 billionths of a second(0.322 nanoseconds). Recall that the light bulb that is helping you read this textis switching on and oﬀat the rate of 60 times a second. Thus, in the time it takesal i g h tb u l bt os w i t c ho na n doﬀonce, today’s computers can complete more than51 million clock cycles!...DECODEThe DECODE phase examines the instruction in order to ﬁgure out whatthe microarchitecture is being asked to do. Recall the decoders we studied inChapter 3. In the LC-3, a 4-to-16 decoder identiﬁes which of the 16 opcodes is tobe processed (even though one of the 16 is not used!). Input is the four-bit opcodeIR [15:12]. The output line asserted is the one corresponding to the opcode atthe input. Depending on which output of the decoder is asserted, the remaining12 bits identify what else is needed to process that instruction....EVALUATE ADDRESSThis phase computes the address of the memory location that is needed to pro-cess the instruction. Recall the example of the LD instruction: The LD instructioncauses a value stored in memory to be loaded into a register. In that exam-ple, the address was obtained by sign-extending bits [8:0] of the instruction to16 bits and adding that value to the current contents of the PC. This calculationwas performed during the EVALUATE ADDRESS phase. It is worth noting thatnot all instructions access memory to load or store data. For example, we havealready seen that the ADD and AND instructions in the LC-3 obtain their sourceoperands from registers or from the instruction itself and store the result of theADD or AND instruction in a register. For those instructions, the EVALUATEADDRESS phase is not needed....FETCH OPERANDSThis phase obtains the source operands needed to process the instruction. In theLD example, this phase took two steps: loading MAR with the address calculatedin the EVALUATE ADDRESS phase and reading memory that resulted in thesource operand being placed in MDR.\n",
      "\n",
      "In the ADD example, this phase consisted of obtaining the source operandsfrom R2 and R6. In most current microprocessors, this phase (for the ADDinstruction) can be done at the same time the instruction is being executed (theﬁfth phase of the instruction cycle). Exactly how we can speed up the processingof an instruction in this way is a fascinating subject, but it is one we are forced toleave for later in your education....EXECUTEThis phase carries out the execution of the instruction. In the ADD example, thisphase consisted of the step of performing the addition in the ALU....STORE RESULTThe ﬁnal phase of an instruction’s execution. The result is written to its designateddestination. In the case of the ADD instruction, in many computers this action isperformed during the EXECUTE phase. That is, in many computers, includingthe LC-3, an ADD instruction can fetch its source operands, perform the ADD inthe ALU, and store the result in the destination register all in a single clock cycle.As e p a r a t eS T O R ER E S U L Tp h a s ei sn o tn e e d e d .Once the instruction cycle has been completed, the control unit begins theinstruction cycle for the next instruction, starting from the top with the FETCHphase. Since the PC was updated during the previous instruction cycle, it containsat this point the address of the instruction stored in the next sequential memorylocation. Thus, the next sequential instruction is fetched next. Processing con-tinues in this way until something breaks this sequential ﬂow, or the programﬁnishes execution.It is worth noting again that although the instruction cycle consists of sixphases, not all instructions require all six phases. As already pointed out, the LC-3A D Di n s t r u c t i o nd o e sn o tr e q u i r eas e p a r a t eE V A L U A T EA D D R E S Sp h a s eo ras e p a r a t eS T O R ER E S U L Tp h a s e .T h eL C - 3L Di n s t r u c t i o nd o e sn o tr e q u i r ea nEXECUTE phase. On the other hand, there are instructions in other ISAs thatrequire all six phases.Example.ADD [eax], edxThis is an example of an Intel x86 instruction that requiresall six phases of the instruction cycle. All instructions require the ﬁrst two phases,FETCH and DECODE. This instruction uses the eax register to calculate the addressof a memory location (EVALUATE ADDRESS). The contents of that memorylocation is then read (FETCH OPERAND), added to the contents of the edx reg-ister (EXECUTE), and the result written into the memory location that originallycontained the ﬁrst source operand (STORE RESULT)...Changing the Sequence of ExecutionEverything we have said thus far happens when a computer program is executedin sequence. That is, the ﬁrst instruction is executed, then the second instructionis executed, followed by the third instruction, and so on.\n",
      "\n",
      "We have identiﬁed two types of instructions, the ADD and AND, which areexamples ofoperate instructionsin that they operate on data, and the LD, whichis an example of adata movement instructionin that it moves data from oneplace to another. There are other examples of both operate instructions and datamovement instructions, as we will discover in Chapter 5 when we study the LC-3in greater detail.There is a third type of instruction, thecontrol instruction,w h o s ep u r p o s ei sto change the sequence of instruction execution. For example, there are times, aswe shall see very soon, when it is desirable to ﬁrst execute the ﬁrst instruction,then the second, then the third, then the ﬁrst again, the second again, then the thirdagain, then the ﬁrst for the third time, the second for the third time, and so on. Aswe know, each instruction cycle starts with loading the MAR with the PC. Thus,if we wish to change the sequence of instructions executed, we must change thecontents of the PC between the time it is incremented (during the FETCH phaseof one instruction) and the start of the FETCH phase of the next instruction.Control instructions perform that function by loading the PC during theEXECUTE phase, which wipes out the incremented PC that was loaded duringthe FETCH phase. The result is that, at the start of the next instruction cycle,when the computer accesses the PC to obtain the address of an instruction tofetch, it will get the address loaded during the previous instruction’s EXECUTEphase, rather than the next sequential instruction in the computer’s program.The most common control instruction is theconditional branch(BR), whicheither changes the contents of the PC or does not change the contents of the PC,depending on the result of a previous instruction (usually the instruction that isexecuted immediately before the conditional branch instruction).Example.The BR InstructionThe BR instruction consists of three parts, the opcode (bits[15:12] = 0000), the condition to be tested (bits [11:9]), and the addressing mode bits(bits [8:0]) that are used to form the address to be loaded into the PC if the result ofthe previous instruction agrees with the test speciﬁed by bits [11:9]. The addressingmode, i.e., the mechanism used to determine the actual address, is the same one weused in the LD instruction. Bits [8:0] are sign-extended to 16 bits and then added tothe current contents of the PC.Suppose the BR instruction shown below is located in memory location x36C9.15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0000010 1111111010BR condition−6The opcode 0000 identiﬁes the instruction as a conditional branch. Bits [11:9] = 101speciﬁes that the test to be performed on the most recent result is whether or not thatresult is something other than 0. In Chapter 5 we will describe in detail all the teststhat can be performed on the most recent result. For now, we will just use one test:Is the result not zero? Bits [8:0] is the value−6.Assume the previous instruction executed (in memory location x36C8) was anADD instruction and the result of the ADD was 0. Since the test “not-zero” failed,the BR instruction would do nothing during its EXECUTE phase, and so the next(continued on next page)\n",
      "\n",
      "instruction executed would be the instruction at M[x36CA], the address formed byincrementing the PC during the FETCH phase of the BR instruction’s instructioncycle.On the other hand, if the result of the ADD instruction is not 0, then the testsucceeds, causing the BR instruction to load PC with x36C4, the address formed bysign-extending bits [8:0] to 16 bits and adding that value (-6) to the incremented PC(x36CA).Thus, the next instruction executed after the BR instruction at x36C9 is eitherthe instruction at x36CA or the one at x36C4, depending on whether the result of theADD instruction was zero or not zero...Control of the Instruction CycleThe instruction cycle is controlled by a synchronous ﬁnite state machine. Anabbreviated version of its state diagram, highlighting a few of the LC-3 instruc-tions discussed in this chapter, is shown in Figure 4.4. As is the case with theﬁnite state machines studied in Section 3.6, each state corresponds to one machinecycle of activity that takes one clock cycle to perform. The processing controlledby each state is described within the node representing that state. The arcs showthe next state transitions.Processing starts with State 1. The FETCH phase takes three clock cycles,corresponding to the three steps described earlier. In the ﬁrst clock cycle, theMAR is loaded with the contents of the PC, and the PC is incremented. In orderfor the contents of the PC to be loaded into the MAR (see Figure 4.3), the ﬁnitestate machine must assert GatePC and LD.MAR. GatePC connects the PC to theprocessor bus. LD.MAR, the write enable signal of the MAR register, loads thecontents of the bus into the MAR at the end of the current clock cycle. (Registersare loaded at the end of the clock cycle if the corresponding control signal isasserted.)In order for the PC to be incremented (again, see Figure 4.3), the ﬁnitestate machine must assert the PCMUX select lines to choose the output of thebox labeled+1a n dm u s ta l s oa s s e r tt h eL D . P Cs i g n a lt ol o a dt h eo u t p u to ft h ePCMUX into the PC at the end of the current cycle.The ﬁnite state machine then goes to State 2. Here, the MDR is loaded withthe instruction, which is read from memory.In State 3, the instruction is transferred from the MDR to the instructionregister (IR). This requires the ﬁnite state machine to assert GateMDR and LD.IR,which causes the IR to be loaded at the end of the clock cycle, concluding theFETCH phase of the instruction cycle.The DECODE phase takes one clock cycle. In State 4, using the externalinput IR, and in particular the opcode bits of the instruction, the ﬁnite statemachine can go to the appropriate next state for processing instructions depend-ing on the particular opcode in IR [15:12]. Three of the 15 paths out of State 4are shown. Processing continues clock cycle by clock cycle until the instructioncompletes execution, and the next state logic returns the ﬁnite state machine toState 1.\n",
      "\n",
      "As has already been discussed, it is sometimes necessary not to executethe next sequential instruction but rather to access another location to ﬁnd thenext instruction to execute. As we have said, instructions that change the ﬂow ofinstruction processing in this way are called control instructions. In the case ofthe conditional branch instruction (BR), at the end of its instruction cycle, thePC contains one of two addresses: either the incremented PC that was loaded inState 1 or the new address computed from sign-extending bits [8:0] of the BRinstruction and adding it to the PC, which was loaded in State 63. Which addressgets loaded into the PC depends on the test of the most recent result.A endix C contains a full descri tion of the im lementation of theLofm\n",
      "o a e o a eo a eFigure.An abbreviated state diagram of the LC-.\n",
      "\n",
      "state diagram would be able to control, clock cycle by clock cycle, all the stepsrequired to execute all the phases of every instruction cycle. Since each instruc-tion cycle ends by returning to State 1, the ﬁnite state machine can process, clockcycle by clock cycle, a complete computer program...Halting the Computer (the TRAP Instruction)From everything we have said, it appears that the computer will continueprocessing instructions, carrying out the instruction cycle again and again,ad nauseum.S i n c et h ec o m p u t e rd o e sn o th a v et h ec a p a c i t yt ob eb o r e d ,m u s tt h i scontinue until someone pulls the plug and disconnects power to the computer?Usually, user programs execute under the control of an operating system.Linux, DOS, MacOS, and Windows are all examples of operating systems.Operating systems are just computer programs themselves. As far as the com-puter is concerned, the instruction cycle continues whether a user program isbeing processed or the operating system is being processed. This is ﬁne asfar as user programs are concerned since each user program terminates with acontrol instruction that changes the PC to again start processing the operatingsystem—often to initiate the execution of another user program.But what if we actually want to stop this potentially inﬁnite sequence ofinstruction cycles? Recall our analogy to the conductor’s baton, beating at therate of billions of clock cycles per second. Stopping the instruction sequencingrequires stopping the conductor’s baton. We have pointed out many times thatthere is inside the computer a component that corresponds very closely to theconductor’s baton. It is called theclock, and it deﬁnes the amount of time eachmachine cycle takes. We saw in Chapter 3 that the clock enables the synchronousﬁnite state machine to continue on to the next clock cycle. In Chapter 3 the nextclock cycle corresponded to the next state of the danger sign we designed. Herethe next clock cycle corresponds to the next state of the instruction cycle, whichis either the next state of the current phase of the instruction cycle or the ﬁrst stateof the next phase of the instruction cycle. Stopping the instruction cycle requiresstopping the clock.Figure 4.5a shows a block diagram of the clock circuit, consisting primarilyof a clock generator and a RUN latch. The clock generator is a crystal oscillator,ap i e z o e l e c t r i cd e v i c et h a ty o um a yh a v es t u d i e di ny o u rp h y s i c so rc h e m i s t r yclass. Ftion ofFigureclock cCroClgenFigure.The clock circuit and its control.\n",
      "\n",
      "If the RUN latch is in the 1 state (i.e.,Q=1), the output of the clock circuitis the same as the output of the clock generator. If the RUN latch is in the 0 state(i.e.,Q=0), the output of the clock circuit is 0.Thus, stopping the instruction cycle requires only clearing the RUN latch.Every computer has some mechanism for doing that. In some older machines, itis done by executing a HALT instruction. In the LC-3, as in many other machines,it is done under control of the operating system, as we will see in Chapter 9. Fornow it is enough to know that if a user program requires help from the operatingsystem, it requests that help with the TRAP instruction (opcode = 1111) and aneight-bit code called atrap vector,w h i c hi d e n t i ﬁ e st h eh e l pt h a tt h eu s e rp r o g r a mneeds. The eight-bit code x25 tells the operating system that the program hasﬁnished executing and the computer can stop processing instructions.Question:If a HALT instruction can clear the RUN latch, thereby stoppingthe instruction cycle, what instruction is needed to set the RUN latch, therebyreinitiating the instruction cycle?Hint:This is a trick question!.Our First Program:A Multiplication AlgorithmWe now have all that we need to write our ﬁrst program. We have a data movementinstruction LD to load data from memory into a register, and we have two operateinstructions, ADD for performing arithmetic and AND for performing a bit-wiselogical operation. We have a control instruction BR for loading the PC with anaddress diﬀerent from the incremented PC so the instruction to be executed nextwill NOT be the instruction in the next sequential location in memory. And wehave the TRAP instruction (a.k.a. system call) that allows us to ask the operatingsystem for help, in this case to stop the computer. With all that under our belt, wecan write our ﬁrst program.Suppose the computer does not know how to multiply two positive integers.In the old days, that was true for a lot of computers! They had ADD instructions,but they did not have multiply instructions. What to do? Suppose we wanted tomultiply 5 times 4. Even if we do not know how to multiply, if we know that 5times 4 is 5+5+5+5, and the computer has an ADD instruction, we can write aprogram that can multiply. All we have to do is add 5 to itself four times.Figure 4.6 illustrates the process.Let us assume that memory location x3007, abbreviated M[x3007], containsthe value 5, and M[x3008] contains the value 4. We start by copying the twovalues from memory to the two registers R1 and R2. We are going to accumulatethe results of the additions in R3, so we initialize R3 to 0. Then we add 5 to R3,and subtract 1 from R2 so we will know how many more times we will need toadd 5 to R3. We keep doing this (adding 5 to R3 and subtracting 1 from R2) untilR2 contains the value 0. That tells us that we have added 5 to R3 four times andwe are done, so we HALT the computer. R3 contains the value 20, the result ofour multiplication.Figure 4.7 shows the actual LC-3 program, stored in memory locations x3000to x3008.\n",
      "\n",
      "\n",
      "StopFigure.Flowchart for an algorithm that multiplies two positive integers.The program counter, which keeps track of the next instruction to beexecuted, initially contains the address x3000.To move the data from memory locations M[x3007] and M[x3008] to R1 andR2, we use the data movement instruction LD. The LC-3 computer executes theLD instruction in M[x3000] by sign-extending the oﬀset (in this case 6) to 16 bits,adding it to the incremented PC (in this case x3001 since we incremented the PC\n",
      "Fg u r e .A program that multiplies without a multiply instruction.\n",
      "\n",
      "LC-InC h a p t e r4 ,w ed i s c u s s e dt h eb a s i cc o m p o n e n t so fac o m p u t e r — i t sm e m -ory, its processing unit, including the associated temporary storage (usuallyas e to fr e g i s t e r s ) ,i n p u ta n do u t p u td e v i c e s ,a n dt h ec o n t r o lu n i tt h a td i r e c t st h eactivity of all the units (including itself!). We also studied the six phases of theinstruction cycle—FETCH, DECODE, ADDRESS EVALUATION, OPERANDFETCH, EXECUTE, and STORE RESULT. We used elements of the LC-3 toillustrate some of the concepts. In fact, we introduced ﬁve opcodes: two operateinstructions (ADD and AND), one data movement instruction (LD), and two con-trol instructions (BR and TRAP). We are now ready to study the LC-3 in muchgreater detail.Recall from Chapter 1 that the ISA is the interface between what the soft-ware commands and what the hardware actually carries out. In this chapter, wewill point out most of the important features of the ISA of the LC-3. (A few ele-ments we will leave for Chapter 8 and Chapter 9.) You will need these featuresto write programs in the LC-3’s own language, that is, in the LC-3’smachinelanguage.A complete description of the ISA of the LC-3 is contained in Appendix A..The ISA: OverviewThe ISA speciﬁes all the information about the computer that the software hasto be aware of. In other words, the ISA speciﬁes everything in the computerthat is available to a programmer when he/she writes programs in the com-puter’s own machine language. Most people, however, do not write programsin the computer’s own machine language, but rather opt for writing programs ina high-level language like C++ or Python (or Fortran or COBOL, which havebeen around for more than 50 years). Thus, the ISA also speciﬁes everythingin the computer that is needed by someone (a compiler writer) who wishes totranslate programs written in a high-level language into the machine language ofthe computer.\n",
      "\n",
      "The ISA speciﬁes the memory organization, register set, and instruction set,including the opcodes, data types, and addressing modes of the instructions inthe instruction set...Memory OrganizationThe LC-3 memory has an address space of 216(i.e., 65,536) locations, and anaddressability of 16 bits. Not all 65,536 addresses are actually used for memorylocations, but we will leave that discussion for Chapter 9. Since the normal unitof data that is processed in the LC-3 is 16 bits, we refer to 16 bits as oneword,and we say the LC-3 isword-addressable...RegistersSince it usually takes far more than one clock cycle to obtain data from mem-ory, the LC-3 provides (like almost all computers) additional temporary storagelocations that can be accessed in a single clock cycle.The most common type of temporary storage locations, and the one used inthe LC-3, is a set of registers. Each register in the set is called ageneral purposeregister(GPR). Like memory locations, registers store information that can beoperated on later. The number of bits stored in each register is usually one word.In the LC-3, this means 16 bits.Registers must be uniquely identiﬁable. The LC-3 speciﬁes eight GPRs, eachidentiﬁed by a three-bit register number. They are referred to as R0, R1,…R7.Figure 5.1 shows a snapshot of the LC-3’s register set, sometimes called aregisterﬁle,w i t ht h ee i g h tv a l u e s1 ,3 ,5 ,7 ,−2,−4,−6, and−8s t o r e di nR 0 ,…R7,respectively.\n",
      "Figure.A snapshot of the LC-’s register ﬁle.\n",
      "\n",
      "Fi000101 0000000001ADD R2 R0 R1where the twosourcesof the ADD instruction are speciﬁed in bits [8:6] andbits [2:0]. Thedestinationof the ADD result is speciﬁed in bits [11:9]. Figure 5.2shows the contents of the register ﬁle of Figure 5.1 AFTER the instructionADD R2, R1, R0.is executed...The Instruction SetRecall from Chapter 4 that an instruction is made up of two things, itsopcode(what the instruction is asking the computer to do) and itsoperands(who thecomputer is expected to do it to!). The instruction set is deﬁned by its set ofopcodes,data types,a n daddressing modes.T h ea d d r e s s i n gm o d e sd e t e r m i n ewhere the operands are located. The data type is the representation of the operandsin 0s and 1s.The instruction ADD R2, R0, R1 has an opcode ADD, one addressing mode(register mode), and one data type (2’s complement integer). The instructiondirects the computer to perform a 2’s complement integer addition and speci-ﬁes the locations (GPRs) where the computer is expected to ﬁnd the operandsand the location (a GPR) where the computer is to write the result.We saw in Chapter 4 that the ADD instruction can also have two addressingmodes (register mode and immediate mode), where one of the two operands isliterally contained in bits [4:0] of the instruction.Figure 5.3 lists all the instructions of the LC-3, the bit encoding [15:12] foreach opcode, and the format of each instruction. Some of them you will recognizefrom Chapter 4. Many others will be explained in Sections 5.2, 5.3, and 5.4.\n",
      "\n",
      "..OpcodesSome ISAs have a very large number of opcodes, one for each of a very largenumber of tasks that a program may wish to carry out. The x86 ISA has more than200 opcodes. Other ISAs have a very small set of opcodes. Some ISAs have specificopcodes to help with processing scientific calculations. For example, the HewlettPackardPrecision Architecturecan specify the compound operation (A/uni22C5B)+Cwith one opcode; that is, a multiply, followed by an add on three source operandsA, B, and C. Other ISAs have instructions that process video images obtained fromthe World Wide Web. The Intel x86 ISA added a number of instructions which theyoriginally calledMMX instructionsbecause they eXtended the ISA to assist withMultiMedia applications that use the web. Still other ISAs have specific opcodes tohelp with handling the tasks of the operating system. For example, the VAX ISA,popular in the 1980s, used a single opcode instead of a long sequence of instructionsthat other computers used to save the information associated with a program thatwas in the middle of executing prior to switching to another program. The decisionas to which instructions to include or leave out of an ISA is usually a hotly debatedtopic in a company when a new ISA is being specified.The LC-3 ISA has 15 instructions, each identiﬁed by its unique opcode. Theopcode is speciﬁed in bits [15:12] of the instruction. Since four bits are usedto specify the opcode, 16 distinct opcodes are possible. However, the LC-3 ISAspeciﬁes only 15 opcodes. The code 1101 has been left unspeciﬁed, reserved forsome future need that we are not able to anticipate today.As we already discussed brieﬂy in Chapter 4, there are three diﬀerent typesof instructions, which means three diﬀerent types of opcodes:operates,datamovement,a n dcontrol.O p e r a t ei n s t r u c t i o n sp r o c e s si n f o r m a t i o n .D a t am o v e -ment instructions move information between memory and the registers andbetween registers/memory and input/output devices. Control instructions changethe sequence of instructions that will be executed. That is, they enable the exe-cution of an instruction other than the one that is stored in the next sequentiallocation in memory...Data TypesAs we ﬁrst pointed out in Section 2.1.2, adata typeis a representation of infor-mation such that the ISA has opcodes that operate on that representation. Thereare many ways to represent the same information in a computer. That should notsurprise us, since in our daily lives, we regularly represent the same informationin many diﬀerent ways. For example, a child, when asked how old he is, mighthold up three ﬁngers, signifying that he is 3 years old. If the child is particularlyprecocious, he might write the decimal digit3to indicate his age. Or, if the childis a CS or CE major at the university, he might write 0000000000000011, the16-bit binary representation for 3. If he is a chemistry major, he might write3.0/uni22C5100.A l lf o u rr e p r e s e n tt h es a m ev a l u e :3 .In addition to the representation of a single number by diﬀerent bit patternsin diﬀerent data types, it is also the case that the same bit pattern can corre-spond to diﬀerent numbers, depending on the data type. For example, the 16\n",
      "\n",
      "bits 0011000100110000 represent the 2’s complement integer 12,592, the ASCIIcode for 10, and a bit vector such thatb13,b12,b7,b4,a n db3have the relevantproperty of the bit vector.That should also not surprise us, since in our daily lives, the same represen-tation can correspond to multiple interpretations, as is the case with a red light.When you see it on the roadway while you are driving, it means you should stop.When you see it at Centre Bell where the Montreal Canadiens play hockey, itmeans someone has just scored a goal.Every opcode will interpret the bit patterns of its operands according to thedata type it is designed to support. In the case of the ADD opcode, for example,the hardware will interpret the bit patterns of its operands as 2’s complementintegers. Therefore, if a programmer stored the bit pattern 0011000100110000 inR3, thinking that the bit pattern represented the integer 10, the instruction ADDR4, R3, #10 would write the integer 12,602 into R4, and not the ASCII code forthe integer 20. Why? Because the opcode ADD interprets the bit patterns of itsoperands as 2’s complement integers, and not ASCII codes, regardless what theperson creating those numbers intended...Addressing ModesAn addressing mode is a mechanism for specifying where the operand is located.An operand can generally be found in one of three places: in memory, in a register,or as a part of the instruction. If the operand is a part of the instruction, we refer toit as aliteralor as animmediateoperand. The termliteralcomes from the fact thatthe bits of the instructionliterallyform the operand. The termimmediatecomesfrom the fact that we can obtain the operand immediately from the instruction,that is, we don’t have to look elsewhere for it.The LC-3 supports ﬁve addressing modes: immediate (or literal), register,and three memory addressing modes:PC-relative,indirect,a n dBase+oﬀset.W ewill see in Section 5.2 that operate instructions use two addressing modes: registerand immediate. We will see in Section 5.3 that data movement instructions usefour of the ﬁve addressing modes...Condition CodesOne ﬁnal item will complete our overview of the ISA of the LC-3: conditioncodes. The LC-3 has three single-bit registers that are individually set (set to1) or cleared (set to 0) each time one of the eight general purpose registers iswritten into as a result of execution of one of the operate instructions or one ofthe load instructions. Each operate instruction performs a computation and writesthe result into a general purpose register. Each load instruction reads the contentsof a memory location and writes the value found there into a general purposeregister. We will discuss all the operate instructions in Section 5.2 and all theload instructions in Section 5.3.The three single-bit registers are calledN,Z,a n dP,c o r r e s p o n d i n gt ot h e i rmeaning: negative, zero, and positive. Each time a GPR is written by an operateor a load instruction, the N, Z, and P one-bit registers are individually set to 0\n",
      "\n",
      "or 1, corresponding to whether the result written to the GPR is negative, zero,or positive. That is, if the result is negative, the N register is set, and Z and Pare cleared. If the result is zero, Z is set and N and P are cleared. If the result ispositive, P is set and N and Z are cleared.The set of three single-bit registers are referred to ascondition codesbecausethe condition of those bits are used to change the sequence of execution of theinstructions in a computer program. Many ISAs use condition codes to changethe execution sequence. SPARC and x86 are two examples. We will show howthe LC-3 does it in Section 5.4..Operate Instructions..ADD, AND, and NOTOperate instructions process data. Arithmetic operations (like ADD, SUB, MUL,and DIV) and logical operations (like AND, OR, NOT, XOR) are commonexamples. The LC-3 has three operate instructions: ADD, AND, and NOT.TheNOT(opcode=1001) instruction is the only operate instruction thatperforms aunaryoperation, that is, the operation requires one source operand.Theresulits sspeciIinstrNOT R3 R5R3 will contain 1010111100001111.Figure 5.4 shows the key parts of the data path that are used to perform theNOT instruction shown here. Since NOT is a unary operation, only the A inputof the ALU is relevant. It is sourced from R5. The control signal to the ALUdirects the ALU to perform the bit-wise complement operation. The output ofthe ALU (the result of the operation) is stored in R3 and the condition codes areset, completing the execution of the NOT instruction.Recall from Chapter 4 that theADD(opcode=0001) andAND(opcode=0101) instructions both performbinaryoperations; they require two 16-bit sourceoperands. The ADD instruction performs a 2’s complement addition of its twosource operands. The AND instruction performs a bit-wise AND of each pairof bits of its two 16-bit operands. Like the NOT, the ADD and AND use theregister addressing mode for one of the source operands and for the destina-tion operand. Bits [8:6] specify the source register, and bits [11:9] specify thedestination register (where the result will be written).\n",
      "\n",
      "\n",
      "Figure.Data path relevant to the execution of NOT R,R...ImmediatesThe second source operand for both ADD and AND instructions (as also dis-cussed in Chapter 4) can be speciﬁed by either register mode or as an immediateoperand. Bit [5] determines which. If bit [5] is 0, then the second source operanduses a register, and bits [2:0] specify which register. In that case, bits [4:3] are set000100 1100000101ADD R1 R4 R5If bit [5] is 1, the second source operand is contained within the instruction.In that case the second source operand is obtained by sign-extending bits [4:0] to16 bits before performing the ADD or AND. The result of the ADD (or AND)instruction is written to the destination register and the condition codes are set,\n",
      "\n",
      "Figure.Data path relevant to the execution of ADD R,R,#−.completing the execution of the ADD (or AND) instruction. Figure 5.5 shows thekey parts of the data path that are used to perform the instructionADD R1, R4, #-2.Since the immediate operand in an ADD or AND instruction must ﬁt in bits[4:0]operanimmeWhaANSWER:Register 2 is cleared (i.e., set to all 0s).\n",
      "\n",
      "E\n",
      "E\n",
      "stion:What distasteful result is also produced by this sequence? How can iteasily be avoided?..The LEA Instruction (Although Not Really an Operate)Where to put the LEA instruction is a matter for debate (when you have nothingmore important to do!). It does not really operate on data, it simply loads a registerwith an address. It clearly does not move data from memory to a register, nor is itac o n t r o li n s t r u c t i o n .W eh a dt op u ti ts o m e w h e r e ,s ow ec h o s et od i s c u s si th e r e !LEA(opcode=1110) loads the register speciﬁed by bits [11:9] of theinstruction with the value formed by adding the incremented program counterto the sign-extended bits [8:0] of the instruction. We saw this method of con-structing an address in Chapter 4 with the LD instruction. However, in thiscase, the instruction does not access memory, it simply loads the computedaddress into a register. Perhaps a better name for this opcode would be CEA (forCompute Eﬀective Address). However, since many microprocessors in industrythat have this instruction in their ISAs call it LEA (for Load Eﬀective Address),we have chosen to use the same acronym.\n",
      "\n",
      "Figure.Data path relevant to the execution of LEA R,#−.We shall see shortly that the LEA instruction is useful to initialize a regis-15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0111010 1111111101LEA R5−3R5 will contain x4016 after the instruction at x4018 is executed. Question: Whywill R5 not contain the address x4015?Figure 5.6 shows the relevant parts of the data path required to execute theLEA instruction. Note that the value to be loaded into the register doesnotinvolveany access to memory. ...nor does it have any eﬀect on the condition codes..Data Movement InstructionsData movement instructions move information between the general purpose reg-isters and memory and between the registers and the input/output devices. We willignore for now the business of moving information from input devices to registersand from registers to output devices. This will be an important part of Chapter 9.In this chapter, we will conﬁne ourselves to moving information between memoryand the general purpose registers.\n",
      "\n",
      "The process of moving information from memory to a register is called aload,a n dt h ep r o c e s so fm o v i n gi n f o r m a t i o nf r o mar e g i s t e rt om e m o r yi sc a l l e dastore. In both cases, the information in the location containing the source operandremains unchanged. In both cases, the location of the destination operand is over-15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0opcodeDR or SRAddr Gen bitsData movement instructions require two operands, a source and a destination.The source is the data to be moved; the destination is the location where it ismoved to. One of these locations is a register, the other is a memory location oran input/output device. In this chapter we will assume the second operand is inmemory. In Chapter 9 we will study the cases where the second operand is aninput or output device.Bits [11:9] specify one of these operands, the register. If the instruction is aload,DRrefers to the destination general purpose register that will contain thevalue after it is read from memory (at the completion of the instruction cycle). Ifthe instruction is a store,SRrefers to the register that contains the value that willbe written to memory.Bits [8:0] contain theaddress generation bits.T h a ti s ,b i t s[ 8 : 0 ]c o n t a i ni n f o r -mation that is used to compute the 16-bit address of the second operand. In thecase of the LC-3’s data movement instructions, there are three ways to interpretbits [8:0]. They are collectively calledaddressing modes.T h eo p c o d es p e c i ﬁ e show to interpret bits [8:0]. That is, the LC-3’s opcode speciﬁes which of the threeaddressing modes should be used to obtain the address of the operand from bits[8:0] of the instruction...PC-Relative ModeLD(opcode=0010) andST(opcode=0011) specify thePC-relativeaddress-ing mode. We have already discussed this addressing mode in Chapter 4. It isso named because bits [8:0] of the instruction specify an oﬀset relative to thePC. The memory address is computed by sign-extending bits [8:0] to 16 bits andadding the result to the incremented PC. The incremented PC is the contents ofthe program counter after the FETCH phase, that is, after the PC has been incre-mented. If the instruction is LD, the computed address (PC + oﬀset) speciﬁes thememory location to be accessed. Its contents is loaded into the register speciﬁedby bits [11:9] of the instruction. If the instruction is ST, the contents of the regis-ter speciﬁed by bits [11:9] of the instruction is written into the memory locationwhose address is PC + oﬀset. ...and the N, Z, and P one-bit condition codes areset depending on whether the value loaded is negative, positive, or zero.\n",
      "\n",
      "15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0001001 0110101111LD R2 x1AFFigure 5.7 shows the relevant parts of the data path required to execute thisinstruction. The three steps of the LD instruction are identiﬁed. In step 1, theincremented PC (x4019) is added to the sign-extended value contained in IR [8:0](xFFAF), and the result (x3FC8) is loaded into the MAR. In step 2, memory isread and the contents of x3FC8 is loaded into the MDR. Suppose the value storedin x3FC8 is 5. In step 3, the value 5 is loaded into R2, and the NZP condition codesare set, completing the instruction cycle.Note that the address of the memory operand is limited to a small range ofthe total memory. That is, the address can only be within+256 or−255 locationsof the LD or ST instruction. This is the range provided by the sign-extended value\n",
      "Figure.Data path relevant to execution of LD R,xAF.\n",
      "\n",
      "..Indirect ModeLDI(opcode=1010) andSTI(opcode=1011) specify theindirectaddress-ing mode. An address is ﬁrst formed exactly the same way as with LD and ST.However, instead of this address being theaddress of the operandto be loadedor stored, it isthe addressof the address of the operand to be loaded or stored.Hence the nameindirect.N o t et h a tt h ea d d r e s so ft h eo p e r a n dc a nb ea n y w h e r e’LDI R3 x1CCis in x4A1B, and the contents of x49E8 is x2110, execution of this instructionresults in the contents of x2110 being loaded into R3.Figure 5.8 shows the relevant parts of the data path required to execute thisinstof aIR [is i\n",
      "Figure.Data path relevant to the execution of LDI R,xCC.\n",
      "\n",
      "contents of x2110 being loaded into R3. In step 3, since x2110 is not the operand,but the address of the operand, it is loaded into the MAR. In step 4, memory isagain read, and the MDR again loaded. This time the MDR is loaded with thecontents of x2110. Suppose the value−1 is stored in memory location x2110. Instep 5, the contents of the MDR (i.e.,−1) is loaded into R3 and the NZP conditioncodes are set, completing the instruction cycle...Base+oﬀset ModeLDR(opcode=0110) andSTR(opcode=0111) specify theBase+oﬀsetaddroperThe sspeciIwithinstrIR\n",
      "Figure.Data path relevant to the execution of LDR R,R,xD.\n",
      "\n",
      "contained in IR [5:0] (x001D), and the result (x2362) is loaded into the MAR.Second, memory is read, and the contents of x2362 is loaded into the MDR.Suppose the value stored in memory location x2362 is x0F0F. Third, and ﬁnally,the contents of the MDR (in this case, x0F0F) is loaded into R1 and the NZPcondition codes are set, completing the execution of the LDR instruction.Note that the Base+oﬀset addressing mode also allows the address of theoperand to be anywhere in the computer’s memory...An ExampleWe conclude our study of addressing modes with a comprehensive example.Assume the contents of memory locations x30F6 through x30FC are as shown inFigure 5.10, and the PC contains x30F6. We will examine the eﬀects of carryingout the seven instructions starting at location x30FC.Since the PC points initially to location x30F6, the ﬁrst instruction to beexecuted is the one stored in location x30F6. The opcode of that instruction is1110, load eﬀective address (LEA). LEA loads the register speciﬁed by bits [11:9]with the address formed by sign-extending bits [8:0] of the instruction and addingthe result to the incremented PC. The 16-bit value obtained by sign-extendingbits [8:0] of the instruction is xFFFD. The incremented PC is x30F7. Therefore,at the end of execution of the LEA instruction, R1 contains x30F4, and the PCcontains x30F7.Next, the instruction stored in location x30F7 is executed. Since the opcode0001 speciﬁes ADD, the sign-extended immediate in bits [4:0] (since bit [5] is1) is added to the contents of the register speciﬁed in bits [8:6], and the resultis written to the register speciﬁed by bits [11:9]. Since the previous instructionwrote x30F4 into R1, and the sign-extended immediate value is x000E, the sumis x3102. At the end of execution of this instruction, R2 contains x3102, and thePC contains x30F8. R1 still contains x30F4.Next, the instruction stored in x30F8. The opcode 0011 speciﬁes the STinstruction, which stores the contents of the register speciﬁed by bits [11:9](R2)addr(x3\n",
      "Figure.Ac o d ef r a g m e n ti l l u s t r a t i n gt h et h r e ea d d r e s s i n gm o d e s .\n",
      "\n",
      "(xFFFB). Therefore, at the end of execution of the ST instruction, memory loca-tion x30F4 (i.e., x30F9 + xFFFB) contains the value stored in R2 (x3102) andthe PC contains x30F9.Next the instruction at x30F9. The AND instruction, with an immediateoperand x0000. At the end of execution, R2 contains the value 0, and the PCcontains x30FA.At x30FA, the opcode 0001 speciﬁes the ADD instruction. After execution,R2 contains the value 5, and the PC contains x30FB.At x30FB, the opcode 0111 signiﬁes the STR instruction. STR (like LDR)uses the Base+oﬀset addressing mode. The memory address is obtained byadding the contents of the BASE register (speciﬁed by bits [8:6]) to the sign-extended oﬀset contained in bits [5:0]. In this case, bits [8:6] specify R1, whichcontains x30F4. The 16-bit sign-extended oﬀset is x000E. Since x30F4+x000Eis x3102, the memory address is x3102. The STR instruction stores into x3102the contents of the register speciﬁed by bits [11:9], in this case R2. Since R2 con-tains the value 5, at the end of execution of this instruction, M[x3102] containsthe value 5, and the PC contains x30FC.Finally the instruction at x30FC. The opcode 1010 speciﬁes LDI. LDI (likeSTI) uses the indirect addressing mode. The memory address is obtained by ﬁrstforming an address as is done in the PC-relative addressing mode. Bits [8:0] aresign-extended to 16 bits (xFFF7) and added to the incremented PC (x30FD).Their sum (x30F4) is theaddressof the operand address. Since M[x30F4] con-tains x3102, x3102 is the operand address. The LDI instruction loads the valuefound at this address (in this case 5) into the register identiﬁed by bits [11:9] ofthe instruction (in this case R3). At the end of execution of this instruction, R3contains the value 5 and the PC contains x30FD..Control InstructionsControl instructions change the sequence of instructions to be executed. If therewere no control instructions, the next instruction fetched after the current instruc-tion ﬁnishes would always be the instruction located in the next sequentialmemory location. As you know, this is because the PC is incremented in theFETCH phase of each instruction cycle. We have already seen in the program ofSection 4.4 that it is often useful to be able to break that sequence.The LC-3 has ﬁve opcodes that enable the sequential execution ﬂow tobe broken: conditional branch, unconditional jump, subroutine call (sometimescalledfunction), TRAP, and RTI (Return from Trap or Interrupt). In this sec-tion, we will deal almost entirely with the most common control instruction, theconditional branch.W ew i l la l s od i s c u s st h eu n c o n d i t i o n a lj u m pa n dt h eT R A Pinstruction. The TRAP instruction, often calledservice call,i su s e f u lb e c a u s eit allows a programmer to get help from the operating system to do things thatthe typical programmer does not fully understand how to do. Typical examples:getting information into the computer from input devices, displaying informationto output devices, and stopping the computer. The TRAP instruction breaks the\n",
      "\n",
      "sequential execution of a user program to start a sequence of instructions in theoperating system. How the TRAP instruction does this, and in fact, most of thediscussion of the TRAP instruction and all of the discussion of the subroutinecall and the return from interrupt we will leave for Chapters 8 and 9...Conditional BranchesOf the ﬁve instructions which change the execution ﬂow from the next sequentialinstruction to an instruction located someplace else in the program, only one ofthem decides each time it is executed whether to execute the next instruction insequence or whether to execute an instruction from outside that sequence. Theinstruction that makes that decision each time it is executed is the conditionalbranch instructionBR(opcode = 0000).Like all instructions in the LC-3, the PC is incremented during the FETCHphase of its instruction cycle. Based on the execution of previous instructions inthe program, the conditional branch’s EXECUTE phase either does nothing or itloads the PC with the address of the instruction it wishes to execute next. If theconditional branch instruction does nothing during the EXECUTE phase, thenthe incremented PC will remain unchanged, and the next instruction executedwill beThchangereﬂectTh15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 00000nzpPCoﬀsetBits [11], [10], and [9] are associated with the three condition codes, N, Z, and P.As you know, the three operate instructions (ADD, AND, and NOT) andthe three load instructions (LD, LDI, and LDR) in the LC-3 write values intogeneral purpose registers, and also set the three condition codes in accordancewith whether the value written is negative, zero, or positive.The conditional branch instruction uses that information to determinewhether or not to depart from the usual sequential execution of instructions thatwe get as a result of incrementing the PC during the FETCH phase of eachinstruction.We said (without explanation) in the computer program we studied inSection 4.4 that if bits [11:9] of the conditional branch instruction are 101, wewill depart from the usual sequential execution if the last value written into a reg-ister by one of the six instructions listed above is not 0. We are now ready to seeexactly what causes that to happen.During the EXECUTE phase of the BR instruction cycle, the processorexamines the condition codes whose associated bits in the instruction, bits [11:9],are 1. Note the lower casen,z,a n dpin bits [11:9] of the BR instruction for-mat shown above. If bit [11] is 1, condition code N is examined. If bit [10] is 1,\n",
      "\n",
      "condition code Z is examined. If bit [9] is 1, condition code P is examined. If anyof bits [11:9] are 0, the associated condition codes are not examined. If any of thecondition codes that are examined are set (i.e., equal to 1), then the PC is loadedwith the address obtained in the EVALUATE ADDRESS phase. If none of thecondition codes that are examined are set, the incremented PC is left unchanged,and the next sequential instruction will be fetched at the start of the nextinstruction cycle.The address obtained during the EVALUATE ADDRESS phase of theinstruction cycle is generated using the PC-relative addressing mode.In our example in Section 4.4, the ADD instruction in memory locationx3004 subtracted 1 from R2, wrote the result to R2, and set the condition codes.The BR instruction in memory location x3005 shows bits [11:9] = 101. Since bit[11] is 1, if the N bit is set, the result of the ADD must have been negative. Sincebit [9] is also 1, if the P bit is set, the result must have been positive. Since bit[10] is 0, we do not examine the Z bit. Thus if the previous result is positive ornegative (i.e., not 0), the PC is loaded with x3003, the address calculated in theEVALUATE ADDRESS phase of the branch instruction.Recall that the program of Figure 4.7 used R2 to keep track of the numberof times the number 5 was added to R3. As long as we were not done with allour additions, the result of subtracting 1 from R2 was not zero. When we weredone with our additions, subtracting 1 from R2 produced the result 0, so Z wasset to 1, N and P were set to 0. At that point, bits [11:9] checked the N and Pcondition codes which were 0, so the incremented PC was not changed, and theinstruction at location x3006, a trap to the operating system to halt the computer,was executed next.Let’s Loat x4027,15000001 0011011001BR n z p x0D9Figure 5.11 shows the data path elements that are required to execute thisinstruction. Note the logic required to determine whether the sequential instruc-tion ﬂow should be broken. Each of the three AND gates corresponds to one ofthe three condition codes. The output of the AND gate is 1 if the correspondingcondition code is 1 and if the associated bit in the instruction directs the hardwareto check that condition code. If any of the three AND gates have an output 1, theOR gate has an output 1, indicating that the sequential instruction ﬂow shouldbe broken, and the PC should be loaded with the address evaluated during theEVALUATE ADDRESS phase of the instruction cycle.In the case of the conditional branch instruction at x4027, the answer is yes,and the PC is loaded with x4101, replacing x4028, which had been loaded intothe PC during the FETCH phase of the BR instruction.\n",
      "\n",
      "\n",
      "Yes!Figure.Data path relevant to the execution of BRz xD.Another Example.If all three bits [11:9] are 1, then all three condition codesare examined. In this case, since the last result stored into a register had to beeither negative, zero, or positive (there are no other choices!), one of the three\n",
      "Question:What happens if all three bits [11:9] in the BR instruction are 0?\n",
      "\n",
      "..Two Methods of Loop ControlWe saw in Section 4.4 in our multiplication program that we repeatedly executedas e q u e n c eo fi n s t r u c t i o n su n t i lt h ev a l u ei nar e g i s t e rw a sz e r o .W ec a l lt h a tsequence aloop body,a n de a c ht i m et h el o o pb o d yi se x e c u t e dw ec a l li to n eiterationof the loop body. The BR instruction at the end of the sequence controlsthe number of times the loop body is executed. There are two common ways tocontrol the number of iterations.\n",
      "Figure.An algorithm for adding integers using a counter for loop control.First, as in all algorithms, we mustinitialize our variables.T h a ti s ,w em u s tset up the initial values of the variables that the computer will use in executing theprogram that solves the problem. There are three such variables: the address ofthe next integer to be added (assigned to R1), the running sum (assigned to R3),and the number of integers left to be added (assigned to R2). The three variablesare initialized as follows: The address of the ﬁrst integer to be added is put in R1.R3, which will keep track of the running sum, is initialized to 0. R2, which willkeep track of the number of integers left to be added, is initialized to 12. Thenthe process of adding begins.The program repeats the process of loading into R4 one of the 12 integersand adding it to R3. Each time we perform the ADD, we increment R1 so it willpoint to (i.e., contain the address of) the next number to be added and decrementR2 so we will know how many numbers still need to be added. When R2 becomeszero, the Z condition code is set, and we can detect that we are done.The 10-instruction program shown in Figure 5.13 accomplishes the task.The details of the program execution are as follows: The program startswith PC=x3000. The ﬁrst instruction (at location x3000) initializes R1 with\n",
      "\n",
      "\n",
      "x3009000011 1111111010BRnzp x3004Figure.Ap r o g r a mt h a ti m p l e m e n t st h ea l g o r i t h mo fF i g u r e..the address x3100. (The incremented PC is x3001; the sign-extended PCoﬀset isx00FF.)The instruction at x3001 clears R3. R3 will keep track of the running sum,so it must start with the value 0. As we said previously, this is calledinitializingthe SUM to zero.The instructions at x3002 and x3003 initialize R2 to 12, the number of inte-gers to be added. R2 will keep track of how many numbers have already beenadded. This will be done (by the instruction in x3008) by decrementing R2 aftereach addition takes place.The instruction at x3004 is a conditional branch instruction. Note that bit[10] is a 1. That means that the Z condition code will be examined. If it is set, weknow R2 must have just been decremented to 0. That means there are no morenumbers to be added, and we are done. If it is clear, we know we still have workto do, and we continue with another iteration of the loop body.The instruction at x3005 loads the next integer into R4, and the instructionat x3006 adds it to R3.The instructions at x3007 and x3008 perform the necessary bookkeeping.The instruction at x3007 increments R1, so R1 will point to the next location inmemory containing an integer to be added. The instruction at x3008 decrementsR2, which is keeping track of the number of integers still to be added, and setsthe condition codes.The instruction at x3009 is an unconditional branch, since bits [11:9] are all 1.It loads the PC with x3004. It also does not aﬀect the condition codes, so the nextinstruction to be executed (the conditional branch at x3004) will be based on theinstruction executed at x3008.This is worth saying again. The conditional branch instruction at x3004 fol-lows the instruction at x3009, which does not aﬀect condition codes, which inturn follows the instruction at x3008. Thus, the conditional branch instructionat x3004 will be based on the condition codes set by the instruction at x3008.The instruction at x3008 sets the condition codes based on the value producedby decrementing R2. As long as there are still integers to be added, the ADDinstruction at x3008 will produce a value greater than zero and therefore clearthe Z condition code. The conditional branch instruction at x3004 examines the\n",
      "\n",
      "Zc o n d i t i o nc o d e .A sl o n ga sZi sc l e a r ,t h eP Cw i l ln o tb eaﬀected, and the nextiteration of the loop body will begin. That is, the next instruction cycle will startwith an instruction fetch from x3005.The conditional branch instruction causes the execution sequence to follow:x3000, x3001, x3002, x3003, x3004, x3005, x3006, x3007, x3008, x3009, x3004,x3005, x3006, x3007, x3008, x3009, x3004, x3005, and so on. The loop body consistsof the instructions at x3005 to x3009. When the value in R2 becomes 0, the PC isloaded with x300A, and the program continues at x300A with its next activity.You may have noticed that we can remove the branch instruction at x3004if we replace the unconditional branch instruction at x3009 with a conditionalbranch that tests for not 0 (i.e., bits [11:9]=101), and branches to the instruc-tion currently located in x3005. It is tempting to do that since it decreases theloop body by one instruction. BUT, we admonish you not to do that! The pro-gram as shown obeys the rules of structured programming that we will discussin Chapter 6. The shortcut does work for this simple example, but it breaks themethodology of structured programming. You do not want to get in the habit oftaking such shortcuts, since for larger programs it is a clear invitation to disaster.More on this in Chapter 6.Finally, it is worth noting that we could have written a program to add these12 integerswithoutany control instructions. We still would have needed the LEAinstruction in x3000 to initialize R1. We would not have needed the instructionat x3001 to initialize the running sum, nor the instructions at x3002 and x3003to initialize the number of integers left to be added. We could have loaded thecontents of x3100 directly into R3, and then repeatedly (by incrementing R1),loaded subsequent integers into R4 and adding R4 to the running sum in R3 11more times! After the addition of the twelfth integer, we would go on to the nexttask, as does the example of Figure 5.13 with the branch instruction in x3004.Unfortunately, instead of a 10-instruction program, we would have a 35-instruction program. Moreover, if we had wished to add 100 integers without anycontrol instructions instead of 12, we would have had a 299-instruction programinstead of 10. The control instructions in the example of Figure 5.13 permit thereuse of sequences of code (the loop body) by breaking the sequential instructionexecution ﬂow.Loop Control with a SentinelThe example above controls the number of timesthe loop body executes by means of a counter. We knew we wanted to execute theloop 12 times, so we simply set a counter to 12, and then after each execution ofthe loop, we decremented the counter and checked to see if it was zero. If it wasnot zero, we set the PC to the start of the loop and continued with another iteration.A second method for controlling the number of executions of a loop is to useasentinel.T h i sm e t h o di sp a r t i c u l a r l yeﬀective if we do not know ahead of timehow many iterations we will want to perform. Each iteration is usually based onprocessing a value. We append to our sequence of values to be processed a valuethat we know ahead of time can never occur (i.e., the sentinel). For example, ifwe are adding a sequence of numbers, a sentinel could be a letter A or a *, that is,something that is not a number. Our loop test is simply a test for the occurrenceof the sentinel. When we ﬁnd it, we know we are done.\n",
      "\n",
      "\n",
      "xnzp xFigure.A program that implements the algorithm of Figure..Suppose we know the values stored in locations x3100 to x310B are all pos-itive. Then we could use any negative number as a sentinel. Let’s say the sentinelstored at memory address x310C is−1. The resulting ﬂowchart for this solutionis shown in Figure 5.14, and the resulting program is shown in Figure 5.15.As before, the instruction at x3000 loads R1 with the address of the ﬁrst valueto be added, and the instruction at x3001 initializes R3 (which keeps track of thesum) to 0.At x3002, we load the contents of the next memory location into R4. If thesentinel is loaded, the N condition code is set.The conditional branch at x3003 examines the N condition code. If N=1, PCis loaded with x3008 and onto the next task. If N=0, R4 must contain a validnumber to be added. In this case, the number is added to R3 (x3004), R1 isincremented to point to the next memory location (x3005), R4 is loaded withthe contents of the next memory location (x3006), and the PC is loaded withx3003 to begin the next iteration (x3007).\n",
      "\n",
      "..The JMP InstructionThe conditional branch instruction, for all its capability, does have one unfor-tunate limitation. The next instruction executed must be within the range ofaddresses that can be computed by adding the incremented PC to the sign-extended oﬀset obtained from bits [8:0] of the instruction. Since bits [8:0] specifya2 ’ sc o m p l e m e n ti n t e g e r ,t h en e x ti n s t r u c t i o ne x e c u t e da f t e rt h ec o n d i t i o n a lbranch can be at most+256 or−255 locations from the branch instruction itself.What if we would like to execute next an instruction that is 2000 locationsfrom the current instruction? We cannot ﬁt the value 2000 into the nine-bit ﬁeld;ergo, the conditional branch instruction does not work.The LC-3 ISA does provide an instructionJMP(opcode=1100) that can dothe job.ﬁedaddr110000 0010000000JMP BaseRR2 contains the value x6600, and the PC contains x4000, then the instruction atx4000 (the JMP instruction) will be executed, followed by the instruction locatedat x6600. Since registers contain 16 bits (the full address space of memory), theJMP instruction has no limitation on where the next instruction to be executedmust reside...The TRAP InstructionWe will discuss the details of how the TRAP instruction works in Chapter 9.However, because it will be useful long before that to get data into and out of thecomputer, we discuss the TRAP instruction here. TheTRAP(opcode=1111)instruction changes the PC to a memory address that is part of the operatingsystem so that the operating system will perform some task on behalf of theprogram that is executing. In the language of operating system jargon, we saythe TRAP instruction invokes an operating systemservice call.B i t s[ 7 : 0 ]o ft h eTRAP instruction form thetra vectoran ei ht-bit code that identiﬁes the ser-vice calTablethe LC-15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0111100 0 0trapvectorOnce the operating system is ﬁnished performing the service call, the pro-gram counter is set to the address of the instruction following the TRAP instruc-tion, and the program continues. In this way, a program can, during its execution,\n",
      "\n",
      "request services from the operating system and continue processing after eachsuch service is performed. The services we will require for now are*I n p u tac h a r a c t e rf r o mt h ek e y b o a r d( t r a p v e c t o r=x 2 3 ) .*O u t p u tac h a r a c t e rt ot h em o n i t o r( t r a p v e c t o r=x 2 1 ) .*H a l tt h ep r o g r a m( t r a p v e c t o r=x 2 5 ) ..Another Example: CountingOccurrences of a CharacterWe will ﬁnish our introduction to the ISA of the LC-3 with another exampleprogram. Suppose we would like to be able to input a character from the keyboard,then count the number of occurrences of that character in a ﬁle, and ﬁnally displaythat count on the monitor. We will simplify the problem by assuming that thenumber of occurrences of any character that we would be interested in is smallenough that it can be expressed with a single decimal digit. That is, there will beat most nine occurrences. This simpliﬁcation allows us to not have to worry aboutcomplex conversion routines between the binary count and the ASCII display onthe monitor—a subject we will get into in Chapter 10, but not today.Figure 5.16 is a ﬂowchart of the algorithm that solves this problem. Notethat each step is expressed both in English and also (in parentheses) in terms ofan LC-3 implementation.The ﬁrst step is (as always) to initialize all the variables. This means pro-viding starting values (calledinitial values)f o rR 0 ,R 1 ,R 2 ,a n dR 3 ,t h ef o u rregisters the computer will use to execute the program that will solve the prob-lem. R2 will keep track of the number of occurrences; in Figure 5.16, it is referredto asCount. It is initialized to zero. R3 will point to the next character in the ﬁlethat is being examined. We refer to it as apointersince it points to (i.e., containstheaddressof) the location where the next character of the ﬁle that we wish toexamine resides. The pointer is initialized with the address of theﬁrstcharacterin the ﬁle. R0 will hold the character that is being counted; we will input thatcharacter from the keyboard and put it in R0. R1 will hold, in turn, each characterthat we get from the ﬁle being examined.We should also note that there is no requirement that the ﬁle we are examiningbe close to or far away from the program we are developing. For example, it isperfectly reasonable for the program we are developing to start at x3000 and theﬁle we are examining to start at x9000. If that were the case, in the initializationprocess, R3 would be initialized to x9000.The next step is to count the number of occurrences of the input character.This is done by processing, in turn, each character in the ﬁle being examined, untilthe ﬁle is exhausted. Processing each character requires one iteration of a loop.Recall from Section 5.4.3 that there are two common methods for keeping trackof iterations of a loop. We will use the sentinel method, using the ASCII code forEOT (End of Transmission) (00000100) as the sentinel. A table of ASCII codesis in Appendix E.\n",
      "\n",
      "\n",
      "x3013000000 0 0 0 0 1 1 0 0 0 0ASCII TEMPLATEFigure.Am a c h i n el a n g u a g ep r o g r a mt h a ti m p l e m e n t st h ea l g o r i t h mo fF i g u r e..In each iteration of the loop, the contents of R1 is ﬁrst compared to the ASCIIcode for EOT. If they are equal, the loop is exited, and the program moves on tothe ﬁnal step, displaying on the screen the number of occurrences. If not, there iswork to do. R1 (the current character under examination) is compared to R0 (thecharacter input from the keyboard). If they match, R2 is incremented. In eithercase, we move on to getting the next character. The pointer R3 is incremented, thenext character is loaded into R1, and the program returns to the test that checksfor the sentinel at the end of the ﬁle.When the end of the file is reached, all the characters have been examined, andthe count is contained as a binary number in R2. In order to display the count on themonitor, it is first converted to an ASCII code. Since we have assumed the countis less than 10, we can do this by putting a leading 0011 in front of the four-bitbinary representation of the count. Note in Figure E.2 the relationship between thebinary value of each decimal digit between 0 and 9 and its corresponding ASCII code.Finally, the count is output to the monitor, and the program terminates.Figure 5.17 is a machine language program that implements the ﬂowchart ofFigure 5.16.First the initialization steps. The instruction at x3000 clears R2 by ANDingit with x0000. The instruction at x3001 loads the starting address of the ﬁle to beexamined into R3. Again, we note that this ﬁle can be anywhere in memory. Priorto starting execution at x3000, some sequence of instructions must have stored theﬁrst address of this ﬁle in x3012. Location x3002 contains the TRAP instruction,\n",
      "\n",
      "which requests the operating system to perform a service call on behalf of this pro-gram. The function requested, as identiﬁed by the eight-bit trapvector 00100011(i.e., x23), is to load into R0 the ASCII code of the next character typed on thekeyboard. Table A.2 lists trapvectors for all operating system service calls thatcan be performed on behalf of a user program. The instruction at x3003 loads thecharacter pointed to by R3 into R1.Then the process of examining characters begins. We start (x3004) by sub-tracting 4 (the ASCII code for EOT) from R1 and storing it in R4. If the resultis zero, the end of the ﬁle has been reached, and it is time to output the count.The instruction at x3005 conditionally branches to x300E, where the process ofoutputting the count begins.If R4 is not equal to zero, the character in R1 is legitimate and must beexamined. The sequence of instructions at locations x3006, x3007, and x3008determines whether the contents of R1 and R0 are identical. Taken together, thethree instructions computeR0−R1This produces all zeros only if the bit patterns of R1 and R0 are identical. If thebit patterns are not identical, the conditional branch at x3009 branches to x300B;that is, it skips the instruction at x300A, which increments the counter (R2).The instruction at x300B increments R3, so it will point to the next charac-ter in the ﬁle being examined, the instruction at x300C loads that character intoR1, and the instruction at x300D unconditionally takes us back to x3004 to startprocessing that character.When the sentinel (EOT) is ﬁnally detected, the process of outputting thecount begins (at x300E). The instruction at x300E loads 00110000 into R0, andthe instruction at x300F adds the count to R0. This converts the binary represen-tation of the count (in R2) to the ASCII representation of the count (in R0). Theinstruction at x3010 invokes a TRAP to the operating system to output the con-tents of R0 to the monitor. When that is done and the program resumes execution,the instruction at x3011 invokes a TRAP instruction to terminate the program.Question: Can you improve the execution of the above program?Hint:Howmany times are the instructions at x3006 and x3007 executed. What small changewill decrease the total number of instructions that have to be executed..The Data Path RevisitedBefore we leave Chapter 5, let us revisit the data path diagram that we ﬁrstencountered in Chapter 3 (Figure 3.35). Many of the structures we have seenearlier in this chapter in Figures 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, and 5.11. We repro-duce the data path diagram as Figure 5.18. Note at the outset that there are twokinds of arrows in the data path, those with arrowheads ﬁlled in and those witharrowheads not ﬁlled in. Filled-in arrowheads designate information that is pro-cessed. Unﬁlled-in arrowheads designate control signals. Control signals emanatefrom the block labeled “Finite State Machine.” The connections from the ﬁnitestate machine to most control signals have been left oﬀFigure 5.18 to reduceunnecessary clutter in the diagram.\n",
      "\n",
      "..Basic Components of the Data Path...The Global BusThe most obvious item on the data path diagram is the heavy black structurewith arrowheads at both ends. This represents the data path’s global bus. TheLC-3 global bus consists of 16 wires and associated electronics. It allows onestructure to transfer up to 16 bits of information to another structure by making thenecessary electronic connections on the bus. Exactly one value can be transferredon the bus at one time. Note that each structure that supplies values to the bushas a triangle just behind its input arrow to the bus. This triangle (called atri-state device)a l l o w st h ec o m p u t e r ’ sc o n t r o ll o g i ct oe n a b l ee x a c t l yo n es u p p l i e rt oprovide information to the bus at any one time. The structure wishing to obtain thevalue being supplied can do so by asserting its LD.x (load enable) signal (recallour discussion of gated latches in Section 3.4.2). Not all computers have a singleglobal bus. The pros and cons of a single global bus is yet another topic that willhave to wait for later in your education....MemoryOne of the most important parts of any computer is the memory that containsboth instructions and data. Memory is accessed by loading the memory addressregister (MAR) with the address of the location to be accessed. To perform a load,control signals then read the contents of that memory location, and the result ofthat read is delivered by the memory to the memory data register (MDR). On theother hand, to perform a store, what is to be stored is loaded into the MDR. Thenthe control signals assert a write enable (WE) signal in order to store the valuecontained in MDR in the memory location speciﬁed by MAR....The ALU and the Register FileThe ALU is the processing element. It has two inputs, source 1 from a register andsource 2 from either a register or the sign-extended immediate value provided bythe instruction. The registers (R0 through R7) can provide two values: source 1,which is controlled by the three-bit register number SR1, and source 2, which iscontrolled by the three-bit register number SR2. SR1 and SR2 are ﬁelds in theLC-3 operate instructions. The selection of a second register operand or a sign-extended immediate operand is determined by bit [5] of the LC-3 instruction.Note the mux that provides source 2 to the ALU. The select line of that mux isbit [5] of the LC-3 operate instruction.The results of an ALU operation are (a) a result that is stored in one of theregisters, and (b) the three single-bit condition codes. Note that the ALU can supply16 bits to the bus, and that value can then be written into the register specified by thethree-bit register number DR. Also, note that the 16 bits supplied to the bus are alsoinput to logic that determines whether that 16-bit value is negative, zero, or positive.The three one-bit condition code registers N, Z, and P are set accordingly....The PC and the PCMUXAt the start of each instruction cycle, the PC supplies to the MAR over theglobal bus the address of the instruction to be fetched. In addition, the PC, inturn, is supplied via the three-to-one PCMUX. During the FETCH phase of the\n",
      "\n",
      "instruction cycle, the PC is incremented and written into the PC. That is shownas the rightmost input to the PCMUX.If the current instruction is a control instruction, then the relevant source ofthe PCMUX depends on which control instruction is currently being processed.If the current instruction is a conditional branch and the branch is taken, then thePC is loaded with the incremented PC+PCoﬀset (the 16-bit value obtained bysign-extending IR [8:0]). Note that this addition takes place in the special adderand not in the ALU. The output of the adder is the middle input to PCMUX. Thethird input to PCMUX is obtained from the global bus. Its use will become clearafter we discuss other control instructions in Chapters 9....The MARMUXAs you know, memory is accessed by supplying the address to the MAR. TheMARMUX controls which of two sources will supply the MAR with the appro-priate address during the execution of a load, a store, or a TRAP instruction. Theright input to the MARMUX is obtained by adding either the incremented PC ora base register to zero or a literal value supplied by the IR. Whether the PC or abase register and what literal value depends on which opcode is being processed.The control signal ADDR1MUX speciﬁes the PC or base register. The controlsignal ADDR2MUX speciﬁes which of four values is to be added. The left inputto MARMUX provides the zero-extended trapvector, which is needed to invokeservice calls, and will be discussed in detail in Chapter 9...The Instruction Cycle Speciﬁc to the LC-We coinstructlocatio15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0011001 1010000100LDR R3 R2 4Suppose the LC-3 has just completed processing the instruction at x3455, whichhappened to be an ADD instruction....FETCHAs you know, the instruction cycle starts with the FETCH phase. That is, theinstruction is obtained by accessing memory with the address contained in the PC.In the ﬁrst cycle, the contents of the PC is loaded via the global bus into the MAR,and the PC is incremented and loaded into the PC. At the end of this cycle, thePC contains x3457. In the next cycle (if memory can provide information in onecycle), the memory is read, and the instruction 0110011010000100 is loaded intothe MDR. In the next cycle, the contents of the MDR is loaded into the instructionregister (IR), completing the FETCH phase....DECODEIn the next cycle, the contents of the IR is decoded, resulting in the controllogic providing the correct control signals (unﬁlled arrowheads) to control the\n",
      "\n",
      "...OPERAND FETCHIn the next cycle (or more than one, if memory access takes more than one cycle),the value at that address is loaded into the MDR....EXECUTEThe LDR instruction does not require an EXECUTE phase, so this phase takeszero cycles.\n",
      "....same way as in the LC-3.\n",
      "\n",
      "rammingWea r en o wr e a d yt od e v e l o pp r o g r a m st os o l v ep r o b l e m sw i t ht h ec o m -puter. In this chapter we attempt to do two things: ﬁrst, we develop amethodology for constructing programs to solve problems (Section 6.1, ProblemSolving), and second, we develop a methodology for ﬁxing those programs (Sec-tion 6.2, Debugging) under the likely condition that we did not get everythingright the ﬁrst time.There is a long tradition that the errors present in programs are referred to asbugs,a n dt h ep r o c e s so fr e m o v i n gt h o s ee r r o r si sc a l l e ddebugging. The opportu-nities for introducing bugs into a complicated program are so great that it usuallytakes much more time to get the program to work correctly (debugging) than itdoes to create the program in the ﬁrst place..Problem Solving..Systematic DecompositionRecall from Chapter 1 that in order for electrons to solve a problem, we need to gothrough several levels of transformation to get from a natural language descriptionof the problem (in our case English, although many of you might prefer Italian,Mandarin, Hindi, or something else) to something electrons can deal with. Oncewe have a natural language description of the problem, the next step is to trans-form the problem statement into an algorithm. That is, the next step is to transformthe problem statement into a step-by-step procedure that has the properties of def-initeness (each step is precisely stated), eﬀective computability (each step can becarried out by a computer), and ﬁniteness (the procedure terminates).In the late 1960s, the concept ofstructured programmingemerged as a wayto dramatically improve the ability of average programmers to take a complexdescription of a problem and systematically decompose it into smaller and smallermanageable units so that they could ultimately write a program that executed cor-rectly. The methodology has also been calledsystematic decompositionbecausethe larger tasks are systematically broken down into smaller ones.\n",
      "\n",
      "We will ﬁnd the systematic decomposition model a useful technique fordesigning computer programs to carry out complex tasks...The Three Constructs: Sequential, Conditional, IterativeSystematic decomposition is the process of taking a task, that is, a unit of work(see Figure 6.1a), and breaking it into smaller units of work such that the collec-tion of smaller units carries out the same task as the one larger unit. The idea isthat if one starts with a large, complex task and applies this process again andagain, one will end up with very small units of work and consequently be able toeasily write a program to carry out each of these small units of work. The processis also referred to asstepwise reﬁnement,because the process is applied one stepat a time, and each step reﬁnes one of the tasks that is still too complex into acollection of simpler subtasks.The idea is to replace each larger unit of work with a construct that correctlydecomposes it. There are basically three constructs for doing this:sequential,conditional,anditerative.Thesequentialconstruct (Figure 6.1b) is the one to use if the designatedtask can be broken down into two subtasks, one following the other. That is, thecomputer is to carry out the ﬁrst subtask completely,thengo on and carry out thesecond subtask completely—nevergoing back to the ﬁrst subtask after starting\n",
      "Figure.The basic constructs of structured programming.\n",
      "\n",
      "condition is true, the computer is to carry out one subtask. If the condition is not true,the computer is to carry out a different subtask. Either subtask may be vacuous; thatis, it maydo nothing.R e g a r d l e s s ,a f t e rt h ec o r r e c ts u b t a s ki sc o m p l e t e d ,t h ep r o g r a mmoves onward. The program never goes back and retests the condition.Theiterativeconstruct (Figure 6.1d) is the one to use if the task consists ofdoing a subtask a number of times, but only as long as some condition is true. Ifthe condition is true, do the subtask. After the subtask is ﬁnished, go back andtest the condition again. As long as the result of the condition tested is true, theprogram continues to carry out the same subtask again and again. The ﬁrst timethe test is not true, the program proceeds onward.Note in Figure 6.1 that whatever the task of Figure 6.1a, work starts with thearrow into the top of the ‘‘box’’ representing the task and finishes with the arrow outof the bottom of the box. There is no mention of what goes oninsidethe box. In eachof the three possible decompositions of Figure 6.1a (i.e., Figure 6.1b, c, and d), thereis exactlyone entrance into the constructand exactlyone exit out of the construct.Thus, it is easy to replace any task of the form of Figure 6.1a with whichever of itsthree decompositions apply. We will see how with several examples...LC-Control Instructions to Implement\n",
      "Figure.Use of LC-control instructions to implement structured programming.\n",
      "\n",
      "decomposition constructs. That is, Figure 6.2b, c, and d corresponds respectivelyto the three constructs shown in Figure 6.1b, c, and d.We use the letters A, B, C, and D to represent addresses in memory containingLC-3 instructions. The letter A, for example, represents the address of the ﬁrstLC-3 instruction to be executed in all three cases, since it is the starting addressof the task to be decomposed (shown in Figure 6.2a).Figure 6.2b illustrates the control ﬂow of the sequential decomposition. Notethat no control instructions are needed since the PC is incremented from AddressB1to Address B1+1. The program continues to execute instructions throughaddress D1. It does not return to the ﬁrst subtask.Figure 6.2c illustrates the control ﬂow of the conditional decomposition.First, a condition is generated, resulting in the setting of one of the conditioncodes. This condition is tested by the conditional branch instruction at AddressB2. If the condition is true, the PC is set to Address C2+1, and subtask 1 isexecuted. (Note: xequals 1 + the number of instructions in subtask 2.) If thecondition is false, the PC (which had been incremented during the FETCH phaseof the branch instruction) fetches the instruction at Address B2+1, and subtask2i se x e c u t e d .S u b t a s k2t e r m i n a t e si nab r a n c hi n s t r u c t i o nt h a ta ta d d r e s sC2unconditionally branches to D2+1. (Note: yequals the number of instructions insubtask 1.)Figure 6.2d illustrates the control ﬂow of the iterative decomposition. Asin the case of the conditional construct, ﬁrst a condition is generated, a condi-tion code is set, and a conditional branch instruction is executed. In this case,the condition bits of the instruction at address B3are set to cause a conditionalbranch if the condition generated is false. If the condition is false, the PC is setto address D3+1. (Note: zequals 1 + the number of instructions in the subtaskin Figure 6.2d.) On the other hand, as long as the condition is true, the PC willbe incremented to B3+1, and the subtask will be executed. The subtask termi-nates in an unconditional branch instruction at address D3,w h i c hs e t st h eP Ct oAt oa g a i ng e n e r a t ea n dt e s tt h ec o n d i t i o n .(Note: wequals the total number ofinstructions in the decomposition shown as Figure 6.2d.)Now, we are ready to move on to an example...The Character Count Example from Chapter, RevisitedRecall the example of Section 5.5. The statement of the problem is as follows:“We wish to input a character from the keyboard, count the number of occurrencesof that character in a ﬁle, and display that count on the monitor.”The systematic decomposition of this English language statement of theproblem to the ﬁnal LC-3 implementation is shown in Figure 6.3. Figure 6.3ais a brief statement of the problem.In order to solve the problem, it is always a good idea ﬁrst to examine exactlywhat is being asked for, and what is available to help solve the problem. In thiscase, the statement of the problem says that we will get the character of inter-est from the keyboard, and that we must examine all the characters in a ﬁle anddetermine how many are identical to the character obtained from the keyboard.Finally, we must output the result.\n",
      "\n",
      "Figure.Stepwise reﬁnement of the character count program (Fig..continued onnext page.)To do this, we will need to examine in turn all the characters in a ﬁle, we willneed to compare each to the character we input from the keyboard, and we willneed a counter to increment each time we get a match.We will need registers to hold all these pieces of information:1. The character input from the keyboard.2. Where we are (a pointer) in our scan of the ﬁle.3. The character in the ﬁle that is currently being examined.4. The count of the number of occurrences.We will also need to know when we have reached the end of the ﬁle.\n",
      "\n",
      "\n",
      "Figure.Stepwise reﬁnement of the character count program (Fig..continued onnext page.)The problem decomposes naturally (using the sequential construct) into threeparts as shown in Figure 6.3b: (A) initialization, which includes keyboard inputof the character to be “counted,” (B) the process of determining how many occur-rences of the character are present in the ﬁle, and (C) displaying the count on themonitor.We have seen the importance of proper initialization in several examplesalready. Before a computer program can get to the crux of the problem, it musthave the correct initial values. These initial values do not just show up in the GPRsby magic. They get there as a result of the ﬁrst set of steps in every algorithm: theinitialization of its variables.In this particular algorithm, initialization (as we said in Chapter 5) consistsof starting the counter at 0, setting the pointer to the address of the ﬁrst characterin the ﬁle to be examined, getting an input character from the keyboard, and get-ting the ﬁrst character from the ﬁle. Collectively, these four steps comprise theinitialization of the algorithm shown in Figure 6.3b as A.\n",
      "\n",
      "Figure.Stepwise reﬁnement of the character count program (continued Fig..from previous page.)Figure 6.3c decomposes B into an iteration construct, such that as long asthere are characters in the ﬁle to examine, the loop iterates. B1 shows what getsaccomplished in each iteration. The character is tested and the count incrementedif there is a match. Then the next character is prepared for examination. Recallfrom Chapter 5 that there are two basic techniques for controlling the number\n",
      "\n",
      "of iterations of a loop: the sentinel method and the use of a counter. Since weare unlikely to know how many characters there are in a random ﬁle, and sinceeach ﬁle ends with an end of text (EOT) character, our choice is obvious. We usethe sentinel method, that is, testing each character to see if we are examining acharacter in the ﬁle or the EOT character.Figure 6.3c also shows the initialization step in greater detail. Four LC-3registers (R0, R1, R2, and R3) have been speciﬁed to handle the four requirementsof the algorithm: the input character from the keyboard, the current characterbeing tested, the counter, and the pointer to the next character to be tested.Figure 6.3d decomposes both B1 and C using the sequential construct in bothcases. In the case of B1, ﬁrst the current character is tested (B2), and the counterincremented if we have a match, and then the next character is fetched (B3). Inthe case of C, ﬁrst the count is prepared for display by converting it from a 2’scomplement integer to an ASCII code (C1), and then the actual character outputis performed (C2).\n",
      ".DebuggingDebugging a program is pretty much applied common sense. A simple examplecomes to mind: You are driving to a place you have never visited, and somewherealong the way you made a wrong turn. What do you do now? One common “driv-ing debugging” technique is to wander aimlessly, hoping to ﬁnd your way back.When that does not work, and you are ﬁnally willing to listen to the person sittingnext to you, you turn around and return to some “known” position on the route.Then, using a map (very diﬃcult for some people), you follow the directions pro-vided, periodically comparing where you are (from landmarks you see out thewindow) with where the map says you should be, until you reach your desireddestination.Debugging is somewhat like that. A logical error in a program can makeyou take a wrong turn. The simplest way to keep track of where you are as\n",
      "\n",
      "compared to where you want to be is totracethe program. This consists ofkeeping track of thesequenceof instructions that have been executed and theresultsproduced by each instruction executed. When you examine the sequenceof instructions executed, you can detect errors in the ﬂow of the program. Whenyou compare what each instruction has done to what it is supposed to do, youcan detect logical errors in the program. In short, when the behavior of the pro-gram as it is executing is diﬀerent from what it should be doing, you know thereis a bug.Au s e f u lt e c h n i q u ei st op a r t i t i o nt h ep r o g r a mi n t op a r t s ,o f t e nr e f e r r e dt oa smodules,a n de x a m i n et h er e s u l t st h a th a v eb e e nc o m p u t e da tt h ee n do fe x e c u -tion of each module. In fact, the structured programming approach discussed inSection 6.1 can help you determine where in the program’s execution you shouldexamine results. This allows you to systematically get to the point where youare focusing your attention on the instruction or instructions that are causing theproblem...Debugging OperationsMany sophisticated debugging tools are oﬀered in the marketplace, andundoubtedly you will use many of them in the years ahead. In Chapter 15, forexample, we will examine debugging techniques using a source-level debuggerfor C.Right now, however, we wish to stay at the level of the machine architecture,so we will see what we can accomplish with a few very elementary interactivedebugging operations. We will set breakpoints, single-step, and examine the stateof a program written in the LC-3 ISA.In Chapter 15, we will see these same concepts again: breakpoints, single-stepping, and examining program state that we are introducing here, but appliedto a C program, instead of the 0s and 1s of a program written in the LC-3 ISA.When debugging interactively, the user sits in front of the keyboard and mon-itor and issues commands to the computer. In our case, this means operating anLC-3 simulator, using the menu available with the simulator. It is important to beable to:1. Write values into memory locations and into registers.2. Execute instruction sequences in a program.3. Stop execution when desired.4. Examine what is in memory and registers at any point in the program.These few simple operations will go a long way toward debugging programs....Set ValuesIn order to test the execution of a part of a program in isolation without havingto worry about parts of the program that come before it, it is useful to ﬁrst writevalues in memory and in registers that would have been written by earlier parts ofthe program. For example, suppose one module in your program supplies inputfrom a keyboard, and a subsequent module operates on that input. Suppose you\n",
      "\n",
      "want to test the second module before you have ﬁnished debugging the ﬁrst mod-ule. If you know that the keyboard input module ends up with an ASCII code inR0, you can test the module that operates on that input by ﬁrst writing an ASCIIcode into R0....Execute SequencesIt is important to be able to execute a sequence of instructions and then stopexecution in order to examine the values that the program has computed as aresult of executing that sequence. Three simple mechanisms are usually availablefor doing this: run, step, and set breakpoints.TheRuncommand causes the program to execute until something makes itstop. This can be either a HALT instruction or a breakpoint.TheStepcommand causes the program to execute a ﬁxed number of instruc-tions and then stop. The interactive user enters the number of instructions he/shewishes the simulator to execute before it stops. When that number is 1, the com-puter executes one instruction, then stops. Executing one instruction and thenstopping is calledsingle-stepping. It allows the person debugging the program toexamine the individual results of each instruction executed.TheSet Breakpointcommand causes the program to stop execution at aspeciﬁc instruction in a program. Executing the debugging command Set Break-point consists of adding an address to a list maintained by the simulator. Duringthe FETCH phase of each instruction, the simulator compares the PC with theaddresses in that list. If there is a match, execution stops. Thus, the eﬀect of settingab r e a k p o i n ti st oa l l o we x e c u t i o nt op r o c e e du n t i lt h eP Cc o n t a i n sa na d d r e s st h a thas been set as a breakpoint. This is useful if one wishes to know what has beencomputed up to a particular point in the program. One sets a breakpoint at thataddress in the program and executes the Run command. The program executesuntil that point and then stops so the user can examine what has been computedup to that point. (When one no longer wishes to have the program stop executionat that point, the breakpoint can be removed by executing the Clear Breakpointcommand.)...Display ValuesFinally, it is useful to examine the results of execution when the simulator hasstopped execution. The Display command allows the user to examine the contentsof any memory location or any register...Use of an Interactive DebuggerWe conclude this chapter with four examples, showing how the use of interactivedebugging operations can help us ﬁnd errors in a program. We have chosen thefollowing four errors: (1) incorrectly setting the loop control so that the loop exe-cutes an incorrect number of times, (2) confusing the load instruction 0010, whichloads a register with thecontentsof a memory location, with the load eﬀectiveaddress instruction 1110, which loads a register with theaddressof a memorylocation, (3) forgetting which instructions set the condition codes, resulting in\n",
      "\n",
      "ab r a n c hi n s t r u c t i o nt e s t i n gt h ew r o n gc o n d i t i o n ,a n d( 4 )n o tc o v e r i n ga l lp o s s i b l ecases of input values....Example: Multiplying Without a Multiply Instruction\n",
      "xxxxxFigure.Debugging Example. An LC-program to multiply (without a Multiplyinstruction).If we examine the program instruction by instruction, we note that the pro-gram ﬁrst clears R2 (i.e., initializes R2 to 0) and then attempts to perform themultiplication by adding R4 to itself a number of times equal to the initial valuein R5. Each time an add is performed, R5 is decremented. When R5=0, theprogram terminates.It looks like the program should work! Upon execution, however, we ﬁnd thatif R4 initially contains the integer 10 and R5 initially contains the integer 3, theprogram produces the result 40. What went wrong?Our ﬁrst thought is to trace the program. Before we do that, we note that theprogram assumes positive integers in R4 and R5. Using the Set Values command,we put the value 10 in R4 and the value 3 in R5.It is also useful to annotate each instruction with some algorithmic descrip-tion ofexactlywhat each instruction is doing. While this can be very tediousand not very helpful in a 10,000-instruction program, it often can be very helpfulafter one has isolated a bug to within a few instructions. There is a big diﬀerencebetween quickly eyeballing a sequence of instructions and stating precisely whateach instruction is doing. Quickly eyeballing often results in mistaking what oneeyeballs! Stating precisely usually does not. We have included in Figure 6.4, nextto each instruction, such an annotation.Figure 6.5a shows a trace of the program, which we can obtain by single-stepping. The column labeledPCshows the contents of the PC at the start ofeach instruction. R2, R4, and R5 show the values in those three registers at thestart of each instruction.Aq u i c kl o o ka tt h et r a c es h o w st h a tt h el o o pb o d yw a se x e c u t e df o u rt i m e s ,rather than three. That suggests that the condition codes for our branch instructioncould have been set incorrectly. From there it is a short step to noting that thebranch should have been taken only when R5 was positive, and not when R5 is 0.That is, bit [10]=1 in the branch instruction caused the extra iteration of the loop.\n",
      "\n",
      "\n",
      "15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0000000 1111111101BR n z p−3We should also note that we could have saved a lot of the work of tracing theprogram by using a breakpoint. That is, instead of examining the results ofeachinstruction,if we set a breakpoint at x3203, we would examine the results ofeach iterationof the loop. Setting a breakpoint to stop the program after eachiteration of the loop is often enough to have us see the problem (and debug the pro-gram) without the tedium of single-stepping each iteration of the loop. Figure 6.5bshows the results of tracing the program, where each step is one iteration of theloop. We see that the loop executed four times instead of three, immediatelyidentifying the bug.\n",
      "\n",
      "Figure.Debugging Example.At r a c eo ft h eﬁ r s tf o u ri n s t r u c t i o n so ft h eA d dprogram.x3002, the loop control (R4), which counts the number of values added to R1, isinitialized to #10. The program subtracts 1 each time through the loop and repeatsuntil R4 contains 0. In x3003, the base register (R2) is initialized to the startinglocation of the values to be added: x3100.From there, each time through the loop, one value is loaded into R3 (inx3004), the base register is incremented to get ready for the next iteration (x3005),the value in R3 is added to R1, which contains the running sum (x3006), thecounter is decremented (x3007), the P bit is tested, and if true, the PC is set tox3004 to begin the next iteration of the loop body (x3008). After ten times throughthe loop, R4 contains 0, the P bit is 0, the branch is not taken, and the programterminates (x3009).It looks like the program should work. However, when we execute the pro-gram and then check the value in R1, we ﬁnd the number x0024, which is notx8135, the sum of the numbers stored in locations x3100 to x3109. What wentwrong?We turn to the debugger and trace the program. Figure 6.8 shows a trace ofthe ﬁrst four instructions executed. Note that after the instruction at x3003 hasexecuted, R2 contains x3107, not x3100 as we had expected. The problem isthat the opcode 0010 loaded thecontentsof M[x3100] (i.e., x3107) into R2, nottheaddressx3100. The result was to add the ten numbers starting at M[x3107]instead of the ten numbers starting at M[x3100].Our mistake: We used the wrong opcode. We should have used the opcode1110, which would have loaded R2 with the address x3100. We correct the bugby replacing the opcode 0010 with 1110, and the program runs correctly....Example: Does a Sequence of Memory Locations Contain a?The program of Figure 6.9 has been written to examine the contents of the tenmemory locations starting at address x3100 and to store a 1 in R0 if any of themcontains a 5 and a 0 in R0 if none of them contains a 5.The program is supposed to do the following: The ﬁrst six instructions (atx3000 to x3005) initialize R0 to 1, R1 to−5, and R3 to 10. The instruction atx3006 initializes R4 to the address (x3100) of the ﬁrst location to be tested, andx3007 loads the contents of x3100 into R2.The instructions at x3008 and x3009 determine if R2 contains the value 5 byadding−5t oR 2a n db r a n c h i n gt ox 3 0 0 Fi ft h er e s u l ti s0 .S i n c eR 0i si n i t i a l i z e dto 1, the program terminates with R0 reporting the presence of a 5 among thelocations tested.\n",
      "\n",
      "x3010001100 0 1 0 0 0 0 0 0 0 0x3100Figure.Debugging Example.A nL C -program to detect the presence of a.x300A increments R4, preparing to load the next value. x300B decrementsR3, indicating the number of values remaining to be tested. x300C loads the nextvalue into R2. x300D branches back to x3008 to repeat the process if R3 stillindicates more values to be tested. If R3=0, we have exhausted our tests, so R0is set to 0 (x300E), and the program terminates (x300F).When we run the program for some sample data that contains a 5 in one ofthe memory locations, the program terminates with R0=0, indicating there wereno 5s in locations x3100 to x310A.What went wrong? We examine a trace of the program, with a breakpoint setat x300D. The results are shown in Figure 6.10.The ﬁrst time the PC is at x300D, we have already tested the value stored inx3100, we have loaded 7 (the contents of x3101) into R2, and R3 indicates thereare still nine values to be tested. R4 contains the address from which we mostrecently loaded R2.The second time the PC is at x300D, we have loaded 32 (the contents ofx3102) into R2, and R3 indicates there are eight values still to be tested. Thethird time the PC is at x300D, we have loaded 0 (the contents of x3103) into R2,\n",
      "Figure.Debugging Example. Tracing Examplewith a breakpoint at xD.\n",
      "\n",
      "The error in the program occurred because the branch instruction immedi-ately followed the load instruction that set the condition codes based on what wasloaded. That wiped out the condition codes set by the iteration control instructionat x300B, which was keeping track of the number of iterations left to do. Sincethe branch instruction should branch if there are still more memory locations toexamine, the branch instruction should have immediately followed the iterationcontrol instruction and NOT the load instruction which also sets condition codes.Ac o n d i t i o n a lb r a n c hi n s t r u c t i o ns h o u l db ec o n s i d e r e dt h es e c o n di n s t r u c t i o nin a pair of instructions.Instruction A ; sets the condition codesBR instruction ; branches based on the condition codesThe first instruction in the pair (Instruction A) sets the condition codes. Thesecond instruction (BR) branches or not, depending on the condition codes set byinstruction A. It is important to never insert any instruction that sets condition codesbetween instruction A and the branch instruction, since doing so will wipe out thecondition codes set by instruction A that are needed by the branch instruction.Since the branch at x300D was based on the value loaded into R2, insteadof how many values remained to be tested, the third time the branch instructionwas executed, it was not taken when it should have been. If we interchange theinstructions at x300B and x300C, the branch instruction at x300D immediatelyfollows the iteration control instruction, and the program executes correctly.It is also worth noting that the branch at x300Dcoincidentallybehaved cor-rectly the ﬁrst two times it executed because the load instruction at x300C loadedpositive values into R2. The bug did not produce incorrect behavior until the thirditeration. It would be nice if bugs would manifest themselves the ﬁrst time theyare encountered, but that is often not the case. Coincidences do occur, which addsto the challenges of debugging....Example:F i n d i n gt h eF i r s tin a WordOur last example contains an error that is usually one of the hardest to ﬁnd, as weAddrx300x300x300x300x300x300x300x300x300x300Figure.Debugging Example.A nL C -program to ﬁnd the ﬁrstin a word.\n",
      "\n",
      "example, if the location examined contained 0010000110000000, the programwould terminate with R1=13. If the location contained 0000000000000110,the program would terminate with R1=2.The program Figure 6.11 is supposed to work as follows (and it usually does):x3000 and x3001 initialize R1 to 15, the bit number of the leftmost bit.x3002 loads R2 with the contents of x3400, the bit pattern to be exam-ined. Since x3400 is too far from x3000 for a LD instruction, the load indirectinstruction is used, obtaining the location of the bit pattern in x3009.x3003 tests the most signiﬁcant bit of the bit pattern (bit [15]), and if it isa1 ,b r a n c h e st ox 3 0 0 8 ,w h e r et h ep r o g r a mt e r m i n a t e sw i t hR 1 = 1 5 .I ft h em o s tsigniﬁcant bit is 0, the branch is not taken, and processing continues at x3004.The loop body, locations x3004 to x3007, does two things. First (x3004), itsubtracts 1 from R1, yielding the bit number of the next bit to the right. Second(x3005), it adds R2 to itself, resulting in the contents of R2 shifting left one bit,resulting in the next bit to the right being shifted into the bit [15] position. Third(x3006), the BR instruction tests the “new” bit [15], and if it is a 1, branches tox3008, where the program halts with R1 containing the actual bit number of thecurrent leftmost bit. If the new bit [15] is 0, x3007 is an unconditional branch tox3004 for the next iteration of the loop body.The process continues until the ﬁrst 1 is found. The program works correctlyalmost all the time. However, when we ran the program on our data, the program\n",
      "Figure.Debugging Example. A Trace of Debugging Examplewith a breakpointat x.\n",
      "\n",
      "Each time the PC contained the address x3007, R1 contained a value smallerby 1 than the previous time. The reason is as follows: After R1 was decrementedand the value in R2 shifted left, the bit tested was a 0, and so the program did notterminate. This continued for values in R1 equal to 14, 13, 12, 11, 10, 9, 8, 7, 6,5, 4, 3, 2, 1, 0,−1,−2,−3,−4, and so forth.The problem was that the initial value in x3400 was x0000. The programworked ﬁne as long as there was at least one 1 present. For the case where x3400contained all zeros, the conditional branch at x3006 was never taken, and so theprogram continued with execution of x3007, then x3004, x3005, x3006, x3007,and then back again to x3004. There was no way to break out of the sequencex3004, x3005, x3006, x3007, and back again to x3004. We call the sequencex3004 to x3007 a loop. Because there is no way for the program execution to breakout of this loop, we call it aninﬁnite loop.T h u s ,t h ep r o g r a mn e v e rt e r m i n a t e s ,and so we can never get the correct answer.Again, we emphasize that this is often the hardest error to detect because itis as we said earlier a corner case. The programmer assumed that at least one bit\n",
      "...eﬃciently multiplies two integers and places the result in R3. Show the\n",
      "\n",
      "embly LanguageByn o w ,y o ua r ep r o b a b l yal i t t l et i r e do f1 sa n d0 sa n dk e e p i n gt r a c ko f0 0 0 1meaning ADD and 1001 meaning NOT. Also, wouldn’t it be nice if wecould refer to a memory location by some meaningful symbolic name instead ofmemorizing its 16-bit address? And wouldn’t it be nice if we could represent eachinstruction in some more easily comprehensible way, instead of having to keeptrack of which bit of an instruction conveys which individual piece of informationabout that instruction? It turns out that help is on the way.In this chapter, we introduce assembly language, a mechanism that does allof the above, and more..Assembly LanguageProgramming—Moving Up a LevelRecall the levels of transformation identiﬁed in Figure 1.9 of Chapter 1. Algo-rithms are transformed into programs described in some mechanical language.This mechanical language can be, as it is in Chapter 5, the machine language of aparticular computer. Recall that a program is in a computer’s machine languageif every instruction in the program is from the ISA of that computer.On the other hand, the mechanical language can be more user-friendly. Wegenerally partition mechanical languages into two classes, high-level and low-level. Of the two, high-level languages are much more user-friendly. Examplesare C, C++, Java, Fortran, COBOL, Python, plus more than a thousand others.Instructions in a high-level language almost (but not quite) resemble statementsin a natural language such as English. High-level languages tend to be ISA inde-pendent. That is, once you learn how to program in C (or Fortran or Python)for one ISA, it is a small step to write programs in C (or Fortran or Python) foranother ISA.\n",
      "\n",
      "Before a program written in a high-level language can be executed, it mustbe translated into a program in the ISA of the computer on which it is expected toexecute. It is often the case that each statement in the high-level language speciﬁesseveral instructions in the ISA of the computer. In Chapter 11, we will introducethe high-level language C, and in Chapters 12 through 19, we will show the rela-tionship between various statements in C and their corresponding translations toLC-3 code. In this chapter, however, we will only move up a small step from theISA we dealt with in Chapter 5.A small step up from the ISA of a machine is that ISA’s assembly language.Assembly language is a low-level language. There is no confusing an instruc-tion in a low-level language with a statement in English. Each assembly languageinstruction usually speciﬁes a single instruction in the ISA. Unlike high-level lan-guages, which are usually ISA independent, low-level languages are very muchISA dependent. In fact, it is usually the case that each ISA has only one assemblylanguage.The purpose of assembly language is to make the programming process moreuser-friendly than programming in machine language (i.e., in the ISA of the com-puter with which we are dealing), while still providing the programmer withdetailed control over the instructions that the computer can execute. So, for exam-ple, while still retaining control over the detailed instructions the computer is tocarry out, we are freed from having to remember what opcode is 0001 and whatopcode is 1001, or what is being stored in memory location 0011111100001010and what is being stored in location 0011111100000101. Assembly languageslet us use mnemonic devices for opcodes, such as ADD for 0001 and NOT for1001, and they let us give meaningful symbolic names to memory locations, suchas SUM or PRODUCT, rather than use the memory locations’ 16-bit addresses.This makes it easier to diﬀerentiate which memory location is keeping track of aSUM and which memory location is keeping track of a PRODUCT. We call thesenamessymbolic addresses.We will see, starting in Chapter 11, that when we take the larger step ofmoving up to a higher-level language (such as C), programming will be even moreuser-friendly, but in doing so, we will relinquish some control over exactly whichdetailed ISA instructions are to be carried out to accomplish the work speciﬁedby a high-level language statement..An Assembly Language ProgramWe will begin our study of the LC-3 assembly language by means of an example.The program in Figure 7.1 multiplies the integer initially stored in NUMBERby 6 by adding the integer to itself six times. For example, if the integer is 123,the program computes the product by adding 123+123+123+123+123+123.Where have you seen that before? :-)The program consists of 21 lines of code. We have added aline numbertoeach line of the program in order to be able to refer to individual lines easily.This is a common practice. These line numbers are not part of the program. Tenlines start with a semicolon, designating that they are strictly for the beneﬁt of\n",
      "\n",
      "15 .ENDFigure.An assembly language program.the human reader. More on this momentarily. Seven lines (06, 07, 08, 0C, 0D, 0E,and 10) specify assembly language instructions to be translated into machine lan-guage instructions of the LC-3, which will be executed when the program runs.The remaining four lines (05, 12, 13, and 15) contain pseudo-ops, which are mes-sages from the programmer to the translation program to help in the translationprocess. The translation program is called anassembler(in this case the LC-3assembler), and the translation process is calledassembly...InstructionsInstead of an instruction being 16 0s and 1s, as is the case in the LC-3 ISA, aninstruction in assembly language consists of four parts, as follows:Label Opcode Operands ; CommentTwo of the parts (Label and Comment) are optional. More on that momentarily....Opcodes and OperandsTwo of the parts (Opcode and Operands) aremandatory.F o ra na s s e m b l yl a n -guage instruction to correspond to an instruction in the LC-3 ISA, it must havean Opcode (the thing the instruction is to do), and the appropriate number ofOperands (the things it is supposed to do it to). Not surprisingly, this was exactlywhat we encountered in Chapter 5 when we studied the LC-3 ISA.The Opcode is a symbolic name for the opcode of the corresponding LC-3instruction. The idea is that it is easier to remember an operation by the symbolic\n",
      "\n",
      "name ADD, AND, or LDR than by the four-bit quantity 0001, 0101, or 0110.Figure 5.3 (also Figure A.2) lists the Opcodes of the 15 LC-3 instructions.Pages 658 through 673 show the assembly language representations for the 15LC-3 instructions.The number of operands depends on the operation being performed. Forexample, the ADD instruction (line 0C in the program of Figure 7.1) requiresthree operands (two sources to obtain the numbers to be added, and one desti-nation to designate where the result is to be stored). All three operands must beexplicitly identiﬁed in the instruction.AGAIN ADD R3,R3,R2In this case the operands to be added are obtained from register 2 and from register3. The result is to be placed in register 3. We represent each of the registers 0through 7 as R0, R1, R2,…,R 7 ,r a t h e rt h a n0 0 0 ,0 0 1 ,0 1 0 ,…,1 1 1 .The LD instruction (line 07 of the program in Figure 7.1) requires twooperands (the memory location from which the value is to be read and the destina-tion register that is to contain the value after the instruction ﬁnishes execution). InLC-3 assembly language, we assign symbolic names calledlabelsto the memorylocations so we will not have to remember their explicit 16-bit addresses. In thiscase, the location from which the value is to be read is given the labelNUMBER.The destination (i.e., where the value is to be loaded) is register 2.LD R2, NUMBERAs we discussed in Section 5.1.6, operands can be obtained from registers, frommemory, or they may be literal (i.e., immediate) values in the instruction. In thecase of register operands, the registers are explicitly represented (such as R2 andR3 in line 0C). In the case of memory operands, the symbolic name of the mem-ory location is explicitly represented (such as NUMBER in line 07 and SIX in line06). In the case of immediate operands, the actual value is explicitly represented(such as the value 0 in line 08).AND R3, R3, #0 ; Clear R3. It will contain the product.Al i t e r a lv a l u em u s tc o n t a i nas y m b o li d e n t i f y i n gt h er e p r e s e n t a t i o nb a s eo ft h enumber. We use # for decimal, x for hexadecimal, and b for binary. Sometimesthere is no ambiguity, such as in the case 3F0A, which is a hex number. Nonethe-less, we write it as x3F0A. Sometimes there is ambiguity, such as in the case1000. x1000 represents the decimal number 4096, b1000 represents the decimalnumber 8, and #1000 represents the decimal number 1000....LabelsLabels are symbolic names that are used to identify memory locations that arereferred to explicitly in the program. In LC-3 assembly language, a label consistsof from 1 to 20 alphanumeric characters (i.e., each character is a capital or lower-case letter of the English alphabet, or a decimal digit), starting with a letter of thealphabet.However, not all sequences of characters that follow these rules can be usedas labels. You know that computer programs cannot tolerate ambiguity. So ADD,\n",
      "\n",
      "NOT, x1000, R4, and other character strings that have speciﬁc meanings in anLC-3 program cannot be used as labels. They could confuse the LC-3 assembleras it tries to translate the LC-3 assembly language program into a program in theLC-3 ISA. Such not-allowed character strings are often referred to asreservedwords.NOW, Under21, R2D2, R785, and C3PO are all examples of legitimate LC-3assembly language labels.We said we give a label (i.e., a symbolic name) to a memory location if weexplicitly refer to it in the program. There are two reasons for explicitly referringto a memory location.1. The location is the target of a branch instruction (e.g., AGAIN in line 0C).That is, the label AGAIN identiﬁes the location of the instruction that willbe executed next if the branch is taken.2. The location contains a value that is loaded or stored (e.g., NUMBER inline 12, and SIX in line 13).Note the location AGAIN (identiﬁed in line 0C) is speciﬁcally referenced bythe branch instruction in line 0E.BRp AGAINIf the result of ADD R1,R1,#–1 is positive (which results in the P bit beingset), then the program branches to the location explicitly referenced as AGAINto perform another iteration.The location NUMBER is speciﬁcally referenced by the load instructionin line 07. The value stored in the memory location explicitly referenced asNUMBER is loaded into R2.If a location in the program is not explicitly referenced, then there is no needto give it a label....CommentsComments are messages intended only for human consumption. They have noeﬀect on the translation process and indeed are not acted on by the LC-3 assem-bler. They are identiﬁed in the program by semicolons. A semicolon signiﬁesthat the rest of the line is a comment and is to be ignored by the assembler. If thesemicolon is the ﬁrst nonblank character on the line, the entire line is ignored. Ifthe semicolon follows the operands of an instruction, then only the comment isignored by the assembler.The purpose of comments is to make the program more comprehensible tothe human reader. Comments help explain a nonintuitive aspect of an instructionor a set of instructions. In lines 08 and 09, the comment “Clear R3; it will containthe product” lets the reader know that the instruction on line 08 is initializingR3 prior to accumulating the product of the two numbers. While the purpose ofline 08 may be obvious to the programmer today, it may not be the case two yearsfrom now, after the programmer has written an additional 30,000 instructions andcannot remember why he/she wrote AND R3,R3,#0. It may also be the case thattwo years from now, the programmer no longer works for the company, and the\n",
      "\n",
      "Another purpose of comments is to make the visual presentation of a programeasier to understand. That is, comments are used to separate pieces of a programfrom each other to make the program more readable. Lines of code that worktogether to compute a single result are placed on successive lines, but they areseparated from the rest of the program by blank lines. For example, note thatlines 0C through 0E, which together form the loop body that is the crux of thiscomputer program, are separated from the rest of the code by lines 0B and 0F.There is nothing on lines 0B and 0F other than the semicolons in the ﬁrst column.Incidentally, another opportunity to make a program easier to read is the judi-cious use of white space, accomplished by adding extra spaces to a line that areignored by the assembler—for example, having all the opcodes start in the samecolumn on the page, whether or not the instruction has a label...Pseudo-Ops (Assembler Directives)The LC-3 assembler is a program that takes as input a string of characters repre-senting a computer program written in LC-3 assembly language and translates itinto a program in the ISA of the LC-3. Pseudo-ops help the assembler performthat task.The more formal name for a pseudo-op isassembler directive. It is called apseudo-op because, like its Greek root “pseudes” (which means “false”), it doesnot refer to an operation that will be performed by the program during execution.Rather, the pseudo-op is strictly a message from the assembly language program-mer to the assembler to help the assembler in the assembly process. Once theassembler handles the message, the pseudo-op is discarded. The LC-3 assem-bly language contains ﬁve pseudo-ops that we will ﬁnd useful in our assemblylanguage programming: .ORIG, .FILL, .BLKW, .STRINGZ, and .END. All areeasily recognizable by the dot as their ﬁrst character.....ORIG.ORIG tells the assembler where in memory to place the LC-3 program. In line 05,.ORIG x3050 says, place the ﬁrst LC-3 ISA instruction in location x3050. As aresult, 0010001000001100 (the translated LD R1,SIX instruction) is put in loca-tion x3050, and the rest of the translated LC-3 program is placed in the subsequentsequential locations in memory. For example, if the program consists of x100 LC-3i n s t r u c t i o n s ,a n d. O R I Gs a y st op u tt h eﬁ r s ti n s t r u c t i o ni nx 3 0 5 0 ,t h er e m a i n i n gxFF instructions are placed in locations x3051 to x314F.\n",
      "\n",
      ".An Assembly Language Program....FILL.FILL tells the assembler to set aside the next location in the program and initial-ize it with the value of the operand. The value can be either a number or a label.In line 13, the ninth location in the resulting LC-3 program is initialized to thevalue x0006.....BLKW.BLKW tells the assembler to set aside some number of sequential memory loca-tions (i.e., aBLocKofWords) in the program. The actual number is the operandof the .BLKW pseudo-op. In line 12, the pseudo-op instructs the assembler to setaside one location in memory (and, incidentally, to label it NUMBER).The pseudo-op .BLKW is particularly useful when the actual value of theoperand is not yet known. In our example we assumed the number in locationNUMBER was 123. How did it get there? A common use of .BLKW is to setaside a location in the program, as we did here, and have another section of codeproduce the number, perhaps from input from a keyboard (which we cannot knowat the time we write the program), and store that value into NUMBER before weexecute the code in Figure 7.1.....STRINGZ.STRINGZ tells the assembler to initialize a sequence ofn+1m e m o r yl o c a t i o n s .The argument is a sequence ofncharacters inside double quotation marks. The\n",
      "x: xx301C: x0021x301D: x0000\n",
      "\n",
      "....END.END tells the assembler it has reached the end of the program and need noteven look at anything after it. That is, any characters that come after .END willnot be processed by the assembler.Note:.END does not stop the program duringexecution. In fact, .END does not evenexistat the time of execution. It is simply adelimiter—it marks the end of the program. It is a message from the programmer,telling the assembler where the assembly language program ends...Example: The Character Count Example of Section.,Revisited Again!Now we are ready for a complete example. Let’s consider again the problem ofSection 5.5. We wish to write a program that will take a character that is inputfrom the keyboard and count the number of occurrences of that character in aﬁle. As before, we ﬁrst develop the algorithm by constructing the ﬂowchart.Recall that in Section 6.1, we showed how to decompose the problem system-atically so as to generate the ﬂowchart of Figure 5.16. In fact, the ﬁnal step ofthat process in Chapter 6 is the ﬂowchart of Figure 6.3e, which is essentiallyidentical to Figure 5.16. Next, we use the ﬂowchart to write the actual program.This time, however, we enjoy the luxury of not worrying about 0s and 1s andinstead write the program in LC-3 assembly language. The program is shown inFigure 7.2.A few comments about this program: Three times during this program, assis-tance in the form of a service call is required of the operating system. In each case,aT R A Pi n s t r u c t i o ni su s e d .T R A Px 2 3c a u s e sac h a r a c t e rt ob ei n p u tf r o mt h ekeyboard and placed in R0 (line 0D). TRAP x21 causes the ASCII code in R0to be displayed on the monitor (line 28). TRAP x25 causes the machine to behalted (line 29). As we said before, we will leave the details of how the TRAPinstruction is carried out until Chapter 9.The ASCII codes for the decimal digits 0 to 9 (0000 to 1001) are x30 to x39.The conversion from binary to ASCII is done simply by adding x30 to the binaryvalue of the decimal digit. Line 2D shows the label ASCII used to identify thememory location containing x0030. The LD instruction in line 26 uses it to loadx30 into R0, so it can convert the count that is in R2 from a binary value to anASCII code. That is done by the ADD instruction in line 27. TRAP x21 in line28 prints the ASCII code to the monitor.The ﬁle that is to be examined starts at address x4000 (see line 2E). Usually,this starting address would not be known to the programmer who is writing thisprogram since we would want the program to work on many ﬁles, not just the onestarting at x4000. To accomplish that, line 2E would be replaced with .BLKW1a n db eﬁ l l e di nb ys o m eo t h e rp i e c eo fc o d et h a tk n e wt h es t a r t i n ga d d r e s so fthe desired ﬁle before executing the program of Figure 7.2. That situation will bediscussed in Section 7.4.\n",
      "\n",
      ".The Assembly Process..IntroductionBefore an LC-3 assembly language program can be executed, it must ﬁrst betranslated into a machine language program, that is, one in which each instructionis in the LC-3 ISA. It is the job of the LC-3 assembler to perform that translation.If you have available an LC-3 assembler, you can cause it to translate yourassembly language program into a machine language program by executing anappropriate command. In the LC-3 assembler that is generally available via theweb, that command isassemble,a n di tr e q u i r e sa sa na r g u m e n tt h eﬁ l e n a m eo fyour assembly language program. For example, if the ﬁlename is solution1.asm,thenassemble solution1.asm outﬁleproduces the ﬁle outﬁle, which is in the ISA of the LC-3. It is necessary to checkwith your instructor for the correct command line to cause the LC-3 assembler toproduce a ﬁle of 0s and 1s in the ISA of the LC-3...A Two-Pass ProcessIn this section, we will see how the assembler goes through the process of trans-lating an assembly language program into a machine language program. We willuse as our input to the process the assembly language program of Figure 7.2.You remember that there is in general a one-to-one correspondence betweeninstructions in an assembly language program and instructions in the ﬁnalmachine language program. We could try to perform this translation in one passthrough the assembly language program. Starting from the top of Figure 7.2, theassembler discards lines 01 to 09, since they contain only comments. Commentsare strictly for human consumption; they have no bearing on the translation pro-cess. The assembler then moves on to line 0A. Line 0A is a pseudo-op; it tellsthe assembler that the machine language program is to start at location x3000.The assembler then moves on to line 0B, which it can easily translate into LC-3machine code. At this point, we havex3000: 0101010010100000The LC-3 assembler moves on to translate the next instruction (line 0C). Unfor-tunately, it is unable to do so since it does not know the meaning of the symbolicaddress PTR. At this point the assembler is stuck, and the assembly process fails.To prevent this from occurring, the assembly process is done in two com-plete passes (from beginning to .END) through the entire assembly languageprogram. The objective of the ﬁrst pass is to identify the actual binary addressescorresponding to the symbolic names (or labels). This set of correspondences isknown as thesymbol table. In pass 1, we construct the symbol table. In pass 2, wetranslate the individual assembly language instructions into their correspondingmachine language instructions.Thus, when the assembler examines line 0C for the purpose of translatingLD R3,PTR\n",
      "\n",
      "during the second pass, it already knows that PTR is the symbolic address ofmemory location x3013 (from the ﬁrst pass). Thus, it can easily translate line0C tox3001: 0010011000010001The problem of not knowing the 16-bit address corresponding to PTR no longerexists...The First Pass: Creating the Symbol TableFor our purposes, the symbol table is simply a correspondence of symbolic nameswith their 16-bit memory addresses. We obtain these correspondences by pass-ing through the assembly language program once, noting which instruction isassigned to which memory location, and identifying each label with the memoryaddress of its assigned entry.Recall that we provide labels in those cases where we have to refer to a loca-tion, either because it is the target of a branch instruction or because it containsdata that must be loaded or stored. Consequently, if we have not made any pro-gramming mistakes, and if we identify all the labels, we will have identiﬁed allthe symbolic addresses used in the program.The preceding paragraph assumes that our entire program exists between our.ORIG and .END pseudo-ops. This is true for the assembly language programof Figure 7.2. In Section 7.4, we will consider programs that consist of multi-ple parts, each with its own .ORIG and .END, wherein each part is assembledseparately.The ﬁrst pass starts, after discarding the comments on lines 01 to 09, bynoting (line 0A) that the ﬁrst instruction will be assigned to address x3000. Wekeep track of the location assigned to each instruction by means of a locationcounter (LC). The LC is initialized to the address speciﬁed in .ORIG, that is,x3000.The assembler examines each instruction in sequence and increments the LConce for each assembly language instruction. If the instruction examined containsal a b e l ,as y m b o lt a b l ee n t r yi sm a d ef o rt h a tl a b e l ,s p e c i f y i n gt h ec u r r e n tc o n -tents of LC as its address. The ﬁrst pass terminates when the .END pseudo-op isreached.The ﬁrst instruction that has a label is at line 13. Since it is the ﬁfth instructionin the program and since the LC at that point contains x3004, a symbol table entryis constructed thus:SymbolAddressTESTx3004The second instruction that has a label is at line 20. At this point, the LC has beenincremented to x300B. Thus, a symbol table entry is constructed, as follows:SymbolAddressGETCHARx300B\n",
      "\n",
      "At the conclusion of the ﬁrst pass, the symbol table has the following entries:SymbolAddressTESTx3004GETCHARx300BOUTPUTx300EASCIIx3012PTRx3013..The Second Pass: Generating theMachine Language ProgramThe second pass consists of going through the assembly language program a sec-ond time, line by line, this time with the help of the symbol table. At each line,the assembly language instruction is translated into an LC-3 machine languageinstruction.Starting again at the top, the assembler again discards lines 01 through 09because they contain only comments. Line 0A is the .ORIG pseudo-op, whichthe assembler uses to initialize LC to x3000. The assembler moves on to line 0Band produces the machine language instruction 0101010010100000. Then theassembler moves on to line 0C.This time, when the assembler gets to line 0C, it can completely assemblethe instruction since it knows that PTR corresponds to x3013. The instruction isLD, which has an opcode encoding of 0010. The destination register (DR) is R3,that is, 011.The only part of the LD instruction left to do is the PCoﬀset. It is computed asfollows: The assembler knows that PTR is the label for address x3013 and that theincremented PC is LC+1, in this case x3002. Since PTR (x3013) must be the sumof the incremented PC (x3002) and the sign-extended PCoﬀset, PCoﬀset must bex0011. Putting this all together, the assembler sets x3001 to 0010011000010001and increments the LC to x3002.Note:In order to use the LD instruction, it is necessary that the source ofthe load, in this case the address whose label is PTR, is not more than+256 or−255 memory locations from the LD instruction itself. If the address of PTRhad been greater than LC+1+255 or less than LC+1−256, then the oﬀset wouldnot ﬁt in bits [8:0] of the instruction. In such a case, an assembly error wouldhave occurred, preventing the assembly process from ﬁnishing successfully. For-tunately, PTR is close enough to the LD instruction, so the instruction assembledcorrectly.The second pass continues. At each step, the LC is incremented and thelocation speciﬁed by LC is assigned the translated LC-3 instruction or, in thecase of .FILL, the value speciﬁed. When the second pass encounters the .ENDpseudo-op, assembly terminates.The resulting translated program is shown in Figure 7.3.That process was, on a good day, merely tedious. Fortunately, you do not haveto do it for a living—the LC-3 assembler does that. And, since you now know the\n",
      "\n",
      "Figure.The machine language program for the assembly language program ofFigure..LC-3 assembly language, there is no need to program in machine language. Nowwe can write our programs symbolically in LC-3 assembly language and invokethe LC-3 assembler to create the machine language versions that can execute onan LC-3 computer..Beyond the Assembly of a SingleAssembly Language ProgramOur purpose in this chapter has been to take you up one more step from the ISAof the computer and introduce assembly language. Although it is still quite alarge step from C or C++, assembly language does, in fact, save us a good dealof pain. We have also shown how a rudimentary two-pass assembler actuallyworks to translate an assembly language program into the machine language ofthe LC-3 ISA.There are many more aspects to sophisticated assembly language program-ming that go well beyond an introductory course. However, our reason forteaching assembly language is not to deal with its sophistication, but rather toshow its innate simplicity. Before we leave this chapter, however, there are a fewadditional highlights we should explore.\n",
      "\n",
      "..The Executable ImageWhen a computer begins execution of a program, the entity being executed iscalled anexecutable image.T h ee x e c u t a b l ei m a g ei sc r e a t e df r o mm o d u l e so f t e ncreated independently by several diﬀerent programmers. Each module is trans-lated separately into an object ﬁle. We have just gone through the process ofperforming that translation ourselves by mimicking the LC-3 assembler. Othermodules, some written in C perhaps, are translated by the C compiler. Some mod-ules are written by users, and some modules are supplied as library routines bythe operating system. Each object ﬁle consists of instructions in the ISA of thecomputer being used, along with its associated data. The ﬁnal step is to combine(i.e.,link)a l lt h eo b j e c tm o d u l e st o g e t h e ri n t oo n ee x e c u t a b l ei m a g e .D u r i n ge x e -cution of the program, the FETCH, DECODE,…instruction cycle is applied toinstructions in the executable image...More than One Object FileIt is very common to form an executable image from more than one object ﬁle.In fact, in the real world, where most programs invoke libraries provided by theoperating system as well as modules generated by other programmers, it is muchmore common to have multiple object ﬁles than a single one.Ac a s ei np o i n ti so u re x a m p l ec h a r a c t e rc o u n tp r o g r a m .T h ep r o g r a mc o u n t sthe number of occurrences of a character in a ﬁle. A typical application couldeasily have the program as one module and the input data ﬁle as another. If thiswere the case, then the starting address of the ﬁle, shown as x4000 in line 2E ofFigure 7.2, would not be known when the program was written. If we replace line2E withPTR .FILL STARTofFILEthen the program of Figure 7.2 will not assemble because there will be no symboltable entry for STARTofFILE. What can we do?If the LC-3 assembly language, on the other hand, contained the pseudo-op.EXTERNAL, we could identify STARTofFILE as the symbolic name of anaddress that is not known at the time the program of Figure 7.2 is assembled.This would be done by the following line.EXTERNAL STARTofFILE,which would send a message to the LC-3 assembler that the absence of labelSTARTofFILE is not an error in the program. Rather, STARTofFILE is a labelin some other module that will be translated independently. In fact, in our case,it will be the label of the location of the ﬁrst character in the ﬁle to be examinedby our character count program.If the LC-3 assembly language had the pseudo-op .EXTERNAL, and if wehad designated STARTofFILE as .EXTERNAL, the LC-3 assembler would beable to create a symbol table entry for STARTofFILE, and instead of assigningit an address, it would mark the symbol as belonging to another module. Atlink\n",
      "\n",
      "Upt on o ww eh a v ec o m p l e t e l yi g n o r e dt h ed e t a i l so fi n p u ta n do u t p u t ,t h a ti s ,how the computer actually gets information from the keyboard (input), andhow the computer actually delivers information to the monitor (output). Insteadwe have relied on the TRAP instruction (e.g., TRAP x23 for input and TRAP x21for output) to accomplish these tasks. The TRAP instruction enables us to tell theoperating system what we need done by means of a trap vector, and we trust theoperating system to do it for us.The more generic term for our TRAP instruction issystem callbecause theTRAP instruction is calling on the operating system to do something for us whileallowing us to remain completely clueless as to how it gets done. Now we areready to examine how input and output actually work in the LC-3, what happenswhen the user program makes a system call by invoking the TRAP instruction,and how it all works under the control of the operating system.We will start with the actual physical structures that are required to causeinput and output to occur. But before we do that, it is useful to say a few wordsabout the operating system and understand a few basic concepts that have not beenimportant so far but become very important when considering what the operatingsystem needs to do its job.You may be familiar with Microsoft’s various ﬂavors of Windows, Apple’sMacOS, and Linux. These are all examples of operating systems. They all havethe same goal: to optimize the use of all the resources of the computer systemwhile making sure that no software does harmful things to any program or datathat it has no right to mess with. To better understand their job, we need to under-stand the notions of privilege and priority and the layout of the memory addressspace (i.e., the regions of memory and the purpose of each).\n",
      "\n",
      ".Privilege, Priority, and theMemory Address Space..Privilege and PriorityTwo very diﬀerent (we often say orthogonal) concepts associated with computerprocessing areprivilegeandpriority....PrivilegePrivilege is all about the right to do something, such as execute a particularinstruction or access a particular memory location. Not all computer programshave the right to execute all instructions. For example, if a computer system isshared among many users and the ISA contains a HALT instruction, we wouldnot want any random program to execute that HALT instruction and stop thecomputer. If we did, we would have some pretty disgruntled users on our hands.Similarly, some memory locations are only available to the operating system. Wewould not want some random program to interfere with the data structures orcode that is part of the operating system, which would in all likelihood cause theentire system to crash. In order to make sure neither of these two things happens, wedesignate every computer program as either privileged or unprivileged. We oftensaysupervisor privilegeto indicate privileged. We say a program is executing inSupervisor mode to indicate privileged, or User mode to indicate unprivileged. If aprogram is executing in Supervisor mode, it can execute all instructions and accessall of memory. If a program is executing in User mode, it cannot. If a programexecuting in User mode tries to execute an instruction or access a memory locationthat requires being in Supervisor mode, the computer will not allow it....PriorityPriority is all about the urgency of a program to execute. Every program isassigned a priority, specifying its urgency as compared to all other programs.This allows programs of greater urgency to interrupt programs of lesser urgency.For example, programs written by random users may be assigned a priority of 0.The keyboard may be asigned a priority of 4, and the fact that the computer isplugged into a source of energy like a wall outlet may be assigned a priority of 6.If that is the case, a random user program would be interrupted if someone sittingat a keyboard wanted to execute a program that caused data to be input into thecomputer. And that program would be interrupted if someone pulled the powercord out of the wall outlet, causing the computer to quickly lose its source ofenergy. In such an event, we would want the computer to execute some operatingsystem program that is provided speciﬁcally to handle that situation....Two Orthogonal NotionsWe said privilege and priority are two orthogonal notions, meaning they havenothing to do with each other. We humans sometimes have a problem with thatas we think of ﬁre trucks that have the privilege of ignoring traﬃcl i g h t sb e c a u s e\n",
      "\n",
      ".Privilege, Priority, and the Memory Address Spacethey must quickly reach the ﬁre. In our daily lives, we often are given privilegesbecause of our greater sense of urgency. Not the case with computer systems.For example, we can have a user program that is tied to a physics experimentthat needs to interrupt the computer at a speciﬁc instance of time to record infor-mation being generated by the physics experiment. If the user program does notpre-empt the program running at that instant of time, the data generated by theexperiment may be lost. This is a user program, so it does not have supervisorprivilege. But it does have a greater urgency, so it does have a higher priority.Another example: The system administrator wants to execute diagnostic pro-grams that access all memory locations and execute all instructions as part ofsome standard preventive maintenance. The diagnostic program needs supervi-sor privilege to execute all instructions and access all memory locations. But ithas no sense of urgency. Whether this happens at 1 a.m. or 2 a.m. is irrelevant,compared to the urgency of other programs that need access to the computersystem exactly when they need it. The diagnostic program has privilege but nopriority.Finally, an example showing that even in human activity one can have prioritybut not privilege. Our friend Bob works in the basement of one of those NewYork City skyscrapers. He is about to go to the men’s room when his managertells him to take a message immediately to the vice president on the 88th ﬂoor,and bring back a response. So Bob delays his visit to the men’s room and takesthe elevator to the 88th ﬂoor. The vice president keeps him waiting, causing Bobto be concerned he might have an accident. Finally, the vice president gives hisresponse, and Bob pushes the button to summon the elevator to take him back tothe basement, in pain because he needs to go to the men’s room. While waiting forthe elevator, another vice president appears, unlocks the executive men’s room,and enters. Bob is in pain, but he cannot enter the executive men’s room. Althoughhe certainly has the priority, he does not have the privilege!...The Processor Status Register (PSR)Each program executing on the computer has associated with it two very impor-tant registers. The Program Counter (PC) you are very familiar with. The otherregister, the Processor Status Register (PSR), is shown in Figure 9.1. It containsthe privilege and priority assigned to that program.Bit [15] speciﬁes the privilege, where PSR[15]=0 means supervisor privi-lege, and PSR[15]=1 means unprivileged. Bits [10:8] specify the priority level(PL) of the program. The highest priority level is 7 (PL7), the lowest is PL0.\n",
      "Figure.Processor status register (PSR).\n",
      "\n",
      "..Organization of MemoryFigure 9.2 shows the layout of the LC-3 memory.You know that the LC-3 has a 16-bit address space; ergo, memory locationsfrom x0000 to xFFFF. Locations x0000 to x2FFF are privileged memory loca-tions. They contain the various data structures and code of the operating system.They require supervisor privilege to access. They are referred to assystem space.Locations x3000 to xFDFF are unprivileged memory locations. Supervisorprivilege is not required to access these memory locations. All user programs anddata use this region of memory. The region is often referred to asuser space.Addresses xFE00 to xFFFF do not correspond to memory locations at all.That is, the last address of a memory location is xFDFF. Addresses xFE00 toxFFFF are used to identify registers that take part in input and output functionsand some special registers associated with the processor. For example, the PSRis assigned address xFFFC, and the processor’s Master Control Register (MCR)is assigned address xFFFE. The beneﬁt of assigning addresses from the memoryaddress space will be discussed in Section 9.2.1.2. The set of addresses fromxFE00 to xFFFF is usually referred to as the I/O page since most of the addressesare used for identif in re isters that take art in in ut or out ut functions. Access\n",
      "Figure.Regions of memory.\n",
      "\n",
      "operating system and requires supervisor privilege to access. The user stack iscontrolled by the user program and does not require privilege to access.Each has a stack pointer, Supervisor Stack Pointer (SSP) and User StackPointer (USP), to indicate the top of the stack. Since a program can only executein Supervisor mode or User mode at any one time, only one of the two stacks isactive at any one time. Register 6 is generally used as the stack pointer (SP) forthe active stack. Two registers, SavedSSP and SavedUSP, are provided to savethe SP not in use. When privilege changes, for example, from Supervisor mode toUser mode, the SP is stored in SavedSSP, and the SP is loaded from SavedUSP..Input/OutputInput and output devices (keyboards, monitors, disks, or kiosks at the shoppingmall) all handle input or output data using registers that are tailored to the needsof each particular input or output device. Even the simplest I/O devices usuallyneed at least two registers: one to hold the data being transferred between thedevice and the computer, and one to indicate status information about the device.An example of status information is whether the device is available or is it stillbusy processing the most recent I/O task...Some Basic Characteristics of I/OAll I/O activity is controlled by instructions in the computer’s ISA. Does the ISAneed special instructions for dealing with I/O? Does the I/O device execute at thesame speed as the computer, and if not, what manages the diﬀerence in speeds? Isthe transfer of information between the computer and the I/O device initiated bya program executing in the computer, or is it initiated by the I/O device? Answersto these questions form some of the basic characteristics of I/O activity....Memory-Mapped I/O vs. Special I/O InstructionsAn instruction that interacts with an input or output device register must identifythe particular input or output device register with which it is interacting. Twoschemes have been used in the past. Some computers use special input and outputinstructions. Most computers prefer to use the same data movement instructionsthat are used to move data in and out of memory.The very old PDP-8 (from Digital Equipment Corporation, more than 50years ago—1965) is an example of a computer that used special input and outputinstructions. The 12-bit PDP-8 instruction contained a three-bit opcode. If theopcode was 110, an I/O instruction was indicated. The remaining nine bits of thePDP-8 instruction identiﬁed which I/O device register and what operation was tobe performed.Most computer designers prefer not to specify an additional set of instructionsfor dealing with input and output. They use the same data movement instructionsthat are used for loading and storing data between memory and the general pur-pose registers. For example, a load instruction (LD, LDI, or LDR), in which the\n",
      "\n",
      "source address is that of an input device register, is an input instruction. Similarly,as t o r ei n s t r u c t i o n( S T ,S T I ,o rS T R )i nw h i c ht h ed e s t i n a t i o na d d r e s si st h a to fan output device register is an output instruction.Since programmers use the same data movement instructions that are usedfor memory, every input device register and every output device register must beuniquely identiﬁed in the same way that memory locations are uniquely identiﬁed.Therefore, each device register is assigned an address from the memory addressspace of the ISA. That is, the I/O device registers aremappedto a set of addressesthat are allocated to I/O device registers rather than to memory locations. Hencethe namememory-mapped I/O.The original PDP-11 ISA had a 16-bit address space. All addresses whereinbits [15:13]=111 were allocated to I/O device registers. That is, of the 216addresses, only 57,344 corresponded to memory locations. The remaining 213were memory-mapped I/O addresses.The LC-3 uses memory-mapped I/O. As we discussed in Section 9.1.2,addresses x0000 to xFDFF refer to actual memory locations. Addresses xFE00 toxFFFF are reserved for input/output device registers. Table A.3 lists the memory-mapped addresses of the LC-3 device registers that have been assigned so far.Future uses and future sales of LC-3 microprocessors may require the expansionof device register address assignments as new and exciting applications emerge!...Asynchronous vs. SynchronousMost I/O is carried out at speeds very much slower than the speed of the processor.At y p i s t ,t y p i n go nak e y b o a r d ,l o a d sa ni n p u td e v i c er e g i s t e rw i t ho n eA S C I Icode every time he/she types a character. A computer can read the contents ofthat device register every time it executes a load instruction, where the operandaddress is the memory-mapped address of that input device register.Many of today’s microprocessors execute instructions under the control of aclock that operates well in excess of 2 GHz. Even for a microprocessor operatingat only 2 GHz, a clock cycle lasts only 0.5 nanoseconds. Suppose a processorexecuted one instruction at a time, and it took the processor ten clock cycles toexecute the instruction that reads the input device register and stores its contents.At that rate, the processor could read the contents of the input device register onceevery 5 nanoseconds. Unfortunately, people do not type fast enough to keep thisprocessor busy full-time reading characters.Question:How fast would a personhave to type to supply input characters to the processor at the maximum rate theprocessor can receive them?We could mitigate this speed disparity by designing hardware that wouldaccept typed characters at some slower ﬁxed rate. For example, we could designa piece of hardware that accepts one character every 200 million cycles. Thiswould require a typing speed of 100 words/minute, assuming words on averageconsisted of ﬁve letters, which is certainly doable. Unfortunately, it would alsorequire that the typist work in lockstep with the computer’s clock. That is notacceptable since the typing speed (even of the same typist) varies from momentto moment.What’s the point? The point is that I/O devices usually operate at speedsvery diﬀerent from that of a microprocessor, and not in lockstep. We call this\n",
      "\n",
      "latter characteristicasynchronous.M o s ti n t e r a c t i o nb e t w e e nap r o c e s s o ra n dI / Ois asynchronous. To control processing in an asynchronous world requires someprotocol orhandshakingmechanism. So it is with our keyboard and monitor. Inthe case of the keyboard, we will need a one-bit status register, called aﬂag,toindicate if someone has or has not typed a character. In the case of the monitor,we will need a one-bit status register to indicate whether or not the most recentcharacter sent to the monitor has been displayed, and so the monitor can be givenanother character to display.These ﬂags are the simplest form ofsynchronization.As i n g l eﬂ a g ,c a l l e dtheready bit, is enough to synchronize the output of the typist who can typecharacters at the rate of 100 words/minute with the input to a processor that canaccept these characters at the rate of 200 million characters/second. Each timethe typist types a character, the ready bit is set to 1. Each time the computer readsac h a r a c t e r ,i tc l e a r st h er e a d yb i t .B ye x a m i n i n gt h er e a d yb i tb e f o r er e a d i n gac h a r a c t e r ,t h ec o m p u t e rc a nt e l lw h e t h e ri th a sa l r e a d yr e a dt h el a s tc h a r a c t e rtyped. If the ready bit is clear, no characters have been typed since the last timethe computer read a character, and so no additional read would take place. Whenthe computer detects that the ready bit is set, it could only have been caused by anewcharacter being typed, so the computer would know to again read a character.The single ready bit provides enough handshaking to ensure that the asyn-chronous transfer of information between the typist and the microprocessor canbe carried out accurately.If the typist could type at a constant speed, and we did have a piece of hard-ware that would accept typed characters at precise intervals (e.g., one characterevery 200 million cycles), then we would not need the ready bit. The computerwould simply know, after 200 million cycles of doing other stuﬀ, that the typisthad typed exactly one more character, and the computer would read that charac-ter. In this hypothetical situation, the typist would be typing in lockstep with theprocessor, and no additional synchronization would be needed. We would say thecomputer and typist were operatingsynchronously.T h a ti s ,t h ei n p u ta c t i v i t yw a ssynchronous....Interrupt-Driven vs. PollingThe processor, which is computing, and the typist, who is typing, are two separateentities. Each is doing its own thing. Still, they need to interact; that is, the data thatis typed has to get into the computer. The issue ofinterrupt-drivenvs.pollingisthe issue of who controls the interaction. Does the processor do its own thing untilbeing interrupted by an announcement from the keyboard, “Hey, a key has beenstruck. The ASCII code is in the input device register. You need to read it.” This iscalledinterrupt-driven I/O,w h e r et h ek e y b o a r dc o n t r o l st h ei n t e r a c t i o n .O r ,d o e sthe processor control the interaction, specifically by interrogating (usually, againand again) the ready bit until it (the processor) detects that the ready bit is set. Atthat point, the processor knows it is time to read the device register. This secondtype of interaction when the processor is in charge is calledpolling,s i n c et h er e a d ybit is polled by the processor, asking if any key has been struck.Section 9.2.2.2 describes how polling works. Section 9.4 explains interrupt-driven I/O.\n",
      "\n",
      "..Input from the Keyboard...Basic Input Registers (KBDR and KBSR)We have already noted that in order to handle character input from the keyboard,we need two things: a data register that contains the character to be input andas y n c h r o n i z a t i o nm e c h a n i s mt ol e tt h ep r o c e s s o rk n o wt h a ti n p u th a so c c u r r e d .The synchronization mechanism is contained in the status register associated withthe keyboard.These two registers are called thekeyboard data register(KBDR) and the\n",
      "KBSRFigure.Keyboard device registers.Even though a character needs only 8 bits and the synchronization mecha-nism needs only 1 bit, it is easier to assign 16 bits (like all memory addressesin the LC-3) to each. In the case of KBDR, bits [7:0] are used for the data, andbits [15:8] contain x00. In the case of KBSR, bit [15] contains the synchroniza-tion mechanism, that is, the ready bit. Figure 9.3 shows the two device registersneeded by the keyboard....The Basic Input Service RoutineKBSR[15] controls the synchronization of the slow keyboard and the fast pro-cessor. When a key on the keyboard is struck, the ASCII code for that key isloaded into KBDR[7:0], and the electronic circuits associated with the keyboardautomatically set KBSR[15] to 1. When the LC-3 reads KBDR, the electroniccircuits associated with the keyboard automatically clear KBSR[15], allowinganother key to be struck. If KBSR[15]=1, the ASCII code corresponding to thelast key struck has not yet been read, and so the keyboard is disabled; that is, nokey can be struck until the last key is read.If input/output is controlled by the processor (i.e., via polling), then a pro-gram can repeatedly test KBSR[15] until it notes that the bit is set. At that point,the processor can load the ASCII code contained in KBDR into one of the LC-3registers. Since the processor only loads the ASCII code if KBSR[15] is 1, there isno danger of reading a single typed character multiple times. Furthermore, sincethe keyboard is disabled until the previous code is read, there is no danger of theprocessor missing characters that were typed. In this way, KBSR[15] providesthe mechanism to guarantee that each key typed will be loaded exactly once.\n",
      "\n",
      ",04 BRnzp NEXT_TASK ; Go to the next task05 A .FILL xFE00 ; Address of KBSR06 B .FILL xFE02 ; Address of KBDRAs long as KBSR[15] is 0, no key has been struck since the last time the processorread the data register. Lines 01 and 02 comprise a loop that tests bit [15] of KBSR.Note the use of the LDI instruction, which loads R1 with the contents of xFE00,the memory-mapped address of KBSR. If the ready bit, bit [15], is clear, BRzpwill branch to START and another iteration of the loop. When someone strikes akey, KBDR will be loaded with the ASCII code of that key, and the ready bit ofKBSR will be set. This will cause the branch to fall through, and the instructionat line 03 will be executed. Again, note the use of the LDI instruction, whichthis time loads R0 with the contents of xFE02, the memory-mapped address ofKBDR. The input routine is now done, so the program branches unconditionallyto its NEXTTASK.\n",
      "Figure.Memory-mapped input.\n",
      "\n",
      "carry out the EXECUTE phase of the load instructions. Essentially three stepsare required:1. The MAR is loaded with the address of the memory location to be read.2. Memory is read, resulting in MDR being loaded with the contents at thespeciﬁed memory location.3. The destination register (DR) is loaded with the contents of MDR.In the case of memory-mapped input, the same steps are carried out,exceptinstead of MAR being loaded with the address of a memory location, MAR isloaded with the address of a device register. Instead of the address control logicenabling memory to read, the address control logic selects the correspondingdevice register to provide input to the MDR...Output to the Monitor...Basic Output Registers (DDR and DSR)Out ut works in a wa ver similar to in ut with DDR and DSR re lacin the\n",
      "DSRFigure.Monitor device registers.As is the case with input, even though an output character needs only 8 bitsand the synchronization mechanism needs only one bit, it is easier to assign16 bits (like all memory addresses in the LC-3) to each output device register.In the case of DDR, bits [7:0] are used for data, and bits [15:8] contain x00. Inthe case of DSR, bit [15] contains the synchronization mechanism, that is, theready bit. Figure 9.5 shows the two device registers needed by the monitor....The Basic Output Service RoutineDSR[15] controls the synchronization of the fast processor and the slow monitordisplay. When the LC-3 transfers an ASCII code to DDR[7:0] for outputting, theelectronics of the monitor automatically clear DSR[15] as the processing of thecontents of DDR[7:0] begins. When the monitor ﬁnishes processing the characteron the screen, it (the monitor) automatically sets DSR[15]. This is a signal tothe processor that it (the processor) can transfer another ASCII code to DDRfor outputting. As long as DSR[15] is clear, the monitor is still processing theprevious character, so the monitor is disabled as far as additional output from theprocessor is concerned.\n",
      "\n",
      "If input/output is controlled by the processor (i.e., via polling), a program can\n",
      ",04 BRnzp NEXT_TASK05 A .FILL xFE04 ; Address of DSR06 B .FILL xFE06 ; Address of DDRLike the routine for KBDR and KBSR in Section 9.2.2.2, lines 01 and 02 repeat-edly poll DSR[15] to see if the monitor electronics is ﬁnished with the lastcharacter shipped by the processor. Note the use of LDI and the indirect accessto xFE04, the memory-mapped address of DSR. As long as DSR[15] is clear,the monitor electronics is still processing this character, and BRzp branches toSTART for another iteration of the loop. When the monitor electronics ﬁnisheswith the last character shipped by the processor, it automatically sets DSR[15]to 1, which causes the branch to fall through and the instruction at line 03 to beexecuted. Note the use of the STI instruction, which stores R0 into xFE06, thememory-mapped address of DDR. The write to DDR also clears DSR[15], dis-abling for the moment DDR from further output. The monitor electronics takesover and writes the character to the screen. Since the output routine is now done,the program unconditionally branches (line 04) to its NEXTTASK....Implementation of Memory-Mapped OutputFigure 9.6 shows the additional data path required to implement memory-mappedoutput. As we discussed previously with respect to memory-mapped input,the mechanisms for handling the device registers provide very little additionalcomplexity to what already exists for handling memory accesses.In Chapter 5, you became familiar with the process of carrying out theEXECUTE phase of the store instructions.1. The MAR is loaded with the address of the memory location to be written.2. The MDR is loaded with the data to be written to memory.3. Memory is written, resulting in the contents of MDR being stored in thespeciﬁed memory location.In the case of memory-mapped output, the same steps are carried out,exceptinstead of MAR being loaded with the address of a memory location, MAR isloaded with the address of a device register. Instead of the address control logicenabling memory to write, the address control logic asserts the load enable signalof DDR.Memory-mapped output also requires the ability toreadoutput device reg-isters. You saw in Section 9.2.3.2 that before the DDR could be loaded, the ready\n",
      "\n",
      "\n",
      "INMUXFigure.Memory-mapped output.bit had to be in state 1, indicating that the previous character had already ﬁn-ished being written to the screen. The LDI and BRzp instructions on lines 01and 02 perform that test. To do this, the LDI reads the output device registerDSR, and BRzp tests bit [15]. If the MAR is loaded with xFE04 (the memory-mapped address of the DSR), the address control logic selects DSR as the inputto the MDR, where it is subsequently loaded into R1, and the condition codesare set....Example: Keyboard EchoWhen we type at the keyboard, it is helpful to know exactly what characters we\n",
      "0B DDR .FILL xFE06 ; Address of DDR\n",
      "\n",
      "..A More Sophisticated Input RoutineIn the example of Section 9.2.2.2, the input routine would be a part of a programbeing executed by the computer. Presumably, the program requires character inputfrom the keyboard. But how does the person sitting at the keyboard know when totype a character? Sitting there, the person may wonder whether or not the programis actually running, or if perhaps the computer is busy doing something else.To let the person sitting at the keyboard know that the program is waiting forinput from the keyboard, the computer typically prints a message on the monitor.Such a message is often referred to as aprompt.T h es y m b o l st h a ta r ed i s p l a y e dby your operating system (e.g.,%orC:) or by your editor (e.g.,:) are examplesof prompts.The program fragment shown in Figure 9.7 obtains keyboard input viapolling as we have shown in Section 9.2.2.2. It also includes a prompt to let theperson sitting at the keyboard know when it is time to type a key. Let’s examinethis program fragment.You are already familiar with lines 13 through 19 and lines 25 through 28,which correspond to the code in Section 9.2.3.4 for inputting a character via thekeyboard and echoing it on the monitor.You are also familiar with the need to save and restore registers if those reg-isters are needed by instructions in the input routine. Lines 01 through 03 saveR1, R2, and R3, lines 1D through 1F restore R1, R2, and R3, and lines 22 through24 set aside memory locations for those register values.This leaves lines 05 through 08, 0A through 11, 1A through 1C, 29 and 2A.These lines serve to alert the person sitting at the keyboard that it is time to typeac h a r a c t e r .Lines 05 through 08 write the ASCII code x0A to the monitor. This is theASCII code for anew line.M o s tA S C I Ic o d e sc o r r e s p o n dt oc h a r a c t e r st h a ta r evisible on the screen. A few, like x0A, are control characters. They cause an actionto occur. Speciﬁcally, the ASCII code x0A causes the cursor to move to the farleft of the next line on the screen. Thus, the nameNewline. Before attemptingto write x0A, however, as is always the case, DSR[15] is tested (line 6) to seeif DDR can accept a character. If DSR[15] is clear, the monitor is busy, and theloop (lines 06 and 07) is repeated. When DSR[15] is 1, the conditional branch(line 7) is not taken, and (line 8) x0A is written to DDR for outputting.Lines 0A through 11 cause the promptInput a character>to be writtento the screen. The prompt is specified by the .STRINGZ pseudo-op on line 2Aand is stored in 19 memory locations—18 ASCII codes, one per memory location,corresponding to the 18 characters in the prompt, and the terminating sentinelx0000.Line 0C iteratively tests to see if the end of the string has been reached (bydetecting x0000), and if not, once DDR is free, line 0F writes the next characterin the input prompt into DDR. When x0000 is detected, the entire input prompthas been written to the screen, and the program branches to the code that handlesthe actual keyboard input (starting at line 13).After the person at the keyboard types a character and it has been echoed(lines 13 to 19), the program writes one more new line (lines 1A through 1C)before branching to its NEXTTASK.\n",
      "\n",
      "\n",
      "ew ne . x ; co e or new ne2A Prompt .STRINGZ ''Input a character>''Figure.The more sophisticated input routine...Implementation of Memory-Mapped I/O, RevisitedWe showed in Figures 9.4 and 9.6 partial implementations of the data path tohandle (separately) memory-mapped input and memory-mapped output. We havealso learned that in order to support interrupt-driven I/O, the two status registersmust be writeable as well as readable.\n",
      "\n",
      "INMUXFigure.Relevant data path implementation of memory-mapped I/O.Figure 9.8 (also shown as Figure C.3 of Appendix C) shows the data pathnecessary to support the full range of features we have discussed for the I/O deviceregisters. The Address Control Logic Block controls the input or output operation.Note that there are three inputs to this block. MIO.EN indicates whether a datamovement from/to memory or I/O is to take place this clock cycle. MAR containsthe address of the memory location or the memory-mapped address of an I/O deviceregister. R.W indicates whether a load or a store is to take place. Depending on thevalues of these three inputs, the address control logic does nothing (MIO.EN=0),or it provides the control signals to direct the transfer of data between the MDRand the memory or between the MDR and one of the I/O registers.If R.W indicates a load, the transfer is from memory or I/O device to theMDR. The Address Control Logic Block provides the select lines to INMUX tosource the appropriate I/O device register or memory (depending on MAR) andalso enables the memory if MAR contains the address of a memory location.If R.W indicates a store, the contents of the MDR is written either to memoryor to one of the device registers. The address control logic either enables a writeto memory or asserts the load enable line of the device register speciﬁed by thecontents of the MAR..Operating System ServiceRoutines (LC-Trap Routines)..IntroductionRecall Figure 9.7 of the previous section. In order for the program to successfullyobtain input from the keyboard, it was necessary for the programmer to knowseveral things:1. The hardware data registers for both the monitor and the keyboard: themonitor so a prompt could be displayed, and the keyboard so the programwould know where to get the input character.\n",
      "\n",
      "2. The hardware status registers for both the monitor and the keyboard: themonitor so the program would know when it was OK to display the nextcharacter in the input prompt, and the keyboard so the program would knowwhen someone had struck a key.3. The asynchronous nature of keyboard input relative to the executing program.This is beyond the knowledge of most application programmers. In fact, in thereal world, if application programmers (or user programmers, as they are some-times called) had to understand I/O at this level, there would be much less I/Oand far fewer programmers in the business.There is another problem with allowing user programs to perform I/O activityby directly accessing KBDR and KBSR. I/O activity involves the use of deviceregisters that are shared by many programs. This means that if a user programmerwere allowed to access the hardware registers, and he/she messed up, it couldcreate havoc for other user programs. Thus, in general it is ill-advised to giveuser programmers access to these registers. That is why the addresses of hardwareregisters are part of the privileged memory address space and accessible only toprograms that have supervisor privilege.The simpler solution, as well as the safer solution to the problem of userprograms requiring I/O, involves the TRAP instruction and the operating system,which of course has supervisor privilege.We were ﬁrst introduced to the TRAP instruction in Chapter 4 as a way toget the operating system to halt the computer. In Chapter 5 we saw that a userprogram could use the TRAP instruction to get the operating system to do I/Otasks for it (the user program). In fact a great beneﬁt of the TRAP instruction,which we have already pointed out, is that it allows the user programmer to nothave to know the gory details of I/O discussed earlier in this chapter. In addition,\n",
      "Figure.Invoking an OS service routine using the TRAP instruction.\n",
      "\n",
      "operating system to perform the task on behalf of the user program. The operatingsystem takes control of the computer, handles the request speciﬁed by the TRAPinstruction, and then returns control back to the user program at location x4001.As we said at the start of this chapter, we usually refer to the request made by theuser program as asystem callor aservice call...The Trap MechanismThe trap mechanism involves several elements:1.As e to fs e r v i c er o u t i n e sexecuted on behalf of user programs by theoperating system. These are part of the operating system and start atarbitrary addresses in system space. The LC-3 was designed so that up to256 service routines can be speciﬁed. Table A.2 in Appendix A contains theLC-3’s current complete list of operating system service routines.2.A table of the starting addressesof these 256 service routines. This tableis stored in memory locations x0000 to x00FF. The table is referred to byvarious names by various companies. One company calls this table theSystem Control Block. Another company calls it the Trap Vector Table.Figure 9.10 shows the Trap Vector Table of the LC-3, with speciﬁc startingaddresses highlighted. Among the starting addresses are the one for thecharacter output service routine (memory location x0420), which is stored\n",
      "Figure.The Trap Vector Table.\n",
      "\n",
      "3.The TRAP instruction.When a user program wishes to have the operatingsystem execute a speciﬁc service routine on behalf of the user program, andthen return control to the user program, the user program uses the TRAPinstruction (as we have been doing since Chapter 4).4.Al i n k a g eback to the user program. The service routine must have amechanism for returning control to the user program...The TRAP InstructionThe TRAP instruction causes the service routine to execute by (1) changing thePC to the starting address of the relevant service routine on the basis of its trapvector, and (2) providing a way to get back to the program that executed the TRAPinstruction. The “way back” is referred to as alinkage.15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 01111000 000100011TRAP trap vectorThe EXECUTE phase of the TRAP instruction’s instruction cycle doesthree things:1. The PSR and PC are both pushed onto the system stack. Since the PC wasincremented during the FETCH phase of the TRAP instruction’s instructioncycle, the return linkage is automatically saved in the PC. When controlreturns to the user program, the PC will automatically be pointing to theinstruction following the TRAP instruction.Note that the program requesting the trap service routine can be runningeither in Supervisor mode or in User mode. If in User mode, R6, the stackpointer, is pointing to the user stack. Before the PSR and PC can bepushed onto the system stack, the current contents of R6 must be storedin SavedUSP, and the contents of SavedSSP loaded into R6.2. PSR[15] is set to 0, since the service routine is going to require supervisorprivilege to execute. PSR[10:8] are left unchanged since the priority of theTRAP routine is the same as the priority of the program that requested it.3. The 8-bit trap vector is zero-extended to 16 bits to form an address thatcorresponds to a location in the Trap Vector Table. For the trap vector x23,that address is x0023. Memory location x0023 contains x04A0, the startingaddress of the TRAP x23 service routine. The PC is loaded with x04A0,completing the instruction cycle.Since the PC contains x04A0, processing continues at memory addressx04A0.\n",
      "\n",
      "Location x04A0 is the starting address of the operating system service rou-tine to input a character from the keyboard. We say the trap vector “points” tothe starting address of the TRAP routine. Thus, TRAP x23 causes the operatingsystem to start executing the keyboard input service routine...The RTI Instruction: To Return Controlto the Calling Program15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0100000 0 0 0 0 0 0 0 0 0 0RTIThe RTI instruction (opcode =1000,w i t hn oo p e r a n d s )p o p st h et o pt w ovalues on the system stack into the PC and PSR. Since the PC contains the addressfollowing the address of the TRAP instruction, control returns to the user programat the correct address.Finally, once the PSR has been popped oﬀthe system stack, PSR[15] mustbe examined to see whether the processor was running in User mode or Super-visor mode when the TRAP instruction was executed. If in User mode, the stackpointers need to be adjusted to reﬂect that now back in User mode, the relevantstack in use is the user stack. This is done by loading the SavedSSP with thecurrent contents of R6, and loading R6 with the contents of SavedUSP...A Summary of the Trap Service Routine ProcessFigure 9.11 shows the LC-3 using the TRAP instruction and the RTI instruction toimplement the example of Figure 9.9. The ﬂow of control goes from (A) within auser program that needs a character input from the keyboard, to (B) the operatingsystem service routine that performs that task on behalf of the user program,back to the user program (C) that presumably uses the information contained inthe input character.As we know, the computer continually executes its instruction cycle (FETCH,DECODE, etc.) on sequentially located instructions until the flow of control ischanged by changing the contents of the PC during the EXECUTE phase of thecurrent instruction. In that way, the next FETCH will be at a redirected address.The TRAP instruction with trap vector x23 in our user program does exactlythat. Execution of TRAP x23 causes the PSR and incremented PC to be pushedonto the system stack and the contents of memory location x0023 (which, in thiscase, contains x04A0) to be loaded into the PC. The dashed line on Figure 9.11shows the use of the trap vector x23 to obtain the starting address of the trapservice routine from the Trap Vector Table.The next instruction cycle starts with the FETCH of the contents of x04A0,which is the ﬁrst instruction of the relevant operating system service routine.The trap service routine executes to completion, ending with the RTI instruction,\n",
      "\n",
      "\n",
      "Figure.Flow of control from a user program to an OS service routine and back.which loads the PC and PSR with the top two elements on the system stack, that is,the PSR and incremented PC that were pushed during execution of the TRAPinstruction. Since the PC was incremented prior to being pushed onto the systemstack, it contains the address of the instruction following the TRAP instructionin the calling program, and the user program resumes execution by fetching theinstruction following the TRAP instruction.The following program is provided to illustrate the use of the TRAP instruc-tion. It can also be used to amuse the average four-year-old!Example.Write a game program to do the following: A person is sitting at a keyboard. Eachtime the person types a capital letter, the program outputs the lowercase version ofthat letter. If the person types a 7, the program terminates.The following LC-3 assembly language program will do the job.01 .ORIG x300002 LD R2,TERM ; Load -703 LD R3,ASCII ; Load ASCII difference04 AGAIN TRAP x23 ; Request keyboard input05 ADD R1,R2,R0 ; Test for terminating06 BRz EXIT ; character07 ADD R0,R0,R3 ; Change to lowercase08 TRAP x21 ; Output to the monitor09 BRnzp AGAIN ; ... and do it again!0A TERM .FILL xFFC9 ; FFC9 is negative of ASCII 70B ASCII .FILL x00200C EXIT TRAP x25 ; Halt0D .END\n",
      "\n",
      "The program executes as follows: The program ﬁrst loads constants xFFC9 andx0020 into R2 and R3. The constant xFFC9, which is the negative of the ASCII codefor 7, is used to test the character typed at the keyboard to see if the four-year-old wantsto continue playing. The constant x0020 is the zero-extended diﬀerence between theASCII code for a capital letter and the ASCII code for that same letter’s lowercaserepresentation. For example, the ASCII code forAis x41; the ASCII code foraisx61. The ASCII codes forZandzare x5A and x7A, respectively.Then TRAP x23 is executed, which invokes the keyboard input service routine.When the service routine is ﬁnished, control returns to the application program (atline 05), and R0 contains the ASCII code of the character typed. The ADD andBRz instructions test for the terminating character 7. If the character typed is not a7, the ASCII uppercase/lowercase diﬀerence (x0020) is added to the input ASCIIcode, storing the result in R0. Then a TRAP to the monitor output service routine iscalled. This causes the lowercase representation of the same letter to be displayed onthe monitor. When control returns to the application program (this time at line 09),an unconditional BR to AGAIN is executed, and another request for keyboard inputappears.The correct operation of the program in this example assumes that the per-son sitting at the keyboard only types capital letters and the value 7. What if theperson types a $? A better solution to Example 9.1 would be a program that teststhe character typed to be sure it really is a capital letter from among the 26 cap-ital letters in the alphabet or the single digit 7, and if it is not, takes correctiveaction.Question:Augment this program to add the test for bad data. That is, write aprogram that will type the lowercase representation of any capital letter typed andwill terminate if anything other than a capital letter is typed. See Exercise 9.20...Trap Routines for Handling I/OWith the constructs just provided, the input routine described in Figure 9.7 canbe slightly modiﬁed to be the input service routine shown in Figure 9.12. Twochanges are needed: (1) We add the appropriate .ORIG and .END pseudo-ops..ORIG speciﬁes the starting address of the input service routine—the addressfound at location x0023 in the Trap Vector Table. And (2) we terminate theinput service routine with the RTI instruction rather than the BR NEXTTASK,as is done on line 20 in Figure 9.7. We use RTI because the service routine isinvoked by TRAP x23. It is not part of the user program, as was the case inFigure 9.7.The output routine of Section 9.2.3.2 can be modiﬁed in a similar way, asshown in Figure 9.13. The results are input (Figure 9.12) and output (Figure 9.13)service routines that can be invoked simply and safely by the TRAP instructionwith the appropriate trap vector. In the case of input, upon completion of TRAPx23, R0 contains the ASCII code of the keyboard character typed. In the case ofoutput, the initiating program must load R0 with the ASCII code of the characterit wishes displayed on the monitor and then invoke TRAP x21.\n",
      "\n",
      "ave .0F .ENDFigure.Character output service routine...A Trap Routine for Halting the ComputerRecall from Section 4.5 that the RUN latch is ANDed with the crystal oscillatorto produce the clock that controls the operation of the computer. We noted that ifthat one-bit latch was cleared, the output of the AND gate would be 0, stoppingthe clock.Years ago, most ISAs had a HALT instruction for stopping the clock. Givenhow infrequently that instruction is executed, it seems wasteful to devote anoc o d e t o i t . I n m a n m o d e r n c o mu t e r s , t h e R U N l a t c h i s c l e a r e d b a T R A P\n",
      ",Figure.HALT service routine for the LC-(Fig..continued on next page.)\n",
      "\n",
      "\n",
      ".Figure.HALT service routine for the LC-(continued Fig..fromprevious page.)rst (lines 02 and 03), registers R1 and R0 are saved. R1 and R0 are savedse they are needed by the service routine. Then (lines 07 through 0C),nnerHalting the machineis displayed on the monitor. Finally (lines 10h 13), the RUN latch (MCR[15]) is cleared by ANDing the MCR with0111111111111111. That is, MCR[14:0] remains unchanged, but MCR[15] iscleared.Question:W h a ti n s t r u c t i o n( o rt r a ps e r v i c er o u t i n e )c a nb eu s e dt os t a r tthe clock?Hint:This is a trick question! :-)..The Trap Routine for Character Input (One Last Time)Let’s look again at the keyboard input service routine of Figure 9.12. In particular,let’s look at the three-line sequence that occurs at symbolic addresses L1, L2, L3,and L4:LABEL LDI R3,DSRBRzp LABELSTI Reg,DDRCan the JSR/RET mechanism enable us to replace these four occurrences of thesame sequence with a single subroutine?Answer:Yes,almost.Figure 9.15, our “improved” keyboard input service routine, containsJSR WriteCharat lines 04, 0A, 10, and 13, and the four-instruction subroutineWriteChar LDI R3,DSRBRzp WriteCharSTI R2,DDRRETat lines 1A through 1D. Note the RET instruction (a.k.a. JMP R7) that is neededto terminate the subroutine.\n",
      "\n",
      "Note the hedging:almost. In the original sequences starting at L2 and L3,the STI instruction forwards the contents of R0 (not R2) to the DDR. We can ﬁxthat easily enough, as follows: In line 08 of Figure 9.15, we useLDR R2,R1,#0instead ofLDR R0,R1,#0This causes each character in the prompt to be loaded into R2. The subroutineWritechar forwards each character from R2 to the DDR.In line 0F of Figure 9.15, we insert the instructionADD R2,R0,#0in order to move the keyboard input (which is in R0) into R2. The subroutineWritechar forwards it from R2 to the DDR. Note that R0 still contains the key-board input. Furthermore, since no subsequent instruction in the service routineloads R0, R0 still contains the keyboard input after control returns to the userprogram.In line 12 of Figure 9.15, we insert the instructionLD R2,Newlinein order to move the “newline” character into R2. The subroutine Writecharforwards it from R2 to the DDR.Figure 9.15 is the actual LC-3 trap service routine provided for keyboardinput...PUTS: Writing a Character String to the MonitorBefore we leave the example of Figure 9.15, note the code on lines 08 through 0C.This fragment of the service routine is used to write the sequence of charactersInput a characterto the monitor. A sequence of characters is often referred toas astring of charactersor acharacter string.T h i sf r a g m e n ti sa l s op r e s e n ti nFigure 9.14, with the result thatHalting the machineis written to the monitor. Infact, it is so often the case that a user program needs to write a string of charactersto the monitor that this function is given its own trap service routine in the LC-3operating system. Thus, if a user program requires a character string to be writtento the monitor, it need only provide (in R0) the starting address of the characterstring, and then invoke TRAP x22. In LC-3 assembly language this TRAP iscalledPUTS.PUTS (or TRAP x22) causes control to be passed to the operating system,and the trap routine shown in Figure 9.16 is executed. Note that PUTS is the codeof lines 08 through 0C of Figure 9.15, with a few minor adjustments.\n",
      "\n",
      "1111111111111111F SaveR3 .FILL x000020 .ENDFigure.The LC-PUTS service routine..Interrupts and Interrupt-Driven I/OIn Section 9.2.1.3, we noted that interaction between the processor and an I/Odevice can be controlled by the processor (i.e., polling) or it can be controlled bythe I/O device (i.e., interrupt driven). In Sections 9.2.2, 9.2.3, and 9.2.4, we havestudied several examples of polling. In each case, the processor tested the readybit of the status register again and again, and when the ready bit was ﬁnally 1, theprocessor branched to the instruction that did the input or output operation.We are now ready to study the case where the interaction is controlled by theI/O device...What Is Interrupt-Driven I/O?The essence of interrupt-driven I/O is the notion that an I/O device that may ormay not have anything to do with the program that is running can (1) force the\n",
      "\n",
      "\n",
      "..Figure.Instruction execution ﬂow for interrupt-driven I/O.running program to stop, (2) have the processor execute a program that carries outthe needs of the I/O device, and then (3) have the stopped program resume exe-cution as if nothing had happened. These three stages of the instruction executionﬂow are shown in Figure 9.17.As far as Program A is concerned, the work carried out and the resultscomputed are no diﬀerent from what would have been the case if the interrupthad never happened; that is, as if the instruction execution ﬂow had been thefollowing:...Program A is executing instruction nProgram A is executing instruction n+1Program A is executing instruction n+2Program A is executing instruction n+3Program A is executing instruction n+4.....Why Have Interrupt-Driven I/O?As is undoubtedly clear, polling requires the processor to waste a lot of time spin-ning its wheels, re-executing again and again the LDI and BR instructions untilthe ready bit is set. With interrupt-driven I/O, none of that testing and branchinghas to go on. Interrupt-driven I/O allows the processor to spend its time doing\n",
      "\n",
      "what is hopefully useful work, executing some other program perhaps, until it isnotiﬁed that some I/O device needs attention.Example.Suppose we are asked to write a program that takes a sequence of 100 characterstyped on a keyboard and processes the information contained in those 100 characters.Assume the characters are typed at the rate of 80 words/minute, which correspondsto one character every 0.125 seconds. Assume the processing of the 100-charactersequence takes 12.49999 seconds, and that our program is to perform this process on1000 consecutive sequences. How long will it take our program to complete the task?(Why did we pick 12.49999? To make the numbers come out nice, of course.) :-)We could obtain each character input by polling, as in Section 9.2.2. If we did,we would waste a lot of time waiting for the “next” character to be typed. It wouldtake 100/uni22C50.125 or 12.5 seconds to get a 100-character sequence.On the other hand, if we use interrupt-driven I/O, the processor does not wasteany time re-executing the LDI and BR instructions while waiting for a character tobe typed. Rather, the processor can be busy working on the previous 100-charactersequence that was typed,exceptfor those very small fractions of time when it is inter-rupted by the I/O device to read the next character typed. Let’s say that to read the nextcharacter typed requires executing a ten-instruction program that takes on the aver-age 0.00000001 seconds to execute each instruction. That means 0.0000001 secondsfor each character typed, or 0.00001 seconds for the entire 100-character sequence.That is, with interrupt-driven I/O, since the processor is only needed when charactersare actually being read, the time required for each 100-character sequence is 0.00001seconds, instead of 12.50000 seconds. The remaining 12.49999 of every 12.50000seconds, the processor is available to do useful work. For example, it can process theprevious 100-character sequence.The bottom line: With polling, the time to complete the entire task for eachsequence is 24.9999 seconds, 12.5 seconds to obtain the 100 characters + 12.49999seconds to process them. With interrupt-driven I/O, the time to complete the entiretask for each sequence after the ﬁrst is 12.5 seconds, 0.00001 seconds to obtainthe characters + 12.49999 seconds to process them. For 1000 sequences, that is thediﬀerence between 7 hours and 312hours...Two Parts to the ProcessThere are two parts to interrupt-driven I/O:1. the mechanism that enables an I/O device to interrupt the processor, and2. the mechanism that handles the interrupt request...Part I: Causing the Interrupt to OccurSeveral things must be true for an I/O device to actually interrupt the programthat is running:1. The I/O devicemust wantservice.2. The devicemust have the rightto request the service.3. The device requestmust be more urgentthan what the processor iscurrently doing.\n",
      "\n",
      "If all three elements are present, the processor stops executing the programthat is running and takes care of the interrupt....The Interrupt Signal from the DeviceFor an I/O device to generate an interrupt request, the device must want service,and it must have the right to request that service.The Device Must Want ServiceWe have discussed that already in the study ofpolling. It is the ready bit of the KBSR or the DSR. That is, if the I/O device isthe keyboard, it wants service if someone has typed a character. If the I/O deviceis the monitor, it wants service (i.e., the next character to output) if the associatedelectronic circuits have successfully completed the display of the last character.In both cases, the I/O device wants service when the corresponding ready bit isset.The Device Must Have the Right to Request That ServiceThis is the interruptenable bit, which can be set or cleared by the processor (usually by the operatingsystem), depending on whether or not the processor wants to give the I/O devicethe ri ht to re uest service. In most I/O devices, this interru t enable IE bit is\n",
      "Interrupt signal to the processorFigure.Interrupt enable bits and their use.If the interrupt enable bit (bit [14]) is clear, it does not matter whether theready bit is set; the I/O device will not be able to interrupt the processor becauseit (the I/O device) has not been given the right to interrupt the processor. In thatcase, the program will have to poll the I/O device to determine if it is ready.If bit [14] is set, then interrupt-driven I/O is enabled. In that case, as soon assomeone types a key (or as soon as the monitor has ﬁnished processing the lastcharacter), bit [15] is set. In this case, the device wants service, and it has beengiven the right to request service. The AND gate is asserted, causing an interruptrequest to be generated from the I/O device....The Urgency of the RequestThe third element in the list of things that must be true for an I/O device to actuallyinterrupt the processor is that the request must be more urgent than the program\n",
      "\n",
      "that is currently executing. Recall from Section 9.1.1.2 that each program runsat a speciﬁed level of urgency called its priority level. To interrupt the runningprogram, the device must have a higher priority than the program that is currentlyrunning. Actually, there may be many devices that want to interrupt the processorat a speciﬁc time. To succeed, the device must have a higher priority level thanall other demands for use of the processor.Almost all computers have a set of priority levels that programs can run at.As we have already noted, the LC-3 has eight priority levels, PL0 to PL7. Thehigher the number, the more urgent the program. The PL of a program is usuallythe same as the PL (i.e., urgency) of the request to run that program. If a programis running at one PL, and a higher-level PL request wants the computer, the lower-priority program suspends processing until the higher-PL program executes andsatisﬁes its more urgent request. For example, a computer’s payroll program mayrun overnight, and at PL0. It has all night to ﬁnish—not terribly urgent. A programthat corrects for a nuclear plant current surge may run at PL6. We are perfectlyhappy to let the payroll wait while the nuclear power correction keeps us frombeing blown to bits.For our I/O device to successfully stop the processor and start an interrupt-driven I/O request, the priority of the request must be higher than the priorityof the program it wishes to interrupt. For example, we would not normally wantto allow a keyboard interrupt from a professor checking e-mail to interrupt thenuclear power correction program....The INT SignalTo stop the processor from continuing execution of its currently running programand service an interrupt request, the INT signal must be asserted. Figure 9.19 showswhat is required to assert the INT signal. Figure 9.19 shows the status registers ofseveral devices operating at various priority levels (PL). Any device that has bits [14]and [15] both set asserts its interrupt request signal. The interrupt request signals areinput to a priority encoder, a combinational logic structure that selects the highestpriority request from all those asserted. If the PL of that request is higher than the PLof the currently executing program, the INT signal is asserted....The Test for INTFinally, the test to enable the processor to stop and handle the interrupt. Recallfrom Chapter 4 that the instruction cycle continually sequences through thephases of the instruction cycle (FETCH, DECODE, EVALUATE ADDRESS,FETCH OPERAND, EXECUTE, and STORE RESULT). Each instructionchanges the state of the computer, and that change is completed at the end ofthe instruction cycle for that instruction. That is, in the last clock cycle before thecomputer returns to the FETCH phase for the next instruction, the computer isput in the state caused by the complete execution of the current instruction.Interrupts can happen at any time. They are asynchronous to the synchronousﬁnite state machine controlling the computer. For example, the interrupt signalcould occur when the instruction cycle is in its FETCH OPERAND phase. Ifwe stopped the currently executing program when the instruction cycle was in\n",
      "\n",
      "\n",
      "INTFigure.Generation of the INT signal.its FETCH OPERAND phase, we would have to keep track of what part of thecurrent instruction has executed and what part of the current instruction still haswork to do. It makes much more sense to ignore interrupt signals except whenwe are at an instruction boundary; that is, the current instruction has completed,and the next instruction has not yet started. Doing that means we do not have toworry about partially executed instructions, since the state of the computer is thestate created by the completion of the current instruction, period!The additional logic to test for the interrupt signal is to augment the laststate of the instruction cycle for each instruction with a test. Instead ofalwaysgoing from the last state of one instruction cycle to the ﬁrst state of the FETCHphase of the next instruction, the next state depends on the INT signal. If INTis not asserted, then it is business as usual, with the control unit returning to theFETCH phase to start processing the next instruction. If INT is asserted, then thenext state is the ﬁrst state of Part II, handling the interrupt request...Part II: Handling the Interrupt RequestHandling the interrupt request goes through three stages, as shown in Figure 9.17:1. Initiate the interrupt (three lines numbered 1 in Figure 9.17).2. Service the interrupt (four lines numbered 2 in Figure 9.17).3. Return from the interrupt (one line numbered 3 in Figure 9.17).We will discuss each.\n",
      "\n",
      "...Initiate the InterruptSince the INT signal was asserted, the processor does not return to the ﬁrst stateof the FETCH phase of the next instruction cycle, but rather begins a sequence ofactions to initiate the interrupt. The processor must do two things: (1) save thestate of the interrupted program so it can pick up where it left oﬀafter the require-ments of the interrupt have been completed, and (2) load the state of the higherpriority interrupting program so it can start satisfying its request.Save the State of the Interrupted ProgramThe state of a program is a snap-shot of the contents of all the program’s resources. It includes the contents of thememory locations that are part of the program and the contents of all the generalpurpose registers. It also includes the PC and PSR.Recall from Figure 9.1 in Section 9.1.1.4 that a program’s PSR speciﬁesthe privilege level and priority level of that program. PSR[15] indicates whetherthe program is running in privileged (Supervisor) or unprivileged (User) mode.PSR[10:8] speciﬁes the program’s priority level (PL), from PL0 (lowest) to PL7(highest). Also, PSR[2:0] is used to store the condition codes. PSR[2] is the Nbit, PSR[1] is the Z bit, and PSR[0] is the P bit.The ﬁrst step in initiating the interrupt is to save enough of the state of theprogram that is running so that it can continue where it left oﬀafter the I/O devicerequest has been satisﬁed. That means, in the case of the LC-3, saving the PC andthe PSR. The PC must be saved since it knows which instruction should be exe-cuted next when the interrupted program resumes execution. The condition codes(the N, Z, and P ﬂags) must be saved since they may be needed by a subsequentconditional branch instruction after the program resumes execution. The prioritylevel of the interrupted program must be saved because it speciﬁes the urgency ofthe interrupted program with respect to all other programs. When the interruptedprogram resumes execution, it is important to know what priority level programscan interrupt it and which ones cannot. Finally, the privilege level of the programmust be saved since it speciﬁes what processor resources the interrupted programcan and cannot access.Although many computers save the contents of the general purpose registers,we will not since we will assume that the service routine will always save thecontents of any general purpose register that it needs before using it, and thenrestore it before returning to the interrupted program. The only state informationthe LC-3 saves are the PC and PSR.The LC-3 saves this state information on the supervisor stack in the sameway the PC and PSR are saved when a TRAP instruction is executed. That is,before the interrupt service routine starts, if the interrupted program is in Usermode, the User Stack Pointer (USP) is stored in SavedUSP, and R6 is loaded withthe Supervisor Stack Pointer (SSP) from SavedSSP. Then the PSR and PC ofthe interrupted program are pushed onto the supervisor stack, where they remainunmolested while the service routine executes.Load the State of the Interrupt Service RoutineOnce the state of the inter-rupted program has been safely saved on the supervisor stack, the second step\n",
      "\n",
      "is to load the PC and PSR of the interrupt service routine. Interrupt service rou-tines are similar to the trap service routines we have already discussed. They areprogram fragments stored in system space. They service interrupt requests.Most processors use the mechanism ofvectored interrupts. You are famil-iar with this notion from your study of the trap vector contained in the TRAPinstruction. In the case of interrupts, the eight-bit vector is provided by the devicethat is requesting the processor be interrupted. That is, the I/O device trans-mits to the processor an eight-bit interrupt vector along with its interrupt requestsignal and its priority level. The interrupt vector corresponding to the highestpriority interrupt request is the one supplied to the processor. It is designatedINTV.If the interrupt is taken, the processor expands the 8-bit interrupt vector(INTV) to form a 16-bit address, which is an entry into the Interrupt VectorTable. You know that the Trap Vector Table consists of memory locations x0000to x00FF, each containing the starting address of a trap service routine. The Inter-rupt Vector Table consists of memory locations x0100 to x01FF, each containingthe starting address of an interrupt service routine. The processor loads the PCwith the contents of the location in the Interrupt Vector Table corresponding tothe address formed by expanding the interrupt vector INTV.For example, the LC-3 keyboard could interrupt the processor every time akey is pressed by someone sitting at the keyboard. The keyboard interrupt vectorwould indicate the location in the interrupt vector table that contains the startingaddress of the keyboard interrupt service routine.The PSR is loaded as follows: Since no instructions in the service routinehave yet executed, PSR[2:0] contains no meaningful information. We arbitrarilyload it initially with 010. Since the interrupt service routine runs in privilegedmode, PSR[15] is set to 0. PSR[10:8] is set to the priority level associated withthe interrupt request.This completes the initiation phase, and the interrupt service routine is readyto execute....Service the InterruptSince the PC contains the starting address of the interrupt service routine, theservice routine will execute, and the requirements of the I/O device will beserviced....Return from the InterruptThe last instruction in every interrupt service routine is RTI, return from trapor interrupt. When the processor ﬁnally accesses the RTI instruction, all therequirements of the I/O device have been taken care of.Like the return from a trap routine discussed in Section 9.3.4, execution oftheRTIinstruction (opcode=1000) for an interrupt service routine consistssimply of popping the PC and the PSR from the supervisor stack (where theyhave been resting peacefully) and restoring them to their rightful places in the\n",
      "\n",
      "processor. The condition codes are now restored to what they were when theprogram was interrupted, in case they are needed by a subsequent BR instructionin the interrupted program. PSR[15] and PSR[10:8] now reﬂect the privilege leveland priority level of the about-to-be-resumed program. If the privilege level ofthe interrupted program is unprivileged, the stack pointers must be adjusted, thatis, the Supervisor Stack Pointer saved, and the User Stack Pointer loaded into R6.The PC is restored to the address of the instruction that would have been executednext if the program had not been interrupted.With all these things as they were before the interrupt occurred, the programcan resume as if nothing had happened...An ExampleWe complete the discussion of interrupt-driven I/O with an example.Suppose program A is executing when I/O device B, having a PL higher\n",
      "Figure.Execution ﬂow for interrupt-driven I/O.Program A consists of instructions in locations x3000 to x3010 and was inthe middle of executing the ADD instruction at x3006 when device B sent itsinterrupt request signal and accompanying interrupt vector xF1, causing INT tobe asserted.Note that the interrupt service routine for device B is stored in locationsx6200 to x6210; x6210 contains the RTI instruction. Note that the service routine\n",
      "\n",
      "for B was in the middle of executing the AND instruction at x6202 when deviceCs e n ti t si n t e r r u p tr e q u e s ts i g n a la n da c c o m p a n y i n gi n t e r r u p tv e c t o rx F 2 .S i n c ethe request associated with device C is of a higher priority than that of device B,INT is again asserted.Note that the interrupt service routine for device C is stored in locationsx6300 to x6315; x6315 contains the RTI instruction.Let us examine the order of execution by the processor. Figure 9.21 showsseveral snapshots of the contents of the supervisor stack and the PC during theexecution of this example.The processor executes as follows: Figure 9.21a shows the supervisor stackand the PC before program A fetches the instruction at x3006. Note that the stackpointer is shown as SavedSSP, not R6. Since the interrupt has not yet occurred,\n",
      "Figure.Snapshots of the contents of the supervisor stack and the PC duringinterrupt-driven I/O.\n",
      "\n",
      "saved on the supervisor stack, the ﬁrst step is to start using the supervisor stack.This is done by saving R6 in the Saved.UPC register and loading R6 with thecontents of the SavedSSP register. The PSR of program A, which includes thecondition codes produced by the ADD instruction, is pushed on the supervisorstack. Then the address x3007, the PC for the next instruction to be executed inprogram A is pushed on the stack. The interrupt vector associated with device Bis expanded to 16 bits x01F1, and the contents of x01F1 (x6200) is loaded intothe PC. Figure 9.21b shows the stack and PC at this point.The service routine for device B executes until a higher priority interruptis detected at the end of execution of the instruction at x6202. The PSR of theservice routine for B, which includes the condition codes produced by the ANDinstruction at x6202, and the address x6203 are pushed on the stack. The interruptvector associated with device C is expanded to 16 bits (x01F2), and the contentsof x01F2 (x6300) is loaded into the PC. Figure 9.21c shows the supervisor stackand PC at this point.Assume the interrupt service routine for device C executes to completion, ﬁn-ishing with the RTI instruction in x6315. The supervisor stack is popped twice,restoring the PC to x6203 and the PSR of the service routine for device B, includ-ing the condition codes produced by the AND instruction in x6202. Figure 9.21dshows the stack and PC at this point.The interrupt service routine for device B resumes execution at x6203 andruns to completion, ﬁnishing with the RTI instruction in x6210. The supervisorstack is popped twice, restoring the PC to x3007 and the PSR of program A,including the condition codes produced by the ADD instruction in x3006. Finally,since program A is in User mode, the contents of R6 is stored in SavedSSP andR6 is loaded with the contents of SavedUSP. Figure 9.21e shows the supervisorstack and PC at this point.Program A resumes execution with the instruction at x3007...Not Just I/O DevicesWe have discussed the processing of interrupts in the context of I/O devices thathave higher priority than the program that is running and therefore can stop thatprogram to enable its interrupt service routine to execute.We must point out that not all interrupts deal with I/O devices. Any event thathas a higher priority and is external to the program that is running can interruptthe computer. It does so by supplying its INT signal, its INTV vector, and its pri-ority level. If it is the highest priority event that wishes to interrupt the computer,it does so in the same way that I/O devices do as described above.There are many examples of such events that have nothing to do with I/Odevices. For example, atimer interruptinterrupts the program that is running inorder to note the passage of a unit of time. Themachine checkinterrupt calls atten-tion to the fact that some part of the computer system is not functioning properly.Thepower failureinterrupt notiﬁes the computer that, for example, someone hasyanked the power cord out of its receptacle. Unfortunately, we will have to putoﬀdealing with all of these until later in your coursework.\n",
      "\n",
      ".Polling Revisited, Now ThatWe Know About Interrupts..The ProblemRecall our discussion of polling: We continually test the ready bit in the relevantstatus register, and if it is not set, we branch back to again test the ready bit. Forexample, suppose we are writing a character string to the monitor, and we areusing polling to determine when the monitor has successfully written the currentcharacter so we can dispatch the next character. We take it for granted that thethree-instruction sequence LDI (to load the ready bit of the DSR), BRzp (to testit and fall through if the device is ready), and STI (to store the next character in theDDR) acts as an atomic unit. But what if we had interrupts enabled at the sametime? That is, if an interrupt occurredwithinthat LDI, BRzp, STI sequence (say,just before the STI instruction), it could easily be the case that the LDI instructionindicated the DDR was ready, the BRzp instruction did not branch back, but bythe time the interrupt service routine completed so the STI could write to theDDR, the DDR may no longer be ready. The computer would execute the STI,but the write would not happen.As i m p l e ,b u ts o m e w h a tc o n t r i v e de x a m p l e: - ) ,w i l li l l u s t r a t et h ep r o b l e m .Suppose you are executing a “for” loop ten times, where each time the loop bodyprints to the monitor a particular character. Polling is used to determine that themonitor is ready before writing the next character to the DDR. Since the loopbody executes ten times, this should result in the character being printed on themonitor ten times. Suppose you also have keyboard interrupts enabled, and thekeyboard service routine echoes the character typed.Suppose the loop body executes as follows: LDI loads the ready bit, BRzpfalls through since the monitor is ready, and STI stores the character in DDR. Inthe middle of this sequence, before the STI can execute, someone types a key.The keyboard interrupt occurs, the character typed is echoed, i.e., written to theDDR, and the keyboard interrupt service routine completes.The interrupted loop body then takes over and “knows” the monitor is ready,so it executes the STI. ... except the monitor is not ready because it has not com-pleted the write of the keyboard service routine! The STI of the loop body writes,but since DDR is not ready, the write does not occur. The ﬁnal result: Only ninecharacters get written, not ten.The problem becomes more serious if the string written is in code, and themissing write prevents the code from being deciphered.A simple way to handle this would be to disable all interrupts while pollingwas going on. But consider the consequences. Suppose the polling was requiredfor a long time. If we disable interrupts while polling is going on, interrupts wouldbe disabled for that very long time, unacceptable in an environment where one isconcerned about the time between a higher priority interrupt occurring and theinterrupt getting service.\n",
      "\n",
      "LC-ISAA.OverviewThe instruction set architecture (ISA) of the LC-3 is deﬁned as follows:Memory address space16 bits, corresponding to 216locations, eachcontaining one word (16 bits). Addresses are numbered from 0 (i.e., x0000)to 65,535 (i.e., xFFFF). Addresses are used to identify memory locationsand memory-mapped I/O device registers. Certain regions of memory arereserved for special uses, as described in Figure A.1.\n",
      "xFFFFFigure A.Memory map of the LC-\n",
      "\n",
      "Table A.Device Register AssignmentsAddress I/O Register Name I/O Register FunctionxFEKeyboard status register (KBSR) The ready bit (bit []) indicates if the keyboard has received anew character.xFEKeyboard data register (KBDR) Bits [:]c o n t a i nt h el a s tc h a r a c t e rt y p e do nt h ek e y b o a r d .xFEDisplay status register (DSR) The ready bit (bit []) indicates if the display device is ready toreceive another character to print on the screen.xFEDisplay data register (DDR) A character written in bits [:]w i l lb ed i s p l a y e do nt h es c r e e n .xFFFC Processor Status Register (PSR) Contains privilege mode, priority level and condition codes ofthe currently executing process.xFFFE Machine control register (MCR) Bit []i st h ec l o c ke n a b l eb i t .W h e nc l e a r e d ,i n s t r u c t i o nprocessing stops.data. Addresses xFE00 to xFFFF specify input and output device registersand special internal processor registers that are also only accessible if theprocess is executing in Supervisor mode (PSR[15]=0). For purposes ofcontrolling access to these device registers, their addresses are alsoconsidered part of privileged memory.Memory-mapped I/OInput and output are handled by load/store (LD/ST,LDI/STI, LDR/STR) instructions using memory addresses from xFE00 toxFFFF to designate each device register. Table A.1 lists the input andoutput device registers and internal processor registers that have beenspeciﬁed for the LC-3 thus far, along with their corresponding assignedaddresses from the memory address space.Bit numberingBits of all quantities are numbered, from right to left,starting with bit 0. The leftmost bit of the contents of a memory location isbit 15.InstructionsInstructions are 16 bits wide. Bits [15:12] specify the opcode(operation to be performed); bits [11:0] provide further information that isneeded to execute the instruction. The speciﬁc operation of each LC-3instruction is described in Section A.2.Illegal opcode exceptionBits [15:12]=1101 has not been speciﬁed. Ifan instruction contains 1101 in bits [15:12], an illegal opcode exceptionoccurs. Section A.3 explains what happens.Program counterA1 6 - b i tr e g i s t e rc o n t a i n i n gt h ea d d r e s so ft h en e x tinstruction to be processed.General purpose registersEight 16-bit registers, numbered from 000 to111 (R0 to R7).Condition codesThree 1-bit registers: N (negative), Z (zero), and P(positive). Load instructions (LD, LDI, and LDR) and operate instructions(ADD, AND, and NOT) each load a result into one of the eight generalpurpose registers. The condition codes are set, based on whether that result,taken as a 16-bit 2’s complement integer, is negative (N=1; Z,P=0), zero(Z=1; N,P=0), or positive (P=1; N,Z=0). All other LC-3 instructionsleave the condition codes unchanged.\n",
      "\n",
      "Interrupt processingI/O devices have the capability of interrupting theprocessor. Section A.3 describes the mechanism.Priority levelThe LC-3 supports eight levels of priority. Priority level 7(PL7) is the highest, PL0 is the lowest. The priority level of the currentlyexecuting process is speciﬁed in bits PSR[10:8].Processor status register (PSR)A1 6 - b i tr e g i s t e r ,c o n t a i n i n gs t a t u sinformation about the currently executing process. Seven bits of the PSRhave been deﬁned thus far. PSR[15] speciﬁes the privilege mode ofthe executing process. PSR[10:8] speciﬁes the priority level of the currentlyexecuting process. PSR[2:0] contains the condition codes. PSR[2] is N,PSR[1] is Z, and PSR[0] is P.Supervisor modeThe LC-3 speciﬁes two modes of operation, Supervisormode (privileged) and User mode (unprivileged). Interrupt service routinesand trap service routines (i.e., system calls) execute in Supervisor mode.The privilege mode is speciﬁed by PSR[15]. PSR[15]=0 indicatesSupervisor mode; PSR[15]=1 indicates User mode.Privilege mode exceptionThe RTI instruction executes in Supervisor mode.If the processor attempts to execute the RTI instruction while in User mode, aprivilege mode exception occurs. Section A.3 explains what happens.Access Control Violation (ACV) exceptionAn ACV exception occurs if aprocess attempts to access a location in privileged memory (either a location insystem space or a device register having an address from xFE00 to xFFFF)while operating in User mode. Section A.3 explains what happens.Supervisor stackAr e g i o no fm e m o r yi ns y s t e ms p a c ea c c e s s i b l ev i at h eSupervisor Stack Pointer (SSP). When PSR[15]=0, the stack pointer (R6) isSSP. When the processor is operating in User mode (PSR[15]=1), the SSPis stored in SavedSSP.User stackAr e g i o no fm e m o r yi nu s e rs p a c ea c c e s s i b l ev i at h eU s e rS t a c kPointer (USP). When PSR[15]=1, the stack pointer (R6) is USP. When theprocessor is operating in Supervisor mode (PSR[15]=0), the USP is storedin SavedUSP.A.The Instruction SetThe LC-3 supports a rich, but lean, instruction set. Each 16-bit instruction consistsof an opcode (bits[15:12]) plus 12 additional bits to specify the other informa-tion that is needed to carry out that instruction. Figure A.2 summarizes the 15diﬀerent opcodes in the LC-3 and the speciﬁcation of the remaining bits of eachinstruction. The 16th four-bit opcode is not speciﬁed but is reserved for future use.In the following pages, the instructions will be described in greater detail.Table A.2 is provided to help you to understand those descriptions. For eachinstruction, we show the assembly language representation, the format of the16-bit instruction, the operation of the instruction, an English-language descrip-tion of its operation, and one or more examples of the instruction. Where relevant,additional notes about the instruction are also provided.\n",
      "\n",
      "Table A.Notational ConventionsNotation MeaningxNumber The number in hexadecimal notation. Example: xFA#Number The number in decimal notation. Example #bNumber The number in binary. Example bA[l:r] The ﬁeld delimited by bit [l] on the left and bit [r] on the right, of the datum A. For example, if PCcontains,t h e nP C [:]i s.P C [:]i s.I fla n dra r et h es a m eb i tnumber, we generally write PC[].BaseR Base Register; one of R..R,s p e c i ﬁ e db yb i t s[:]o ft h ei n s t r u c t i o n ,u s e di nc o n j u n c t i o nw i t has i x - b i toﬀset to compute Base+oﬀset addresses (LDR and STR), or alone to identify the target address of acontrol instruction (JMP and JSRR).DR Destination Register; one of R..R,w h i c hs p e c i ﬁ e st h er e g i s t e rar e s u l ts h o u l db ew r i t t e nt o .immA ﬁve-bit immediate value (bits [:] of an instruction), when used as a literal (immediate) value. Takenas a ﬁve-bit,’s complement integer, it is sign-extended tobits before it is used. Range:−...INTV An eight-bit value, supplied along with an interrupting event; used to determine the starting addressof an interrupt service routine. The eight bits form an oﬀset from the starting address of the interruptvector table. The corresponding location in the interrupt vector table contains the starting addressof the corresponding interrupt service routine. Range...LABEL An assembly language construct that identiﬁes a location symbolically (i.e., by means of a name,rather than its-bit address).mem[address] Denotes the contents of memory at the given address.oﬀsetAs i x - b i ts i g n e d’s complement integer (bits [:]o fa ni n s t r u c t i o n ) ,u s e dw i t ht h eB a s e+oﬀsetaddressing mode. Bits [:]a r es i g n - e x t e n d e dt obits and then added to the Base Register toform an address. Range:−...PC Program Counter;-bit register that contains the memory address of the next instruction to befetched. For example, if the instruction at address A is not a control instruction, during its execution,the PC contains the address A+,i n d i c a t i n gt h a tt h en e x ti n s t r u c t i o nt ob ee x e c u t e di sc o n t a i n e di nmemory location A+.PCoﬀsetAn i n e - b i ts i g n e d’s complement integer (bits [:]o fa ni n s t r u c t i o n ) ,u s e dw i t ht h eP C+oﬀsetaddressing mode. Bits [:]a r es i g n - e x t e n d e dt obits and then added to the incremented PC toform an address. Range−...PCoﬀsetAn eleven-bit signed’s complement integer (bits [:]o fa ni n s t r u c t i o n ) ,u s e dw i t ht h eJ S Ro p c o d eto compute the target address of a subroutine call. Bits [:]a r es i g n - e x t e n d e dt obits and thenadded to the incremented PC to form the target address. Range−...PSR Processor Status Register. A-bit register that contains status information of the process that isexecuting. Seven bits of the PSR have been speciﬁed. PSR[]=privilege mode. PSR[:]=Priority Level. PSR[:]c o n t a i n st h ec o n d i t i o nc o d e s .P S R []=N, PSR[]=Z, PSR[]=P.SavedSSP Saved Supervisor Stack Pointer. The processor is executing in either Supervisor mode or User mode.If in User mode, R, the stack pointer, is the User Stack Pointer (USP). The Supervisor Stack Pointer(SSP) is stored in SavedSSP. When the privilege mode changes from User mode to Supervisormode, SavedUSP is loaded with Rand Ris loaded with SavedSSP.SavedUSP Saved User Stack Pointer. The User Stack Pointer is stored in SavedUSP when the processor isexecuting in Supervisor mode. See SavedSSP.setcc() Indicates that condition codes N, Z, and P are set based on the value of the result written to DR.SEXT(A) Sign-extend A. The most signiﬁcant bit of A is replicated as many times as necessary to extend A tobits. For example, if A=,t h e nS E X T ( A )=   .SP The current stack pointer. Ris the current stack pointer. There are two stacks, one for each privilegemode. SP is SSP if PSR[]=;S Pi sU S Pi fP S R []=.SR, SR,S RSource register; one of R..Rthat speciﬁes the register from which a source operand is obtained.SSP The Supervisor Stack Pointer.trapvectAn eight-bit value (bits [:]o fa ni n s t r u c t i o n ) ,u s e dw i t ht h eT R A Po p c o d et od e t e r m i n et h es t a r t i n gaddress of a trap service routine. Bits [:]a r et a k e na sa nu n s i g n e di n t e g e ra n dz e r o - e x t e n d e dt obits. This is the address of the memory location containing the starting address of thecorresponding service routine. Range...USP The User Stack Pointer.ZEXT(A) Zero-extend A. Zeros are appended to the leftmost bit of A to extend it tobits. For example, ifA=,t h e nZ E X T ( A )=   .\n",
      "\n",
      "ADDAddition\n",
      "  98 654 0DR SR1 1imm5Operationif (bit[5]==0)DR = SR1 + SR2;elseDR = SR1 + SEXT(imm5);setcc();DescriptionIf bit [5] is 0, the second source operand is obtained from SR2. If bit [5] is 1, thesecond source operand is obtained by sign-extending the imm5 ﬁeld to 16 bits.In both cases, the second source operand is added to the contents of SR1 and theresult stored in DR. The condition codes are set, based on whether the result isnegative, zero, or positive.ExamplesADD R2, R3, R4 ; R2/uni2190R3+R4ADD R2, R3, #7 ; R2/uni2190R3+7\n",
      "\n",
      "ANDBit-wise Logical AND\n",
      " 98 654 0DR SR1imm5Operationif (bit[5]==0)DR = SR1 AND SR2;elseDR = SR1 AND SEXT(imm5);setcc();DescriptionIf bit [5] is 0, the second source operand is obtained from SR2. If bit [5] is 1,the second source operand is obtained by sign-extending the imm5 ﬁeld to 16bits. In either case, the second source operand and the contents of SR1 are bit-wise ANDed and the result stored in DR. The condition codes are set, based onwhether the binary value produced, taken as a 2’s complement integer, is negative,zero, or positive.ExamplesAND R2, R3, R4 ;R2/uni2190R3 AND R4AND R2, R3, #7 ;R2/uni2190R3 AND 7\n",
      "\n",
      "BRConditional BranchAssembler FormatsBRn LABEL BRzp LABEL\n",
      "znpPCoﬀset9Operationif ((n AND N) OR (z AND Z) OR (p AND P))PC = PC‡+S E X T ( P C o f f s e t 9 ) ;DescriptionThe condition codes speciﬁed by bits [11:9] are tested. If bit [11] is 1, N is tested;if bit [11] is 0, N is not tested. If bit [10] is 1, Z is tested, etc. If any of the condi-tion codes tested is 1, the program branches to the memory location speciﬁed byadding the sign-extended PCoﬀset9 ﬁeld to the incremented PC.ExamplesBRzp LOOP ; Branch to LOOP if the last result was zero or positive.BR†NEXT ; Unconditionally branch to NEXT.\n",
      "†The assembly language opcode BR is interpreted the same as BRnzp; that is, always branch to the targetaddress.‡This is the incremented PC.\n",
      "\n",
      "JMPRETJumpReturn from SubroutineAssembler Formats\n",
      "  05689RETOperationPC=BaseR;DescriptionThe program unconditionally jumps to the location speciﬁed by the contents ofthe base register. Bits [8:6] identify the base register.ExamplesJMP R2 ; PC/uni2190R2RET ; PC/uni2190R7NoteThe RET instruction is a special case of the JMP instruction, normally used in thereturn from a subroutine. The PC is loaded with the contents of R7, which con-tains the linkage back to the instruction following the subroutine call instruction.\n",
      "\n",
      "JSRJSRRJump to SubroutineAssembler Formats\n",
      "000 BaseR05689JSRROperationTEMP = PC;†if (bit[11]==0)PC=BaseR;elsePC = PC†+SEXT(PCoffset11);R7 = TEMP;DescriptionFirst, the incremented PC is saved in a temporary location. Then the PC is loadedwith the address of the ﬁrst instruction of the subroutine, which will cause anunconditional jump to that address after the current instruction completes execu-tion. The address of the subroutine is obtained from the base register (if bit [11]is 0), or the address is computed by sign-extending bits [10:0] and adding thisvalue to the incremented PC (if bit [11] is 1). Finally, R7 is loaded with the valuestored in the temporary location. This is the linkage back to the calling routine.ExamplesJSR QUEUE ; Put the address of the instruction following JSR into R7;;J u m pt oQ U E U E .JSRR R3 ; Put the address of the instruction following JSRR into R7;;J u m pt ot h ea d d r e s sc o n t a i n e di nR 3 .†This is the incremented PC.\n",
      "\n",
      "LDLoad\n",
      "PCoﬀset9DR  98 0Operationif (computed address is in privileged memory AND PSR[15] == 1)Initiate ACV exception;elseDR=mem[PC†+SEXT(PCoffset9)];setcc();DescriptionAn address is computed by sign-extending bits [8:0] to 16 bits and addingthis value to the incremented PC. If the address is to privileged memory andPSR[15]=1, initiate ACV exception. If not, the contents of memory at this addressis loaded into DR. The condition codes are set, based on whether the value loadedis negative, zero, or positive.ExampleLD R4, VALUE ; R4/uni2190mem[VALUE]\n",
      "†This is the incremented PC.\n",
      "\n",
      "LDILoad Indirect\n",
      "PCoﬀset9DR  98 0Operationif (either computed address is in privileged memory AND PSR[15] == 1)Initiate ACV exception;elseDR=mem[mem[PC†+SEXT(PCoffset9)]];setcc();DescriptionAn address is computed by sign-extending bits [8:0] to 16 bits and adding thisvalue to the incremented PC. What is stored in memory at this address is theaddress of the data to be loaded into DR. If either address is to privileged mem-ory and PSR[15]=1, initiate ACV exception. If not, the data is loaded and thecondition codes are set, based on whether the value loaded is negative, zero, orpositive.ExampleLDI R4, ONEMORE ; R4/uni2190mem[mem[ONEMORE]]\n",
      "†This is the incremented PC.\n",
      "\n",
      "LDRLoad Base+oﬀset\n",
      "  98 65 0BaseRDRoﬀset6OperationIf (computed address is in privileged memory AND PSR[15] == 1)Initiate ACV exception;elseDR=mem[BaseR+SEXT(offset6)];setcc();DescriptionAn address is computed by sign-extending bits [5:0] to 16 bits and adding thisvalue to the contents of the register speciﬁed by bits [8:6]. If the computed addressis to privileged memory and PSR[15]=1, initiate ACV exception. If not, the con-tents of memory at this address is loaded into DR. The condition codes are set,based on whether the value loaded is negative, zero, or positive.ExampleLDR R4, R2, #−5; R 4/uni2190mem[R2−5]\n",
      "\n",
      "LEALoad Eﬀective Address\n",
      "  98 0DRPCoﬀset9OperationDR=PC†+SEXT(PCoffset9);DescriptionAn address is computed by sign-extending bits [8:0] to 16 bits and adding thisvalue to the incremented PC. This address is loaded into DR.‡ExampleLEA R4, TARGET ; R4/uni2190address of TARGET.\n",
      "†This is the incremented PC.‡The LEA instruction computes an address but does NOT read memory. Instead, the address itself isloaded into DR.\n",
      "\n",
      "NOTBit-Wise Complement\n",
      "  98 65432 0DRSR 1OperationDR = NOT(SR);setcc();DescriptionThe bit-wise complement of the contents of SR is stored in DR. The condi-tion codes are set, based on whether the binary value produced, taken as a 2’scomplement integer, is negative, zero, or positive.ExampleNOT R4, R2 ; R4/uni2190NOT(R2)\n",
      "\n",
      "RETReturn from Subroutine\n",
      "  5OperationPC = R7;DescriptionThe PC is loaded with the value in R7. Its normal use is to cause a return from aprevious JSR(R) instruction.ExampleRET ; PC/uni2190R7\n",
      "†The RET instruction is a speciﬁc encoding of the JMP instruction. See also JMP.\n",
      "\n",
      "RTIterrupt  0Operationif (PSR[15]==1)Initiate a privilege mode exception;elsePC = mem[R6]; R6 is the SSP , PC is restoredR6 = R6+1;TEMP = mem[R6];R6 = R6+1; system stack completes POP before saved PSR is restoredPSR = TEMP; PSR is restoredif (PSR[15]==1)SavedSSP=R6 and R6=SavedUSP;DescriptionIf the processor is running in User mode, a privilege mode exception occurs. Ifin Supervisor mode, the top two elements on the system stack are popped andloaded into PC, PSR. After PSR is restored, if the processor is running in Usermode, the SSP is saved in SavedSSP, and R6 is loaded with SavedUSP.ExampleRTI ; PC, PSR/uni2190top two values popped oﬀstack.NoteRTI is the last instruction in both interrupt and trap service routines and returnscontrol to the program that was running. In both cases, the relevant service routineis initiated by first pushing the PSR and PC of the program that is running onto thesystem stack. Then the starting address of the appropriate service routine is loadedinto the PC, and the service routine executes with supervisor privilege. The lastinstruction in the service routine is RTI, which returns control to the interruptedprogram by popping two values off the supervisor stack to restore the PC and PSR.In the case of an interrupt, the PC is restored to the address of the instruction that wasabout to be processed when the interrupt was initiated. In the case of an exception,the PC is restored to either the address of the instruction that caused the exception orthe address of the following instruction, depending on whether the instruction thatcaused the exception is to be re-executed. In the case of a TRAP service routine,the PC is restored to the instruction following the TRAP instruction in the callingroutine. In the case of an interrupt or TRAP, the PSR is restored to the value it hadwhen the interrupt was initiated. In the case of an exception, the PSR is restored tothe value it had when the exception occurred or to some modified value, dependingon the exception. See also Section A.3.\n",
      "\n",
      "STStore\n",
      "PCoﬀset9SR  98 0Operationif (computed address is in privileged memory AND PSR[15] == 1)Initiate ACV exception;elsemem[PC†+SEXT(PCoffset9)]=SR;DescriptionIf the computed address is to privileged memory and PSR[15]=1, initiate ACVexception. If not, the contents of the register speciﬁed by SR is stored in thememory location whose address is computed by sign-extending bits [8:0] to 16bits and adding this value to the incremented PC.ExampleST R4, HERE ; mem[HERE]/uni2190R4\n",
      "†This is the incremented PC.\n",
      "\n",
      "STIStore Indirect\n",
      "PCoﬀset9SR  98 0Operationif (either computed address is in privileged memory AND PSR[15] == 1)Initiate ACV exception;elsemem[mem[PC†+SEXT(PCoffset9)]]=SR;DescriptionIf either computed address is to privileged memory and PSR[15]=1, initiateACV exception. If not, the contents of the register speciﬁed by SR is storedin the memory location whose address is obtained as follows: Bits [8:0] are sign-extended to 16 bits and added to the incremented PC. What is in memory at thisaddress is the address of the location to which the data in SR is stored.ExampleSTI R4, NOTHERE ; mem[mem[NOTHERE]]/uni2190R4\n",
      "†This is the incremented PC.\n",
      "\n",
      "STRStore Base+oﬀset\n",
      "15 12 11 9 8 6 5 0BaseRSRoﬀset6Operationif (computed address is in privileged memory AND PSR[15] == 1)Initiate ACV exception;elsemem[BaseR+SEXT(offset6)]=SR;DescriptionIf the computed address is to privileged memory and PSR[15]=1, initiate ACVexception. If not, the contents of the register speciﬁed by SR is stored in thememory location whose address is computed by sign-extending bits [5:0] to 16bits and adding this value to the contents of the register speciﬁed by bits [8:6].ExampleSTR R4, R2, #5 ; mem[R2+5]/uni2190R4\n",
      "\n",
      "TRAPSystem CallAsEn078111215trapvect8OperationTEMP=PSR;if (PSR[15] == 1)SavedUSP=R6 and R6=SavedSSP;PSR[15]=0;Push TEMP ,PC†on the system stackPC = mem[ZEXT(trapvect8)];DescriptionIf the the program is executing in User mode, the User Stack Pointer must besaved and the System Stack Pointer loaded. Then the PSR and PC are pushedon the system stack. (This enables a return to the instruction physically follow-ing the TRAP instruction in the original program after the last instruction in theservice routine (RTI) has completed execution.) Then the PC is loaded with thestarting address of the system call speciﬁed by trapvector8. The starting addressis contained in the memory location whose address is obtained by zero-extendingtrapvector8 to 16 bits.ExampleTRAP x23 ; Directs the operating system to execute theINsystem call.;T h es t a r t i n ga d d r e s so ft h i ss y s t e mc a l li sc o n t a i n e di n;m e m o r yl o c a t i o nx 0 0 2 3 .Note:Memory locations x0000 through x00FF, 256 in all, are available to containstarting addresses for system calls speciﬁed by their corresponding trap vectors.This region of memory is called the Trap Vector Table. Table A.3 describes thefunctions performed by the service routines corresponding to trap vectors x20to x25.†This is the incremented PC.\n",
      "\n",
      "Unused Opcode\n",
      "1101OperationInitiate an illegal opcode exception.DescriptionIf an illegal opcode is encountered, an illegal opcode exception occurs.Note:The opcode 1101 has been reserved for future use. It is currently not deﬁned. Ifthe instruction currently executing has bits [15:12]=1101, an illegal opcodeexception occurs. Section A.3 describes what happens.\n",
      "\n",
      "Table A.Trap Service RoutinesTrap Vector Assembler Name DescriptionxGETC Read a single character from the keyboard. The character is not echoed onto theconsole. Its ASCII code is copied into R.T h eh i g he i g h tb i t so fRare cleared.xOUT Write a character in R[:] to the console display.xPUTS Write a string of ASCII characters to the console display. The characters arecontained in consecutive memory locations, one character per memory location,starting with the address speciﬁed in R.W r i t i n gt e r m i n a t e sw i t ht h eo c c u r r e n c eo fxin a memory location.xIN Print a prompt on the screen and read a single character from the keyboard. Thecharacter is echoed onto the console monitor, and its ASCII code is copied intoR.T h eh i g he i g h tb i t so fRare cleared.xPUTSP Write a string of ASCII characters to the console. The characters are contained inconsecutive memory locations, two characters per memory location, starting withthe address speciﬁed in R.T h eA S C I Ic o d ec o n t a i n e di nb i t s[:]o fam e m o r ylocation is written to the console ﬁrst. Then the ASCII code contained in bits [:]of that memory location is written to the console. (A character string consisting ofan odd number of characters to be written will have xin bits [:]o ft h ememory location containing the last character to be written.) Writing terminateswith the occurrence of xin a memory location.xHALT Halt execution and print a message on the console.A.Interrupt and ExceptionProcessingAs has been discussed in detail in Chapter 9, events external to the program thatis running can interrupt the processor. A common example of an external eventis interrupt-driven I/O. It is also the case that the processor can be interruptedby exceptional events that occur while the program is running that are caused bythe program itself. An example of such an “internal” event is the presence of anunused opcode in the computer program that is running.Associated with each event that can interrupt the processor is an eight-bitvector that provides an entry point into a 256-entryinterrupt vector table.T h estarting address of the interrupt vector table is x0100. That is, the interrupt vectortable occupies memory locations x0100 to x01FF. Each entry in the interruptvector table contains the starting address of the service routine that handles theneeds of the corresponding event. These service routines execute in Supervisormode.Half (128) of these entries, locations x0100 to x017F, provide the startingaddresses of routines that service events caused by the running program itself.These routines are calledexception service routinesbecause they handle excep-tional events, that is, events that prevent the program from executing normally.The other half of the entries, locations x0180 to x01FF, provide the startingaddresses of routines that service events that are external to the program thatis running, such as requests from I/O devices. These routines are calledinterruptservice routines.\n",
      "\n",
      "A..InterruptsAt this time, an LC-3 computer system provides only one I/O device that caninterrupt the processor. That device is the keyboard. It interrupts at priority levelPL4 and supplies the interrupt vector x80.An I/O device can interrupt the processor if it wants service, if its interruptenable (IE) bit is set, and if the priority of its request is greater than the priority ofany other event that wants to interrupt and greater than the priority of the programthat is running.Assume a program is running at a priority level less than 4, and someonestrikes a key on the keyboard. If the IE bit of the KBSR is 1, the currently execut-ing program is interrupted at the end of the current instruction cycle. The interruptservice routine isinitiatedas follows:1. The PSR of the interrupted process is saved in TEMP.2. The processor sets the privilege mode to Supervisor mode (PSR[15]=0).3. The processor sets the priority level to PL4, the priority level of theinterrupting device (PSR[10:8]=100).4. If the interrupted process is in User mode, R6 is saved in SavedUSP andR6 is loaded with the Supervisor Stack Pointer (SSP).5. TEMP and the PC of the interrupted process are pushed onto the supervisorstack.6. The keyboard supplies its eight-bit interrupt vector, in this case x80.7. The processor expands that vector to x0180, the corresponding 16-bitaddress in the interrupt vector table.8. The PC is loaded with the contents of memory location x0180, the addressof the ﬁrst instruction in the keyboard interrupt service routine.The processor then begins execution of the interrupt service routine.The last instruction executed in an interrupt service routine is RTI. The toptwo elements of the supervisor stack are popped and loaded into the PC and PSRregisters. R6 is loaded with the appropriate stack pointer, depending on the new valueof PSR[15]. Processing then continues where the interrupted program left off.A..ExceptionsAt this time, the LC-3 ISA speciﬁes three exception conditions: privilege modeviolation, illegal opcode, and access control violation (ACV). The privilege modeviolation occurs if the processor attempts to execute the RTI instruction whilerunning in User mode. The illegal opcode exception occurs if the processorattempts to execute an instruction having the unused opcode (bits [15:12] =1101). The ACV exception occurs if the processor attempts to access privilegedmemory (i.e., a memory location in system space or a device register having anaddress from xFE00 to xFFFF while running in User mode).Exceptions are handled as soon as they are detected. They areinitiatedverymuch like interrupts are initiated, that is:1. The PSR of the process causing the exception is saved in TEMP.\n",
      "\n",
      "2. The processor sets the privilege mode to Supervisor mode (PSR[15]=0).3. If the process causing the exception is in User mode, R6 is saved inSavedUSP and R6 is loaded with the SSP.4. TEMP and the PC of the process causing the exception are pushed onto thesupervisor stack.5. The exception supplies its eight-bit vector. In the case of the privilege modeviolation, that vector is x00. In the case of the illegal opcode, that vector isx01. In the case of the ACV exception, that vector is x02.6. The processor expands that vector to x0100, x0101, or x0102, thecorresponding 16-bit address in the interrupt vector table.7. The PC is loaded with the contents of memory location x0100, x0101, orx0102, the address of the ﬁrst instruction in the corresponding exceptionservice routine.The processor then begins execution of the exception service routine.The details of the exception service routine depend on the exception and theway in which the operating system wishes to handle that exception.In many cases, the exception service routine can correct any problem causedby the exceptional event and then continue processing the original program. Inthose cases, the last instruction in the exception service routine is RTI, which popsthe top two elements from the supervisor stack and loads them into the PC andPSR registers. The program then resumes execution with the problem corrected.In some cases, the cause of the exceptional event is suﬃciently catastrophicthat the exception service routine removes the program from further processing.Another diﬀerence between the handling of interrupts and the handling ofexceptions is the priority level of the processor during the execution of the serviceroutine. In the case of exceptions, we normally do not change the priority levelwhen we service the exception. The priority level of a program is the urgencywith which it needs to be executed. In the case of the exceptions speciﬁed by theLC-3 ISA, the urgency of a program is not changed by the fact that a privilegemode violation occurred or there was an illegal opcode in the program or theprogram attempted to access privileged memory while it was in User mode.\n",
      "\n",
      "LC-to xAs you know, the ISA of the LC-3 explicitly speciﬁes the interface betweenwhat the LC-3 machine language programmer or LC-3 compilers produceand what a microarchitecture of the LC-3 can accept and process. Among thosethings speciﬁed are the address space and addressability of memory, the numberand size of the registers, the format of the instructions, the opcodes, the data typesthat are the encodings used to represent information, and the addressing modesthat are available for determining the location of an operand.The ISA of the microprocessor in your PC also speciﬁes an interface betweenthe compilers and the microarchitecture. However, in the case of the PC, the ISAis not the LC-3. Rather it is the x86. Intel introduced the ﬁrst member of this ISAin 1979. It was called the 8086, and the “normal” size of the addresses and dataelements it processed was 16 bits, the same size as the LC-3. Today, the typicalsize of addresses and data is 64 bits. With special vector extensions, instructionscan operate on vectors that can be of size 128, 256, and 512 bits. Because thereare a lot of old programs and data expressed in 32 bits, the x86 is able to processinstructions in what we call 64-bit mode or 32-bit mode. That is, in 32-bit mode,the x86 restricts itself to a 32-bit address space and 32-bit elements.From the 8086 to the present time, Intel has continued implementationsof the x86 ISA, among them the 386 (in 1985), 486 (in 1989), Pentium (in1992), Pentium Pro (in 1995), Pentium II (in 1997), Pentium IV (in 2001), “1stGeneration Core i7-9xx Series,” codename Nehalem (in 2008), “4th GenerationCore i7-4xxx Series,” codename Haswell (in 2013), and “8th Generation Corei7-8086K,” codename: Coﬀee Lake (in 2018).The ISA of the x86 is much more complicated than that of the LC-3. Thereare more opcodes, more data types, more addressing modes, a more complicatedmemory structure, and a more complicated encoding of instructions into 0s and1s. However, fundamentally, they have the same basic ingredients.You have spent a good deal of time understanding computing within the con-text of the LC-3. Some may feel that it would be good to learn about arealISA.One way to do that would be to have some company such as Intel mass-produceLC-3 microprocessors, some other company like Dell put them in their PCs, and athird company such as Microsoft compile Windows NT into the ISA of the LC-3.An easier way to introduce you to arealISA is by way of this appendix.\n",
      "\n",
      "We present here elements of the x86, a very complicated ISA. We do so inspite of its complexity because it is one of the most pervasive of all ISAs availablein the marketplace.We make no attempt to provide a complete speciﬁcation of the x86 ISA.That would require a whole book by itself, and to appreciate it, a deeper under-standing of operating systems, compilers, and computer systems than we thinkis reasonable at this point in your education. If one wants a complete treat-ment, we recommend theIntel Architecture Software Developer’s Manual. In thisappendix, we restrict ourselves to some of the characteristics that are relevant toapplication programs. Our intent is to give you a sense of the richness of the x86ISA. We introduce these characteristics within the context of the LC-3 ISA, whichat this point you are very familiar with.B.LC-Features andCorresponding xFeaturesB..Instruction SetAn instruction set is made up of instructions, each of which has an opcode andzero or more operands. The number of operands depends on how many are neededby the corresponding opcode. Each operand is a data element and is encodedaccording to its data type. The location of an operand is determined by evaluatingits addressing mode.The LC-3 instruction set contains one data type, 15 opcodes, and threeaddressing modes: PC-relative (LD, ST), indirect (LDI, STI), and register-plus-oﬀset (LDR, STR). The x86 instruction set has more than a dozen data types,more than a thousand opcodes, and more than two dozen addressing modes(depending on how you count).B...Data TypesRecall that a data type is a representation of information such that the ISA pro-vides opcodes that operate on information that is encoded in that representation.The LC-3 supports only one data type, 16-bit 2’s-complement integers. Thisis not enough for eﬃcient processing in the real world. Scientiﬁc applicationsneed numbers that are represented by the ﬂoating point data type. Multimediaapplications require information that is represented by a diﬀerent data type. Com-mercial applications written years ago, but still active today, require an additionaldata type, referred to aspacked decimal.S o m ea p p l i c a t i o n sr e q u i r eag r e a t e rrange of values and a greater precision of each value than other applications.As a result of all these requirements, the x86 is designed with instructionsthat operate on (for example) 8-bit integers, 16-bit integers, and 32-bit integers,32-bit and 64-bit ﬂoating point numbers, 64-bit, 128-bit, 256-bit, and 512-bit-multimedia values. Figure B.1 shows some of the data types present in thex86 ISA.\n",
      "\n",
      "B...OpcodesThe LC-3 comprises 15 opcodes; the x86 instruction set comprises more thanat h o u s a n d .R e c a l lt h a tt h et h r e eb a s i ci n s t r u c t i o nt y p e sa r eo p e r a t e s ,d a t amovement, and control. Operates process information, data movement opcodesmove information from one place to another (including input and output), andcontrol opcodes change the ﬂow of the instruction stream.In addition, we should add a fourth category to handle functions that mustbe performed in the real world because a user program runs in the context of anoperating system that is controlling a computer system, rather than in isolation.These instructions deal with computer security, system management, hardwareperformance monitoring, and various other issues that are beyond what the typicalapplication program pays attention to. We will ignore those instructions in thisappendix, but please realize that they do exist, and you will see them as yourstudies progress. Here we will concentrate on the three basic instruction types:operates, data movement, and control.OperatesThe LC-3 has three operate instructions: ADD, AND, and NOT. TheADD opcode is the only LC-3 opcode that performs arithmetic. If one wants tosubtract, one obtains the negative of an operand and then adds. If one wantsto multiply, one can write a program with a loop to ADD a number some speciﬁednumber of times. However, this is too time-consuming for a real microprocessor.So the x86 has separate SUB and MUL, as well as DIV, INC (increment), DEC(decrement), and ADC (add with carry), to name a few.A useful feature of an ISA is to extend the size of the integers on which it canoperate. To do this, one writes a program to operate on suchlongintegers. TheADC opcode, which adds two operands plus the carry from the previous add, isav e r yu s e f u lo p c o d ef o re x t e n d i n gt h es i z eo fi n t e g e r s .In addition, the x86 has, for each data type, its own set of opcodes to operateon that data type. For example, multimedia instructions (collectively called theMMX instructions) often requiresaturating arithmetic,w h i c hi sv e r yd iﬀerentfrom the arithmetic we are used to. PADDS is an opcode that adds two operandswith saturating arithmetic.Saturating arithmetic can be explained as follows: Suppose we represent thedegree of grayness of an element in a ﬁgure with a digit from 0 to 9, where 0 iswhite and 9 is black. Suppose we want to add some darkness to an existing valueof grayness of that ﬁgure. An element could start out with a grayness value of7, and we might wish to add a 5 worth of darkness to it. In normal arithmetic,7+5 is 2 (with a carry), which is lighter than either 7 or 5. Something is wrong!With saturating arithmetic, when we reach 9, we stay there—we do not generatea carry. So, for example, 7+5=9a n d9+n=9. Saturating arithmetic is adiﬀerent kind of arithmetic, and the x86 has opcodes (MMX instructions) thatperform this type of arithmetic.Scientiﬁc applications require opcodes that operate on values representedin the ﬂoating point data type. FADD, FMUL, FSIN, FSQRT are examples ofﬂoating point opcodes in the x86 ISA.The AND and NOT opcodes are the only LC-3 opcodes that perform logicalfunctions. One can construct any logical expression using these two opcodes.\n",
      "\n",
      "Table B.Operate Instructions, xISAInstruction ExplanationADC x, y x, y, and the carry retained from the last relevant operation (in CF) are added andthe result stored in x.MUL x The value in EAX is multiplied by x, and the result is stored in the-bit registerformed by EDX, EAX.SAR x x is right shifted (arithmetic shift) n bits, and the result is stored in x. The value of ncan be,a ni m m e d i a t eo p e r a n d ,o rt h ec o u n ti nt h eC Lr e g i s t e r .XOR x, y A bit-wise exclusive-OR is performed on x, y and the result is stored in x.DAA After adding two packed decimal numbers, AL contains two BCD values, whichmay be incorrect due to propagation of the carry bit after,r a t h e rt h a na f t e r.DAA corrects the two BCD digits in AL.FSIN The top of the stack (call it x) is popped. The sin(x) is computed and pushed ontothe stack.FADD The top two elements on the stack are popped, added, and their result pushedonto the stack.PANDN x, y A bit-wise AND-NOT operation is performed on MMX values x, y, and the result isstored in x.PADDS x, y Saturating addition is performed on packed MMX values x, y, and the result isstored in x.However, as is the case with arithmetic, this also is too time-consuming. The x86has in addition separate OR, XOR, AND-NOT, and separate logical operators fordiﬀerent data types.Furthermore, the x86 has a number of other operate instructions that set andclear registers, convert a value from one data type to another, shift or rotate thebits of a data element, and so on. Table B.1 lists some of the operate opcodes inthe x86 instruction set.Data MovementThe LC-3 has six data movement opcodes: LD, LDI, ST,STI, LDR, and STR. They all copy information between memory (and memory-mapped device registers) and the eight general purpose registers, R0 to R7.Although the x86 does not have LDI or STI opcodes, it does have the otherfour, and in addition to these, many other data movement opcodes. XCHG canswap the contents of two locations. PUSHA pushes all eight general purposeregisters onto the stack. IN and OUT move data between input and output portsand the processor. CMOVcc copies a value from one location to another only if apreviously computed condition is true. Table B.2 lists some of the data movementopcodes in the x86 instruction set.ControlThe LC-3 has ﬁve control opcodes: BR, JSR/JSRR, JMP, RTI, andTRAP. x86 has all these and more. Table B.3 lists some of the control opcodes inthe x86 instruction set.B...Two Address vs. Three AddressThe LC-3 is a three-address ISA. This description reﬂects the number of operandsexplicitly speciﬁed by the ADD instruction. An add operation requires twosource operands (the numbers to be added) and one destination operand to store\n",
      "\n",
      "Table B.Data Movement Instructions, xISAInstruction ExplanationMOV x, y The value stored in y is copied into x.XCHG x, y The values stored in x and y are swapped.PUSHA All the registers are pushed onto the top of the stack.PUSH Push a register onto the top of the stack.POP Pop a register from the top of the stack.MOVS The element in the DS segment pointed to by ESI is copied into the location inthe ES segment pointed to by EDI. After the copy has been performed, ESI andEDI are both incremented.REP MOVS Perform the MOVS. Then decrement ECX. Repeat this instruction until ECX=.(This allows a string to be copied in a single instruction, after initializing ECX.)LODS The element in the DS segment pointed to by ESI is loaded into EAX, and ESI isincremented or decremented, according to the value of the DF ﬂag.INS Data from the I/O port speciﬁed by the DX register is loaded into the EAXregister (or AX or AL, if the size of the data isbits orbits, respectively).CMOVZ x, y If ZF=, the value stored in y is copied into x. If ZF=,t h ei n s t r u c t i o na c t sl i k ean o - o p .LEA x, y The address y is stored in x. This is very much like the LC-instruction of thesame name.Table B.Control Instructions, xISAInstruction ExplanationJcond x Branch based on the condition speciﬁed by cond. If cond is true, the IP is loadedwith x.JMP x IP is loaded with the address x. This is very much like the LC-instruction of thesame name.CALL x The IP is pushed onto the stack, and a new IP is loaded with x.RET The stack is popped, and the value popped is loaded into IP.LOOP x ECX is decremented. If ECX is notand ZF=,t h eI Pi sl o a d e dw i t hx .INTnThe value n is an index into a table of descriptors that specify operating systemservice routines. The end result of this instruction is that IP is loaded with thestarting result of the corresponding service routine. This is very much like theTRAP instruction in the LC-.the result. In the LC-3, all three must be speciﬁed explicitly, hence the namethree-address ISA.Even if the same location is to be used both for one of the sources and for thedestination, the three addresses are all speciﬁed. For example, the LC-3ADD R1,R1,R2identiﬁes R1 as both a source and the destination.The x86 is mostly (except for special instructions deﬁned as SSE or AVXinstructions) a two-address ISA. Since the add operation needs three operands, thelocation of one of the sources must also be used to store the result. For example,the corresponding 16-bit ADD instruction in the x86 ISA would beADD AX,BXwhere AX and BX are names of two of the x86’s eight 16-bit general purposeregisters. AX and BX are the sources, and AX is the destination.\n",
      "\n",
      "Since the result of the operate is stored in the location that originally con-tained one of the sources, that source operand is no longer available after thatinstruction is executed. If that source operand is needed later, it must be savedbefore the operate instruction is executed.B...Memory OperandsAm a j o rd iﬀerence between the LC-3 instruction set and the x86 instruction setis the restriction on where operate instructions can get their operands. An LC-3operate instruction must obtain its source operands from registers and write theresult to a destination register. An x86 instruction, on the other hand, can obtainone of its sources from memory and/or write its result to memory. In other words,the x86 can read a value from memory, operate on that value, and store the resultin memory all in a single instruction. The LC-3 cannot.The LC-3 program requires a separate load instruction to read the value frommemory before operating on it, and a separate store instruction to write the resultin memory after the operate instruction. An ISA, like the LC-3, that has thisrestriction is called aload-storeISA. The x86 is not a load-store ISA.B..MemoryThe LC-3 memory consists of 216locations, each containing 16 bits of informa-tion. We say the LC-3 has a 16-bit address space, since one can uniquely addressits 216locations with 16 bits of address. We say the LC-3 has an addressabilityof 16 bits, since each memory location contains 16 bits of information.The x86 memory has a 64-bit address space and an addressability of eightbits. Since one byte contains eight bits, we say the x86 memory is byte address-able. Since each location contains only eight bits, four contiguous locations inmemory are needed to store a 32-bit data element, say locations X, X+1, X+2,and X+3. We designate X as the address of the 32-bit data element. In actuality,Xo n l yc o n t a i n sb i t s[ 7 : 0 ] ,X+1c o n t a i n sb i t s[ 1 5 : 8 ] ,X+2c o n t a i n sb i t s[ 2 3 : 1 6 ] ,and X+3c o n t a i n sb i t s[ 3 1 : 2 4 ]o ft h e3 2 - b i tv a l u e .One can determine an LC-3 memory location by simply obtaining its addressfrom the instruction, using one of the three addressing modes available in theinstruction set. An x86 instruction has available to it more than two dozenaddressing modes that it can use to specify the memory address of an operand.We examine the addressing modes of an x86 instruction in Section B.2.In addition to the larger number of addressing modes, the x86 contains amechanism calledsegmentationthat provides a measure of protection againstunwanted accesses to particular memory addresses. The address produced by aninstruction’s addressing mode, rather than being an address in its own right, isused as an address within a segment of memory. Access to that memory locationmust take into account the segment register that controls access to that segment.The details of how the protection mechanism works will have to wait for later inyour studies.However, Figure B.2 does show how an address is calculated for theregister+oﬀset addressing mode, both for the LC-3 and for the x86, with\n",
      "\n",
      "segmentation. In both cases, the opcode is to move data from memory to a gen-eral purpose register. The LC-3 uses the LDR instruction. The x86 uses theMOV instruction. In the case of the x86, the address calculated is in the DSsegment, which is accessed via the DS register. That access is done through a 16-bitselector,w h i c hi n d e x e si n t oas e g m e n td e s c r i p t o rt a b l e ,y i e l d i n gt h esegmentdescriptorfor that segment. The segment descriptor contains asegment base reg-ister,asegment limit register,a n dp r o t e c t i o ni n f o r m a t i o n .T h em e m o r ya d d r e s sobtained from the addressing mode of the instruction is added to the segmentbase register to provide the actual memory address, as shown in Figure B.2.B..Internal StateThe internal state of the LC-3 consists of eight 16-bit general purpose registers,R0 to R7, a 16-bit PC, and a 16-bit PSR that speciﬁes the privilege mode, priority,and three 1-bit condition codes (N, Z, and P). The user-visible internal state ofthe x86 consists of 64-bit application-visible registers, a 64-bit Instruction pointer(RIP), a 64-bit RFLAGS register, and the 16-bit segment registers.B...Application-Visible RegistersFigure B.3 shows some of the application-visible registers in the x86 ISA.In 64-bit mode, the x86 has 16 general purpose registers: RAX, RBX, RCX,RDX, RSP, RBP, RCI, RDI, and R8 through R15. Each register contains 64 bitsreﬂecting the normal size of operands. In 32-bit mode, there are eight generalpurpose registers: EAX, EBX, ECX, EDX, ESP, EBP, ECI, and EDI, which usebits [31:0] of the corresponding 64-bit registers. Also, since some x86 opcodesprocess 16-bit and 8-bit operands, x86 also speciﬁes 16-bit registers AX, BX,...DI by using bits [15:0] of the 64-bit registers, and 8 bit registers AL, BL,CL, and DL using bits [7:0] and AH, BH, CH, and DH, using bits [15:8] ofthe corresponding 64-bit registers. The x86 also provides 128-bit, 256-bit, and512-bit SIMD registers for operands needed by SSE and AVX operations. Theyare, respectively, XMM0 to XMM31 for 128 bits, YMM0 to YMM31 for 256bits, and ZMM0 to ZMM31 for 512 bits.B...System RegistersThe LC-3 has two system-level registers—the PC and the PSR. The user-visiblex86 has these and more. Figure B.4 shows some of the user-visible systemregisters in the x86 ISA.Instruction Pointer (RIP)The x86 has the equivalent of the LC-3’s 16-bit pro-gram counter. The x86 calls it aninstruction pointer(RIP). Since the addressspace of the x86 is 64 bits, the RIP is a 64-bit register. In 32-bit mode, sincethe address space is only 32 bits, the instruction pointer (EIP) uses bits [31:0] ofthe RIP.RFLAGS RegisterCorresponding to the LC-3’s N, Z, and P condition codes,the x86 has a one-bit SF (sign ﬂag) register and a one-bit ZF (zero ﬂag) register.\n",
      "\n",
      "Figure B.xsystem registers.The CF ﬂag stores thecarryproduced by the last relevant operation thatgenerated a carry. As we said earlier, together with the ADC instruction, CF facil-itates the generation of procedures, which allows the software to deal with largerintegers than the ISA supports.The OF ﬂag stores anoverﬂowcondition if the last relevant operate generatedav a l u et o ol a r g et os t o r ei nt h ea v a i l a b l en u m b e ro fb i t s .R e c a l lt h ed i s c u s s i o no foverﬂow in Section 2.5.3.The DF ﬂag indicates thedirectionin which string operations are to processstrings. If DF=0, the string is processed from the high-address byte down (i.e.,the pointer keeping track of the element in the string to be processed next is decre-mented). If DF=1, the string is processed from the low-address byte up (i.e., thestring pointer is incremented).Two ﬂags not usually considered as part of the application state are the IF(interrupt)ﬂ a ga n dt h eT F(trap)ﬂ a g .B o t hc o r r e s p o n dt of u n c t i o n sw i t hw h i c hyou are familiar.IF is very similar to the IE (interrupt enable) bit in the KBSR and DSR,discussed in Section 9.4.4.1. If IF=1, the processor can recognize external\n",
      "\n",
      "interrupts (like keyboard input, for example). If IF=0, these external inter-rupts have no eﬀect on the process that is executing. We say the interrupts aredisabled.TF is very similar tosingle-step modein the LC-3 simulator, only in this caseit is part of the ISA. If TF=1, the processor halts after every instruction so thestate of the system can be examined. If TF=0, the processor ignores the trap andprocesses the next instruction.Segment RegistersWhen operating in its preferred operating mode (calledpro-tected mode), the address calculated by the instruction is really an oﬀset from thestarting address of a segment, which is speciﬁed by somesegment base regis-ter.T h e s es e g m e n tb a s er e g i s t e r sa r ep a r to ft h e i rc o r r e s p o n d i n gdata segmentdescriptors,w h i c ha r ec o n t a i n e di nt h esegment descriptor table. At each instantof time, six of these segments are active. They are called, respectively, thecodesegment(CS),stack segment(SS), and four data segments (DS, ES, FS, andGS). The six active segments are accessed via their corresponding segment reg-isters shown in Figure B.4, which contain pointers to their respective segmentdescriptors.B.The Format and Speciﬁcation ofxInstructionsThe LC-3 instruction is a 16-bit instruction. Bits [15:12] always contain theopcode; the remaining 12 bits of each instruction are used to support the needsof that opcode.The length of an x86 instruction is not ﬁxed. It consists of from 1 to16 bytes, depending on the needs of that instruction. A lot of informationcan be packed into one x86 instruction. Figure B.5 shows the format of anx86 instruction.The two key parts of an x86 instruction are the opcode and, where neces-\n",
      "Figure B.Format of the xinstruction.\n",
      "\n",
      "the use of registers, a one-, two-, or four-byte displacement, and additional registerinformation contained in an optional SIB byte.Some opcodes specify an immediate operand and also specify the numberof bytes of the instruction that is used to store that immediate information. Theimmediate value (when one is speciﬁed) is the last element of the instruction.Finally, instructions assume certain default information with respect to thesemantics of an instruction, such as address size, operand size, segment to beused, and so forth. The instruction can change this default information by meansof one or more preﬁxes, which are located at the beginning of the instruction.Each part of an x86 instruction is discussed in more detail in Sections B.2.1through B.2.6.B..PreﬁxPreﬁxes provide additional information that is used to process the instruction.There are four classes of preﬁx information, and each instruction can have fromzero to four preﬁxes, depending on its needs. Fundamentally, a preﬁx overridesthe usual interpretation of the instruction.The four classes of preﬁxes are lock and repeat, segment override, operandoverride, and address override. Table B.4 describes the four types of preﬁxes.B..OpcodeThe opcode byte (or bytes—some opcodes are represented by two bytes) spec-iﬁes a large amount of information about the needs of that instruction. TheTable B.Preﬁxes, xISARepeat/LockxF(LOCK) This preﬁx guarantees that the instruction will have exclusive useof all shared memory until the instruction completes execution.xF, xF(REP/REPE/REPNE)This preﬁx allows the instruction (a string instruction) to berepeated some speciﬁed number of times. The iteration countis speciﬁed by ECX. The instruction is also terminated on theoccurrence of a speciﬁed value of ZF.Segment overridexE(CS), x(SS),xE(DS), x(ES),x(FS), x(GS)This preﬁx causes the memory access to use the speciﬁedsegment, instead of the default segment expected for thatinstruction.Operand size overridexThis preﬁx changes the size of data expected for this instruction.That is, instructions expecting-bit data elements use-bitdata elements. And instructions expecting-bit data elementsuse-bit data elements.Address size overridexThis preﬁx changes the size of operand addresses expected forthis instruction. That is, instructions expecting a-bit addressuse-bit addresses. And instructions expecting-bitaddresses use-bit addresses.\n",
      "\n",
      "opcode byte (or bytes) speciﬁes, among other things, the operation to be per-formed, whether the operands are to be obtained from memory or from reg-isters, the size of the operands, whether or not one of the source operands isan immediate value in the instruction, and if so, the size of that immediateoperand.Some opcodes are formed by combining the opcode byte with bits [5:3]of the ModR/M byte, if those bits are not needed to provide addressing modeinformation. The ModR/M byte is described in Section B.2.3.B..ModR/M ByteThe ModR/M byte, shown in Figure B.5, provides addressing mode informationfor two operands, when necessary, or for one operand, if that is all that is needed.If two operands are needed, one may be in memory, the other in a register, or bothmay be in registers. If one operand is needed, it can be either in a register or inmemory. The ModR/M byte supports all cases.The ModR/M byte is essentially partitioned into two parts. The ﬁrst partconsists of bits [7:6] and bits [2:0]. The second part consists of bits [5:3].If bits [7:6]=00, 01, or 10, the ﬁrst part speciﬁes the addressing modeof a memory operand, and the combined ﬁve bits ([7:6],[2:0]) identify whichaddressing mode. If bits [7:6]=11, there is no memory operand, and bits [2:0]specify a register operand.Bits [5:3] specify the register number of the other operand, if the opcoderequires two operands. If the opcode only requires one operand, bits [5:3] areavailable as a subopcode to diﬀerentiate among eight opcodes that have the same\n",
      ",. ,[:]) are part of the opcode.\n",
      "\n",
      ".then added to whatever is speciﬁed by theModR/M byte.B..SIB ByteIf the opcode speciﬁes that an operand is to be obtained from memory, the Mod-R/M byte speciﬁes the addressing mode, that is, the information that is neededto calculate the address of that operand. Some addressing modes require moreinformation than can be speciﬁed by the ModR/M byte alone. Those operandspeciﬁers (see the third entry in Table B.5) specify the inclusion of an SIB bytein the instruction. The SIB byte (for scaled-index-base), shown in Figure B.5, pro-vides scaling information and identiﬁes which register is to be used as an indexregister and/or which register is to be used as a base register. Taken together, theSIB byte computes scale/uni22C5index+base, where base and/or index can be zero,and scale can be 1. Table B.6 lists some of the interpretations of the SIB byte.B..DisplacementIf the ModR/M byte speciﬁes that the address calculation requires a displacement,the displacement (one, two, or four bytes) is contained in the instruction. Theopcode and/or ModR/M byte speciﬁes the size of the displacement.Figure B.6 shows the addressing mode calculation for the source operand ifthe instruction is as shown. The preﬁx x26 overrides the segment register andspeciﬁes using the ES segment. The ModR/M and SIB bytes specify that a four-byte displacement is to be added to the base register ECX+the index registerEBX after its contents is multiplied by 4.B..ImmediateRecall that the LC-3 allowed small immediate values to be present in the instruc-tion, by setting inst[5:5] to 1. The x86 also permits immediate values in theinstruction. As stated previously, if the opcode speciﬁes that a source operandis an immediate value in the instruction, it also speciﬁes the number of bytesof the instruction used to represent the operand. That is, an immediate can be\n",
      "\n",
      "\n",
      "AddressFigure B.Addressing mode calculation for Base+ScaledIndes+disp.represented in the instruction with one, two, or four bytes. Since the opcodealso speciﬁes the size of the operand, immediate values that can be stored infewer bytes than the operand size are ﬁrst sign-extended to their full size before\n",
      "Figure B.Example xinstruction in-bit mode: ADD EAX, $.\n",
      "\n",
      "B.An ExampleWe conclude this appendix with an example. The problem is one we have dealtwith extensively in Chapter 14. Given an input character string consisting of text,numbers, and punctuation, write a C program to convert all the lowercase lettersto uppercase. Figure B.8 shows a C program that solves this problem. Figure B.9shows the annotated LC-3 assembly language code that a C compiler would gen-erate. Figure B.10 shows the corresponding annotated x86 assembly languagecode, assuming we are operating the x86 in 32-bit mode. For readability, we showassembly language representations of the LC-3 and x86 programs rather than themachine code.#include <stdio.h>voidUpcaseString(charinputString[]);int main (void){char string[8];scanf(\"%s\", string);UpcaseString(string);}voidUpcaseString(charinputString[]){int i = 0;while(inputString[i]) {if (('a' <= inputString[i]) && (inputString[i] <= 'z'))inputString[i] = inputString[i] - ('a' - 'A');i++;}}Figure B.Cs o u r c ec o d ef o rt h eu p p e r - / l o w e r c a s ep r o g r a m .\n",
      "\n",
      "MicroarchitectureeL C -Weh a v es e e ni nC h a p t e r s4a n d5t h es e v e r a ls t a g e so ft h ei n s t r u c t i o nc y c l ethat must occur in order for the computer to process each instruction. If amicroarchitecture is to implement an ISA, it must be able to carry out this instruc-tion cycle for every instruction in the ISA. This appendix illustrates one exampleof a microarchitecture that can do that for the LC-3 ISA. Many of the details ofthe microarchitecture and the reasons for each design decision are well beyondthe scope of an introductory course. However, for those who want to understandhowam i c r o a r c h i t e c t u r ec a nc a r r yo u tt h er e q u i r e m e n t so fe a c hi n s t r u c t i o no ft h eLC-3 ISA, this appendix is provided.C.OverviewFigure C.1 shows the two main components of a microarchitecture: thedata path,which contains all the components that actually process the instructions, and thecontrol,w h i c hc o n t a i n sa l lt h ec o m p o n e n t st h a tg e n e r a t et h es e to fc o n t r o ls i g n a l sthat are needed to control the processing at each instant of time.We say, “at each instant of time,” but we really meanduring each clock cycle.That is, time is divided intoclock cycles.T h ec y c l et i m eo fam i c r o p r o c e s s o ri st h eduration of a clock cycle. A common cycle time for a microprocessor today is 0.33nanoseconds, which corresponds to 3 billion clock cycles each second. We saythat such a microprocessor is operating at a frequency of 3 gigahertz, or 3 GHz.At each instant of time—or, rather, during each clock cycle—the 52 controlsignals (as shown in Figure C.1) control both the processing in the data path andthe generation of the control signals for the next clock cycle. Processing in thedata path is controlled by 42 bits, and the generation of the control signals for thenext clock cycle is controlled by 10 bits.Note that the hardware that determines which control signals are needed eachclock cycle does not operate in a vacuum. On the contrary, the control signalsneeded in the “next” clock cycle depend on the following:1. The control signals that are present during the current clock cycle.2. The LC-3 instruction that is being executed.\n",
      "\n",
      "4240Control\n",
      "10Control Signals(J, COND, IRD)52Memory, I/OAddr16Inst.Data,1616DataData Path2\n",
      "RINTIR[15:11]BENPSR[15]ACV\n",
      "Figure C.Microarchitecture of the LC-,m a j o rc o m p o n e n t s .3. The privilege mode of the program that is executing, and whether theprocessor has the right to access a particular memory location.4. If that LC-3 instruction is a BR, whether the conditions for the branch havebeen met (i.e., the state of the relevant condition codes).5. Whether or not an external device is requesting that the processor beinterrupted.6. If a memory operation is in progress, whether it is completing during this cycle.Figure C.1 identiﬁes the speciﬁc information in our implementation of theLC-3 that corresponds to these six items. They are, respectively:1. J[5:0], COND[2:0], and IRD—ten bits of control signals provided by thecurrent clock cycle.2. inst[15:12], which identiﬁes the opcode, and inst[11:11], whichdiﬀerentiates JSR from JSRR (i.e., the addressing mode for the target of thesubroutine call).3. PSR[15], bit [15] of the Processor Status Register, which indicates whetherthe current program is executing with supervisor or user privileges, andACV, a signal that informs the processor that a process operating in User\n",
      "\n",
      "mode is trying to access a location in privileged memory. ACV stands forAccess Control Violation. When asserted, it denies the process access to theprivileged memory location.4. BEN to indicate whether or not a BR should be taken.5. INT to indicate that some external device of higher priority than theexecuting process requests service.6. R to indicate the end of a memory operation.C.The State MachineThe behavior of the LC-3 microarchitecture during a given clock cycle is com-pletely determined by the 52 control signals, combined with ten bits of addi-tional information (inst[15:11], PSR[15], ACV, BEN, INT, and R), as shown inFigure C.1. We have said that during each clock cycle, 42 of these control signalsdetermine the processing of information in the data path and the other ten controlsignals combine with the ten bits of additional information to determine whichset of control signals will be required in the next clock cycle.We say that these 52 control signals specify thestateof the control struc-ture of the LC-3 microarchitecture. We can completely describe the behavior ofthe LC-3 microarchitecture by means of a directed graph that consists of nodes(one corresponding to each state) and arcs (showing the ﬂow from each state tothe one[s] it goes to next). We call such a graph astate machine.Figure C.2, combined with Figure C.7, is the state machine for our implemen-tation of the LC-3. The state machine describes what happens during each clockcycle in which the computer is running. Each state is active for exactly one clockcycle before control passes to the next state. The state machine shows the step-by-step (clock cycle–by–clock cycle) process that each instruction goes throughfrom the start of its FETCH phase to the end of its instruction cycle, as describedin Section 4.3.2. Each node in the state machine corresponds to the activity thatthe processor carries out during a single clock cycle. The actual processing thatis performed in the data path is contained inside the node. The step-by-step ﬂowis conveyed by the arcs that take the processor from one state to the next.Let’s start our study of Figure C.2 by examining the FETCH phase of theinstruction cycle. As you know, every instruction goes through the same FETCHphase in its instruction cycle. Recall from Chapter 4 that the FETCH phase startswith a memory access to read the instruction at the address speciﬁed by the PC.Note that in the state numbered 18, the MAR is loaded with the address containedin PC, and the PC is incremented in preparation for the FETCH of the next LC-3instruction after the current instruction ﬁnishes its instruction cycle. If the contentof MAR speciﬁes privileged memory, and PSR[15]=1, indicating User mode,the access of the instruction will not be allowed. That would be an access controlviolation, so ACV is set. Finally, if there is no interrupt request present (INT=0),the ﬂow passes to the state numbered 33. We will describe in Section C.7 the ﬂowof control if INT=1, that is, if an external device is requesting an interrupt.\n",
      "\n",
      "Before we get into what happens during the clock cycle when the proces-sor is in the state numbered 33, we should explain the numbering system—thatis, why are states numbered 18 and 33. Recall, from our discussion of ﬁnitestate machines in Chapter 3, that each state must be uniquely speciﬁed and thatthis unique speciﬁcation is accomplished by means of state variables. Our statemachine that implements the LC-3 ISA requires 59 distinct states to implementthe entire behavior of the LC-3. Figure C.2 shows 31 of them plus pointers toseven others (states 8, 13, 15, 48, 49, 57, and 60). Figure C.7 shows the other28 states (including the seven that are pointed to in Figure C.2). We will visit allof them as we go through this appendix. Sinceklogical variables can uniquelyidentify 2kitems, six state variables are needed to uniquely specify 59 states. Thenumber next to each node in Figure C.2 and Figure C.7 is the decimal equivalentof the values (0 or 1) of the six state variables for the corresponding state. Thus,for example, the state numbered 18 has state variable values 010010.Now, back to what happens after the clock cycle in which the activity of state18 has ﬁnished. As we said, if no external device is requesting an interrupt, theﬂow passes to state 33 (i.e., 100001). From state 33, control passes to state 60if the processor is trying to access privileged memory while in User mode, or tostate 28, if the memory access is allowed, that is, if there is no ACV violation.We will discuss what happens if there is an ACV violation in Section C.7.In state 28, since the MAR contains the address of the instruction to be processed,this instruction is read from memory and loaded into the MDR. Since this memoryaccess can take multiple cycles, this state continues to execute until a ready signalfrom the memory (R) is asserted, indicating that the memory access has completed.Thus, the MDR contains the valid contents of the memory location specified byMAR. The state machine then moves on to state 30, where the instruction is loadedinto the instruction register (IR), completing the fetch phase of the instruction cycle.The state machine then moves to state 32, where DECODE takes place. Notethat there are 13 arcs emanating from state 32, each one corresponding to bits [15:12]of the LC-3 instruction. These are the opcode bits that direct the state machine toone of 16 paths to carry out the instruction cycle of the particular instruction that hasjust been fetched. Note that the arc from the last state of each instruction cycle (i.e.,the state that completes the processing of that LC-3 instruction) takes us to state 18(to begin the instruction cycle of the next LC-3 instruction).C.The Data PathThe data path consists of all components that actually process the informationduring each clock cycle—the functional units that operate on the information, theregisters that store information at the end of one cycle so it will be available forfurther use in subsequent cycles, and the buses and wires that carry informationfrom one point to another in the data path. Figure C.3, an expanded version ofwhat you have already encountered in Figure 5.18, illustrates the data path of ourmicroarchitecture of the LC-3.Note the control signals that are associated with each component in the datapath. For example, ALUK, consisting of two control signals, is associated with\n",
      "\n",
      "the ALU. These control signals determine how that component (the ALU) willbe used each cycle. Table C.1 lists the set of 42 control signals that control theelements of the data path and the set of values that each control signal can have.(Actually, for readability, we provide a symbolic name for each value, rather thanthe binary value.) For example, since ALUK consists of two bits, it can have oneof four values. Which value it has during any particular clock cycle depends onwhether the ALU is required to ADD, AND, NOT, or simply pass one of its inputsto the output during that clock cycle. PCMUX also consists of two control signalsand speciﬁes which input to the MUX is required during a given clock cycle.LD.PC is a single-bit control signal and is a 0 (NO) or a 1 (YES), depending onwhether or not the PC is to be loaded during the given clock cycle.During each clock cycle, corresponding to the “current state” in the statemachine, the 42 bits of control direct the processing of all components in the datapath that are required during that clock cycle. As we have said, the processingthat takes place in the data path during that clock cycle is speciﬁed inside thenode representing the state.C.The Control StructureThe control structure of a microarchitecture is speciﬁed by its state machine. Asdescribed earlier, the state machine (Figure C.2 and Figure C.7) determines whichcontrol signals are needed each clock cycle to process information in the data pathand which control signals are needed each clock cycle to direct the ﬂow of controlfrom the currently active state to its successor state.Figure C.4 shows a block diagram of the control structure of our implemen-tation of the LC-3. Many implementations are possible, and the design consider-ations that must be studied to determine which of many possible implementationsshould be used is the subject of a full course in computer architecture.We have chosen here a straightforward microprogrammed implementation.Each state of the control structure requires 42 bits to control the processing in thedata path and 10 bits to help determine which state comes next. These 52 bits arecollectively known as amicroinstruction. Each microinstruction (i.e., each stateof the state machine) is stored in one 52-bit location of a special memory calledthe control store. There are 59 distinct states. Since each state corresponds to onemicroinstruction in the control store, the control store for our microprogrammedimplementation requires six bits to specify the address of each microinstruction.Those six bits correspond to the state number associated with each state in thestate machine. For example, the microinstruction associated with state 18 is theset of 52 control signals stored in address 18 of the control store.Table C.2 lists the function of the ten bits of control information that helpdetermine which state comes next. Figure C.5 shows the logic of the micro-sequencer. The purpose of the microsequencer is to determine the address in thecontrol store that corresponds to the next state, that is, the location where the52 bits of control information for the next state are stored.\n",
      "\n",
      "\n",
      "Address of NextS t a t eFigure C.The microsequencer of the LC-.As we said, state 32 of the state machine (Figure C.2) performs the DECODEphase of the instruction cycle. It has 16 “next” states, depending on the LC-3instruction being executed during the current instruction cycle. If the IRD con-trol signal in the microinstruction corresponding to state 32 is 1, the output MUXof the microsequencer (Figure C.5) will take its source from the six bits formedby 00 concatenated with the four opcode bits IR[15:12]. Since IR[15:12] speci-ﬁes the opcode of the current LC-3 instruction being processed, the next addressof the control store will be one of 16 addresses, corresponding to the 15 opcodesplus the one unused opcode, IR[15:12]=1101. That is, each of the 16 next statesafter state 32 is the ﬁrst state to be carried out after the instruction has beendecoded in state 32. For example, if the instruction being processed is ADD, theaddress of the next state is state 1, whose microinstruction is stored at location000001. Recall that IR[15:12] for ADD is 0001.If, somehow, the instruction inadvertently contained IR[15:12]=1101,the unused opcode, the microarchitecture would execute a sequence ofmicroinstructions, starting at state 13. These microinstructions would respond tothe fact that an instruction with an illegal opcode had been fetched. Section C.7.3describes what happens in that case.\n",
      "\n",
      "(d)Figure C.Additional logic required to provide control signals.Several signals necessary to control the data path and the microsequencerare not among those listed in Tables C.1 and C.2. They are DR, SR1, BEN, INT,ACV, and R. Figure C.6 shows the additional logic needed to generate DR, SR1,BEN, and ACV.The INT signal is supplied by some event external to the normal instructionprocessing, indicating that normal instruction processing should be interruptedand this external event dealt with. The interrupt mechanism was described inChapter 9. The corresponding ﬂow of control within the microarchitecture isdescribed in Section C.7.The remaining signal, R, is a signal generated by the memory in order toallow the LC-3 to operate correctly with a memory that takes multiple clockcycles to read or store a value.Suppose it takes memory ﬁve cycles to read a value. That is, once MARcontains the address to be read and the microinstruction asserts READ, it will takeﬁve cycles before the contents of the speciﬁed location in memory is available tobe loaded into MDR. (Note that the microinstruction asserts READ by means oftwo control signals: MIO.EN/YES and R.W/RD; see Figure C.3.)\n",
      "\n",
      "Recall our discussion in Section C.2 of the function of state 28, whichaccesses an instruction from memory during the FETCH phase of each instruc-tion cycle. If the memory takes ﬁve cycles to read a value, for the LC-3 to operatecorrectly, state 28 must execute ﬁve times before moving on to state 30. That is,until MDR contains valid data from the memory location speciﬁed by the con-tents of MAR, we want state 28 to continue to re-execute. After ﬁve clock cycles,the memory has completed the “read,” resulting in valid data in MDR, so the pro-cessor can move on to state 30. What if the microarchitecture did not wait for thememory to complete the read operation before moving on to state 30? Since thecontents of MDR would still be garbage, the microarchitecture would put garbageinto the IR in state 30.The ready signal (R) enables the memory read to execute correctly. Since thememory knows it needs ﬁve clock cycles to complete the read, it asserts a readysignal (R) throughout the ﬁfth clock cycle. Figure C.2 shows that the next stateis 28 (i.e., 011100) if the memory read will not complete in the current clockcycle and state 30 (i.e., 011110) if it will. As we have seen, it is the job of themicrosequencer (Figure C.5) to produce the next state address.The ten microsequencer control signals for state 28 are:IRD/0 ; NOCOND/001 ; Memory ReadyJ/011100With these control signals, what next state address is generated by the microse-quencer? For each of the ﬁrst four executions of state 28, since R=0, the nextstate address is 011100. This causes state 28 to be executed again in the next clockcycle. In the ﬁfth clock cycle, since R=1, the next state address is 011110, andthe LC-3 moves on to state 30. Note that in order for the ready signal (R) frommemory to be part of the next state address, COND had to be set to 001, whichallowed R to pass through its four-input AND gate.C.The TRAP InstructionAs we have said, each LC-3 instruction follows its own path from state 32 toits ﬁnal state in its instruction cycle, after which it returns to state 18 to startprocessing the next instruction. As an example, we will follow the instructioncycle of the TRAP instruction, shown in Figure C.7.Recall that the TRAP instruction pushes the PSR and PC onto the systemstack, loads the PC with the starting address of the trap service routine, andexecutes the service routine from privileged memory.From state 32, the next state after DECODE is state 15, consistent with theTRAP instruction opcode 1111. In state 15, the Table register, which will beused to form MAR[15:8] of the trap vector table entry, is loaded with x00, thePC is incremented (we will see why momentarily), and the MDR is loaded withthe PSR in preparation for pushing it onto the system stack. Control passes tostate 47.\n",
      "\n",
      "In state 47, the trap vector (IR[7:0]) is loaded into the eight-bit registerVector, PSR[15] is set to Supervisor mode since the trap service routine exe-cutes in privileged memory, and the state machine branches to state 37 or 45,depending on whether the program that executed the TRAP instruction was inUser mode or Supervisor mode. If in User mode, state 45 saves the User StackPointer in SavedUSP, loads the stack pointer from SavedSSP, and continues onto state 37, where the processor starts pushing PSR and PC onto the stack. If theprogram executing the TRAP instruction is already in Privileged mode, state 45is not necessary.In states 37 and 41, the PSR is pushed onto the system stack. In states 43, 46,and 52, the PC is pushed onto the system stack. Note that in state 43, the PC isdecremented before being pushed onto the stack. This is necessary in the case ofdealing with interrupts and exceptions, which will be explained in Section C.7.This is not necessary for processing the TRAP instruction, which is why PC isincremented in state 15.The only thing remaining is to load PC with the starting address of the trapservice routine. This is done by loading MAR with the address of the proper entryin the trap vector table, obtained by concatenating Table and Vector (in state 54),loading the starting address from memory into MDR (in state 53), and loadingthe PC (in state 55). This completes the execution of the TRAP instruction, andcontrol returns to state 18 to begin processing the next instruction – in this case,the ﬁrst instruction of the trap service routine.The last instruction in every trap service routine is RTI (return from trap orinterrupt). From DECODE in state 32, the next state of RTI is state 8, consistentwith its eight-bit opcode 1000. In states 8, 36, and 38, the PC is popped oﬀthesystem stack and loaded into PC. In states 39, 40, 42, and 34, the PSR is poppedoﬀthe system stack and loaded into PSR. This returns the PC and PSR to thevalues it had before the trap service routine was executed. Finally, if the programthat invoked the TRAP instruction was in User mode, PSR[15] must be returnedto 1, the Supervisor Stack Pointer saved, and the User Stack Pointer loaded intoSP. This is done in state 59, completing the instruction cycle for RTI.C.Memory-Mapped I/OAs you know from Chapter 9, the LC-3 ISA performs input and output viamemory-mapped I/O, that is, with the same data movement instructions that ituses to read from and write to memory. The LC-3 does this by assigning anaddress to each device register. Input is accomplished by a load instruction whoseeﬀective address is the address of an input device register. Output is accomplishedby a store instruction whose eﬀective address is the address of an output deviceregister. For example, in state 25 of Figure C.2, if the address in MAR is xFE02,MDR is supplied by the KBDR, and the data input will be the last keyboardcharacter typed. On the other hand, if the address in MAR is a legitimate memoryaddress, MDR is supplied by the memory.\n",
      "\n",
      "\n",
      "otherWx otherRmem otherWx The state machine of Figure C.2 does not have to be altered to accommo-date memory-mapped I/O. However, something has to determine when memoryshould be accessed and when I/O device registers should be accessed. This is thejob of the address control logic (ADDR.CTL.LOGIC) shown in Figure C.3.Table C.3 is a truth table for the address control logic, showing what con-trol signals are generated, based on (1) the contents of MAR, (2) whether or notmemory or I/O is accessed this cycle (MIO.EN/NO, YES), and (3) whether a load(R.W/Read) or store (R.W/Write) is requested. Note that, for a memory-mappedload, data can be supplied to MDR from one of four sources: memory, KBDR,KBSR, or DSR. The address control logic provides the appropriate select signalsto the INMUX. For a memory-mapped store, the data supplied by MDR can bewritten to memory, KBSR, DDR, or DSR. The address control logic supplies theappropriate enable signal to the corresponding structure.C.Interrupt and Exception ControlThe ﬁnal piece of the state machine needed to complete the LC-3 story are thosestates that control the initiation of an interrupt, those states that control the returnfrom an interrupt (the RTI instruction), and those states that control the initiationof one of the three exceptions speciﬁed by the ISA.Interrupts and exceptions are very similar. Both stop the program that is cur-rently executing. Both push the PSR and PC of the interrupted program onto thesystem stack, obtain the starting address of the interrupt or exception service rou-tine from the interrupt vector table, and load that starting address into the ProgramCounter. The main diﬀerence between interrupts and exceptions is the nature of\n",
      "\n",
      "an interrupt by asserting its interrupt request signal. Recall from Chapter 9 thatif the priority level of the device asserting its interrupt request signal is higher thanboth the priority level of the currently executing program and any other externalinterrupt request asserted at the same time, INT is asserted and INTV is loadedwith the interrupt vector corresponding to that external event. The microproces-sor responds to INT by initiating the interrupt. That is, the processor puts itselfinto Supervisor mode if it isn’t in Supervisor mode, pushes the PSR and PC ofthe interrupted process onto the supervisor stack, and loads the PC with the start-ing address of the interrupt service routine. The PSR contains the privilege modePSR[15], priority level PSR[10:8], and condition codes PSR[2:0] of a program.It is important that when the processor resumes execution of the interrupted pro-gram, the privilege mode, priority level, and condition codes are restored to whatthey were when the interrupt occurred.The microarchitecture of the LC-3 initiates an interrupt as follows: Recallfrom Figure C.2 that in state 18, while MAR is loaded with the contents of PCand PC is incremented, INT is tested.State 18 is the only state in which the processor checks for interrupts. Thereason for only testing in state 18 is straightforward: Once an LC-3 instructionstarts processing, it is easier to let it ﬁnish its complete instruction cycle (FETCH,DECODE, etc.) than to interrupt it in the middle and have to keep track of how faralong it was when the external device requested an interrupt (i.e., asserted INT).If INT is only tested in state 18, the current instruction cycle can be aborted early(even before the instruction has been fetched), and control directed to initiatingthe interrupt.The test is enabled by the control signals that make up COND5, which are101 only in state 18, allowing the value of INT to pass through its four-input ANDgate, shown in Figure C.5, to contribute to the address of the next state. Since theCOND signals are not 101 in any other state, INT has no eﬀect in any other state.In state 18, the ten microsequencer control bits are as follows:IRD/0 ; NOCOND/101 ; Test forinterruptsJ/100001If INT=1, a 1 is produced at the output of the AND gate, which in turnmakes the next state address not 100001, corresponding to state 33, but rather110001, corresponding to state 49. This starts the initiation of the interrupt (seeFigure C.7).Several functions are performed in state 49. The PSR, which contains theprivilege mode, priority level, and condition codes of the interrupted program,are loaded into MDR, in preparation for pushing it onto the supervisor stack.PSR[15] is cleared, reﬂecting the change to Supervisor mode, since all inter-rupt service routines execute in Supervisor mode. The three-bit priority leveland eight-bit interrupt vector (INTV) provided by the interrupting device arerecorded. PSR[10:8] is loaded with the priority level of the interrupting device.The internal register Vector is loaded with INTV and the eight-bit register Tableis loaded with x01 in preparation for accessing the interrupt vector table to obtainthe starting address of the interrupt service routine. Finally, the processor tests\n",
      "\n",
      "the old PSR[15] to determine whether the stack pointers must be adjusted beforepushing PSR and PC.If the old PSR[15]=0, the processor is already operating in Supervisor mode.R6 is the Supervisor Stack Pointer (SSP), so the processor proceeds immediatelyto states 37 and 41 to push the PSR of the interrupted program onto the super-visor stack. If PSR[15]=1, the interrupted program was in User mode. In thatcase, the User Stack Pointer (USP) must be saved in SavedUSP and R6 must beloaded with the contents of SavedSSP before moving to state 37. This is done instate 45.The control ﬂow from state 49 to either 37 or 45 is enabled by the tenmicrosequencer control bits, as follows:IRD/0 ; NOCOND/100 ; TestPSR[15],privilegemodeJ/100101If PSR[15]=0, control goes to state 37 (100101); if PSR[15]=1, controlgoes to state 45 (101101).In state 37, R6 (the SSP) is decremented (preparing for the push), and MARis loaded with the address of the new top of the stack.In state 41, the memory is enabled to WRITE (MIO.EN/YES, R.W/WR).When the write completes, signaled by R=1, PSR has been pushed onto thesupervisor stack, and the ﬂow moves on to state 43.In state 43, the PC is loaded into MDR. Note that state 43 says MDR is loadedwith PC-1. Recall that in state 18, at the beginning of the instruction cycle for theinterrupted instruction, PC was incremented. Loading MDR with PC-1 adjustsPC to the correct address of the interrupted program.In states 46 and 52, the same sequence as in states 37 and 41 occurs, onlythis time the PC of the interrupted program is pushed onto the supervisor stack.The ﬁnal task to complete the initiation of the interrupt is to load the PCwith the starting address of the interrupt service routine. This is carried out bystates 54, 53, and 55. It is accomplished in a manner similar to the loading ofthe PC with the starting address of a TRAP service routine. The event causingthe INT request supplies the eight-bit interrupt vector INTV associated with theinterrupt, similar to the eight-bit trap vector contained in the TRAP instruction.This interrupt vector is stored in the eight-bit register INTV, shown on the datapath in Figure C.8.The interrupt vector table occupies memory locations x0100 to x01FF. Instate 54, the interrupt vector that was loaded into Vector in state 49 is combinedwith the base address of the interrupt vector table (x0100) and loaded into MAR.In state 53, memory is READ. When R=1, the read has completed, and MDRcontains the starting address of the interrupt service routine. In state 55, the PCis loaded with that starting address, completing the initiation of the interrupt.It is important to emphasize that the LC-3 supports two stacks, one for eachprivilege mode, and two stack pointers (USP and SSP), one for each stack. R6 isthe stack pointer and is loaded from the SavedSSP when privilege changes fromUser mode to Supervisor mode, and from SavedUSP when privilege changes\n",
      "\n",
      "from Supervisor mode to User mode. When the privilege mode changes, the cur-rent value in R6 must be stored in the appropriate “Saved” stack pointer in orderto be available the next time the privilege mode changes back.C..Returning from an Interrupt or Trap Service Routine, RTIInterrupt service routines, like trap service routines already described, end withthe execution of the RTI instruction. The job of the RTI instruction is to restorethe computer to the state it was in before the interrupt or trap service routine wasexecuted. This means restoring the PSR (i.e., the privilege mode, priority level,and the values of the condition codes N, Z, P) and restoring the PC. These valueswere pushed onto the stack during the initiation of the interrupt or execution ofthe TRAP instruction. They must, therefore, be popped oﬀthe stack in the reverseorder.The ﬁrst state after DECODE is state 8. Here we load the MAR with theaddress of the top of the supervisor stack, which contains the last thing pushed(that has not been subsequently popped)—the state of the PC when the interruptwas initiated. At the same time, we test PSR[15] since RTI is a privileged instruc-tion and can only execute in Supervisor mode. If PSR[15]=0, we can continueto carry out the requirements of RTI.States 36 and 38 restore PC to the value it had when the interrupt was initi-ated. In state 36, the memory is read. When the read is completed, MDR containsthe address of the instruction that was to be processed next when the interruptoccurred. State 38 loads that address into the PC.States 39, 40, 42, and 34 restore the privilege mode, priority level, and con-dition codes (N, Z, P) to their original values. In state 39, the Supervisor StackPointer is incremented so that it points to the top of the stack after the PC waspopped. The MAR is loaded with the address of the new top of the stack. State40 initiates the memory READ; when the READ is completed, MDR containsthe interrupted PSR. State 42 loads the PSR from MDR, and state 34 incrementsthe stack pointer.The only thing left is to check the privilege mode of the interrupted pro-gram to see whether the stack pointers have to be switched. In state 34, themicrosequencer control bits are as follows:IRD/0 ; NOCOND/100 ; TestPSR[15],privilegemodeJ/110011If PSR[15]=0, control ﬂows to state 51 (110011) to do nothing for one cycle.If PSR[15]=1, control ﬂows to state 59, where R6 is saved in SavedSSP andR6 is loaded from SavedUSP. In both cases, control returns to state 18 to beginprocessing the next instruction.C..Initiating an ExceptionThe LC-3 identiﬁes three cases where processing is not allowed to continue nor-mally due to something going awry in the executing program. We refer to thesecases as exceptions. They are initiated in the same way interrupts are initiated,\n",
      "\n",
      "by pushing the PSR and PC onto the system stack, obtaining the starting addressof the exception service routine from the interrupt vector table, and loading thataddress into the PC to initiate the exception service routine.The three exceptions identiﬁed in the LC-3 are (1) a privileged mode excep-tion caused by the program attempting to execute the RTI instruction while inUser mode, (2) the illegal opcode exception caused by the program trying to exe-cute an instruction whose opcode is 1101, and (3) an access control violation(ACV) exception caused by the program trying to access a privileged memorylocation while in User mode.C...Privilege Mode ExceptionIf the processor is in User mode (PSR[15]=1) and is attempting to executeRTI, a privilege mode exception occurs. The processor pushes the PSR and theaddress of the RTI instruction onto the supervisor stack and loads the PC withthe starting address of the service routine that handles privilege mode violations.Figure C.7 shows the ﬂow, starting with a branch from state 8 to state 44 ifPSR[15]=1.In state 44, the eight-bit Table register is loaded with x01, indicating theaddress of an entry in the interrupt vector table, and the eight-bit Vector registeris loaded with x00, indicating the ﬁrst entry in the interrupt vector table. The con-tents of x0100 is the starting address of the service routine that handles privilegemode exceptions. The MDR is loaded with the PSR of the program that causedthe exception in preparation for pushing it onto the system stack. Finally, PSR[15]is set to 0, since the service routine will execute with supervisor privileges. Thenthe processor moves to state 45, where it follows the same ﬂow as the initiationof interrupts.The main diﬀerence between this ﬂow and that for the initiation of interruptsis in state 54, where MAR is loaded with x01’Vector. In the case of interrupts,Vector is loaded in state 49 with INTV, which is supplied by the interruptingdevice. In the case of the privilege mode violation, Vector is loaded in state44 with x00.There are two additional functions performed in state 49 that are not per-formed in state 44. First, the priority level is changed, based on the priority ofthe interrupting device. We do not change the priority in handling a privilegemode violation. The service routine executes at the same priority as the programthat caused the violation. Second, a test to determine the privilege mode is per-formed for an interrupt. This is unnecessary for a privilege mode violation sincethe processor already knows it is executing in User mode.C...Illegal Opcode ExceptionAlthough it would be a rare situation, it is possible, we suppose, that a pro-grammer writing a program in machine language could mistakenly include aninstruction having opcode = 1101. Since there is no such opcode in the LC-3 ISA,the computer cannot process that instruction. State 32 performs the DECODE,and the next state is state 13.\n",
      "\n",
      "The action the processor takes is very similar to that of a privilege modeexception. The PSR and PC of the program are pushed onto the supervisor stack,and the PC is loaded with the starting address of the Illegal Opcode exceptionservice routine.State 13 is very similar to state 44, which starts the initiation of a privilegemode exception. There are two diﬀerences: (1) Vector is loaded with x01, sincethe starting address of the service routine for the illegal opcode exception is inx0101. (2) In the case of the privilege mode exception, we know the program isin User mode when the processor attempts to execute the RTI instruction. In thecase of an illegal opcode, the processor can be in either mode, so from state 13the processor goes to state 37 or state 45, depending on whether the program isexecuting in Supervisor mode or User mode when the illegal opcode instructionis encountered.Like state 44, the priority of the running program is not changed, since theurgency of handling the exception is the same as the urgency of executing theprogram that contains it. Like state 49, state 13 tests the privilege mode of theprogram that contains the illegal opcode, since if the currently executing pro-gram is in User mode, the stack pointers need to be switched as described inSection C.7.1. Like state 49, the processor then microbranches either to state 37if the stack pointer is already pointing to the supervisor stack, or to state 45 if thestack pointers have to be switched. From there, the initiating sequence continuesin states 37, 41, 43, etc., identical to what happens when an interrupt is initiated(Section C.7.1) or a privilege mode exception is initiated (Section C.7.3.1). ThePSR and PC are pushed onto the supervisor stack and the starting address of theservice routine is loaded into the PC, completing the initiation of the exception.C...Access Control Violation (ACV) ExceptionAn Access Control Violation (ACV) exception occurs if the processor attemptsto access privileged memory while operating in User mode. The state machinechecks for this in every case where the processor accesses memory, that is, instates 17, 19, 23, 33, and 35. If an ACV violation occurs, the next state is respec-tively states 56, 61, 48, 60, or 57 (see Figure C.2). In all ﬁve states, the processorloads Table with x01, Vector with x02, MDR with the PSR, sets PSR[15] to 0,exactly like state 44, with one exception. Vector is set to x02 since the startingaddress of the ACV exception service routine is in memory location x0102. Pro-cessing continues exactly like in state 44, moving ﬁrst to state 45 to switch to thesystem stack, and then pushing PSR and PC onto the stack and loading the PCwith the starting address of the service routine.C.Control StoreFigure C.9 completes our microprogrammed implementation of the LC-3. Itshows the contents of each location of the control store, corresponding to the52 control signals required by each state of the state machine. We have left theexact entries blank to allow you, the reader, the joy of ﬁlling in the required signalsyourself. The solution is available from your instructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, page in enumerate(textbook_cleaned):\n",
    "# for i, page in enumerate(textbook):\n",
    "    # print(page['page_number'], page['textbook_name'])\n",
    "    print(page['text'])\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save textbook to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "# save all_text json to file\n",
    "\n",
    "import json\n",
    "with open('../../non-public-datasets/cleaned_data/patel_textbook/patel_only_ECE120_content_keep_diagrams.json', 'w') as f:\n",
    "    json.dump(textbook_cleaned, f)\n",
    "\n",
    "print(len(textbook_cleaned)) # 740 pages remaining in patel textbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas = [dict(page_number=page['page_number'], textbook_name=page['textbook_name']) for page in textbook]\n",
    "textbook_texts = [page['text'] for page in textbook_cleaned]\n",
    "assert len(textbook_texts) == len(metadatas), 'must be equal sizes'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split the textbook string into context-size contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n"
     ]
    }
   ],
   "source": [
    "from langchain import text_splitter\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.text_splitter import CharacterTextSplitter, NLTKTextSplitter, SpacyTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "# good examples here: https://langchain.readthedocs.io/en/latest/modules/utils/combine_docs_examples/textsplitter.html\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-xxl')\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(tokenizer, chunk_size=350, chunk_overlap=80, separators = \". \")\n",
    "# texts = text_splitter.split_text(textbook)\n",
    "texts = text_splitter.create_documents(texts=textbook_texts, metadatas=metadatas)\n",
    "print(len(texts))\n",
    "\n",
    "# full textbook \n",
    "# 250 --> 2723\n",
    "# 350 --> 1692\n",
    "# 450 chunks -> 1397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='It does not matter which state since wenever use that information untilafterwe have set it to 1 or 0...The Gated D LatchTo be useful, it is necessary to control when a latch is set and when it is cleared.As i m p l ew a yt oa c c o m p l i s ht h i si sw i t ht h eg a t e dl a t c h .Figure 3.19 shows a logic circuit that implements a gatedDlatch. It consistsof the R-S latch of Figure 3.18, plus two additional NAND gates that allow the', lookup_str='', metadata={'page_number': 68, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='RFigure.Ag a t e dDl a t c h .latch to be set to the value ofD,b u tonlywhen WE is asserted (i.e., when WEequals 1). WE stands forwrite enable. When WE is not asserted (i.e., when WEequals 0), the outputsSandRare both equal to 1. SinceSandRare inputs to theR-S latch, if they are kept at 1, the value stored in the latch remains unchanged,as we explained in Section 3.4.1. When WE is momentarily set to 1, exactly oneof the outputsSorRis set to 0, depending on the value ofD. IfDequals 1, thenSis set to 0. IfDequals 0, then both inputs to the lower NAND gate are 1, resultinginRbeing set to 0. As we saw earlier, ifSis set to 0, the R-S latch is set to 1. IfRis set to 0, the R-S latch is set to 0. Thus, the R-S latch is set to 1 or 0 accordingto whetherDis 1 or 0. When WE returns to 0,SandRreturn to 1, and the valuestored in the R-S latch persists..The Concept of MemoryWe now have all the tools we need to describe one of the most important struc-tures in the electronic digital computer, itsmemory', lookup_str='', metadata={'page_number': 69, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='When WE returns to 0,SandRreturn to 1, and the valuestored in the R-S latch persists..The Concept of MemoryWe now have all the tools we need to describe one of the most important struc-tures in the electronic digital computer, itsmemory.W ew i l ls e ei nC h a p t e r4how memory ﬁts into the basic scheme of computer processing, and you will seethroughout the rest of the book and indeed the rest of your work with computershow important the concept of memory is to computing.Memory is made up of a (usually large) number of locations, each uniquelyidentiﬁable and each having the ability to store a value. We refer to the uniqueidentiﬁer associated with each memory location as itsaddress.W er e f e rt ot h enumber of bits of information stored in each location as itsaddressability.For example, an advertisement for a laptop computer might say, “This com-puter comes with 2 gigabytes of memory.” Actually, most ads generally usethe abbreviation 2 GB (or, often: 2 Gig). This statement means, as we willexplain momentarily, that the laptop includes two billion memory locations, eachcontaining one byte of information...Address SpaceWe refer to the total number of uniquely identiﬁable locations as the memory’saddress space', lookup_str='', metadata={'page_number': 69, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='” Actually, most ads generally usethe abbreviation 2 GB (or, often: 2 Gig). This statement means, as we willexplain momentarily, that the laptop includes two billion memory locations, eachcontaining one byte of information...Address SpaceWe refer to the total number of uniquely identiﬁable locations as the memory’saddress space.A2G Bm e m o r y ,f o re x a m p l e ,r e f e r st oam e m o r yt h a tc o n s i s t so ftwo billion uniquely identiﬁable memory locations.', lookup_str='', metadata={'page_number': 69, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Actually, the number two billion is only an approximation, due to the way wespecify memory locations. Since everything else in the computer is representedby sequences of 0s and 1s, it should not be surprising that memory locations areidentiﬁed by binary addresses as well. Withnbits of address, we can uniquelyidentify 2nlocations. Ten bits provide 1024 locations, which is approximately1000. If we have 20 bits to represent each address, we have 220uniquely identi-ﬁable locations, which is approximately one million. With 30 bits, we have 230locations, which is approximately one billion. In the same way we use the preﬁxes“kilo” to represent 210(approximately 1000) and “mega” to represent 220(approx-imately one million), we use the preﬁx “giga” to represent 230(approximatelyone billion). Thus, 2 giga really corresponds to the number of uniquely iden-tiﬁable locations that can be speciﬁed with 31 address bits. We say the addressspace is 231,w h i c hi sexactly2,147,483,648 locations, rather than 2,000,000,000,although we colloquially refer to it as two billion...AddressabilityThe number of bits stored in each memory location is the memory’s addressabil-ity', lookup_str='', metadata={'page_number': 70, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='We say the addressspace is 231,w h i c hi sexactly2,147,483,648 locations, rather than 2,000,000,000,although we colloquially refer to it as two billion...AddressabilityThe number of bits stored in each memory location is the memory’s addressabil-ity. A 2-gigabyte memory (written 2GB) is a memory consisting of 2,147,483,648memory locations, each containing one byte (i.e., eight bits) of storage. Mostmemories are byte-addressable. The reason is historical; most computers got theirstart processing data, and one character stroke on the keyboard corresponds to one8-bit ASCII code, as we learned in Chapter 2. If the memory is byte-addressable,then each ASCII character occupies one location in memory. Uniquely identi-fying each byte of memory allows individual bytes of stored information to bechanged easily.Many computers that have been designed speciﬁcally to perform large scien-tiﬁc calculations are 64-bit addressable. This is due to the fact that numbers usedin scientiﬁc calculations are often represented as 64-bit ﬂoating-point quantities.Recall that we discussed the ﬂoating-point data type in Chapter 2. Since scientiﬁccalculations are likely to use numbers that require 64 bits to represent them, it isreasonable to design a memory for such a computer that stores one such numberin each uniquely identiﬁable memory location...A-by--Bit MemoryFigure 3', lookup_str='', metadata={'page_number': 70, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Recall that we discussed the ﬂoating-point data type in Chapter 2. Since scientiﬁccalculations are likely to use numbers that require 64 bits to represent them, it isreasonable to design a memory for such a computer that stores one such numberin each uniquely identiﬁable memory location...A-by--Bit MemoryFigure 3.20 illustrates a memory of size 22by 3 bits. That is, the memoryhas an address space of four locations and an addressability of three bits.Am e m o r yo fs i z e22requires two bits to specify the address. We describethe two-bit address as A[1:0]. A memory of addressability three stores threebits of information in each memory location. We describe the three bitsof data as D[2:0]. In both cases, our notation A[high:low] and D[high:low]reﬂects the fact that we have numbered the bits of address and data fromright to left, in order, starting with the rightmost bit, which is numbered 0', lookup_str='', metadata={'page_number': 70, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='We describe the three bitsof data as D[2:0]. In both cases, our notation A[high:low] and D[high:low]reﬂects the fact that we have numbered the bits of address and data fromright to left, in order, starting with the rightmost bit, which is numbered 0.The notation [high:low] means a sequence ofhigh−low+1b i t ss u c ht h a t“high” is the bit number of the leftmost (orhigh)b i tn u m b e ri nt h es e q u e n c eand “low” is the bit number of the rightmost (orlow)b i tn u m b e ri nt h es e q u e n c e .', lookup_str='', metadata={'page_number': 70, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='D[1]D[2]D[0]Figure.A-by--bit memory.Accesses of memory require decoding the address bits. Note that the addressdecoder takes as input the address bitsA[1:0] and asserts exactly one of its fouroutputs, corresponding to theword linebeing addressed. In Figure 3.20, each rowof the memory corresponds to a unique three-bit word, thus the termword line.Memory can be read by applying the addressA[1:0], which asserts the word lineto be read. Note that each bit of the memory is ANDed with its word line and thenORed with the corresponding bits of the other words. Since only one word linecan be asserted at a time, this is eﬀectively a mux with the output of the decoderproviding the select function to each bit line. Thus, the appropriate word is readatD[2:0].Figure 3.21 shows the process of reading location 3. The code for 3 is 11.The addressA[1:0]=11 is decoded, and the bottom word line is asserted. Notethat the three other decoder outputs are not asserted. That is, they have the value0. The value stored in location 3 is 101. These three bits are each ANDed withtheir word line producing the bits 101, which are supplied to the three outputOR gates. Note that all other inputs to the OR gates are 0, since they have beenproduced by ANDing with their unasserted word lines', lookup_str='', metadata={'page_number': 71, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='That is, they have the value0. The value stored in location 3 is 101. These three bits are each ANDed withtheir word line producing the bits 101, which are supplied to the three outputOR gates. Note that all other inputs to the OR gates are 0, since they have beenproduced by ANDing with their unasserted word lines. The result is thatD[2:0]= 101. That is, the value stored in location 3 is output by the OR gates. Memory', lookup_str='', metadata={'page_number': 71, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='D[1]D[2]D[0]  10 1Figure.Reading locationin our-by--bit memory.can be written in a similar fashion. The address speciﬁed byA[1:0] is presented tothe address decoder, resulting in the correct word line being asserted. With writeenable (WE) also asserted, the three bitsD[2:0] can be written into the three gatedlatches corresponding to that word line..Sequential Logic CircuitsIn Section 3.3, we discussed digital logic structures that process information(decision structures, we call them) wherein the outputs depend solely on the val-ues that are present on the inputsnow.E x a m p l e sa r em u x e s ,d e c o d e r s ,a n df u l ladders. We call these structures combinational logic circuits. In these circuits,there is no sense of the past. Indeed, there is no capability for storing any infor-mation about anything that happened before the present time. In Sections 3.4and 3.5, we described structures that do store information—in Section 3.4, somebasic storage elements, and in Section 3.5, a simple 22-by-3-bit memory.', lookup_str='', metadata={'page_number': 72, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Figure.Sequential logic circuit block diagram.In this section, we discuss digital logic structures that canbothprocess infor-mation (i.e., make decisions)andstore information. That is, these structures basetheir decisions not only on the input values now present, but also (and this isvery important) on what has happened before. These structures are usually calledsequential logic circuits. They are distinguishable from combinational logic cir-cuits because, unlike combinational logic circuits, they contain storage elementsthat allow them to keep track of prior history information. Figure 3.22 shows ablock diagram of a sequential logic circuit. Note the storage elements. Note alsothat the output can be dependent on both the inputs now and the values stored inthe storage elements. The values stored in the storage elements reﬂect the historyof what has happened before.Sequential logic circuits are used to implement a very important class ofmechanisms calledﬁnite state machines.W eu s eﬁ n i t es t a t em a c h i n e si ne s s e n -tially all branches of engineering. For example, they are used as controllers ofelectrical systems, mechanical systems, and aeronautical systems', lookup_str='', metadata={'page_number': 73, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='For example, they are used as controllers ofelectrical systems, mechanical systems, and aeronautical systems. A traﬃcl i g h tcontroller that sets the traﬃcl i g h tt or e d ,y e l l o w ,o rg r e e nd e p e n d so nt h el i g h tthat is currently on (history information) and input information from sensors suchas trip wires on the road, a timer keeping track of how long the current light hasbeen on, and perhaps optical devices that are monitoring traﬃc.We will see in Chapter 4 when we introduce the von Neumann model of acomputer that a ﬁnite state machine is at the heart of the computer. It controls theprocessing of information by the computer...A Simple Example: The Combination LockAs i m p l ee x a m p l es h o w st h ed iﬀerence between combinational logic structuresand sequential logic structures. Suppose one wishes to secure a bicycle with alock, but does not want to carry a key. A common solution is the combinationlock. The person memorizes a “combination” and uses it to open the lock. Twocommon types of locks are shown in Figure 3.23.In Figure 3', lookup_str='', metadata={'page_number': 73, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Suppose one wishes to secure a bicycle with alock, but does not want to carry a key. A common solution is the combinationlock. The person memorizes a “combination” and uses it to open the lock. Twocommon types of locks are shown in Figure 3.23.In Figure 3.23a, the lock consists of a dial, with the numbers from 0 to 30equally spaced around its circumference. To open the lock, one needs to knowthe “combination.” One such combination could be: R13-L22-R3. If this werethe case, one would open the lock by turning the dial two complete turns to theright (clockwise), and then continuing until the dial points to 13, followed by one', lookup_str='', metadata={'page_number': 73, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='(a) (b)Figure.Combination locks.complete turn to the left (counterclockwise), and then continuing until the dialpoints to 22, followed by turning the dial again to the right (clockwise) until itpoints to 3. At that point, the lock opens. What is important here is thesequenceof the turns. The lock will not open, for example if one performed two turns to theright, and then stopped on 22 (instead of 13), followed by one complete turn tothe left, ending on 13, followed by one turn to the right, ending on 3. That is, eventhough the ﬁnal position of the dial is 3, and even though R22-L13-R3 uses thesame three numbers as the combination R13-L22-R3, the lock would not open.Why? Because the lock stores the previous rotations and makes its decision (openor don’t open) on the basis of the the history of the past operations, that is, on thecorrectsequencebeing performed.Another type of lock is shown in Figure 3.23b. The mechanism consists of(usually) four wheels, each containing the digits 0 through 9. When the digitsare lined up properly, the lock will open. In this case, the combination is the setof four digits. Whether or not this lock opens is totally independent of the pastrotations of the four wheels. The lock does not care at all about past rotations.The only thing important is the current value of each of the four wheels', lookup_str='', metadata={'page_number': 74, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='When the digitsare lined up properly, the lock will open. In this case, the combination is the setof four digits. Whether or not this lock opens is totally independent of the pastrotations of the four wheels. The lock does not care at all about past rotations.The only thing important is the current value of each of the four wheels. This isas i m p l ee x a m p l eo fac o m b i n a t i o n a ls t r u c t u r e .It is curious that in our everyday speech, both mechanisms are referred toas “combination locks.” In fact, only the lock of Figure 3.23b is a combinationallock. The lock of Figure 3.23a would be better called a sequential lock!..The Concept of StateFor the mechanism of Figure 3.23a to work properly, it has to keep track of thesequence of rotations leading up to the opening of the lock. In particular, it hasto diﬀerentiate the correct sequence R13-L22-R3 from all other sequences. Forexample, R22-L13-R3 must not be allowed to open the lock. Likewise, R10-L22-R3 must also not be allowed to open the lock.For the lock of Figure 3.23a to work, it must identify several relevantsituations, as follows:A', lookup_str='', metadata={'page_number': 74, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Forexample, R22-L13-R3 must not be allowed to open the lock. Likewise, R10-L22-R3 must also not be allowed to open the lock.For the lock of Figure 3.23a to work, it must identify several relevantsituations, as follows:A. The lock is not open, and NO relevant operations have beenperformed.B. The lock is not open, but the user has just completed theR13 operation.', lookup_str='', metadata={'page_number': 74, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='C. The lock is not open, but the user has just completed R13,followed by L22.D. The lock is open, since the user has just completed R13,followed by L22, followed by R3.We have labeled these four situations A, B, C, and D. We refer to each of thesesituations as thestateof the lock.The notion ofstateis a very important concept in computer engineering, andactually, in just about all branches of engineering. The state of a mechanism—more generally, the state of a system—is a snapshot of that system in which allrelevant items are explicitly expressed.That is:The state of a system is a snapshot of all the relevant elements of thesystem at the moment the snapshot is taken.In the case of the lock of Figure 3.23a, there are four states A, B, C, and D.Either the lock is open (State D), or if it is not open, we have already performedeither zero (State A), one (State B), or two (State C) correct operations. This isthe sum total of all possible states that can exist.Question: Why are there exactly four states needed to describe the combina-tion lock of Figure 3', lookup_str='', metadata={'page_number': 75, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='This isthe sum total of all possible states that can exist.Question: Why are there exactly four states needed to describe the combina-tion lock of Figure 3.23a? Can you think of a snapshot of the combination lockafter an operation (Rn or Ln) that requires a ﬁfth state because it is not coveredby one of the four states A, B, C, or D?There are many examples of systems that you are familiar with that can beeasily described by means of states.The state of a game of basketball can be described by the scoreboard in thebasketball arena. Figure 3.24 shows the state of the basketball game as Texas 73,Oklahoma 68, 7 minutes and 38 seconds left in the second half, 14 seconds left onthe sfoulsball\\nFigure.An example of a state.', lookup_str='', metadata={'page_number': 75, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='(a) (b) (c)Figure.Three states in a tic-tac-toe machine.at w o - p o i n ts h o t ,t h en e ws t a t ew o u l db ed e s c r i b e db yt h eu p d a t e ds c o r e b o a r d .That is, the score would then be Texas 75, Oklahoma 68, the time remaining inthe game would be 7 minutes and 26 seconds, the shot clock would be back to 25seconds, and Oklahoma would have the ball.The game of tic-tac-toe can also be described in accordance with the notionof state. Recall that the game is played by two people (or, in our case, a personand the computer). The state is a snapshot of the game in progress each time thecomputer asks the person to make a move. The game is played as follows: Thereare nine locations on the diagram. The person and then the computer take turnsplacing an X (the person) and an O (the computer) in an empty location. Theperson goes ﬁrst', lookup_str='', metadata={'page_number': 76, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='The state is a snapshot of the game in progress each time thecomputer asks the person to make a move. The game is played as follows: Thereare nine locations on the diagram. The person and then the computer take turnsplacing an X (the person) and an O (the computer) in an empty location. Theperson goes ﬁrst. The winner is the ﬁrst to place three symbols (three Xs for theperson, three Os for the computer) in a straight line, either vertically, horizontally,or diagonally.The initial state, before either the person or the computer has had a turn, isshown in Figure 3.25a. Figure 3.25b shows a possible state of the game when theperson is prompted for a second move, if he/she put an X in the upper left corneras his/her ﬁrst move, and the computer followed with an O in the middle squareas its ﬁrst move. Figure 3.25c shows a possible state of the game when the personis prompted for a third move if he/she put an X in the upper right corner on thesecond move, and the computer followed by putting its second O in the uppermiddle location.One ﬁnal example: a very old soft drink machine, when drinks sold for15 cents, and the machine would only take nickels (5 cents) and dimes (10 cents)and not be able to give change', lookup_str='', metadata={'page_number': 76, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='One ﬁnal example: a very old soft drink machine, when drinks sold for15 cents, and the machine would only take nickels (5 cents) and dimes (10 cents)and not be able to give change.The state of the machine can be described as the amount of money inserted,and whether the machine is open (so one can remove a bottle). There are onlythree possible states:A. The lock is open, so a bottle can be (or has been!) removed.B. The lock is not open, but 5 cents has been inserted.C. The lock is not open, but 10 cents has been inserted...The Finite State Machine and Its State DiagramWe have seen that a state is a snapshot of all relevant parts of a system at aparticular point in time. At other times, that system can be in other states. Wehave described four systems: a combination lock, a basketball game, a tic-tac-toe machine, and a very old soft drink machine when a bottle of cola cost only', lookup_str='', metadata={'page_number': 76, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='15 cents. The behavior of each of these systems can be speciﬁed by aﬁnite statemachine,a n dr e p r e s e n t e da sastate diagram.Aﬁ n i t es t a t em a c h i n ec o n s i s t so fﬁ v ee l e m e n t s :1. a ﬁnite number of states2. a ﬁnite number of external inputs3. a ﬁnite number of external outputs4. an explicit speciﬁcation of all state transitions5. an explicit speciﬁcation of what determines each externaloutput value.The set of states represents all possible situations (or snapshots) that the sys-tem can be in. Each state transition describes what it takes to get from one stateto another.Let’s examine the ﬁnite state machines for these four systems.The Combination LockAs t a t ed i a g r a mi sac o n v e n i e n tr e p r e s e n t a t i o no faﬁnite state machine. Figure 3.26 is a state diagram for the combination lock.Recall, we identiﬁed four states A, B, C, and D', lookup_str='', metadata={'page_number': 77, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Figure 3.26 is a state diagram for the combination lock.Recall, we identiﬁed four states A, B, C, and D. Which state we are in dependson the progress we have made in getting from a random initial state to the lockbeing open. In the state diagram of Figure 3.26, each circle corresponds to oneof the four states, A, B, C, or D.The external inputs are R13, L22, R3, and R-other-than-13, L-other-than-22,and R-other-than-3.The external output is either the lock is open or the lock is not open. (Onelogical variable will suﬃce to describe that!) As shown in the state diagram, instates A, B, and C, the combination lock is locked. In state D, the combinationloth\\nFigure.State diagram of the combination lock of Figure.a.', lookup_str='', metadata={'page_number': 77, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='on each arc speciﬁes which state the system is coming from and which state it isgoing to. We refer to the state the system is coming from as thecurrent state,and the state it is going to as thenext state.T h ec o m b i n a t i o nl o c kh a se i g h ts t a t etransitions. Associated with each transition is the input that causes the transitionfrom the current state to the next state. For example, R13 causes the transitionfrom state A to state B.Ac o u p l eo ft h i n g sa r ew o r t hn o t i n g .F i r s t ,i ti su s u a l l yt h ec a s et h a tf r o macurrent state there are multiple transitions to next states. The state transition thatoccurs depends on both the current state and the value of the external input. Forexample, if the combination lock is in state B, and the input is L22, the next stateis state C. If the current state is state B and the input is anything other than L22,the next state is state A', lookup_str='', metadata={'page_number': 78, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='The state transition thatoccurs depends on both the current state and the value of the external input. Forexample, if the combination lock is in state B, and the input is L22, the next stateis state C. If the current state is state B and the input is anything other than L22,the next state is state A. In short, the next state is determined by the combinationof the current state and the current external input.The output values of a system can also be determined by the combination ofthe current state and the value of the current external input. However, as is the casefor the combination lock, where states A, B, and C specify the lock is “locked,”and state D speciﬁes the lock is “unlocked,” the output can also be determinedsolely by the current state of the system. In all the systems we will study in thisbook, the output values will be speciﬁed solely by the current state of the system.AV e r yO l dS o f tD r i n kM a c h i n eFigure 3.27 is the state diagram for the softdrink machine.The soft drink machine has only three states: 5 cents has been inserted,10 cents has been inserted, and at least 15 cents has been inserted. Transitionsare caused by the insertion (the input) of a nickel or a dime. The output is asso-\\nFigure.State diagram of the soft drink machine', lookup_str='', metadata={'page_number': 78, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='The soft drink machine has only three states: 5 cents has been inserted,10 cents has been inserted, and at least 15 cents has been inserted. Transitionsare caused by the insertion (the input) of a nickel or a dime. The output is asso-\\nFigure.State diagram of the soft drink machine.AB a s k e t b a l lG a m eWe could similarly draw a state diagram for the basketballgame we described earlier, where each state would be one possible conﬁgurationof the scoreboard. A transition would occur if either the referee blew a whistle orthe other team got the ball. We showed earlier the transition that would be causedby Texas scoring a two-point shot. Clearly, the number of states in the ﬁnite statemachine describing a basketball game would be huge.', lookup_str='', metadata={'page_number': 78, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Also clearly, the number of legitimate transitions from one state to another issmall, compared to the number of arcs one could draw connecting arbitrary pairsof states. For example, there is no arc from a score of Texas 68, Oklahoma 67 toTexas 75, Oklahoma 91, since no single input can cause that transition. The inputis the activity that occurred on the basketball court since the last transition. Someinput values are: Texas scored two points, Oklahoma scored three points, Texasstole the ball, Oklahoma successfully rebounded a Texas shot, and so forth.The output is the ﬁnal result of the game. The output has three values: Gamestill in progress, Texas wins, Oklahoma wins', lookup_str='', metadata={'page_number': 79, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Question:Can one have an arc from a state where the score is Texas 30,Oklahoma 28 to a state where the score is tied, Texas 30, Oklahoma 30? Is itpossible to have two states, one where Texas is ahead 30-28 and the other wherethe score is tied 30-30, but no arc between the two?AT i c - T a c - T o eM a c h i n eWe could also draw a state diagram for a tic-tac-toemachine, in our case when a person is playing against a computer', lookup_str='', metadata={'page_number': 79, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Each state is arepresentation of the position of the game when the person is asked to put an Xinto one of the empty cells. Figure 3.25 shows three states. The transition from thestate of Figure 3.25a to the state of Figure 3.25b is caused by the person puttingan X in the top left cell, followed by the computer putting an O in the center cell.The transition from the state of Figure 3.25b to the state of Figure 3.25c is causedby the person putting an X in the top right cell, followed by the computer puttingan O in the top middle cell.Since there are nine cells, and each state has an X, an O, or nothing in eachcell, there must be fewer than 39states in the tic-tac-toe machine. Clearly thereare far fewer than that, due to various constraints of the game.There are nine inputs, corresponding to the nine cells a person can put anXi n .T h e r ea r et h r e eo u t p u t s :( a )g a m es t i l li np r o g r e s s ,( b )p e r s o nw i n s ,a n d(c) computer wins..', lookup_str='', metadata={'page_number': 79, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='..The Synchronous Finite State MachineUp to now a transition from a current state to a next state in our ﬁnite state machinehappened when it happened. For example, a person could insert a nickel into thesoft drink machine and then wait 10 seconds or 10 minutes before inserting thenext coin into the machine. And the soft drink machine would not complain. Itwould not dispense the soft drink until 15 cents was inserted, but it would waitpatiently as long as necessary for the 15 cents to be inserted. That is, there is noﬁxed amount of time between successive inputs to the ﬁnite state machine. Thisis true in the case of all four systems we have discussed. We say these systems areasynchronousbecause there is nothing synchronizing when each state transitionmust occur.However, almost no computers work that way. On the contrary, we say thatcomputers aresynchronousbecause the state transitions take place, one after theother, at identical ﬁxed units of time. They are controlled by asynchronous ﬁnitestate machine. We will save for Chapter 4 and beyond the state transitions thatoccur at identical, ﬁxed units of time that control a computer. In this chapter, we', lookup_str='', metadata={'page_number': 79, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='will take on a simpler task, the design of a traﬃcc o n t r o l l e r ,a na d m i t t e d l ys i m p l e rstructure, but one that is also controlled by a synchronous ﬁnite state machine.It is worth pointing out that both the four asynchronous ﬁnite state machinesdiscussed above and the synchronous ﬁnite state machine that controls a digitalcomputer share an important characteristic: They carry out work, one state tran-sition at a time, moving closer to a goal. In the case of the combination lock, aslong as you make the correct moves, each state transition takes us closer to thelock opening. In the case of the soft drink machine, each state transition takes uscloser to enjoying the taste of the soft drink. In the case of a computer, each statetransition takes us closer to solving a problem by processing a computer programthat someone has written..', lookup_str='', metadata={'page_number': 80, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='In the case of the soft drink machine, each state transition takes uscloser to enjoying the taste of the soft drink. In the case of a computer, each statetransition takes us closer to solving a problem by processing a computer programthat someone has written...The ClockAs y n c h r o n o u sﬁ n i t es t a t em a c h i n et r a n s i t i o n sf r o mi t sc u r r e n ts t a t et oi t sn e x tstate after an identical ﬁxed interval of time. Control of that synchronous behavioris in part the responsibility of the clock circuit.Ac l o c kc i r c u i tp r o d u c e sas i g n a l ,c o m m o n l yr e f e r r e dt oa sTHE clock, whosevalue alternates between 0 volts and some speciﬁed ﬁxed voltage. In digital logicterms, the clock is a signal whose value alternates between 0 and 1. Figure 3', lookup_str='', metadata={'page_number': 80, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='In digital logicterms, the clock is a signal whose value alternates between 0 and 1. Figure 3.28shows the value of the clock signal as a function of time. Each of the repeatedsequence of identical intervals is referred to as aclock cycle.Ac l o c kc y c l es t a r t swhen the clock signal transitions from 0 to 1 and ends the next time the clocksignal transitions from 0 to 1.We will see in Chapter 5 and beyond that in each clock cycle, a computercan perform a piece of useful work. When people say their laptop computers runat a frequency of 2 gigahertz, they are saying their laptop computers performtwo billion pieces of work each second since 2 gigahertz means two billion clockcycles each second, each clock cycle lasting for just one-half of a nanosecond. Thesynchronous ﬁnite state machine makes one state transition each clock cycle.We will show by means of a traﬃcs i g n a lc o n t r o l l e rh o wt h ec l o c ks i g n a lcontrols the transition, ﬁxed clock cycle after ﬁxed clock cycle, from one state tothe next.\\n10Figure.Ac l o c ks i g n a l .', lookup_str='', metadata={'page_number': 80, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='..Example: A Danger SignMany electrical, mechanical, and aeronautical systems are controlled by a syn-chronous ﬁnite state machine. In this section, we will design the complete logicneeded for a synchronous ﬁnite state machine to control a traﬃcd a n g e rs i g n .Figure 3.29 shows the danger sign as it will be placed on the highway. Note thesign says, “Danger, Move Right.” The sign contains ﬁve lights (labeled 1 through5i nt h eﬁ g u r e ) .The purpose of our synchronous ﬁnite state machine (a.k.a. a controller) is todirect the behavior of our system. In our case, the system is the set of lights on thetraﬃcd a n g e rs i g n .T h ec o n t r o l l e r ’ sj o bi st oh a v et h eﬁ v el i g h t sﬂ a s ho na n doﬀto warn automobile drivers to move to the right. The controller is equipped withas w i t c h', lookup_str='', metadata={'page_number': 81, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='The controller is equipped withas w i t c h .W h e nt h es w i t c hi si nt h eO Np o s i t i o n ,t h ec o n t r o l l e rd i r e c t st h el i g h t sas follows: During one unit of time, all lights will be oﬀ. In the next unit of time,lights 1 and 2 will be on. The next unit of time, lights 1, 2, 3, and 4 will be on.Then all ﬁve lights will be on. Then the sequence repeats: no lights on, followedby 1 and 2 on, followed by 1, 2, 3, and 4 on, and so forth. Each unit of time lastsonedirthelig\\nFigure.At r aﬃcd a n g e rs i g n .The State Diagram for the Danger Sign ControllerFigure 3.30 is a state dia-gram for the synchronous ﬁnite state machine that controls the lights. There arefour states, one for each of the four conditions corresponding to which lights areon', lookup_str='', metadata={'page_number': 81, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='At r aﬃcd a n g e rs i g n .The State Diagram for the Danger Sign ControllerFigure 3.30 is a state dia-gram for the synchronous ﬁnite state machine that controls the lights. There arefour states, one for each of the four conditions corresponding to which lights areon. Note that the outputs (whether each light is on or oﬀ)a r ed e t e r m i n e db yt h ecurrent state of the system.If the switch is on (input=1), the transition from each state to the nextstate happens at one-second intervals, causing the lights to ﬂash in the sequence', lookup_str='', metadata={'page_number': 81, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='1Figure.State diagram for the danger sign controller.described. If the switch is turned oﬀ(input=0), the state always transitions tostate A, the “all oﬀ”s t a t e .The Sequential Logic Circuit for the Danger Sign ControllerRecall thatFigFigto\\nClockFigure.Sequential logic circuit for the danger sign controller.', lookup_str='', metadata={'page_number': 82, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='First, the two external inputs: the switch and the clock. The switch determineswhether the ﬁnite state machine will transition through the four states or whetherit will transition to state A, where all lights are oﬀ.T h eo t h e ri n p u t( t h ec l o c k )controls the transition from state A to B, B to C, C to D, and D to A by controllingthe state of the storage elements. We will see how, momentarily.Second, there are two storage elements for storing state information. Sincethere are four states, and since each storage element can store one bit of informa-tion, the four states are identiﬁed by the contents of the two storage elements: A(00), B (01), C (10), and D (11). Storage element 2 contains the high bit; storageelement 1 contains the low bit. For example, the danger sign controller is in stateBw h e ns t o r a g ee l e m e n t2i s0a n ds t o r a g ee l e m e n t1i s1 .Third, combinational logic circuit 1 shows that the on/oﬀbehavior of thelights is controlled by the storage elements', lookup_str='', metadata={'page_number': 83, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Third, combinational logic circuit 1 shows that the on/oﬀbehavior of thelights is controlled by the storage elements. That is, the input to the combinationallogic circuit is from the two storage elements, that is, the current state of the ﬁnitestate machine.Finally, combinational logic circuit 2 shows that the transition from the cur-rent state to the next state depends on the two storage elements and the switch. Ifthe switch is on, the output of combinational logic circuit 2 depends on the stateof the two storage elements.The Combinational LogicFigure 3.32 shows the logic that implements com-binational lo ic circuits 1 and 2.extertwo s\\nFigure.Combinational logic circuitsand.', lookup_str='', metadata={'page_number': 83, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='First, let us look at the outputs that control the lights. As we have said, thereare only three outputs necessary to control the lights. Light 5 is controlled bythe output of the AND gate labeled V, since the only time light 5 is on is whenthe controller is in state 11. Lights 3 and 4 are controlled by the output of theOR gate labeled X, since there are two states in which those lights are on, thoselabeled 10 and 11. Why are lights 1 and 2 controlled by the output of the OR gatelabeled W? See Exercise 3.42.Next, let us look at the internal outputs that control the storage elements,which specify the next state of the controller. Storage element 2 should be setto 1 for the next clock cycle if the next state is 10 or 11. This is true only if theswitch is on and the current state is either 01 or 10. Therefore, the output signalthat will make storage element 2 be 1 in the next clock cycle is the output of theOR gate labeled Y. Why is the next state of storage element 1 controlled by theoutput of the OR gate labeled Z? See Exercise 3.42.The Two Storage ElementsIn order for the danger sign controller to work, thestate transitions must occur once per second when the switch is on', lookup_str='', metadata={'page_number': 84, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='AP r o b l e mw i t hG a t e dL a t c h e sa sS t o r a g eE l e m e n t sWhat would happen if thestorage elements were gated D latches? If the two storage elements were gatedDl a t c h e s ,w h e nt h ew r i t ee n a b l es i g n a l( t h ec l o c k )i s1 ,t h eo u t p u to fO Rg a t e sY and Z would immediately change the bits stored in the two gated D latches', lookup_str='', metadata={'page_number': 84, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='This would produce new input values to the three AND gates that are input toOR gates Y and Z, producing new outputs that would be applied to the inputs ofthe gated latches, which would in turn change the bits stored in the gated latches,which would in turn mean new inputs to the three AND gates and new outputsof OR gates Y and Z. This would happen again and again, continually changingthe bits stored in the two storage elements as long as the Write Enable signal tothe gated D latches was asserted. The result: We have no idea what the state of theﬁnite state machine would be for the next clock cycle. And, even in the currentclock cycle, the state of the storage elements would change so fast that the ﬁvelights would behave erratically.The problem is the gated D latch. We want the output of OR gates Y and Zto transition to the next state at the end of the current clock cycle and allow thecurrent state to remain unchanged until then. That is, we do not want the inputto the storage elements to take eﬀect until the end of the current clock cycle.Since the output of a gated D latch changes immediately in response to its inputif the Write Enable signal is asserted, it cannot be the storage element for oursynchronous ﬁnite state machine. We need storage elements that allow us to readthe current state throughout the current clock cycle, and not write the next statevalues into the storage elements until the beginning of the next clock cycle', lookup_str='', metadata={'page_number': 84, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='We need storage elements that allow us to readthe current state throughout the current clock cycle, and not write the next statevalues into the storage elements until the beginning of the next clock cycle.The Flip-Flop to the RescueIt is worth repeating: To prevent the above fromhappening, we need storage elements that allow us to read the current statethroughout the current clock cycle, and not write the next state values into thestorage elements until the beginning of the next clock cycle. That is, the function', lookup_str='', metadata={'page_number': 84, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='ClockFigure.Am a s t e r / s l a v eﬂ i p - ﬂ o p .to be performed during a single clock cycle involves reading and writing a partic-ular variable. Reading must be allowed throughout the clock cycle, and writingmust occur at the end of the clock cycle.Aﬂ i p - ﬂ o pc a na c c o m p l i s ht h a t .O n ee x a m p l eo faﬂ i p - ﬂ o pi st h em a s t e r / s l a v eﬂip-ﬂop shown in Figure 3.33. The master/slave ﬂip-ﬂop can be constructed outof two gatedDlatches, one referred to as the master, the other referred to as theslave. Note that the write enable signal of the master is 1 when the clock is 0, andthe write enable signal of the slave is 1 when the clock is 1.Figure 3.34 is a timing diagram for the master/slave ﬂip-ﬂop, which showshow and why the master/slave ﬂip-ﬂop solves the problem. A timing diagramshows time passing from left to right', lookup_str='', metadata={'page_number': 85, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Figure 3.34 is a timing diagram for the master/slave ﬂip-ﬂop, which showshow and why the master/slave ﬂip-ﬂop solves the problem. A timing diagramshows time passing from left to right. Note that clock cycle n starts at the timelabeled 1 and ends at the time labeled 4. Clock cycle n+1 starts at the timelabeled 4.Consider clock cycle n, which we will discuss in terms of its ﬁrst half A, itssecond half B, and the four time points labeled 1, 2, 3, and 4.At the start of each clock cycle, the outputs of the storage elements are theoutputs of the two slave latches. These outputs (starting at time 1) are input tothe AND gates, resulting in OR gates Y and Z producing the next state values forthe storage elements (at time 2). The timing diagram shows the propagation delayof the combinational logic, that is, the time it takes for the combinational logicto produce outputs of OR gates Y and Z. Although OR gates Y and Z producethe Next State value sometime during half-cycle A, the write enable signal to themaster latches is 0, so the next state cannot be written into the master latches.At the start of half-cycle B (at time 3), the clock signal is 0, which meansthe write enable signal to the master latches is 1, and the master latches can bewritten', lookup_str='', metadata={'page_number': 85, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='At the start of half-cycle B (at time 3), the clock signal is 0, which meansthe write enable signal to the master latches is 1, and the master latches can bewritten. However, during the half-cycle B, the write enable to the slave latches is0, so the slave latches cannot write the new information now stored in the masterlatches.At the start of clock cycle n+1 (at time 4), the write enable signal to the slavelatches is 1, so the slave latches can store the next state value that was created bythe combinational logic during clock cycle n. This becomes the current state forclock cycle n+1.', lookup_str='', metadata={'page_number': 85, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='nal to the master latches is now 0, the state of theThus, although the write enable signal to the slavetc h a n g eb e c a u s et h em a s t e rl a t c h e sc a n n o tc h a n g e .slave latches contains the current state of the systemcle and produces the inputs to the six AND gates ints. Their state changes at the start of the clock cycleby storing the next state information created by the combinational logic duringthe previous cycle but does not change again during the clock cycle. The reasonthey do not change again during the clock cycle is as follows: During half-cycleA, the master latches cannot change, so the slave latches continue to see the stateinformation that is the current state for the new clock cycle. During half-cycle B,the slave latches cannot change because the clock signal is 0.Meanwhile, during half-cycle B, the master latches can store the next stateinformation produced by the combinational logic, but they cannot write it intothe slave latches until the start of the next clock cycle, when it becomes the stateinformation for the next clock cycle.', lookup_str='', metadata={'page_number': 86, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Meanwhile, during half-cycle B, the master latches can store the next stateinformation produced by the combinational logic, but they cannot write it intothe slave latches until the start of the next clock cycle, when it becomes the stateinformation for the next clock cycle..Preview of Coming Attractions:The Data Path of the LC-In Chapter 5, we will specify a computer, which we call the LC-3, and you willhave the opportunity to write computer programs to execute on it. We close outChapter 3 with a discussion of Figure 3.35, thedata pathof the LC-3 computer.The data path consists of all the logic structures that combine to processinformation in the core of the computer. Right now, Figure 3.35 is undoubtedlymore than a little intimidating, but you should not be concerned by that. You arenot ready to analyze it yet. That will come in Chapter 5. We have included ithere, however, to show you that you are already familiar with many of the basicstructures that make up a computer. For example, you see ﬁve MUXes in the datapath, and you already know how they work. Also, an adder (shown as the ALUsymbol with a + sign inside) and an ALU. You know how those elements areconstructed from gates.One element that we have not identified explicitly yet is a register. A registeris simply a set ofnflip-flops that collectively are used to store onen-bit value. InFigure 3', lookup_str='', metadata={'page_number': 86, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='You know how those elements areconstructed from gates.One element that we have not identified explicitly yet is a register. A registeris simply a set ofnflip-flops that collectively are used to store onen-bit value. InFigure 3.35, PC, IR, MAR, and MDR are all 16-bit registers that store 16 bits ofinformation each. The block labeled REG FILE consists of eight registers that eachstore 16 bits of information. As you know, one bit of information can be stored inone flip-flop. Therefore, each of these registers consists of 16 flip-flops. The datapath also shows three 1-bit registers,N,Z, andP.T h o s er e g i s t e r sr e q u i r eo n l yo n eflip-flop each. In fact, a register can be any size that we need. The size depends onlyon the number of bits we need to represent the value we wish to store.One way to implement registers is with master/slave ﬂip-ﬂops. Figure 3.36shows a four-bit register made up of four master/slave ﬂip-ﬂops. We usually needﬂip-ﬂops, rather than latches, because it is usually important to be able to bothread the contents of a register throughout a clock cycle and also store a new value', lookup_str='', metadata={'page_number': 86, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[200:250]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embed each context, and save it to a vector database, this one is hosted by Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/kastanday/.cache/torch/sentence_transformers/intfloat_e5-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import HuggingFaceEmbeddings #OpenAIEmbeddings, \n",
    "import pinecone\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# See the docs here, (search for pinecone): https://langchain.readthedocs.io/en/latest/reference/modules/vectorstore.html\n",
    "\n",
    "\n",
    "pinecone.init(api_key='87823627-c1f4-48fe-9c36-3d19d3dd29bb', environment=\"us-west1-gcp\")\n",
    "\n",
    "model_name = \"intfloat/e5-large\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "pinecone_index = Pinecone.from_texts(\n",
    "    texts=textbook_texts,\n",
    "    metadatas=metadatas,\n",
    "    embedding=embeddings,\n",
    "    index_name=\"uiuc-chatbot\" \n",
    ")\n",
    "\n",
    "# see the Pinecone index here (requires auth): https://app.pinecone.io/organizations/-NF9ryDGePT7APP6wrFM/projects/us-west1-gcp:32dcf9c/indexes/uiuc-chatbot-2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✅ Done with critical steps, the rest is for demonstration only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Easily run simliarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code to run Pinecone search during inference.\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "# pinecone.init(api_key=\"***\", environment=\"us-west1-gcp\")\n",
    "# pincecone_index = pinecone.Index(\"uiuc-chatbot\")\n",
    "# vectorstore = Pinecone(index=pincecone_index, embedding_function=embeddings, text_key=\"text\")\n",
    "# question = \"What is a finite state machine in electrical engineering?\"\n",
    "# relevant_context_list = pinecone_index.similarity_search(question, k=3)\n",
    "\n",
    "# for d in relevant_context_list:\n",
    "#     print(d.page_content)\n",
    "#     print(d.metadata['page_number'], d.metadata['textbook_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82  3.1.3 Finite State Machines Aﬁnite state machine (orFSM) is a model for understanding the behavior of a system by describin g the system as occupying one of a ﬁnite set of states, moving betwe en these states in response to external inputs, and producing external outputs. In any given state, a pa rticular input may cause the FSM to move to another state; this combination is called a transition rule . An FSM comprises ﬁve parts: a ﬁnite set of states, a set of possible inputs, a set of possible outputs, a set of transition rules, and methods for calculating outputs. When an FSM is implemented as a digital system, all states must be rep resented as patterns using a ﬁxed number of bits, all inputs must be translated into bits, and all outpu ts must be translated into bits. For a digital FSM, transition rules must be complete ; in other words, given any state of the FSM, and any pattern of input bits, a transition must be deﬁned from that state to another state (transitions from a state to itself, called self-loops , are acceptable). And, of course, calculation of outputs for a dig ital FSM reduces to Boolean logic expressions. In this class, we focus on clocked sync hronous FSM implementations, in which the FSM’s internal state bits are stored in ﬂip-ﬂops. In this section, we introduce the tools used to describe, develop, a nd analyze implementations of FSMs with digital logic. In the next few weeks, we will show you how an FSM can se rve as the central control logic in a computer. At the same time, we will illustrate connections between F SMs and software and will make some connections with other areas of interest in ECE, such as the design and analysis of digital control systems. The table below gives a list of abstract states for a typical keyless entry system for a car. In this case, we have merely named the states rather than specifying the bit pat terns to be used for each state—for this reason, we refer to them as abstract states. The description of the states in the ﬁrst column is an optional element often included in the early design stages for an FSM, when ide ntifying the states needed for the design. A list may also include the outputs for each state. Again, in th e list below, we have speciﬁed these outputs abstractly. By including outputs for each state, we implicit ly assume that outputs depend only on the state of the FSM. We discuss this assumption in more detail later in these notes (see “Machine Models”), but will make the assumption throughout our class. meaning state driver’s door other doors alarm on vehicle locked LOCKED locked locked no driver door unlocked DRIVER unlocked locked no all doors unlocked UNLOCKED unlocked unlocked no alarm sounding ALARM locked locked yes Another tool used with FSMs is the next-state table (sometimes called a state transition table , or just astate table ), which maps the current state and input combination into the next state of the FSM. The abstract variant shown below outlines desired behavior at a high leve l, and is often ambiguous, incomplete, and even inconsistent. For example, what happens if a user pushes two buttons? What happens if they push unlock while the alarm is sounding? These questions should event ually be considered. However, we can already start to see the intended use of the design: starting f rom a locked car, a user can push “unlock” once to gain entry to the driver’s seat, or push “unlock” twice to op en the car fully for passengers. To lock the car, a user can push the “lock” button at any time. And, if a use r needs help, pressing the “panic” button sets oﬀ an alarm. state action/input next state LOCKED push “unlock” DRIVER DRIVER push “unlock” UNLOCKED (any) push “lock” LOCKED (any) push “panic” ALARM\n",
      "\n",
      "3.1 Serialization and Finite State Machines 79 ECE120: Introduction to Computer Engineering Notes Set 3.1 Serialization and Finite State Machines The third part of our class builds upon the basic combinational and se quential logic elements that we developed in the second part. After discussing a simple application of stored state to trade between area and performance, we introduce a powerful abstraction for formalizin g and reasoning about digital systems, the Finite State Machine (FSM). General FSM models are broadly applicab le in a range of engineering contexts, including not only hardware and software design but also the design o f control systems and distributed systems. We limit our model so as to avoid circuit timing issues in your ﬁr st exposure, but provide some amount of discussion as to how, when, and why you should eventually learn the more sophisticated models. Through development a range of FSM examples, we illustrate importa nt design issues for these systems and motivateacoupleofmoreadvancedcombinationallogicdevicesthat canbe usedasbuilding blocks. Together with the idea of memory, another form of stored state, these elem ents form the basis for development of our ﬁrst computer. At this point we return to the textbook, in whic h Chapters 4 and 5 provide a solid introduction to the von Neumann model of computing systems and t he LC-3 (Little Computer, version 3) instruction set architecture. By the end of this part of the cours e, you will have seen an example of the boundary between hardware and software, and will be ready to wr ite some instructions yourself. In this set of notes, we cover the ﬁrst few parts of this material. W e begin by describing the conversion of bit-sliced designs into serial designs, which store a single bit slice’s out put in ﬂip-ﬂops and then feed the outputs back into the bit slice in the next cycle. As a speciﬁc example, we use our bit-sliced comparator to discuss tradeoﬀs in area and performance. We introduce Finite S tate Machines and some of the tools used to design them, then develop a handful of simple counter desig ns. Before delving too deeply into FSM design issues, we spend a little time discussing other strategies for c ounter design and placing the material covered in our course in the broader context of digital system des ign. Remember that sections marked with an asterisk are provided solely for your interest, but you may need to learn this material in later classes. 3.1.1 Serialization: General Strategy In previous notes, we discussed and illustrated the development of bit-sliced logic, in which one designs a logic block to handle one bit of a multi-bit operation, then replicates th e bit slice logic to construct a design for the entire operation. We developed ripple carry adders in this wa y in Notes Set 2.3 and both unsigned and 2’s complement comparators in Notes Set 2.4. Another interesting design strategy is serialization : rather than replicating the bit slice, we can use ﬂip- ﬂops to store the bits passed from one bit slice to the next, then pr esent the stored bits to the same bit slice in the next cycle. Thus, in a serial design, we only need one copy of th e bit slice logic! The area needed for a serial design is usually much less than for a bit-sliced design, but such a design is also usually slower. After illustrating the general design strategy, we’ll consider thes e tradeoﬀs more carefully in the context of a detailed example. Recall the general bit-sliced design ap- proach, as illustrated to the right. Some number of copies of the logic for a single bit slice are connected in sequence. Each bit slice accepts Pbits of operand input and produces Qbits of external output. Adjacent bit slices receive an addi- tionalMbits of information from the previous bit slice and pass along Mbits to the next bit slice, generallyusing some representation chosen by the designer.P Qsecond bit sliceMP Qlast bit sliceMP QM Moutput logicRinitial values . . .first bit sliceresults per−slice outputsper−slice inputsa general bit−sliced design The ﬁrst bit slice is initialized by passing in constant values, and some ca lculation may be performed on the ﬁnal bit slice’s results to produce Rbits more external output.\n",
      "\n",
      "3.3 Design of the Finite State Machine for the Lab 103 be reached from any of the states in our design. We might then try to leverage the fact that the next- state patterns from these two states are not relevant (recall that we ﬁxed the next-state patterns for all four of the possible PAID states) to further simplify our logic, but doing so does not provide any advan- tage (you may want to check our claim). The ﬁnal state table is shown to the right. We have included the extra states at the bottom of the table. Wehavespeciﬁedthenext-statelogicfortheseS+ 2S+ 1S+ 0 state S2S1S0T= 0T= 1A P PAID1 010 000 100 1 1 PAID2 101 000 100 1 1 DIME 000 001 101 1 0 REJECTD 001 001 101 0 0 QUARTER 100 010 110 1 0 REJECTQ 110 010 110 0 0 EXTRA1 011 000 100 x x EXTRA2 111 000 100 x x states, but left the output bits as don’t cares. A state transition diagram appears at the bottom of this page. 3.3.4 Testing the Design Having a complete design on paper is a good step forward, but human s make mistakes at all stages. How can we know that a circuit that we build in the lab correctly implements t he FSM that we have outlined in these notes? For the lab design, we have two problems to solve. First, we have not speciﬁed an initialization scheme for the FSM. We may want the FSM to start in one of the PAID states, bu t adding initialization logic to the design may mean requiring you to wire together signiﬁcantly more chip s. Second, we need a sequence of inputs that manages to test that all of the next-state and outpu t logic implementations are correct. Testing sequential logic, including FSMs, is in general extremely diﬃcu lt. In fact, large sequential systems today are generally converted into combinational logic by using shift registers to ﬁll the ﬂip-ﬂops with a particular pattern, executing the logic for one clock cycle, and che cking that the resulting pattern of bits in the ﬂip-ﬂops is correct. This approach is called scan-based testing , and is discussed in ECE 543. You will make use of a similar approach when you test your combinational logic in the second week of the lab, before wiring up the ﬂip-ﬂops. We have designed our FSM to be easy to test (even small FSMs may be challenging) with a brute force approach. In particular, we identify two input sequences that tog ether serve both to initialize and to test a correctly implemented variant of our FSM. Our initialization sequence forces the FSM into a speciﬁc state regardless of its initial state. And our test sequence crosses eve ry transition arc leaving the six valid states. In terms of T, the coin type, we initialize the FSM with the input sequence 001. Notic e that such a sequence takes any initial state into PAID2. For testing, we use the input sequence 111010010001. You should trace this sequence, starting from PAID2, on the diagram below to see how the test sequence covers all of the possible arcs. As we test, we need also to observe the AandPoutputs in each state to check the output logic. T=0 T=0 T=1T=1 T=1T=1 T=1T=0 T=0T=0 T=1T=1 T=0T=1T=0 T=0 QTR 100/10PAID1 010/11PAID2 101/11EXTRA1 011/xxEXTRA2 111/xxDIME 000/10REJECTD 001/00 REJECTQ 110/00\n",
      "\n",
      "3.2 Finite State Machine Design Examples, Part I 89 ECE120: Introduction to Computer Engineering Notes Set 3.2 Finite State Machine Design Examples, Part I This set of notes uses a series of examples to illustrate design princip les for the implementation of ﬁnite state machines (FSMs) using digital logic. We begin with an overview of the design process for a digital FSM, from the development of an abstract model through the imple mentation of functions for the next-state variables and output signals. Our ﬁrst few examples cover only the c oncrete aspects: we implement several counters, which illustrate the basic process of translating a concr ete and complete state transition diagram into an implementation based on ﬂip-ﬂops and logic gates. We next con sider a counter with a number of states that is not a power of two, with which we illustrate the need fo r FSM initialization. We then consider the design process as a whole through a more gene ral example of a counter with multiple inputs to control its behavior. We work from an abstract model do wn to an implementation, illustrating how semantic knowledge from the abstract model can be used to sim plify the implementation. Finally, we illustrate how the choice of representation for the FSM’s internal s tate aﬀects the complexity of the imple- mentation. Fortunately, designs that are more intuitive and easier for humans to understand also typically make the best designs in terms of other metrics, such as logic comple xity. 3.2.1 Steps in the Design Process Before we begin exploring designs, let’s talk brieﬂy about the genera l approach that we take when designing an FSM. We follow a six-step process: 1. develop an abstract model 2. specify I/O behavior 3. complete the speciﬁcation 4. choose a state representation 5. calculate logic expressions 6. implement with ﬂip-ﬂops and gates In Step 1, we translate our description in human language into a mode l with states and desired behavior. At this stage, we simply try to capture the intent of the description and are not particularly thorough nor exact. Step 2 begins to formalize the model, starting with its input and outpu t behavior. If we eventually plan to develop an implementation of our FSM as a digital system (which is no t the only choice, of course!), all input and output must consist of bits. Often, input and/or output speciﬁcations may need to match other digital systems to which we plan to connect our FSM. In fact, most problems in developing large digital systems today arise because of incompatibilities when comp osing two or more separately designed pieces (or modules ) into an integrated system. Once we know the I/O behavior for our FSM, in Step 3 we start to mak e any implicit assumptions clear and to make any other decisions necessary to the design. Occasion ally, we may choose to leave something undecided in the hope of simplifying the design with “don’t care” entrie s in the logic formulation. In Step 4, we select an internal representation for the bits neces sary to encode the state of our FSM. In practice, for small designs, this representationcan be selected b y a computer in such a way as to optimize the implementation. However, for large designs, such as the LC-3 instr uction set architecture that we study later in this class, humans do most of the work by hand. In the later examp les in this set of notes, we show how even a small design can leverage meaningful information from the de sign when selecting the representation, leading to an implementation that is simpler and is easier to build correct ly. We also show how one can use abstraction to simplify an implementation. By Step 5, our design is a complete speciﬁcation in terms of bits, and w e need merely derive logic expressions for the next-state variables and the output signals. This process is no diﬀerent than for combinational logic, and should already be fairly familiar to you.\n",
      "\n",
      "Figure.Sequential logic circuit block diagram.In this section, we discuss digital logic structures that canbothprocess infor-mation (i.e., make decisions)andstore information. That is, these structures basetheir decisions not only on the input values now present, but also (and this isvery important) on what has happened before. These structures are usually calledsequential logic circuits. They are distinguishable from combinational logic cir-cuits because, unlike combinational logic circuits, they contain storage elementsthat allow them to keep track of prior history information. Figure 3.22 shows ablock diagram of a sequential logic circuit. Note the storage elements. Note alsothat the output can be dependent on both the inputs now and the values stored inthe storage elements. The values stored in the storage elements reﬂect the historyof what has happened before.Sequential logic circuits are used to implement a very important class ofmechanisms calledﬁnite state machines.W eu s eﬁ n i t es t a t em a c h i n e si ne s s e n -tially all branches of engineering. For example, they are used as controllers ofelectrical systems, mechanical systems, and aeronautical systems. A traﬃcl i g h tcontroller that sets the traﬃcl i g h tt or e d ,y e l l o w ,o rg r e e nd e p e n d so nt h el i g h tthat is currently on (history information) and input information from sensors suchas trip wires on the road, a timer keeping track of how long the current light hasbeen on, and perhaps optical devices that are monitoring traﬃc.We will see in Chapter 4 when we introduce the von Neumann model of acomputer that a ﬁnite state machine is at the heart of the computer. It controls theprocessing of information by the computer...A Simple Example: The Combination LockAs i m p l ee x a m p l es h o w st h ed iﬀerence between combinational logic structuresand sequential logic structures. Suppose one wishes to secure a bicycle with alock, but does not want to carry a key. A common solution is the combinationlock. The person memorizes a “combination” and uses it to open the lock. Twocommon types of locks are shown in Figure 3.23.In Figure 3.23a, the lock consists of a dial, with the numbers from 0 to 30equally spaced around its circumference. To open the lock, one needs to knowthe “combination.” One such combination could be: R13-L22-R3. If this werethe case, one would open the lock by turning the dial two complete turns to theright (clockwise), and then continuing until the dial points to 13, followed by one\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Easily run similarity search on the Pinecone index\n",
    "question = \"What is a finite state machine in electrical engineering?\"\n",
    "relevant_context_list = pinecone_index.similarity_search(question, k=5)\n",
    "\n",
    "for d in relevant_context_list:\n",
    "    print(d.page_content)\n",
    "    # print(d.metadata['page_number'], d.metadata['textbook_name'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ISA speciﬁes the memory organization, register set, and instruction set,including the opcodes, data types, and addressing modes of the instructions inthe instruction set...Memory OrganizationThe LC-3 memory has an address space of 216(i.e., 65,536) locations, and anaddressability of 16 bits. Not all 65,536 addresses are actually used for memorylocations, but we will leave that discussion for Chapter 9. Since the normal unitof data that is processed in the LC-3 is 16 bits, we refer to 16 bits as oneword,and we say the LC-3 isword-addressable...RegistersSince it usually takes far more than one clock cycle to obtain data from mem-ory, the LC-3 provides (like almost all computers) additional temporary storagelocations that can be accessed in a single clock cycle.The most common type of temporary storage locations, and the one used inthe LC-3, is a set of registers. Each register in the set is called ageneral purposeregister(GPR). Like memory locations, registers store information that can beoperated on later. The number of bits stored in each register is usually one word.In the LC-3, this means 16 bits.Registers must be uniquely identiﬁable. The LC-3 speciﬁes eight GPRs, eachidentiﬁed by a three-bit register number. They are referred to as R0, R1,…R7.Figure 5.1 shows a snapshot of the LC-3’s register set, sometimes called aregisterﬁle,w i t ht h ee i g h tv a l u e s1 ,3 ,5 ,7 ,−2,−4,−6, and−8s t o r e di nR 0 ,…R7,respectively.\n",
      "Figure.A snapshot of the LC-’s register ﬁle.\n",
      "105.0 Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems\n",
      "LC-ISAA.OverviewThe instruction set architecture (ISA) of the LC-3 is deﬁned as follows:Memory address space16 bits, corresponding to 216locations, eachcontaining one word (16 bits). Addresses are numbered from 0 (i.e., x0000)to 65,535 (i.e., xFFFF). Addresses are used to identify memory locationsand memory-mapped I/O device registers. Certain regions of memory arereserved for special uses, as described in Figure A.1.\n",
      "xFFFFFigure A.Memory map of the LC-\n",
      "200.0 Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems\n",
      "NOT).Data movementinstructions move information from the processing unitto and from memory and to and from input/output devices. The LC-3 has six datamovement instructions.Controlinstructions are necessary for altering the sequential processing ofinstructions. That is, normally the next instruction executed is the instructioncontained in the next memory location. If a program consists of instructions1,2,3,4...10 located in memory locations A, A+1, A+2, ...A+9, normally theinstructions would be executed in the sequence 1,2,3...10. We will see before weleave Chapter 4, however, that sometimes we will want to change the sequence.Control instructions enable us to do that.An LC-3 instruction consists of 16 bits (one word), numbered from left toright, bit [15] to bit [0]. Bits [15:12] contain the opcode. This means there are atmost 24distinct opcodes. Actually, we use only 15 of the possible four-bit codes.One is reserved for some future use. Bits [11:0] are used to ﬁgure out where theoperands are.Exa\n",
      "s a or a as e er e con en s o reg s er o e con en s o\n",
      "94.0 Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems\n"
     ]
    }
   ],
   "source": [
    "# Easily run similarity search on the Pinecone index\n",
    "question = \"What is a LC-3?\"\n",
    "relevant_context_list = pinecone_index.similarity_search(question, k=3)\n",
    "\n",
    "for d in relevant_context_list:\n",
    "    print(d.page_content)\n",
    "    print(d.metadata['page_number'], d.metadata['textbook_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "reader = pipeline(\n",
    "  tokenizer='roberta-large',\n",
    "  model='roberta-large',\n",
    "  task='question-answering',\n",
    "  device='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "question=\"What is a programmable logic array (PLA)?\"\n",
    "for doc in relevant_context_list:\n",
    "  answer = reader(question=question, context=doc.page_content)\n",
    "  print(answer)\n",
    "  print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8513702ffebcddd0565c7cb8940121422c1007cb2eaee71f9f7918f25ee15d0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
