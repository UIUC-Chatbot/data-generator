[
  {
    "textbook-paragraph": "produce it gives  F=S_1S_0{V^+{S_1}S_0{V^.  If we  ignore the two states outside of the main loop for S, the first term  is 1 only when the lights are green on the East and West roads and the  detector for the North and South roads indicates that no vehicles are  approaching.  Similarly, the second term is 1 only when the lights are  green on the North and South roads and the detector for the East and  West roads indicates that no vehicles are approaching.  What happens when F=1?  First, the OR gate feeding into the timer's LD input produces a 1, meaning that the timer loads a new value instead of counting down.  Second, the OR gate controlling the lower mux selects the A input.  In other words, the timer is reset to A cycles, corresponding to the initial value for the green light states. In other words, the light stays green until vehicles approach on  the other road, plus A more cycles.  Unfortunately, the signal F may also be 1 in the unused states of S, in which case the lights on both roads may remain red even though cars are waiting on one of the roads.  To avoid this behavior, we must be  sure to initialize the state S to one of the six states in the desired loop.    {From FSM to Computer}  The FSM designs we have explored so far have started with a human-based design process in which someone writes down the desired behavior in terms of states, inputs, outputs, and transitions.  Such an approach makes it easier to build a digital FSM, since the abstraction used corresponds almost directly to the implementation.  As an alternative, one can start by mapping the desired task into a high-level programming language, then using components such as registers, counters, and memories to implement the variables needed.  In this approach, the control structure of the code maps into a high-level FSM design. Of course, in order to implement our FSM with digital logic, we eventually still need to map down to bits and gates.  In this set of notes, we show how one can transform a piece of code written in a high-level language into an FSM.  This process is meant to help you understand how we can design an FSM that executes simple pieces of a flow chart such as assignments, { if} statements, and  loops.  Later, we generalize this concept and build an FSM that allows the pieces to be executed to be specified after the FSM is built---in  other words, the FSM executes a program specified by bits stored in  memory.  This more general model, as you might have already guessed,  is a computer.    {Specifying the Problem}  Let's begin by specifying the problem that we want to solve. Say that we want to find the minimum value in a set of 10 integers. Using the C programming language, we can write the following fragment of  code:   {  aaaa=aaaa= int >values[10];    /* 10 integers--filled in by other code */ int >idx; int >min  min = values[0]; for (idx = 1; 10 > idx; idx = idx + 1) { >  if (min > values[idx]) { >  >  min = values[idx]; >  } } /* The minimum value from array is now in min. */  }   The code uses array notation, which we have not used previously in our  class, so let's first discuss the meaning of the code.  The code uses three variables.  The variable { values} represents the 10 values in our set. The suffix ``[10]'' after the variable name tells the compiler that we want an array of 10 integers ({ int}) indexed from 0 to 9. These integers can be treated as 10 separate variables, but can be accessed using the single name ``{ values}'' along with an index (again, from 0 to 9 in this case).  The variable { idx} holds a loop index that we use to examine each of the values one by one in order to find the minimum value in the set.  Finally, the variable { min} holds the smallest known value as  the program examines each of the values in the set.  The program body consists of two statements.    We assume that some other piece of code---one not shown here---has  initialized the 10 values in our set before the code above executes.  The first",
    "GPT-3-Semantic-Search-Generations": {
      "question": " How is FSM initialization solved?\\n",
      "answer": "\nThe FSM is initialized to one of the six states in the desired loop. This ensures that the lights on both roads are not red when cars are waiting on one of the roads."
    }
  },
  {
    "textbook-paragraph": "{Finite State Machine Design Examples, Part I}  This set of notes uses a series of examples to illustrate design principles  for the implementation of finite state machines (FSMs) using digital logic. We begin with an overview of the design process for a digital FSM, from the development of an abstract model through the implementation of functions for the next-state variables and output signals. Our first few examples cover only the concrete aspects: we implement several counters, which illustrate the basic  process of translating a concrete and complete state transition diagram into an implementation based on flip-flops and logic gates. We next consider a counter with a number of states that is not a power of two, with which we illustrate the need for FSM initialization.  As part of solving the initialization problem, we also introduce   a general form of selection logic called a multiplexer.  We then consider the design process as a whole through a more general example of a counter with multiple inputs to control its behavior.  We work from an abstract model down to an implementation, illustrating how semantic knowledge from the abstract model can be used to simplify the  implementation.  Finally, we illustrate how the choice of representation for the FSM's internal state affects the complexity of the implementation. Fortunately, designs that are more intuitive and easier for humans to understand also typically make the best designs in terms of  other metrics, such as logic complexity.   {Steps in the Design Process}  Before we begin exploring designs, let's talk briefly about the general approach that we take when designing an FSM.  We follow a six-step process:{-8pt}  {{}{} {}{}{} {develop an abstract model}{step-abs} {specify I/O behavior}{step-io} {complete the specification}{step-complete} {choose a state representation}{step-repn} {calculate logic expressions}{step-logic} {implement with flip-flops and gates}{step-gates} } {-8pt}  In Step {step-abs}, we translate our description in human language into a model with states and desired behavior.  At this stage, we  simply try to capture the intent of the description and are not particularly thorough nor exact.  Step {step-io} begins to formalize the model, starting with its input and output behavior.  If we eventually plan to develop an implementation of our FSM as a digital system (which is not the  only choice, of course!), all input and output must consist of bits.  Often, input and/or output specifications may need to match other digital systems to which we plan to connect our FSM.  In fact, { most problems in developing large digital systems today arise because of incompatibilities when composing two or more separately designed pieces} (or { modules}) into an integrated system.  Once we know the I/O behavior for our FSM, in Step {step-complete} we start to make any implicit assumptions clear and to make any other decisions necessary to the design.  Occasionally, we may choose to leave something undecided in the hope of simplifying the design with ``don't care'' entries in the logic formulation.  In Step {step-repn}, we select an internal representation for the bits necessary to encode the state of our FSM.  In practice, for small designs, this representation can be selected by a computer  in such a way as to optimize the implementation.  However, for large designs, such as the LC-3 instruction set architecture that we study later in this class, humans do most of the work by hand.  In the later examples in this set of notes, we show how even a  small design can leverage meaningful information from the design when selecting the representation, leading to an implementation that is simpler and is easier to build correctly.  We also show how one can use abstraction to simplify an implementation.  By Step {step-logic}, our design is a complete specification in terms of bits, and we need merely derive logic expressions for the next-state variables and the output signals.",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the first step in the design process?\\n",
      "answer": "\nThe first step in the design process is to develop an abstract model. This model is a translation of the human language description into a model with states and desired behavior. The model is not particularly thorough or exact at this stage."
    }
  },
  {
    "textbook-paragraph": "compact  approaches when comparing functions, but those solutions are a subject for a later class (such as ECE 462).     {Two-Level Logic}   { Two-level logic} is a popular way of expressing logic functions. The two levels refer simply to the number of functions through which an input passes to reach an output, and both the SOP and POS forms are  examples of two-level logic.  In this section, we illustrate one of the  reasons for this popularity and  show you how to graphically manipulate expressions, which can sometimes help when trying to understand gate diagrams.  We begin with one of DeMorgan's laws, which we can illustrate both  algebraically and graphically: C  =  B+A  =      {file=part2/figs/demorgan-nand.eps,width=0.95in}     Let's say that we have a function expressed in SOP form, such as Z=ABC+DE+FGHJ.  The diagram on the left below shows the function constructed from three AND gates and an OR gate.  Using DeMorgan's law, we can replace the OR gate with a NAND with inverted inputs. But the bubbles that correspond to inversion do not need to sit at the input to the gate.  We can invert at any point along the wire, so we slide each bubble down the wire to the output of the first column of AND gates.  { Be careful: if the wire splits, which does not happen in our example, you have to replicate the inverter onto the other output paths as you slide past the split point!}  The end result is shown on the right: we have not changed the  function, but now we use only NAND gates.  Since CMOS technology only supports NAND and NOR directly, using two-level logic makes it simple to map our expression into CMOS gates.  {file=part2/figs/SOP-equiv.eps,width=6.5in}   You may want to make use of DeMorgan's other law, illustrated graphically to the right, to perform the same transformation on a POS expression.  What do you get?   {file=part2/figs/demorgan-nor.eps,width=0.95in}    {Multi-Metric Optimization}  As engineers, almost every real problem that you encounter will admit  multiple metrics for evaluating possible designs.  Becoming a good engineer thus requires not only that you be able to solve problems creatively so as to improve the quality of your solutions, but also that you are aware of how people might evaluate those solutions and are able both to identify the most important metrics and to balance  your design effectively according to them.  In this section, we introduce some general ideas and methods that may be of use to you in this regard.  { We will not test you on the concepts in this section.}  When you start thinking about a new problem, your first step should be to think carefully about metrics of possible interest.  Some important metrics may not be easy to quantify.    For example, compatibility of a design with other products already  owned by a customer has frequently defined the success or failure of computer hardware and software solutions.  But how can you compute the compability of your approach as a number?  Humans---including engineers---are not good at comparing multiple metrics simultaneously.  Thus, once you have a set of metrics that you feel is complete,  your next step is to get rid of as many as you can.  Towards this end, you may identify metrics that have no practical  impact in current technology, set threshold values for other metrics to simplify reasoning about them, eliminate redundant metrics, calculate linear sums to reduce the count of metrics, and, finally, make use of the notion of Pareto optimality.  All of these ideas are described in the rest of this section.  Let's start by considering metrics that we can quantify as real numbers.  For a given metric, we can divide possible measurement values into three ranges.  In the first range, all measurement values are equivalently useful. In the second range,  possible values are ordered and interesting with respect to one another. Values in the third range are all impossible to use in practice. Using power consumption as our example, the first",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the second step in the design process?\\n",
      "answer": "\nThe second step in the design process is to think carefully about metrics of possible interest. Once you have a set of metrics that you feel is complete, your next step is to get rid of as many as you can."
    }
  },
  {
    "textbook-paragraph": "compact  approaches when comparing functions, but those solutions are a subject for a later class (such as ECE 462).     {Two-Level Logic}   { Two-level logic} is a popular way of expressing logic functions. The two levels refer simply to the number of functions through which an input passes to reach an output, and both the SOP and POS forms are  examples of two-level logic.  In this section, we illustrate one of the  reasons for this popularity and  show you how to graphically manipulate expressions, which can sometimes help when trying to understand gate diagrams.  We begin with one of DeMorgan's laws, which we can illustrate both  algebraically and graphically: C  =  B+A  =      {file=part2/figs/demorgan-nand.eps,width=0.95in}     Let's say that we have a function expressed in SOP form, such as Z=ABC+DE+FGHJ.  The diagram on the left below shows the function constructed from three AND gates and an OR gate.  Using DeMorgan's law, we can replace the OR gate with a NAND with inverted inputs. But the bubbles that correspond to inversion do not need to sit at the input to the gate.  We can invert at any point along the wire, so we slide each bubble down the wire to the output of the first column of AND gates.  { Be careful: if the wire splits, which does not happen in our example, you have to replicate the inverter onto the other output paths as you slide past the split point!}  The end result is shown on the right: we have not changed the  function, but now we use only NAND gates.  Since CMOS technology only supports NAND and NOR directly, using two-level logic makes it simple to map our expression into CMOS gates.  {file=part2/figs/SOP-equiv.eps,width=6.5in}   You may want to make use of DeMorgan's other law, illustrated graphically to the right, to perform the same transformation on a POS expression.  What do you get?   {file=part2/figs/demorgan-nor.eps,width=0.95in}    {Multi-Metric Optimization}  As engineers, almost every real problem that you encounter will admit  multiple metrics for evaluating possible designs.  Becoming a good engineer thus requires not only that you be able to solve problems creatively so as to improve the quality of your solutions, but also that you are aware of how people might evaluate those solutions and are able both to identify the most important metrics and to balance  your design effectively according to them.  In this section, we introduce some general ideas and methods that may be of use to you in this regard.  { We will not test you on the concepts in this section.}  When you start thinking about a new problem, your first step should be to think carefully about metrics of possible interest.  Some important metrics may not be easy to quantify.    For example, compatibility of a design with other products already  owned by a customer has frequently defined the success or failure of computer hardware and software solutions.  But how can you compute the compability of your approach as a number?  Humans---including engineers---are not good at comparing multiple metrics simultaneously.  Thus, once you have a set of metrics that you feel is complete,  your next step is to get rid of as many as you can.  Towards this end, you may identify metrics that have no practical  impact in current technology, set threshold values for other metrics to simplify reasoning about them, eliminate redundant metrics, calculate linear sums to reduce the count of metrics, and, finally, make use of the notion of Pareto optimality.  All of these ideas are described in the rest of this section.  Let's start by considering metrics that we can quantify as real numbers.  For a given metric, we can divide possible measurement values into three ranges.  In the first range, all measurement values are equivalently useful. In the second range,  possible values are ordered and interesting with respect to one another. Values in the third range are all impossible to use in practice. Using power consumption as our example, the first",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the third step in the design process?\\n",
      "answer": "\nThe third step in the design process is to identify metrics that have no practical impact in current technology, set threshold values for other metrics to simplify reasoning about them, eliminate redundant metrics, calculate linear sums to reduce the count of metrics, and, finally, make use of the notion of Pareto optimality."
    }
  },
  {
    "textbook-paragraph": "compact  approaches when comparing functions, but those solutions are a subject for a later class (such as ECE 462).     {Two-Level Logic}   { Two-level logic} is a popular way of expressing logic functions. The two levels refer simply to the number of functions through which an input passes to reach an output, and both the SOP and POS forms are  examples of two-level logic.  In this section, we illustrate one of the  reasons for this popularity and  show you how to graphically manipulate expressions, which can sometimes help when trying to understand gate diagrams.  We begin with one of DeMorgan's laws, which we can illustrate both  algebraically and graphically: C  =  B+A  =      {file=part2/figs/demorgan-nand.eps,width=0.95in}     Let's say that we have a function expressed in SOP form, such as Z=ABC+DE+FGHJ.  The diagram on the left below shows the function constructed from three AND gates and an OR gate.  Using DeMorgan's law, we can replace the OR gate with a NAND with inverted inputs. But the bubbles that correspond to inversion do not need to sit at the input to the gate.  We can invert at any point along the wire, so we slide each bubble down the wire to the output of the first column of AND gates.  { Be careful: if the wire splits, which does not happen in our example, you have to replicate the inverter onto the other output paths as you slide past the split point!}  The end result is shown on the right: we have not changed the  function, but now we use only NAND gates.  Since CMOS technology only supports NAND and NOR directly, using two-level logic makes it simple to map our expression into CMOS gates.  {file=part2/figs/SOP-equiv.eps,width=6.5in}   You may want to make use of DeMorgan's other law, illustrated graphically to the right, to perform the same transformation on a POS expression.  What do you get?   {file=part2/figs/demorgan-nor.eps,width=0.95in}    {Multi-Metric Optimization}  As engineers, almost every real problem that you encounter will admit  multiple metrics for evaluating possible designs.  Becoming a good engineer thus requires not only that you be able to solve problems creatively so as to improve the quality of your solutions, but also that you are aware of how people might evaluate those solutions and are able both to identify the most important metrics and to balance  your design effectively according to them.  In this section, we introduce some general ideas and methods that may be of use to you in this regard.  { We will not test you on the concepts in this section.}  When you start thinking about a new problem, your first step should be to think carefully about metrics of possible interest.  Some important metrics may not be easy to quantify.    For example, compatibility of a design with other products already  owned by a customer has frequently defined the success or failure of computer hardware and software solutions.  But how can you compute the compability of your approach as a number?  Humans---including engineers---are not good at comparing multiple metrics simultaneously.  Thus, once you have a set of metrics that you feel is complete,  your next step is to get rid of as many as you can.  Towards this end, you may identify metrics that have no practical  impact in current technology, set threshold values for other metrics to simplify reasoning about them, eliminate redundant metrics, calculate linear sums to reduce the count of metrics, and, finally, make use of the notion of Pareto optimality.  All of these ideas are described in the rest of this section.  Let's start by considering metrics that we can quantify as real numbers.  For a given metric, we can divide possible measurement values into three ranges.  In the first range, all measurement values are equivalently useful. In the second range,  possible values are ordered and interesting with respect to one another. Values in the third range are all impossible to use in practice. Using power consumption as our example, the first",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the fourth step in the design process?\\n",
      "answer": "\nThe fourth step in the design process is to choose a particular design from the set of possible designs. In making this choice, engineers typically consider a variety of factors, including cost, performance, manufacturability, and reliability."
    }
  },
  {
    "textbook-paragraph": "{Finite State Machine Design Examples, Part I}  This set of notes uses a series of examples to illustrate design principles  for the implementation of finite state machines (FSMs) using digital logic. We begin with an overview of the design process for a digital FSM, from the development of an abstract model through the implementation of functions for the next-state variables and output signals. Our first few examples cover only the concrete aspects: we implement several counters, which illustrate the basic  process of translating a concrete and complete state transition diagram into an implementation based on flip-flops and logic gates. We next consider a counter with a number of states that is not a power of two, with which we illustrate the need for FSM initialization.  As part of solving the initialization problem, we also introduce   a general form of selection logic called a multiplexer.  We then consider the design process as a whole through a more general example of a counter with multiple inputs to control its behavior.  We work from an abstract model down to an implementation, illustrating how semantic knowledge from the abstract model can be used to simplify the  implementation.  Finally, we illustrate how the choice of representation for the FSM's internal state affects the complexity of the implementation. Fortunately, designs that are more intuitive and easier for humans to understand also typically make the best designs in terms of  other metrics, such as logic complexity.   {Steps in the Design Process}  Before we begin exploring designs, let's talk briefly about the general approach that we take when designing an FSM.  We follow a six-step process:{-8pt}  {{}{} {}{}{} {develop an abstract model}{step-abs} {specify I/O behavior}{step-io} {complete the specification}{step-complete} {choose a state representation}{step-repn} {calculate logic expressions}{step-logic} {implement with flip-flops and gates}{step-gates} } {-8pt}  In Step {step-abs}, we translate our description in human language into a model with states and desired behavior.  At this stage, we  simply try to capture the intent of the description and are not particularly thorough nor exact.  Step {step-io} begins to formalize the model, starting with its input and output behavior.  If we eventually plan to develop an implementation of our FSM as a digital system (which is not the  only choice, of course!), all input and output must consist of bits.  Often, input and/or output specifications may need to match other digital systems to which we plan to connect our FSM.  In fact, { most problems in developing large digital systems today arise because of incompatibilities when composing two or more separately designed pieces} (or { modules}) into an integrated system.  Once we know the I/O behavior for our FSM, in Step {step-complete} we start to make any implicit assumptions clear and to make any other decisions necessary to the design.  Occasionally, we may choose to leave something undecided in the hope of simplifying the design with ``don't care'' entries in the logic formulation.  In Step {step-repn}, we select an internal representation for the bits necessary to encode the state of our FSM.  In practice, for small designs, this representation can be selected by a computer  in such a way as to optimize the implementation.  However, for large designs, such as the LC-3 instruction set architecture that we study later in this class, humans do most of the work by hand.  In the later examples in this set of notes, we show how even a  small design can leverage meaningful information from the design when selecting the representation, leading to an implementation that is simpler and is easier to build correctly.  We also show how one can use abstraction to simplify an implementation.  By Step {step-logic}, our design is a complete specification in terms of bits, and we need merely derive logic expressions for the next-state variables and the output signals.",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the fifth step in the design process?', '\\n",
      "answer": "\nThe fifth step in the design process is to select an internal representation for the bits necessary to encode the state of our FSM. In practice, for small designs, this representation can be selected by a computer in such a way as to optimize the implementation. However, for large designs, such as the LC-3 instruction set architecture that we study later in this class, humans do most of the work by hand."
    }
  },
  {
    "textbook-paragraph": "{Finite State Machine Design Examples, Part I}  This set of notes uses a series of examples to illustrate design principles  for the implementation of finite state machines (FSMs) using digital logic. We begin with an overview of the design process for a digital FSM, from the development of an abstract model through the implementation of functions for the next-state variables and output signals. Our first few examples cover only the concrete aspects: we implement several counters, which illustrate the basic  process of translating a concrete and complete state transition diagram into an implementation based on flip-flops and logic gates. We next consider a counter with a number of states that is not a power of two, with which we illustrate the need for FSM initialization.  As part of solving the initialization problem, we also introduce   a general form of selection logic called a multiplexer.  We then consider the design process as a whole through a more general example of a counter with multiple inputs to control its behavior.  We work from an abstract model down to an implementation, illustrating how semantic knowledge from the abstract model can be used to simplify the  implementation.  Finally, we illustrate how the choice of representation for the FSM's internal state affects the complexity of the implementation. Fortunately, designs that are more intuitive and easier for humans to understand also typically make the best designs in terms of  other metrics, such as logic complexity.   {Steps in the Design Process}  Before we begin exploring designs, let's talk briefly about the general approach that we take when designing an FSM.  We follow a six-step process:{-8pt}  {{}{} {}{}{} {develop an abstract model}{step-abs} {specify I/O behavior}{step-io} {complete the specification}{step-complete} {choose a state representation}{step-repn} {calculate logic expressions}{step-logic} {implement with flip-flops and gates}{step-gates} } {-8pt}  In Step {step-abs}, we translate our description in human language into a model with states and desired behavior.  At this stage, we  simply try to capture the intent of the description and are not particularly thorough nor exact.  Step {step-io} begins to formalize the model, starting with its input and output behavior.  If we eventually plan to develop an implementation of our FSM as a digital system (which is not the  only choice, of course!), all input and output must consist of bits.  Often, input and/or output specifications may need to match other digital systems to which we plan to connect our FSM.  In fact, { most problems in developing large digital systems today arise because of incompatibilities when composing two or more separately designed pieces} (or { modules}) into an integrated system.  Once we know the I/O behavior for our FSM, in Step {step-complete} we start to make any implicit assumptions clear and to make any other decisions necessary to the design.  Occasionally, we may choose to leave something undecided in the hope of simplifying the design with ``don't care'' entries in the logic formulation.  In Step {step-repn}, we select an internal representation for the bits necessary to encode the state of our FSM.  In practice, for small designs, this representation can be selected by a computer  in such a way as to optimize the implementation.  However, for large designs, such as the LC-3 instruction set architecture that we study later in this class, humans do most of the work by hand.  In the later examples in this set of notes, we show how even a  small design can leverage meaningful information from the design when selecting the representation, leading to an implementation that is simpler and is easier to build correctly.  We also show how one can use abstraction to simplify an implementation.  By Step {step-logic}, our design is a complete specification in terms of bits, and we need merely derive logic expressions for the next-state variables and the output signals.",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the first step in the design process?\\n",
      "answer": "\nThe first step in the design process is to develop an abstract model. This model captures the intent of the description and is not particularly thorough nor exact."
    }
  },
  {
    "textbook-paragraph": "compact  approaches when comparing functions, but those solutions are a subject for a later class (such as ECE 462).     {Two-Level Logic}   { Two-level logic} is a popular way of expressing logic functions. The two levels refer simply to the number of functions through which an input passes to reach an output, and both the SOP and POS forms are  examples of two-level logic.  In this section, we illustrate one of the  reasons for this popularity and  show you how to graphically manipulate expressions, which can sometimes help when trying to understand gate diagrams.  We begin with one of DeMorgan's laws, which we can illustrate both  algebraically and graphically: C  =  B+A  =      {file=part2/figs/demorgan-nand.eps,width=0.95in}     Let's say that we have a function expressed in SOP form, such as Z=ABC+DE+FGHJ.  The diagram on the left below shows the function constructed from three AND gates and an OR gate.  Using DeMorgan's law, we can replace the OR gate with a NAND with inverted inputs. But the bubbles that correspond to inversion do not need to sit at the input to the gate.  We can invert at any point along the wire, so we slide each bubble down the wire to the output of the first column of AND gates.  { Be careful: if the wire splits, which does not happen in our example, you have to replicate the inverter onto the other output paths as you slide past the split point!}  The end result is shown on the right: we have not changed the  function, but now we use only NAND gates.  Since CMOS technology only supports NAND and NOR directly, using two-level logic makes it simple to map our expression into CMOS gates.  {file=part2/figs/SOP-equiv.eps,width=6.5in}   You may want to make use of DeMorgan's other law, illustrated graphically to the right, to perform the same transformation on a POS expression.  What do you get?   {file=part2/figs/demorgan-nor.eps,width=0.95in}    {Multi-Metric Optimization}  As engineers, almost every real problem that you encounter will admit  multiple metrics for evaluating possible designs.  Becoming a good engineer thus requires not only that you be able to solve problems creatively so as to improve the quality of your solutions, but also that you are aware of how people might evaluate those solutions and are able both to identify the most important metrics and to balance  your design effectively according to them.  In this section, we introduce some general ideas and methods that may be of use to you in this regard.  { We will not test you on the concepts in this section.}  When you start thinking about a new problem, your first step should be to think carefully about metrics of possible interest.  Some important metrics may not be easy to quantify.    For example, compatibility of a design with other products already  owned by a customer has frequently defined the success or failure of computer hardware and software solutions.  But how can you compute the compability of your approach as a number?  Humans---including engineers---are not good at comparing multiple metrics simultaneously.  Thus, once you have a set of metrics that you feel is complete,  your next step is to get rid of as many as you can.  Towards this end, you may identify metrics that have no practical  impact in current technology, set threshold values for other metrics to simplify reasoning about them, eliminate redundant metrics, calculate linear sums to reduce the count of metrics, and, finally, make use of the notion of Pareto optimality.  All of these ideas are described in the rest of this section.  Let's start by considering metrics that we can quantify as real numbers.  For a given metric, we can divide possible measurement values into three ranges.  In the first range, all measurement values are equivalently useful. In the second range,  possible values are ordered and interesting with respect to one another. Values in the third range are all impossible to use in practice. Using power consumption as our example, the first",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the second step in the design process?\\n",
      "answer": "\nThe second step in the design process is to think carefully about metrics of possible interest. Once you have a set of metrics that you feel is complete, your next step is to get rid of as many as you can."
    }
  },
  {
    "textbook-paragraph": "compact  approaches when comparing functions, but those solutions are a subject for a later class (such as ECE 462).     {Two-Level Logic}   { Two-level logic} is a popular way of expressing logic functions. The two levels refer simply to the number of functions through which an input passes to reach an output, and both the SOP and POS forms are  examples of two-level logic.  In this section, we illustrate one of the  reasons for this popularity and  show you how to graphically manipulate expressions, which can sometimes help when trying to understand gate diagrams.  We begin with one of DeMorgan's laws, which we can illustrate both  algebraically and graphically: C  =  B+A  =      {file=part2/figs/demorgan-nand.eps,width=0.95in}     Let's say that we have a function expressed in SOP form, such as Z=ABC+DE+FGHJ.  The diagram on the left below shows the function constructed from three AND gates and an OR gate.  Using DeMorgan's law, we can replace the OR gate with a NAND with inverted inputs. But the bubbles that correspond to inversion do not need to sit at the input to the gate.  We can invert at any point along the wire, so we slide each bubble down the wire to the output of the first column of AND gates.  { Be careful: if the wire splits, which does not happen in our example, you have to replicate the inverter onto the other output paths as you slide past the split point!}  The end result is shown on the right: we have not changed the  function, but now we use only NAND gates.  Since CMOS technology only supports NAND and NOR directly, using two-level logic makes it simple to map our expression into CMOS gates.  {file=part2/figs/SOP-equiv.eps,width=6.5in}   You may want to make use of DeMorgan's other law, illustrated graphically to the right, to perform the same transformation on a POS expression.  What do you get?   {file=part2/figs/demorgan-nor.eps,width=0.95in}    {Multi-Metric Optimization}  As engineers, almost every real problem that you encounter will admit  multiple metrics for evaluating possible designs.  Becoming a good engineer thus requires not only that you be able to solve problems creatively so as to improve the quality of your solutions, but also that you are aware of how people might evaluate those solutions and are able both to identify the most important metrics and to balance  your design effectively according to them.  In this section, we introduce some general ideas and methods that may be of use to you in this regard.  { We will not test you on the concepts in this section.}  When you start thinking about a new problem, your first step should be to think carefully about metrics of possible interest.  Some important metrics may not be easy to quantify.    For example, compatibility of a design with other products already  owned by a customer has frequently defined the success or failure of computer hardware and software solutions.  But how can you compute the compability of your approach as a number?  Humans---including engineers---are not good at comparing multiple metrics simultaneously.  Thus, once you have a set of metrics that you feel is complete,  your next step is to get rid of as many as you can.  Towards this end, you may identify metrics that have no practical  impact in current technology, set threshold values for other metrics to simplify reasoning about them, eliminate redundant metrics, calculate linear sums to reduce the count of metrics, and, finally, make use of the notion of Pareto optimality.  All of these ideas are described in the rest of this section.  Let's start by considering metrics that we can quantify as real numbers.  For a given metric, we can divide possible measurement values into three ranges.  In the first range, all measurement values are equivalently useful. In the second range,  possible values are ordered and interesting with respect to one another. Values in the third range are all impossible to use in practice. Using power consumption as our example, the first",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the third step in the design process?\\n",
      "answer": "\nThe third step in the design process is to evaluate the design using multiple metrics. This includes identifying metrics that have no practical impact in current technology, setting threshold values for other metrics to simplify reasoning about them, eliminating redundant metrics, calculating linear sums to reduce the count of metrics, and making use of the notion of Pareto optimality."
    }
  },
  {
    "textbook-paragraph": "compact  approaches when comparing functions, but those solutions are a subject for a later class (such as ECE 462).     {Two-Level Logic}   { Two-level logic} is a popular way of expressing logic functions. The two levels refer simply to the number of functions through which an input passes to reach an output, and both the SOP and POS forms are  examples of two-level logic.  In this section, we illustrate one of the  reasons for this popularity and  show you how to graphically manipulate expressions, which can sometimes help when trying to understand gate diagrams.  We begin with one of DeMorgan's laws, which we can illustrate both  algebraically and graphically: C  =  B+A  =      {file=part2/figs/demorgan-nand.eps,width=0.95in}     Let's say that we have a function expressed in SOP form, such as Z=ABC+DE+FGHJ.  The diagram on the left below shows the function constructed from three AND gates and an OR gate.  Using DeMorgan's law, we can replace the OR gate with a NAND with inverted inputs. But the bubbles that correspond to inversion do not need to sit at the input to the gate.  We can invert at any point along the wire, so we slide each bubble down the wire to the output of the first column of AND gates.  { Be careful: if the wire splits, which does not happen in our example, you have to replicate the inverter onto the other output paths as you slide past the split point!}  The end result is shown on the right: we have not changed the  function, but now we use only NAND gates.  Since CMOS technology only supports NAND and NOR directly, using two-level logic makes it simple to map our expression into CMOS gates.  {file=part2/figs/SOP-equiv.eps,width=6.5in}   You may want to make use of DeMorgan's other law, illustrated graphically to the right, to perform the same transformation on a POS expression.  What do you get?   {file=part2/figs/demorgan-nor.eps,width=0.95in}    {Multi-Metric Optimization}  As engineers, almost every real problem that you encounter will admit  multiple metrics for evaluating possible designs.  Becoming a good engineer thus requires not only that you be able to solve problems creatively so as to improve the quality of your solutions, but also that you are aware of how people might evaluate those solutions and are able both to identify the most important metrics and to balance  your design effectively according to them.  In this section, we introduce some general ideas and methods that may be of use to you in this regard.  { We will not test you on the concepts in this section.}  When you start thinking about a new problem, your first step should be to think carefully about metrics of possible interest.  Some important metrics may not be easy to quantify.    For example, compatibility of a design with other products already  owned by a customer has frequently defined the success or failure of computer hardware and software solutions.  But how can you compute the compability of your approach as a number?  Humans---including engineers---are not good at comparing multiple metrics simultaneously.  Thus, once you have a set of metrics that you feel is complete,  your next step is to get rid of as many as you can.  Towards this end, you may identify metrics that have no practical  impact in current technology, set threshold values for other metrics to simplify reasoning about them, eliminate redundant metrics, calculate linear sums to reduce the count of metrics, and, finally, make use of the notion of Pareto optimality.  All of these ideas are described in the rest of this section.  Let's start by considering metrics that we can quantify as real numbers.  For a given metric, we can divide possible measurement values into three ranges.  In the first range, all measurement values are equivalently useful. In the second range,  possible values are ordered and interesting with respect to one another. Values in the third range are all impossible to use in practice. Using power consumption as our example, the first",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the fourth step in the design process?\\n",
      "answer": "\nThe fourth step in the design process is to choose a particular design from the set of possible designs. This choice is made based on a number of factors, including the objectives of the design, the constraints of the problem, and the preferences of the designer."
    }
  },
  {
    "textbook-paragraph": "{Finite State Machine Design Examples, Part I}  This set of notes uses a series of examples to illustrate design principles  for the implementation of finite state machines (FSMs) using digital logic. We begin with an overview of the design process for a digital FSM, from the development of an abstract model through the implementation of functions for the next-state variables and output signals. Our first few examples cover only the concrete aspects: we implement several counters, which illustrate the basic  process of translating a concrete and complete state transition diagram into an implementation based on flip-flops and logic gates. We next consider a counter with a number of states that is not a power of two, with which we illustrate the need for FSM initialization.  As part of solving the initialization problem, we also introduce   a general form of selection logic called a multiplexer.  We then consider the design process as a whole through a more general example of a counter with multiple inputs to control its behavior.  We work from an abstract model down to an implementation, illustrating how semantic knowledge from the abstract model can be used to simplify the  implementation.  Finally, we illustrate how the choice of representation for the FSM's internal state affects the complexity of the implementation. Fortunately, designs that are more intuitive and easier for humans to understand also typically make the best designs in terms of  other metrics, such as logic complexity.   {Steps in the Design Process}  Before we begin exploring designs, let's talk briefly about the general approach that we take when designing an FSM.  We follow a six-step process:{-8pt}  {{}{} {}{}{} {develop an abstract model}{step-abs} {specify I/O behavior}{step-io} {complete the specification}{step-complete} {choose a state representation}{step-repn} {calculate logic expressions}{step-logic} {implement with flip-flops and gates}{step-gates} } {-8pt}  In Step {step-abs}, we translate our description in human language into a model with states and desired behavior.  At this stage, we  simply try to capture the intent of the description and are not particularly thorough nor exact.  Step {step-io} begins to formalize the model, starting with its input and output behavior.  If we eventually plan to develop an implementation of our FSM as a digital system (which is not the  only choice, of course!), all input and output must consist of bits.  Often, input and/or output specifications may need to match other digital systems to which we plan to connect our FSM.  In fact, { most problems in developing large digital systems today arise because of incompatibilities when composing two or more separately designed pieces} (or { modules}) into an integrated system.  Once we know the I/O behavior for our FSM, in Step {step-complete} we start to make any implicit assumptions clear and to make any other decisions necessary to the design.  Occasionally, we may choose to leave something undecided in the hope of simplifying the design with ``don't care'' entries in the logic formulation.  In Step {step-repn}, we select an internal representation for the bits necessary to encode the state of our FSM.  In practice, for small designs, this representation can be selected by a computer  in such a way as to optimize the implementation.  However, for large designs, such as the LC-3 instruction set architecture that we study later in this class, humans do most of the work by hand.  In the later examples in this set of notes, we show how even a  small design can leverage meaningful information from the design when selecting the representation, leading to an implementation that is simpler and is easier to build correctly.  We also show how one can use abstraction to simplify an implementation.  By Step {step-logic}, our design is a complete specification in terms of bits, and we need merely derive logic expressions for the next-state variables and the output signals.",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the fifth step in the design process?', \"\\n",
      "answer": "\nThe fifth step in the design process is to select an internal representation for the bits necessary to encode the state of the FSM. In practice, for small designs, this representation can be selected by a computer in such a way as to optimize the implementation. However, for large designs, such as the LC-3 instruction set architecture that we study later in this class, humans do most of the work by hand."
    }
  },
  {
    "textbook-paragraph": "{Finite State Machine Design Examples, Part I}  This set of notes uses a series of examples to illustrate design principles  for the implementation of finite state machines (FSMs) using digital logic. We begin with an overview of the design process for a digital FSM, from the development of an abstract model through the implementation of functions for the next-state variables and output signals. Our first few examples cover only the concrete aspects: we implement several counters, which illustrate the basic  process of translating a concrete and complete state transition diagram into an implementation based on flip-flops and logic gates. We next consider a counter with a number of states that is not a power of two, with which we illustrate the need for FSM initialization.  As part of solving the initialization problem, we also introduce   a general form of selection logic called a multiplexer.  We then consider the design process as a whole through a more general example of a counter with multiple inputs to control its behavior.  We work from an abstract model down to an implementation, illustrating how semantic knowledge from the abstract model can be used to simplify the  implementation.  Finally, we illustrate how the choice of representation for the FSM's internal state affects the complexity of the implementation. Fortunately, designs that are more intuitive and easier for humans to understand also typically make the best designs in terms of  other metrics, such as logic complexity.   {Steps in the Design Process}  Before we begin exploring designs, let's talk briefly about the general approach that we take when designing an FSM.  We follow a six-step process:{-8pt}  {{}{} {}{}{} {develop an abstract model}{step-abs} {specify I/O behavior}{step-io} {complete the specification}{step-complete} {choose a state representation}{step-repn} {calculate logic expressions}{step-logic} {implement with flip-flops and gates}{step-gates} } {-8pt}  In Step {step-abs}, we translate our description in human language into a model with states and desired behavior.  At this stage, we  simply try to capture the intent of the description and are not particularly thorough nor exact.  Step {step-io} begins to formalize the model, starting with its input and output behavior.  If we eventually plan to develop an implementation of our FSM as a digital system (which is not the  only choice, of course!), all input and output must consist of bits.  Often, input and/or output specifications may need to match other digital systems to which we plan to connect our FSM.  In fact, { most problems in developing large digital systems today arise because of incompatibilities when composing two or more separately designed pieces} (or { modules}) into an integrated system.  Once we know the I/O behavior for our FSM, in Step {step-complete} we start to make any implicit assumptions clear and to make any other decisions necessary to the design.  Occasionally, we may choose to leave something undecided in the hope of simplifying the design with ``don't care'' entries in the logic formulation.  In Step {step-repn}, we select an internal representation for the bits necessary to encode the state of our FSM.  In practice, for small designs, this representation can be selected by a computer  in such a way as to optimize the implementation.  However, for large designs, such as the LC-3 instruction set architecture that we study later in this class, humans do most of the work by hand.  In the later examples in this set of notes, we show how even a  small design can leverage meaningful information from the design when selecting the representation, leading to an implementation that is simpler and is easier to build correctly.  We also show how one can use abstraction to simplify an implementation.  By Step {step-logic}, our design is a complete specification in terms of bits, and we need merely derive logic expressions for the next-state variables and the output signals.",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the first step in the design process?\\n",
      "answer": "\nThe first step in the design process is to develop an abstract model. This model captures the intent of the description and is not particularly thorough nor exact."
    }
  },
  {
    "textbook-paragraph": "compact  approaches when comparing functions, but those solutions are a subject for a later class (such as ECE 462).     {Two-Level Logic}   { Two-level logic} is a popular way of expressing logic functions. The two levels refer simply to the number of functions through which an input passes to reach an output, and both the SOP and POS forms are  examples of two-level logic.  In this section, we illustrate one of the  reasons for this popularity and  show you how to graphically manipulate expressions, which can sometimes help when trying to understand gate diagrams.  We begin with one of DeMorgan's laws, which we can illustrate both  algebraically and graphically: C  =  B+A  =      {file=part2/figs/demorgan-nand.eps,width=0.95in}     Let's say that we have a function expressed in SOP form, such as Z=ABC+DE+FGHJ.  The diagram on the left below shows the function constructed from three AND gates and an OR gate.  Using DeMorgan's law, we can replace the OR gate with a NAND with inverted inputs. But the bubbles that correspond to inversion do not need to sit at the input to the gate.  We can invert at any point along the wire, so we slide each bubble down the wire to the output of the first column of AND gates.  { Be careful: if the wire splits, which does not happen in our example, you have to replicate the inverter onto the other output paths as you slide past the split point!}  The end result is shown on the right: we have not changed the  function, but now we use only NAND gates.  Since CMOS technology only supports NAND and NOR directly, using two-level logic makes it simple to map our expression into CMOS gates.  {file=part2/figs/SOP-equiv.eps,width=6.5in}   You may want to make use of DeMorgan's other law, illustrated graphically to the right, to perform the same transformation on a POS expression.  What do you get?   {file=part2/figs/demorgan-nor.eps,width=0.95in}    {Multi-Metric Optimization}  As engineers, almost every real problem that you encounter will admit  multiple metrics for evaluating possible designs.  Becoming a good engineer thus requires not only that you be able to solve problems creatively so as to improve the quality of your solutions, but also that you are aware of how people might evaluate those solutions and are able both to identify the most important metrics and to balance  your design effectively according to them.  In this section, we introduce some general ideas and methods that may be of use to you in this regard.  { We will not test you on the concepts in this section.}  When you start thinking about a new problem, your first step should be to think carefully about metrics of possible interest.  Some important metrics may not be easy to quantify.    For example, compatibility of a design with other products already  owned by a customer has frequently defined the success or failure of computer hardware and software solutions.  But how can you compute the compability of your approach as a number?  Humans---including engineers---are not good at comparing multiple metrics simultaneously.  Thus, once you have a set of metrics that you feel is complete,  your next step is to get rid of as many as you can.  Towards this end, you may identify metrics that have no practical  impact in current technology, set threshold values for other metrics to simplify reasoning about them, eliminate redundant metrics, calculate linear sums to reduce the count of metrics, and, finally, make use of the notion of Pareto optimality.  All of these ideas are described in the rest of this section.  Let's start by considering metrics that we can quantify as real numbers.  For a given metric, we can divide possible measurement values into three ranges.  In the first range, all measurement values are equivalently useful. In the second range,  possible values are ordered and interesting with respect to one another. Values in the third range are all impossible to use in practice. Using power consumption as our example, the first",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the third step in the design process?\\n",
      "answer": "\nThe third step in the design process is to evaluate the design using multiple metrics. This includes identifying metrics that have no practical impact in current technology, setting threshold values for other metrics to simplify reasoning about them, eliminating redundant metrics, calculating linear sums to reduce the count of metrics, and making use of the notion of Pareto optimality."
    }
  },
  {
    "textbook-paragraph": "compact  approaches when comparing functions, but those solutions are a subject for a later class (such as ECE 462).     {Two-Level Logic}   { Two-level logic} is a popular way of expressing logic functions. The two levels refer simply to the number of functions through which an input passes to reach an output, and both the SOP and POS forms are  examples of two-level logic.  In this section, we illustrate one of the  reasons for this popularity and  show you how to graphically manipulate expressions, which can sometimes help when trying to understand gate diagrams.  We begin with one of DeMorgan's laws, which we can illustrate both  algebraically and graphically: C  =  B+A  =      {file=part2/figs/demorgan-nand.eps,width=0.95in}     Let's say that we have a function expressed in SOP form, such as Z=ABC+DE+FGHJ.  The diagram on the left below shows the function constructed from three AND gates and an OR gate.  Using DeMorgan's law, we can replace the OR gate with a NAND with inverted inputs. But the bubbles that correspond to inversion do not need to sit at the input to the gate.  We can invert at any point along the wire, so we slide each bubble down the wire to the output of the first column of AND gates.  { Be careful: if the wire splits, which does not happen in our example, you have to replicate the inverter onto the other output paths as you slide past the split point!}  The end result is shown on the right: we have not changed the  function, but now we use only NAND gates.  Since CMOS technology only supports NAND and NOR directly, using two-level logic makes it simple to map our expression into CMOS gates.  {file=part2/figs/SOP-equiv.eps,width=6.5in}   You may want to make use of DeMorgan's other law, illustrated graphically to the right, to perform the same transformation on a POS expression.  What do you get?   {file=part2/figs/demorgan-nor.eps,width=0.95in}    {Multi-Metric Optimization}  As engineers, almost every real problem that you encounter will admit  multiple metrics for evaluating possible designs.  Becoming a good engineer thus requires not only that you be able to solve problems creatively so as to improve the quality of your solutions, but also that you are aware of how people might evaluate those solutions and are able both to identify the most important metrics and to balance  your design effectively according to them.  In this section, we introduce some general ideas and methods that may be of use to you in this regard.  { We will not test you on the concepts in this section.}  When you start thinking about a new problem, your first step should be to think carefully about metrics of possible interest.  Some important metrics may not be easy to quantify.    For example, compatibility of a design with other products already  owned by a customer has frequently defined the success or failure of computer hardware and software solutions.  But how can you compute the compability of your approach as a number?  Humans---including engineers---are not good at comparing multiple metrics simultaneously.  Thus, once you have a set of metrics that you feel is complete,  your next step is to get rid of as many as you can.  Towards this end, you may identify metrics that have no practical  impact in current technology, set threshold values for other metrics to simplify reasoning about them, eliminate redundant metrics, calculate linear sums to reduce the count of metrics, and, finally, make use of the notion of Pareto optimality.  All of these ideas are described in the rest of this section.  Let's start by considering metrics that we can quantify as real numbers.  For a given metric, we can divide possible measurement values into three ranges.  In the first range, all measurement values are equivalently useful. In the second range,  possible values are ordered and interesting with respect to one another. Values in the third range are all impossible to use in practice. Using power consumption as our example, the first",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the fourth step in the design process?\\n",
      "answer": "\nThe fourth step in the design process is to choose a particular design from the set of possible designs. This choice is made based on a number of factors, including the objectives of the design, the constraints of the problem, and the preferences of the designer."
    }
  },
  {
    "textbook-paragraph": "{Finite State Machine Design Examples, Part I}  This set of notes uses a series of examples to illustrate design principles  for the implementation of finite state machines (FSMs) using digital logic. We begin with an overview of the design process for a digital FSM, from the development of an abstract model through the implementation of functions for the next-state variables and output signals. Our first few examples cover only the concrete aspects: we implement several counters, which illustrate the basic  process of translating a concrete and complete state transition diagram into an implementation based on flip-flops and logic gates. We next consider a counter with a number of states that is not a power of two, with which we illustrate the need for FSM initialization.  As part of solving the initialization problem, we also introduce   a general form of selection logic called a multiplexer.  We then consider the design process as a whole through a more general example of a counter with multiple inputs to control its behavior.  We work from an abstract model down to an implementation, illustrating how semantic knowledge from the abstract model can be used to simplify the  implementation.  Finally, we illustrate how the choice of representation for the FSM's internal state affects the complexity of the implementation. Fortunately, designs that are more intuitive and easier for humans to understand also typically make the best designs in terms of  other metrics, such as logic complexity.   {Steps in the Design Process}  Before we begin exploring designs, let's talk briefly about the general approach that we take when designing an FSM.  We follow a six-step process:{-8pt}  {{}{} {}{}{} {develop an abstract model}{step-abs} {specify I/O behavior}{step-io} {complete the specification}{step-complete} {choose a state representation}{step-repn} {calculate logic expressions}{step-logic} {implement with flip-flops and gates}{step-gates} } {-8pt}  In Step {step-abs}, we translate our description in human language into a model with states and desired behavior.  At this stage, we  simply try to capture the intent of the description and are not particularly thorough nor exact.  Step {step-io} begins to formalize the model, starting with its input and output behavior.  If we eventually plan to develop an implementation of our FSM as a digital system (which is not the  only choice, of course!), all input and output must consist of bits.  Often, input and/or output specifications may need to match other digital systems to which we plan to connect our FSM.  In fact, { most problems in developing large digital systems today arise because of incompatibilities when composing two or more separately designed pieces} (or { modules}) into an integrated system.  Once we know the I/O behavior for our FSM, in Step {step-complete} we start to make any implicit assumptions clear and to make any other decisions necessary to the design.  Occasionally, we may choose to leave something undecided in the hope of simplifying the design with ``don't care'' entries in the logic formulation.  In Step {step-repn}, we select an internal representation for the bits necessary to encode the state of our FSM.  In practice, for small designs, this representation can be selected by a computer  in such a way as to optimize the implementation.  However, for large designs, such as the LC-3 instruction set architecture that we study later in this class, humans do most of the work by hand.  In the later examples in this set of notes, we show how even a  small design can leverage meaningful information from the design when selecting the representation, leading to an implementation that is simpler and is easier to build correctly.  We also show how one can use abstraction to simplify an implementation.  By Step {step-logic}, our design is a complete specification in terms of bits, and we need merely derive logic expressions for the next-state variables and the output signals.",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the fifth step in the design process?', \"\\n",
      "answer": "\nThe fifth step in the design process is to select an internal representation for the bits necessary to encode the state of the FSM. In practice, for small designs, this representation can be selected by a computer in such a way as to optimize the implementation. However, for large designs, such as the LC-3 instruction set architecture that we study later in this class, humans do most of the work by hand."
    }
  },
  {
    "textbook-paragraph": "these outputs is given in the table to the right.   {c|c} L& light color  0x& red 10& yellow 11& green    Let's think about the basic operation of the controller.  For safety reasons, the controller must ensure that the lights on one or both roads are red at all times.    Similarly, if a road has a green light, the controller should  show a yellow light before showing a red light to give drivers some warning and allow them to slow down.  Finally, for fairness, the controller should alternate green lights between the two roads.  Now take a look at the logic diagram below.  The state of the FSM has been split into two pieces: a {3-bit}  register S and a {6-bit} timer.  The timer is simply a binary  counter that counts downward and produces an output of Z=1 when it  reaches 0.  Notice that the register S only takes a new value when the timer reaches 0, and that the Z signal from the timer also forces a new value to be loaded into the timer in the next  cycle.  We can thus think of transitions in the FSM on a cycle by  cycle basis as consisting of two types.  The first type simply counts downward for a number of cycles while holding the register S constant, while the second changes the value of S and sets the timer in order to maintain the new value of S  for some number of cycles.    3.45   Let's look at the next-state logic for S, which feeds into the IN inputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice  that none of the inputs to the FSM directly affect these values.  The states of S thus act like a counter.  By examining the connections, we can derive equations for the next state and draw a transition diagram, as shown to the right.  As the figure shows, there are six states in the loop defined by the  next-state logic, with the two remaining states converging into the loop after a single cycle.  Let's now examine the outputs for each state in order to understand how the stoplight sequencing works.  We derive equations for the outputs that control the lights, as shown to the right, then calculate values and colors for each state, as shown to the far right.  For completeness, the table  includes the states outside of the desired loop.  The  lights are all red in both of these states, which is necessary for safety.   {eqnarray*}  S_2^+ &=& {S_2} + S_0 S_1^+ &=& {S_2}  S_1 S_0^+ &=& {S_2} {eqnarray*}  {eqnarray*} L_1^ &=& S_2 S_1 L_0^ &=& S_0 L_1^ &=& S_2 {S_1} L_0^ &=& S_0 {eqnarray*}    {c|cc|cc} &&& EW& NS &&& light& light S& L^& L^& color& color  000& 00& 00&    red&    red 111& 11& 01&  green&    red 110& 10& 00& yellow&    red 010& 00& 00&    red&    red 101& 01& 11&    red&  green 100& 00& 10&    red& yellow  001& 01& 01&    red&    red 011& 01& 01&    red&    red     Now let's think about how the timer works.  As we already noted, the timer value is set whenever S enters a new state, but it can also be set under other conditions---in particular, by the signal F calculated at the bottom of the FSM logic diagram.     For now, assume that F=0.  In this case, the timer is set only when the state S changes, and we can find the duration of each state by analyzing the muxes.  The bottom mux selects A when S_2=0, and  selects the output of the top mux when S_2=1.  The top mux selects B when S_0=1, and selects C when S_0=0.  Combining these results, we can calculate the duration of the next states of S when F=0,  as shown in the table to the right.  We can then combine the next state duration with our previous calculation of the state sequencing  (also the order in the table) to obtain the durations of each state, also shown in the rightmost column of the table.   {c|cc|cc} & EW& NS& next& current & light& light& state& state S& color& color& duration& duration  000&    red&    red& A& C 111&  green&    red& B& A 110& yellow&    red& C& B 010&    red&    red& A& C 101&    red&  green& B& A 100&    red& yellow& C& B  001&    red&    red& A& --- 011&    red&    red& A& ---    What does F do?  Analyzing the gates that",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What is the next state value for S2?\\n",
      "answer": "\nThe next state value for S2 is 0. This is because the timer is set only when the state S changes, and we can find the duration of each state by analyzing the muxes. The bottom mux selects A when S_2=0, and  selects the output of the top mux when S_2=1."
    }
  },
  {
    "textbook-paragraph": "these outputs is given in the table to the right.   {c|c} L& light color  0x& red 10& yellow 11& green    Let's think about the basic operation of the controller.  For safety reasons, the controller must ensure that the lights on one or both roads are red at all times.    Similarly, if a road has a green light, the controller should  show a yellow light before showing a red light to give drivers some warning and allow them to slow down.  Finally, for fairness, the controller should alternate green lights between the two roads.  Now take a look at the logic diagram below.  The state of the FSM has been split into two pieces: a {3-bit}  register S and a {6-bit} timer.  The timer is simply a binary  counter that counts downward and produces an output of Z=1 when it  reaches 0.  Notice that the register S only takes a new value when the timer reaches 0, and that the Z signal from the timer also forces a new value to be loaded into the timer in the next  cycle.  We can thus think of transitions in the FSM on a cycle by  cycle basis as consisting of two types.  The first type simply counts downward for a number of cycles while holding the register S constant, while the second changes the value of S and sets the timer in order to maintain the new value of S  for some number of cycles.    3.45   Let's look at the next-state logic for S, which feeds into the IN inputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice  that none of the inputs to the FSM directly affect these values.  The states of S thus act like a counter.  By examining the connections, we can derive equations for the next state and draw a transition diagram, as shown to the right.  As the figure shows, there are six states in the loop defined by the  next-state logic, with the two remaining states converging into the loop after a single cycle.  Let's now examine the outputs for each state in order to understand how the stoplight sequencing works.  We derive equations for the outputs that control the lights, as shown to the right, then calculate values and colors for each state, as shown to the far right.  For completeness, the table  includes the states outside of the desired loop.  The  lights are all red in both of these states, which is necessary for safety.   {eqnarray*}  S_2^+ &=& {S_2} + S_0 S_1^+ &=& {S_2}  S_1 S_0^+ &=& {S_2} {eqnarray*}  {eqnarray*} L_1^ &=& S_2 S_1 L_0^ &=& S_0 L_1^ &=& S_2 {S_1} L_0^ &=& S_0 {eqnarray*}    {c|cc|cc} &&& EW& NS &&& light& light S& L^& L^& color& color  000& 00& 00&    red&    red 111& 11& 01&  green&    red 110& 10& 00& yellow&    red 010& 00& 00&    red&    red 101& 01& 11&    red&  green 100& 00& 10&    red& yellow  001& 01& 01&    red&    red 011& 01& 01&    red&    red     Now let's think about how the timer works.  As we already noted, the timer value is set whenever S enters a new state, but it can also be set under other conditions---in particular, by the signal F calculated at the bottom of the FSM logic diagram.     For now, assume that F=0.  In this case, the timer is set only when the state S changes, and we can find the duration of each state by analyzing the muxes.  The bottom mux selects A when S_2=0, and  selects the output of the top mux when S_2=1.  The top mux selects B when S_0=1, and selects C when S_0=0.  Combining these results, we can calculate the duration of the next states of S when F=0,  as shown in the table to the right.  We can then combine the next state duration with our previous calculation of the state sequencing  (also the order in the table) to obtain the durations of each state, also shown in the rightmost column of the table.   {c|cc|cc} & EW& NS& next& current & light& light& state& state S& color& color& duration& duration  000&    red&    red& A& C 111&  green&    red& B& A 110& yellow&    red& C& B 010&    red&    red& A& C 101&    red&  green& B& A 100&    red& yellow& C& B  001&    red&    red& A& --- 011&    red&    red& A& ---    What does F do?  Analyzing the gates that",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What is the next state value for S1?\\n",
      "answer": "\nThe next state value for S1 is 1. This is because the value of S1 is determined by the value of S0, and the value of S0 is 1."
    }
  },
  {
    "textbook-paragraph": "these outputs is given in the table to the right.   {c|c} L& light color  0x& red 10& yellow 11& green    Let's think about the basic operation of the controller.  For safety reasons, the controller must ensure that the lights on one or both roads are red at all times.    Similarly, if a road has a green light, the controller should  show a yellow light before showing a red light to give drivers some warning and allow them to slow down.  Finally, for fairness, the controller should alternate green lights between the two roads.  Now take a look at the logic diagram below.  The state of the FSM has been split into two pieces: a {3-bit}  register S and a {6-bit} timer.  The timer is simply a binary  counter that counts downward and produces an output of Z=1 when it  reaches 0.  Notice that the register S only takes a new value when the timer reaches 0, and that the Z signal from the timer also forces a new value to be loaded into the timer in the next  cycle.  We can thus think of transitions in the FSM on a cycle by  cycle basis as consisting of two types.  The first type simply counts downward for a number of cycles while holding the register S constant, while the second changes the value of S and sets the timer in order to maintain the new value of S  for some number of cycles.    3.45   Let's look at the next-state logic for S, which feeds into the IN inputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice  that none of the inputs to the FSM directly affect these values.  The states of S thus act like a counter.  By examining the connections, we can derive equations for the next state and draw a transition diagram, as shown to the right.  As the figure shows, there are six states in the loop defined by the  next-state logic, with the two remaining states converging into the loop after a single cycle.  Let's now examine the outputs for each state in order to understand how the stoplight sequencing works.  We derive equations for the outputs that control the lights, as shown to the right, then calculate values and colors for each state, as shown to the far right.  For completeness, the table  includes the states outside of the desired loop.  The  lights are all red in both of these states, which is necessary for safety.   {eqnarray*}  S_2^+ &=& {S_2} + S_0 S_1^+ &=& {S_2}  S_1 S_0^+ &=& {S_2} {eqnarray*}  {eqnarray*} L_1^ &=& S_2 S_1 L_0^ &=& S_0 L_1^ &=& S_2 {S_1} L_0^ &=& S_0 {eqnarray*}    {c|cc|cc} &&& EW& NS &&& light& light S& L^& L^& color& color  000& 00& 00&    red&    red 111& 11& 01&  green&    red 110& 10& 00& yellow&    red 010& 00& 00&    red&    red 101& 01& 11&    red&  green 100& 00& 10&    red& yellow  001& 01& 01&    red&    red 011& 01& 01&    red&    red     Now let's think about how the timer works.  As we already noted, the timer value is set whenever S enters a new state, but it can also be set under other conditions---in particular, by the signal F calculated at the bottom of the FSM logic diagram.     For now, assume that F=0.  In this case, the timer is set only when the state S changes, and we can find the duration of each state by analyzing the muxes.  The bottom mux selects A when S_2=0, and  selects the output of the top mux when S_2=1.  The top mux selects B when S_0=1, and selects C when S_0=0.  Combining these results, we can calculate the duration of the next states of S when F=0,  as shown in the table to the right.  We can then combine the next state duration with our previous calculation of the state sequencing  (also the order in the table) to obtain the durations of each state, also shown in the rightmost column of the table.   {c|cc|cc} & EW& NS& next& current & light& light& state& state S& color& color& duration& duration  000&    red&    red& A& C 111&  green&    red& B& A 110& yellow&    red& C& B 010&    red&    red& A& C 101&    red&  green& B& A 100&    red& yellow& C& B  001&    red&    red& A& --- 011&    red&    red& A& ---    What does F do?  Analyzing the gates that",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What is the next state value for S0?', '\\n",
      "answer": "\nThe next state value for S0 is 0. This is because the timer is set only when the state S changes, and we can find the duration of each state by analyzing the muxes. The bottom mux selects A when S_2=0, and  selects the output of the top mux when S_2=1. The top mux selects B when S_0=1, and selects C when S_0=0."
    }
  },
  {
    "textbook-paragraph": "these outputs is given in the table to the right.   {c|c} L& light color  0x& red 10& yellow 11& green    Let's think about the basic operation of the controller.  For safety reasons, the controller must ensure that the lights on one or both roads are red at all times.    Similarly, if a road has a green light, the controller should  show a yellow light before showing a red light to give drivers some warning and allow them to slow down.  Finally, for fairness, the controller should alternate green lights between the two roads.  Now take a look at the logic diagram below.  The state of the FSM has been split into two pieces: a {3-bit}  register S and a {6-bit} timer.  The timer is simply a binary  counter that counts downward and produces an output of Z=1 when it  reaches 0.  Notice that the register S only takes a new value when the timer reaches 0, and that the Z signal from the timer also forces a new value to be loaded into the timer in the next  cycle.  We can thus think of transitions in the FSM on a cycle by  cycle basis as consisting of two types.  The first type simply counts downward for a number of cycles while holding the register S constant, while the second changes the value of S and sets the timer in order to maintain the new value of S  for some number of cycles.    3.45   Let's look at the next-state logic for S, which feeds into the IN inputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice  that none of the inputs to the FSM directly affect these values.  The states of S thus act like a counter.  By examining the connections, we can derive equations for the next state and draw a transition diagram, as shown to the right.  As the figure shows, there are six states in the loop defined by the  next-state logic, with the two remaining states converging into the loop after a single cycle.  Let's now examine the outputs for each state in order to understand how the stoplight sequencing works.  We derive equations for the outputs that control the lights, as shown to the right, then calculate values and colors for each state, as shown to the far right.  For completeness, the table  includes the states outside of the desired loop.  The  lights are all red in both of these states, which is necessary for safety.   {eqnarray*}  S_2^+ &=& {S_2} + S_0 S_1^+ &=& {S_2}  S_1 S_0^+ &=& {S_2} {eqnarray*}  {eqnarray*} L_1^ &=& S_2 S_1 L_0^ &=& S_0 L_1^ &=& S_2 {S_1} L_0^ &=& S_0 {eqnarray*}    {c|cc|cc} &&& EW& NS &&& light& light S& L^& L^& color& color  000& 00& 00&    red&    red 111& 11& 01&  green&    red 110& 10& 00& yellow&    red 010& 00& 00&    red&    red 101& 01& 11&    red&  green 100& 00& 10&    red& yellow  001& 01& 01&    red&    red 011& 01& 01&    red&    red     Now let's think about how the timer works.  As we already noted, the timer value is set whenever S enters a new state, but it can also be set under other conditions---in particular, by the signal F calculated at the bottom of the FSM logic diagram.     For now, assume that F=0.  In this case, the timer is set only when the state S changes, and we can find the duration of each state by analyzing the muxes.  The bottom mux selects A when S_2=0, and  selects the output of the top mux when S_2=1.  The top mux selects B when S_0=1, and selects C when S_0=0.  Combining these results, we can calculate the duration of the next states of S when F=0,  as shown in the table to the right.  We can then combine the next state duration with our previous calculation of the state sequencing  (also the order in the table) to obtain the durations of each state, also shown in the rightmost column of the table.   {c|cc|cc} & EW& NS& next& current & light& light& state& state S& color& color& duration& duration  000&    red&    red& A& C 111&  green&    red& B& A 110& yellow&    red& C& B 010&    red&    red& A& C 101&    red&  green& B& A 100&    red& yellow& C& B  001&    red&    red& A& --- 011&    red&    red& A& ---    What does F do?  Analyzing the gates that",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What is the desired pattern for the light?\\n\\n",
      "answer": "\nThe light should be red on one or both roads at all times. If a road has a green light, the controller should show a yellow light before showing a red light to give drivers some warning and allow them to slow down. Finally, for fairness, the controller should alternate green lights between the two roads."
    }
  },
  {
    "textbook-paragraph": "Lemma 2:}  Given enough {2-input} OR functions, one can express an OR function on any finite number of variables.  { Proof:}  The proof of Lemma 2 is identical in structure to that of Lemma 1, but uses OR functions instead of AND functions.   Let's now consider a small subset of functions on N variables.   For any such function, you can write out the truth table for the function.  The output of a logic function is just a bit,  either a 0 or a 1.  Let's consider the set of functions on N variables that produce a 1 for exactly one combination of the N variables.  In other words, if you were to write out the truth table for such a function, exactly one row in the truth table would have output value 1, while all other rows had output value 0.  { Lemma 3:}  Given enough AND functions and {1-input} NOT functions, one can express any Boolean logic function  that produces a 1 for exactly one combination of any finite number of variables.  { Proof:}  The proof of Lemma 3 is by construction. Let N be the number of variables on which the function operates. We construct a { minterm} on these N variables, which is an AND operation on each variable or its complement. The minterm is specified by looking at the unique combination of  variable values that produces a 1 result for the function. Each variable that must be a 1 is included as itself, while each variable that must be a 0 is included as the variable's complement (using a NOT function).  The resulting minterm produces the desired function exactly.  When the variables all match the values for which the function should produce 1, the inputs to the AND function are all 1, and the function produces 1. When any variable does not match the value for which the function should produce 1, that variable (or its complement) acts as a 0 input to the AND function, and the function produces a 0, as desired.  The table below shows all eight minterms for three variables.  { {ccc|cccccccc} {c|}&  A& B& C&    &   C&  B &  B C& A  & A  C& A B & A B C   0& 0& 0& 1& 0& 0& 0& 0& 0& 0& 0 0& 0& 1& 0& 1& 0& 0& 0& 0& 0& 0 0& 1& 0& 0& 0& 1& 0& 0& 0& 0& 0 0& 1& 1& 0& 0& 0& 1& 0& 0& 0& 0 1& 0& 0& 0& 0& 0& 0& 1& 0& 0& 0 1& 0& 1& 0& 0& 0& 0& 0& 1& 0& 0 1& 1& 0& 0& 0& 0& 0& 0& 0& 1& 0 1& 1& 1& 0& 0& 0& 0& 0& 0& 0& 1  }  We are now ready to prove our theorem.  { Proof (of Theorem):}  Any given function on N variables produces the value 1 for some set of combinations of inputs.  Let's say that M such combinations produce 1.   Note that M{2^N}. For each combination that produces 1, we can use Lemma 1 to construct an {N-input} AND function. Then, using Lemma 3, we can use as many as M NOT functions and the {N-input} AND function to construct a minterm for that input combination. Finally, using Lemma 2, we can construct an {M-input} OR function and OR together all of the minterms. The result of the OR is the desired function. If the function should produce a 1 for some combination of inputs, that combination's  minterm provides a 1 input to the OR, which in turn produces a 1. If a combination should produce a 0, its minterm does not appear in the OR; all other minterms produce 0 for that combination, and thus all inputs to the OR are 0 in such cases, and the OR produces 0, as desired.  The construction that we used to prove logical completeness does not necessarily help with efficient design of logic functions.  Think about some of the expressions that we discussed earlier in these notes for overflow conditions.  How many minterms do you need  for {N-bit} unsigned overflow?  A single Boolean logic function can be expressed in many different ways, and learning how to develop an efficient implementation of a function as well as how to determine whether two logic expressions are identical without actually writing out truth tables are important engineering skills that you will start to  learn in the coming months.    {Implications of Logical Completeness}  If logical completeness doesn't really help us to engineer logic",
    "GPT-3-Semantic-Search-Generations": {
      "question": " How many flip-flops will be needed?\\n\\n",
      "answer": "\nFrom the passage, it can be inferred that logical completeness does not necessarily help with efficient design of logic functions. In other words, a single Boolean logic function can be expressed in many different ways. Therefore, it is important for engineers to learn how to develop an efficient implementation of a function, as well as how to determine whether two logic expressions are identical without actually writing out truth tables."
    }
  },
  {
    "textbook-paragraph": "Lemma 2:}  Given enough {2-input} OR functions, one can express an OR function on any finite number of variables.  { Proof:}  The proof of Lemma 2 is identical in structure to that of Lemma 1, but uses OR functions instead of AND functions.   Let's now consider a small subset of functions on N variables.   For any such function, you can write out the truth table for the function.  The output of a logic function is just a bit,  either a 0 or a 1.  Let's consider the set of functions on N variables that produce a 1 for exactly one combination of the N variables.  In other words, if you were to write out the truth table for such a function, exactly one row in the truth table would have output value 1, while all other rows had output value 0.  { Lemma 3:}  Given enough AND functions and {1-input} NOT functions, one can express any Boolean logic function  that produces a 1 for exactly one combination of any finite number of variables.  { Proof:}  The proof of Lemma 3 is by construction. Let N be the number of variables on which the function operates. We construct a { minterm} on these N variables, which is an AND operation on each variable or its complement. The minterm is specified by looking at the unique combination of  variable values that produces a 1 result for the function. Each variable that must be a 1 is included as itself, while each variable that must be a 0 is included as the variable's complement (using a NOT function).  The resulting minterm produces the desired function exactly.  When the variables all match the values for which the function should produce 1, the inputs to the AND function are all 1, and the function produces 1. When any variable does not match the value for which the function should produce 1, that variable (or its complement) acts as a 0 input to the AND function, and the function produces a 0, as desired.  The table below shows all eight minterms for three variables.  { {ccc|cccccccc} {c|}&  A& B& C&    &   C&  B &  B C& A  & A  C& A B & A B C   0& 0& 0& 1& 0& 0& 0& 0& 0& 0& 0 0& 0& 1& 0& 1& 0& 0& 0& 0& 0& 0 0& 1& 0& 0& 0& 1& 0& 0& 0& 0& 0 0& 1& 1& 0& 0& 0& 1& 0& 0& 0& 0 1& 0& 0& 0& 0& 0& 0& 1& 0& 0& 0 1& 0& 1& 0& 0& 0& 0& 0& 1& 0& 0 1& 1& 0& 0& 0& 0& 0& 0& 0& 1& 0 1& 1& 1& 0& 0& 0& 0& 0& 0& 0& 1  }  We are now ready to prove our theorem.  { Proof (of Theorem):}  Any given function on N variables produces the value 1 for some set of combinations of inputs.  Let's say that M such combinations produce 1.   Note that M{2^N}. For each combination that produces 1, we can use Lemma 1 to construct an {N-input} AND function. Then, using Lemma 3, we can use as many as M NOT functions and the {N-input} AND function to construct a minterm for that input combination. Finally, using Lemma 2, we can construct an {M-input} OR function and OR together all of the minterms. The result of the OR is the desired function. If the function should produce a 1 for some combination of inputs, that combination's  minterm provides a 1 input to the OR, which in turn produces a 1. If a combination should produce a 0, its minterm does not appear in the OR; all other minterms produce 0 for that combination, and thus all inputs to the OR are 0 in such cases, and the OR produces 0, as desired.  The construction that we used to prove logical completeness does not necessarily help with efficient design of logic functions.  Think about some of the expressions that we discussed earlier in these notes for overflow conditions.  How many minterms do you need  for {N-bit} unsigned overflow?  A single Boolean logic function can be expressed in many different ways, and learning how to develop an efficient implementation of a function as well as how to determine whether two logic expressions are identical without actually writing out truth tables are important engineering skills that you will start to  learn in the coming months.    {Implications of Logical Completeness}  If logical completeness doesn't really help us to engineer logic",
    "GPT-3-Semantic-Search-Generations": {
      "question": " How many flip-flops will we need?\\n",
      "answer": "\nLogical completeness does not necessarily help with efficient design of logic functions. A single Boolean logic function can be expressed in many different ways. Learning how to develop an efficient implementation of a function as well as how to determine whether two logic expressions are identical without actually writing out truth tables are important engineering skills that students will learn in the coming months."
    }
  },
  {
    "textbook-paragraph": "Lemma 2:}  Given enough {2-input} OR functions, one can express an OR function on any finite number of variables.  { Proof:}  The proof of Lemma 2 is identical in structure to that of Lemma 1, but uses OR functions instead of AND functions.   Let's now consider a small subset of functions on N variables.   For any such function, you can write out the truth table for the function.  The output of a logic function is just a bit,  either a 0 or a 1.  Let's consider the set of functions on N variables that produce a 1 for exactly one combination of the N variables.  In other words, if you were to write out the truth table for such a function, exactly one row in the truth table would have output value 1, while all other rows had output value 0.  { Lemma 3:}  Given enough AND functions and {1-input} NOT functions, one can express any Boolean logic function  that produces a 1 for exactly one combination of any finite number of variables.  { Proof:}  The proof of Lemma 3 is by construction. Let N be the number of variables on which the function operates. We construct a { minterm} on these N variables, which is an AND operation on each variable or its complement. The minterm is specified by looking at the unique combination of  variable values that produces a 1 result for the function. Each variable that must be a 1 is included as itself, while each variable that must be a 0 is included as the variable's complement (using a NOT function).  The resulting minterm produces the desired function exactly.  When the variables all match the values for which the function should produce 1, the inputs to the AND function are all 1, and the function produces 1. When any variable does not match the value for which the function should produce 1, that variable (or its complement) acts as a 0 input to the AND function, and the function produces a 0, as desired.  The table below shows all eight minterms for three variables.  { {ccc|cccccccc} {c|}&  A& B& C&    &   C&  B &  B C& A  & A  C& A B & A B C   0& 0& 0& 1& 0& 0& 0& 0& 0& 0& 0 0& 0& 1& 0& 1& 0& 0& 0& 0& 0& 0 0& 1& 0& 0& 0& 1& 0& 0& 0& 0& 0 0& 1& 1& 0& 0& 0& 1& 0& 0& 0& 0 1& 0& 0& 0& 0& 0& 0& 1& 0& 0& 0 1& 0& 1& 0& 0& 0& 0& 0& 1& 0& 0 1& 1& 0& 0& 0& 0& 0& 0& 0& 1& 0 1& 1& 1& 0& 0& 0& 0& 0& 0& 0& 1  }  We are now ready to prove our theorem.  { Proof (of Theorem):}  Any given function on N variables produces the value 1 for some set of combinations of inputs.  Let's say that M such combinations produce 1.   Note that M{2^N}. For each combination that produces 1, we can use Lemma 1 to construct an {N-input} AND function. Then, using Lemma 3, we can use as many as M NOT functions and the {N-input} AND function to construct a minterm for that input combination. Finally, using Lemma 2, we can construct an {M-input} OR function and OR together all of the minterms. The result of the OR is the desired function. If the function should produce a 1 for some combination of inputs, that combination's  minterm provides a 1 input to the OR, which in turn produces a 1. If a combination should produce a 0, its minterm does not appear in the OR; all other minterms produce 0 for that combination, and thus all inputs to the OR are 0 in such cases, and the OR produces 0, as desired.  The construction that we used to prove logical completeness does not necessarily help with efficient design of logic functions.  Think about some of the expressions that we discussed earlier in these notes for overflow conditions.  How many minterms do you need  for {N-bit} unsigned overflow?  A single Boolean logic function can be expressed in many different ways, and learning how to develop an efficient implementation of a function as well as how to determine whether two logic expressions are identical without actually writing out truth tables are important engineering skills that you will start to  learn in the coming months.    {Implications of Logical Completeness}  If logical completeness doesn't really help us to engineer logic",
    "GPT-3-Semantic-Search-Generations": {
      "question": " How many flip-flops will we need?\\n",
      "answer": "\nLogical completeness does not necessarily help with efficient design of logic functions. A single Boolean logic function can be expressed in many different ways, and learning how to develop an efficient implementation of a function as well as how to determine whether two logic expressions are identical without actually writing out truth tables are important engineering skills that you will start to learn in the coming months."
    }
  },
  {
    "textbook-paragraph": "representation, we can add by counting clockwise around the circle, and we can subtract by counting in a counterclockwise direction around the circle.  With an unsigned representation, we choose to use the group from [0,15] (the middle group in the diagram markings to the right) as the number represented by each of the patterns.  Overflow occurs with unsigned addition (or subtraction) because we can only choose one value for each binary pattern.      In fact, we can choose any single value for each pattern to create a  representation, and our add unit will always produce results that are correct modulo 16.  Look back at our overflow example, where we added 12 and 6 to obtain 2, and notice that (2=18)  16. Normally, only a contiguous sequence of integers makes a useful representation, but we do not have to restrict ourselves to  non-negative numbers.  The 2's complement representation can then be defined by choosing a  set of integers balanced around zero from the groups.  In the circle  diagram, for example, we might choose to represent numbers in the range [-7,7] when using 4 bits.  What about the last pattern, 1000? We could choose to represent either -8 or 8.  The number of arithmetic operations that overflow is the same with both choices (the choices are symmetric around 0, as are the combinations of input operands that  overflow), so we gain nothing in that sense from either choice. If we choose to represent -8, however, notice that all patterns starting with a 1 bit then represent negative numbers.  No such simple check arises with the opposite choice, and thus an {N-bit} 2's complement  representation is defined to represent the range [-2^{N-1},2^{N-1}-1], with patterns chosen as shown in the circle.  {An Algebraic Approach}  Some people prefer an algebraic approach to understanding the definition of 2's complement, so we present such an approach next. Let's start by writing f(A,B) for the result of our add unit:  {eqnarray*} f(A,B) = (A + B)  2^N {eqnarray*}  We assume that we want to represent a set of integers balanced around 0 using our signed representation, and that we will use the same binary patterns as we do with an unsigned representation to represent non-negative numbers.  Thus, with an {N-bit} representation, the patterns in the range [0,2^{N-1}-1] are the same as those used with an unsigned representation.  In this case, we are left with all patterns beginning with a 1 bit.  The question then is this: given an integer k, 2^{N-1}>k>0, for which we  want to find a pattern to represent -k, and any integer m that we might want to add to -k,  can we find another integer p>0 such that    (-k + m = p + m)  2^N   ?   If we can, we can use p's representation to represent -k and our unsigned addition unit f(A,B) will work correctly.  To find the value p, start by subtracting m from both sides of Equation () to obtain:   (-k = p)  2^N   Note that (2^N=0)  2^N, and add this equation to  Equation () to obtain  {eqnarray*} (2^N-k = p)  2^N {eqnarray*}  Let p=2^N-k.    For example, if N=4, k=3 gives p=16-3=13, which is the pattern 1101. With N=4 and k=5, we obtain p=16-5=11, which is the pattern 1011. In general, since 2^{N-1}>k>0,  we have 2^{N-1}<p<2^N.  But these patterns are all unused---they all start with a 1 bit!---so the patterns that we have defined for negative numbers are disjoint from those that we used for positive numbers, and the meaning of each pattern is unambiguous.  The algebraic definition of bit patterns for negative numbers also matches our circle diagram from the last section exactly, of course.    {Negating 2's Complement Numbers}  The algebraic approach makes understanding negation of an integer represented using 2's complement fairly straightforward, and gives  us an easy procedure for doing so. Recall that given an integer k in an {N-bit} 2's complement representation, the {N-bit} pattern for -k is given by 2^N-k  (also true for k=0 if we keep only the low N bits of the result).   But",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What is the desired pattern?\\n",
      "answer": "\nThe desired pattern is the one that represents the number in the 2's complement representation. This is because the 2's complement representation is defined by choosing a set of integers balanced around zero from the groups. So, if we want to represent a number in the 2's complement representation, we need to choose the pattern that represents the number in that representation."
    }
  },
  {
    "textbook-paragraph": "these outputs is given in the table to the right.   {c|c} L& light color  0x& red 10& yellow 11& green    Let's think about the basic operation of the controller.  For safety reasons, the controller must ensure that the lights on one or both roads are red at all times.    Similarly, if a road has a green light, the controller should  show a yellow light before showing a red light to give drivers some warning and allow them to slow down.  Finally, for fairness, the controller should alternate green lights between the two roads.  Now take a look at the logic diagram below.  The state of the FSM has been split into two pieces: a {3-bit}  register S and a {6-bit} timer.  The timer is simply a binary  counter that counts downward and produces an output of Z=1 when it  reaches 0.  Notice that the register S only takes a new value when the timer reaches 0, and that the Z signal from the timer also forces a new value to be loaded into the timer in the next  cycle.  We can thus think of transitions in the FSM on a cycle by  cycle basis as consisting of two types.  The first type simply counts downward for a number of cycles while holding the register S constant, while the second changes the value of S and sets the timer in order to maintain the new value of S  for some number of cycles.    3.45   Let's look at the next-state logic for S, which feeds into the IN inputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice  that none of the inputs to the FSM directly affect these values.  The states of S thus act like a counter.  By examining the connections, we can derive equations for the next state and draw a transition diagram, as shown to the right.  As the figure shows, there are six states in the loop defined by the  next-state logic, with the two remaining states converging into the loop after a single cycle.  Let's now examine the outputs for each state in order to understand how the stoplight sequencing works.  We derive equations for the outputs that control the lights, as shown to the right, then calculate values and colors for each state, as shown to the far right.  For completeness, the table  includes the states outside of the desired loop.  The  lights are all red in both of these states, which is necessary for safety.   {eqnarray*}  S_2^+ &=& {S_2} + S_0 S_1^+ &=& {S_2}  S_1 S_0^+ &=& {S_2} {eqnarray*}  {eqnarray*} L_1^ &=& S_2 S_1 L_0^ &=& S_0 L_1^ &=& S_2 {S_1} L_0^ &=& S_0 {eqnarray*}    {c|cc|cc} &&& EW& NS &&& light& light S& L^& L^& color& color  000& 00& 00&    red&    red 111& 11& 01&  green&    red 110& 10& 00& yellow&    red 010& 00& 00&    red&    red 101& 01& 11&    red&  green 100& 00& 10&    red& yellow  001& 01& 01&    red&    red 011& 01& 01&    red&    red     Now let's think about how the timer works.  As we already noted, the timer value is set whenever S enters a new state, but it can also be set under other conditions---in particular, by the signal F calculated at the bottom of the FSM logic diagram.     For now, assume that F=0.  In this case, the timer is set only when the state S changes, and we can find the duration of each state by analyzing the muxes.  The bottom mux selects A when S_2=0, and  selects the output of the top mux when S_2=1.  The top mux selects B when S_0=1, and selects C when S_0=0.  Combining these results, we can calculate the duration of the next states of S when F=0,  as shown in the table to the right.  We can then combine the next state duration with our previous calculation of the state sequencing  (also the order in the table) to obtain the durations of each state, also shown in the rightmost column of the table.   {c|cc|cc} & EW& NS& next& current & light& light& state& state S& color& color& duration& duration  000&    red&    red& A& C 111&  green&    red& B& A 110& yellow&    red& C& B 010&    red&    red& A& C 101&    red&  green& B& A 100&    red& yellow& C& B  001&    red&    red& A& --- 011&    red&    red& A& ---    What does F do?  Analyzing the gates that",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What is the transition diagram for our color sequencer?\\n",
      "answer": "\nThe transition diagram for the color sequencer is a loop of six states, with the two remaining states converging into the loop after a single cycle. The lights are all red in both of these states, which is necessary for safety. The timer is set only when the state S changes, and the duration of each state is calculated by analyzing the muxes."
    }
  },
  {
    "textbook-paragraph": "ever get into the unexpected states?   What is the initial state of the three flip-flops in our implementation?  { The initial state may not even be 0s and 1s unless we have an  explicit mechanism for initialization.}   Initialization can work in two ways.    The first approach makes use of the flip-flop design. As you know, a flip-flop is built from a pair of latches, and we can  make use of the internal reset lines on these latches to force each flip-flop into the 0 state (or the 1 state) using an additional input.   Alternatively, we can add some extra logic to our design.  Consider adding a few AND gates and a  input (active low), as shown in the dashed box in the figure to the right. In this case, when we assert  by setting it to 0, the FSM moves to state 000 in the next cycle, putting it into the BLACK state.  The approach taken here is for clarity; one can optimize the design, if desired.  For example, we could simply connect  as an extra input into the three AND gates on the left rather than adding new ones, with the same effect.  We may sometimes want a more powerful initialization mechanism---one that allows us to force the FSM into any specific state in the next cycle.  In such a case, we can add multiplexers to each of our  flip-flop inputs, allowing us to use the INIT input to choose between normal operation (INIT=0) of the FSM and forcing the FSM into the next state given by I_2I_1I_0 (when INIT=1).         {Developing an Abstract Model}   We are now ready to discuss the design process for an FSM from start to finish.  For this first abstract FSM example, we build upon something that we have already seen: a two-bit Gray code counter. We now want a counter that allows us to start and stop the   {c|ccc} state&    no input&  halt button& go button  counting& counting&      halted&  halted&   halted&              & counting    count.  What is the mechanism for stopping and starting?  To begin our design, we could sketch out an abstract next-state table such as the one shown to the right above.  In this form of the table, the first column lists the states, while each of the other columns lists states to which the FSM transitions after a clock cycle for a particular input combination.   The table contains two states, counting and halted, and specifies that the design uses two distinct buttons to move between the states. The table further implies that if the counter is halted, the ``halt'' button has no additional effect, and if the counter is counting, the ``go'' button has no additional effect.   A counter with a single counting state, of course, does not provide much value.  We extend the table with four counting states and four halted states, as shown to the right.  This version of the table also introduces more formal state names, for which these notes  use all capital letters.  The upper four states represent uninterrupted counting, in which  the counter cycles through these states indefinitely.  A user can stop the counter in any state by pressing the ``halt'' button, causing the counter to retain its current value until the user presses the ``go'' button.  Below the state table is an abstract transition diagram, which provides exactly the same information in graphical form.  Here circles represent states (as labeled) and arcs represent transitions from one state to another based on an input combination (which is used to label the arc).  We have already implicitly made a few choices about our counter design.  First, the counter   {c|ccc} state&    no input&  halt button& go button  { COUNT A}& { COUNT B}& { HALT A}&  { COUNT B}& { COUNT C}& { HALT B}&  { COUNT C}& { COUNT D}& { HALT C}&  { COUNT D}& { COUNT A}& { HALT D}&  { HALT A}&  { HALT A}&              & { COUNT B} { HALT B}&  { HALT B}&              & { COUNT C} { HALT C}&  { HALT C}&              & { COUNT D} { HALT D}&  { HALT D}&              & { COUNT A}     shown retains the current state of the system when ``halt'' is pressed. We could instead reset",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the initial state of the three flip-flops in our implementation?\\n",
      "answer": "\nThe initial state of the three flip-flops in our implementation is 0s and 1s. We can use the INIT input to choose between normal operation (INIT=0) of the FSM and forcing the FSM into the next state given by I_2I_1I_0 (when INIT=1)."
    }
  },
  {
    "textbook-paragraph": "range corresponds to systems in which when a processor's power consumption in a digital  system is extremely low relative to the power consumption of the system. For example, the processor in a computer might use less than 1  of the total used by  the system including the disk drive, the monitor, the power  supply, and so forth.  One power consumption value in this range  is just as good as any another, and no one cares about the power consumption of the processor  in such cases.  In the second range, power consumption of the processor makes a difference.  Cell phones use most of their energy in radio operation, for example, but if you own a phone with a powerful processor, you may have noticed that you can turn off the phone and  drain the battery fairly quickly by playing a game.  Designing a processor that uses half as much power lengthens the battery life in such cases.  Finally, the third region of power consumption measurements is impossible: if you use so much power, your chip will overheat or even burst into flames.  Consumers get unhappy when such things happen.  As a first step, you can remove any metrics for which all solutions are effectively equivalent.  Until a little less than a decade ago, for example, the power  consumption of a desktop processor actually was in the first range that we discussed.  Power was simply not a concern to engineers: all designs of  interest consumed so little power that no one cared.  Unfortunately, at that point, power consumption jumped into the third range rather quickly.  Processors hit a wall, and  products had to be cancelled.  Given that the time spent designing a processor has historically been about five years, a lot of engineering effort was wasted because people had not thought carefully enough about power (since it had never mattered in the past).  Today, power is an important metric that engineers must take into account in their designs.   However, in some areas, such as desktop and high-end server processors, other metrics (such as performance) may be so  important that we always want to operate at the edge of the interesting range.  In such cases, we might choose to treat  a metric such as power consumption as a { threshold}: stay below 150 Watts for a desktop processor, for example.  One still has to make a coordinated effort to ensure that the system as a whole does not exceed the threshold, but reasoning about  threshold values, a form of constraint, is easier than trying to think about multiple metrics at once.  Some metrics may only allow discrete quantification.  For example, one could choose to define compatibility with previous processor generations as binary: either an existing piece of software (or operating system) runs out of the box on your new processor, or it does not.  If you  want people who own that software to make use of your new processor, you must ensure that the value of this binary metric is 1, which can also be viewed as a threshold.  In some cases, two metrics may be strongly { correlated}, meaning that a design that is good for one of the metrics is frequently  good for the other metric as well.  Chip area and cost, for example, are technically distinct ways to measure a digital design, but we rarely consider them separately.  A design that requires a larger chip is probably more complex, and thus takes more engineering time to get right (engineering time costs money).    Each silicon wafer costs money to fabricate, and fewer copies of a  large design fit on one wafer, so large chips mean more fabrication cost.  Physical defects in silicon can cause some chips not to work.  A large chip uses more silicon than a small one, and is thus more likely to suffer from defects (and not work).  Cost thus goes up again for large chips relative to small ones.  Finally, large chips usually require more careful testing to ensure that they work properly (even ignoring the cost of getting the design right, we have to test for the presence of defects), which",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What could be going wrong?\\n",
      "answer": "\nThe passage states that power consumption is an important metric that engineers must take into account in their designs. However, in some cases, such as desktop and high-end server processors, other metrics (such as performance) may be so important that we always want to operate at the edge of the interesting range. This could be what is going wrong, as engineers are not taking power consumption into account as much as they should be."
    }
  },
  {
    "textbook-paragraph": "if a chip finishes its work, the chip can turn itself off, saving energy.  How do such high-level metrics relate to the problem at hand?  Only indirectly in practice.  There are too many factors involved to make direct calculations of cost, power, or performance at the level of logic expressions.    Finding an { optimal} solution---the best formulation of a specific logic function for a given metric---is often impossible using the  computational resources and algorithms available to us.  Instead, tools typically use heuristic approaches to find solutions that strike a balance between these metrics. A { heuristic} approach is one that is believed to yield fairly good solutions to a problem, but does not necessarily find an optimal solution.  A human engineer can typically impose { constraints}, such as limits on the chip area or limits on the minimum performance, in order to guide the process.  Human engineers may also restructure the implementation of a  larger design, such as a design to perform floating-point arithmetic, so as to change the logic functions used in the design.  { Today, manipulation of logic expressions for the purposes of  optimization is performed almost entirely by computers.}  Humans must supply the logic functions of interest, and must program the acceptable  transformations between equivalent forms, but computers do the grunt work of comparing alternative formulations and deciding which one is best to use in context.  Although we believe that hand optimization of Boolean expressions is no longer an important skill for our graduates, we do think that you should be exposed to the ideas and metrics historically used for such optimization.  The rationale for retaining this exposure is  threefold.   First, we believe that you still need to be able to perform basic logic reformulations (slowly is acceptable) and logical equivalence checking (answering the question, ``Do two  expressions represent the same function?'').  Second, the complexity of the problem is a good way to introduce you to real engineering.  Finally, the contextual information will help you to develop a better understanding of finite state machines and higher-level abstractions that form the core of digital systems and are still defined directly by humans today.  Towards that end, we conclude this introduction by discussing two metrics that engineers traditionally used to optimize  logic expressions.  These metrics are now embedded in { computer-aided  design} ({ CAD}) tools and tuned to specific underlying technologies, but the reasons for their use are still interesting.  The first metric of interest is a heuristic for the area needed for a design.  The measurement is simple: count the number of variable occurrences in an expression.  Simply go through and add up how many variables you see. Using our example function C,  Equation () gives a count of 6, Equation () gives a count of 8, and Equation () gives a count of 24. Smaller numbers represent better expressions, so  Equation () is the best choice by this metric.  Why is this metric interesting? Recall how gates are built from transistors. An {N-input} gate requires roughly 2N transistors, so if you  count up the number of variables in the expression, you get an estimate of the number of transistors needed, which is in turn an estimate for the area required for the design.  A variation on variable counting is to add the number of operations, since each gate also takes space for wiring (within as well as between gates).  Note that we ignore the number of inputs to the operations, so a {2-input} AND counts as 1, but a {10-input} AND also counts as 1.  We do not usually count complementing variables as an operation for this metric because the complements of variables are sometimes  available at no extra cost in gates or wires.  If we add the number of operations in our example, we get a count of 10 for Equation ()---two ANDs, two ORs, and 6 variables,  a count of 12 for Equation ()---three",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the purpose of adding a few AND gates and a  input?', '\\n",
      "answer": "\nThe purpose of adding a few AND gates and a input is to create a logic function that is more efficient in terms of area and power. This is done by reducing the number of variables in the expression."
    }
  },
  {
    "textbook-paragraph": "to implement a procedure and a call of that procedure.   {file=part4/figs/lec23-2.eps,width=1.25in}   [t] { [t]  int =add3 (int n1, int n2, int n3) { >return (n1 + n2 + n3); }  printf (``d'', add3 (10, 20, 30));    by convention: = n1 is in R0 >n2 is in R1 >n3 is in R2 >return value is in R6    [t]  add3:  = WWWW= WWWWW=  add3:>ADD>R0,R0,R1 >ADD>R6,R0,R2 >RETN > >PUSH>R1>; save the value in R1 >LDI>R0,#10>; marshal arguments >LDI>R1,#20 >LDI>R2,#30 >CALL>add3 >MOV>R1,R6>; return value becomes 2nd argument >LDI>R0,``d''>; load a pointer to the string >CALL>printf >POP>R1>; restore R1    The add3 procedure takes three integers as arguments, adds them together, and returns the sum.  The procedure is called with the constants 10, 20, and 30, and the result is printed.  By the calling convention, when the call is made, R0 must contain the value 10, R1 the value 20, and R2 the value 30.  We assume that the caller wants to preserve the value of R1, but does not care about R3 or R5.  In the assembly language version on the right, R1 is first saved to the stack, then the arguments are marshaled into position, and finally the call is made.  The procedure itself needs no local storage and does not change any callee-saved registers, thus must simply add the numbers together and place the result in R6.  After add3 returns, its return value is moved from R6 to R1 in preparation for the call to printf.  After loading a pointer to the format string into R0, the second call is made, and R1 is restored, completing the translation.  { System calls} are almost identical to procedure calls.  As with procedure calls, a calling convention is used: before invoking a system call, arguments are marshaled into the appropriate registers or locations in the stack; after a system call returns, any result appears in a pre-specified register.  The calling convention used for system calls need not be the same as that used for procedure calls. Rather than a call instruction, system calls are usually initiated with a { trap} instruction, and system calls are also known as traps.  With many architectures, a system call places the processor in privileged or kernel mode, and the instructions that implement the call are considered to be part of the operating system.  The term system call arises from this fact.      {Interrupts and Exceptions*}  Unexpected processor interruptions arise both from interactions between a processor and external devices and from errors or unexpected behavior in the program being executed.  The term { interrupt} is reserved for asynchronous interruptions generated by other devices, including disk drives, printers, network cards, video cards, keyboards, mice, and any number of other possibilities.  { Exceptions} occur when a processor encounters an unexpected opcode or operand.  An undefined instruction, for example, gives rise to an exception, as does an attempt to divide by zero.  Exceptions usually cause the current program to terminate, although many operating systems will allow the program to catch the exception and to handle it more intelligently.  The table below summarizes the characteristics of the two types and compares them to system calls.  { {|l|l|l|c|c|} {|c|}& {c|}{generated by}& {c|}& asynchronous& unexpected  interrupt& external device& packet arrived at network card& yes& yes exception& invalid opcode or operand& divide by zero& no& yes trap/system call& deliberate, via trap instruction& print character to console& no& no   }  Interrupts occur asynchronously with respect to the program.  Most designs only recognize interrupts between instructions.  In other words,  the presence of interrupts is checked only after completing an instruction rather than in every cycle.  In pipelined designs, however, instructions execute simultaneously, and the decision as to which instructions occur ``before'' an interrupt and which occur ``after'' must be made by the processor.  Exceptions are not asynchronous in the sense that they occur",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is a more powerful initialization mechanism?', '\\n",
      "answer": "\nInterrupts are more powerful than exceptions because they can occur asynchronously with respect to the program. This means that the processor can check for interrupts between instructions, which allows for more flexibility in the design of the processor."
    }
  },
  {
    "textbook-paragraph": "these outputs is given in the table to the right.   {c|c} L& light color  0x& red 10& yellow 11& green    Let's think about the basic operation of the controller.  For safety reasons, the controller must ensure that the lights on one or both roads are red at all times.    Similarly, if a road has a green light, the controller should  show a yellow light before showing a red light to give drivers some warning and allow them to slow down.  Finally, for fairness, the controller should alternate green lights between the two roads.  Now take a look at the logic diagram below.  The state of the FSM has been split into two pieces: a {3-bit}  register S and a {6-bit} timer.  The timer is simply a binary  counter that counts downward and produces an output of Z=1 when it  reaches 0.  Notice that the register S only takes a new value when the timer reaches 0, and that the Z signal from the timer also forces a new value to be loaded into the timer in the next  cycle.  We can thus think of transitions in the FSM on a cycle by  cycle basis as consisting of two types.  The first type simply counts downward for a number of cycles while holding the register S constant, while the second changes the value of S and sets the timer in order to maintain the new value of S  for some number of cycles.    3.45   Let's look at the next-state logic for S, which feeds into the IN inputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice  that none of the inputs to the FSM directly affect these values.  The states of S thus act like a counter.  By examining the connections, we can derive equations for the next state and draw a transition diagram, as shown to the right.  As the figure shows, there are six states in the loop defined by the  next-state logic, with the two remaining states converging into the loop after a single cycle.  Let's now examine the outputs for each state in order to understand how the stoplight sequencing works.  We derive equations for the outputs that control the lights, as shown to the right, then calculate values and colors for each state, as shown to the far right.  For completeness, the table  includes the states outside of the desired loop.  The  lights are all red in both of these states, which is necessary for safety.   {eqnarray*}  S_2^+ &=& {S_2} + S_0 S_1^+ &=& {S_2}  S_1 S_0^+ &=& {S_2} {eqnarray*}  {eqnarray*} L_1^ &=& S_2 S_1 L_0^ &=& S_0 L_1^ &=& S_2 {S_1} L_0^ &=& S_0 {eqnarray*}    {c|cc|cc} &&& EW& NS &&& light& light S& L^& L^& color& color  000& 00& 00&    red&    red 111& 11& 01&  green&    red 110& 10& 00& yellow&    red 010& 00& 00&    red&    red 101& 01& 11&    red&  green 100& 00& 10&    red& yellow  001& 01& 01&    red&    red 011& 01& 01&    red&    red     Now let's think about how the timer works.  As we already noted, the timer value is set whenever S enters a new state, but it can also be set under other conditions---in particular, by the signal F calculated at the bottom of the FSM logic diagram.     For now, assume that F=0.  In this case, the timer is set only when the state S changes, and we can find the duration of each state by analyzing the muxes.  The bottom mux selects A when S_2=0, and  selects the output of the top mux when S_2=1.  The top mux selects B when S_0=1, and selects C when S_0=0.  Combining these results, we can calculate the duration of the next states of S when F=0,  as shown in the table to the right.  We can then combine the next state duration with our previous calculation of the state sequencing  (also the order in the table) to obtain the durations of each state, also shown in the rightmost column of the table.   {c|cc|cc} & EW& NS& next& current & light& light& state& state S& color& color& duration& duration  000&    red&    red& A& C 111&  green&    red& B& A 110& yellow&    red& C& B 010&    red&    red& A& C 101&    red&  green& B& A 100&    red& yellow& C& B  001&    red&    red& A& --- 011&    red&    red& A& ---    What does F do?  Analyzing the gates that",
    "GPT-3-Semantic-Search-Generations": {
      "question": " Why does the light sometimes glow cyan or red briefly before appearing white?\\n",
      "answer": "\nThe light sometimes glows cyan or red briefly before appearing white because the controller must ensure that the lights on one or both roads are red at all times. Similarly, if a road has a green light, the controller should show a yellow light before showing a red light to give drivers some warning and allow them to slow down."
    }
  },
  {
    "textbook-paragraph": "compact  approaches when comparing functions, but those solutions are a subject for a later class (such as ECE 462).     {Two-Level Logic}   { Two-level logic} is a popular way of expressing logic functions. The two levels refer simply to the number of functions through which an input passes to reach an output, and both the SOP and POS forms are  examples of two-level logic.  In this section, we illustrate one of the  reasons for this popularity and  show you how to graphically manipulate expressions, which can sometimes help when trying to understand gate diagrams.  We begin with one of DeMorgan's laws, which we can illustrate both  algebraically and graphically: C  =  B+A  =      {file=part2/figs/demorgan-nand.eps,width=0.95in}     Let's say that we have a function expressed in SOP form, such as Z=ABC+DE+FGHJ.  The diagram on the left below shows the function constructed from three AND gates and an OR gate.  Using DeMorgan's law, we can replace the OR gate with a NAND with inverted inputs. But the bubbles that correspond to inversion do not need to sit at the input to the gate.  We can invert at any point along the wire, so we slide each bubble down the wire to the output of the first column of AND gates.  { Be careful: if the wire splits, which does not happen in our example, you have to replicate the inverter onto the other output paths as you slide past the split point!}  The end result is shown on the right: we have not changed the  function, but now we use only NAND gates.  Since CMOS technology only supports NAND and NOR directly, using two-level logic makes it simple to map our expression into CMOS gates.  {file=part2/figs/SOP-equiv.eps,width=6.5in}   You may want to make use of DeMorgan's other law, illustrated graphically to the right, to perform the same transformation on a POS expression.  What do you get?   {file=part2/figs/demorgan-nor.eps,width=0.95in}    {Multi-Metric Optimization}  As engineers, almost every real problem that you encounter will admit  multiple metrics for evaluating possible designs.  Becoming a good engineer thus requires not only that you be able to solve problems creatively so as to improve the quality of your solutions, but also that you are aware of how people might evaluate those solutions and are able both to identify the most important metrics and to balance  your design effectively according to them.  In this section, we introduce some general ideas and methods that may be of use to you in this regard.  { We will not test you on the concepts in this section.}  When you start thinking about a new problem, your first step should be to think carefully about metrics of possible interest.  Some important metrics may not be easy to quantify.    For example, compatibility of a design with other products already  owned by a customer has frequently defined the success or failure of computer hardware and software solutions.  But how can you compute the compability of your approach as a number?  Humans---including engineers---are not good at comparing multiple metrics simultaneously.  Thus, once you have a set of metrics that you feel is complete,  your next step is to get rid of as many as you can.  Towards this end, you may identify metrics that have no practical  impact in current technology, set threshold values for other metrics to simplify reasoning about them, eliminate redundant metrics, calculate linear sums to reduce the count of metrics, and, finally, make use of the notion of Pareto optimality.  All of these ideas are described in the rest of this section.  Let's start by considering metrics that we can quantify as real numbers.  For a given metric, we can divide possible measurement values into three ranges.  In the first range, all measurement values are equivalently useful. In the second range,  possible values are ordered and interesting with respect to one another. Values in the third range are all impossible to use in practice. Using power consumption as our example, the first",
    "GPT-3-Semantic-Search-Generations": {
      "question": " How many states are in the second version of the table?\\n",
      "answer": "\nThere are four states in the second version of the table. The states are A, B, C, and D. A and B are both in the ON state, while C and D are both in the OFF state."
    }
  },
  {
    "textbook-paragraph": "transitions specified so far are that when we press ``go'' (HG=01), the counter moves to  the { COUNT B} state, and that the counter remains halted in  state { HALT A} if no buttons are pressed (HG=00). What if the ``halt'' button is pressed (HG=10), or both buttons are pressed (HG=11)?  For consistency, we decide that ``halt'' overrides ``go,'' but does nothing special if it alone is pressed while the counter is halted.  Thus, input patterns HG=10 and HG=11 also  take state { HALT A} back to itself. Here the arc could be labeled HG=00,10,11 or, equivalently, HG=00,1x or HG=x0,11.   To complete our design, we apply the same decisions that we made for  the { COUNT A} state to all of the other counting states, and the  decisions that we made for the { HALT A} state to all of the other  halted states.  If we had chosen not to specify an answer, an implementation could produce different behavior from the different counting and/or halted states, which might confuse a user.  The resulting design appears to the right.        {Choosing a State Representation}  Now we need to select a representation for the states.  Since our counter has eight states, we need at least three (_2 (8)=3) state bits S_2S_1S_0 to keep track of the current state.  As we show later, { the choice of representation for an FSM's states can dramatically affect the design complexity}.  For a design as simple as  our counter, you could just let a computer implement all possible  representations (there aren't more than 840, if we consider simple  symmetries) and select one according to whatever metrics are interesting.  For bigger designs, however, the number of possibilities quickly becomes impossible to explore completely.  Fortunately, { use of abstraction in selecting a representation  also tends to produce better designs} for a wide variety of metrics (such as design complexity, area, power consumption, and performance).  The right strategy is thus often to start by selecting a representation  that makes sense to a human, even if it requires more bits than are strictly necessary.  The resulting implementation will be easier to design and to debug than an implementation in which only the global  behavior has any meaning.   Let's return to our specific example, the counter.  We can use one bit,  S_2, to record whether or not our counter is counting (S_2=0) or halted (S_2=1).  The other two bits can then record the counter state in terms of the desired output.  Choosing this representation implies that only wires will be necessary to compute outputs Z_1  and Z_0 from the internal state: Z_1=S_1 and Z_0=S_0.  The resulting design, in which states are now labeled with both internal state and outputs (S_2S_1S_0/Z_1Z_0) appears to the right.  In this version, we have changed the arc labeling to use logical expressions, which can sometimes help us to think about the implementation.      The equivalent state listing and state table appear below.  We have ordered the rows of the state table in Gray code order to simplify transcription of K-maps.    & S_2S_1S_0&  { COUNT A}& 000& counting, output Z_1Z_0=00 { COUNT B}& 001& counting, output Z_1Z_0=01 { COUNT C}& 011& counting, output Z_1Z_0=11 { COUNT D}& 010& counting, output Z_1Z_0=10  { HALT A}& 100& halted, output Z_1Z_0=00  { HALT B}& 101& halted, output Z_1Z_0=01  { HALT C}& 111& halted, output Z_1Z_0=11  { HALT D}& 110& halted, output Z_1Z_0=10   {rc|cccc} &&{HG} &S_2S_1S_0& 00& 01& 11& 10  { COUNT A}&000& 001& 001& 100& 100 { COUNT B}&001& 011& 011& 101& 101 { COUNT C}&011& 010& 010& 111& 111 { COUNT D}&010& 000& 000& 110& 110  { HALT D}&110& 110& 000& 110& 110  { HALT C}&111& 111& 010& 111& 111  { HALT B}&101& 101& 011& 101& 101  { HALT A}&100& 100& 001& 100& 100    Having chosen a representation, we can go ahead and implement our design in the usual way.  As shown to the right, K-maps for the  next-state logic are complicated, since we have five variables and must consider implicants that are not contiguous in",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What choices have been made about the counter design?', \"\\n\\n",
      "answer": "\nThe design of the counter includes eight states, with three state bits used to keep track of the current state. The choice of representation for an FSM's states can dramatically affect the design complexity. The right strategy is thus often to start by selecting a representation that makes sense to a human, even if it requires more bits than are strictly necessary."
    }
  },
  {
    "textbook-paragraph": "the K-maps. The S_2^+ logic is easy enough: we only need two terms,  as shown.  Notice that we have used color and line style to distinguish different          implicants in the K-maps.  Furthermore, the symmetry of the design produces symmetry in the S_1^+ and S_0^+ formula, so we have used the same color and line style for analogous terms in these two K-maps.  For S_1^+, we need four terms.  The green  ellipses in the HG=01 column are part of the same term, as are the two halves of the dashed blue circle.  In S_0^+, we still need four terms, but three of them are split into two pieces  in the K-map.  As you can see, the utility of the K-map is starting to break down with five variables.   {Abstracting Design Symmetries}  Rather than implementing the design as two-level logic, let's try to take advantage of our design's symmetry to further simplify the logic (we reduce gate count at the expense of longer, slower paths).  Looking back to the last transition diagram, in which the arcs were labeled with logical expressions, let's calculate an expression for when the counter should retain its current value in the next cycle.  We call  this variable HOLD.  In the counting states, when S_2=0,  the counter stops (moves into a halted state without changing value)  when H is true. In the halted states, when S_2=1, the counter stops (stays in  a halted state) when H+ is true.  We can thus write  {eqnarray*} HOLD &=& {S_2}  H + S_2  ( H +  ) HOLD &=& {S_2} H + S_2 H + S_2  HOLD &=& H + S_2  {eqnarray*}  In other words, the counter should hold its current  value (stop counting) if we press the ``halt'' button or if the counter was already halted and we didn't press the ``go'' button.  As desired, the current value of the counter (S_1S_0) has no impact on this  decision.  You may have noticed that the expression we derived for HOLD also matches S_2^+, the next-state value of S_2 in the  K-map on the previous page.  Now let's re-write our state transition table in terms of HOLD.  The left version uses state names for clarity; the right uses state values to help us transcribe K-maps.  { {rc|cc} &&{HOLD} &S_2S_1S_0& 0& 1  { COUNT A}&000& { COUNT B}& { HALT A} { COUNT B}&001& { COUNT C}& { HALT B} { COUNT C}&011& { COUNT D}& { HALT C} { COUNT D}&010& { COUNT A}& { HALT D}  { HALT A}&100& { COUNT B}& { HALT A}  { HALT B}&101& { COUNT C}& { HALT B}  { HALT C}&111& { COUNT D}& { HALT C}  { HALT D}&110& { COUNT A}& { HALT D}  {rc|cc} &&{HOLD} &S_2S_1S_0& 0& 1  { COUNT A}&000& 001& 100 { COUNT B}&001& 011& 101 { COUNT C}&011& 010& 111 { COUNT D}&010& 000& 110  { HALT A}&100& 001& 100  { HALT B}&101& 011& 101  { HALT C}&111& 010& 111  { HALT D}&110& 000& 110    The K-maps based on the HOLD abstraction are shown to the right. As you can see, the necessary logic has been simplified substantially, requiring only two terms each for both S_1^+ and S_0^+.  Writing the next-state logic algebraically, we obtain  {eqnarray*} S_2^+ &=& HOLD S_1^+ &=&   S_0 + HOLD  S_1 S_0^+ &=&   {{S_1}} + HOLD  S_0 {eqnarray*}          Notice the similarity between the equations for S_1^+S_0^+ and the  equations for a {2-to-1} mux: when HOLD=1, the counter retains  its state, and when HOLD=0, it counts.      An implementation appears below.  By using semantic meaning in our choice of representation---in particular the use of S_2 to record whether the counter is currently halted (S_2=1) or counting (S_2=0)---we have enabled ourselves to  separate out the logic for deciding whether to advance the counter fairly cleanly from the logic for advancing the counter itself. Only the HOLD bit in the diagram is used to determine whether or not the counter should advance in the current cycle.  Let's check that the implementation matches our original design.  Start by verifying that the HOLD variable is calculated correctly, HOLD=H+S_2, then look back at the K-map for S_2^+ in the low-level design to verify that the expression we used does indeed match.    Next, check the mux",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What does pressing the ``halt'' button do when the counter is halted?\\n",
      "answer": "\nPressing the ``halt'' button does nothing when the counter is halted. The counter remains in the same state until the ``go'' button is pressed."
    }
  },
  {
    "textbook-paragraph": "to implement a procedure and a call of that procedure.   {file=part4/figs/lec23-2.eps,width=1.25in}   [t] { [t]  int =add3 (int n1, int n2, int n3) { >return (n1 + n2 + n3); }  printf (``d'', add3 (10, 20, 30));    by convention: = n1 is in R0 >n2 is in R1 >n3 is in R2 >return value is in R6    [t]  add3:  = WWWW= WWWWW=  add3:>ADD>R0,R0,R1 >ADD>R6,R0,R2 >RETN > >PUSH>R1>; save the value in R1 >LDI>R0,#10>; marshal arguments >LDI>R1,#20 >LDI>R2,#30 >CALL>add3 >MOV>R1,R6>; return value becomes 2nd argument >LDI>R0,``d''>; load a pointer to the string >CALL>printf >POP>R1>; restore R1    The add3 procedure takes three integers as arguments, adds them together, and returns the sum.  The procedure is called with the constants 10, 20, and 30, and the result is printed.  By the calling convention, when the call is made, R0 must contain the value 10, R1 the value 20, and R2 the value 30.  We assume that the caller wants to preserve the value of R1, but does not care about R3 or R5.  In the assembly language version on the right, R1 is first saved to the stack, then the arguments are marshaled into position, and finally the call is made.  The procedure itself needs no local storage and does not change any callee-saved registers, thus must simply add the numbers together and place the result in R6.  After add3 returns, its return value is moved from R6 to R1 in preparation for the call to printf.  After loading a pointer to the format string into R0, the second call is made, and R1 is restored, completing the translation.  { System calls} are almost identical to procedure calls.  As with procedure calls, a calling convention is used: before invoking a system call, arguments are marshaled into the appropriate registers or locations in the stack; after a system call returns, any result appears in a pre-specified register.  The calling convention used for system calls need not be the same as that used for procedure calls. Rather than a call instruction, system calls are usually initiated with a { trap} instruction, and system calls are also known as traps.  With many architectures, a system call places the processor in privileged or kernel mode, and the instructions that implement the call are considered to be part of the operating system.  The term system call arises from this fact.      {Interrupts and Exceptions*}  Unexpected processor interruptions arise both from interactions between a processor and external devices and from errors or unexpected behavior in the program being executed.  The term { interrupt} is reserved for asynchronous interruptions generated by other devices, including disk drives, printers, network cards, video cards, keyboards, mice, and any number of other possibilities.  { Exceptions} occur when a processor encounters an unexpected opcode or operand.  An undefined instruction, for example, gives rise to an exception, as does an attempt to divide by zero.  Exceptions usually cause the current program to terminate, although many operating systems will allow the program to catch the exception and to handle it more intelligently.  The table below summarizes the characteristics of the two types and compares them to system calls.  { {|l|l|l|c|c|} {|c|}& {c|}{generated by}& {c|}& asynchronous& unexpected  interrupt& external device& packet arrived at network card& yes& yes exception& invalid opcode or operand& divide by zero& no& yes trap/system call& deliberate, via trap instruction& print character to console& no& no   }  Interrupts occur asynchronously with respect to the program.  Most designs only recognize interrupts between instructions.  In other words,  the presence of interrupts is checked only after completing an instruction rather than in every cycle.  In pipelined designs, however, instructions execute simultaneously, and the decision as to which instructions occur ``before'' an interrupt and which occur ``after'' must be made by the processor.  Exceptions are not asynchronous in the sense that they occur",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What does pressing the ``go'' button do when the counter is counting?\", '\\n\\n",
      "answer": "\nPressing the ``go'' button causes the counter to start counting."
    }
  },
  {
    "textbook-paragraph": "However, if the person who designed the dispenser assumed that no one would ever ask for more than one serving, something worse might happen.  In other words, giving an input of C_L=11 to the ice cream dispenser may lead to other unexpected behavior if its designer decided that that input  pattern was a ``don't care.''  The root of the problem is that { while we don't care about the value of any particular output marked ``x'' for any particular input combination, we do actually care about the relationship between the outputs}.    What can we do?  When in doubt, it is safest to make  choices and to add the new decisions to the specification rather than  leaving output values specified as ``don't care.''  For our ice cream dispenser logic, rather than leaving the outputs  unspecified whenever a user presses more than one button, we could  choose an acceptable outcome for each input combination and  replace the x's with 0s and 1s.  We might, for example, decide to produce lychee ice cream whenever the lychee button is pressed, regardless of other buttons (LBM=1xx, which means that we don't care about the inputs B and M, so LBM=100, LBM=101, LBM=110, or LBM=111).   That decision alone covers three of the four unspecified input patterns.  We might also decide that when the  blend and mango buttons are pushed together (but without the lychee button, LBM=011), our logic produces a blend.    The resulting K-maps are shown below, again with shading and green italics  identifying the combinations in which our original design specified ``don't care.''  {{file=part2/figs/CLhigh-priority.eps,width=1.00in}{file=part2/figs/CLlow-priority.eps,width=1.00in}{file=part2/figs/CMhigh-priority.eps,width=1.00in}{file=part2/figs/CMlow-priority.eps,width=1.00in}}   The logic in the dashed box to the right implements the set of choices just discussed, and matches the K-maps above.  Based on our additional choices, this implementation enforces a strict priority scheme on the user's button presses.  If a user requests lychee, they can also press either or both of the other buttons with no effect.  The lychee button has priority.  Similarly, if the user does not press lychee, but press-      es the blend button, pressing the mango button at the same time has no effect.  Choosing mango requires that no other buttons be pressed. We have thus chosen a prioritization order for the buttons and imposed  this order on the design.  We can view this same implementation in another way.  Note the one-to-one correspondence between inputs (on the left) and  outputs (on the right) for the dashed box.  This logic takes the user's button presses and chooses at most one of the buttons to pass along to our original controller implementation  (to the right of the dashed box).  In other words, rather than thinking of the logic in the dashed box as implementing a specific set of decisions, we can think of the logic as cleaning up the inputs to ensure that only valid combinations are passed to our original implementation.  Once the inputs are cleaned up, the original implementation is  acceptable, because input combinations containing more than a  single 1 are in fact impossible.  Strict prioritization is one useful way to clean up our inputs.  In general, we can design logic to map each of the four undesirable input patterns into one of the permissible  combinations (the four that we specified explicitly in our original design, with LBM  in the set ).  Selecting a prioritization scheme is just one approach for making these choices in a way that is easy for a user to understand and  is fairly easy to implement.   A second simple approach is to ignore illegal combinations by mapping them into the ``no buttons pressed''  input pattern.  Such an implementation appears to the right, laid out to show that one can again view the logic in the dashed box either as cleaning up  the inputs (by mentally grouping the logic with the inputs) or as a specific  set of choices for our ``don't",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What does the ``halt'' button do?\\n",
      "answer": "\nThe ``halt'' button on the ice cream dispenser stops the machine from dispensing any more ice cream. This is useful if the user wants to stop the machine from dispensing more ice cream, or if the machine is malfunctioning and needs to be stopped."
    }
  },
  {
    "textbook-paragraph": "these outputs is given in the table to the right.   {c|c} L& light color  0x& red 10& yellow 11& green    Let's think about the basic operation of the controller.  For safety reasons, the controller must ensure that the lights on one or both roads are red at all times.    Similarly, if a road has a green light, the controller should  show a yellow light before showing a red light to give drivers some warning and allow them to slow down.  Finally, for fairness, the controller should alternate green lights between the two roads.  Now take a look at the logic diagram below.  The state of the FSM has been split into two pieces: a {3-bit}  register S and a {6-bit} timer.  The timer is simply a binary  counter that counts downward and produces an output of Z=1 when it  reaches 0.  Notice that the register S only takes a new value when the timer reaches 0, and that the Z signal from the timer also forces a new value to be loaded into the timer in the next  cycle.  We can thus think of transitions in the FSM on a cycle by  cycle basis as consisting of two types.  The first type simply counts downward for a number of cycles while holding the register S constant, while the second changes the value of S and sets the timer in order to maintain the new value of S  for some number of cycles.    3.45   Let's look at the next-state logic for S, which feeds into the IN inputs on the {3-bit} register (S_2^+=IN_2 and so forth).  Notice  that none of the inputs to the FSM directly affect these values.  The states of S thus act like a counter.  By examining the connections, we can derive equations for the next state and draw a transition diagram, as shown to the right.  As the figure shows, there are six states in the loop defined by the  next-state logic, with the two remaining states converging into the loop after a single cycle.  Let's now examine the outputs for each state in order to understand how the stoplight sequencing works.  We derive equations for the outputs that control the lights, as shown to the right, then calculate values and colors for each state, as shown to the far right.  For completeness, the table  includes the states outside of the desired loop.  The  lights are all red in both of these states, which is necessary for safety.   {eqnarray*}  S_2^+ &=& {S_2} + S_0 S_1^+ &=& {S_2}  S_1 S_0^+ &=& {S_2} {eqnarray*}  {eqnarray*} L_1^ &=& S_2 S_1 L_0^ &=& S_0 L_1^ &=& S_2 {S_1} L_0^ &=& S_0 {eqnarray*}    {c|cc|cc} &&& EW& NS &&& light& light S& L^& L^& color& color  000& 00& 00&    red&    red 111& 11& 01&  green&    red 110& 10& 00& yellow&    red 010& 00& 00&    red&    red 101& 01& 11&    red&  green 100& 00& 10&    red& yellow  001& 01& 01&    red&    red 011& 01& 01&    red&    red     Now let's think about how the timer works.  As we already noted, the timer value is set whenever S enters a new state, but it can also be set under other conditions---in particular, by the signal F calculated at the bottom of the FSM logic diagram.     For now, assume that F=0.  In this case, the timer is set only when the state S changes, and we can find the duration of each state by analyzing the muxes.  The bottom mux selects A when S_2=0, and  selects the output of the top mux when S_2=1.  The top mux selects B when S_0=1, and selects C when S_0=0.  Combining these results, we can calculate the duration of the next states of S when F=0,  as shown in the table to the right.  We can then combine the next state duration with our previous calculation of the state sequencing  (also the order in the table) to obtain the durations of each state, also shown in the rightmost column of the table.   {c|cc|cc} & EW& NS& next& current & light& light& state& state S& color& color& duration& duration  000&    red&    red& A& C 111&  green&    red& B& A 110& yellow&    red& C& B 010&    red&    red& A& C 101&    red&  green& B& A 100&    red& yellow& C& B  001&    red&    red& A& --- 011&    red&    red& A& ---    What does F do?  Analyzing the gates that",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What are the two control buttons?\\n",
      "answer": "\nThere are two control buttons: one for the east-west road and one for the north-south road."
    }
  },
  {
    "textbook-paragraph": "to implement a procedure and a call of that procedure.   {file=part4/figs/lec23-2.eps,width=1.25in}   [t] { [t]  int =add3 (int n1, int n2, int n3) { >return (n1 + n2 + n3); }  printf (``d'', add3 (10, 20, 30));    by convention: = n1 is in R0 >n2 is in R1 >n3 is in R2 >return value is in R6    [t]  add3:  = WWWW= WWWWW=  add3:>ADD>R0,R0,R1 >ADD>R6,R0,R2 >RETN > >PUSH>R1>; save the value in R1 >LDI>R0,#10>; marshal arguments >LDI>R1,#20 >LDI>R2,#30 >CALL>add3 >MOV>R1,R6>; return value becomes 2nd argument >LDI>R0,``d''>; load a pointer to the string >CALL>printf >POP>R1>; restore R1    The add3 procedure takes three integers as arguments, adds them together, and returns the sum.  The procedure is called with the constants 10, 20, and 30, and the result is printed.  By the calling convention, when the call is made, R0 must contain the value 10, R1 the value 20, and R2 the value 30.  We assume that the caller wants to preserve the value of R1, but does not care about R3 or R5.  In the assembly language version on the right, R1 is first saved to the stack, then the arguments are marshaled into position, and finally the call is made.  The procedure itself needs no local storage and does not change any callee-saved registers, thus must simply add the numbers together and place the result in R6.  After add3 returns, its return value is moved from R6 to R1 in preparation for the call to printf.  After loading a pointer to the format string into R0, the second call is made, and R1 is restored, completing the translation.  { System calls} are almost identical to procedure calls.  As with procedure calls, a calling convention is used: before invoking a system call, arguments are marshaled into the appropriate registers or locations in the stack; after a system call returns, any result appears in a pre-specified register.  The calling convention used for system calls need not be the same as that used for procedure calls. Rather than a call instruction, system calls are usually initiated with a { trap} instruction, and system calls are also known as traps.  With many architectures, a system call places the processor in privileged or kernel mode, and the instructions that implement the call are considered to be part of the operating system.  The term system call arises from this fact.      {Interrupts and Exceptions*}  Unexpected processor interruptions arise both from interactions between a processor and external devices and from errors or unexpected behavior in the program being executed.  The term { interrupt} is reserved for asynchronous interruptions generated by other devices, including disk drives, printers, network cards, video cards, keyboards, mice, and any number of other possibilities.  { Exceptions} occur when a processor encounters an unexpected opcode or operand.  An undefined instruction, for example, gives rise to an exception, as does an attempt to divide by zero.  Exceptions usually cause the current program to terminate, although many operating systems will allow the program to catch the exception and to handle it more intelligently.  The table below summarizes the characteristics of the two types and compares them to system calls.  { {|l|l|l|c|c|} {|c|}& {c|}{generated by}& {c|}& asynchronous& unexpected  interrupt& external device& packet arrived at network card& yes& yes exception& invalid opcode or operand& divide by zero& no& yes trap/system call& deliberate, via trap instruction& print character to console& no& no   }  Interrupts occur asynchronously with respect to the program.  Most designs only recognize interrupts between instructions.  In other words,  the presence of interrupts is checked only after completing an instruction rather than in every cycle.  In pipelined designs, however, instructions execute simultaneously, and the decision as to which instructions occur ``before'' an interrupt and which occur ``after'' must be made by the processor.  Exceptions are not asynchronous in the sense that they occur",
    "GPT-3-Semantic-Search-Generations": {
      "question": "What is the input behavior?\\n ",
      "answer": "\nSystem calls are initiated with a trap instruction, and system calls are also known as traps. With many architectures, a system call places the processor in privileged or kernel mode, and the instructions that implement the call are considered to be part of the operating system."
    }
  },
  {
    "textbook-paragraph": "transitions specified so far are that when we press ``go'' (HG=01), the counter moves to  the { COUNT B} state, and that the counter remains halted in  state { HALT A} if no buttons are pressed (HG=00). What if the ``halt'' button is pressed (HG=10), or both buttons are pressed (HG=11)?  For consistency, we decide that ``halt'' overrides ``go,'' but does nothing special if it alone is pressed while the counter is halted.  Thus, input patterns HG=10 and HG=11 also  take state { HALT A} back to itself. Here the arc could be labeled HG=00,10,11 or, equivalently, HG=00,1x or HG=x0,11.   To complete our design, we apply the same decisions that we made for  the { COUNT A} state to all of the other counting states, and the  decisions that we made for the { HALT A} state to all of the other  halted states.  If we had chosen not to specify an answer, an implementation could produce different behavior from the different counting and/or halted states, which might confuse a user.  The resulting design appears to the right.        {Choosing a State Representation}  Now we need to select a representation for the states.  Since our counter has eight states, we need at least three (_2 (8)=3) state bits S_2S_1S_0 to keep track of the current state.  As we show later, { the choice of representation for an FSM's states can dramatically affect the design complexity}.  For a design as simple as  our counter, you could just let a computer implement all possible  representations (there aren't more than 840, if we consider simple  symmetries) and select one according to whatever metrics are interesting.  For bigger designs, however, the number of possibilities quickly becomes impossible to explore completely.  Fortunately, { use of abstraction in selecting a representation  also tends to produce better designs} for a wide variety of metrics (such as design complexity, area, power consumption, and performance).  The right strategy is thus often to start by selecting a representation  that makes sense to a human, even if it requires more bits than are strictly necessary.  The resulting implementation will be easier to design and to debug than an implementation in which only the global  behavior has any meaning.   Let's return to our specific example, the counter.  We can use one bit,  S_2, to record whether or not our counter is counting (S_2=0) or halted (S_2=1).  The other two bits can then record the counter state in terms of the desired output.  Choosing this representation implies that only wires will be necessary to compute outputs Z_1  and Z_0 from the internal state: Z_1=S_1 and Z_0=S_0.  The resulting design, in which states are now labeled with both internal state and outputs (S_2S_1S_0/Z_1Z_0) appears to the right.  In this version, we have changed the arc labeling to use logical expressions, which can sometimes help us to think about the implementation.      The equivalent state listing and state table appear below.  We have ordered the rows of the state table in Gray code order to simplify transcription of K-maps.    & S_2S_1S_0&  { COUNT A}& 000& counting, output Z_1Z_0=00 { COUNT B}& 001& counting, output Z_1Z_0=01 { COUNT C}& 011& counting, output Z_1Z_0=11 { COUNT D}& 010& counting, output Z_1Z_0=10  { HALT A}& 100& halted, output Z_1Z_0=00  { HALT B}& 101& halted, output Z_1Z_0=01  { HALT C}& 111& halted, output Z_1Z_0=11  { HALT D}& 110& halted, output Z_1Z_0=10   {rc|cccc} &&{HG} &S_2S_1S_0& 00& 01& 11& 10  { COUNT A}&000& 001& 001& 100& 100 { COUNT B}&001& 011& 011& 101& 101 { COUNT C}&011& 010& 010& 111& 111 { COUNT D}&010& 000& 000& 110& 110  { HALT D}&110& 110& 000& 110& 110  { HALT C}&111& 111& 010& 111& 111  { HALT B}&101& 101& 011& 101& 101  { HALT A}&100& 100& 001& 100& 100    Having chosen a representation, we can go ahead and implement our design in the usual way.  As shown to the right, K-maps for the  next-state logic are complicated, since we have five variables and must consider implicants that are not contiguous in",
    "GPT-3-Semantic-Search-Generations": {
      "question": "How does the design continue until we press H?\\n ",
      "answer": "\nThe design continues by choosing a state representation that makes sense to a human, even if it requires more bits than are strictly necessary. The resulting implementation will be easier to design and to debug than an implementation in which only the global behavior has any meaning."
    }
  },
  {
    "textbook-paragraph": "ever get into the unexpected states?   What is the initial state of the three flip-flops in our implementation?  { The initial state may not even be 0s and 1s unless we have an  explicit mechanism for initialization.}   Initialization can work in two ways.    The first approach makes use of the flip-flop design. As you know, a flip-flop is built from a pair of latches, and we can  make use of the internal reset lines on these latches to force each flip-flop into the 0 state (or the 1 state) using an additional input.   Alternatively, we can add some extra logic to our design.  Consider adding a few AND gates and a  input (active low), as shown in the dashed box in the figure to the right. In this case, when we assert  by setting it to 0, the FSM moves to state 000 in the next cycle, putting it into the BLACK state.  The approach taken here is for clarity; one can optimize the design, if desired.  For example, we could simply connect  as an extra input into the three AND gates on the left rather than adding new ones, with the same effect.  We may sometimes want a more powerful initialization mechanism---one that allows us to force the FSM into any specific state in the next cycle.  In such a case, we can add multiplexers to each of our  flip-flop inputs, allowing us to use the INIT input to choose between normal operation (INIT=0) of the FSM and forcing the FSM into the next state given by I_2I_1I_0 (when INIT=1).         {Developing an Abstract Model}   We are now ready to discuss the design process for an FSM from start to finish.  For this first abstract FSM example, we build upon something that we have already seen: a two-bit Gray code counter. We now want a counter that allows us to start and stop the   {c|ccc} state&    no input&  halt button& go button  counting& counting&      halted&  halted&   halted&              & counting    count.  What is the mechanism for stopping and starting?  To begin our design, we could sketch out an abstract next-state table such as the one shown to the right above.  In this form of the table, the first column lists the states, while each of the other columns lists states to which the FSM transitions after a clock cycle for a particular input combination.   The table contains two states, counting and halted, and specifies that the design uses two distinct buttons to move between the states. The table further implies that if the counter is halted, the ``halt'' button has no additional effect, and if the counter is counting, the ``go'' button has no additional effect.   A counter with a single counting state, of course, does not provide much value.  We extend the table with four counting states and four halted states, as shown to the right.  This version of the table also introduces more formal state names, for which these notes  use all capital letters.  The upper four states represent uninterrupted counting, in which  the counter cycles through these states indefinitely.  A user can stop the counter in any state by pressing the ``halt'' button, causing the counter to retain its current value until the user presses the ``go'' button.  Below the state table is an abstract transition diagram, which provides exactly the same information in graphical form.  Here circles represent states (as labeled) and arcs represent transitions from one state to another based on an input combination (which is used to label the arc).  We have already implicitly made a few choices about our counter design.  First, the counter   {c|ccc} state&    no input&  halt button& go button  { COUNT A}& { COUNT B}& { HALT A}&  { COUNT B}& { COUNT C}& { HALT B}&  { COUNT C}& { COUNT D}& { HALT C}&  { COUNT D}& { COUNT A}& { HALT D}&  { HALT A}&  { HALT A}&              & { COUNT B} { HALT B}&  { HALT B}&              & { COUNT C} { HALT C}&  { HALT C}&              & { COUNT D} { HALT D}&  { HALT D}&              & { COUNT A}     shown retains the current state of the system when ``halt'' is pressed. We could instead reset",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What should happen if the user presses the ``halt'' button while in state { HALT A}?\\n",
      "answer": "\nThere are a few possible ways to answer this question. One way would be to say that if the user presses the ``halt'' button while in state { HALT A}, the system should reset to state { COUNT A}. Another way to answer this question would be to say that if the user presses the ``halt'' button while in state { HALT A}, the system should remain in state { HALT A}."
    }
  },
  {
    "textbook-paragraph": "implementation of  a specification  implies decisions} about these details, so decisions should only be left  unspecified if any of the possible answers is indeed acceptable.  As a concrete example, let's design logic to control an ice cream  dispenser.  The dispenser has two flavors, lychee and mango, but also allows us to create a blend of the two flavors. For each of the two flavors, our logic must output two bits to control the amount of ice cream that comes out of the dispenser. The two-bit C_L[1:0] output of our logic must specify the number  of half-servings of lychee ice cream as a binary number, and the two-bit C_M[1:0] output must specify the number of  half-servings of mango ice cream.  Thus, for either flavor, 00 indicates none of that flavor, 01 indicates one-half of a serving, and  10 indicates a full serving.  Inputs to our logic will consist of three buttons: an L button to request a serving of lychee ice cream, a B button to request a blend---half a serving of each flavor, and an M button to request a serving of mango ice cream.  Each button produces a 1  when pressed and a 0 when not pressed.    Let's start with the assumption that the user only presses one button at a time.  In this case, we can treat input combinations in which more than one button is pressed as ``don't care'' values in the truth tables for the outputs.  K-maps for all four output bits appear below. The x's indicate ``don't care'' values.    When we calculate the logic function for an output, each ``don't care'' value can be treated as either 0 or 1, whichever is more convenient in terms of creating the logic.  In the case of C_M[1], for  example, we can treat the three x's in the ellipse as 1s, treat the x outside of the ellipse as a 0, and simply use M (the implicant represented by the ellipse) for C_M[1].  The other three output bits are left as an exercise, although the result  appears momentarily.   The implementation at right takes full advantage of the ``don't care'' parts of our specification.  In this case, we require no logic at all; we need merely connect the inputs to the correct outputs.  Let's verify the operation.  We have four cases to consider.  First, if none of the  buttons are pushed (LBM=000), we get no ice cream, as desired (C_M=00  and C_L=00).  Second, if we request lychee ice cream (LBM=100), the outputs are C_L=10 and C_M=00, so we get a full serving of lychee and no mango.  Third, if we request a blend (LBM=010), the outputs are C_L=01 and C_M=01, giving us half a serving of each flavor. Finally, if we request mango ice cream (LBM=001), we get no lychee but a full serving of mango.      The K-maps for this implementation appear below.  Each of the ``don't care'' x's from the original design has been replaced with either a 0 or a 1 and highlighted with shading and green italics. Any implementation produces  either 0 or 1 for every output bit for every possible input combination.  {{file=part2/figs/CLhigh-basic.eps,width=1.00in}{file=part2/figs/CLlow-basic.eps,width=1.00in}{file=part2/figs/CMhigh-basic.eps,width=1.00in}{file=part2/figs/CMlow-basic.eps,width=1.00in}}  As you can see, leveraging ``don't care'' output bits can sometimes significantly simplify our logic.  In the case of this example, we were able to completely eliminate any need for gates!  Unfortunately,  the resulting implementation may sometimes produce unexpected results.   Based on the implementation, what happens if a user presses more than one button?  The ice cream cup overflows!  Let's see why.  Consider the case LBM=101, in which we've pressed both the lychee and mango buttons.  Here C_L=10 and C_M=10, so our dispenser releases a  full serving of each flavor, or two servings total.  Pressing other  combinations may have other repercussions as well. Consider pressing lychee and blend (LBM=110).  The outputs are then C_L=11 and C_M=01.  Hopefully the dispenser simply gives us one and a half servings of lychee and a half serving of mango.",
    "GPT-3-Semantic-Search-Generations": {
      "question": " How do you determine what should happen if a user presses the ``go'' button (HG=01)?\\n",
      "answer": "\nIf a user presses the \"go\" button (HG=01), the ice cream cup will overflow. This is because the outputs are C_L=11 and C_M=10, which means that the dispenser will release a full serving of each flavor, or two servings total."
    }
  },
  {
    "textbook-paragraph": "transitions specified so far are that when we press ``go'' (HG=01), the counter moves to  the { COUNT B} state, and that the counter remains halted in  state { HALT A} if no buttons are pressed (HG=00). What if the ``halt'' button is pressed (HG=10), or both buttons are pressed (HG=11)?  For consistency, we decide that ``halt'' overrides ``go,'' but does nothing special if it alone is pressed while the counter is halted.  Thus, input patterns HG=10 and HG=11 also  take state { HALT A} back to itself. Here the arc could be labeled HG=00,10,11 or, equivalently, HG=00,1x or HG=x0,11.   To complete our design, we apply the same decisions that we made for  the { COUNT A} state to all of the other counting states, and the  decisions that we made for the { HALT A} state to all of the other  halted states.  If we had chosen not to specify an answer, an implementation could produce different behavior from the different counting and/or halted states, which might confuse a user.  The resulting design appears to the right.        {Choosing a State Representation}  Now we need to select a representation for the states.  Since our counter has eight states, we need at least three (_2 (8)=3) state bits S_2S_1S_0 to keep track of the current state.  As we show later, { the choice of representation for an FSM's states can dramatically affect the design complexity}.  For a design as simple as  our counter, you could just let a computer implement all possible  representations (there aren't more than 840, if we consider simple  symmetries) and select one according to whatever metrics are interesting.  For bigger designs, however, the number of possibilities quickly becomes impossible to explore completely.  Fortunately, { use of abstraction in selecting a representation  also tends to produce better designs} for a wide variety of metrics (such as design complexity, area, power consumption, and performance).  The right strategy is thus often to start by selecting a representation  that makes sense to a human, even if it requires more bits than are strictly necessary.  The resulting implementation will be easier to design and to debug than an implementation in which only the global  behavior has any meaning.   Let's return to our specific example, the counter.  We can use one bit,  S_2, to record whether or not our counter is counting (S_2=0) or halted (S_2=1).  The other two bits can then record the counter state in terms of the desired output.  Choosing this representation implies that only wires will be necessary to compute outputs Z_1  and Z_0 from the internal state: Z_1=S_1 and Z_0=S_0.  The resulting design, in which states are now labeled with both internal state and outputs (S_2S_1S_0/Z_1Z_0) appears to the right.  In this version, we have changed the arc labeling to use logical expressions, which can sometimes help us to think about the implementation.      The equivalent state listing and state table appear below.  We have ordered the rows of the state table in Gray code order to simplify transcription of K-maps.    & S_2S_1S_0&  { COUNT A}& 000& counting, output Z_1Z_0=00 { COUNT B}& 001& counting, output Z_1Z_0=01 { COUNT C}& 011& counting, output Z_1Z_0=11 { COUNT D}& 010& counting, output Z_1Z_0=10  { HALT A}& 100& halted, output Z_1Z_0=00  { HALT B}& 101& halted, output Z_1Z_0=01  { HALT C}& 111& halted, output Z_1Z_0=11  { HALT D}& 110& halted, output Z_1Z_0=10   {rc|cccc} &&{HG} &S_2S_1S_0& 00& 01& 11& 10  { COUNT A}&000& 001& 001& 100& 100 { COUNT B}&001& 011& 011& 101& 101 { COUNT C}&011& 010& 010& 111& 111 { COUNT D}&010& 000& 000& 110& 110  { HALT D}&110& 110& 000& 110& 110  { HALT C}&111& 111& 010& 111& 111  { HALT B}&101& 101& 011& 101& 101  { HALT A}&100& 100& 001& 100& 100    Having chosen a representation, we can go ahead and implement our design in the usual way.  As shown to the right, K-maps for the  next-state logic are complicated, since we have five variables and must consider implicants that are not contiguous in",
    "GPT-3-Semantic-Search-Generations": {
      "question": " How do you determine what should happen if a user presses the ``halt'' button (HG=10)?\\n",
      "answer": "\nIf the ``halt'' button is pressed (HG=10), the counter remains halted in state { HALT A}. If both buttons are pressed (HG=11), ``halt'' overrides ``go,'' but does nothing special if it alone is pressed while the counter is halted. Thus, input patterns HG=10 and HG=11 also take state { HALT A} back to itself."
    }
  },
  {
    "textbook-paragraph": "transitions specified so far are that when we press ``go'' (HG=01), the counter moves to  the { COUNT B} state, and that the counter remains halted in  state { HALT A} if no buttons are pressed (HG=00). What if the ``halt'' button is pressed (HG=10), or both buttons are pressed (HG=11)?  For consistency, we decide that ``halt'' overrides ``go,'' but does nothing special if it alone is pressed while the counter is halted.  Thus, input patterns HG=10 and HG=11 also  take state { HALT A} back to itself. Here the arc could be labeled HG=00,10,11 or, equivalently, HG=00,1x or HG=x0,11.   To complete our design, we apply the same decisions that we made for  the { COUNT A} state to all of the other counting states, and the  decisions that we made for the { HALT A} state to all of the other  halted states.  If we had chosen not to specify an answer, an implementation could produce different behavior from the different counting and/or halted states, which might confuse a user.  The resulting design appears to the right.        {Choosing a State Representation}  Now we need to select a representation for the states.  Since our counter has eight states, we need at least three (_2 (8)=3) state bits S_2S_1S_0 to keep track of the current state.  As we show later, { the choice of representation for an FSM's states can dramatically affect the design complexity}.  For a design as simple as  our counter, you could just let a computer implement all possible  representations (there aren't more than 840, if we consider simple  symmetries) and select one according to whatever metrics are interesting.  For bigger designs, however, the number of possibilities quickly becomes impossible to explore completely.  Fortunately, { use of abstraction in selecting a representation  also tends to produce better designs} for a wide variety of metrics (such as design complexity, area, power consumption, and performance).  The right strategy is thus often to start by selecting a representation  that makes sense to a human, even if it requires more bits than are strictly necessary.  The resulting implementation will be easier to design and to debug than an implementation in which only the global  behavior has any meaning.   Let's return to our specific example, the counter.  We can use one bit,  S_2, to record whether or not our counter is counting (S_2=0) or halted (S_2=1).  The other two bits can then record the counter state in terms of the desired output.  Choosing this representation implies that only wires will be necessary to compute outputs Z_1  and Z_0 from the internal state: Z_1=S_1 and Z_0=S_0.  The resulting design, in which states are now labeled with both internal state and outputs (S_2S_1S_0/Z_1Z_0) appears to the right.  In this version, we have changed the arc labeling to use logical expressions, which can sometimes help us to think about the implementation.      The equivalent state listing and state table appear below.  We have ordered the rows of the state table in Gray code order to simplify transcription of K-maps.    & S_2S_1S_0&  { COUNT A}& 000& counting, output Z_1Z_0=00 { COUNT B}& 001& counting, output Z_1Z_0=01 { COUNT C}& 011& counting, output Z_1Z_0=11 { COUNT D}& 010& counting, output Z_1Z_0=10  { HALT A}& 100& halted, output Z_1Z_0=00  { HALT B}& 101& halted, output Z_1Z_0=01  { HALT C}& 111& halted, output Z_1Z_0=11  { HALT D}& 110& halted, output Z_1Z_0=10   {rc|cccc} &&{HG} &S_2S_1S_0& 00& 01& 11& 10  { COUNT A}&000& 001& 001& 100& 100 { COUNT B}&001& 011& 011& 101& 101 { COUNT C}&011& 010& 010& 111& 111 { COUNT D}&010& 000& 000& 110& 110  { HALT D}&110& 110& 000& 110& 110  { HALT C}&111& 111& 010& 111& 111  { HALT B}&101& 101& 011& 101& 101  { HALT A}&100& 100& 001& 100& 100    Having chosen a representation, we can go ahead and implement our design in the usual way.  As shown to the right, K-maps for the  next-state logic are complicated, since we have five variables and must consider implicants that are not contiguous in",
    "GPT-3-Semantic-Search-Generations": {
      "question": " How do you apply the same decisions that you made for the { COUNT A} state to all of the other counting states?\", \"\\n",
      "answer": "\nThe design for the counter is completed by applying the same decisions that were made for the { COUNT A} state to all of the other counting states, and the decisions that were made for the { HALT A} state to all of the other halted states. This results in a design in which states are labeled with both internal state and outputs (S_2S_1S_0/Z_1Z_0)."
    }
  },
  {
    "textbook-paragraph": "systematic technique (or a machine) capable of solving a problem that cannot be solved by a Turing machine.  No one has been able to do so to date.   {The Halting Problem*}  You might reasonably ask whether any problems can be shown to be incomputable.  More common terms for such problems---those known to be insolvable by any computer---are { intractable} or  undecidable.  In the same 1936 paper in which he introduced the universal computing machine, Alan Turing also provided an answer to this question by introducing (and proving) that there are in fact problems that cannot be computed by a universal computing machine. The problem that he proved undecidable, using proof techniques almost identical to those developed for similar problems in the 1880s, is now known as { the halting problem}.    The halting problem is easy to state and easy to prove undecidable. The problem is this: given a Turing machine and an input to the Turing machine, does the Turing machine finish computing in a finite number of steps (a finite amount of time)?  In order to solve the problem, an answer, either yes or no, must be given in a finite amount of time regardless of the machine or input in question.  Clearly some machines never finish.  For example, we can write a Turing machine that counts upwards starting from one.  You may find the proof structure for undecidability of the halting problem easier to understand if you first think about a related problem with which you may already be familiar, the Liar's paradox (which is at least 2,300 years old).  In its stengthened form, it is the following sentence: ``This sentence is not true.''   To see that no Turing machine can solve the halting problem, we begin by assuming that such a machine exists, and then show that its existence is self-contradictory.  We call the machine the ``Halting Machine,'' or HM for short.  HM is a machine that operates on  another      Turing machine and its inputs to produce a yes or no answer in finite time: either the machine in question finishes in finite time (HM returns ``yes''), or it does not (HM returns ``no'').  The figure illustrates HM's operation.   From HM, we construct a second machine that we call the HM Inverter, or HMI.  This machine inverts the sense of the answer given by HM.  In particular, the inputs are fed directly into a copy of HM, and if HM answers ``yes,'' HMI enters an infinite loop.  If HM answers ``no,'' HMI halts.  A diagram appears to the right.  The inconsistency can now be seen by asking HM whether HMI halts when given itself as an input (repeatedly), as      shown below.  Two copies of HM are thus being asked the same question.  One copy is the rightmost in the figure below and the second is embedded in the HMI machine that we are using as the input to the rightmost HM.  As the two copies of HM operate on the same input (HMI operating on HMI), they should return the same answer: a Turing machine either halts on an input, or it does not; they are deterministic.    Let's assume that the rightmost HM tells us that HMI operating on itself halts. Then the copy of HM in HMI (when HMI executes on itself, with itself as an input) must also say ``yes.''  But this answer implies that HMI doesn't halt (see the figure above), so the answer should have been no!  Alternatively, we can assume that the rightmost HM says that HMI operating on itself does not halt.  Again, the copy of HM in HMI must give the same answer.  But in this case HMI halts, again contradicting our assumption.  Since neither answer is consistent, no consistent answer can be given, and the original assumption that HM exists is incorrect.  Thus, no Turing machine can solve the halting problem.      {Programming Concepts and the C Language}  This set of notes introduces the C programming language and explains some basic concepts in computer programming.  Our purpose in showing you a high-level language at this early stage of the course is to give you time to become familiar with the",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What does it mean when a counter is \"halted?\"\\nA: When a counter is halted, it is no longer counting. \\n\\n",
      "answer": "\nWhen a Turing machine is given an input, it either finishes in a finite number of steps, or it does not. If it does not finish in a finite number of steps, the machine is said to be \"halted.\""
    }
  },
  {
    "textbook-paragraph": "systematic technique (or a machine) capable of solving a problem that cannot be solved by a Turing machine.  No one has been able to do so to date.   {The Halting Problem*}  You might reasonably ask whether any problems can be shown to be incomputable.  More common terms for such problems---those known to be insolvable by any computer---are { intractable} or  undecidable.  In the same 1936 paper in which he introduced the universal computing machine, Alan Turing also provided an answer to this question by introducing (and proving) that there are in fact problems that cannot be computed by a universal computing machine. The problem that he proved undecidable, using proof techniques almost identical to those developed for similar problems in the 1880s, is now known as { the halting problem}.    The halting problem is easy to state and easy to prove undecidable. The problem is this: given a Turing machine and an input to the Turing machine, does the Turing machine finish computing in a finite number of steps (a finite amount of time)?  In order to solve the problem, an answer, either yes or no, must be given in a finite amount of time regardless of the machine or input in question.  Clearly some machines never finish.  For example, we can write a Turing machine that counts upwards starting from one.  You may find the proof structure for undecidability of the halting problem easier to understand if you first think about a related problem with which you may already be familiar, the Liar's paradox (which is at least 2,300 years old).  In its stengthened form, it is the following sentence: ``This sentence is not true.''   To see that no Turing machine can solve the halting problem, we begin by assuming that such a machine exists, and then show that its existence is self-contradictory.  We call the machine the ``Halting Machine,'' or HM for short.  HM is a machine that operates on  another      Turing machine and its inputs to produce a yes or no answer in finite time: either the machine in question finishes in finite time (HM returns ``yes''), or it does not (HM returns ``no'').  The figure illustrates HM's operation.   From HM, we construct a second machine that we call the HM Inverter, or HMI.  This machine inverts the sense of the answer given by HM.  In particular, the inputs are fed directly into a copy of HM, and if HM answers ``yes,'' HMI enters an infinite loop.  If HM answers ``no,'' HMI halts.  A diagram appears to the right.  The inconsistency can now be seen by asking HM whether HMI halts when given itself as an input (repeatedly), as      shown below.  Two copies of HM are thus being asked the same question.  One copy is the rightmost in the figure below and the second is embedded in the HMI machine that we are using as the input to the rightmost HM.  As the two copies of HM operate on the same input (HMI operating on HMI), they should return the same answer: a Turing machine either halts on an input, or it does not; they are deterministic.    Let's assume that the rightmost HM tells us that HMI operating on itself halts. Then the copy of HM in HMI (when HMI executes on itself, with itself as an input) must also say ``yes.''  But this answer implies that HMI doesn't halt (see the figure above), so the answer should have been no!  Alternatively, we can assume that the rightmost HM says that HMI operating on itself does not halt.  Again, the copy of HM in HMI must give the same answer.  But in this case HMI halts, again contradicting our assumption.  Since neither answer is consistent, no consistent answer can be given, and the original assumption that HM exists is incorrect.  Thus, no Turing machine can solve the halting problem.      {Programming Concepts and the C Language}  This set of notes introduces the C programming language and explains some basic concepts in computer programming.  Our purpose in showing you a high-level language at this early stage of the course is to give you time to become familiar with the",
    "GPT-3-Semantic-Search-Generations": {
      "question": " What is the difference between a counter that is \"counting\" and a counter that is \"halted?\"\\nA: When a counter is counting, it is in the process of incrementing. When a counter is halted, it is not incrementing. \\n\\n",
      "answer": "\nA counter that is \"counting\" is in the process of incrementing, while a counter that is \"halted\" is not incrementing."
    }
  },
  {
    "textbook-paragraph": "Notes Set 2.4, for example, we showed a design for a logic slice that compares  two bits at a time.  In general, we can optimize logic for any  number of bits and then apply multiple copies of the resulting logic in space (a generalization of the bit-sliced approach), or in time (a generalization of the serialization approach), or in a combination of the two.  Sometimes these tradeoffs may happen at a higher level. As mentioned in Notes Set 2.3, computer software uses  the carry out of an adder to perform addition of larger  groups of bits (over multiple clock cycles) than is supported by the processor's adder hardware.  In computer system design, engineers often design hardware elements that are general enough to support this kind of extension in software.  As a concrete example of the possible tradeoffs, consider a serial comparator design based on the {2-bit} slice variant.  This approach leads to a serial design with 24 gates and 10 inverters,  which is not much larger than our earlier serial design.  In terms of gate delays, however, the new design is identical, meaning that we finish a comparison in half the time.  More realistic area and timing metrics show slightly more difference between the two designs.  These differences can  dominate the  results if we blindly scale the idea to handle more bits without  thinking carefully about the design.  Neither many-input gates nor gates driving many outputs work well in practice.    {Finite State Machines}  A { finite state machine} (or { FSM}) is a model for understanding the behavior of a system by describing the system as occupying one of a finite set of states, moving between these states in response to external inputs, and producing external outputs.  In any given state, a particular input may cause the FSM to move to another state; this  combination is called a { transition rule}.  An FSM comprises five parts: a finite set of states, a set of  possible inputs, a set of possible outputs, a set of transition rules, and methods for calculating outputs.    When an FSM is implemented as a digital system, all states must be represented as patterns using a fixed number of bits, all inputs must be translated into bits, and all outputs must be translated into bits.  For a digital FSM, transition rules must be { complete}; in other words, given any state of the FSM, and any pattern of input bits, a transition must be defined from that state to another state  (transitions from a state to itself, called { self-loops},  are acceptable).  And, of course, calculation of outputs for a digital FSM reduces to Boolean logic expressions.  In this class, we focus on clocked synchronous FSM implementations, in which the FSM's internal state bits are stored in flip-flops.  In this section, we introduce the tools used to describe, develop, and analyze implementations of FSMs with digital logic.  In the next few weeks, we will show you how an FSM can serve as the central control logic in a computer.  At the same time, we will illustrate connections between FSMs and software and will make some connections with other areas of interest in ECE, such as the design and analysis of digital  control systems.  The table below gives a { list of abstract states} for a typical  keyless entry system for a car.  In this case, we have merely named the states rather than specifying the bit patterns to be used for each state---for this reason, we refer to them as abstract states. The description of the states in the first column is an optional element often included in the early design stages for an FSM, when identifying the states needed for the design. A list may also include the outputs for each state.  Again, in the list below, we have specified these outputs abstractly.  By including outputs for each state, we implicitly assume that outputs depend only on the state of the FSM.  We discuss this assumption in more detail later in these notes (see ``Machine Models''),  but will make the assumption throughout",
    "GPT-3-Semantic-Search-Generations": {
      "question": " How does the choice of representation for an FSM\\'s states affect the design complexity?\\nA: The choice of representation can dramatically affect the design complexity. \\n\\n",
      "answer": "\nThe choice of representation for an FSM's states can affect the design complexity because it determines how many bits are needed to represent each state. If more bits are needed to represent a state, then the design will be more complex."
    }
  }
]