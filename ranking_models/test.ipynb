{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('final')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ogm = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "# ogt = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = open('../../../QA_generation_from_textbook/prompt_engineering/gpt-3_semantic_search/GPT-3_semantic_search.json')\n",
    "data = json.load(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [row['GPT-3-Semantic-Search-Generations']['question'] for row in data]\n",
    "a = [row['GPT-3-Semantic-Search-Generations']['answer'] for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score(q, a, model):\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained(model)\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "#     features = tokenizer([q for i in range(len(a))], a,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         scores = model(**features).logits\n",
    "    \n",
    "#     return scores\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = tokenizer(['How many people live in Berlin?', 'How many people live in Berlin?'], ['Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.', 'New York City is famous for the Metropolitan Museum of Art.'],  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     scores = model(**features).logits\n",
    "#     print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ogt(['How many people live in Berlin?', 'How many people live in Berlin?'], ['Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.', 'New York City is famous for the Metropolitan Museum of Art.'],  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# ogm.eval()\n",
    "# with torch.no_grad():\n",
    "#     scores = ogm(**features).logits\n",
    "#     print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "best = pd.read_csv('cleaned_student_written_QA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does a decoder work? How is it different f...</td>\n",
       "      <td>A decoder has n input lines, and (2^n) output ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the Branch Opcode work in LC3?</td>\n",
       "      <td>During Branch, the LC3 looks at the value in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is a Multiplexer?</td>\n",
       "      <td>A multiplexer acts a selector of multiple diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is de Morgan's Law?</td>\n",
       "      <td>De Morgan’s Law is a way to find out an altern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are don’t care values?</td>\n",
       "      <td>'Don’t care values' are used when the output o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>How is a clock abstraction related to a clock ...</td>\n",
       "      <td>A clock abstraction ignores many details from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Why would I use an iterative construct in C?</td>\n",
       "      <td>An iterative construct would be used in C when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Why would I use a constructive construct in C?</td>\n",
       "      <td>A conditional construct would be used in C whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>What is an operator and when would you use it ...</td>\n",
       "      <td>An operator is a symbol that is used to perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>What is a function used for in C?</td>\n",
       "      <td>A function is a block of code that does a cert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   How does a decoder work? How is it different f...   \n",
       "1             How does the Branch Opcode work in LC3?   \n",
       "2                              What is a Multiplexer?   \n",
       "3                            What is de Morgan's Law?   \n",
       "4                         What are don’t care values?   \n",
       "..                                                ...   \n",
       "64  How is a clock abstraction related to a clock ...   \n",
       "65       Why would I use an iterative construct in C?   \n",
       "66     Why would I use a constructive construct in C?   \n",
       "67  What is an operator and when would you use it ...   \n",
       "68                  What is a function used for in C?   \n",
       "\n",
       "                                           completion  \n",
       "0   A decoder has n input lines, and (2^n) output ...  \n",
       "1   During Branch, the LC3 looks at the value in t...  \n",
       "2   A multiplexer acts a selector of multiple diff...  \n",
       "3   De Morgan’s Law is a way to find out an altern...  \n",
       "4   'Don’t care values' are used when the output o...  \n",
       "..                                                ...  \n",
       "64  A clock abstraction ignores many details from ...  \n",
       "65  An iterative construct would be used in C when...  \n",
       "66  A conditional construct would be used in C whe...  \n",
       "67  An operator is a symbol that is used to perfor...  \n",
       "68  A function is a block of code that does a cert...  \n",
       "\n",
       "[69 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differences = []\n",
    "# all = []\n",
    "\n",
    "# for i in range(len(best)):\n",
    "\n",
    "#     question = best['prompt'][i]\n",
    "#     answers = [best['completion'][i], a[i]]\n",
    "\n",
    "#     features = tokenizer([question for i in range(len(answers))], answers,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#     features = ogt([question for i in range(len(answers))], answers,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         scores = model(**features).logits\n",
    "#         ogs = ogm(**features).logits\n",
    "\n",
    "        \n",
    "#         differences.append((float(scores[0]) - float(ogs[0]), float(scores[1]) - float(ogs[1])))\n",
    "#         all.append({'final':scores, 'original':ogs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0 \n",
    "# for row in differences:\n",
    "#     if row[0] > 1 or row[0] < -1:\n",
    "#         print(counter)\n",
    "#     if row[1] > 1 or row[1] < -1:\n",
    "#         print(counter)\n",
    "#     counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = best['prompt'][0]\n",
    "# answers = [best['completion'][0], 'The decoder works by doing all sorts of things. It is different from the multiplexer by doing something else.']\n",
    "\n",
    "# features = tokenizer([question for i in range(len(answers))], answers,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "# features = ogt([question for i in range(len(answers))], answers,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     scores = model(**features).logits\n",
    "#     ogs = ogm(**features).logits\n",
    "#     print(scores, '\\n', ogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(question, '\\n', answers[0], '\\n', answers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m',\n",
       " 'so',\n",
       " 'only',\n",
       " 'further',\n",
       " 'does',\n",
       " 'all',\n",
       " \"won't\",\n",
       " \"doesn't\",\n",
       " 'did',\n",
       " 'they',\n",
       " \"that'll\",\n",
       " 'with',\n",
       " 'a',\n",
       " \"isn't\",\n",
       " \"hasn't\",\n",
       " 'than',\n",
       " 'such',\n",
       " \"should've\",\n",
       " 'shan',\n",
       " 'wouldn',\n",
       " 'while',\n",
       " 'o',\n",
       " 'there',\n",
       " 'll',\n",
       " 'ma',\n",
       " 'don',\n",
       " 'doing',\n",
       " 'through',\n",
       " 'she',\n",
       " 'under',\n",
       " \"mightn't\",\n",
       " 'now',\n",
       " 'when',\n",
       " \"you're\",\n",
       " 'mustn',\n",
       " 'having',\n",
       " 'some',\n",
       " 'before',\n",
       " 'him',\n",
       " 'its',\n",
       " 'in',\n",
       " 'each',\n",
       " 'other',\n",
       " 'up',\n",
       " 'had',\n",
       " \"weren't\",\n",
       " \"aren't\",\n",
       " \"wouldn't\",\n",
       " 'between',\n",
       " 'until',\n",
       " 'our',\n",
       " 'what',\n",
       " 'then',\n",
       " 'my',\n",
       " 'of',\n",
       " 'shouldn',\n",
       " 'just',\n",
       " 'hasn',\n",
       " 'from',\n",
       " 'ourselves',\n",
       " 'and',\n",
       " 'on',\n",
       " 'their',\n",
       " 've',\n",
       " 'yourself',\n",
       " 'more',\n",
       " 'those',\n",
       " 'because',\n",
       " \"it's\",\n",
       " 'about',\n",
       " 'her',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'not',\n",
       " 'at',\n",
       " 'itself',\n",
       " 'an',\n",
       " 'the',\n",
       " \"haven't\",\n",
       " 'herself',\n",
       " \"you've\",\n",
       " 'has',\n",
       " 'theirs',\n",
       " 'being',\n",
       " 'he',\n",
       " 'hers',\n",
       " 'that',\n",
       " 'can',\n",
       " 'y',\n",
       " \"she's\",\n",
       " 'into',\n",
       " 'needn',\n",
       " 'do',\n",
       " 'ours',\n",
       " 'is',\n",
       " 'whom',\n",
       " 'me',\n",
       " 'during',\n",
       " 'for',\n",
       " 'doesn',\n",
       " \"wasn't\",\n",
       " 'once',\n",
       " 'out',\n",
       " 'are',\n",
       " 'won',\n",
       " 'as',\n",
       " 'after',\n",
       " \"shan't\",\n",
       " 'same',\n",
       " 'yourselves',\n",
       " 'why',\n",
       " 't',\n",
       " 'again',\n",
       " 'where',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'here',\n",
       " 'to',\n",
       " 'will',\n",
       " 'weren',\n",
       " 'few',\n",
       " 'own',\n",
       " 're',\n",
       " 'myself',\n",
       " 'this',\n",
       " 'been',\n",
       " 'if',\n",
       " 'your',\n",
       " 'very',\n",
       " \"couldn't\",\n",
       " \"shouldn't\",\n",
       " 'you',\n",
       " 'over',\n",
       " 'nor',\n",
       " 'them',\n",
       " 'no',\n",
       " 'wasn',\n",
       " 'we',\n",
       " 'ain',\n",
       " 'am',\n",
       " 'were',\n",
       " 'mightn',\n",
       " 'be',\n",
       " 'couldn',\n",
       " 'have',\n",
       " 'aren',\n",
       " \"hadn't\",\n",
       " 'yours',\n",
       " 'below',\n",
       " 'against',\n",
       " 'these',\n",
       " 's',\n",
       " 'd',\n",
       " 'i',\n",
       " 'or',\n",
       " 'how',\n",
       " \"needn't\",\n",
       " 'should',\n",
       " 'but',\n",
       " \"you'd\",\n",
       " 'himself',\n",
       " 'most',\n",
       " 'above',\n",
       " 'isn',\n",
       " \"you'll\",\n",
       " 'was',\n",
       " 'who',\n",
       " 'themselves',\n",
       " 'too',\n",
       " 'any',\n",
       " 'off',\n",
       " 'it',\n",
       " 'his',\n",
       " \"mustn't\",\n",
       " 'by',\n",
       " 'hadn',\n",
       " 'which',\n",
       " 'haven',\n",
       " 'both']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = list(stop_words)\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_first = []\n",
    "for i in range(len(best)):\n",
    "    text = ''\n",
    "    for word in best['prompt'][i].split(' '):\n",
    "        if word.isupper() and len(word) > 1:\n",
    "            text += word + ' '\n",
    "        elif word.lower() not in stop_words:\n",
    "            text += word + ' '\n",
    "    kw_first.append(text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_second = []\n",
    "for i in range(len(kw_first)):\n",
    "    text = ''\n",
    "    for word in kw_first[i].split():\n",
    "        for punc in ['.', '!', '?']:\n",
    "            if punc in word:\n",
    "                word = word.replace(punc, '')\n",
    "        text += word + ' '\n",
    "    kw_second.append(text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_first = []\n",
    "for i in range(len(a)):\n",
    "    text = ''\n",
    "    for word in a[i].split(' '):\n",
    "        if word.isupper() and len(word) > 1:\n",
    "            text += word.lower() + ' '\n",
    "        elif word.lower() not in stop_words:\n",
    "            text += word.lower() + ' '\n",
    "    a_first.append(text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_second = []\n",
    "for i in range(len(a_first)):\n",
    "    text = ''\n",
    "    for word in a_first[i].split():\n",
    "        for punc in ['.', '!', '?']:\n",
    "            if punc in word:\n",
    "                word = word.replace(punc, '')\n",
    "        text += word + ' '\n",
    "    a_second.append(text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = {}\n",
    "\n",
    "\n",
    "for i in range(len(kw_second)):\n",
    "    rs = []\n",
    "    for word in kw_second[i].split():\n",
    "        for row in a_second:\n",
    "            if word.lower() in row:\n",
    "                rs.append(row)\n",
    "    numbers[i] = rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['decoder work', 'multiplexer', 'different']\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "rake_class = Rake()\n",
    "rake_class.extract_keywords_from_text(best['prompt'][0])\n",
    "extracted_keyword = rake_class.get_ranked_phrases()\n",
    "print(extracted_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.0, 'decoder work'), (1.0, 'multiplexer'), (1.0, 'different')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rake_class.extract_keywords_from_text(best['prompt'][0])\n",
    "rake_class.get_ranked_phrases_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "text = \"This is one simple example.\"\n",
    "tokens = word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decoder work', 'NN'), ('multiplexer', 'CD'), ('different', 'JJ')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['decoder work', 'multiplexer', 'different'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('How', 'WRB'),\n",
       " ('does', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('decoder', 'NN'),\n",
       " ('work', 'NN'),\n",
       " ('?', '.'),\n",
       " ('How', 'WRB'),\n",
       " ('is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('different', 'JJ'),\n",
       " ('from', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('multiplexer', 'NN')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(best['prompt'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('How', 'WRB'),\n",
       " ('does', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('Branch', 'NNP'),\n",
       " ('Opcode', 'NNP'),\n",
       " ('work', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('LC3', 'NNP'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(best['prompt'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = []\n",
    "for i in range(len(kw_second)):\n",
    "    nouns = []\n",
    "    tags = nltk.pos_tag(kw_second[i].split())\n",
    "    for tag in tags:\n",
    "        if tag[1] == 'NNP' or tag[1] == 'NN' or tag[1] == 'NNS' or tag[0][0].isupper():\n",
    "            if tag[0] != 'work':\n",
    "                nouns.append(tag[0])\n",
    "    \n",
    "    key_words.append(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_negatives = {}\n",
    "counter = 0\n",
    "for row in key_words:\n",
    "    rs = []\n",
    "    n = len(row)\n",
    "    ncount = 0\n",
    "    for word in row:\n",
    "        for answer in a_second:\n",
    "            if answer != best['completion'][counter]:\n",
    "                if word.lower() in answer and answer not in rs:\n",
    "                    rs.append(answer)\n",
    "                    ncount += 1\n",
    "    # if ncount >= int(n/2):\n",
    "    #     key_negatives[counter] = rs\n",
    "    key_negatives[counter] = rs\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRAP', 'Vectors', 'LC3']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_words[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Branch', 'Opcode', 'LC3']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in key_negatives.items():\n",
    "    if len(v) < 5:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How does a decoder work? How is it different from a multiplexer'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best['prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 How does the Branch Opcode work in LC3?\n",
      "9 What are the TRAP Vectors in LC3?\n",
      "15 What is a 2’s complement integer used for?\n",
      "22 What are DeMorgan’s Laws?\n",
      "59 Why are Hamming codes used?\n",
      "What is Hamming distance?\n"
     ]
    }
   ],
   "source": [
    "print(1, best['prompt'][1])\n",
    "print(9, best['prompt'][9])\n",
    "print(15, best['prompt'][15])\n",
    "print(22, best['prompt'][22])\n",
    "print(59, best['prompt'][59])\n",
    "print(best['prompt'][60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is a crucial relationship between AND and OR functions. The basis of DeMorgan’s Laws says that we complement (perform the NOT operation) on 2 inputs A and B, and then perform the AND operation on the complement of the two inputs, and then take the complement of the result of the operation.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best['completion'][22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeMorgan’s', 'Laws']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_words[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_negatives[1] = ['The Branch Opcode is in LC3', 'The branch opcode works in the lc3', 'The lc3 contains the branch opcode',\n",
    " 'The branch opcode works by the lc3', 'The branch opcode is in the lc3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_negatives[9].extend(['The trap vectors in lc3 are very similar to the trap vectors in lc3.', 'The lc3 are in trap vectors', 'Vectors are made up of trap',\n",
    " 'Lc3 contains the trap vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_negatives[15].extend([\"The 2's complement integer is used for computations\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_negatives[22].extend([\"DeMorgan's Laws are logical laws\", \"DeMorgan's Laws are laws of logic\", \n",
    "\"DeMorgan's Laws are laws of mathematics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_negatives[59].extend(['The Hamming codes are codes used in Hamming', 'Hamming codes are used because of their ability', 'People use Hamming codes because of its versatility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_negatives[60].extend(['The hamming distance is the distance between two things', 'The Hamming distance detects the length between two points', \n",
    " 'The Hamming distance is the distance between two points', 'The Hamming distance is a distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('marco_negatives.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(key_negatives, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28596858067060ee176f7bab50a17c769bfd8a96306468e7ae0695529617abaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
