{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using spacy <br>\n",
    "```\n",
    "conda install -c conda-forge spacy\n",
    "conda install -c conda-forge cupy\n",
    "python -m spacy download en_core_web_trf\n",
    "\n",
    "pip install langchain pinecone-client PyPDF2\n",
    "# maybe: conda install -c conda-forge -y ipykernel=6\n",
    "# maybe: conda install -c anaconda -y notebook\n",
    "```\n",
    "\n",
    "Note: \n",
    "* Flan T5 XL max length is 512\n",
    "* Flan T5 XXL max length is 1024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Parse textbook (retain page numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages:  801\n"
     ]
    }
   ],
   "source": [
    "# parse textbook. \n",
    "# pip install PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    " \n",
    "# reader = PdfReader('../raw_data/notes/Student_Notes.pdf')\n",
    "reader = PdfReader('../raw_data/patel_textbook/Yale Patt - Introduction to Computing Systems_ From Bits & Gates to C & Beyond.pdf')\n",
    "print(\"Total pages: \", len(reader.pages))\n",
    " \n",
    "# extracting text from page\n",
    "textbook = []\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text().replace(\"\\n\", \" \")\n",
    "    # skip empty pages\n",
    "    if text:\n",
    "        textbook.append(dict(\n",
    "                            text=text,\n",
    "                            page_number=i, \n",
    "                            textbook_name='Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up useless pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'D.9 Some Standard Library Functions 751 to byptr. The value passed to free must be a pointer to a previously allocated region of memory, otherwise errors could occur. D.9.4.3 randandsrand The C standard utility functions contain a function to generate a sequence of random numbers. The function is called rand . It does not generate a truly random sequence, however. Instead, it generates the same sequence of varying values based on an initial seed value. When the seed is changed, a diﬀerent sequence is generated. For example, when seeded with the value 10, the generator will always generate the same sequence of numbers. However, this sequence will be diﬀerent than the sequence generated by another seed value. The function rand has the following declaration: int rand(void) It returns a pseudo-random integer in the range 0 to RAND_MAX , which is at least 32,767. To seed the pseudo-random number generator, use the function srand . This function has the following declaration: void srand(unsigned int seed);',\n",
       " 'page_number': 779,\n",
       " 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual delete last pages\n",
    "textbook = textbook[:765] # remove everything past page 780. Delete all appendix stuff.\n",
    "textbook[-1] # should show page_number 779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '1CHAPTER Welcome Aboard 1.1 What We Will Try to Do Welcome to From Bits and Gates to C and Beyond . Our intent is to introduce you over the next xxx pages to the world of computing. As we do so, we have one objective above all others: to show you very clearly that there is no magic to computing. The computer is a deterministic system—every time we hit it over the head in the same way and in the same place (provided, of course, it was in the same starting condition), we get the same response. The computer is not an electronic genius; on the contrary, if anything, it is an electronic idiot, doing exactly what we tell it to do. It has no mind of its own. What appears to be a very complex organism is really just a very large, sys- tematically interconnected collection of very simple parts. Our job throughout this book is to introduce you to those very simple parts and, step-by-step, build the interconnected structure that you know by the name computer . Like a house, we will start at the bottom, construct the foundation ﬁrst, and then go on to add layer after layer, as we get closer and closer to what most people know as a full-blown computer. Each time we add a layer, we will explain what we are doing, tying the new ideas to the underlying fabric. Our goal is that when we are done, you will be able to write programs in a computer language such as C using the sophisticated features of that language and to understand what is going on underneath, inside the computer. 1.2 How We Will Get There We will start (in Chapter 2) by ﬁrst showing that any information processed by the computer is represented by a sequence of 0s and 1s. That is, we will encode all information as sequences of 0s and 1s. For example, one encoding of the letter athat is commonly used is the sequence 01100001. One encoding of the decimal number 35is the sequence 00100011. We will see how to perform operations on such encoded information.',\n",
       " 'page_number': 29,\n",
       " 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual delete first 29 pages\n",
    "textbook = textbook[25:]\n",
    "textbook[0] # should show page_number 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\n"
     ]
    }
   ],
   "source": [
    "# save all_text json to file\n",
    "import json\n",
    "with open('./patel_textbook_cleaned.json', 'w') as f:\n",
    "    json.dump(textbook, f)\n",
    "\n",
    "print(len(textbook)) # 740 pages remaining in patel textbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas = [dict(page_number=page['page_number'], textbook_name=page['textbook_name']) for page in textbook]\n",
    "textbook_texts = [page['text'] for page in textbook]\n",
    "assert len(textbook_texts) == len(metadatas), 'must be equal sizes'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split the textbook string into context-size contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397\n"
     ]
    }
   ],
   "source": [
    "from langchain import text_splitter\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.text_splitter import CharacterTextSplitter, NLTKTextSplitter, SpacyTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "# good examples here: https://langchain.readthedocs.io/en/latest/modules/utils/combine_docs_examples/textsplitter.html\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-xl')\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(tokenizer, chunk_size=450, chunk_overlap=50, separators = \". \",)\n",
    "# texts = text_splitter.split_text(textbook)\n",
    "texts = text_splitter.create_documents(texts=textbook_texts, metadatas=metadatas)\n",
    "print(len(texts))\n",
    "\n",
    "# 250 --> 2723\n",
    "# 350 --> 1692\n",
    "# 450 chunks -> 1397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='In Chapter 5, we will begin the complete deﬁnition of the LC-3 computer. We will see that the memory address space of t h eL C - 3i s216, and the addressability is 16 bits. Recall from Chapter 3 that we access memory by providing the address from which we wish to read, or to which we wish to write. To read the contents of a', lookup_str='', metadata={'page_number': 150, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='4.1Basic Components 123 00000110 00000100000 001 010 011 100 101 110 111 Figure 4.2 Location 6 contains the value 4; location 4 contains the value 6. memory location, we ﬁrst place the address of that location in the memory’s address register ( MAR ) and then interrogate the computer’s memory. The information stored in the location having that address will be placed in the memory’s data register ( MDR ). To write (or store) a value in a memory location, we ﬁrst write the address of the memory location in the MAR, and the value to be stored in the MDR. We then interrogate the computer’s memory with the write enable signal asserted. The information contained in the MDR will be written into the memory location whose address is in the MAR. Before we leave the notion of memory for the moment, let us again emphasize the two characteristics of a memory location: its address and what is stored there. Figure 4.2 shows a representation of a memory consisting of eight locations. Its addresses are shown at the left, numbered in binary from 0 to 7. Each location contains eight bits of information. Note that the value 6 is stored in the memory location whose address is 4, and the value 4 is stored in the memory location whose address is 6. These represent two very diﬀerent situations. Finally, an analogy: the post oﬃce boxes in your local post oﬃce. The box number is like the memory location’s address. Each box number is unique. The information stored in the memory location is like the letters contained in the post oﬃce box. As time goes by, what is contained in the post oﬃce box at any par- ticular moment can change. But the box number remains the same. So, too, with each memory location. The value stored in that location can be changed, but the location’s memory address remains unchanged. 4.1.2 Processing Unit The actual processing of information in the computer is carried out by the processing unit', lookup_str='', metadata={'page_number': 151, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='The value stored in that location can be changed, but the location’s memory address remains unchanged. 4.1.2 Processing Unit The actual processing of information in the computer is carried out by the processing unit . The processing unit in a modern computer can consist of many sophisticated complex functional units, each performing one particular operation (divide, square root, etc.). The simplest processing unit, and the one normally thought of when discussing the basic von Neumann model, is the ALU .ALU is the abbreviation for Arithmetic and Logic Unit, so called because it is usually capa- ble of performing basic arithmetic functions (like ADD and SUBTRACT) and basic logic operations (like bit-wise AND, OR, and NOT) that we have already studied in Chapter 2. We will see in Chapter 5 that the LC-3 has an ALU, which', lookup_str='', metadata={'page_number': 151, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='124 chapter 4 The von Neumann Model can perform ADD, AND, and NOT operations. Two of these (ADD and AND) we will discuss in this chapter. The ALU normally processes data elements of a ﬁxed size referred to as the word length of the computer. The data elements are called words . For example, to perform ADD, the ALU receives two words as inputs and produces a single word (the sum) as output. Each ISA has its own word length, depending on the intended use of the computer. Most microprocessors today that are used in PCs or workstations have a word length of 64 bits (as is the case with Intel’s “Core” processors) or 32 bits (as is the case with Intel’s “Atom” processors). Even most microprocessors now used in cell phones have 64-bit word lengths, such as Apple’s A7 through A11 processors, and Qualcomm’s SnapDragon processors. However, the microprocessors used in very inexpensive applications often have word lengths of as little as 16 or even 8 bits. In the LC-3, the ALU processes 16-bit words. We say the LC-3 has a word length of 16 bits. It is almost always the case that a computer provides some small amount of storage very close to the ALU to allow results to be temporarily stored if they will be needed to produce additional results in the near future. For example, if a computer is to calculate ( A+B)⋅C, it could store the result of A+Bin memory, and then subsequently read it in order to multiply that result by C. However, the time it takes to access memory is long compared to the time it takes to perform the ADD or MULTIPLY. Almost all computers, therefore, have temporary storage for storing the result of A+Bin order to avoid the much longer access time that would be necessary when it came time to multiply', lookup_str='', metadata={'page_number': 152, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Almost all computers, therefore, have temporary storage for storing the result of A+Bin order to avoid the much longer access time that would be necessary when it came time to multiply. The most common form of temporary storage is a set of registers, like the register described in Section 3.7. Typically, the size of each register is identical to the size of values processed by the ALU; that is, they each contain one word. The LC-3 has eight registers (R0, R1, …R7), each containing 16 bits. Current microprocessors typically contain 32 registers, each consisting of 32 or 64 bits, depending on the architecture. These serve the same purpose as the eight 16-bit registers in the LC-3. However, the importance of temporary storage for values that most modern computers will need shortly means many computers today have an additional set of special-purpose registers consisting of 128 bits of information to handle special needs. Those special needs we will have to save for later in your studies. 4.1.3 Input and Output In order for a computer to process information, the information must get into the computer. In order to use the results of that processing, those results must be displayed in some fashion outside the computer. Many devices exist for the purposes of input and output. They are generically referred to in computer jar- gon as peripherals because they are in some sense accessories to the processing function. Nonetheless, they are no less important. In the LC-3 we will have the two most basic input and output devices. For input, we will use the keyboard; for output, we will use the monitor.', lookup_str='', metadata={'page_number': 152, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='4.2The LC-3: An Example von Neumann Machine 125 There are, of course, many other input and output devices in computer sys- tems today. For input we have among other things the mouse, digital scanners, and shopping mall kiosks to help you navigate the shopping mall. For output we have among other things printers, LED displays, disks, and shopping mall kiosks to help you navigate the shopping mall. :-) In the old days, a lot of input and out- put was carried out by punched cards. Fortunately, for those who would have to lug around boxes of cards, the use of punched cards has largely disappeared. 4.1.4 Control Unit The control unit is like the conductor of an orchestra; it is in charge of making all the other parts of the computer play together. As we will see when we describe the step-by-step process of executing a computer program, it is the control unit that keeps track of both where we are within the process of executing the program and where we are in the process of executing each instruction. To keep track of which instruction is being executed, the control unit has an instruction register to contain that instruction. To keep track of which instruc- tion is to be processed next, the control unit has a register that contains the next instruction’s address. For historical reasons, that register is called the program counter (abbreviated PC), although a better name for it would be the instruction pointer , since the contents of this register is, in some sense, “pointing” to the next instruction to be processed. Curiously, Intel does in fact call that register the instruction pointer, but the simple elegance of that name has not caught on. 4.2 The LC-3: An Example von Neumann Machine In Chapter 5, we will specify in detail the LC-3, a simple computer that we will study extensively. We have already shown you its data path in Chapter 3 (Figure 3.35) and identiﬁed several of its structures in Section 4.1', lookup_str='', metadata={'page_number': 153, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='We have already shown you its data path in Chapter 3 (Figure 3.35) and identiﬁed several of its structures in Section 4.1. In this sec- tion, we will pull together all the parts of the LC-3 we need to describe it as a von Neumann computer (see Figure 4.3). We constructed Figure 4.3 by starting with the LC-3’s full data path (Figure 3.35) and removing all elements that are not essential to pointing out the ﬁve basic components of the von Neumann model. Note that there are two kinds of arrowheads in Figure 4.3: ﬁlled-in and not-ﬁlled-in. Filled-in arrowheads denote data elements that ﬂow along the cor- responding paths. Not-ﬁlled-in arrowheads denote control signals that control the processing of the data elements. For example, the box labeled ALU in the pro- cessing unit processes two 16-bit values and produces a 16-bit result. The two sources and the result are all data, and are designated by ﬁlled-in arrowheads. The operation performed on those two 16-bit data elements (it is labeled ALUK) is part of the control—therefore, a not-ﬁlled-in arrowhead. MEMORY consists of the storage elements, along with the Memory Address Register (MAR) for addressing individual locations and the', lookup_str='', metadata={'page_number': 153, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='126 chapter 4 The von Neumann Model MDRCONTROL UNITPROCESSOR BUS OUTPUT INPUTPROCESSING UNIT MEMORYMAR16 16 161616G G a a t t e e P MARMUX C 16 16SEXTSEXT I NPZ LogicR 163 16 316SR2MUX [8:0][5]1616 [4:0] 161616 LD.IR DSR KBSRDDRME M. EN, R .W KBDR LD.MAR LD.MDRGateMDR+PC SR2 OUTSR1 OUTREG FI LEP MARMUX CMUXLD.PC 3 332 SR1 SR2LD.REGDR+1 162 ALUKALUA BCLK RFINITE STATE MACHINE GateALU Figure 4.3 The LC-3 as an example of the von Neumann model. Memory Data Register (MDR) for holding the contents of a memory location on its way to/from the storage. Note that the MAR contains 16 bits, reﬂecting the fact that the memory address space of the LC-3 is 216 memory locations. The MDR contains 16 bits, reﬂecting the fact that each memory location contains 16 bits—that is, the LC-3 is 16-bit addressable. INPUT/OUTPUT consists of a keyboard and a monitor. The simplest keyboard requires two registers: a keyboard data register (KBDR) for holding the ASCII codes of keys struck and a keyboard status register (KBSR) for maintaining status information about the keys struck. The simplest monitor also requires two registers: a display data register (DDR) for holding the ASCII code of something to be displayed on the screen and', lookup_str='', metadata={'page_number': 154, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='4.3 Inst ruction P rocessing 127 a display status register (DSR) for maintaining associated status information. These input and output registers will be discussed in detail in Chapter 9. THE PROCESSING UNIT consists of a functional unit (ALU) that performs arithmetic and logic operations and eight registers (R0, …R7) for storing temporary values that will be needed in the near future as operands for subsequent instructions. The LC-3 ALU can perform one arithmetic operation (addition) and two logical operations (bitwise AND and bitwise NOT). THE CONTROL UNIT consists of all the structures needed to manage the processing that is carried out by the computer. Its most important structure is the ﬁnite state machine, which directs all the activity. Recall the ﬁnite state machines in Section 3.6. Processing is carried out step by step, or rather, clock cycle by clock cycle. Note the CLK input to the ﬁnite state machine in Figure 4.3. It speciﬁes how long each clock cycle lasts. The instruction register (IR) is also an input to the ﬁnite state machine since the LC-3 instruction being processed determines what activities must be carried out. The program counter (PC) is also a part of the control unit; it keeps track of the next instruction to be executed after the current instruction ﬁnishes. Note that all the external outputs of the ﬁnite state machine in Figure 4.3 have arrowheads that are not ﬁlled in. These outputs control the processing through- out the computer. For example, one of these outputs (two bits) is ALUK, which controls the operation performed in the ALU (ADD, AND, or NOT) during the current clock cycle. Another output is GateALU, which determines whether or not the output of the ALU is provided to the processor bus during the current clock cycle', lookup_str='', metadata={'page_number': 155, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0),\n",
       " Document(page_content='Another output is GateALU, which determines whether or not the output of the ALU is provided to the processor bus during the current clock cycle. The complete description of the data path, control, and ﬁnite state machine for one implementation of the LC-3 is the subject of Appendix C. 4.3 Instruction Processing The central idea in the von Neumann model of computer processing is that the program and data are both stored as sequences of bits in the computer’s memory, and the program is executed one instruction at a time under the direction of the control unit. 4.3.1 The Instruction The most basic unit of computer processing is the instruction. It is made up of two parts, the opcode (what the instruction does) and the operands (who it does it to!). There are fundamentally three kinds of instructions: operates ,data move- ment , and control , although many ISAs have some special instructions that are necessary for those ISAs. Operate instructions operate on data. The LC-3 has three operate instructions: one arithmetic (ADD) and two logicals (AND and', lookup_str='', metadata={'page_number': 155, 'textbook_name': 'Yale-Patt_Sanjay-Patel--Intro_to_Computing_Systems'}, lookup_index=0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[200:210]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embed each context, and save it to a vector database, this one is hosted by Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/kastanday/.cache/torch/sentence_transformers/intfloat_e5-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import HuggingFaceEmbeddings #OpenAIEmbeddings, \n",
    "import pinecone\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# See the docs here, (search for pinecone): https://langchain.readthedocs.io/en/latest/reference/modules/vectorstore.html\n",
    "\n",
    "pinecone.init(api_key=\"87823627-c1f4-48fe-9c36-3d19d3dd29bb\", environment=\"us-west1-gcp\")\n",
    "\n",
    "model_name = \"intfloat/e5-large\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "pinecone_index = Pinecone.from_texts(\n",
    "    texts=textbook_texts,\n",
    "    metadatas=metadatas,\n",
    "    embedding=embeddings,\n",
    "    index_name=\"uiuc-chatbot\" \n",
    ")\n",
    "\n",
    "# see the Pinecone index here (requires auth): https://app.pinecone.io/organizations/-NF9ryDGePT7APP6wrFM/projects/us-west1-gcp:32dcf9c/indexes/uiuc-chatbot-2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✅ Done with critical steps, the rest is for demonstration only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Easily run simliarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code to run Pinecone search during inference.\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "# pinecone.init(api_key=\"***\", environment=\"us-west1-gcp\")\n",
    "# pincecone_index = pinecone.Index(\"uiuc-chatbot\")\n",
    "# vectorstore = Pinecone(index=pincecone_index, embedding_function=embeddings, text_key=\"text\")\n",
    "# question = \"What is a finite state machine in electrical engineering?\"\n",
    "# relevant_context_list = pinecone_index.similarity_search(question, k=3)\n",
    "\n",
    "# for d in relevant_context_list:\n",
    "#     print(d.page_content)\n",
    "#     print(d.metadata['page_number'], d.metadata['textbook_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='82  3.1.3 Finite State Machines Aﬁnite state machine (orFSM) is a model for understanding the behavior of a system by describin g the system as occupying one of a ﬁnite set of states, moving betwe en these states in response to external inputs, and producing external outputs. In any given state, a pa rticular input may cause the FSM to move to another state; this combination is called a transition rule . An FSM comprises ﬁve parts: a ﬁnite set of states, a set of possible inputs, a set of possible outputs, a set of transition rules, and methods for calculating outputs. When an FSM is implemented as a digital system, all states must be rep resented as patterns using a ﬁxed number of bits, all inputs must be translated into bits, and all outpu ts must be translated into bits. For a digital FSM, transition rules must be complete ; in other words, given any state of the FSM, and any pattern of input bits, a transition must be deﬁned from that state to another state (transitions from a state to itself, called self-loops , are acceptable). And, of course, calculation of outputs for a dig ital FSM reduces to Boolean logic expressions. In this class, we focus on clocked sync hronous FSM implementations, in which the FSM’s internal state bits are stored in ﬂip-ﬂops. In this section, we introduce the tools used to describe, develop, a nd analyze implementations of FSMs with digital logic. In the next few weeks, we will show you how an FSM can se rve as the central control logic in a computer. At the same time, we will illustrate connections between F SMs and software and will make some connections with other areas of interest in ECE, such as the design and analysis of digital control systems. The table below gives a list of abstract states for a typical keyless entry system for a car. In this case, we have merely named the states rather than specifying the bit pat terns to be used for each state—for this reason, we refer to them as abstract states. The description of the states in the ﬁrst column is an optional element often included in the early design stages for an FSM, when ide ntifying the states needed for the design. A list may also include the outputs for each state. Again, in th e list below, we have speciﬁed these outputs abstractly. By including outputs for each state, we implicit ly assume that outputs depend only on the state of the FSM. We discuss this assumption in more detail later in these notes (see “Machine Models”), but will make the assumption throughout our class. meaning state driver’s door other doors alarm on vehicle locked LOCKED locked locked no driver door unlocked DRIVER unlocked locked no all doors unlocked UNLOCKED unlocked unlocked no alarm sounding ALARM locked locked yes Another tool used with FSMs is the next-state table (sometimes called a state transition table , or just astate table ), which maps the current state and input combination into the next state of the FSM. The abstract variant shown below outlines desired behavior at a high leve l, and is often ambiguous, incomplete, and even inconsistent. For example, what happens if a user pushes two buttons? What happens if they push unlock while the alarm is sounding? These questions should event ually be considered. However, we can already start to see the intended use of the design: starting f rom a locked car, a user can push “unlock” once to gain entry to the driver’s seat, or push “unlock” twice to op en the car fully for passengers. To lock the car, a user can push the “lock” button at any time. And, if a use r needs help, pressing the “panic” button sets oﬀ an alarm. state action/input next state LOCKED push “unlock” DRIVER DRIVER push “unlock” UNLOCKED (any) push “lock” LOCKED (any) push “panic” ALARM' lookup_str='' metadata={'page_number': 87.0, 'textbook_name': 'ECE-120-student-notes'} lookup_index=0\n",
      "\n",
      "page_content='3.1 Serialization and Finite State Machines 79 ECE120: Introduction to Computer Engineering Notes Set 3.1 Serialization and Finite State Machines The third part of our class builds upon the basic combinational and se quential logic elements that we developed in the second part. After discussing a simple application of stored state to trade between area and performance, we introduce a powerful abstraction for formalizin g and reasoning about digital systems, the Finite State Machine (FSM). General FSM models are broadly applicab le in a range of engineering contexts, including not only hardware and software design but also the design o f control systems and distributed systems. We limit our model so as to avoid circuit timing issues in your ﬁr st exposure, but provide some amount of discussion as to how, when, and why you should eventually learn the more sophisticated models. Through development a range of FSM examples, we illustrate importa nt design issues for these systems and motivateacoupleofmoreadvancedcombinationallogicdevicesthat canbe usedasbuilding blocks. Together with the idea of memory, another form of stored state, these elem ents form the basis for development of our ﬁrst computer. At this point we return to the textbook, in whic h Chapters 4 and 5 provide a solid introduction to the von Neumann model of computing systems and t he LC-3 (Little Computer, version 3) instruction set architecture. By the end of this part of the cours e, you will have seen an example of the boundary between hardware and software, and will be ready to wr ite some instructions yourself. In this set of notes, we cover the ﬁrst few parts of this material. W e begin by describing the conversion of bit-sliced designs into serial designs, which store a single bit slice’s out put in ﬂip-ﬂops and then feed the outputs back into the bit slice in the next cycle. As a speciﬁc example, we use our bit-sliced comparator to discuss tradeoﬀs in area and performance. We introduce Finite S tate Machines and some of the tools used to design them, then develop a handful of simple counter desig ns. Before delving too deeply into FSM design issues, we spend a little time discussing other strategies for c ounter design and placing the material covered in our course in the broader context of digital system des ign. Remember that sections marked with an asterisk are provided solely for your interest, but you may need to learn this material in later classes. 3.1.1 Serialization: General Strategy In previous notes, we discussed and illustrated the development of bit-sliced logic, in which one designs a logic block to handle one bit of a multi-bit operation, then replicates th e bit slice logic to construct a design for the entire operation. We developed ripple carry adders in this wa y in Notes Set 2.3 and both unsigned and 2’s complement comparators in Notes Set 2.4. Another interesting design strategy is serialization : rather than replicating the bit slice, we can use ﬂip- ﬂops to store the bits passed from one bit slice to the next, then pr esent the stored bits to the same bit slice in the next cycle. Thus, in a serial design, we only need one copy of th e bit slice logic! The area needed for a serial design is usually much less than for a bit-sliced design, but such a design is also usually slower. After illustrating the general design strategy, we’ll consider thes e tradeoﬀs more carefully in the context of a detailed example. Recall the general bit-sliced design ap- proach, as illustrated to the right. Some number of copies of the logic for a single bit slice are connected in sequence. Each bit slice accepts Pbits of operand input and produces Qbits of external output. Adjacent bit slices receive an addi- tionalMbits of information from the previous bit slice and pass along Mbits to the next bit slice, generallyusing some representation chosen by the designer.P Qsecond bit sliceMP Qlast bit sliceMP QM Moutput logicRinitial values . . .first bit sliceresults per−slice outputsper−slice inputsa general bit−sliced design The ﬁrst bit slice is initialized by passing in constant values, and some ca lculation may be performed on the ﬁnal bit slice’s results to produce Rbits more external output.' lookup_str='' metadata={'page_number': 84.0, 'textbook_name': 'ECE-120-student-notes'} lookup_index=0\n",
      "\n",
      "page_content='3.3 Design of the Finite State Machine for the Lab 103 be reached from any of the states in our design. We might then try to leverage the fact that the next- state patterns from these two states are not relevant (recall that we ﬁxed the next-state patterns for all four of the possible PAID states) to further simplify our logic, but doing so does not provide any advan- tage (you may want to check our claim). The ﬁnal state table is shown to the right. We have included the extra states at the bottom of the table. Wehavespeciﬁedthenext-statelogicfortheseS+ 2S+ 1S+ 0 state S2S1S0T= 0T= 1A P PAID1 010 000 100 1 1 PAID2 101 000 100 1 1 DIME 000 001 101 1 0 REJECTD 001 001 101 0 0 QUARTER 100 010 110 1 0 REJECTQ 110 010 110 0 0 EXTRA1 011 000 100 x x EXTRA2 111 000 100 x x states, but left the output bits as don’t cares. A state transition diagram appears at the bottom of this page. 3.3.4 Testing the Design Having a complete design on paper is a good step forward, but human s make mistakes at all stages. How can we know that a circuit that we build in the lab correctly implements t he FSM that we have outlined in these notes? For the lab design, we have two problems to solve. First, we have not speciﬁed an initialization scheme for the FSM. We may want the FSM to start in one of the PAID states, bu t adding initialization logic to the design may mean requiring you to wire together signiﬁcantly more chip s. Second, we need a sequence of inputs that manages to test that all of the next-state and outpu t logic implementations are correct. Testing sequential logic, including FSMs, is in general extremely diﬃcu lt. In fact, large sequential systems today are generally converted into combinational logic by using shift registers to ﬁll the ﬂip-ﬂops with a particular pattern, executing the logic for one clock cycle, and che cking that the resulting pattern of bits in the ﬂip-ﬂops is correct. This approach is called scan-based testing , and is discussed in ECE 543. You will make use of a similar approach when you test your combinational logic in the second week of the lab, before wiring up the ﬂip-ﬂops. We have designed our FSM to be easy to test (even small FSMs may be challenging) with a brute force approach. In particular, we identify two input sequences that tog ether serve both to initialize and to test a correctly implemented variant of our FSM. Our initialization sequence forces the FSM into a speciﬁc state regardless of its initial state. And our test sequence crosses eve ry transition arc leaving the six valid states. In terms of T, the coin type, we initialize the FSM with the input sequence 001. Notic e that such a sequence takes any initial state into PAID2. For testing, we use the input sequence 111010010001. You should trace this sequence, starting from PAID2, on the diagram below to see how the test sequence covers all of the possible arcs. As we test, we need also to observe the AandPoutputs in each state to check the output logic. T=0 T=0 T=1T=1 T=1T=1 T=1T=0 T=0T=0 T=1T=1 T=0T=1T=0 T=0 QTR 100/10PAID1 010/11PAID2 101/11EXTRA1 011/xxEXTRA2 111/xxDIME 000/10REJECTD 001/00 REJECTQ 110/00' lookup_str='' metadata={'page_number': 108.0, 'textbook_name': 'ECE-120-student-notes'} lookup_index=0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Easily run similarity search on the Pinecone index\n",
    "question = \"What is a finite state machine in electrical engineering?\"\n",
    "relevant_context_list = pinecone_index.similarity_search(question, k=3)\n",
    "\n",
    "for d in relevant_context_list:\n",
    "    print(d.page_content)\n",
    "    print(d.metadata['page_number'], d.metadata['textbook_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-large and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 3.074671985814348e-05, 'start': 1981, 'end': 2020, 'answer': 'wishes to secure a bicycle with a lock,'}\n",
      "3.6 Sequential Logic Circuits 79 Combinational logic ci rcuit Sto rage elementsOutput Input Figure 3.22 Sequential logic circuit block diagram. In this section, we discuss digital logic structures that can both process infor- mation (i.e., make decisions) andstore information. That is, these structures base their decisions not only on the input values now present, but also (and this is very important) on what has happened before. These structures are usually called sequential logic circuits . They are distinguishable from combinational logic cir- cuits because, unlike combinational logic circuits, they contain storage elements that allow them to keep track of prior history information. Figure 3.22 shows a block diagram of a sequential logic circuit. Note the storage elements. Note also that the output can be dependent on both the inputs now and the values stored in the storage elements. The values stored in the storage elements reﬂect the history of what has happened before. Sequential logic circuits are used to implement a very important class of mechanisms called ﬁnite state machines . We use ﬁnite state machines in essen- tially all branches of engineering. For example, they are used as controllers of electrical systems, mechanical systems, and aeronautical systems. A traﬃc light controller that sets the traﬃc light to red, yellow, or green depends on the light that is currently on (history information) and input information from sensors such as trip wires on the road, a timer keeping track of how long the current light has been on, and perhaps optical devices that are monitoring traﬃc. We will see in Chapter 4 when we introduce the von Neumann model of a computer that a ﬁnite state machine is at the heart of the computer. It controls the processing of information by the computer. 3.6.1 A Simple Example: The Combination Lock A simple example shows the diﬀerence between combinational logic structures and sequential logic structures. Suppose one wishes to secure a bicycle with a lock, but does not want to carry a key. A common solution is the combination lock. The person memorizes a “combination” and uses it to open the lock. Two common types of locks are shown in Figure 3.23. In Figure 3.23a, the lock consists of a dial, with the numbers from 0 to 30 equally spaced around its circumference. To open the lock, one needs to know the “combination.” One such combination could be: R13-L22-R3. If this were the case, one would open the lock by turning the dial two complete turns to the right (clockwise), and then continuing until the dial points to 13, followed by one\n",
      "{'score': 3.898281283909455e-05, 'start': 1035, 'end': 1068, 'answer': 'the transition arc for each state'}\n",
      "Exercises 119 b.Complete the state machine. (We have provided nine states. You will not need all of them. Use only as many as you need): ★3.62 You are taking three courses, one each in computing (C), engineering (E), and math (M). In each course, you periodically receive assignments. You never receive more than one assignment at a time. You also never receive another assignment in a course if you currently have an assignment in that course that has not been completed. You must procrastinate (i.e., do nothing) unless you have unﬁnished assignments in both computing and engineering. Design a ﬁnite state machine to describe the state of the work you have to do and whether you are working or procrastinating. a.Label each state with the unﬁnished assignments (with letters C,E,M) for when you are in that state. There are far more states provided than you actually need. Use only what you need. b.There are six inputs: c, e, m, c,e,m. c, e, m refer to you receiving an assignment. c,e,mrefer to you completing an assignment. Draw the transition arc for each state/input pair. For example, if you had previously only had an unﬁnished assignment in math and you received an assignment in computing, you would transition from state M to state CM, as shown below.\n",
      "{'score': 3.661367009044625e-05, 'start': 469, 'end': 475, 'answer': 'is the'}\n",
      "Exercises 117 The contents of the memory is shown below to the left. The next state transition table is shown below to the right. Address Content A[2:0] D[1:0] 000 11 001 10 010 01 011 10 100 01 101 00 110 00 111 01Current State Next State S[2:0] D[1:0] D[1:0] D[1:0] D[1:0] 00 01 10 11 000 001 010 110 100 001 100 000 011 110 010 010 100 111 010 011 001 100 100 010 100 110 011 011 111 101 100 010 100 110 110 001 110 100 010 111 000 101 111 101 The output Z0, Z1, Z2 is the current state of the ﬁnite state machine. That is, Z0=S0, Z1=S1, Z2=S2. The cycle time of the ﬁnite state machine is long enough so that during a single cycle, the following happens: The output of the ﬁnite state machine accesses the memory, and the values supplied by the memory are input to the combinational logic, which determines the next state of the machine. a.Complete the following table. Cycles State Data Cycle 0 000 11 Cycle 1 Cycle 2 Cycle 3 b.What will the state of the FSM be just before the end of cycle 100? Why?\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "reader = pipeline(\n",
    "  tokenizer='roberta-large',\n",
    "  model='roberta-large',\n",
    "  task='question-answering',\n",
    "  device='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "question=\"What is a programmable logic array (PLA)?\"\n",
    "for doc in relevant_context_list:\n",
    "  answer = reader(question=question, context=doc.page_content)\n",
    "  print(answer)\n",
    "  print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8513702ffebcddd0565c7cb8940121422c1007cb2eaee71f9f7918f25ee15d0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
