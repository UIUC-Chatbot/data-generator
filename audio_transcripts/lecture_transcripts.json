[
    {
        "ECE120-2016-11-04-LEC-30-slides.mp4": " Okay, so let's go ahead and start. So today we're going to go through an example, and we might get into a second example, but I think not. So we're going to try to go through this example of counting to 10. The code is there for you on the page. You also have this handout I gave you last time. Hopefully you brought it back today on your LC3 reference sheet. I meant to bring some of the extras back, but we have a battle to retreat all afternoon. So it was just upstairs. And didn't have the chance to run over to my office. So let's just go ahead and get started. Then on Monday, we'll start another lengthy example of typing in a number. And then we're going to work towards looking at how we break problems down. And we'll keep working back down to LC3 code. So just do a few examples. This slide again, sorry, I know you're tired of it now, but I'm going to keep showing it until this day. All right. So what I want to do is look at the infrastructure we need with LC3 to be able to do something 10 times. So you know how to do this in C from the S8 or 7 or 8 weeks ago. But to use the LC3 instructions or a bunch of ways we can do it, there are three ways on the sheet I gave you. One, just to show you the different addressing modes. One with PC relative addressing, one with indirect addressing, and one with base plus offset addressing. So just using the different loads and stores to do the same thing. So let's work through the middle one, the second one, which is the indirect addressing using LDI and STI. And then do the others on your own just to practice, make sure you understand things. For some of your labs, notably it's the last two labs in the class, not next week, but the ones after that. They are sort of substantially more programming. And so you will have opportunity to make use of your programming skills. And students have found them relatively heavy in the past. So do try to spend some time on this and make sure you're understanding it. This is also arguably one of the more important parts of the class, right? To learn how to program because then at 220, you'll have an entire semester of programming, right? So I told you on the first day, well, we tried to spread this out for you. So make sure you're getting the most out of it. And there will be a fair bit of coverage, a little bit on midterm three of just looking at LC3 instructions. But then also writing programs on the final. So this is the part of the sheet that we're going to solve. So this is the second piece of three. And this is the code for the indirect address loop. So it's got the PC. We're going to start at 3,000 hex by convention. And I don't know why it put zeros there. Sorry, that's C notation. You probably know LC3 notation. We usually leave off the initial zero. So this is the first part of the code we'll look at. And then the last part of the code we'll look at down here. And then down here we have some data that was placed in memory, some other bits that are non-instructions. And then in the middle here, I've left out something which is whatever that, some section of code we want to do 10 times. So that would be our loop body. So our loop initialization would be up at the top there, our loop test actually ends up being down at the bottom here. Our update is also down at the bottom. But you'll see all of this in detail as we decode these instructions. So I want to use the same data path image I used before for the most part. So I filled in the values, the data values that I told you about in memory. I've got the eight registers over here in the register file. Not much of memory will we use just those two locations. I've got four microarchitectural registers down here. But actually, we're going to ignore these three. So at this point, I think you understand how we go through and do fetch, how we do execution with regard to loads and stores using MAR and DR. But we're going to ignore those this time and just focus on the register file, the memory on the right and the PC down here. So where should I go to get my first instruction? 3000, right? So to answer that question, you just say, well, the next instruction is always in the PC, the address of that instruction. So look down on the PC and say, OK, I should go to 3000. So we'll go to 3000. So look at our code page and 3000 is up there at the top. So here's address 3000. And here, the bits at address 3000. So let's take these bits and figure out what that's supposed to do. So there's the bits. So what kind of instruction is that? LDI, right? So hopefully, how many of you don't have your sheets? Is there someone you can sit with and look? Or if you have your book, it's in the back cover. All right, so LDI. And that has two fields. So the first one is, what is it again? Destination, right? So when we do a load, remember, things are going to come out of memory and go into a register. So this is which register we're going to put it in. What register is that? R3, good. And this is going to be kind of a human-friendly notation I'll write underneath. Turns out later, we're going to call this assembly code. So it'll be sort of like RTL, but this will be what you write after we've put you through enough pain and punishment writing bits. And you get tired of bits. I mean, the computer only understands bits, right? But you really don't want to write too many of those. All right, so there's one other field in LDI, which is the nine bit whose complement offset. And so what is this one in hex? Yeah, so this is the leading bit for the nine. So we'll sign extend to zero, right? So that's zeroes. And this one is 1,001. So nine. And what's the last one? OK, good. All right. So this is the RTL then. So if you look that up on the sheet, remember LDI takes the PC, adds it to this thing, sign extended to 16 bits, which is 0,009F in hex. Ghost to memory reads that value, then ghost to memory a second time, right? OK, so that's the LDI instruction. So let's see how it works. So let's first write that into our sheet. So we've got this instruction really means LDI, R3, X9F, where you could write that in RTL, if you'd rather, either one's fine for now. So then let's go execute it. So we'll go back to our data path picture. And we've got this, I'm sorry, not to the data path yet. We've got this RTL down here. So what is this first memory address? Yeah, so what is PC? So let's see. 3,001. Why is it 3,001? I don't know which one I was going to use for the test. Oh, so OK. So in fetch, it got incremented, right? So when we fetched the instruction, we increment PC. So when we execute it, it's the address of the instruction, which is 3,001. So we've got 3,001 in PC. So go back here. So 3,001, X plus 9F, X gives us this number, at least if I did my math correctly. So we'll go to that address. So we'll go back to the data path. So where's the address? So 3,008,0. And we'll read that address, so there's the first memory read. And what we get out of it really is these bits. But for humans, we're going to call that 4123. So we get 4123 back. And then we're going to read, that'll be the inside memory reference. So that one gives us 4123 hex. So then we're going to go read memory again, this time from 4123. So where's 4123? It's down there. And that gives us 0. So there's our instruction. The second memory reference returns all 0 bits. So we're going to go to R3 and fill that up with 0 bits. So we go to R3 and overwrite whatever bits were there and put 0,00,00. Now of course, it's really 160 bits. But for human convenience, we're going to write that this way to the side. OK. One instruction done. So time for another one. Where do we go? Yeah, we're going to fetch from what address? Good. So we just go down and look at the PC. LC3 doesn't do anything smart. OK, where do I go? PC, that's where. OK, so the next one on our sheet. So let's go look at it and decode these bits now. So we'll copy them here. And what is that? That's an ad. And the first field is destination. And what register is that? R4. OK. And what's the next field? OK, one of our source registers. OK, and what register is that? R3. Good. What's the next field? Yeah, so it's the mode that tells us what the addressing mode for the last operand. So what does this one mean? Immediate, right? So then we have this five bit, whose complement number is an immediate value in the instruction. And that number is 1. OK, so this again is our assembly language, which is nice for humans. So basically all you do with LC3 is you write the human form of each of the fields, and then you get the assembly language form. You can see there are commas in between. So eventually you'll get to write this nice friendly form. But right now you still have to write bits. All right, so R4 gets R3 plus 1. Right? That's what our instruction is supposed to do. So we can go back, write that into our sheet. So we've decoded the instruction. So that's what the second instruction means. Now let's go ahead and execute that on our data path. So we say, well, let's take R3 and 1 to it, right into R4. So go to the data path, look for what's in R3. So R3 is here, so that's 0. And we add 1 to that, and we get 1. So we're going to write 1 into R4. So you get a question kind of, you're just stretching. OK. All right, so we wrote 1 into R4. So now whatever used to be in R4 is gone, hopefully there was nothing important. Same thing for R3. If we started with some important bits there, those are also gone. Now they have 0 and 1. And we're done with another instruction. So we're 2. 3,000, too, right? Whatever is in the PC, that's where we're going to go. Good. All right. So let's take a look. 3,000, 2 is up here. Here are the bits in that memory location. So same exercise, right? Go get those bits and figure out what they mean. So here's the bits. What's that up code? STI. And STI's first field is what? Source register. And what is that one? OK, so that's R4. OK, and what's the next one? The PC, the 9 bit 2's complement offset, right? And what's this number in hex? So 0, 9, d, right? OK. All right, so here's RTL for it. Again, this is a store instead of a load, but it's store, I'm sorry, store and direct, STI. So it uses the same address formation as we did with the LDI. So we're going to go to PC, add this constant sign extended to 16 bits. We're going to go to memory and get an address. Go to memory, get 16 bits, say, well, 16 bits, that's an address. And then we're going to do the store of R4 at that address that we got back from this memory location we calculated by adding 9b to the PC. All right, so let's write that into our sheet, and then we'll go execute it. So let's see. So I guess the first step again is PC plus 9b, right? So what's that address? What's the PC? Yeah, so good. You remember, we have to increment in fact, right? So when this STI executes, the PC will be 3,0003. Because it got incremented from 3,0002, which is the address of the STI during the fetch part of instruction processing. So we'll add that again. So notice that when we add 3,0003 to this constant, this constant is a little bit different. So we still end up with the address 3,000A0. That was of course delivered in the code. So both the LDI and the STI go indirectly through 3,000A0. So here again is 3,000A0. That hasn't changed. Nothing changed those bits. So when we read that, we again get back 4123. So the LC3 then says, OK, well, the first read, return 4123, now in my RTL, I'm going to write to address 4123, write the bits out of R4 into that memory location. So we'll go look at our data path. So R4 has the value 1. So we're going to take that value and copy it over here to memory address 4123. And then we're done with that instruction. Time for another fetch. We're from 3,0003. Good. OK, so where is that? Yeah, it's not there, right? It's a part we left out. OK, so now after the LC3 has done those three instructions, there's going to be some loop body that we didn't write down. We don't know what it does. But we're just going to assume that it does something important that we want to do 10 times. So whatever it is we want to do, we would write into those instructions that I've left out. And then eventually, the LC3 will hopefully get down here to the end. And PC, let's say, is 3,010 in hex. The current value of this is now 0,0001. This one hasn't changed, so I didn't edit it. But we're going to start executing this instruction. So it's going to do some loop body for us, and we'll get to the end of the loop. And now we're going to do our loop management code down here these last two instructions. OK. All right, so I want to make another little table just to keep track of what's going on here. So we just executed the loop body. We just did it the first time. So I'll say, well, that's loop body execution number 1. So what was R4 when that was executing? Go back for a second. What was R4? It's 1, right? OK, so put that in the table. And there's this other thing that I'll fill in later. So R4 was 1 during the first loop body execution. OK, so now here's address 3,010. So we said that after the loop body, eventually the PC is going to get down to 3,010. So this will be the next instruction we look at. So let's go decode it. What kind of instruction is it? It's another ad. Good. And destination register, R4, source register, R4, immediate, or immediate. And what's the number there? OK, so remember if we wanted to gate to its complement, flip all the bits and add 1, or we can also see this would be negative 16, and this would be 6, so negative 10, right? You can do it either way. And you can do it on paper and practice, too, right? It's fine. All right, so negative 10. So in LC3 notation, the pound sign means decimal. So when you're writing in the tools, if you see the pound sign, just means it's a decimal number. Or if you write the pound sign, it will be a decimal number. So what that means is our RTL, take R4, subtract 10 from it, 10 decimal, and put it back in R4. So that's the instruction. So we can go do that in the data path. Well, first let's write our instruction into our sheet. So we've decoded it at R4, R4 number negative 10. So we'll go execute it. So what is R4? Let's look it up. R4 is 1, right? So we'll go back and subtract 10 from that, and we'll get minus 9, which we're going to then write back to R4. So question? No. All right, so we'll write minus 9, which I'll just put in decimal. I'll write the bits into the second. But from our point of view, it's just easier to know. Well, right now that's minus 9. We just put minus 9 into R4. And it's time for another instruction fetch. So where from? PC, always PC. It's getting kind of dull. All right, so go look at address 3,011 Hex. That one is here. So what are those bits? Let's go decode them. What kind of instruction is that? A branch. And what is that first grouping there? It's NZ and P, right? When we have a branch, we have to say, well, under what conditions do we want to change the PC? And so remember, these are the NZ and P bits. So this is saying, well, branch, if the last result was a negative number. So if the last thing we wrote to the register for was negative, we're going to change the PC. And what does this part tell us? The offset. So this part tells us, well, where we're going to change the PC if we want to change it. So there's a 9.2 complement offset. Oh, sorry. Anyway, you could translate that. 1EE, right? So it's a negative number. So in other words, if we just sign extended, that'll be adding FFEE, or it'll be likes subtracting something from the PC, because the carryout will get discarded. So 16 bit adder, the carryout bit will be thrown away. And it'll be effectively likes subtracting something from the PC. We'll do that in a second. Oh. Yeah. So no ops are used for various purposes, sometimes for delay. So if you need to wait for a device, like if you look in the old Linux code, often before interacting with devices that would delay, they're also used for alignment purposes. Some microarchitectures do better if you have instructions aligned to some bigger addressability. I know there's a question. So if you're in the habit of reading through exercises and else in the patent vatel book, there's a question about what instructions do know up. And yes, branch is one of them. If you set these three to zero as a whole points out, then it does nothing. And so you have an instruction that does nothing. Yeah. Yes, effectively. So what's Dan is asking is, well, how can we make that happen? Do we have to specify in binary? Yes, because if you put BR, as I mentioned two days ago, it will give you BRNZP instead. So if you write in an assembly, you can't easily make it the NOAA without just specifying the bits. Yeah. What's the value? Is that a key to the application? That's the same. That's the value of the application. That's right. So this is what we call a conditional branch instruction. So the conditions happen when one of these three bits matches the last thing that was written to the register file. That's what we did, but not when we did that. It would not match in this case. Yeah. Or if it was a zero value. Yeah. So the only time we're going to change the PC is when the last thing, which is the big end here, the one that condition code. And I guess I could have taken this off at that point, but this was the one that was left. So the full condition, which I wrote up a couple days ago, was little n times big n and not times plus little z times big z plus little p times big p. Nathan? Yes, you could do it that way too. Yeah. BR with a zero offset, it doesn't matter whether the branch is taken because that would reduce to PC gets PC. So a good point. Yeah. You can write a no-op in assembly that way also, without writing bits. Good point. OK, so let's see. So let's go do this. So the first we'll write our instruction in. So we found this was branch negative offset 1e and x. So let's go execute that. So what was last written to the register file at this point? Do you remember? Negative nine. Right? Our add wrote a negative nine to the register file. So r4 got negative nine. That's negative. So we're going to take the branch or not. Yes. So let's write that in here. So r4 at this branch instruction was negative nine. So I'm just building up this table. We'll come back to why we're doing it later. But just have this table. So for the first loop body execution, r4 in the loop body was 1. r4 at the branch was negative nine. OK. So the branch is taken. So what's the current value of PC? So the branch, remember, was at 3,011. So remember it'll get an incremented in fetch. So the current value of PC when we execute the branch is 3012 in x. So what happens when I add 3012? Well, I guess I wrote it up really sorry. So if you add 3012 to ffe, you should notice that 1,2 and e when you add those up, you'll get a round number. And so that'll percolate through. You get 3,000 back. So this is effectively negative 12 hex. So we're going to write 3,000 to the PC. So we'll make that change. Then what happens? Start again, instruction fetch time. So PC, I'll say 3 will go to PC. OK. Let's go to 3,000 because that's what it says to do. LC3 just does whatever you tell us to do. So go back up here, but we've seen that code, right? We know that code already. So we don't have to go through and decoder to anything. We know what it's going to do. So let's look at that. So here's the RTL for the first three instructions. So I just copied it from our previous pages. Now the value of the PC for each of those instructions, the instruction didn't move. It's in the same place. So the PC value is always instruction address plus 1. So when we calculated those addresses before and we found 30A0, that's not going to be any different the next time we execute them, or if we execute them a third time, or fourth time, or a hundredth time. So we can simplify our RTL a little bit and just replace these PC plus values with 30A0. So let me do that. So now I've got going to memory of 30A0, memory of 30A0, instead of depending on the PC, it's a little simpler. But let's also assume that the bits at that address didn't change. Now how could they have changed? Yeah, so I mean, but we didn't do that store, right? Could they have changed somewhere? Yeah, the loop body, right? I didn't tell you what the loop body did, right? So we're going to assume that the loop body didn't do this. And I might ask you later, well, what if it did? But we'll assume the loop body didn't change this address. So if we assume it didn't change the address, well, then 30A0 still has 4123 hex. So now I can simplify my RTL further and say, well, when you go to memory of 30A0, you're going to get 4123 back, just like we did before. So let's do that. So now I've got much simpler RTL. It says, OK, R3 gets the value at memory address 4123. And down here, I'll store R4 to it. So now let's go execute these three. So here's our three. So first one, read memory at 4123, write it to R3. Here's memory at 4123. So I'm going to copy that over to R3. Now R3 has a 1 in it. And then, OK, so that's change is done. So that's checked off. Then add 1 to R3, copy it into R4. So here's R3. So add 1 to that, and write it 2 into R4. And then the last step is take R4 and cut, write it back to memory at 4123. So here's our 4. It's a 2, write it over there. Now we have 2 in memory address 4123. So these three instructions together, they go to memory address 4123, add 1 to it, and write it back. Yeah, Eric. I'll just get back to it. Ah, OK. So remember, when we execute a branch, we are going to add the current value of the PC, which was 3012 to the offset sign extended, which was FFE. So if you add 3012 to FFE, you'll find that you get 3,000. Yes. FFE is equivalent to minus 12. Yeah, that's right. OK. Sure. Ah. OK. Mm-hmm. Yeah, you can put pound negative 12. Ah, I'm sorry. Then there'll be negative 18. Sorry. Yeah. Good question. We'll come back to that one. OK. We executed all these, right? OK. OK. Anything else before we go on? OK. All right. OK. So let's see. So we get down here. We finished. We'll soon we're finished our loop body a second time now. So we get down to 3,010 hex with our PC. So let's go fill in our table. So we have the second loop body execution. What was our 4? 2, right? So we'll fill that in now. And then I want to go back and do the bottom part, the subtracting 10 from our 4, and then checking that to see how big it is and maybe doing a branch again. So these were the two instructions at the end. Subtract 10 from our 4 right back to itself, and then do the branch. So the PC on the right, again, only depends on the instruction address. So we can just replace that also here. That again is going to be 3,012 hex. So when we add it, it's always going to be 3,000. This branch instruction is never going to go somewhere else. So we can just replace that to 3,000. And so now let's go execute these two instructions. So we've got our 4 gets our 4 minus 10. So our 4 is 2. So when we subtract 10, what do we get? Negative 8. So we'll go right negative 8. So that's the first step. So let's fill in the table. So now we're at the branch. So our 4 you said it was negative 8. Let's put that in there. And it's negative. So there's branch then what's going to happen? It's going to change the PC. Good. And it's changed the PC to 3,000. So that's the second execution of our loop. And we just branched up back to here again. So let's go back and look at that table now. So we've gone through the loop two times. So if you look here, our 4, every time the loop body executes, our 4 is the number of times we've executed the loop body. So the first time it was 1, second time it was 2, third time it'll probably be 3. So when does r4 at the branch get to 0? When this one is 10, which means what about the loop body execution? It's also 10. So why did I ask you when this one gets to 0? Yeah, so when it's 0, it's not negative. So when it's 0, this branch will not be taken. In other words, after the 10th time we've done the loop body, we get to the branch. We don't take the branch. We keep going. OK. So in other words, after the 10th loop body, it's not taken. The PC remains set to 3, 0, 1, 2. So guess what the LC3 does? It does a fetch. Good. Good. We're going to stop. OK. That's what the LC3 would do. So if not, you tell it to halt, it would keep going. Keep executing. All right. So there's some questions for you. So one of them, Muhammad Ass, we'll get there. All right. So why is there a 0 stored at 4123? What if I just put some bits there? Wouldn't that be just as good? I mean, what 0's, 1's, they're all the same, right? They're all bits. Yeah. So what would happen if I just put some other bits there? Almost. Not quite random. So what would change about what I wanted? Yeah. Or fewer than 10 times, right? Yeah. So basically, this is what we used to decide effectively, whether we would keep going through a loop or not. It's like saying, well, I want to count to 10. Negative 4,000. We just negative 399. You're not going to let me go, right? You're going to tell me to stop and let you understand. I mean, if I don't start in the right place, if I don't start at 1 when I count to 10, takes me a heck of a lot longer. And I don't count 10 times, right? So if I don't put that 0 there, whatever I put there, it's going to start that count, or iteration, in our table, I'm back here for a second. This 1 was the original value of 4123 plus 1. So if you would put negative 3,000 there, then instead of 1, you'd have negative 2999. And then this question I asked you, well, when do you get to 0? Well, that would still be 10, but then the relationship between this column and that column would have changed. So you would execute the loop many, many more times. So another question for you. So more specific. What if I put 5 at 4123 before I ran my code? How many times would it execute? 5, right? Because instead of counting starting from 1, where it's counting, it's starting at 6. So 5 on. All right, what about if I started negative 5? Then 15. What about 25? So this one's tricky. So can it ever execute less than once the way we wrote this code? It can't, right? It never checks before it executes. So it's got to execute at least once. So it gets down to the bottom. And you've taken 25 and added 1 to a, you get 26, you subtract 10, you get 16. Is that negative? So you're done. So how many times? 1. All right. All right. More questions. So what if we leave that one, I guess I kind of asked you already, right? OK. Yeah. All right. That's a compiler decision. And it's actually, you can write C code that does it either way. But we didn't teach you both variants because you don't need so much C. Yeah. OK. So what happens if we change the value at 30A0 to say 3141? Because I like this number because it's sort of part of pi, right? 3141. So that'll be a better program, right? What'll happen? Yeah. I'm trying to prove it. Yeah. I'll address a different memory if it's load and store and direct. What's at that memory? Bits. So it'll run some random number of times, and then it'll stop, right? We have no idea how many times because we don't know what's there. We didn't say anything about what's there except we'll yet some bits. So what happens if the loop body sets R4 to 0? I think this is what you asked me. So you can answer. So your loop body, somehow someone else writes that. And in the middle of the loop body, they set R4 to 0. So what's going to happen? Yeah. So you take, I mean, at the end, R4 has 0. You subtract 10 from 0. You get minus 10. And that's negative, right? Yeah. So it'll go forever. So just keep going and going and going. What's in 4123 doesn't matter anymore. It'll keep getting incremented. But in the middle of the loop body, we set it to 0. And so you subtract 10 from 0. No matter how many times you do it, you still get negative 10, right? OK. Yeah, that's an unfortunate thing since I wrote it, isn't it? It unfortunately sets them all to 0. And I sort of regretted that in retrospect. I should have set them to random bits, but that might have been more confusing to people. Yeah. So the simulator, this is the question. What is memory set to in the simulator initially? And it's all 0s. Real operating systems do that also for security reasons, right? So if you run a program, and then I can come look at your program, and your program has your password stored, then it's a bad thing. And so an operating system, typically, before it runs your program, will 0 all the memory it gives you. So it's not unrealistic. It's just that it does then sometimes confuse people when they're just learning that they see memory always start to zeroes, which isn't necessarily true. OK. All right. So there's a reference copy to code, data down here. And that's it for that one. Yeah, that's OK. Yeah, I mean, that's sure. There are insecure OSs, yes. So yeah. Yeah. So deallocation is not sufficient, right? So I mean, you would have to zero things. I mean, it goes, there's a step further, right? Which is when you take your hard drive, and you want to get rid of it, it's actually possible, even if you reform at your drive. It's possible unless you spend a fair bit of time writing random bits on it and deleting them and writing them again, that someone who really cares can come in and read the bits you have that. So there are lots of security issues like that. But most modern operating systems will, before they give you memory, they will set it all to zeroes. So yeah. Yeah. So in the LC3ISA, the real use that's the most useful thing I've found with those is that there's some IO registers up in high memory, and they're always in the same places. And so rather than putting the, they're not reachable as PC relative numbers. So they tend to be addresses like FE00. And so you need to either put them in a register and do an LDR, or you can do an LDI directly. If you have the number close to you, you can do an LDI. So it has that value. In terms of practical value, as a real ISA or something, they're not quite right. And then the real ISA is that have things like that are a little bit different. And the little bit of difference makes them much more useful from an idea of generating code from high level languages like C. So they're a little bit strange in that sense. And if you know other assemblies, you might think, well, why did they do it this way? The primary reason, as I mentioned, while I introduced them was that the authors of the textbook wanted to emphasize that if I go to memory and I get 16 bits, that can be a memory address, which is an important lesson because you can. So they wanted to make sure that everyone realizes 16 bits, it can be a memory address, it can be a two-s complement number, it can be an unsigned number, it can be anything you want. And it's up to you, the programmer, to say, well, how should the computer interpret those bits? Did you have a question, Nathan? Here. So after your FCI, why would you get that process for? That added question for, what was the question for? What's the question for? You mean, we did it 10 times, but we did it one time, and then we checked. So this is basically equivalent to the four loop. So we're initializing, and then we've initialized by hands down here. So the initialization is not actually present in our code. The initialization would be to say, write a 0 here. And then we could leave it as bits, but have our code do that writing. Up here, what we're doing is the increment. So we've actually done the increment of our variable, and then we're executing the loop body, and then we're checking, sorry, the loop body, and then we're checking whether we've gotten to 10. So these are pieces of the four loop, if you will. But I mean, I think that's something that a lot of the detectives might be. That's not the FCI. Oh, no, no, no. There's some other code that I have admitted here. So there's that does whatever we want to do 10 times. It doesn't matter. I thought that it's going to be 10 times or 10 more times. Oh, no, no, no, no. Oh, sorry. Yeah. Now the loop body is any code that we want to execute 10 times. So it doesn't matter what code we write there. And it's just this is how we would create a loop to do something 10 times. Yeah. So what do we do? Yeah, yeah. It's the loop part, the loop body I left out. It could be anything. It's the instruction. So let's see how many did I. So that would be 16 minus 3. So there are 13 instructions that can do anything. But you have to be careful not to write R4. And you have to be careful not to write to 30A0 or 4123. So you can do any loop body you want, basically. As long as you can fit it in 13 instructions. Yeah. Yeah. Thanks. Yes. So in assembly, you can specify any of the operands can be written in decimal or in hex or as labels, which we haven't introduced. But we'll talk about that one when we do assembly. Yeah. Mom, I. Can you refer to the PC with decimal values? That part not quite. Yeah, that part not quite. So like, well, maybe you can. Now I take it back, you can. So the only time you would use that would be, the only time explicitly, when you specify where your program starts, if you want, you can say 12, 288 decimal. So I'm not sure what the value add is, I guess. So you can use decimal numbers more or less throughout your program if you want to. The tools you're going to use first will be binary. And you have to write everything in bits. Actually, there is a version you can write in hex too. But I wouldn't suggest doing that. It would write all in bits. Yeah. So if you wanted, if you wanted, for example, to terminate your loop, you could set R4 to a value that would force it to stop at the end. Yeah. So that's true. It does not necessarily obog if you're writing that code. That's a complicated answer. I guess I would never write that code that way. But some companies have insisted that all of their employees write code that way. So it's hard to say no, but I wouldn't advise it. Yeah. Go back to the first state. Yeah, you can make loops within loops. I mean, if you wanted this one to execute again, you would have to reset 4123 to 0 if you wanted to execute 10 times. But that was what I was saying. I left off that initialization from this loop. I did it by hand. Yes, you could do that. OK. Yeah, bro. Sorry. I mean, there are only five or six. And they're all on page 543. You won't need any more for class, the codes, and the LC3OS, too, if you want to look at it. Yeah. Are you referring to this platform? Yeah. Yeah, you don't have to do this through memory. Part of what I wanted to illustrate with these examples was the use of the load and store instructions. So yes, you could simply use another register. In fact, you don't even need to use R5. You could simply keep it in R4. And you could write the difference to R5. So it's not to change R4 when you do the calculation of whether you've gotten to 10. Yeah. So there are many ways to do this kind of loop structure. And that was also part of what I wanted to illustrate is you have many options when you're writing LC3 code to do the same sort of thing. And any of them is fine. OK. Yeah. Yeah. So OK. So that's a tricky question. Is there a better way to write the loads? So if you mean, couldn't we have an ISA that didn't have so many PC relative instructions? That would make your life much easier. As you'll see in our next example, we're going to end up spending a fair bit of time doing counting, because you have to count. How many instructions do I need? Like this one. I didn't make you count this time. But basically, in order to figure out what this offset should be, I could subtract. I could say, OK, well, PC will be 3012. And I want to go to 3,000, so I need negative 12. I can subtract. But I'll make you count in class. And the problem is, if you change the size of this loop body, then you change the offsets. Any offsets that cross code you've changed, you're going to have to recalculate them. And we put them back in bits again, which is a giant pain. And so by the time we get done with a couple of examples, you'll be ready to have an assembler that will do that for you. And the assembler will make that easier, so substantially easier. Meaning you don't have to do it anymore. A computer will do it for you. As to whether it's better to have load and store instructions that are PC relative or absolute, their advantages to both. I mean, if your load and store instructions are PC relative, that means I can take that code and I can put it anywhere in my memory and it'll keep working. Whereas if I have absolute addresses in my instructions, that's not true. I have to rewrite my code to be able to put it in a different set of memory locations. That makes sense. So if I had, for example, branch to 3,000 here, and if 3,000 were encoded as an immediate value in my instruction, as is the case in some instructions at architectures, then in order to take these same instructions and do the same kind of thing elsewhere, I would have to change that branch instruction to make it work. But the way it's written here in LC3, that's not the case. I can take exactly these same instructions, put them, shift them to another location, and they'll still work. Yeah, maybe. Honestly, the best thing to do is to make the computer work for you, which is an important lesson in our class. So as you're writing, it's a little bit of a pain. It's the binary part. And we want to ask you to write that much in terms of binary code, probably like 20 instructions or so. And the reason is it just gets painful. But sanity check yourself by taking your code, pushing it through the tool, and looking it in the simulator, it will tell you the address. And you can say, oh, I got it wrong, or I got it right. So you can double check it. If you don't double checking, you just expect it to work and run it, then good luck. But I would use that to check it myself, rather than trying to just stare at it. That's what's easier. So when you use the LC3 tools, you are doing cross architecture compilation. So what we're all is asking about is, well, when we compile, when we use the LC3 tools, we're running on an X86 machine. We're not actually running on LC3. So the code that we're using to assemble code or to change bits in a file as ASCII 0s and 1s into actual encoded instructions for a simulator, or for a real LC3 processor if you build one, that's not actually running on an LC3. So that's called cross compilation or cross generation of code. That's pretty common for microcontrollers in small ISAs. But if you get an 8 or 16-bit microcontroller, you're not going to compile code for it on that controller. You'll compile it on your desktop, your laptop, your phone, and then download the code as bits to that micro processor. So there's not anything particularly mysterious about it, just that the code in the back end, the tools, generate instructions for a different machine for a different ISA. And then you put those bits in a file and ship them to the machine that should be executing. How do you write the... How do you write exactly like that? I can't hear the first one. Yeah, the compiler actually only generates assembly and then you have an assembly. So... No, it doesn't go through a translation process. Yeah, let's take this one offline because... All right, any other questions on the example? Or... Okay, so maybe we're not going to get far into the typing in number example. So I'll put that one up online if you want to look in advance. The code is actually already there on the web page. So have a good weekend. Thank you for coming. Sure. Find a path to that question. No, it's fine. So... You You You You You You You You You You You"
    },
    {
        "ECE120-2016-09-14-LEC-10-slides.mp4": " end of the class. OK, so let me go ahead and start. So today we're going to cover a little bit again the use of the heuristics, because I know it was a little confusing with the complemented literal. So I'll clarify that and then also show you circuits implementing the three functions, which I think will help make it a little easier to do the counting. It's really pretty easy to use the heuristics, but I think maybe the first few times you do it, it's easier to look at the circuits. So I'll just put those up. Then we're going to spend some time on Boolean terminology, and that will help us understand the question that someone asked, how did I get from the big long construction of F to the shorter construction? But I'll do that algebraically, which is really not very fun. So that'll be the first step. And then I'll show you car nomads, which are a graphical tool that'll make it a lot easier. So that's probably where we'll get to today. I don't know if we'll finish car nomads, but maybe two-level logic, most likely Friday, Professor Varadain will give that lecture. Remember, none of this material this week's on the midterm. So midterm material ended last week. So just so you know what's on the midterm. Another reminder, next Tuesday, you had to have signed up already for the conflict. So hopefully if you need the conflict, you already did that. The coverage, same as before. One thing I do want to point out, so I know some of you will go and look at the Wiki and read the notes. That are connected to the lectures there. There's unmarked content. So there's extra content there, but it's not marked. So in the notes you can get from the store or online for free, all the extra stuff is marked with stars. And there's a summary section 1.6 that says you exactly what you're supposed to know. In those notes, they're not marked. So use section 1.6 to help you, if you need. So basically, you said, maybe it's just a note all that we have in the code. So I think after two years ago, we moved it to, so two years ago, we taught hamming codes now. And that's what I was joking about a little bit, two weeks ago when I said they took a lecture out, but we moved it to the back. 10, 15. OK, so maybe they waited another semester to move it then. I wasn't teaching that semester. I'm not quite sure when they moved it. I thought they were supposed to move it in full. Actually, spring 15. But yeah, question back. Yeah, so the rules for what you get to bring to the midterm, I think, are posted. They should be posted on the midterm page. But are they not there? OK. Well, let's go take a look. Let's see, how about this one? Go to Wiki. Go, probably under syllabus, right? Good to be here. OK. Well, this is where I would look for it. All right, let me ask them to post rules. Because we haven't actually talked about that. We have, when I've been teaching the class, generally, there has been one single page handwritten notes both sides. And I presume they kept that policy. But let me check, because we want to have the policy be consistent in the classroom semester to semester. And I'll ask them to put that up on the Wiki. Oh, OK. Sorry, I forgot to tell PowerPoint. I wanted you to see the Wiki. There's nothing there. So at least I didn't spot anything where I would have looked for it as well. So let me ask them this afternoon. I don't know. It doesn't want me to go forward. OK. All right. So let's go back a step just to review the area here is to quickly. So the idea was you count literals, whether or not they're complemented, doesn't matter. And the idea was to get an estimate of transistor count. And then for the delay heuristic, I just want to be clear this time. So for now, just ignore complemented literals. Don't count them as delays. That'll be easier. And in a few weeks, you'll understand. Sometimes you might want to actually count them, but for now, just ignore them. Make it easier. So here is our first function drawn out as a circuit. So you have the three end gates and the or gate there at the end. And then you can see I've labeled them all. And there's two compliments going in. So I put in burders, but just ignore those in our counts. So to count area, first we'll count literals. So the number of literals is just the number of inputs to the end gates. So you can just count them up and see there are nine. And then actually, the number of operators here is also quite easy when you draw it this way. It's basically just the number of gates. So how many gates are there? Four, right? Good. So that's the number of operators, three ends in an or. So that's what we get. What about delay? So now remember, the delay is the longest path, again, not counting the inverters, from the left side over to the right side. So all the paths go through two, right? So the gate delay is two gate delays to any path on this one. Good. Well, that was impressive. I can't even click that fast. Maybe I've been practicing with my handheld computer. All right, there we go. So this is the second expression. So this one takes a couple of end gates in an or gate. And if I ask you to count literals, what do you get? Four, right? Good. What about operators? Three. Good. OK. And what about gate delays? Two also, right? All paths. All right. And then this was the third form. So here you've got just two gates. How many literals? Three, right? And I guess I gave the answer to the gates. So I'll just click through that. What about gate delays? Yeah. So remember, it's the longest path it matters, right? So there might be different length paths. The one that matters is the longest one, because you're going to have to wait for all of the different paths to finish changing. So in here, there's a couple of paths of two and one path of one. So we look at the two. OK. So I tweak to this slide a little bit. So now they all have the same gate delays. Otherwise, everything's the same. So ignore the input and burgers. All the designs are the same for delay. So just try to simplify that. All right. So now I want to spend a little time just going through and introducing some terminology that we'll use to help us understand how to optimize grueling expressions and then also how the K-MAP actually works to allow us to just do a graphical approach. So one thing is a literal, which I've already used. So hopefully you remember, it just means a variable or its complement. And so maybe we've got three variables, maybe we have 10. A literal is just any of those variables or its complement. Assum uses our notation, our plus and place of OR. This means a bunch of things OR together. So it doesn't matter what those things are, anything we want OR together. So the final operation is an OR. A product, similarly, we use multiplication to represent AND. So a product is just a bunch of things ANDed together. So again, it doesn't matter what they are. A bunch of things, last function is an AND. So a min term, hopefully you'll remember this idea from the logical completeness construction. We constructed a function with 1.1 in the truth table. And I said, well, that expression of the product of all of the literals, one, I'm sorry, each variable, or its complement appears once, exactly once. We call that a min term. It produces exactly 1.1 in the truth table. So that's a min term. There's a corresponding idea called a max term. So max term produces exactly 1.0 in the truth table. So instead of a product, it's a sum. And then each of the variables or its complement appears exactly once. So for example, if you had inputs A and B, you could have A plus B prime, or A prime plus B, or A plus B. If you have three variables, all of the variables have to appear exactly once. So you could have these examples down here. And if you think about what this looks like in a truth table, and you go right down a truth table for any of these with the appropriate number of variables, you'll see there's exactly 1.0. So those are max terms. Some of products form, we call this SOP usually, and it has a specific meaning. So it's not just a sum of products. It's a sum of products of literals. So it's an OR of a bunch of AND terms of literals. So down here are some examples. So the function of F we had before, A, B plus B, C, that is an SOP form. This is also an SOP form. Each of the things in the sum is simply a product of literals. This one down here is not, because it's a sum. But then if you look at this one, it's not a product of literals. It's a product of A, which is a literal, and also this thing. This is not a literal. So this bottom one is not an SOP form. And then there's the opposite, which is POS, product of sum form. Again, the little catch there is, remember, it has to be of literals. So it's just a product of sums of literals. So here are a few examples. Here you've got A plus B, that's a sum, multiplied by another sum. So it's a product of those two sums. Each of those sums is just literals. Same thing down here. Each sum is just literals. This is a sum of one. So it's OK to have a sum of one literal in a POS form. Similarly, if I think I, yeah, if we go back here, this is a product of one literal. So that's OK too. But this kind of thing is not OK. This is a product. The last function is D times this thing here. And this is a sum, but this thing here is not a literal. The BC is not a literal. So the last one there is not a POS form. The reason I want to spend some time on SOP and POS is really the thing we'll use to optimize our expressions will be K-MAPs and the things that are, the forms that are produced by using a K-MAP are going to be SOP and POS. So these, these are the forms you're going to use most of the time in the class. OK, there's also something called a canonical SOP form. And of course, canonical POS on the next slide, or I guess I put it right there. Which is a sum of min terms. So it's not just a sum of products of literals, but it's a sum of products of min terms, or some of min terms, where every variable appears exactly once. So this is the form we get out of the logical completeness construction, the thing we did yesterday to come up with after originally. Do you know what canonical means? No, it's a math term. It means unique. So the value of canonical forms, so often you'll see them different areas of mathematics. You'll see canonical forms. The point is, if I have things that I can write in lots of different ways, like the expression F, right? You saw three different ways. If you think about it, you'll realize, well, I can construct an infinite number of ways. I can always add extra terms that don't change the expression, and I can add an infinite number of those. So there are an infinite number of ways to write it. Wouldn't it be nice if there were some way that we could write it down? I could write it down. You could write it down. We could put them side by side. And if we just glance at them, see that they're exactly the same. So canonical form is a unique form that allows us to do that sort of thing. Now, honestly, with Boolean expressions for 10 variables or something, you might have 400, 500 different min terms or max terms. So they're too big. In even inside computers, there are things called binary decision diagrams, which outside the scope of our class, but computers don't use canonical forms internally either. They're just too big. They're too bulky. And people try to find more efficient ways to represent the functions and yet be able to compare them easily. But it's a useful idea to have an approach that's unique, no way to write it in a way that's guaranteed to be unique. We do have to pick an ordering on the variables. So if you change your ordering on the variables, then you move your terms around. It's not exactly the same. So those are canonical forms. You won't use them very much. What does a a a arrow be mean? This from math? A implies b. So A implies b. So if A is true, b is also true. That's what implies me. So what if A is false? Is the implication true or false? So my mathematician friends tell me, if A is false, A implies b is always true. So that's just the definition of implication. So the only time you care about b is when A is true. If A is false, the implication is true. So that's the mathematical definition. And that's how we'll use it, as you'll see in a second. But it also means that these kind of funny statements are true. So don't score above 125%. So if the premise is false for all of the x, then the implications are true. So that's the definition of mathematical implication. So I just wanted to make sure that if you didn't know that, now you know it. And otherwise, if you knew it, now you remember it. Way we're going to use it is on functions. So I'm going to say a function g is an implicated of another function f on the same set of input variables. If and only if g implies f. In other words, every output of 1 in g's truth table has to also have an output of 1 in f's truth table for the same input combination. Now, if g has a 0, f doesn't matter. It's only when g has a 1, f also has to have a 1. So that's what I mean by the g implies f. And we'll do a couple examples in a second. But this is a notion of implications. Now, in digital design, we actually only talk about products of literals as implicants. So there are lots of possible functions. You remember maybe two to the two to the n and input variables. That's a lot. We're only going to look at products of literals. So it'd be far fewer functions. But the implicants we care about are just products of literals. So any time I say implicant, you should assume I mean product of literals. So how do we simplify functions? So here's an idea. So as a first step, we can say, well, if I can find an implicant of g, then maybe I can take out one of the literals. And if I still have an implicant of g, my function will have fewer literals, but it'll still be correct. It'll still be the same function. So here's our original form of f that we got out of the logical completeness construction. And you can see that this term here by itself is an implicant. So if I say, well, if this equals 1 is f1, so if a b prime c is equal to 1, then f is also 1, right? Because the way we get f is we order that value together with some other values. And if you order 1 together with some other values, we get 1, right? So good. So this is an implicant. Can I cross out any literals and still have an implicant? Maybe not so easy to see, right? OK, so let's do a truth table. Here's a truth table. We've got a, b, and c, all eight combinations on the left. We have f in this column. And we have the a, b prime c with each of the literals removed. And the functions are written out in these three columns. So take a look and tell me, is b prime c an implicant of f or not? Why not? Yeah, there's that one there in b prime c. And if you look over an f, it's a zero, right? So b prime c does not imply f. So that we can't do. We can't cross out the a. What about a c? It is, right? It has two ones. So here's one one. And you look over an f, and there's a one. Here's another one. There's one also. So b, sorry, a c is, in fact, an implicant. So b prime c is not, a c is an implicant of f. What about a b prime? Also not? Why? There's this one here, huh? OK. Good. So because there's a one somewhere in the truth table of a b prime, and there's not a one in f, it's also not an implicant. So in this case, we did find that we can cross out the b prime. So we can cross out the b prime, and we're left with a c. And so we can rewrite f as a c plus a b c prime plus a b c. That's a little better, right? We've got rid of one literal. And then you can go do the same thing. I won't force you to look at all the truth's tables. But if you look at the second one, you'll find you can cross out the c prime. And if you look at the third one, you'll find you can cross out b. Or you can cross out c. You can't cross out both. But let's say we pick b, then we'll get this function down here. a c plus a b plus a c. So well, the two a c's are the same. So let me just cross one of those out. And that gets me to what we had before, a b plus a c or a c plus a b. So if you then ask the same question, you go write all the truth's tables. And you say, well, can I cross any of those literals out? The answer will be no. So for a c, you can't cross out either. For a b, you can't cross out either literal. So let me give you one more definition, which is if I have an implicant g of f, and I can't cross out any of the literals, I'm going to call that a prime implicant. And it means I can't cross out any literals, and still have an implicant. So in this case, a c and a b are prime implicants of f. So that's pretty easy, right? Just as a lot of algebra. So you just write your function as the sum of prime implicants. It's SOP form. One do one of those? Yeah, so that's not really that pleasant, right? You don't want to have to write a whole bunch of truth tables and go poking around, trying to see if one thing is an implicant of another. So instead, what we're going to do is actually develop a graphical tool that will make our lives much, much easier. So all you have to do is look at a bunch of squares and draw circles around them. And that will help you identify those prime implicants without ever having to write down a truth table. So it's actually one that was designed almost 70 years ago. So Carnot maps. So we have this approach that we just looked at. But it wasn't very fun. At least I didn't think it was very fun. Anyone here think it was fun? You can still do it that way. You like it? OK. You can do it algebraically. Everyone else would do this, I think. So it's not so easy to make mistakes, too. So let's try a different approach. Let's start with functions of one variable. And let me ask you, so how many implicants are possible? I mean, if I just have a function of one variable, how many different implicants might I have for that function? Remember, there's only four functions, right? And we only want products of literals. So someone name and implicant? A, good answer. Hey, that's the one I chose first, too. What else? Not A, good. What else? One. There it is. OK. One is the product of zero literals, so we count it. We've got three. OK, that's not so bad. If you think about a function on one variable, we can represent the domain of that function as an n-dimensional hypercube. So in this case, it's a one-dimensional hypercube. And each of the vertices in the hypercube will correspond to one combination of the inputs. And so I'll draw this for you in a second. But the function f will have one value for each vertex, right? So if you take your truth table, you write it out, n-variables input, you've got two to the n-ros. Your hypercube has two to the n-vertices. There's a one-to-one correspondence between your vertices and your hypercube and the outputs of f, right? The rows and the truth table. So here's a one-dimensional hypercube, a line segment, with two vertices. So we can split it in half and say, OK, on the left, we'll have a equals zero. On the right, we'll have a equals one. And the three implicants then correspond to the two vertices and the edge. So on the right side, we've got the a-implicant corresponding to that vertex. On the left side, we have the a-prime-implicant, and then the edge corresponds to the implicant one. So there's a one-to-one connection between the features of the hypercube, very simple hypercube right now, but the features of the hypercube and the implicants that are possible on that one variable. So if we write the values of f, next to the vertices, we can see which implicants of these three possible implicants are covered with ones. So which implicants actually imply or function f? So instead of drawing the hypercube, we'll draw two boxes. So you can think of those boxes as representing the vertices of the hypercube. And the left box will be a equals zero. The right box will be a equals one. And each of those boxes corresponds to a vertex of the hypercube, but they also correspond to a minterm. Remember, a minterm is what gives you one one in the truth table. And each of these boxes is a vertex or an input combination. And so when you write f into those boxes, they correspond to minterms. So what do we do with that? So then we can mark implicants. So we can say, well, let me take a one, and I'm going to draw a loop around it. And that means that implicant is an implicant of f. Because here, this implicant corresponds to a, but the function f has a one there. So a actually implies f. So it is an implicant of f. But it's not prime. So to know whether it's prime or not, I want to think about making that loop bigger. In other words, can I grow it outwards so that it holds more ones inside? So the answer is yes. And if the answer is no, that means it's prime. So you'll see this a few times. But we can grow this one to contain the other one that's next to it. So let me grow that. But once we have the loop that covers both of these, now it's the whole K-map. So it has to be prime. We can't make it any bigger. We can't circle any more of the boxes inside of our loop, because there are no more boxes to circle. So this is a prime implicant of f. And in this case, we can just say, oh, OK. So now f is one. That's the function that we wrote into our K-map. So we might think, well, that's a function on one variable. I actually know all those functions. The K-map thing maybe is not so helpful. So I don't know. Maybe you'll feel excited. All right, let's look at two variables. So if we do two variables, how many implicants? How many minterms? Four, right? Rose of the truth table. So let's put those down. So we've got AB prime, 8 prime b, and 8 prime b prime. Those are the four minterms. What about on one variable? One literal. How many? So there's A, A and A prime, B and B prime. So four more. And then, of course, we've got one. So it seems we have nine. If you think about the hypercube, so first let's split it up. So we'll split A again horizontally. So A equals 0, B on the left again, equals 1, will be on the right. We'll split B vertically, B equals 0, will be on the top, equals 1, will be on the bottom. And then we've got four vertices, four edges and a face. So those are going to correspond to our nine implicants. So let me draw those for you. So the upper left equals 0, B equals 0, will that corresponds to A prime b prime. Then there's AB prime, A prime b, and AB down on the lower right. So those are the implicants, I'm sorry, the minterms, those correspond to the vertices. The implicants with a single variable correspond to the edges. So there's A prime, there's A, there's B prime, there's B. So those four correspond to circling two of our vertices or correspond to an edge, if you'd rather think of it that way. And then there's one face, which corresponds to the implicant 1. So if you've got all of the vertices filled with ones, then you have the implicant 1. So of course, we're going to draw this as boxes again. So in our Carnot map, we have four boxes now. Each of the boxes, again, corresponds to a minterm, one input combination and corresponds to a vertex of a hypercube. So it's a one-to-one mapping between the hypercube and these boxes. A question? Yeah. Yeah. That's a for me. Yes. I'd like to. Beyond, you can use K-MAPs easily up to four variables. So it's not going to go that far. With a little moderate pain up to about six variables. I mean, I've done them, I think, on six variables, before myself in certain cases. Beyond that, you really want to fall back on algebra. So if you want to use the algebraic approach, it's the same math underlying it. So hopefully, once you understand this, you could go off and do the algebra. There's a theorem called Kwein-McClusky, but really 462 is the place to learn much more about it. Yeah. So this is just some function that we're trying to represent. So whatever the function is, remember that each of the boxes corresponds to one input combination. So often what we'll do is just if you can fill it from an expression, you can do that way. Otherwise, you can take a truth table and simply say, well, for a equals 0, b equals 0, here's the output value of my function. For a equals 1, b equals 0. Here's the value for my function and so forth and fill it in. Yeah. There is not. No. Yeah. So 0 is not considered to be an implicant. Yeah. Yeah. It's, I mean, the function 0 should automatically be an implicant, right? Mathematically. But as I said, in digital design, we only consider products of literals to be implicants. And so you can't multiply any literals. Even zero literals is considered to be one. Good question, though. Because mathematically, the answer should be yes, but not for us. All right. So it comes a little more interesting now. What we want to do is find the biggest loop. So why do we want the biggest loops? Well, remember, if the loop can't grow, that means it's a prime implicant. So we want to make our loops as big as we can make them, right? So make the loops as big as we can. They have to have power of two edge lengths. Now here, it's either 1 or 2. When we get to more variables, we'll see that there are certain sizes we can't have. The reason has to be 1 or 2, one corresponds to vertex or a vertical, if you think horizontally, a vertical slice, which would be an edge going vertically. And two would correspond to a bigger feature of the hypercube. And together, those loops have to cover all the ones. So we want to take those different prime implicants, or them together, and get our function. So if we get loops that cover all the ones, then that will allow us to get our function back in a fairly simple form. So this is our strategy. So let's try it out. So we're going to start by picking a loop and circling it. So let's just pick this one up here. So as soon as we circle it, we know, well, that min term, because we circle the 1, is an implicant of g. Is it a prime implicant? Not. Why? Yeah, so I can grow this loop. If I look down, I say, well, I can't include this 0. So I can't grow downward. But if I look to the right, I can make the loop bigger by growing it out to the right. So let me do that. So it's not a prime implicant because we can grow it. So let's grow it. So that loop now represents b prime. So one thing you'll want to be able to do is learn to read these loops off. So I've annotated the K-MAP in the most helpful way, but in some of our notes and other homework problems and stuff, we may not draw these extra markings for a. We may just give you the numbers. But here, you can see this one down here is b. So the implication is this one is the b prime implicant. The b prime is also an implicant of our function. Of our function g. Is it a prime implicant? OK, so remember, if we're going to grow it, we have to grow the whole thing. There's only one direction left. So if we grew it downwards, that would include the 0. We're not allowed to include a 0. So in this case, we can't grow this loop anymore. You can never cover a 0. Because then the function you would get out of that loop would not be g. It would have more ones. All right, so the answer is no, we can't grow it, Eric. I had to start with all. I had to start somewhere. I will tell you how to choose later. But for now, you just got to start somewhere. I'll come back to that later. Because sometimes it matters. But here it doesn't matter much. Well, we'll do that one next. OK, we've got this one left. So we have to cover that one. Otherwise, our function from this loop will not have this particular one. All this implicant will generate are these two ones. So we need a second loop. So let's circle that bottom one now. So that's the midterm AB, which is also an implicant of g. But is it a prime implicant? Why not? Grow it up. We can't go left, but we can grow up. OK, so let's grow up. What we have now is the implicant A in that second loop. And that one is a prime implicant of g because we can't grow it to the left. So we now have two loops, each of which is a prime implicant. And so we can write down those two together with an or in between them and get g out. So these two loops cover all of the ones. So we can write g equals b prime plus A. Are you excited? OK, you're not excited. So we'll have to keep going. We're going to go to 10 variables now. All right, so guess what's next? Three variables. So how many implicants? Yeah, here's some big numbers. But yeah, that's right, lots. OK, so let's do it a different way. So I said that there's a one-to-one mapping between these implicants and features of the hypercube, right? 3D hypercube is a cube. Let's count features. So here's the cube. Let me split it up. Same way for A. Same way for b. C, the bigger square is going to be the outside. It's going to be c equals 0. And then the inner square is going to be c equals 1. So there's our square. So now let's count. So how many vertices? Eight? Yeah. Eight corners of the cube. How many edges? Well, good. How many faces? How many cubes? So it adds up to 27, right? OK, so now I think some of you subbed already. I know. But I had to figure it out. So you notice a pattern? When we had one, we got three implicants. When we had two, we had nine implicants. When we had three, we had 27 implicants. Sounds like 3 to the n. Why should it be 3 to the n? If you think about, well, what are we calling an implicant? It's a product of literals, right? So if I'm going to say, hey, there's a product of literals, I can then ask, well, what about the variable A? What are my choices for A? Yeah, so A, A complement, or not there? Three choices, right? So three choices. Include it, include the complement, don't include it at all. So for every variable, we have three choices. If we have n variables, three times three times three, n three is multiplied together. It gives us three to the n. So if you have n variables, you have three to the n literals, and three to the n features of your hypercube. So that's why, once you get to four, it's actually a pretty complicated problem. Even three variables, it's sometimes difficult to look at an expression and just say, I know how to simplify that one. If you spend a lot of time practicing bullying algebra, maybe you can do it, but probably a little easier to use the K map. But how are we going to map this cube thing into squares? So let's see. So look at the top half up here, and let's try to put that in some order. Let me do that by just drawing lines straight down, and I'm going to write the values of A and C down here on the bottom. So the upper left one is 0, 0. The next one going to the right and ignoring the vertical dimension is this one. A is 0 still C is 1. So A C is 0, 1 there. How about this one here? 1, 1. And how about this last one? 1, 0. Good. OK, so we have this order down here. This is called a gray code order. A gray code means 1 bit flips at a time. It actually wraps around. So you can see if you look here, 1, 0, and then around on the other side, 0, 0, 1 bit has changed at every step. So those connections represent the edges of the hypercube. So each adjacent A, C pair shares an edge, and then the last edge wraps around in this horizontal mapping. So there's four edges. The top face is all four of them. So if you then use that to map into boxes, what you get is this gray code. And your loops can be 1 box wide. That means they're vertex. It could be 2 boxes wide. That means they're an edge. Or they could be 4 boxes wide. That means it's a whole face. It can't be 3 boxes wide. 3 boxes do not correspond to any feature of the hypercube. So when you look at your K-map and you've got two variables in one dimension, first of all, you're going to use gray code order. So here's a picture. So you can see on the top, we've got the variables A, A's on the right, C's, and not A's on the left. And then C is inside as 1, and outside is 0. But you can see there's gray code order across the top for A and C. And if you think about what these mean, any adjacent boxes will map into an edge of the hypercube, including adjacency of wrapping around. And then if you pick all four, that's a face of the hypercube. So let's find a way to solve this particular H. So again, we're going to start by circling a 1. So we'll solve this K-map by doing the same processes we did before. So there's our first 1. So that's the min term, A prime, B prime, C. So is that a prime implicant? So with three variables, there are three ways we can grow. So you've got to look in all three directions. Here to the left, there's a 0. You can't go that way. Here to the right, there's a 0. You can't go that way. Here below it, there's a 0. You can't go that way. So we can't grow it. So this one is prime. But we've got more ones. So let's pick another one. Let's say I pick this one here. So that one is A prime B prime. I'm sorry, A prime B C prime. So you can read the variables off, just like you do in the truth table. So A is the left one in those two. So A prime B is a 1, and C is 0, so C prime. So is that one prime? Why not? Yeah, so remember it wraps around. So I can grow to the left here, wrap around. So let's grow that. So now wraps around. So that new loop is the Implicant B C prime. It's an edge of our hypercube. So is that one prime? Yes. But can't I pull this one in? Yeah, that would be 3Y, right? And 3 is not allowed. That does not correspond to an Implicant. So you can do it in a, if you get confused, you might circle 3, but then when you try to figure out, well, what's the Implicant? There's no answer. There's no Implicant for that. OK. So this one's prime. So that one will leave alone now. But we still have one more one. We'll get a circle it. That one's A, B, C. Is that prime? Why? Grow it to the right. Let's grow it. We go. So that's A, B. Is that prime? OK. So I think we've got all the ones covered. So that's a prime Implicant. So the ones are all covered. So then our function is just the sum of those three loops. So we had the first one we wrote was A prime B prime. I'm sorry, yeah, A prime B prime. I copied that wrong. Didn't I? No, no, no, I got it right. It's B prime C. Yeah. OK. Yeah, this one is A. So it's A prime. B is 0. So it's B prime and C is 1. So it's C. That was right. This one that spanned around, that wrapped around, was B C prime. And then the one we just circled was A B. So together, those three give us our function H. And now hopefully you're excited. Because that was probably a lot easier than playing with the algebra. OK. So let's go on to four variables. It's a little hard to draw the hypercube. Not impossible, but probably not worth the time. The K-maps are not so bad. Basically, we do the two variables in each of the two dimensions now. And we'll use gray code order in both dimensions. So we'll have, again, no three box loops. So in both dimensions, you can circle one. You can circle two. You can circle four, but you can't circle three. So in both dimensions, any of those combinations is fine. Your goal is to come up with a minimal number of loops of maximal size. So if you succeed, it turns out, oh, in that cover all ones. You have to cover all the ones. And of course, your loops can't cover zeros, as you know. If you do, that result will be optimal amongst SOP expressions by our area heuristic. So the same area heuristic that we said, we're going to use this to measure the area of your circuit. This will give you the best answer for that heuristic. Now, POS expression might be better. K-maps don't really help you spot X-ores. So you might be able to use X-ores and come up with an even more efficient circuit. But this will give you a pretty good answer. So this kind of comes back to your question, Eric. So sometimes you'll go through this process, and you might find, well, after I've filled all the loops in, I've got a loop that I don't really need. It's actually everything inside of it is covered by other loops already. You can get rid of that loop. As you get more experience with this stuff, you'll actually start to look around for the loops that you know you're going to have to have. And the way you do that is when you pick a one to start a new loop, if you've got choices, if you have something actually like the, I don't want to go all the way back there. But if we had started with the corner, in the example, maybe what I'll do is draw it on the board. So if we start here in the corner, that means we could grow in either direction, but we can't grow in both. And so I have to make a choice. So choices are bad. Pick the ones where you don't have any choice first. If you pick the ones where you don't have any choice, those you're going to have to include. So as long as you start by doing those, you'll find yourself less often in the end, having to go back and take away some of your loops. All right. So the final thing I wanted to say there is sometimes there's more than one optimal form. So don't worry too much if your answer is different. Because for some functions, there's more than one right answer in terms of optimal SOP forms or optimal POS forms. So here's a four variable KMAP. I'm not going to solve this one now, but let's see what's time. Yeah, let's go play with one in the tool. So I will switch over. And tell my laptop to let you see what I'm doing. Get out of the wiki. So down here, there's this Carnomaps tool. And so we want to be excited. So let's do four variables, solving KMAPs. So here's a random KMAP that it just came up with. So help me out. What should I circle? Yeah, let's start with the top left. That's a good idea. So if I start with the top left, then which way should I grow that? Grow that to the right. So you can grow it once to the right. Can I grow it again? OK, so let me erase this one, and I'll put the whole one there. Can I grow it up or down? No, that one's prime now. So then let me go find another one to cover. How about this one here? I'll do that one next. Which way? Some people sit down. Some people sit up. OK, so down would be here. OK, so let me grow that up. Is that fully grown now, or can I make it bigger? OK, good. And maybe you want me to just do that square there next? OK, now we can do that. OK, so this one, I can grow in two directions that way or that way, and I can actually do it both at the same time. So let me pull that one. What about this one here? To the left, OK, so I'll pick that. How about this one? Yeah, I can go right. I can actually go down also, right? Yeah, so either one of those will be OK. So let me pick the less obvious one. Maybe what I'll do is pick both of them for you. So I can go down, and I can say check answer. Oh, it doesn't like me to pick that one. Hmm. What did I do? Oh, yeah, I can make a square. A good point. There we go. Yeah, that's much better looking. That has one fewer literal, right? Because every time you grow it, you're getting rid of a literal. It's the same thing you're doing algebraically, except it's a heck of a lot easier, at least do this for me. I assume it will be for you, too. OK, so there's a good answer. How do you read this? So there's a good question. So for each of these loops, you would then need to read off the literal, right? So let's take this last one that we did. So because it's all outside the B equals one region, that means there's a B prime in it. So these two rows are B equals one, and the other two rows are B equals zero. So since it's spanning those two rows, we have B prime, H varies, because H is equal to 1 here and 0 up there. So H does not appear in this particular loop. M also does not appear, because it's 0 here and 1 here. And D is equal to 0. D is 1 on that side and 0 on this side. So this is D prime B prime. And if you want practice reading literals, there's actually a couple ways to do it, but you can go back to KMAP Implicance and say you want to identify literals. So here, it's just pulled up an example. So DG prime N. So where is that? So every time you have a literal, it's going to cut the size in half. So the literal one would be all 16 boxes. If you had one variable that would be 8 boxes, two will be four boxes, three will be two boxes. So that's the first step is just to realize, OK, this is two boxes somewhere. It's inside of D. So down here on the bottom, it's inside of G, so on the right. And it's, oh, I'm sorry, G prime. So DG prime and then N prime. So N is here, so N prime is these two. So let me go mark those. And if you get it right, it'll say green. And if you get it wrong, say I say, oh, I like this one. It'll say no, you're wrong. So it'll say green or black, depending on where you get it right or wrong. So you can practice your, practice your implicants with this tool. There's a bunch of different ones you can do expressing too. So with this one, what you have to do is check whether these implicants appear are circled over here. So there's always something extra. So then you just say yes or no if it appears or not. So you can practice your mapping from the KMAP to the algebraic form. And then if you really want to do the whole thing, you can also, you know, necessarily need to use this tool yet. But if you go to here, this tool is actually doing combinational logic design. So it allows you to copy, although it has x's in it, which we haven't talked about, that'll be next week. It allows you to copy the truth table into the KMAP. But because the tool's exercise is logic design, you can also just go over here and say no, do that for me. And then it allows you to solve the KMAP. Again, it's a logic tool. So you can say no, I know how to do that, do that for me. And I'll just solve it for you. And then the next thing is you should write down the expression. And so you can figure out what you think the expression is and then tell it, OK, what should the expression be? And it'll tell you. So if you want to double check, you can do it as in the other tool. I showed you earlier where your answering is this implicant there or not. Or you can do it this way, you know, write down your answer and then have the tool automatically generate the answer so you get the same answer. So a bunch of tools you can use to help you learn how to solve KMAP's. Thanks. I'll see you Monday for a review session. How were it then? The Verdan teaching, I'm Friday."
    },
    {
        "ECE120-2016-08-22-LEC-01-slides.mp4": " Okay, so maybe don't call me that. We have three other sections. You're welcome to go out to any and all, except the fire marshal doesn't like the room to be overcrowded and have people all over the aisles. So the big room, there are two lectures. 1013 is a smaller room, but you know, if you want to, if you miss a lecture, we have a video recorded, so you can watch them online. I encourage you to come that way you can interact and ask questions and do things like that. So please don't just only watch the lectures online, but we will record them for you if you want to review or something. If you're James Scholar, take a look at Wickey and then talk to Professor Varadayan and he will help you set up a Scholar program in this class, which will be fun. So I want to start by just telling you a little bit about what is this class? What are we trying to do and why? So you may have heard this pitch from Bill Sanders because I know he's been going around and giving this pitch. So, but what we wanted to do when we redid this class, a few years ago, was really try to give a systems perspective to our students. So we wanted to get people to understand that, as an engineer, you're going to need to solve problems and the tools that you're disposal as an ECMager are hardware, software, some math, theory, things like that. But you really want to take the right tool for each problem. So you can learn to do software and then you can try to solve all problems with software and it's during complete, which I'll explain in a minute. Which means you can solve all problems. It's just not necessarily the right way to do it. You can do the same thing with hardware. You can solve all problems, just not necessarily the right way to do it. So the question is, how do we get people to do it the right way? How do we get our engineers to go out and be successful and be the people that get the right solutions to whatever problem they're trying to solve? You've been unsolved problems and enable you to go down that path. As you probably know, our department has a huge history of success in that regard. What you may not know is that we've got alumni and fields all over the place. So you'll have an opportunity every year to see alumni award winners. And I think we're giving them videotape again. So I think you might be able to go back and look at the archives. But people like to founder one of the co-founders of C-SPAN, for example, which you might not think, well, ECMager would go found a television network or documentary political television. But in fact, they did the Mars Lander program. That's something more. Yeah, probably somebody in EC is in charge of that. Let's see what else. Patent lawyer. So antenna patents and things like that, antenna designers. So many, many different fields. You can do whatever you want with an ECU degree. I was going to bring it up later. But maybe I'll bring it up now. We've got College of Medicine, based on quantitative science, coming together here in a couple of years. So if you're interested in medicine, but you really want to be more quantitative, you're in a ECU program. That's one path you might want to consider. You will need to get a little bit of chemistry, biology, experience to apply to a medical program, obviously. But that'll be opening up here. So I wanted to encourage people to consider that. There's also a program with the business school. So if you're interested, you'll find out about it soon enough. But if you ask me, I can explain it to you. I've come to office hours or something. So that was kind of what we wanted to be able to teach people. Some of the other things that we need to give you as your introductory class is just an introduction to kind of the EC culture and the goals of the department. So I mentioned some of the goals. But the EC culture, this is the hardest department in the campus we like to say. And your students will tell us that. And we're proud of it, right? You're going to work hard. And hopefully you'll love it. And if you don't love it, then. But you don't necessarily know what you don't necessarily know what you want to do when you sign up. So a lot of engineering schools make you choose going in. So many of you know, hey, I really absolutely want to do EC. Some people are saying, well, I have to pick something. It sounded kind of cool. Some people may be, I'm not sure, but we'll check it out. It doesn't matter. If you like it, great. I love it, obviously. So I would like to share my love with you and have you love it, too. But it's OK. If you don't, I mean, there are lots of other good things to do in life. But the culture is work hard and be successful. And we'd like to see our students go out and be enabled to change the world, right? So we're hoping that you can go out and change the world. I have many alumni before you. So we will train you to do anything. And you can then go out and choose. And you'll be able to choose between going and changing the world. Or if you want a more relaxed life, you can pretty easily take a job with 40 hours a week or whatever. And that will be fine. But it's up to you. You'll have those choices. All right. So expectation of engineers. Engineers are in an often in positions where what you do will matter in a lot of ways that you might not initially think about. So when I first created this class with Doug Jones, one of the examples he gave, I really liked, it's kind of an ethical question. So when you design software, for example, your software will live on and people will use it and grab it. And so you have to think about how they're going to use it. Turn out that there was a piece of software that controlled a medical device and X-ray machine. And so the software, the medical doctor would enter, well, how much radiation do you want to use for this dose? Because they would have to vary it. So they type in a number and they'd press go. Well, turn out the person who wrote the software didn't put any air checking. So if they mistyped something, it just translate whatever they type as an ASCII code and turn that into a number and irradiate the patient. Well, turned out that you could type lethal doses in and then the patient would get a lethal dose of radiation. So it turned out someone died. So as an engineer, you kind of have to think, well, am I working on problems that one day may actually be a safety critical, right? Where you may have to think about is there human life at risk? Is someone going to get hurt as a result? So there's a lot of ethical issues as an engineer. And we want you to understand you should be thinking about them. You should be thinking about what is the impact of what I'm doing, whether it's hardware or software, whatever. And in medical device technology, for example, when we talk to people in medical device companies are actually in the people that build the processors of their use, they say, well, our processors are not designed for medical devices. We don't think they're reliable enough. But the people who want to build medical devices, well, they need processors. So they say, well, we're just going to use yours. So what happens if something goes wrong with the process if it has a hardware fault? Whose fault is that? I mean, whose problem is that the system crashes, and something goes wrong, and someone gets hurt? So as an engineer, there's a lot of things you need to consider. And you're all smart. So otherwise, you wouldn't be here. So you can handle those sort of things. But there are things that you want to be conscious of, that you're in a position of responsibility. You're also in a position where you can help society. So you can help your community and help people understand what the issues are emerging technology with life. So lifelong learning. So we can't teach you what you're going to use in 10 years, probably not even half of what you're going to use in five years. Things change all the time. So all we can teach you is how to learn about things, how things are designed, and maybe instead of learning about the next thing in five years, you'll be the one that designs it. That's probably where we'd like you to be. But you need to be able to learn for the rest of your life as an engineer. So that's really what we want you to take away. So there'll be concrete tools in our class, for example, in many of the classes that you will pick up. And those will be relevant today. But those will probably not be the same tools you use in five years or 10 years. So you need to be able to understand how and why those were built the way they were built and the engineering trade-offs. Again, in engineering, some kind of moving to the next bullet, in engineering, they're always trade-offs. There's no meaning in most cases of, whoa, what is good? There's usually four or five meanings. So I'll give you examples of that in a few weeks, in particular for hardware design. But as an engineer, you need to understand trade-offs. And of course, we're quantitative people where engineers. So you want to be able to quantize them, but then also understand when you have more than one metric, more than one way to say what is good and measure what is good, I need to side between them. So as an engineer, that'll be constantly the problem is knowing, well, how do I measure goodness in the first place? Measureing goodness and then saying, well, is four better or six better if good is bigger? That's not hard. But figuring out, well, how do I measure it in the first place? How do I get the four of the six for different design choices? Or if you've got more than one metric, how do you choose between them? One is better with one metric, and another one is better with the second metric, or the third metric. So that's another issue. Look around. It's an international group. So you look around the room. You've got people from all over the world. This is a university where we draw students from everywhere. And that's a big advantage. All of the engineering companies these days are global. So you're working in a company. You're going to have people on your team spread around the world. You have an opportunity here to learn different cultures. If you're an international student, of course, you've come to the US. You've got an opportunity to learn US culture. You also want to make sure you learn enough English that you can get as much as possible out of the program. Yeah, I know. Well, all right. But if your domestic student take the opportunity also to learn about other cultures by just meeting people in the room, right? You have a big opportunity in that sense here. Let me make one other comment about the English. I've been in many different foreign countries. And it's always really intimidating when you're language and another language you feel is not good enough. So I was teaching in Vietnam actually three or weeks now, last three weeks. And my Vietnamese is awful. I mean, I don't know if anyone Vietnamese is in the room. It's embarrassing even to try it. But even to go somewhere and say, hey, I want to try that food. I can be embarrassing. And you feel kind of lonely and you feel like if there are other people that speak your language, hey, I'd like to just hang out with them and be able to relax when I'm not in class. Be careful. Be careful that you don't take advantage of the opportunity to improve your English so that you're getting again as much as you can out of your classes. If you're in a position where you're not able to follow your lectures or not able to do as well on the exams because your English is a stumbling walk, it's your loss. So you really want to make sure that you're not in that position. So I want to encourage people not to do it. There's an international program in engineering that brings people together and gives you free food. What can be wrong with that? So I'll try to tell you about the opportunities. And I'd like everyone to show up. They don't actually have capacity for everyone in a class. But we'll try to over-capacity them. And I think you'll have fun with it. And I think it'll help you in terms of leveraging the international community here. All right, academic reality. I told you ECE was hard. So it turns out half of the people in the room are under average. Yeah, and you're probably thinking of Lameda. Oh, sorry, I'm thinking. So you get into grad school. And it turns out half of grad students are under average. And you know, you'll be a faculty one day. Professor someone turns out half of professors are under average. It really sucks if you get to that level. You're like, oh, man. So you really have to remember what pool you're in. You're all ECE students. Well, some people transferring in. But I think you'll all be ECE students. So you're in a pretty prestigious pool, already. I've had advisees that had B minus average or something and went on to get their dream job. And I see students that they get one B in a class or they're headed towards a B and they come in like, Professor, should I stay in ECE? I don't know if I fit in. And the answer is absolutely. If you like what you're doing, absolutely. So I read pretty widely. I've been reading. I read this book that Stephen Pinker. He's a developmental neurologist, neurobiologist. But he was talking about how people kind of build their egos around what they're good at. So a lot of you are probably the math and science go to a person at your high school. You feel like, hey, that's what I'm really good at. And look around here. I mean, one of you in this room will be the best of a class. Everyone else will not be. So your ego should not depend on this. I guarantee you that in a couple of years, when you go out to do internships, you will be the best. When you look at people from other schools, you're like, wow, I really learned a lot. Let me help you with that. And in a general environment, when you're not amongst all the ECE students, you will be the best. OK? So don't let that feeling of like, hey, maybe I should transfer to that other department. And then I could stand out as the best again, just like in high school. You don't worry about it. You will be. So we worry about that. I mean, we worry about that a lot, because we don't want you to leave the department thinking you won't be able to succeed when we know you will be able to. So what we decided in this class is to make grades a little easier. In fact, well, they wouldn't take me seriously. When we started the class, I told my colleagues, look, let's just give them all A's. Everyone, don't just give them A's. I mean, that's what MIT does. Freshman class is pass fail. They just say, you all pass. You're good. But we'll actually tell you the real grade. My colleagues were like, are you insane? So that didn't work. But eventually, we agreed that we'll give an easier grading scale. So this class is honestly an easier grading scale than most of the easy classes to help sort of nudge you in the right direction to not have this psychological shock. OK? So that said, that's the reason for it. And you don't have the perspective yet. I said in two years, when you go out and do internships, you'll meet people from other schools, and you'll realize how much you know. But until you get that perspective, I can say whatever I want. And then the feeling versus the words are a little hard to match up. So that's why. So enough philosophizing. Let's talk a little bit about the content. So we're going to build computer systems from the ground up. We're going to start with bits and gates and build upwards through their abstraction layers. And eventually, by the end of the semester, you'll know how to build a computer, how to design a computer from bits and gates. Why do we study computers first? If you talk to your friends in Arrow Astro, I don't even know this term. I just picked it out as some advanced design. Do they start with a high-pass turbofan engine? Is that what they say? I'm a freshman in Arrow. I'm going to look at the high-pass turbofan engine. No. That's probably something in a senior class or something. They're going to do dynamics in physics and lift. They're going to talk about air foils or something like that. So why don't we build up to computer slowly? Why in this class are we going to start and build right into computers immediately? So in 1936, I'll enter a paper about universal computation devices. So take the space of all possible things you might want to do. Things you might want to solve problems. And so some of them are computable. So I do that in green there. So some of them, you can answer questions. And then in that are the computers that can solve those kind of problems. So blue waters, the biggest and most powerful scientific super computer in the United States, a little bit south of here on the campus versus IPAC, same power, same ability to solve problems. It's just memory and time. That's the difference. Blue waters has a big chunk of memory, petabytes. But IPAD don't think they have petabytes. Maybe there's a new option or something. So it's just memory and time. But otherwise, they can solve the same problems. Android phones, same thing. LC3, the computer, little computer 3, the ISA will study in this class. The computer will study in this class. They're all the same. So if there's a problem you can solve with one, you can solve it with any of them. So that's one reason that we're going to look at computers first is that things are either computers or there's not, or they're not computers. There aren't different types of computers. They're all the same in that sense. So we're going to look at a very somewhat simple design for a computer, but it can still solve all the same problems. And that'll be the LC3. There are undecidable problems. Proudly won't talk about it much in class. There's some detail in the first section of the notes. So if you want to know, well, what is an undecidable problem? Actually, Alan Turing gave us an example in 1936 called the halting problem. So you can see something outside of this box. And none of these computers can solve the halting problem. So those are undecidable problems. The church-turing hypothesis is worth mentioning. So one of the other things that Alan's of church and Alan Turing both hypothesized was that this green thing here is the same as what humans can compute. So in other words, if you or I could solve a problem by sitting there and trying to work it out systematically, a computer can solve it too and vice versa. So that's the hypothesis. It's never been proven or disproven, and it probably won't be, because how can you prove what a human can or can't do? But most people in computing and technology believe this to be true. That computers and humans can do the same things. Now, there's a lot of stuff we don't know how to do systematically. So the things that our brains do with neurons, things even like vision, we don't know how to do systematically. So why do captures work? Why is it that when you make someone look at text that's been fuzzified a little bit? Why does that keep a robot from being able to break into your website? Well, it's because we don't know how to solve that problem. Our brains do it very easily. So we don't know how to do it systematically. So we can't teach our computers what you're dumb. Computers are not smart. We can't teach them how to solve that problem. So until someone figures it out, captures are effective. OK. So I promise I won't do this too very often, but I'm going to read your quote. It even came out sort of big enough fun. But it's in the notes that you can grab online if you want. You don't really need to know it or anything. The apparatus they, animals, use for timing their movements, has more in common with an electronic computer, although it's strictly different in fundamental operation. The basic unit of biological computers, the nerve cell, or neuron, is really nothing like a transistor in its internal workings. Transistors are what we're going to use to build our computers. Certainly the code in which neurons communicate with each other seems to be a little bit like the pulse codes of digital computers. But the individual neuron is a much more sophisticated data processing unit than the transistor. Instead of just three connections to other components, a single neuron may have tens of thousands. The neuron is slower than the transistor, but it's gone much farther in the direction of miniaturization. The trend which is dominating the electronics industry over the past two decades. It was in 1976, by the way. So we started about starting in 1956. This is brought home by the fact that there are some 10,000 million neurons in a human brain. You could pack only a few hundred transistors into a skull. So that was in 1976. So miniaturization from 1956 to 1976, Moore's law continued in the intervening 40 years. So in 1997, when the Pentium was released, there were 4.5 million transistors on it. Today there are chips you can go out and buy it, best buy, with 4.3 billion transistors on a chip with 541 millimeter squared and very, very thin. So if you do the math, you can see that you can pack a heck of a lot more transistors into a skull than you can neurons. So they're much, much smaller. There's still only three terminals. So complexity arguments. Yeah, we'll see. But certainly transistors and computers have gotten much, much more powerful. And there's interest and some promise and trying to see if we can get these digital systems to do what human brains do. So that was Richard Dawkins in his selfish gene book. All right, so what's happened in ECE in the last couple of decades is that we've seen really a digital convergence. So most people, even our EE graduates, have gone on and they end up being computer people. Using computers in their daily life, I mean, you use computers in your daily life, I'm sure. Most of the solutions across our fields are digital. There's not much room left for analog engineering. I mean, it's kind of fun and it's hard. But there's not that many jobs out there and there's not that much research going on in a lot of fields with analog, most things are digital. Digital system design thus provides you with a critical set of tools and a critical set of skills that all of our graduates need. And so we want to make sure that all of you have these skills, which is why we require that everyone take these classes. And you'll go a lot further and faster with these tools in your toolbox than with outcome. So that's why, I mean, sometimes, you know, this is in some sense the lead into computer engineering program, but at the same time, all of our EEs are in here, right? And so sometimes our EEs wonder why us? Well, because honestly, most of the, in most of the subfields of electrical engineering these days, these will also be critical skills for you. Oops. All right, so why do we do bottom up? So we really want you to have a firm understanding. We've seen far too many programs where people go from the top down and they're kind of waving their hands and not really understanding what's going on underneath. And so we feel like, you know, this is, it's important to have you understand what's going on underneath before you talk about what we build on top of it. You'll see that we'll build upwards through layers of abstraction in the class. Because then, especially when you're trying to build something, when something goes wrong, you have a model of what's going on underneath, and you can understand and reason about the system as a whole instead of guesswork, instead of making guesses. So we don't want you making guesses about how to do things. We want you to be able to reason about it based on your understanding of the systems underneath. And so that's one reason. If you're designing at different levels, then it's critical that you understand the layers on what you're building, okay? Because you need to be able to understand, well, if there's a problem at one of the layers, is it easier to push it into a layer underneath you to hand it up to a layer above you. So these kind of decisions, if you're working in a subarea in one of the layers of abstraction that'll show you for digital systems, interacting with your adjacent layers, you really need to understand those to a certain degree. So we're building upwards so you have an understanding of all of them in your first class. And of course, our students have been successful with this approach. So, okay, so where do you find information? Well, we start with a wiki. So in one way is, you know, you can bookmark this or whatever, type it in one time. Unfortunately, can Google EC120 wiki and it won't come up with, it won't work. So instead, you can Google my name. So if you can remember how to spell my name, then you can Google it. So just as a demonstration. Let's take this one. I claim if you type Steve Limev into Google, that I will be first. There we go. And then you can go down here to F16 under classes and go there and then there's linked to the wiki at the top along with some other stuff I put there for you. So I want to show you the other stuff now, although actually down at the bottom is lecture slides. So if you want to see this stuff on your own, and so there's a link to the class wiki. If you haven't used a wiki before, you know, it's basically just a hierarchical web page. There is a menu driven system on the left. The only thing I kind of don't like about it myself is that if you click something like syllabus, then you'll get a page with interesting information on it. And then down at the bottom it'll save child pages. So if you want to see those child pages, you can expand the menu on the left. So I find, I don't know, I don't like that interface much, but that's the way it works. So this is the first place you should look at this wiki if you're looking for information about the class. And you should read it every day. We'll post announcements there. So do try to look at it every day. I'm gonna go back to this slide. Yeah, so take a look every day. So what you'll find there is announcements for the class, due dates for homeworks assignments. You can pick up your assignments there. We'll post solutions for homeworks. Those will be there too. Course information, timing, office hours, staff members names, email addresses, so forth, and so on. It's also a place for exchanging information. So you can add questions and comments on assignments and then get answers there, which is the right way to do it. Because if you have a question, chances are really good. Lots of people have that question. So don't feel shy about just putting your question there and then seeing what's the answer. You can try to help people. If you feel you know the answer, that's fine. Don't post answers, please. That sounds weird. Don't post solutions. So if you know the answer, the correct solution to a homework problem, don't post it on the wiki, please. And for one thing, you'll end up getting mad at you, but they will also have to delete it. It'll ruin all the fun for everyone else. But any non-personal question you should put here. So unless it's something like, hey, I want to talk about my grade. Those kind of questions you can use, email, anything else you should put on the wiki. Because again, anything that isn't personal to you is probably something other people are going to want to know the answer to as well. And so we'd like to have that answer be public. So please use that for those reasons. What to read and what not to read? Here's our textbook. It's the second edition of Patent Patel. Sanjay Patel is another one of our faculty members. He helped Patent as his advisor. He's still at Michigan. I'm sorry, not at Michigan. He's still at Texas, University of Texas, Austin. So this introduction to computing system, it's a good book. It doesn't go quite as much into digital design as we had wanted for this section. This two class sequence, 122.20. So there's also about 150 pages of notes that I wrote for you. So that's on the page. It's on the wiki. But the notes will help you read the book, read the notes. But suggested first, you try to read them before and after class. The wiki will tell you the relevant sections. Students have told us sometimes they need to read things more than once. And actually, an alumni, quite a famous alumni, came in. And his comment to the students was, when I was in school, it's sit down, I would read it once. Then I would read it again. And then because I knew I didn't really understand it, I'd read it a third time. So don't feel too bad if it takes a little while to sink in. I mean, try to put lots of examples. I think this is a great book. So hopefully it doesn't take so long. But if it does, it really don't worry about it. You can go on and be successful and happy. And this was, again, one of our famous alumni winning the Senior Alumni Award. So if you read it a couple of times, it's OK. But if you come, if you read it, then you'll come prepared to have questions. And I would like this to be a dynamic environment. So take a look at also the notes. Have summary sections that tell you the learning objectives. So if you want to know, well, what am I supposed to learn? It'll be summarized for you in those sections. I've never taught this class with PowerPoint. I always use the chalkboard. I'm going to try to switch over to PowerPoint. Just give you more resources. But so the two things about that. One is I have to do a better job of rate controlling myself, which with chalk is a little bit easier, although I'm told I'm one of the fastest writers in the unit apartment. But feel free to ask questions. So if you have questions, just raise your hand or for some reason I'm looking the wrong way, then just say hello and ask your question. It's a small enough class that I think don't worry too much about interrupting. I will repeat your question because since we're videotaping, I want to make sure they get on the recording. We have some online tools in JavaScript. So use those to practice your skills for the first and second parts of the class, class that divided into four sections by midterms and then the final at the end. So there's some tools you can use to practice your skills. They'll make up random problems for you. They'll give you instant feedback on your answers. So it should be helpful. There are JavaScript-based. You can run them on your desktop or your mobile. Unfortunately, I don't own an Apple product. So I can't debug them. And I know they're not so nice user interface-wise on Apple. So I apologize to you, Apple users. But when my students at Apple send me one, then I'll be able to debug. Watch out for the web. I do expect you to be able to go out and Google things. But on the flip side, I know there's a lot of bad information out there. So be careful about just trying to look up and learning from random stuff on the web because often the people writing it or shouldn't be writing it. They wouldn't be allowed to write it here. So I've seen a lot of confusing things when I was looking for resources for this class. And I wouldn't point you there, but you can also find them. So just be a little careful because the web is not filtered. Which I think you know, but sometimes it's worth being conscious of. All right. So let's spend some time talking about what are we going to do in the class and how are we going to grade you and stuff like that. So what's the workload? Every week, you will have a lab. So software and hardware. Some will be programming, some will be building hardware. You build a little finite state machine that interacts with the real world at some point with sensors and actuators. You will write some programs. So labs will vary from week to week in terms of what they are. And so how you turn them in will also vary. They usually do Wednesdays at five, but look at the assignment because it will not always be the case every week. The first one is do next Wednesday. So not two days from now. But next Wednesday, 31st of August. They're weekly homework assignments. So those are paper and computer based. The paper stuff you'll turn in at a box near a 3070 in this building, which is the student lounge, the undergrad lounge. And those are due Fridays at four. First one is next Friday. So you have a little time there. But you'll have those every week. And then of course, we'll have some exams. So we try to make more of these just so people don't feel so pressured by them. So we have four exams. So it kind of breaks the class up into four pieces. And we'll have evening exams. The philosophy is we don't want you to be time pressured. So these are designed to be 45 minute exams. And then we'll give you an hour and a half to do them. So hopefully by the end of the hour and a half, most people are gone. If you're still there, don't worry about it. We don't always get it right. I've gotten it really badly wrong sometimes and had almost all of my students there at the end. And I felt bad. But yes, I see people smile. So it's funny because if we give an exam, I used to target 75 average. We're targeting a little higher now because we're moving on to definitely absolute scale, as I'll mention a minute. But other schools, people target 50 because it gives you the most information. And I know most of you probably got 90, 95, 98, who most of your life, and you come into college and you get a 50. Oh, man. And if no one tells you, oh, the average was 50. And you're in this great class of really good students, then you might not realize, well, that's a pretty good score. So it's really kind of psychologically challenging and traumatic sometimes. So we're targeting higher averages with these. But we do screw up sometimes. So if we screw up, we will account for that. So we'll give you an absolute scale. But if we mess up stuff in the averages lower than it should have been, we can push it grades up. But we won't push them down. So if you're on the absolute scale, then I'll show you in a few minutes, and you get an A or a B or whatever, then you'll definitely get that grade. And if we've messed up and given two hard exams, we'll fix it. Don't worry. All right. So three midterms, one final. Those are the times and dates or on the week two. So if you have a conflict, let us know early. There are some rules that the university provides for figuring out if you have a conflict. But let us know. The final's rules actually depend on class sizes. So in some cases, you won't know, right? Because maybe not everyone comes to class or they're sort of seem similar when you look around the room. In which case, go to Laurie Fisher. And she'll know because she can look at everything. She's up in the advising office. So if you can't figure it out, just ask her. And do it soon enough that you know which classes are going to offer you a conflict. Some classes, I mean, I think we'll do this, but some classes will let you take a conflict if you need one. So if you need a conflict, sometimes the rules will say, well, that class has to do it for you. And if that class is offering a conflict, or is not a, well, sorry, let me make this clear. If you have two classes that conflict, then one of those classes definitely has to offer you a conflict, right? So you're protected from people saying, I don't want to be bothered, right? So you definitely deserve a conflict. Now, which class that depends on the rules? Sometimes it's actually bold to have to offer you a conflict. But classes that don't have to offer any one of conflict by the rules for finals might say, well, we don't want to create a conflict exam. You have to take the one that offers you one, right? Other times, the bigger classes tend to say, well, if we're going to make the conflict exam available, then anyone who has a conflict can choose ours, even if technically they were supposed to choose the other one, OK? So this, I think, will become clearer over the next few years. But the main point is, let us know early, OK? Because we do have to arrange to find a time with you that you can take the exam. So let us know early. There's a default time, but all of the classes, a lot of big classes, we'll try to have default times. If the default time also doesn't work for you, it is the class's responsibility to find a time that does work for you. But you do have to let us know. So let us know early. Oh, let's flip to my one-ass queue. All right, so no one asked a question yet. All right, so there's a question for you. What's the skill is least developed in many of our grads? You saw the answer, I did. It's a slow answer. Oh, good answer. Good answer. I wonder how you knew that. I don't know why my laptop did that to me. So shameful. All right, so a lot of people, a lot of our alumni tell us in industry contacts, people that come in recruit here say, you can probably do a better job with your soft skills, right? So one of the things you will do in this class, in discussion section, you will work in groups. So you have an opportunity to meet people in the class, solve fun problems related to the lecture together, and practice working with others. In later classes in ECE, there's a lot of teamwork, right? There's always hands-on work, and there's a lot of teamwork in later classes. This actually feedback from a long time ago, although I think we can still continue to improve, but there's now required team projects, I think, in every route through ECE. So you will eventually have to do big class projects with team members, but even in these introductory classes, you're going to be working with people every week. OK, so use it to meet people that you can work with, talk to do your homeworks together, and try to develop your soft skills, because employers are looking for that. It is important. All right, so how are we going to grade? So we got 15% on labs, 15% on homework, 5% on discussion sheets, midterms. First one is 10, others are 15, and the final is 25. A lot of people, if this is your first semester in college, you might wonder on an exam, well, did I get an A or a B, et cetera. We don't typically do that in engineering classes. We just do points, right? So you've got some number of points, and out of all the possible points, you'll get some number from 0 to 100% of the points. And then we'll map that. I'll show you a mapping in a second, but it's your typical absolute scale. So we'll map that to a grade only in the end. We will, as part of that, calculation, drop your lowest score for your lab, your lowest score for your homework, and your lowest score for your discussion sheets. So if you get sick and you miss a week or something to worry too much, but we don't accept late assignments, so make sure you turn things in on time. Part of that is that we're going to put homework solutions out. So once the homework solutions are out, we can't really take the homework because the solution's up to rate. So do them on time, please. And the other reason, honestly, too, is if we extend an assignment with a 400-person class across many weeks, it becomes a challenge to grade. We have a big team of graders that's going to try to get your homework back quickly so that you can get the useful feedback in time. And if they then have to go back in grade previous weeks homework because people turned them late, then it just becomes completely unmanageable. So it's another reason we've just decided no late assignments. So finish them on time, and we do try to drop one of each to account for, as happens, kind of things. I'm not allowed to say that word. I guess I can say it in other languages. So the EC-120 grading scale is absolute. So again, we calculate total points based on the percentages you just saw. If you get 90% of the points, you get an A of some sort, more details on the wiki. I think it's like 90 to 92 is an A minus 93 to 97 is an A, 98 and up is an A plus or something like that. But look on the wiki if you want more detail. 80% and up is a B of some sort, 70% is a C of some sort. Many of your classes here will be curved. So many of your classes will just say, well, we'll target something on the exams, maybe 75%, maybe 50%. Actually, some AC classes, I think, were targeting 30, at least based on their outcome. But that's the average. So remember, if you got like 35, that was actually good school. You can imagine that feeling before you know the average. Oh, we've all been there. So it's okay. So many of your classes will be curved. So just realize that for the future. And you can ask the professor in your class, is this curved, is there scale, what's the scale? And here, this will be absolute. Unless we really blow it on an exam, and the exam average is 50. In which case, we're going to raise people up so that more people are getting A's and B's than the absolute scale we're talking about. So we'll make it easier. We want to make it harder. All right, again, I mentioned soft skills, but do get to know people. So talk to people in your lecture, talk to people in your discussion section, go to Open Lab. Once a week, we have this Open Lab every Wednesday, 9 to 5 in 2022. There's a red book. So if you want to meet people, there's a red book you can sign up in Terry Peterson's office and the advising office. It was sort of joking, but if you want to turn and say hi to your neighbors now, it'd be okay. I'll walk over there slowly. All right. This is always painful to talk about, but it does happen sometimes. So I want to mention it just because we do take it seriously. There's a code online that describes it in a lot of great detail for you, which you should read once in your life, since you're here. So that's the number. If you type section 101, 402, academic code UI, you see it'll come up. Discussion sections. So the other thing, I actually, much more serious note, every class is different, right? So every class will have a different interpretation of what it means, what's allowed and what's not. So be sure in every class that you figure out what that class allows and what they don't. Because the line's a little blurry, and it's in different places for different classes. So make sure you know where the line is in every class. So this stuff is just meant to help you with what's the line in this class. So discussion sections are done in groups, and some labs you'll have partners, otherwise your work should be your own. Okay. So you can talk to each other, help each other understand, but don't give each other answers, share answers, give any kind of electronic answers. Let someone copy your answers. If one person lets another person copy, and we find out we give them both zeros. Right? And we apply that penalty. So please don't. And I don't think any of you will, but somehow it happens. So your guide to the slides, I'll leave this. I won't go over it here, but it's there in the slide. So, all right. So we've got a few minutes left. So let me talk about, you know, actually with my remaining few minutes, I mean, you probably know this, but you can eat here. So if you get a little package in the afternoon, sorry, a block, but I'm a professor. So I can do what I want. Unfortunately, you know, it's a little embarrassing. I need your help because my kids eat this, think of a peanut butter sandwich, but it's a little embarrassing. I just need your help to tell me what to do. So I got some bread, it's sourdough bread. I hope that's okay. And I got some peanut butter. And I got some paper towels, because the janitors will still kill me. And I got some white paper towels, too, to destroy all the evidence. And I have this knife. What should I do? Can you help? Can someone help? What do I do first? Yeah, what's your name? Eric, what are you, open the bag for? It's not working. Yeah, right. All right, it's open. It's open. What's next? Take the bread, okay. Good bread. Someone else want to help me? Yes, what's your name? Raoul. Raoul, what should I do next other than you? I'm Rob. So, that's what? Hmm. Well, okay. I'm not a tab. I like rap. You're really going to let me do this. All right. So what's the point? There's abstraction, right? You kind of think I know how to use things like a plastic bag or maybe how to undo a lid. And humans have a lot of abstractions that we learn about. I'll give you a couple more examples in a minute. But that abstraction we think about it in terms of interfaces. Like you tell me if they open the bag, right? Eric told me to open the bag. And Raoul told me to open the jar. Right? And you expect that I know what to do. And there's an implementation. There are lots of different jars. There are lots of different bags. And each of them has that interface of, we'll open it, close it, take something out, put something in. And you expect that I'm going to know what that means and how to use it as a human. So an abstraction layer is just that, right? It's some implementation that provides you with a set of functions. And that's built on something underneath that also provides a set of functions to it. But many people don't know what that means. It provides a set of functions to it. But many different ways to do it. Right? Many different bottles, many different bags. So that's an abstraction layer. Just to give you a couple more examples, you know, humans know all kinds of abstraction. So if you get in a taxi, you know, you don't tell the taxi driver, okay, lift your right hand and put it on that stick there. Right? You tell them, hey, I want to go to the airport. Right? And you expect that the taxi driver is going to take that and turn it into driving instructions. And, you know, maybe even helping you put your bags in the, in the back and so forth and so on. Right? There's an abstraction of you just say, where your destination is, taxi driver takes you there and then takes the money. Right? And you should tip. And there's water faucet, right? What's the abstraction? Well, the functions are, get water at some fuzzy rate. Right? There's a low rate and a high rate and maybe a medium rate. And there's, and there's a lot of ways to do it. Right? You can use plumbing. You can use water tanks, cisterns, wells, aqueducts, valves, knobs. There's lots of ways to build a faucet. And you could probably use all of them as a human. Right? But the abstraction is, you know, get some water. And you don't want to care. How many of you know how to build a faucet? Okay. So some people row, right? Right? Right? Some people do, right? And probably for, and then probably most of you could drive a taxi for some form of drive a taxi. But, but, you know, there's lots of, actually, probably not many of you would know enough about the, about the local area to drive a taxi well, but you could do the driving part, right? But the, I guess you can buy GPS. But those are abstractions. So, starting, I guess we have a few minutes left. So maybe I'll start with a first few of these. Digital systems, we can break into seven layers. So this is taken from Patent Patel. This is figure one six, as I recall. Digital systems break into seven layers. So down beneath this is the electrons, right? So what we'd like to do is say, electrons. I want to go to the airport. And the, the electrons will form up a taxi, and I'll climb in. And then those, it me down to the airport, right? And then it'll be good. Unfortunately, no matter how much I talk, I don't talk to, I'm sorry. No matter how much we try. It doesn't work, right? Electrons don't understand human language. So we've got all these other layers in between, where we try to turn human language, that describe problems in tasks, into electrons moving around on a ship, that can implement some problem solving for us. Including autonomous driving. So not really too much of a joke to use of taxi. All right. So the color coding I've added, human language theory is yellow, software is green, and hardware is blue. Those are sort of typical implementations of these layers. So let's, let's go through these. So let's go through these. So yeah, that was my electron joke. Actually, I stole that one from ELPAT. So, it's a credit. All right. So problems in tasks. So this is the first layer at the very top. So for example, these are state and natural language. And I want you to answer this question. What's the sum of numbers between one and three? Think of it in your head. Don't shout it out. Okay. Is it hard? Got it? You ready? I have to walk all the way back over here. So, I'm going to go back to the first layer. I have to walk all the way back over here. So, all right. Sorry. Answer was wrong. It's mean to play tricks on your not engineering friends and take money from this, from this question. So don't do that. All right. So what's the sum? Did you answer it? How many of you answered six? How many people said, oh, some of numbers from one or three? Yeah. Some people answered six. But no. Because if I ask you, okay, look. Here's my bread. For ten, this is a sandwich. What's between the bread and a sandwich? Is it the bread? So if I say, what's between the bread, you wouldn't say, oh, it's the bread. The bread is between the bread. So you shouldn't add one and two. I'm sorry, one and three, right? Well, what if you answered two? So you say, ah, I had the better answer. No. What about two point five? Did you include, what about pi over two? What about E? Do you have those in? All right. So maybe some of you did any one answer infinity? Okay. Oh my gosh. All right. You can read. The answer is still raw. The answer was six. All right. So what's the problem there? The problem is inherent to natural language, right? There's ambiguity. What does between mean? How did we know? Did I mean integers? Are there any real numbers? Maybe I meant complex numbers between one and three. And along the line, in the complex plane. So another example. Time flies like an arrow. What does it mean? How many of you do Pokemon go? All right. So before Pokemon, there was you, and if you know you, and one of the you, characters was time wizard. And one of the you, characters was time wizard. You look kind of like this. This is time wizard. Time wizard or my time wizard and I, good buddies. I'm on a first name basis. I call them time. Turns out that when time wizard flies, don't try this at home. This is purely television, you know. Good hurt people if you try this at home. I talked about safety. Critical, critical technology. Okay? I'm doing this really fast because we're running out of time. So it might not fly as well as it should. And I'm not an aeronautical engineer anyway. Time flies like an arrow. Clearly that's what that means, right? Time flies like an arrow. At least when you give him the proper plane. Okay. So I don't want to run too much over time. So I will stop there, but I did want to show you. And you can just come down and look at them or maybe I'll take them outside. Here in Illinois we have the, I think still the only fabrication facility until donated one of their old tabs. These are examples of chip students have built here. So try to be careful with them, but you can see they're ready. Some of them are broken so don't feel bad if you break them. And I'll let you take a look if you're interested. And then maybe I'll drop them. But there's a lot of cool stuff you can do here. There's also a new Nano Lab just outside of the Up 1 floor. You you you you you you you you you you"
    },
    {
        "ECE120-2016-10-24-LEC-25-slides.mp4": " So, Vlad and I, I think, was it due by Thursday or something, Friday? So, today we're gonna just pick up where we left off with memory and look at bit slices, how they work, look at coincidence selection, which will help us reduce the amount of logic we need for decoders and other things like that. Talk a little bit about tri-state buffers, which we'll use to allow ourselves to have multiple outputs connected to the same wires and then choose which output drives those wires. Obviously, we can't create shorts, we only have to have one at a time and that's what the tri-state buffer will let us do. Look at how we do bigger and wider memories, so take multiple memories and put them together to build memories with more bits, either more bits for address, higher wider addressability or more addresses, a larger address space. And we'll start talking about how we can implement something like a C program using a finite state machine, so we'll walk through an example of that, and it'll kind of illustrate how we actually build a computer. So that'll take us through, I don't think we're gonna get done with this today, so I think it'll be at least halfway through Wednesday, if not all of today in Wednesday for those two topics. So just to get back up to speed after the weekend, just do a little review. So remember with the memory, we wanted to do two different operations, so one is read, so we tell the memory, here's the address we want, right? We had an original design with 2016's names, so we give it 16 bits and say, here's what I want, this address, and outcome the bits on these data outlines, and then we can also do a write where we say, here's the address I want and here's the new bits, so we've said it was 32 bits wide in the original design. And then of course, we have to tell the memory, do we want to read or write in a certain operation? So this is what the symbol looks like. You can see the things I just talked about, data comes in here for a write, it comes out here for a read, read or write, write, and able is here. This was the address lines, and then we also had this chip select, and we said, well, if chip select is high, that means the memory's gonna do something, and if chip select is zero, that means it's basically just turned off, doesn't do anything. So that was chip select. This is a static RAM cell, so double inverted loop, the store with active logic. When we turn on the select line, then these n-type MOSFETs connect the bit and allow the bit stored here in the double inverted loop to drive these bit lines. And then when we want to do a write, we force these bit lines to take on the values we want to store, and we turn the select line on, and then we wait for that double inverted loop to switch over and store the bit we're trying to push in. Yeah. So, they would, and that's, I think, just a balancing act to make sure that it's a little easier, and the shorts are even shorter loop. So, yeah, yeah, a good question. All right, so, and then this was the last one we looked at last time, and went kind of quickly through it. So, what I've done here is taken the cell from the previous slides and turned it sideways. So, now the select lines run vertically. There's cell zero select line here, cell one select line here. There's 16 different cells, each with its own select line, but you can see the bit lines now run horizontally, and all of the 16 cells share the same bit lines. Okay, so we're only gonna look at one bit at a time, read one bit at a time, or write one bit at a time, out of this bit slice. We only have one pair of bit and bit inverse wires, the bit lines for those. So, just to give you a little bit of annotation, so the cells are rotated, I just said, all of the cells are sharing these two bit lines, be down here, be prime up here, and analog logic, like the send SAMs and things like that, to drive the bit lines and read the bit lines are down here in this little box. That's analog, so we'll look at how it's actually built. So, I also want you to notice that, now we're gonna use this decoder here to control the select lines, right? So, four bits of the address, the address might be bigger, and we'll see how we can do that shortly. But four bits of the address would go into this, four to 16 decoder, and the cell that we want out of the 16 would have its select line activated. All the others would not be. It's only one of these select lines will be active at any time, and this decoder's enable input is how we'll use the chip select. So, if chip select is turned off, the decoder's enable is turned off, and that means none of the cells are turned on. If chip select is one, then the address chooses which of these 16 cells is activated by activating its select line. All right, so let's look at how a read would happen in the bit slice model. So, remember for a read, we set chip select to one, we set right and able to zero, set the address bits, and then we'll wait for the data to come out. So, we set chip select to one, so now our decoder's enabled. We put the right and able equal to zero over here on the read write logic. We put the address in on the address port here, and then one of the select lines becomes active. I just picked one of the cells, so pretend address is three. So now this cell select line is activated by the decoder. Now, that means that since we're doing a read, the cells double in vertical loop inside will drive these bit lines, and the stored bit changes will go down the wires towards this analog logic, at which point this logic down here will read the bit off of the bit lines and send it out to data out. So that's a read. So, in this logic, remember that reads and writes act differently. And so the right and able semantically means if we want to do a write, we set right and able to one, if we want to do a read, we set it to zero. So when we tell this logic down here, write and able to zero, that's telling it, okay, don't do anything to the bit lines, just wait until the logic comes down from the cell. As opposed to a write where you'll see in a second, we're gonna push the bit lines to whatever logic we want, whatever value we wanna store. Yeah, so for each operation, you can read one bit or write one bit, and you can't do both at the same time, and you can't read or write more than one every time. There. There. The dual inverter loop. How that is, how that is, is working. So this double inverter loop is exactly the same thing we used in a latch. So it's by stable, you can store a zero on the left and a one on the right, or a one on the left and a zero on the right. Yes, that's right. Yeah, yeah. So when you connect these two, if you're doing a read, then whatever this inverter drives, whether it's zero or one, we'll go down this bit wire. Whatever this inverter drives, which will be the complement of this inverter, goes down the bit prime wire. Yes. Yeah, this double inverter loop is by stable. There are two stable states. Just like when we looked at the latch, it's exactly the same. Makes sense? Okay. Right. Right. I didn't even use one. Let me come back to that. Let me come back to that. Someone had asked earlier about timing last week, and it's similar answer. So I'll talk about it in a little while. For now, think about it as we just have to wait long enough. Okay. So let me skip through the read. Let me put the read. Okay. So that's the read. All right. So actually here. So memory is not clocked. Okay. There's no clock in this system. It operates asynchronously with respect to other logic. Okay. So basically it takes some amount of time. And the person who designs the memory needs to figure out, well, how long is that? And then in the data sheet, it'll say, you must wait this long. Okay. And then the system that you build to use memory has to wait at least that amount of time. So you can translate that to your system's clock cycles and round up. And that'll work. But it's not synchronous. It's not a clock system. So a couple of different approaches. So the designer specifies a minimum wait time in the data sheet for read to happen. Or the way it's done in patent. The tell is the memory can also have another output say a ready signal. It says okay, I'm done now. Okay. Now internally. This option is still done this way. The designer has to know how long it takes. And then they'll just generate the ready signal when the. When the bit is there. Okay. But that ready signals another way it can be done, but can be done. This is a little bit of an aside. You may hear about s d ram. Right. So you may say, hey, I want to buy some ram from a computer. Oh, I can get s d ram. And oh, what does that mean? No, I'm not told me it's always synchronous. It's still true. What s d ram is is the interface between memory and your computer is clocked. And that allows us to transfer bits back and forth between memory and the computer faster than with the. The internal cells are still not clocked. Okay. So the cells inside an s d ram chip are not clocked. Yeah. To some extent, yes, the the asynchronous interface. You always end up kind of waiting for the next cycle. And so if instead you pick a cycle time that's a multiple or a fraction of your of your chip speed. Then overall you can transfer data back and forth. So the interface is clocked. The chip itself is I'm sorry, the memory cells themselves are not. Again, you don't need to know this. I just worry that you'll go out and see it and then feel confused. About synchronous. All right. So this is a this is a right. So we've got our bits slice. We set chips like to get to one. We set right enable now to one. So we're going to do a right from this reading right. And that means it's going to force the the bits down those two bit lines. So set the address. There we go. Set the address. So the bit to write comes in here on data in. And the address cell select line is going to be activated again. Right. So this one will be activated just like last time. But now instead of reading the bits out of that cell, the read right logic knowing this is a right. Is going to hold these bit lines at fixed values. And that will force the inverters. Inside here to flip to the state that matches the bit lines. Okay. So now they're going to store that fit. And that's the end of the right. So once again, we have to know how long that takes and we have to wait long enough. Okay. So the designer has to figure it out. Specify here's how long you wait for a right to finish. And then when you use it, you have to wait the appropriate amount of time. It's not caught. So we activated cell will store that fit. In cell. Yeah. Good question. So does data in matter when right and able is zero. It doesn't. It doesn't get used for anything. And we'll talk about it later. We can actually reuse it. So real chips will reuse it and match our. Safe pins. But let's save that topic for 10 or 15 slides. Logically, yes. Logically. Yeah. And you can think of it that way for our class. It's fine. It's kind of similar to the gated D latch. Right. But it forces it over. Right. So. It does briefly that that's it's an analog design problem, right? So we talked about that a little bit last time. It's outside the scope of our class to do analog design. And even when we look at it, you really have to understand transistor sizing and timing and transistor level circuit simulation. And so it's well beyond anything that the worry about you. You should just know their analog circuits. And so at some point you learn how to do those. But it'll be probably junior year at least. Before you know how to design it. What do you get out? Nothing. Yeah. So that's a good question. So what comes on data out for right nothing. And again, I'll come back to that later, but we're going to figure out. Well, could we actually just share those sets of lines? Because for read, we're using one set for right. We're using the other set. Why do we have two sets? Yeah. Let me leave that to we come back. Because in practice, I mean, it's disconnected electrically, but I need to show you how. So. Yeah. That's handled by read right logic. You simply put the bid in. Yes. I know it actually does use two wires in practice. And the way I showed you the SRM cell looks. Yeah. It could. And that was the question that was asked at the start of today. Could we just use one bit line? You could, but then electrically you'd end up probably burning more energy. It gets back into the analog design question. Right. So you'd save a transistor, but you would end up being less efficient and slower. So, all right. So again, two approaches for rights. Right. Member designer says how long or similar to patent battalion of a ready signal. Your right finishes. It says, okay, R equals one. No. No, this is all the analog logic we talked about in my little box. Yeah. All right. Okay. So here's our bits slice. So this is 16 by one memory. Number of bits is larger and this balances speed against size. Okay. So you can have a thousand cells and a bit slice. Right. And it'll be slower because you have very long bit lines. And when you, when you read that little double inverter loop has to drive that long wire. Right. And so it takes longer. Okay. On the other hand, if you have a thousand instead of 16, that means well, you've got this one copy of this logic over here shared across a thousand bits instead of shared across 16 bits. And so the longer you make them, the slower they are, but the more efficient they are in terms of space. It's a smaller but slower. So the other cost is this decoder. I mean, it looks like a small box here, but how many gates are there in an roughly in an end to two to end decoder. Roughly two to the end, right, because you've got one, one and gate to drive each of these wires. And they're two to the end wires. Right. So if you have end inputs, two to the end outputs, you've got roughly two to the end gates plus some more. Roughly two to the end. So that's a lot. So let's think about that. So if we have more than one bit slice, let's say we stack a few of these and I'll do that in a diagram in a second, we can have, we could share those select lines. Right. But then how would we decide which bit slice is active? Put another of these, right, put another decoder. So what does that mean in terms of our decoder area? Well, so let's say you've got a million cells, two to the 20 cells. So two to the 20 cells, one big decoder, that's two to the 20 gates. If instead I did it in two dimensions and I said, okay, one dimensional use two to the 10 gates. I'm sorry, two to the 10 decoder and the other dimensional use two to the 10 decoder and then where those wires cross, that'll be one cell. Well, that'll give me two decoders with about a thousand gates each. So about 2000 gates compared to a million gates. So much, much smaller decoders if I use two dimensions. Yep. Well, so the problem is the cell really only has a couple of things that can be shared that way, right? So you can, there is actually more hierarchy and real chips than two levels, but in order to generate the signals to those little pieces, you end up putting gates, more gates down here and there anyway. So you can spread your gates out that you end up using it out the same. Yes. I told you I'd show it in a second. All right, so here's four bits, right? So let's just take a look and in the savings on the decoder is not going to be very dramatic, right? Because this is only six bits of address, but here are 64 cells split up into four bits, which each bit slice has 16 cells and it's just like they had before. We now have a six bit address, right? So two bits of our address will decide which bit slice and four bits of our address will decide which of the cells in one of the bits slices. So we can take a look at how that works. So here's our six bit address for two bits over here for bits down here. So let's look first at a right. So chip select is one right, enable is one. So just like before. So set the address bits. So some of our address bits will go up here, right? And so what that means is now, let's see. So right, enable is going to go into this decoder as our enable signal. And so one of the one of the four outputs based on these two bits of the address, the upper two bits in this case will go out and feed the right, enable signal on one of the bits slices read right logic. So all of the other bits slices will think they're doing a read in this design, but we don't really care that much. So they're going to all do reads, but this one here will do a right. The other four address bits go down here. This line is then activated. So three of these bits slices in this design will do reads this one that I've highlighted here will do a right. So the bit to right comes in. The bits are held at a fixed value and that cell there then stores the data in there, but only that cell. All of the other cells. There might be some bits coming down these wires, so this basically will just get ignored. So I mean, typically in a cad tool, you'll say I want a memory and someone will actually have optimized memory variance for you. Yeah, memory optimization. There are tools that will do it for you. If you if you really need to go and do it yourself, there's several academic papers and things like that. Yeah, yeah, Intel does their own by hand. Yeah. And so I mean, so does IBM to some extent, maybe not more. Okay, so let's take a look now at a read on our on our four by 16 design. So this is really a 64 by one memory, right 64 addresses, one bit each. So we've split it into two dimensions. So chip select is one right and able is zero part of the address again goes down here. So one of the select lines is activated. Let's say we know I haven't highlighted it yet here because it doesn't actually use this decoder uses this mucks down here. But so this cell again is activated. So it will flow down these bit wires and then the output will come out of the queue output and go down to the mucks. Now these other bits slices are also going to produce a bit, but we're going to ignore them. So using this mucks will look at the other addresses, pick out the bit that we wanted and that will come out to data out. So the mucks will handle the output. I think, well, wait, there's a little triangle thing. What is that? Okay, so what's the triangle thing? All the tri-state buffer. So why? There should three rows in the truth table. Okay, okay. So the only thing that you might not understand about this truth table is call a tri-state buffer because there's three rows in the truth table. What does z mean? The idea? Means high impedance. Okay, so it means in other words, it's electrically disconnected. So the input and the output are electrically disconnected when the enable input is zero. And what that means is we can have this connection between in and out and if if enable is zero, this outside can be actually driven by some other gate, by some other logic, and it won't create a short. So it's electrically disconnected when enable equals zero. So how can that happen? So here's a diagram. This is not going to look like one of the other gates, right? Because this is not always producing zero one. When we built gates out of transistors, we always wanted to produce zero or one. We never wanted to have it just be left floating, right? For the output. This one is going to be left floating. So look at how that how that happens. So what happens when a equal zero? So put a zero there. Yeah. Hey. So it means it's turned off. It's turned off. It's turned off. Like an open switch. Let me show you in this diagram and then maybe I think that might cleared up. Alright, so enable is zero. So what's the voltage here? What's the it's a one right? So this on or off? Good. And then down here is a one. I'm sorry, zero. Right. There's just a wire. How about this one on or off? Good. So you see what happens when we said enable to zero. Right. Basically out is disconnected from ground out is disconnected from high voltage out is just floating. Not connected to anything. That's what I mean by by the Z high impedance. Okay. So you can't cross the either of these two transistors evil. So what about when able equals one? So that's one. What's here? Zero right? Okay. So on or off. How about let's see down here's a one on or off. Okay. So what does that look like now? Is it a short. You still have two transistors. So this an inverter right with these two transistors. That's an inverter. There's another inverter inverter inverter inverter. So after this inverter is in prime after that inverter is in again. Right. So copied into out. Makes sense? Yeah. Sometimes people get confused and they think a tristate buffer is just like a one end type MOSFET or something. But that's not true. Okay. So it takes a bunch of transistors to make this work. It has to be active logic. You want to drive out using either high voltage or ground. Right. All right. So tristate buffer is what they let us do means we can actually wire outputs together. Okay. So that means we can have one set of outputs and have something like what I'll call the distributed mock. So say we've got four groups of n signals. Okay. So there's something producing n signals over on the left side of the chip. Another thing producing n signals at the top another on the right side another on the bottom. We could use a mux that mean we have to take n wires from each of those bring them all into the same place. So four n wires. And then we'd have to decide which of the four we wanted. And then we could take the answer and send it everywhere with n more wires. Right. So five n wires. A lot of wires. If n is big. So instead what we can do with tristate buffers is send four control signals. Right. Now those will be one hot. We obviously we can only pick one of the four sources. So one of those will be a one. The other three will be zero. But any of them could be a one. So those are good at the tristate buffers. That's four wires that go everywhere. And then we'll have n wires that send the answer out still. But instead those n wires just circle around the chip. Right. So it's n wires going to all four of the things. We'll call those n wires a bus. So now we have n plus four instead of five n wires going everywhere. So those those enamel wires mean that only one of the only one of the four values actually gets written to the wires that go everywhere the bus. So in some sense they're acting like it distributed mocks. And so there's these four control wires go to the tristate buffers and only one group of n signals gets written to the bus at a time. So if you look at the LC3 computer data pass and Pat and Mattel first shows up in chapter four. You'll see that it actually uses a bus and it uses tristate buffers to decide what gets put on to the bus at any point. So that's one use of tristate buffers. Now for memory design the other thing we can do to generalize us a little bit data out is gated with tristate buffers. So whenever you have a memory in our class, then the output is only going to appear on the output when you're doing a read. So if you're not doing a read those output wires are floating. So that means anytime your chip select is zero or you're right and able is one in either case, you're not doing a read right. So your output will float. So basically that means your input and your output wires can be the same wire. You're only looking at the inputs when you're doing the right. You're only using the outputs connecting them to some ground or high voltage when you're doing the read. So why not just use the same wires. In fact, most chips did that right most chips would have a data bus basically a bunch of pins going into them and you would use the same pins on the chip for reading and writing. It's actually a lot of bits right a lot of pins so it was important to do this. So so we use the same bits same pins when we do a right the pins are accepting bits to store when we do a read the tristate buffers right the bits from the memory cells onto those pins. All right, yeah. I don't just use separate wires. So the reason is because pins are of pins are very limited resource compared to transistors on a chip. So in the last 30 or so years, the number of transistors on the chip has gone up by a million fold or something like that, maybe more. The number of pins has gone up by about a factor of 10 or 20. And then the number of pins you can fit physical pins onto a chip is tiny compared to the amount of data you can pump in and out of the chip. And so if you're not using your pins efficiently, like if you just say, well, I don't really need to use these sets of pins at the same time, but heck, I've got lots of pins. You don't have lots of pins. So that's why. And you didn't have lots of pins 20 years ago either. Okay. All right. So building a memory of more addresses. So let me, let me give you this thought problem and then I'll show you how it's done. So let's say we've got two memories and each of them is two to the K. So K bit address to the K addresses by N and bit address ability. So N bits at each address. How can we put those together have a bigger memory with more addresses. So two to the K plus one address. So first just kind of verify well, if I've got to the K by N bit memory that's due to the K by N memory cells, right, that little double and border loops. And so I have enough, right, because if I have twice that many, I can treat that as two to the K plus one times N, which is what I need for this memory. So we have the right number of memory cells. How do we wire it up? It's actually pretty easy. So the one thing that's a little tricky over here, we're going to need a little decoder to handle the chip select signal. Okay. So we're going to put chip select into the enable. So chips elect is zero. The decoder output all zeros. Okay. So you see that zero goes to chip zeros chips, like one, I'm sorry, giving them names. This will be zero on the left one on the right. Zero goes to this one's chips, like one goes to this one's chips, like so if the external chips, like to zero, both chips are not selected. On the other hand, if external chips elect is one, then one bit of the address is used to decide which of these two chips is going to do something. Only one of them is going to do something at a time. Okay. So only one of these two memories is active at a time. So what that means is we can just say, well, we'll take the data in and just copy it to bowl. We'll take the right naval and just copy it to bowl. We'll take the data out and just merge them. Right. Remember, they're try state buffered. So that's safe. So we don't have to worry about that. We'll take the address bits all but the one K that we used for this decoder here, the rest of the address bits will also copy to both chips and we're done. One of them will do a read one of the more do right, which one will depends on the high bit of the address. You have to put mox is down here. Yeah. Yeah. I mean, yeah, to or end end two to one mox is. Yeah. That's right. And some extra delay there to. Yeah. It's it's controlled by chip select and right naval. Yeah. Inside those memories. Yeah. Yeah. Which I in the bigger diagram. There was a try state buffer already in there. Sure. Yeah. Yeah. That's not a bad way to view it because it is it is like a switch is electrically disconnected when you turn it off. Yeah, although you can also have switch styles like the one in the lab is a zero one switch the way we've wired it up. So to be a little careful how you think of a switch. Yeah. The way we drew it with transistors where it's open or closed. Yes. Okay. One more question. So what if we wanted instead to take two memories and make something with more bits for each address. So again, two memory same size, but instead of twice as many addresses, I want twice as many bits at each address. So same argument down here. Well, I've got the right number of memory cells. So should be doable. It's actually a little easier. I don't need any extra logic. So we can just hook them up like this. So the address goes to both. So both of them are going to be active at the same time you can see chips like is going to both of them also right enable also data in. We've actually split up into two groups of bits. We now have two in data inputs and we have two in data outputs. So the top half of those will go to one chip, the bottom half will go to another chip down here. Half will come from one chip, half will come from the other chip for the data outputs. Now, you can mix and match these bits anyway you please. If we ask you this problem on an exam and we'll probably ask you, please don't make complicated patterns. But as long as the pattern you use up here matches the pattern down here, it doesn't matter. So when you write bits, you use the same way of taking those bits here and putting them into the chips. As you do when you get bits back out of the chip, it doesn't matter what what mapping you use. In practice, people do look at more complicated mappings for performance reason that that's something you'll learn maybe in 411. So if you go out to micron site, I think the biggest one you'll get for a chip is about eight. Last time I looked it was about eight, so one to eight. And then you build. So it, you know, there are different questions, right? So that's the memory perspective is most in typically two or four. But from the processor perspective, you're by most instructions at architectures, which we'll start talking about next week will be bite addressable. So any individual bite and memory has a name for it. There were processors people try to build in the 90s where you could only talk about eight bytes in memory. And pretty soon they figured out that there was far too much software that wanted to do bite addressable memory. And so they had to add that as an extension. So I just want to make sure you understand. So right then you'll take the bits split them up. Both of these chips will write at the same time because right now will be one chip select will be one. So both of them will will write half of the bits into their into their cells. So I want to read it back out chip select will be one right naval will be zero. The address will be the same. So we'll collect the two sets of bits from those two chips and then put them together on wires and those would be the bigger answer. So I'm going to expand them in the coming weeks. The question is LC three instructions probably mapping the logic. Yeah, yeah, we'll look at that. So so that's it for memory. What I want to spend the rest of today, and probably all of Wednesday on is developing a finite state machine that will implement a little piece of code. So we can do pretty much anything with the finite state machine. So let's take a piece of C code and we'll use components to store the variables. So by store, I mean, probably registers, flip flops, things like that. So the reg the variables in the C code will become registers counters. We'll also execute the statements. So any time we're moving bits around that'll be something we do it based on the finite state machine. We do comparisons. We'll use a comparator things like that. So we use other components to execute the statements. And the finite state machine is going to use those components by having the outputs of the finite state machine act as control signals for the component. So we'll have a bunch of components will put them together. We'll call it a data path. And then we'll have the finite state machine states say, well, what should the components do in every cycle in order to basically execute those little pieces of C code. Oh, it was the other way, right? You were given the C code and you were asked to draw transitions. This is a little more direct in the sense that a lot of software, software basically is a finite state machine. And so you can do that exercise for almost any piece of software. It's just that the state in software can be arbitrarily complicated. The state of this code is pretty small. So it'll be a little easier in that sense and a little harder in the sense we're building hardware from software. Going the other direction. All right. So here's the here's the piece of code I want to do. So what this is going to do is find the smallest integer amongst 10 integers. So if you look at this code, you shouldn't know how to read everything except that. So what does that mean? Some of you might know, but, but there's no reason for my class. You should know what this means. So let me explain it. So this variable declaration creates 32 to bit. I'm sorry, I'm sorry, 10 32 bit choose complement numbers. So variable declaration says I want 10 of them. And so they are then named it's called an array. They're then named value zero through values nine. It's it's a software analog of a memory. So we said, oh, we're going to have a bunch of values and we need names for them. Let's name them zero through 65,535 as bits. So we can name them as decimal value zero through value nine. But that's all it's doing is saying, OK, I want 10. So we get those 10. The first array element is used here, right. So we'll take the first one and copy that into min. We have to assume that this was filled up by someone else. So assume someone's written 10 numbers into those. So the element is accessed here depends on index the variable index. So again, values goes from zero to nine. So the variable index will have values somewhere between zero or nine. And which of the elements in in values, the array values gets access depends on the value of index. So it can be read, it can be read, it can be written. Let's assume before we execute our code that somehow these 10 numbers get filled in. So something's going to provide our finite state machine with 10 numbers, our finite state machine then will go through and find the smallest of those 10 numbers. So the first thing first step then is to copy the first array element value of zero into min. So we'll start by saying, well, if we just look at one of them, it's obviously the smallest one. So I'm not going to, I'm not going to answer that now because building that into the finite state machine would mean that we have to then build all IO and things like that. So we'll just assume that someone's going to put these into into something the finite state machine can access. So in the next couple of weeks, maybe three weeks or so, you'll see how the LC3 is built and then you'll not answer your question. All right. So here's a loop. Right. So if you look at this loop, you should know how this works. You start at one, you check if index is less than 10 and then you increment index for the update. So the values in that loop index will start at one in the last iteration index will be nine. Right. So it's going to run from one to nine. And then inside here in the loop, we're checking whether the entry indexed by the IDX variable is less than the current minimum and then replacing it if it is. One by one through the 10 values that through the second through 10th and check if it's smaller than our current minimum and if it is, we copy it into our current minimum. So at the end, the value, the variable min holds the smallest of the 10. Makes sense? Someone. Yeah. Sorry. The X plus plus is equivalent. We just didn't teach it in our class. So I just wanted to keep this syntax. So in the value IDX or equal. I don't understand the question. Oh, yeah, they're equal. Then they're equal. It doesn't matter whether you replace it or not. And in software, you want to minimize the amount of the number of instructions that need to be executed. And so executing instructions that have no effect to try to reduce that. So software wise, it's slightly better performance. In terms of what we're going to get. It does nothing. It skips over this and goes down and goes to the update. This is the array element numbered by index. Remember, the numbered zero through nine and index holds a value from one to nine. So min starts out as the first value, meaning values of zero. And then you compare it with the other values. And if one of the other values is smaller, you replace min with that particular number. Okay. Yes, and we'll do that. The index variable. Yes. Okay. So let's draw a flow chart. So we start down here. First thing we did was initialize min to value zero. I'm using colors for the statements here. So this was gray was our initialization. So the first initialization of the for loop was index set to one and then check if 10 is greater than index. And then if that's false, we're done. Of course, it's not false. The first time it's true. So again, those green things are part of the for loop. The blue is part of the if statement and then the body of the if statements of then case. So if checked whether min was greater than value sub index. And if that was true, it copied value sub index into min. If it was once that was done, it went to the update of the for loop. If the if condition was false, we also came down to the update of the for loop after which we want back up to the test. So there's a flow chart for that color coded with statements. So this is just a step towards towards figuring out how will actually organize our finite state machine states. So before we go there, though, let's think about how we're going to turn that flow chart into into a finite state machine. So what component should we use? We need an array. I said that an array is the software analog of a memory. So what do you think we'll use? We need to be able to we need 10 different values, right? We can use registers. We need 10 registers and we need to be able to name them. We let's use a memory. So then we can use a memory and we can name them 0 through 9 just like we did in the code. We can name the 10 value 0 through 9. What about the other variables? Register is counters stuff like that. What about the if statement. Sorry. So we have to do this comparison. Right. Let's use a comparator. In fact, I'm going to use the serial comparator, not because it's better or anything, but just because I want to remind you that we can build these state machines where one state is actually representing a bunch of states like we did with keyless entry where the alarm state became a bunch of states counting the time out. So here the state that uses the comparator is actually going to be a bunch of states that's executing a serial comparator for 32 bits. So just show you the hierarchy of an FSM again. So in order to execute a serial comparator, we have to feed it one bit at a time. So I've shipped registers for that and a counter to count 32 bits as they go into the go into the compared. So what are the rules about implementing state machines? So if I may implement a state machine, well, my states have to be executable in some fixed number of cycles. Right. So I have to figure out how to take this flow chart and break it apart so that I can execute the pieces in one cycle or 10 cycles or at least some predictable number of cycles. Right. I can't just say, just put all the flow chart in one state and I'm done. I could. It wouldn't be very effective. So that's related to how many components and what kinds of components I use. Right. So if I use very simple components, it's going to take me several cycles to do anything. Right. If I use very complicated components, it'll take me more area, but it things might be faster. So for example, I could say to you, well, I need to compare 10 numbers. So go build a 10 offer end comparator. It's doable. Right. You can sit down. You can write the equations out. You can solve the K maps. Only me not K maps. But you can do a 10 output comparator. Right. And it just spits out the biggest number. It's one big combinational logic. Then it's a very easy finite state machine. One state execute comparator done. So probably we're not going to do that. We could do that. Different design point. How we pick our components. What we did when we said, OK, we want to memory registers counters. How we actually pick them will affect how we design our state. So in practice, we'll go back and forth. Right. When I actually designed this. I went back and forth. They said, well, what if I put these down? OK, then here's my states. Oh, but that's kind of annoying. So let me go add some more components. Now that's too complicated. So you go back and forth. But this, this design is all done. So it'll presented as if it were easy, but it's not. You often have to go back and forth as you see how things work. All right. So how do we pick state? So we're going to break the flow chart into pieces. Not every flow chart box is going to become a state. So I'll give you an example in a second. Well, actually examples here. So in our flow chart, the first few steps were to initialize men. We said, OK, let's set men by copying the first value from the memory into men. We also need to initialize index to one. And then we do the first comparison. Well, we don't really need to do that in our finite state machine. Right. We know tennis greater than one. We're done. So we can do all three of those in the same cycle. So in other words, this part. This part and this part. We're going to make into one by a state machine state. So now the colors indicate the state. So this is something we'll call the init state and it'll perform these three boxes the first time. So we can also join some other states and we can do that by leveraging what we call predication. So what does predication mean? It's that's actually just an English word we use in the same sense when we design things as engineers. So predication means that something only happens under certain conditions. So the English sentence, well, if you give me an apple, I'll give you a peach. Right. You only get the peach. If you give me an apple. Right. That's the predicate. If you give me an apple. You satisfy that predicate then you get the peach. We can use that in a logical sense, for example, by saying, well, we get the output from a comparator. And then we can use that output from the comparator to decide should a register load a new value or not. Right. The way we change the register min is to load a new value into it. So we can use that comparator output to decide should min load a new value or not. That means we can we can perform that action in the same cycle that we increment index. So what does that look like in a flow chart. Well, we had these two pieces down here. Right. We had copy value sub index into min. That'll now be predicated by the output of the comparator and then increment index will put both of those into one finite state machine state that I'll call copy. So we have two states. So now let's step back for a minute and say, well, we've got this finite state machine. How's it actually going to get used? Right. It's going to go in and find the minimum of 10 numbers. But we said, well, something has to fill up those 10 numbers. So something's going to fill up those 10 numbers. And then it's going to execute our finite state machine. So with finite state machine needs to just kind of wait around again while that thing, whatever it is, reads out the answer. And then maybe later it'll put 10 more numbers in and execute our finite state machine again. But we ate some kind of weight state. So let's create a weight state. So during steps one and three or finite state machine is just waiting there. And then we'll have a start signal that says go to start step two. So that'll be an external input start for a finite state machine to go actually do its thing run through the flow chart. So where those. So this was the done the finish right. So start will now be this weight state and done also whenever the finite state machine is not executing the code, it'll be sitting in this weight state. And then we'll give the external logic time to fill the memory read the answer out of the min register and so forth. All right, the last piece then is the if statement. So sometimes even though it looks easy in a flow chart, it's not so easy to do on the data path. We said, well, we're going to have a serial comparator has to be fed by shift registers. We need to put values into those shift registers first, right. So it takes time takes a cycle to put a value into a shift register, even if you do parallel load. We also need a counter that's going to measure 32 cycles. So we need a preparation stage. So we'll go and create a prep state in which the finite state machine copies min into the shift register a copies values of index into shift register to be and resets the counter all of that one cycle. And then we're going to have a compare state that'll execute for 32 cycles where we run the serial comparator. And then when the counter counts up to 31, right, we'll have some counter it'll count up to 31 and finite state machine will move to the copy state that we already showed. So here's the here's that last bit of the flow chart, you notice I've broken it up into two colors because we're going to have a prep state and then we're going to have a compare state. So we can finish by just showing you this abstract state diagram. I'll just flip through it and then I'll walk through it. So this is now what we have. We have a weight state, the finite state machine sits around there until it sees the start signal. When you see the start signal, you go to a net that takes one cycle, then it goes to prep where it actually prepares to do a comparison with the second element of the array comes down to do the comparison runs this thing for 32 cycles. So it goes to copy where it might actually copy the second value into min, that would not be the end of the loop. So it would go around this loop here, the yellow, blue, green, yellow, blue, green. It would do that nine times to compare the other nine elements. And then when it's finished, the smallest number is in min, the register min, so we'll go up to weight and finish and then some other logic to come out and read the smallest number. So we'll go over this again and then finish up the design on Wednesday. Thanks. you you you you you you you you you you you you"
    },
    {
        "ECE120-2016-10-17-MT2-review-slides.mp4": " So we're going to do another review session. Same rules as last time, so hopefully people have thought about what they want to talk about. Anyone want to throw out the first suggestion? Okay. Sure. One comment quickly on that is that essential prime applicants are not that name is not required knowledge. And I know it showed up on some of the previous midterms, but you don't need to know what that means. We talk about that, but knowing what's an essential prime applicant is not necessary. Mohammed. Okay. And yeah, Daniel. I'm sorry. Decoders. I mean diagrams. And then. Actually, I mean, matters. Okay. Some of these are pretty specific, so they won't take much time. Anything else people want to throw up there before we vote? If there's anyone, okay, we'll give both of you one last chance. Go ahead. Analyzing sequential feedback circuits. Mohammed, what are you going to add? You need the canonical ones? Okay. All right. So this is a long list. So it's too voting quickly, so we don't spend too much time on that. So you can vote for as many as you want. Essential prime applicants. Two. Anti-peep type mosquets. About 20. Decoders. Oh, lots. Oh, my goodness. Okay. 50 timing diagrams. 40. Let's say demorgans law. Maybe about 15. Adders. 15. Functions as moxas. About 30 to 40. Analyzing sequential feedback circuits. 40 to 45. I think canonical SOPPS. Okay. So let's start off with decoders then. So decoder basically gives you minterums of the input. So the way it works, you would put in some number of wires. Let me draw out the way they've been drawing it in. Other sections. The way we drew it was like this. These are the same. So basically you're taking in some number of select wires. And those select signals you can think about as having some kind of coded value. And you want to know which one of those coded values is held. And so you create an output for each possible bit pattern. So for two bits you've got four possible bit patterns. So each of those wires on the outside on the right side carries a one. If and only if the bit pattern coming in matches that particular number. So 0, 1, 2, or 3 are the four possible bit patterns interpreted as unsigned. The enable then just enables the decoder to output a one at all. So if enable is zero, the decoder outputs is all zero. So enable equals zero means that all outputs are zero. And enable equals one means exactly. One output. There's a one right because the bit pattern can only match one of the four possible bit patterns. So this is decoder is useful primarily in implementing logic where we need to know which of those four bit patterns was being carried or for a three day decoder, for example, which of the eight possible bit patterns was being carried by the inputs. So so a lot of things like vending machines or memories will make use of them. We can also use them for implementing arbitrary logic functions by just using or gates or together the minterms. Remember, these are minterms, right? So matching a particular bit pattern is the same as a minter. So each of these outputs correspond to a minter. So if you wanted to know how to build them, then you can just build the and gates corresponding to the minterms. Right. So you can say, well, here's an and gate that takes enable along with s one prime and a zero prime. And so this would be the zero output. And then the end gate that takes a destroy enable linked up the others, I'll leave along with s one prime and zero. This would be the one. And pick up the navel to all four of them. So this would be s one zero prime. That would be the two. And then s one zero. That would be the three. And so that's how you would implement a decoder. You basically generate all the minterms with and gates. If there were an enable input and it together with all of the minterms. And then each of those and gates would give us one output. Yeah. So the output, the labeling of outputs on a decoder is usually using the unsigned representation of the input values. So usually the inputs we would name something like select and an s one s zero or for five bits, it would be s four down to s zero. Right. And then the output labels would be the unsigned values. So if you had a five to 32 decoder, they'd be labeled from zero to 31. And each of those outputs would correspond to the five bit pattern represented by s four through s zero as an unsigned number. So if you then wanted to make different functions, it's not terribly interesting with a with a two to four decoder. But if you wanted to make X or for example, how would I, how would I do that with say another or gate down here. But which minterms does X or half. Yeah, one in three, right. So I just pull off the one in three outputs and or those together. And that would give me X or. Yeah, one, two, sorry. What about or. Yeah, so or should be true for this minterms, this minterms, and this minterms. Right. So it's, I mean, again, two to four decoders, not terribly interesting, be easier, just pull us one and s zero directly. You can do any function using, by the way, the canonical s op version, right, because the canonical s op is the sum of minterms. So if you write any function of s one s zero as a sum of minterms, then you go find those minterms or the outputs of the decoder together that will give you the function. Anything else we want to talk about with decoders. Yeah, this is no longer really used on much in practice, you know, and if you're building something out of TTL and you had a decoder and you wanted to arbitrary function, maybe you'd use it. But these days it's very easier to just build a function. Yeah, how many. This is the decoder. This, yeah, this is how the decoder is built. These four and gates. Yeah, I didn't draw the not gates to implement this is the decoder. So let me put a box around it. Sorry, I added more logic, but that's the decoder. So those are those and gates are the decoder. All right, so let me do. It was not on the topic. So let me, let me see if we'll see what happens timing wise. Okay, so next up then was supposed to be analyzing sequential feedback circuits, but let me instead, because timing diagrams, I think will be brief. Let me just talk a little bit about timing diagrams. I mean, really, I know there have been a couple of questions on timing diagrams. There have been a couple of questions on timing diagrams on some of the previous exams. You need to know what a timing diagram is. So what it's, you know, you should be able to recognize one, for example. Most of the stuff we're going to do, you wouldn't draw any significant timing, certainly in this part of the class, because we're assuming clock synchronous sequential circuits, so everything operates on a clock signal. And I don't think we've ever, I mean, I'd have to go back and look through those exams, but usually we don't ask you to reason about about gate delays and things like that on a timing diagram. So it would really just be mapping out the kind of thing you did in the homework, or you would draw the clock cycles. You would represent what's going on in the different signals from clock cycle, the clock cycle, without more information than that in the timing diagram. So, you know, it's the kind of thing we also did in lecture, where, for example, if you had a binary counter. And let's just make it easy. So here's Z1 and Z0 outputs. And of course, there's a clock input. So if there's the clock, then the clock should be a square wave. It is the best I can draw a square wave. And so then, if your counter is starting at zero, you might say, okay, so, you know, when, when do the value draw the rest of Z1 and Z0 for a two bit binary counter. So when should Z1 and Z0 change? Yeah, the rising edges. Right. So the first thing would be to go mark the rising edges. So there's one. There's another one. And so what should change at this first rising edge? Z0, right? Because there's a two bit binary counter. So it's three go from zero to one. So Z1 will stay fixed. Z0 will go up to one. Okay, what happens at the next rising edge? Yeah, so we'll go to the one zero state. So I'll go up this one down. What about here? Z1, Z0 goes up. Z1 comes. No, Z stays up. And what about? Z1 goes up to zero. And now we're back at the original state, right? And so this is, this is just going through the four counting states. So this is zero zero. Zero one. One zero. One one. And then we'll go back to zero zero. And then we go, I guess, to zero one. So this is the final answer. And then we'll go back to zero. And then we'll go back to zero. And then we'll go back to zero. The dear to clock. Okay, so yes, there's certainly, it's certainly possible because we talked about registers and things like that for you to have flip flops running on a common clock. So these flip flops inside of this counter, for example, are running on a common clock, right? So all of these transitions. If I would draw the inside of that inside of that binary counter, those are two flip flops running off the same clock. And then of course the inputs are going to be expressions of the of the counter. Now, this is finite state machine design, right? So it's it's later. But we did do registers. Right? So we did shift registers. We did registers with parallel load. Those those topics can be on the exam topics of finite state. Is there anything else people want to talk about with timing diagrams or go and move on? All right, so let's look a little bit at analyzing sequential feedback circuits. So. So if I have a if without using a flip flop, I take the output of one of my circuits and I link it back and make it into an input as well. We call it a sequential feedback circuit. So for example, a latch, right, is a sequential feedback circuit. So if your outputs connected back to input and there's no clock signal in the design, the necessary sequential feedback circuit. So when we looked at in class, we started with was the bar bar, S bar latch, which looks like this. So we built that up and all the way up through a gated D latch and then we went to a went to a D flip flop based on the storing a bit design. You can also build SR latches at nor gates. These are the common designs and CMOS. Instead of NAND use nor so this is an SR latch. So if you think about the functionality here. I'll label a q bar, although if you turn both of those on the both B zero. So here these are active high inputs. So since it's a norgate, if I put a one in on the R input, that will force a norgate output to zero. So q will be zero. So they have the opposite input sense from the R bar S bar latch on the left. This was a q and let's see which way did this work. So if I put this as hero. We do both latches give the same outputs. Both latches can both of these can store a bit, but the input sense. These are active low inputs. These are active high inputs and you'll notice they're swapped relative to q. Active high means that you in order to take the human action represented by the name. So if you want to set the output bit which refers to q. On the left you make the S bar input to zero to set it to set q to one on the right. You make the S input equal to one, which means active high to set q to one. So really all we want you to be able to do is analyze stable state. So there are a couple ways you can do it. There's the simple way in the harder way. So since we already did the circuit on the left. Let's do the one on the right. So you can say, okay, so for R and S I can look at what is q. Let's give this name P actually. So if I set R and S zero and zero does that tell me anything about q or P. Right, because those are nor gates. So if I put a zero and think of it as or followed by not, but put a zero into an or gate. You need to know what the other input is, right. Zero or whatever is whatever. So for both of those zero inputs to the nor gates. I don't I don't change anything in my circuit. So then we could start the way we did in class and say, okay, well, let's just say there's a zero and q. What does that imply about P. So the bottom gate then would have two zeros going into it. It's a nor gate. So I will come on. Right. So P is one. In that case, q, I'll put a little implication arrow here. It means P is one. And if P is one, what does that imply about q. So it also goes back. You want to go around the loop because not all of these will be stable. So if we're just looking for stable states, you know, make sure you go all the way around the loop around the feedback loop and check. So this state is stable. But what if we had instead guessed q equals one. What is P then? Zero. So in that case, if q equals one, then the bottom gate is a nor gate. It has a one coming in from q. Norgid has a one. It gives us zero outputs of P is a zero. And then what is q from given P? The one at the top gate now has two two zeros going in. So those are stable states. Right. So this thing will store a bit when R and S are both low. What if I set S to one? Well, can you tell me about q and P? What's P? It's zero, right? Because that norgate on the bottom has a one coming in from S. So P is zero. So what is q? So we call this S active high. It's setting q to one when you have S input of one. What if R is equal to one? And S is zero. Yeah. q is zero, right? Because the upper nor gate will output a zero. And then P is what? That's why we name it R and it's active high. So when we set R to one, q is reset to zero. And we want to avoid this state just as in the in the latch in the latch on the left. We said, well, we don't want to set them both to zero. Here, we don't want to set them both to one. What output do we get if we do that? Zero, zero, right? q and P are both zero. So we don't want to do that because then the actual value once we stop trying to force both of them to zero will depend which one we which of these we lower first. And so we don't know what the final answer will be unless we analyze the timing carefully, which is a pain. So we try not to use this one. So if you write this as next state table, then q returns it state, right? It's able to hold a bit. So you put q plus equals q in the notation of the homework. Yeah. So you can write this. You could have say RS zero, zero, q plus is q, zero, one, q plus zero, one, one, zero, q plus zero. And one one, and it's zero, but P is not q bar. So you got to be careful. Okay. So the more complicated way that I showed you in class will also work. Usually we're asking you though for stable state. So you then have to go through your truth table and find the ones that are stable. And so remember that when we did it in class with the more complex circuit, we had to look for the rows that were stable by identifying the rows with q equal to q plus. One one is a stable state, but the outputs are both zero. So the outputs are both zero, which means that when you when you let Rs go down, the bits that's actually stored depends which one goes goes down first. Right. And so unless you really understand the timing of your R and S signals, you won't know what bit is stored after you've raised both of them. And worse, if you lower both of them at the same time, you can encounter met a stable states where the thing actually oscillates after you've lowered R and S. Now there is no unstable state in this design. But if you for example, and I think there was a. So here's X or let's run that through. If I do something like this. So it's unstable. If this thing is a single inverter, right. And so since that's an X or gate, if I put a equals zero, then that's basically a wire from its other input to its output. So if I say a equals zero, then that implies, let me call this, this is p, then that implies the q equals p from that X or gate. But then looking at the other gate, if let's see if I put b equals zero, I'm sorry, b equals one down there, then p equals q prime. But I can't satisfy both of these at the same time, right. So if I look at a and b and I say zero one, then this is unstable. Right. Because if you look at these two inputs now on the on the top one, that X or gate is just forwarding its other input to its output. And the bottom one is inverting its input. So you have a loop of one inverter effectively. You can have a loop of one inverter. It's just an oscillator. Yeah, this just keeps inverting the one value and it keeps oscillating. Yeah. So that's why that kind of thing is unstable in the two large designs. There is no unstable state. So possibility for metastable state, but that's not something that our analysis will show you. So we might ask you to identify the stable states or we might ask you to identify which states oscillator things like that. You won't have to analyze the oscillator, but you might have to identify which states might oscillate. So the, you know, we can use so that we don't use as far as our lab is or as our as our lab is our lab is we don't use the two states where you both try to set and reset at the same time. And so we can build extra logic around that so as not to use those states. So if you had something that had an oscillating set of inputs, you could you can build around it so as not to use that particular input combination. And these kind of things are not really that useful in practice, but they're they let you think about well, how do these things work and identify oscillation. So we want to ask you to tell us what happens after certain amount of time with oscillations, for example, because the detailed timing questions are beyond the course. So we're trying to find that a loss away, we should be able to do anything else on this one. All right. So here is our list. So we have decoder timing diagrams and ways in sequential feedback circuits. So implementing functions with mixes. Oh, and so I guess we did have mocks is on there. Okay, so the general question I remember was how to implement a function with a mocks. So let's say that you have some function f of a, B and C. Okay, so there's a truth table. So F will have some values. If I want to implement this with a four to one mocks. And for example, I can put in a and B. So let's call those s one and s zero. Now what does output to be f. So the way I want you to think about this is, well, if a zero and B is zero, then I can simplify my truth table, right. So a zero and B is zero. I'm going to pick the zero input of the mocks. And I'm going to forward that that wire to the output f. But if a zero and B is zero, the only thing I need to look at. Is this part of the truth table right here. That needs to go into this input here. And if a zero and B is one similarly. That needs to go there. And this part. This is going to maybe get a little messy needs to go here. And this part. It needs to go there. So really all you need to do is figure out well for these little, these four little mini truth tables. What functions do I need. Clearly they're only functions of C. But if I implement those four functions and I put those four functions in as my four mocks values. That mocks will put together these four pieces of my bigger truth table into one big truth table. So let me fill in some bits and then we can figure out what functions to put there. Actually it's only one bit input right how many functions are there again. How many different functions do I have to pick from. Before right. So let's put them all. Here's one. Here's another. Here's another. Here's another. So what goes into the what function is this. It's a zero. What's this? What's this? Not see what's that. Okay. So if I want that particular f and up here. Let's see you said zero. Is this one again. C. Not see. One. So I think there is something in the homework about what if I gave you one mocks and one inverter. This input to is where you would use that one inverter. If you have a function of four variables and you want to implement it with a four to one mocks. And you also need a little bit of luck. I was it. So I've asked that question on homework that of the form of can you do it and if not proof that you can't. And I think XOR is if I remember correctly XOR suffices to show that you can't do it. And you have a four values left based on two variables. And so generally you won't necessarily be able to do it. You have a little bit of freedom in how you break up this truth table. Right. So I just picked B and C. You can pick any two. So you've got three different choices of here with four variables. You have six different choices. Right. So maybe one of those six choices you could actually implement. Whereas the other five choices maybe you can't. So you know you need to do a fair bit of thinking before you decide it's impossible to do this function. Whereas the reason I'm thinking XOR is because XOR is symmetric under that set of choices. Right. So you just show that you can't do one of them and then you're done. But really someone asked that on the exam. It's going to mean. All right. Yeah. So bit slice that or if you know the bits. I mean, plug it in. Yeah. Wasn't that one on the homework. Okay. So maybe in the interest of time, I'll skip that one because you guys have homework solutions. Right. Yeah. Anything else on this. Okay. All right. So go back to our list and we have just done this one. So MOSFETs and networks for gates. So let's take a look. So I think my mom did you ask this did you want to go over anti P type functionality or just the networks. Okay. Yeah. All right. So. Okay. So generally, you're. I mentioned this in class, but the end type and P type are duals. So we can read these off. Just as functions. The reason they need to be duals is so that we guarantee there's no shorts. So at least in a gate that will always produce either a zero or one. It will be they will be dual networks. So let's. Let's talk about why. So if f is equal to some function of uncomplmented literals. Then primed. So why do I say uncomplmented literals. Remember that the end type MOSFET. So we use it for us to connect the ground. So either it's directly to ground or it's through some other end type MOSFETs going to ground. The reason is that in order for this thing to turn on, we need a voltage between the input and this side. And so by connecting this side of the circuit to ground, we guarantee that this thing will actually stay on until it brings the other side down to ground. So if we use this connecting into VDD, then the transistor will actually turn it so far before it pulls the output up to high voltage. So we only use this to connect. We only use end types to connect to ground. What that means is that if we're feeding our input variables into the end types. Well, that means in our function, they will not be complemented. Right. So whatever we built here, unless we've got inverters in front of it, whatever we built here will be our uncomplmented literals. And then if that function holds output will have a pass down to ground, which means that F, the function is uncomplmented. So the kind of things we can build would be. The ones we looked at. So if you want an inverter, you just put one of these. Right. So this is your output. And this was say F. And this would be F equals a prime. Right. You could put more than one. So you could say, OK, let me do two of them. And this would be F equals a or b prime. Right. Because here, if I turn on, sorry, I left my connection out there for B. But if I turn on a, well, then F has a path to ground. If I turn on B, F has a path to ground. So either a or B, F has a path to ground. In that case, F equals zero. So let me get to the P type. So I just want to make sure people understand the relationship here. The other way we make constructs here is and constructs. So I'm going to put it down here, which would look like this. So this would be F equals a and B complemented. Right. Because in order to get to ground, we have to turn on a and turn on B. But in all of them, they're uncomplmented literal. So what about the P type stuff? So the P type stuff. F is going to be some function of only complemented literals. And why is that? Well, for a P type, remember that we're connecting it to high voltage. And so if we, if we connect to P type to high voltage, that means that it can actually, it's looking for a voltage from the side on the right, those two terminals, the source and the drain to the gate. And so by connecting, connecting this to high voltage, that means the transistor will stay on until it pulls the other, the other terminal up to high voltage. And so that transistor will turn on when a equals zero. Right. And so that's why in our function written from the top set it from the top network, all of our literals would be complemented. So there one I've drawn with just the one P type is, of course, the inverter. And so in that case, we have F equals a prime, which is the same. Here, and here is two. Right. And if I want to draw the complement of this one, then I would draw it as this way. And then if I were to derive that, I would get F equals a prime, B prime. Right. So if I derive that from the top network, I get F equals a prime and B prime. And that gives me F. If I drive it from the bottom network, I get F equals a or B value complement. And if you look at those two expression, I apply generalized to Morgan's law, you see that they're equal. Right. So this one is equal to that one. And by the Morgan's law. So I can do the same thing for the other gate, but more generally, these two expressions need to be equal. So the P type expression. And the end type expression. Must be equal. So if I write the end type expression, remember, I get some uncomplimented literals with the prime on the end. If I then apply generalized to Morgan's and I push that prime through all the way down to the literal level, then I've swapped all my ends with horse. Right. And instead of uncompliment literals, all of my literals will be complemented. So if you remember in class, we did that as a two-step process, which is to apply generalized to Morgan's, you take the dual. And then you apply your replace. Maybe they should say swap. Literals and uncomplimented literals. So in this case, this duality is in the structure of the network and the swapping comes from the use of n type and p type. Right. So the n type on the bottom turn on when the input variable is high, the p type on the top turn on when the input variable is low. And so in the gate structure is the dual structure is in the two networks. And so in order for these two equations to be equal, I need this relationship, but I can get that relationship algebraically by applying generalized to Morgan's. Again, the dual structure is inherent in the topology of the network. So parallel and serial or duals of one another, but you can generalize that to any function and use the principle of duality to get the structure. And then the swapping is because the n type and p type. Let me do an example. That will be specific to the problem that I want to stick to this one until we finish it. So let's do an example. So let's say that you have something like this on top. Let's say. Let me start over. What is f here? Yeah, so we have the top one on. So that's a not. And then what about that middle part? Yeah, be not or see not. And then the bottom. Okay, so we can just write it down. Now I claim you can you can just take the dual. So the dual here. Remember how to take the dual. Swap and in order swap zeroes and one so zeroes and one's right. So we just swap and in order. And then we use the ends to or and change the order to end. What that'll give me is a. I'm going to leave off the. So A or BC or D, right? And I'll put the compliment outside. So this dual this dual form gives us them the structure of the bottom network. So it says A or B and C or D. So the or is a representative parallel structures. Okay. There's BC. There's D. And I claim that if you go fill in the 16 row true stable that you'll see that this is compatible. There's always exactly one path from out either to high, high voltage or down the ground. So all I did is I took the dual and then I built the dual structure down below. Yes. Yes. So generalize to Morgan's remember you take the dual and then you flip all the literals and complimented literals which you can see here at the top. I already did that by hand. Yeah. The second expression is the compliment of the door because only because they added a prime at the end. Yeah. The the dual. Yeah. Technically the dual expression has all of the has all of the literals the same way. So the actual door is this. The dual structure down there tells us the network structure those two the bottom two expressions are equal. And they're also the two values. So if you read this one off you'll get the bottom expression. So of course you want those to be equal. Yeah. The bottom two are exactly the same. They're both equal. And if you read the top network that's where we got the middle one. And the bottom one is what you would get if you read this one off. The prime comes from using the end type and the dual nature comes from construction of the dual networks. You get one cheat sheet just like last time. What did the person who wanted to talk about the Morgan's law. I mean I would write them down if it's hard to remember them. I guess. Which is those. Yeah. And we also I'm sorry we actually do give you the properties list so this will be there. So you don't even need to read it. Write it on your cheat sheet. Very little. So I mean you need to know how to do K maps and read us of PPS stuff like that. But actually manipulating Boolean algorithm is not a skill that seems to be. Yeah. Yeah. So so two things about that. Perfect induction is is the fancy name for brute force. So I mean write a truth table fill it in zero zero zero one one good. Yeah that's perfect induction. Yeah I don't know who made that name up. Do you need to know how to how to simplify Boolean expressions with Boolean identities. No, not for a class. Yeah. Yeah. On the P types. Yeah, because remember that that they're always connected to high voltage. The P types are always used in the upper half of the network. And you and basically if the input is low, then they'll turn on. So you can always put a put an inverter, but in a logical way that's an inverter. Yeah, yeah. So just think of the way the current has to flow. Right. So if you can get a wire. If they're in series, that's an end. If they're in parallel, that's an or. In this in this setting. I'm sorry. Sorry, I still can't hear you. Taking the dual and then swapping literals and compliment is is generalized to Morgan's law. So if you want to take the compliment of the big nasty expression, you can just take the dual and then swap also literals and complimented literals and that'll be compliment of the whole. Okay. Bring any other questions down here. You You You You You You You You You You You"
    },
    {
        "ECE120-2016-08-31-LEC-05-slides.mp4": " Okay, so yeah, I actually saw your email. Hopefully, sorry to email. So yeah, sorry about that last time. So today we're going to talk about wrap up fixed and floating point, maybe do another example, maybe on the tool or something. Talk about human text representations, and I want to give you kind of a taxonomy for thinking about bits versus representations versus data types, as I'll use those terms in class. So before we get started, you know, since I taught this class a couple of years ago, somehow they took five lectures and then they took some of it out and they left three, but I still have five lectures to deliver it. So we're a little bit ahead. So I have to speak really slowly. So how many of you saw Zootopia? Yeah, okay. So if I teach like a law, yeah. Anyway, so I can't stand it. I'm sorry, I'm going to have to go back to fast mode. Oh, it's supposed to click. There we go. How many of you watch movies? You like movies? Okay. I just waste some time and ask for your help. I was talking to Robbie Iyer. He's teaching a junior senior level probability class and you're saying, you know, I asked my students to do a car no map or mention something they could use a car no map. You'll learn about those in a couple of weeks and they said they couldn't do it. And his grad student said, well, it's probably context. And they just out of context. All right, so let's talk about movies. So you watch movies, right? I need your help. So my friends will never movie club with me. So there's three we're thinking about that are coming out here. There's a Jackie Chan movie on the way. There's wildlife, there's animation. Both of those are kind of funny. And there's a Beatles documentary coming up. And the problem is that, you know, I'm a professor and they're kind of picky too. And so we have to agree in advance which ones we're going to watch. Otherwise, the deals off. We're not going to go off together. So I need your help. So here's the rules. So for me, I was in Asia. Jackie came. Jackie's movie came out a while ago. I don't want to watch it again. It was good. But I don't want to watch it again. But I do want to, you know, what's the point of a movie club if you don't go see a movie? Right. So I say, got to have one movie. But I don't want to watch a Jackie Chan film because I saw it already. If you want to watch movies before they're out in the US, you have to go somewhere else in the world where they get released earlier. My friend, my first friend here says three, so many. So I can't watch all three. My security friend's Alice and Bob. Alice says, let's watch exactly one comedy. Beatles or no Beatles is fine. And Bob says, Bob loves the Beatles. So we have to see that one. So somehow I need your help. I mean, I need you to help me satisfy all of these people. Do you have any ideas? The last two. Are you just solving a problem in your head? Can you help me? Can you help me a little more slowly, please? Can we maybe apply something? I know you. Okay. Maybe it's too easy. But not today. Okay. So this first sentence, I won't watch Jackie Chan. So it means not Jay. Good answer. Okay. So we need to translate this into Boolean, I think. So won't watch Jackie Chan means not Jay. So I need to connect that then to this other clause. How should I connect it? So don't translate it yet. What, once I translate it, what should I use? What operators should I use to connect my J prime to this next one? And, right? Because it has to both be true. Otherwise, I'm not satisfied. So I want J prime and, okay, now go ahead. What do you want this watch at least one to? So W or B. Technically, if I forget that I'm going to end it with this, it's actually all three. Right? Watch one movie is just this thing. Now you're right that the J doesn't matter. Because once I distribute this, I'll get J prime J, which is always zero. Right? So I could just cross out the J that would be the right answer to you. That's okay. And so some of you are going to skipping it and, you know, optimizing it in your heads before you answer. So that's fine. But this is not optimized. Right? Watch one movie means one of the three is true. Right? Any of the three is true in OR function. So good. Good. I think we're making progress. So you've got limited translated to Boolean. Okay. What about this next one? Three is too many. 5JW. Okay. I'll let you all think about it. So not J. Four. Four not W. Okay. Here's how I did it. Does this look like? So I claim this. So if I don't watch this one, that's fine. Or I don't watch that one. That's fine. Or I don't watch that one. Right? But one of the three I'm not going to watch. As long as I don't watch all three, that's okay. I think that's it. You know, there are lots of ways you can write any Boolean expression. So as long as your way was equivalent to this, that's fine. Okay. Actually, we'll look at good ways to write them in a couple of weeks too. Boolean optimization. All right. So Alice, my security friend. Any of you understand that joke? It's okay. You will later. The question is, when you take a security class, whether you think, Oh, now I get lamented joke from two years ago. All right. In security protocols, the two people trying to communicate securely are always Alice and Bob. So, these are my security friends. Yeah, it's a cheesy geek joke. I know. I know I give it away. I did the spoiler on the joke. So how do I set this into Boolean? Okay. Okay. So I'm hearing some Jx or w. So let's watch exactly one comedy. There are two choices. Right. So I can use XOR, the odd function to say, well, I want either J or w. Right. So Jx or w. All right. Okay. And then beetles are no beetles as fine. So that's an and. And what does that give me? B or not B. And here I simplified and I just put a one. So, yeah, B or not B would be a more accurate rendition. Which of course B or not B is one. So I cheated and put the one. Okay. What about Bob? Just B. Right. Bob says B. Anything else? Don't care. But B is not there. He's out. Okay. All right. So, we got Boolean expressions. Now we need to satisfy all four of these people. So again, the all function we need and. So pop up our handy truth table. So help me fill these in. So when I have an and. The easy way to fill in the truth table is to say, well, any time any of these functions gives me a zero. That's a zero, right? Because in order for me to put a one, I have to have all of them be true. So what you can do is go one by one and look for the zeros, fill the zeros in. Whatever's not filled in as a one. So let's start at the top. Let's take my first clause, j prime. So j prime means anywhere that j is equal to one that's going to be a zero. So this one, this one, that one, and that one. Those are not good options. Because I said I'm not going to watch the Jackie Chan movie. I'm not going to watch the options in my truth table or out. So then we'll go on to the next step. So what is this blue clause or roll out? All the zeros are zero. Yeah, good. So that's zero, zero, zero line. That's not allowed because I said, well, we've got to watch some movie. It's a movie club. What's the point? I say, hey, I had this really cool movie club. Well, what do you watch? Well, we don't watch anything. Wow. Okay. So that's that clause. What about this next one? Just the one, one, one. Right? So that's already a zero. I'll just put the little color coding. I added that late. So if you look at the slides online, the extra color coatings are not there. But that's just overlapping. That's already a zero. So. What about Alice's comedy role? So J or Jx or W. Yeah. So zero, zero, zero, one's not acceptable. Right? Zero or zero? Zero x or zero is zero. So this one up here. That's not that's not good. So there are some other ones. Yeah, the ones down. Zero one zero is okay. Zero one zero. We've got J is zero. W is one. So zero x or one is one. So that one's okay. This one's okay. These two. Yeah, those two are not allowed. And this one up here. Also not allowed. So we could add those in. But they're already zero. So let me. Add the little color stripes there. And so Alice would also rule out those. Those three. But they're already zero. And then what about Bob? Yeah, B has to be one. So this one here is out. And there's some other ones that Bob would also say no to except they're also ready zeros. So that one left. We've checked all the clauses. So that one that's left is a one. So. Got the right answer. Eric Sands was right. Okay. So you're able to apply this for useful, useful real life examples. Okay, I'm done. I'm going to watch my movies. Okay, they don't open until the second. So that's the Jackie Chan film. I'm not going to watch that one. All right. It's a good movie though. I really watched it. Yeah, I didn't tell you the name. It's a. Should I say it on video? Yeah, there's a new Jackie Chan film. It was already out in Asia. So I watched it. It's out on the second here. You should watch it. It's funny. All right. Yeah, those were all actual movies. I pulled them up off the movie opening website last night. Okay, so let's. Let's go back and look again at floating point. And I want to go through this and do a couple of examples. But. Remember that we use 32 bits to store a floating point number and I tripletly floating point. We've got a sign bit. We've got an 8-bit exponent. And we've got the 23-bit. And the. The meaning for most of the numbers is given by this equation here. And so we have the sign bit, which tells us positive and negative. We've got 23 significant binary digits. And then we've got an exponent that lets us run from about. Tension the negative 38, which is two digits. From about 10 to the negative 38, which is two to the minus 126 up to 10 to the 38. So. That was review. I mentioned. I mentioned denormalized numbers and finities. Those are not things you need to know for exams. But I'll tell you a little more about them because we do have a little time. So I added some star. I added some star. Lides. So this means not testing material up here. So if you see stars in the slides, just like if you see the star sections of the notes, that's just so you can kind of learn ahead if you want to. So if you're excited about the material, you want to know more now. It's stuff you'll probably see in later classes. But you know, feel free to read it. Feel free to look at these slides. If you feel like you've seen enough and you're getting stressed about exams, don't worry about this stuff. It's not going to be on there. So IEEE floating point was allowed was designed to allow you to have solutions to problems like dividing by zero. If you take a positive number, you divide it by zero. There's actually a representation for infinity. There's a representation for negative infinity. And there's a set of representations, anything with a non-zero mantissa and exponent 255, called not a number. So what is that? What is that good for? For one thing, if something goes wrong with your computation, you can kind of look at where the not of numbers, where the not of numbers are, and figure out what went wrong. You can also ask things like, well, if I write some set of mathematical equations, let's say that I don't know one of my original variables, what are what are the outputs that depend on that variable? Rather than looking through the code and trying to understand it, you can simply set that input to not a number, run your code, and then whatever outputs end up is not a number. Those are the ones that depend on that input. And so there's some useful things you can do from kind of a software debugging point of view. You get not in numbers when you try to do things that don't make any sense from a numeric point of view, like you take infinity and multiply by zero. So it might have been, had you not taken the infinity first, that this would be some finite value. But if you tell the computer, multiply infinity by zero, it doesn't know whether it should give you one or five or zero or infinity. And so it gives you not in number, to say, well, I don't know what the answer is. But how's that one useful extension? The other extension that I mentioned briefly because it gives you a zero, but it's the idea of denormalized numbers. So we talked about, a couple slides back to remind you, we talked about this implicit one, right, that the only in canonical scientific notation, normalized scientific notation, the only digit that we go at the start is a one, because it's written in binary here, right? It can't be a zero, so it must be a one. Now, that doesn't let you write zero, so that's one issue. But it also has this issue that, if I were not to have denormalized numbers, my smallest exponent would be zero minus 127, right? So this would be the smallest number, the closest I could get to zero, so plus or minus two to the negative 127. And then I would have, if I just had a three bit mantissa just for illustration purposes, I'd have seven digits spaced out to the next, sorry, seven bit pattern spaced out to the next exponent, two to the minus 126, right? So the numbers I would be able to represent without denormalization would look like this around zero, actually would not have a way to represent zero either, so that's a different problem. But these are the numbers that I would get. Instead, what we do is we denormalize, which means instead of having the implicit one, if the exponent is zero in the IEEE format, then what happens is you have an implicit zero, right? And so then the representation represents the numbers as I've drawn them here, so you can see it just takes these same bit patterns and it spreads them out, and it gives you actually two different patterns plus or minus zero, right? So it gives you a nicer set of numbers around zero, so that's why they included it in the spec, and you certainly need some kind of representation for zero, right? And again, the representation for zero is the all zero bit, yeah. That's right, that's right. And so there's also an offset issue that the exponent for denormalized numbers is still two to the minus 126, then instead of two to the minus 127, but the bits themselves then go down below that level, because there's a leading zero instead of a leading one. So visually, you know, there are 23 bits of mentissa, right? But that would be 8 million lines for me to draw here, so it'd be hard to understand the diagram. So this is what the three bit mentissa, I could see it a little more clearly, how it works. But the idea is to get numbers spaced around zero, instead of having numbers be scrunched up around the smallest leading one. So that's the denormalization idea, and that's why they put that into the spec. Okay, so I want to go back and just do an example. There's an example in the notes, but let's not do that one. That one you can look over yourself at your leisure. Let's instead pull up the tool, and we'll do an example. So we'll go in both directions. We'll do this one first, maybe. So if we want to convert from decimal to IEEE, and we'll convert to decimal to IEEE, what we'll do is take our decimal number and convert first the integer part to decimal. You know how to do that, I think, from very start of class. And then we'll take the fractional part and convert that to decimal. That'll give us binary scientific notation. We'll normalize that, and then we'll take the three pieces. The sign, the mentissa, and the exponent, and we'll put that into our floating point format. Before we go off and do that, here's the math behind it. So if you take your fraction, again, you can write your fraction using a polynomial. So it would be the part after the binary point. So 0.101 or whatever. So those terms after the binary point can correspond to inverse powers of two. The first digit is the half-stigit, the quarters digit, the eighths digit, and so forth. So in order to take this formula and get the individual A terms out, what we need to realize is that, well, it's a fraction, but if we multiply it by two, then it can become bigger than one. So a fraction, I mean something between 0 and 1, or 0 and smaller than one. But if we multiply it by two, it can become bigger than one. But that can only happen if this term here is a one. Otherwise, all of these others, a quarter, plus an eighth, et cetera, those known an up to one. And so if we multiply by two, the only way we get something greater equal to one is if a minus 1 is equal to 1. So we can just multiply our number, our fraction by two, and that'll tell us a eighth minus 1. So then we can subtract that term off, and we can do the same for a minus 2. Then we can subtract that term off and do the same for a minus 3, 4, so forth. So let's go do that, not for this one. Okay. Let me make sure that it's going to let you see what I'm doing. We'll go to representations and logic. Let's get a more intimidating looking one. So I'll just keep pushing new problem until we get something moderately long. Okay. How about that one? This one's a little easy because it doesn't have an integral part, but actually maybe that makes it a little more challenging. Okay. So let's figure out how to turn this into IEEE floating point. So we've got 0.5625. So our integer part is zero. So let me go over to notepad. So the fraction then is 0.5625. And so we'll multiply that by two. And what do we get? 1.125. All right. Looks right. It gets right. Okay. So that's our first round. And you can see that's bigger than one. So that tells us a minus one is one. And then we'll have 1.125 minus one, subtract off the a minus one. That'll give us 0.125. Multiply that by two. That gives us a quarter. Now that one is less than one. So that means that a of minus two is what? Zero, right? Good. Okay. So I'd subtract zero. So let me write it out. I'll do the node. I'm not going to do anything. Oops. Sorry. That might 0.25 minus zero. So I'll just be explicit. I do have to subtract the a minus two, but it's zero. So you don't really have to do this part when you do it yourself. I just want to make it clear what we're doing. So two times 0.25 is 0.5. So what's a minus three? Okay. So I'll subtract the zero again. Two times 0.5 is one. So what's a minus four? And one minus one is zero. Okay. So there are my four bits after the binary point. So the integer zero. So I have 0.1001. And that's my fraction. Let's write that down here. So if I put that in binary scientific notation, what is it? Yeah. So I need to shift the binary point over here, right? Because I need the leading one. So it'll be 1.001. And what's the exponent on the power of two? Negative one. Make that? Okay. All right. I'm sorry. Oh, I screwed it up. Sorry. Thank you. Okay. Yeah. Same thing. All I did is shift the binary point over by one, and put the exponent of negative one on the two. Good. All right. So now we can go back to our tool. And what's the sign? Zero. Okay. Oops. The exponent then was negative one. And remember that we need to have negative one plus 127, right? So we should have 126. Because we're going to subtract whatever number we put here to get the exponent back, we're going to subtract 127. So to go in this direction, we'll take the exponent minus one, add it to 126, and that'll give us the exponent value that we write into the floating point format. 126 is 7e. So this, unfortunately, had far too much experience, translating numbers, and decimal numbers in the binary. But I wouldn't expect you to do that in your head or anything. But 7e is the exponent. So let's go fill that in. Oops. There we go. So 0, 111, 111. 111, 0. Okay. Ignore that last one. We could actually go check the answer now to see that we've got the exponent, right? So the green means that we got it, right? So we filled in the sign, filled in the exponent. Those are both correct. And then for the bits, let's go back and look at our answer. Again, remember, the leading one is implicit. So this doesn't, this is not represented in the floating point format. These are the bits of the mantissa. 001 followed by a bunch of zeros. So I'll go back to the tool. Put in 001, and then hold 0 down for a while. And check the answer. And ta da, we're right. Okay. So that's it. So hopefully straightforward enough that everyone feels like they could do it themselves. We can also go in the other direction. So you can go push decode. And you get this rather intimidating looking bit pattern. But you'll notice aren't a heck of a lot of, aren't a heck of a lot of one bits. Right. And so it's not going to be nasty to you. There won't be too many one bits in the tool. So if we wanted to translate this, let's see. So the first step would be to turn this into into scientific notation. So what do we have? So what's our sign positive or negative? Positive. And what's our exponent? This one's the 128 bit. That one's the one bit. So that's 129 minus 127. So two, right? Okay. And then mantissa, we just have a one. So let me go try to write that all down. So go up a little bit here. So we have 1.1. First one's implicit, right? And then the mantissa was one followed by a bunch of zeros. Times two to the two, you said it was the exponent. So maybe I'll translate that to regular binary. So that's 1, 1, 0. That's it, right? What number is that? 6. Good. 6. So it'll give you kind of a hint because it'll tell you how many digits you need for your typing. But you can do those exercises until you're happy and comfortable, which maybe is already the case. You can use it to go back and forth and do those exercises. Do you feel comfortable with that? You like you could do it? How is it 6? Okay. So let me highlight parts. Yeah, so there's this implicit one. This part is implicit. And then this part was the mantissa. There was just a one bit in the mantissa. Let me go back and show you that. So the mantissa here are the blue section of the bits. And you can see it's all zeros except for that one one. And so the binary scientific notation, there's the implicit one followed by the mantissa, which is just one one. So 1.1. And then the exponent, remember the 128 plus the one bit. So that's 129 minus 127 is 2. So that gave us our times 2 to the 2. So that's where our scientific notation form came from. Which is here. And then all I did is I shifted that bit over by 2 for the exponent to give myself 1.1.0. And then translated 1.1.0, which has no fractional parts. So it was a relatively easy problem. Yeah. Yeah, sure. Let's get one with a fraction, right? I think that'd be better. Did you have another question? Yes. The question is, there's a negate on the tool. And what is it checking? Yes, it's checking that you were paying attention in class. Scale is kind of similar. Yeah. So how do you negate a floating point number where you flip the sign bit and then you type all those others? So that's why there's lots of 1s and 0s there, because it should be pretty easy to copy them. Yes. So hopefully you don't use this one too often. I mean, you just need to flip the sign bit. Scale 2 is, you know, if you think about this a little bit. So it does things like asks you to multiply by powers of 2 or divide by powers of 2. So you need to figure out how big a power of 2 and then just change the exponent. So some are easy, some are more challenging. Let's go back and do, let's see, oh, this one looks long, huh? Okay. Yeah, the question is whether I can do that fraction in my head. Okay. I have a calculator. So, all right, so let's do this one. So let's see, what's the exponent? That's the same one we had before, right? 126. So negative 1. Okay. And then the sign, positive or negative? Negative, good. And then for Mantissa, we've got implicit 1 followed by 4 ones. So let me go put that in. Okay. Let me show some space. Okay. So implicit 1, 4 ones in the Mantissa exponent minus 1 and minus sign in front of forgot. So I forget anything else. Yeah, yeah, yeah. So this is just scientific notation, right? So if you were to change this into non-scientific notation, which we'll do before we convert it, you shift the, shift the decimal, the binary point over left by 1 and then you'd put a leading 0 to make it look like a normal number. So this will be minus 0.11111, which is 31, 30 seconds. All right. Okay. So I'm going to cheat. And it's not really cheating. I don't really care if you know what 30, 30 seconds is. 31 divided by 32, 96875. So this is equal to negative 0.96875. And we'll go over here and say negative 0.965. Okay. Makes sense? Yeah. Okay. So part without the calculator was this. Havs quarters 8, 16, 30 seconds. Right? So this is 31, 30 seconds. Yeah. Yeah. The fraction is 31, 30 seconds. Yes. This is a half quarter in 8, the 16th and the 30th. Yeah. Yeah. So all I did is I converted that to 31, 30 seconds. I think someone in the audience said, you know, that's 31, of 30 seconds. So yeah. So I took that and took the calculator, 31 over 32. And it told me this answer. If you happen to know what a 30 second is and you can subtract it from one, you can do it that way too. I'd have to think about it for a minute. Okay. All right. Let's go back then. We'll skip over this part. So let's do this one. Okay. So here's a question for you. What is that? Anyone? Now you're nervous. Do the minus 30. Okay. Good. What's this one? Really? It's not what my computer told me. Okay. I'm hearing that makes sense. I mean, to me, I'm not sure it makes sense, but that's how floating point works. So let's explain why it works that way. So first sum in that second problem was to the minus 30 plus one. So you want to put the one, your exponents got to be zero, right? That's to hold that integer one. You need to have that be the leading term in your binary scientific notation. Well, so we got 23 anticipates. What are those? Those are powers of two down to two to the minus 23. So if you add in two to the minus 30, it's got no place to put that, right? So two to the minus 30 just kind of falls off the end. It's too small. So two to the minus 30 plus one is one in floating point. And then yeah, one minus one is zero. That's exactly right. So floating point is not associative. So this can be a problem. It's a very hard problem, actually. There are, I've seen people whose work is computational science. You know, sometimes not realize that this kind of problem is giving them wrong answers. And I could tell you actually quite a few stories about that. There are fortunately some very good numerical analysts on this campus over in CS. So if you're interested in understanding exactly how to deal with these kind of problems, I would strongly suggest you take a numerical analysis class from them. My key, if you used to teach them, but he's retired now, was also one of the best teachers on the campus. So I think there's some good classes you can take. So the question is, does the non-associativity effect speed? No, the non-associativity, I'm sorry, the speed is due to the fact that you're simply doing a much more complex operation. So if you think about it, if I were to ask you to add two floating point numbers, what would you need to do? Right? You'd have to look at the exponents, line them up, add them up, decide how to round, right? So there's actually quite a bit of complexity. Yeah. And because it's more complicated when we build hardware, it tends to be slower. So yeah. What happens to the speed? Yeah. So the point is that this can't be stored together with the number one, because there's only 23 bits of mentissa. So when you add those two in a floating point, add, or the output has to discard that two to the minus 30 term. And anything else in those other ones as well. Now there's one slight difference. If you had one at two to the minus 24, then it has to decide whether to round up or round down. Right? But if it's not two to the minus 24, then it's going to typically just throw it away. I guess if you rounded up, maybe it would add it in. Yeah. So there's a rounding direction. I don't want to spend too much more time on this, but there are five different ways to round things. And I tripling. I think it's five, maybe it's four. But people were seeing in one computation of weather prediction, and they were seeing 30% differences in the final answers. And they traced back why. It turned out one machine rounded up, the other machine rounded down, down at the negative 23rd power level. So they can't explode. They can be sort of chaotic behavior if you're not careful with your applications. All right. So here's hexadecimal. I want you to memorize this bit pattern. Do it quickly, because we're now running short of time. We always use bits, but for us humans, we can use hackedadecimal, base 16. So you got that bit pattern. Good. You're already right? Got it? Okay. All right. So here's hex, 16 digits. It's base 16. So that means each digit represents four bits. So each of the, we add in a through raft. So a is 10, b is 11, so forth. And it's just a way to help us humans. So to make it easier for us to deal with bit patterns, because we can look at just digits instead of a lot of zeros and ones with your hard to remember. Although I know you're good at it, because you memorize that bit pattern. Okay. You're making it up. Okay. So try it again. This time do it in hex. When we write hacks, we usually have in human form, we usually put some extra things, because if I just wrote 13567, you'd think I meant decimal, right? So usually we'll put something else in front of it like an X, for example, to say, hey, this is hex. Okay. So this is all base 16 numbers. In C, we'll put another zero in front of the X. But in patent Patel terms, just put an X in front. So, so that's hex. How do we represent text? Text was historically represented using an eight or seven bit code called ASCII, American Standard Code for Information Interchange. But it was basically designed to represent English, right? So we have English letters, upper and lower case, Arabic digits, punctuation, some special symbols, like a dollar sign, a pound sign, hashmark, if you want to call it that, control characters for terminals. So people designed this code 50 years ago and kind of standardized it. That became the thing everyone used for human text. Once most machines had eight bit bytes in them, then most machines said, well, gee, we can do something with the other 128 patterns. So there were these extended ASCII character sets for graphics and things like that. But those more or less were not standardized, meaning that every machine had every, every manufacturer had a different meaning for those extra 128 patterns. There were standards, but no one really built machines to them. So other languages, other human languages, kind of caught on after Illinois invented the browser in 93. So MIT's media engine will tell you differently, but you should know the truth. MIT puts a lot of money into making you think that, so, but you're an Illinois student. So Unicode is the 16-bit modern form that includes most human languages. Right? So Unicode will capture most other languages in the world. And that's the other one that probably I'd want you to know about. We'll try to differentiate in our class between representation and data type. I may have mentioned this before, but I want to, I want to use representation to describe a way of describing or turning something like signed integers into bit patterns, but not necessarily for a specific length. Was the data type will have a specific number of bits. So for example, we can talk about 32-bit unsigned or 64-bit unsigned. Unsigned is the representation, the 32 and 64 bits. Those would be data types. The reason I want to make that distinction is when you get into, into higher level languages, every variable that you use will be associated with a data type, meaning a specific number of bits. But the representations in many cases are just ways of encoding information into some variable number of bits. So I'll show you this taxonomy that I dreamed up to try to help explain what I mean. So they're bits and we use bits to represent everything. So whatever you want to represent in a computer, you know, everything we've done and vegetables as well or ice-cooming flavors, you're going to use bits. For everything you might want to represent, there are different ways to represent them. So for non-negative integers, we looked at unsigned, we looked at a couple of ways to do just general integers. There are actually many floating point formats. Iterpli is kind of the more modern standard that all the computer's implement today, but there were other forms. There's fixed point as well. There's ASCII, there's UNICODE, and then there's data types where we say, okay, fix number of bits. So for each of those, there are particular data types that we have particular number of bits. So this is kind of my attempt to try to help you organize some of the ideas that we've been playing with in the last few days for the last couple of weeks. So most of the time, when you open a text file like you did in your lab, for example, everything in there is going to be either an ASCII or UNICODE. So human text is generally going to be represented either ASCII or UNICODE. What you type is going into ASCII, going into the computer in that form. Text is printed for you to read, comes out in ASCII on your monitor or in UNICODE. But the computers don't understand what those bits mean. So when bits go in and out, they're just bits to the computer. So for example, if you tell a computer, hey, I want you to add the ASCII character for three, the number three, but it's the number, right? It's the ASCII digit three. I want you to add that to two. What do you think the computer will do? You don't add the bits, right? You told it to add the bits, it'll add the bits. You didn't tell it it was ASCII, you said, add the bits. Okay, I know how to do that. So, oh, sorry, it's going to let you help me. One plus zero. One, good. One plus one. Zero, carry the one. One, zero, carry the one. One, carry the one. You know what that one is? No, it's not an overflow, it's the letter E. You thought natural log was hard. Natural log is fired. Okay, yeah, don't tell computers to do that. The right way to do that is, is, you know, you need to do some in software, probably to convert your ASCII to two's complement or unsigned. Add those two numbers using an adder at that point and then convert it back to ASCII if you want to human to look at the answer. So, it's more steps involved to get it right. Yeah, there are other classes where sadly I've seen people struggle with this where they write this kind of code and high level languages and they can't understand where the computer's not doing what they wanted. Hopefully, none of you will ever have that problem. Wow, good job. Excellent. Okay. I'll get to the point. I won't really give you any any exercises that like memorize this thing. Sorry, it's not a learning objective. But it's a lot easier. It's a lot easier to remember fewer digits than to represent remember lots of zeros and ones and what order to put them in. So one more thing before we wrap up for the day. So, so this is it and then we'll do C coding on on Friday. So, remember this overflow condition, we could give it a name. Let's call it B that we developed for two's complement. So I said that well, there were two cases and we actually wrote it originally in words and then we wrote the Boolean expression for it. So, remember that we had two ways to overflow, right? If we wrote our addition this way and A was the sign bit of one opera and B is the sign bit of the other and then S is the sign bit of the sum. Well, if I take a one in A means A is negative and B is negative and the sum is not negative, something went wrong. Add two negative numbers, get a non negative number, something went wrong. Or if I take a non negative A and a non negative B and I add those up and get a negative sum, something went wrong. So those are the two cases that we had an overflow. And I said you should go read the proof. You did that, right? In the other lectures, they were told the different formula. They were told that if I instead look at the carry out of bit n minus one, the one that would feed in to add to a plus B, if I look at that and I X or it with the carry out, that gives me overflow. So my question for you is, well, are those the same? Who could use algebra? Want to use algebra? Not really that fun. I did it. It's not that fun. So what about some brute force here? Brute force. Yeah. So this is true of a truth table. So we can calculate, if you think back to that sum, if I know cn minus one, I can add that to A and B, that'll give me S and cn. If I add those three digits, I get the other two. So really only three variables. So that's only going to be eight lines. Well, let's do the truth table. So here on the left, I have the different possible values of the A bit, the sign bit of the first one, the B bit and cn minus one. So if I add those three together, that'll give me a sum and then the carry. So what's zero plus zero plus zero? Zero carry zero. What about zero zero one? One carry zero. Zero one zero. Zero one one. One zero zero. One zero one. Good. One one zero. Good. And one one one. Okay. So now we can go calculate what we used as overflow. Right. So if we have A and B the same, but S different than A and B, then that's an overflow. So the first line we have A and B are zero, but S is also zero. So that's not an overflow. Here, a second line, A and B are zero again. S is one. So that's an overflow. Okay. Here, A and B are different. So we don't have to look at S. Zero one zero, A and B are different. A and B are different again. Not an overflow. Different again. Not an overflow. Different again. Not an overflow. How about this one? It's an overflow, right? A and B are one, but S is zero. So that's an overflow. And what about the last row? Not overflow. A and B are one, but S is also one. So all the numbers are negative. That's okay. All right. So now X or the CN minus one and CN for me. First row, zero. Second row, one. Third row, zero. Fourth, fifth, sixth, seventh, and eighth. Good. So we're done. Same columns, right? We just proved that the two are the same. Just fill in the truth table and compare the columns. They're the same function. Don't need to do algebra. All right. So that's the message. In a lot of the Boolean stuff, you know, you can do algebra. You can prove by manipulating algebraic forms, which may be easy for you, especially if you do it a lot. But you can often prove things by pure algebra. But you can also, in many cases, simply write down a truth table. And if you're talking about two or three variables, that's four or eight different things to plug in and say, well, are they the same or not? So you definitely want to pick the easiest and fastest proof strategy and, you know, brute force, especially in these kind of problems, is often something you seriously want to consider. Because you can get it done quickly and easily and have a correct proof. So let me leave you there. I guess 45 seconds early. Thanks. Thank you. You You You You You You You You You You You You You You You You You You You You You You"
    },
    {
        "ECE120-2016-10-19-LEC-23-slides.mp4": " you you know I knew mid So today we're going to do, start talking about designing finite state machines using components. So the first thing we'll do is take our keyless entry design and add a timeout. So we'll use our counter to do that. And so we'll talk about how to do it and then show how we can do it without actually even knowing what the implementation is. So we'll use whatever you came up with. So remember I left that open for you to do the next state logic. And we'll just take whatever your next state logic was and extend it using a box. So then we'll do a vending machine. So both of these are just examples taken from the notes. So you can look there for more detail if you want. So to get started, first I wanted to just remind you that, you know, when we did combinational logic design, the first thing we looked at was just taking it all the way down. We did truth tables into K maps. We solved K maps for good forms, either SOP or POS. And then we took those and turned them into gates. So, you know, we can always go down to that level or even lower. We can optimize at the transistor level if we want to. But it's often easier to build combinational logic with components. So we can pull an adder off the shell for a box, a decoder, whatever, comparators. And then plug things together and then just kind of get the meaning and build it pretty quickly. Won't be as smaller as fast, but it will be much easier and much less likely to have errors. So, with, so we can do that with combinational logic. We can do the same thing for finite state machines. So we can always go through the way we've been doing it. And so, okay, for each state, we're going to draw a circle. We're going to think about how many states there are. We're going to, you know, do log base two, round it up, figure out how many flip-flops we need. Assign just as many bit patterns as we need. And then, and then go from there, do the logic with K maps, et cetera. But we can also organize them hierarchically. Right? So we can think of a circle as representing a bunch of states. And we can think about motion between those groups of states. And we can build our finite state machines up hierarchically. So to do that, we can use both combinational logic components, things like mention on the last slide, adders, comparators, mocks, and decoders. But we can also use things like registers and shift registers. Right? So registers and shift registers can hold part of our state for a finite state. So let's go through the keyless entry just to remind ourselves of what it was in terms of inputs, outputs, state machines, stuff like that. This is a week or two ago, right? One midterm ago. So as you may recall, the finite state machine design only reacted to user input. Right? So we had unlock, lock, and panic buttons, which if you have one of these things, I happen to have one in my pocket. The little red panic button on there actually might as a trunk button too. So if the user pushes the panic button and didn't do anything else, then the alarm would stay on forever. So or until a car battery dies, whichever comes first. So let's modify that design. So let's make the finite state machine actually turn the alarm off after some amount of time. So if you start if you push panic, the alarm starts sounding, and then you walk away. So maybe you were just out of hearing range and you pushed it. Your car starts making loud noises, but you don't notice it. So you go on to your into your lab or whatever and you come out 12 hours later and your car battery is dead. So instead, let's say 12 hours, maybe 12 hours. Make the make the finite state machine turn it off after some time. So the output for a keyless entry system. So just to remind ourselves so we had D R and A. So that was D means if it's one that means we've unlocked the driver's door, zero would still be locked. The other doors, all the other doors controlled by this R signal one again means unlocked. The alarm is on when the a signal is one. So those are outputs. So our inputs were unlock button, lock button and panic button and we get one women's press for the user and zero if it's not. So then we had our state table. This is just the state table with that. So we had four states. The lock state, the driver state, the unlocks state and the alarm state. And then these are the outputs for each of those states over here and the representation we picked for the states. And then this thing is our full state transition diagram. So I color coded these when we built it up. So maybe I'll just go through them color coded again. So the normal protocol of walking up to your car and unlocking it and maybe you know, someone else is with you. So you unlock it again. So the first time you push unlock you go from the lock state over to the driver state and then you push it again you go from driver down to unlocked and you can keep pushing it if you want to, but you stay stay in that state. So I guess I left this loop off. There's a self loop here for staying in the driver state if you don't push anything. But if you push the lock button that has second priority, actually second to panic, which are the red arcs. So if you push lock, it doesn't matter whether you push unlock. So this is an extra for the you input here. But all the black arcs going to the lock state. And then similarly the red arcs out of all the states into the alarm state. So if you push the panic button, we said that has the highest priority. So regardless of what's going on with the other buttons, XX1 and you will PRX, they'll go into this alarm state. So that was our design, our initial design. So what exactly do we want to do with that. So after user turns on the alarm, we want the finite state machine to start measuring time. And then once a certain amount of time has passed, the finite state machine should turn off the alarm. So how does it how does a fight well in what unit can a finite state machine measure time. The question or answer. Yeah, so that's the same thing I'm trying to describe. So my question for you there is the same. How can you measure time. So what component can we use for that. So I'm going to ready set it. So we can use counter. So you can use a ripple counter. You can use a binary counter. I'm not even going to look at the counter. I'm just going to say there's a counter. We know how to design counters. I say we'll look at the counter a little bit. So we'll use a counter. So we're going to use. So it's a down counter. So it's going to count down. We're going to put in some value from the top and we'll decide what value later. I should have the next slide. But we'll put in a value by putting this load input equal to one. So when we set load to one, the counter will load a new value. And then I'll start counting down from that value. When it gets to zero, it'll produce Z equals one. So this will count some number of cycles for us. And after that many clock cycles, it'll generate this Z equals one signal to tell us, OK, the time's up. You know how to build one. And so if I said, OK, get out of this paper, I'd expect you would all be able to do this for arbitrary size counter. It's just going down instead of up just the binary counter. So the counter gives our finite state machine some new inputs and outputs. So first of all, we've got this output Z from the counter, which is an input to our finite state machine. So that's a new input. And then to control the counter, the finite state machine has to output this LV signal to tell the counter when it should load a new value. And it has to somehow set the counter input value. But I claim that the counter input value is just going to be a fixed timeout. Right. We're always going to have the same time out when I'm going to say, well, this time, let's make it five minutes next time, let's make it 13 minutes. Well, now seven minutes, right. It's always going to be the same amount of time. So it's just hard wire the value input. So some T cycles, I'll set T minus one is the counter input. So the number of bits in the counter then depends on T. If we're going to load T minus one into the counter, the number of bits we need depends on T. And that in turn depends on the clock speed. So I pulled a 16 bit microcontroller from TI off the web. And it's clock speed was 16 m. So if you go by one today with the typical clock speed. So if you want a five minute time out, well, that's 300 seconds. And the clock speed is 1.6 times 10 to 7 cycles per second 16 megahertz. So you need this many cycles, 4.8 billion cycles to count. So you need a 33 bit counter. And once it's counted to 4.8 billion or down from 4.8 billion, five minutes have passed. I got that right. That's big. But you know, 33 bit counter. OK, so I couldn't fit those many circles on my slide. So I'm going to draw a few. So let's use those counter bits, which I'll call timer to split the alarm state. So we had one alarm state. So now we're going to split it up into, I guess, for almost 5 billion states. So we'll have lots of states. When the user turns on the alarm, the system will enter the alarm zero state. That'll be the first alarm state by setting timer equal to T minus one, which means just setting load high. And that'll force the counter to load T minus one into the timer bits in the state of the counter. And it will be done. So we've got a few states here, I guess, almost 5 billion. So if it's dot dot dot is 4,990. Yeah, anyway. So that's what we're going to draw it is. Right. So we've got the alarm zero state on the left. And there we've loaded the timer bits with T equals one. So this is the first alarm state. And then after a cycle, we go to the second alarm state alarm one, which has time or T minus two. And then we just keep going and going and going. And eventually we might reach alarm of T. I guess that should be T minus one. Sorry alarm of T minus one, where time or equals zero. And that would be the state where the counter output Z equals one to say it's reached zero. So this is this is why I said it to T minus one. This should take T minus one steps to get to there. And then once Z equals one, the finite state machine can turn the alarm off. And so that's T cycles after you've turned it on. Yeah, if you had a 16, so going back a slide, if you had a 16 megahertz clock, T would be this. Yeah, 4.8 billion. So it's a fairly large number. That's for computers. But for us. All right. Now, so before we had S1 and S0, right, so in all of these states, we're going to keep S1 S0 to be the alarm, the original alarm representation. So when S1 S0 equals zero, one, that still means alarm, right, our output logic will be the same. Actually, the logic for all of the states except the alarm state will be the same. So we're going to replicate all the outgoing arcs from alarm because we've already got logic that takes the system out of the alarm state to other state when when things like you push the lock button. So if you push the lock button, you want to go to the lot state. So that was an outgoing arc. So for each of these states, we're going to have an arc labeled ULP X10, meaning we don't care what unlocked was, but if they push law, then we're going to go to the to the lock state. So if the alarm has been going off, doesn't matter how long it's been going off, you push the lock button, the car locks alarm turns off. Just as before. So what if the user pushes panic, what should we do? So the alarm's on and say two minutes have gone by and they push the panic button again. We should reset. That's what I thought to. I mean, you could just let it keep counting down, but then, you know, every five minutes if they're still panic room for some reason they have to keep pushing it. So let's go ahead and reset it. So what does that mean? Well, that means all of the transitions with ULP XX1, anytime they push the panic button, which I didn't draw here, but anytime they push the panic button, they go back over to the left side. So they're going to reset the timer back up to team minus one. And then the time the timeout will actually happen five minutes or whatever we represented five minutes after the last time they push panic. That's where the system will turn me alarm off. So you've noticed I've added or you may notice I've added these down here as well. So now that we have this arc, I'm not showing with XX1, then we know the left over the motion between these states is when you don't push panic or unlock. Remember, this is ULP. Unlock, remember, we decided when we did the original design, we decided that unlock would not affect the alarm. Right. So if you push the unlock button, it doesn't turn the alarm off. So similarly here, if you push the unlock button, it doesn't matter. You just keep counting along and eventually you'll turn the turn the alarm off automatically. So what happens then when the timer reaches zero. So the counter is going to output Z equals one. And the finite state machine can use that to leave the alarm state. So where should it go? Locked. Okay. So why not unlock the driver. Yeah, it's probably not a good idea. Right. I mean, it's a design decision, but you know, you turn your alarm on and you walk away. And then when you come back, your cars are locked. So that's the best thing. Right. All right. So sometimes design decisions, they seem like there's a good answer. Right. But no one would think about it. It's just the right answer. All right. So let's say locked. So we'll add that in. We'll add that in down here. So I've added this little arc saying, well, once you, once you time out that transition that turns the alarm off, we'll go back to lock state. All right. So that's the design so far. So we're going to treat these other states as just single states. Right. I mean, the bits are there in the timer. The finite state machine state now consists of let's say 33 extra bits. But we're not going to even think about well, what about the driver state, right. It's now four billion states also. Right. But it's okay. We're just going to treat it as one group of states that has the same behavior. And no dependence at all on these timer bits. Same thing for locked, same thing for unlocked. Right. They have no dependence at all on the timer bits. Oh, yeah. That's a good. I'll let you do that on an exam. Maybe that's a good question. I don't know what to say. I actually did put that on an exam. But maybe I won't do it for you now. But I was surprised because I put it on an exam and then, you know, of course, I wanted to solve it before I put it on the exam. And I found that it actually further simplified the design. I was very surprised. So yeah, you can use the same timer to say do something as I've been suggesting that, you know, after you've unlocked the doors, maybe they automatically lock after a certain amount of time. It doesn't have to be the same. Right. If we picked a different time, say, Q, what will we do to decide whether to put Q or T into the counter amongst right. Yeah. Can you have asynchronous finite state machines? Yeah, you can. Yes, you can. And I mean, the finite state machine abstraction in general doesn't need to be synchronous with a good anything. But in our class, we're only looking at digital systems based on clock synchronous. So I mean, in any real world system, where time is a continuous variable. So, you know, when we model aircraft behavior, things like that, we don't model it as a time dependent anything where there's rates of change also. So, they're not synchronous. Okay. So, so the states are split that their behaviors independent. So we're going to keep treating them the single states and not worry about it. We could we could use the timer for other purposes. We could use it as advice suggested to turn off the or I'm sorry to lock the doors after certain amount of time, but we don't have to. So, we think about the implementation. Can we use the old design? Yes, we can pretty easily. We just have two things we need to think about how to do. Right. So if we have the old design, we put the timer down the counter down, I should say. So, well, first we need to set the timer to T T minus one whenever we enter the alarm zero state. And so if we enter that state, we need to make sure the timer bits are accurate. Right. The counter, I should jump down the counter is actually going to handle the transitions between those states, right. It's the down counter. So every cycle, it's just going to count down. That'll take us from alarm zero to alarm one to alarm two, etc. So we don't need to do anything there. Right. The counter already has that logic. To move from alarm to locked when Z equals one. So somehow we have to set up logic somewhere in our next state diagram or next state logic to make sure that when we hit alarm T minus one that we take the system from alarm to locked. We'll know when to do it because we'll see the equals one. Alright, so let's look at this first one. So we want to set the timer to T minus one when alarm zero is entered. So remember that we decided when are we going to enter alarm sub zero. Well, anytime we press the panic button. Right. So what signals should I use to load the timer. Just P. Right. If I just do this. I put up. Sorry. If I put P into L.D. Right. Then anytime you push the P button in the next cycle, the counter will load T minus one. Okay. So as long as we also make while we already know actually in the original design, whenever you push the P button, you're going to the alarm state. I guess this solves the whole problem. Right. The other logic for going into alarm sub zero is already part of our state machine. We've already got the logic to go S one S zero equals zero one. So now we also have the logic here just by putting connecting P to L.D. We also have the logic to make sure that we're going into the alarm sub zero state anytime you push the P button. So that serves both to enter the alarm state as well as to reset the timer if you're if you're pushing it again. Pretty simple. Alright, so we're half done. What about this one. This one's a little trickier. So we want to go from alarm. So the alarm is S one of zero zero one over the locked, which is zero zero when Z equals one. So we only need to change S zero. So how can we do that? Is there an easy way or do we need to go look at the big state table and add another variable. We had five already. Do you want to do a six variable came up? Okay, so do you think of a way that I can I can somehow I know choose between the old stuff and the new stuff. I like I like the besides something. If you put a if you put a flip flop in the middle, you're going to end up delaying things by a cycle, right? If you use that as state. Maybe. Yeah, I think I think I'm hearing mux and mux a couple places. So let's just use a mux. So we've got the thing that you were supposed to build on your own right this original S zero plus logic right we showed you the table and I said, okay, you know how to do this stuff. So I'll leave it to you. Let's say someone's done it right. So we've got that. We'll just put the zero input of the mux from there. And we have the one input of the mux be zero right. And when we want to go when we want to force the system to move from alarm to lock will set the mux selection input to one and it'll go to that state. And then otherwise that the mux select input is zero. It'll just act as it always did before. So all I did is kind of push the problem around a little bit right. So what controls the mux select. So when do we want to go from one to the other. So one I put that last. So remember that one. What else needs to be true to force this transition. Yeah, no panic right. What about other buttons. So unlock we decide to ignore right. Okay, so lock unlock doesn't matter. What about lock. Yeah, it turns out it won't matter either, but. But in terms of the transition that we're adding, we said it was you'll P equals X zero zero right. And what about just being in this alarm state. What is the alarm state. Zero one right as one as zero zero one. So we don't want to force. If we're in some other state, we need to be a little careful. We don't want to force this. This S zero to zero for in some other state. Right. So I would argue the first. The first thing we need to make sure is we're actually in the alarm state. So for in the alarm state. So this is the state. Right. So all I really did is I read, okay, I want to go from alarm to locked. Here's the state that I'm starting in. Here's the transition label. And by the way, I wanted to add this thing, which is the other thing people mentioned. Right. So this thing says, okay, the timer has not counted down to zero. So if I put all those three conditions together, I get S one prime S zero from this. I get L prime P prime from from the transition label and I get Z. Now, as someone already mentioned, if we press L, we're also going to locked. Right. So our system is already going to do that to us. So it doesn't much matter if we just drop the L prime. If we drop the L prime, this is this is going to give us the same behavior. Alright. So here's the diagram. So you'll notice that encapsulated the S one plus and S zero plus logic in these little boxes, right. Whatever someone already solved, that's all done. It's just a box. It takes you LPS one and S zero. And it calculates next state for S one plus calculates that next state for S zero. Sorry, which is S zero plus. And those would have normally just gone into S one's D input and S zero's D input. And that was our final state machine. Now we've added our counter. We've taken P and connected it to the load input as before. P equals one hard coded bits into the counter parallel load input. And then down here, we have Z equals one ended with P nodded so P equals zero ended with S one nodded ended with S zero. And that's our max control signal. So if that thing is on, we want to force S zero to be zero, which we do. If this mux input is one, you get the zero and put that into S zero. Otherwise, you've got a zero on the mux select. Then S zero plus just goes in there and the then the finance machine acts like it used to. So what we needed was a counter a couple of inverters and and gate in a mux. Any questions. And the other logic is also the same. I didn't draw it on here, but we don't need to touch it. So whatever, whatever we calculated before we just keep the same output logic. So there are two examples. We won't go through all of them, but I wanted to do at least one. So I think we'll start this. I doubt we're going to finish it today. So this is a vending machine. It's more more complex than the more complex than the one you do in the lab. So it's a more realistic vending machine. So we're going to show you how you can build things out of components. So we're going to use a few different components for this vending machine. We'll have registers, we'll have adders, we'll have muxes, we'll have decoders. We're also going to develop a new component priority encoders. So priority encoders are often used for things like deciding which device gets attention when you have multiple devices and one processor. So you prioritize them and you put the inputs about getting attention from the processor into priority encoder and outcomes and encoded number saying, well, this particular device you should look at now for the processor. So and we'll also do one little module specific to this fsm design, which will translate an input representation into into a value for us, not unlike the one on the midterm last night actually. So let's assume that we've, we're going to sell three items. So why three. So every item we put into our machine is going to have a price. So we have to keep track of that. We have an input to identify it like a button. So when you have your vending machine, you have to be able to buy that thing. So usually going to have a button or some set of buttons that scale up with the number of things you could buy. So you also need a release mechanism to drop that product when you buy it. So if we, if we choose three items, it's, you know, big enough to be interesting. So all of the pieces will have to develop. We'll have to think about and think about how we would scale. But it's small enough that we can fit it on slides and kind of show you easily. So so that's why the vending machine will sell three. So once you understand this implementation, you could pretty easily say, well, I want a vending machine that sells 100 things and just go extend those. It's not that hard. So let's think a little bit before we start. You know, how is our vending machine going to work? So I claim this is kind of a general protocol for vending machines. So you walk up to the machine, say you're the user. You look through the items, you say, OK, I want that thing. It's probably do or metallic or something. And you see you want to buy it and the you then put some money into the machine as the next step. The machine has to keep track of how much money you put in. So we need some state in the machine to do that. When the user has put enough money for the item, then you know, user pushes a button. So this is our expected protocol. This is the abstract model design process, the first step of designing a friend state machine. So you push your button and then the machine checks, of course, how much money you put in and it sees you put in enough money releases the item for you and deducts the price of the item from how much is stored inside of it. So you have to keep track of that too. Often, most machines you'd encounter with them, you know, give you back all the money that was left. Our machine won't it'll just keep your money and hope you'll buy something else mostly for simplicity. We won't do this last step. Readyed out. So what's going to be the main state of the vending machine. Okay, so let me, let me ask this a little different way. So yeah, I mean, if you get no input, you'll stay in the same state in the couple of meetings of state. So what I meant here is is what information does the vending machine have to keep track of. So the main thing is the main thing. So simplest answers, maybe how much money is being stored. And as people said, you know, if we don't do anything to it, it'll store the same amount of money. That amount will only change when the user pushes buttons or puts coins or bills and there's something. So let's use a register. So when the money is inserted, we can use an adder. You put some money in, got some money there, put some more money in how much money is all they're all together. Well, why don't we just add it? Well, store is a number. We'll add the new number, put it back in the register. So what about when I buy something? What should I use? So subtractor, right, which is also an adder by the way. So so when we want to make a purchase, we'll subtract. We'll just represent the amount of money as some integer. And then when we put money in, we'll add to that integer, put it back in the register. When we buy something, we'll subtract from that from that integer, put it back in the register. And so those are some of the pieces we'll use. So how much how much your products usually cost in a vending machine? A couple dollars there. That's what I thought to so one to two dollars. I've seen them up at like five to $10, but I don't go back to those running machines. So how much money can the machine store? What do you think? Okay, yeah, I said two to four. So let's probably about enough. We can make it bigger pretty easily. Coins or bills are both. Yeah, probably, probably both. Or credit cards, even better. Our answer is going to be coins. It takes up coins, but no pennies. So so let's come money and nickels. Okay, so the amount of money will store will be a number of nickels. So our state is a register and which is the number of nickels stored. I just really like nickels. I just wanted to have it doesn't actually matter much at all, right? So I wanted to have a variety of variety of values that were around the cost of an item. And so, you know, if you put coins in, then those are all are close enough to the, you know, somewhere under a dollar up to a couple dollars cost. So give some variety. That was why to make it more interesting. Plus I can use the end for the register. I needed other letters for other stuff. All right, so the machine we said should store a few dollars. The value then is in units of five cents, 0.05 dollars. So N should hold maybe 40 to 80. So let's just have a six bit register. Again, you know, you can take this design, you can make it eight bits, you can make it 20 bits if you want pretty easily just cross out the sixes replace it whatever size you want. Right. So it's pretty, pretty easy to extend this. So in this case, the maximum is 63 or $3.15. So that's what our machine will be able to store. So we have to pick something. It doesn't, doesn't much matter for the design process what we pick. But we have to pick something when we build it. So what about item prices? So these should be easy to change. Right. So we could, we could say, OK, for to make our design easy, we could hard code these design hard code these prices. So item one will be a dollar item tool, be a dollar 50. But instead, let's keep those in registers. It's will throw some more six bit registers in to hold item prices for three items. Whoever owns the machine can then set the prices. And I wanted to also introduce this idea of extraction and the sense that we're now going to design a finite state machine where decisions will be based on numbers. But those numbers will actually be in registers. So we won't be able to even know what exactly transitions do we have without thinking about specific values of these registers. So we're actually going to extract away the notion that well, we have to look at every arc. I mean, every arc has to be specified will actually specify them in terms of unknown values. The values are there in registers, but we have to read them out to use them. So the prices will be stored here in registers P1 or rather as values P1, P2 and P3 will store those in six bit registers. So those are state. That's another 24, I'm sorry, 18 bits of state there. But again, we're going to extract those away for the most part. So we're going to design our finite state machine, assuming that our prices are constant, but they're not known in advance. So they're just going to be numbers. So the user will set the prices and then the finite state machine will operate. But we won't know what those are until we're actually operating. Okay, so now we have a model of what we want to do. We can start to draw an abstract state table. So here are a couple entries. There's a more complete table in the notes with all of the possible inputs. So here's just an example. Well, so here's the first one that someone, someone already mentioned. So if nothing happens, if the user does nothing to the machine, this is, oh, sorry, all of these lines are coming from state N. Meaning that you've got N Nichols and you nothing happens. So they don't push any buttons. They don't put any money in. Then what happens is you always stay in that state. You don't accept any coin or rather this access. I don't care if the coin accepts signals. Yes or no, because you didn't put a coin in. And you don't release any profits. Right. You don't just drop products out. If you want to know how. All right. So it would be nice, but maybe not to the owner. So the other thing here, I want to mention now that the condition. Right. So you can see there are two input events quarter inserted. So what actually happens depends on the current state. So well, there's a design decision and posted here actually in the answer. So what should happen. Do you think if, if you know you've got what do we say up to three 15. So you've got three dollars in the machine. You put a quarter in what should you do. Steel the money. Okay. We need to change this. Yeah. So I've used those machines too. But we're going to we're going to design a nicer machine. Yeah. I've used the machines where you don't have to have three dollars. You can have nothing and you put the quarter in it. It just goes away. So we're going to have a quarter. Now, but if you're going to overflow your register, right. If you're going to go above 63 instead will just return the coin. Okay. So this is checking right a quarter is 25 cents. So it's five nickels. So if you add five to 59, you get 64. So we don't have space for that in our six bit register. So if n is greater or equal to 59, then we'll stay in state and reject the coin. So we'll send the quarter back. We still want release a product. On the other hand, if we can add five, the value of the quarter to n, then we'll go to state n plus five, keep the coin. And also not really sending products for coin insertion. Okay. So here's another couple of examples. These are for the product selection. Again, there are actually same things for item two and three. All of these are in the in the notes. If you want to see the big table. So again, starting from state n again, two choices and then this condition. So in this case, what we do depends on whether n is greater or equal to the price of the item that the user is trying to pick. So here the user is trying to pick item one. So if the money in the machine n is at least as big as p one, we're going to sell them the item. So to sell them the item, we make two changes. First, we subtract p one from our current number of nickels held. So we go to state n minus p one. And also release the product number one. So we give them the product and we take away their money. Except coin doesn't matter here because we're just doing the abstract model. So there is no coin. And so we just don't care. On the other hand, if they haven't put enough money in, then we just ignore them. We stand the same state. We don't release a product and accept coin again doesn't matter. So you would flesh all of these out as part of your abstract state table for all the different possible inputs. So then let's go on to step two of our FSM design process and say, well, what exactly do we want our inputs and outputs to look like, right? We need bits. So we're going to get a coin sometimes. So it's going to be a three bit value C. It's going to be C21 C C1 C0. We're going to assume that someone's providing us with a representation. So I'll show you that representation on the next slide. But we don't get to pick it. It'll just be, this is the kind of coin you're getting. And here's the three bit value to tell you that. So get that input. We'll also get product selection buttons. So these will be like the UL and P buttons before, except it'll be, well, if I want product one, I'll push B1 and then B1 will be a one. There's also B2 and B3. So our inputs, expits of input, our outputs will be coin accept. So one means accept the coin that just came in zero means rejected. And then item release signals are one are two are three each of which means release one particular item. So if you set that high that gives them one of those items. So that's our IO. This was the representation I mentioned. So often I talked about this a little bit earlier when I first talked about designing IO. But often someone else is going to pick the representation. Right. You're going to have to interface with some standard or you're going to interface with a component someone that already built or is just buying off the shelf. And so what information it gives you and how that information is represented you don't get to control right if you want you can translate it to a different representation. But again, you have to build logic to do that. Right. So here's the representation will assume. So if no, no coin comes in a cycle will get one one zero. If a nickel comes in will get zero one zero and so forth. So we've got five different kinds of coin. We've got this no coin input that's the no event or no input event. These are the values and dollars. These are the values and nickels. That's for later, but. But this is the representation we're going to use. So of course, two patterns are not used. Right. There's only five coins and one one no coin. So two patterns are not used. And when we use this will put don't care for those because we'll assume that this representation is valid and the coin mechanism is never going to give us the other two patterns. So one aspect of the outputs that we need to be careful about and we need to make sure that we communicate with the people building the other parts of the system. You know, we decided that the finite state machine never produces outputs based on inputs. So in other words, these tables the abstract state tables I just looked at and the next state table, we just looked at, you know, it gave the outputs as a function of the inputs, but we don't build things that way in our class. So we're going to calculate the outputs based on the state and the inputs, but then we're just going to put those in flip-flops. So the output for the coin you put a coin in cycle 10 in cycle 11, the coin mechanism will get the accept signal. So the coin mechanism designer needs to know, well, you're not going to get the answer until next cycle. They can keep putting coins in every cycle. They'll get an answer delayed one cycle because we don't want our output to depend directly on the input. So we'll just put those in flip-flops, but those outputs now are also state. So we have four more bits of state. So we have an abstract model, we have IO, what's next? Remember we have this six step process, right? We said, okay, do an abstract model, specify your IO, then you've got to complete your specification, right? Okay, good. So how many bits of state do we have? So we ignore the prices. Let's see, ignoring the prices, we have six bit registered for the number of nickels. What else do we have? Four bits of shared output, of stored output, right? So 10 bits, okay, 1224 states. Not too bad, right? And one, we want to draw 1224 circles. All right, what about inputs? Remember? We have coin, right, which is three bits, and then we have three buttons, so six bits. Okay, so 1224 states, each was 64 arcs. Remember, digital system has to be complete, so we have to know what each of those does. Good luck. All right, so we better simplify. So first of all, the poor output bits, those don't have any impact on where we go next, right? So even though we have a thousand 24 states, we're going to ignore the output bits. We're just storing them because we want them to be held for a cycle so that the coin mechanism can see clearly, except a reject for a full cycle. You can use it to drive its gate or whatever, right? So those are, those we're going to ignore. So each of our state sub-ens will then be actually 16 equivalent states. So just like we said, well, you know, the driver state, it's got the 33-bit counter, but it's all just one state for our purposes, right? So here, each of these states, based on the number of nickels, they don't, nothing matters, or sorry, these output bits don't matter at all, so they all look the same regardless of what the output bits are. Okay, so we'll have 16 equivalent states, but we'll just represent it as state event. So that reduces from a thousand states down to 64 states, right? So the other thing to notice is that we had these two unused bit patterns in our coin, in our coin inputs, really it's not eight times eight, and it's not two to the six, it's eight from the button inputs, eight different button combinations, and six choices of coin. So we only have 48 arcs, that's still a lot, right? So 64 states, 48 arcs each, that's a lot. So we make it easier. So, hmm, sorry, table had only nine input events, right? So we had nothing happen with five types of coin, and we had three types of purchases. So where do the other 39 arcs come from? How can we have 48 arcs? So when we completed specs before, what kind of things do we have to worry about? Short answer is humans, right? Long answer is people pushing more than one button, people putting a coin in while they make a purchase, right? Input events are only nine of them that we care about, right? But nothing keeps a human user from doing them at the same time, right? So when we multiply them all out, we get 48. So, yeah. We map them to a function that says this. In the past, we did pretty simple strategies. I wouldn't say they don't care. You do have to make a decision that makes sense. For example, probably user wouldn't be happy if they put a coin in and push the button, it happens to be the same cycle. So you just decide to eat their coin. Owner wouldn't be happy. If you said it, don't care, you could also release all three products, right? Yeah, so that's good answer, right? So one strategy is just to say, well, let's pick a priority, and that's what we'll do is we'll pick a priority, and then we'll say we're just going to strictly prioritize. We'll show that in detail the next slide. Do you want to say something? Yeah. So Eric suggesting that, well, what if we just say, if you do more than one input, we ignore all the inputs and absolutely. Yeah, so if you do more than one input, we could say, okay, in that case, we do nothing. The choice will make this time is just to pick a prioritization order. So let's choose a strategy. So we'll prioritize, and we'll prioritize strictly. So meaning that we'll ignore the lower priority events and try to execute the highest priority event. Now, this is the little, there's going to be a little strangeness here in the following sense. So let's say that your highest priority event is a purchase, so you put a dollar in and you push the button too quickly. Your dollar is enough to pay. Without the dollar, you didn't have enough to pay, and we're going to prioritize purchases. So we checked, you have enough money. We say, no, we don't let you buy it. We're not then going to go say, oh, but you put a dollar in. No, we're just going to ignore all the other input events. Okay, so your dollar will get returned also. It's a little strange. You can make it more flexible if you wanted to, but it's a little more complicated. So we're going to have it very simple. We'll prioritize them strictly and try to execute just one of them. Okay, so our strategy will be purchases or high priority. Item three is the highest priority. So if you push button three, the only thing the system will do is try to sell you item three. Okay, if you didn't push button three, then a little see if you tried to buy item two, then item one. If you didn't try to buy anything, then it will see if you try to put a coin in. Now, the coin inputs are all distinct. Right, we're getting this three bit input that says nickel or dollar. You can't put both in at the same time. So we don't need to do anything there. We don't need to pick a priority. All right, so now we can actually go back and write a complete next state table. It's actually quite large. So you don't want to really do it, but, but, just to show you what the kind of thing it would look like. So if you pick some prices, so let's say that P three is 60 nickels. P two is 10 nickels. P one is 35 nickels. And let's say that we're in state 50. So I've ordered these in priority order. So the first one says, well, if you push button three, right, then it doesn't matter whether you push the other two buttons. So those are don't cares on the input side. It doesn't matter if you put a coin in or not. Don't care about that pattern at all. Your final state will be state 50. Wait a minute. Why is that? So you tried to buy item three. You had 15 nickels. Oh, but item three cost 60 nickels. So the answer is no. You only put 15 nickels into the machine. You tried to buy something for 60 nickels. So the answer is no, you can't buy it. So don't release anything. Our three is zero, our two is zero, our one is zero. We don't release any product. Why why do I have zero here instead of don't care? Yeah, so you know, we said we don't care what coin they put in, but if they put a coin in, it should come back to them, right? We don't want to take it just because they happen to try to buy something in the same cycle. Even though in the abstract diagram, when we made a, when we try to make a purchase, we said we didn't care. In this case, we actually do care. We want to return the point. All right. So the next one. Next line is trying to purchase item two. So. Okay, we're kind of running out of time. So I think I'll try to finish this one up and maybe start again with it on on Friday. Try to purchase item two. In that case, item one doesn't matter, coin doesn't matter. The cost is only 10, right? So go ahead and let them purchase it, which means we'll go from state 50 down to state 40 by subtracting 10. And then we'll release item two for them. Similarly, we're going to reject any coin they happen to put in question. Technically, yes, but we're going to design with components and make sure that our rules are followed. So that's why I said you wouldn't want to really write this out, right? Because there are, you know, it also depends on the prices. So yeah. So when we get to this level of abstraction, you really don't want to have to, you want to be able to verify your ideas without going to this level because this level will blow up. Yeah. Yeah. Yeah. So I mean, we would still say go from it. You know, we would still have our conditions and still say to go from end to end minus. Yeah. Yeah. Okay. Let's stop there and we can we can follow up more offline if you want because the times up, don't want to hold people up. Thanks. you you you you you you you you you you you"
    },
    {
        "ECE120-2016-10-10-LEC-20-slides.mp4": " Okay, so let's go ahead and get started. A couple of administrative things to start. So we will. So there's this feedback survey. So if you haven't done that already, please try to do it before midnight. Today we will finish off our serial comparator and a few more comments to make. I do another example, somewhat faster for power to checker and then start in on finite state machines. So most of today will be an example to introduce the tools that we use to design finite state machines. And then we'll do counters and things like that on Wednesday. So I know there's some. And I've got some problems on the homework. So sorry for being a little late in that regard, but I like this ordering better. I think it's better to understand the serial stuff because it's a little simpler. So. So that's the plan for today. I wanted to remind you we have a midterm today's the last data sign up for conflict on the wiki. So if you haven't done that and you have a conflict with this time and date, please do that. Also, so section 2.8 of the notes plus reading writing truth tables from last time since the other lectures hadn't done that yet. There are the notes on the wiki they have a lot of extra content. So things like T flip flops are not part of the class. If you're looking at those doing or that extra content. And if you need to know if something's included, look at note section 2.8. That'll give you all of the learning objectives for this part of the class. So in the notes, you know, every part of the class has basically two pages of the learning objectives. For that quarter of the class. We'll have a review section next Monday. So we from today will do what we did for the first midterm go through topics of your choice and review. So come prepared with your choice of topics and we'll vote on them. Okay, so I wanted to take a little bit of a review. So this was our serial comparator. You know, this we adapted from the general model. So we initialized it to zero zero and f equals one. And then we had our single bits slice here. The outputs of the bits wise got stored in the two flip flops and then those are cycled back to execute on the comparator in the next cycle. And you've got one bit of a and B operands coming in each cycle as well. And then we just look at those two outputs from the bits slice as our answer, right, a less than equal or greater than B. So the serialization just means that it's operating over time, right, rather than simultaneously in parallel. So the bits slice design everything happens. And there is gate delay, but it's logically inside of say a clock cycle, right, whereas this design is operating over many clock cycles using the same hardware. So something in between where say you had two bits slices would be a mixture of the two. So then we compared area and delay. And so the the area gave us that the serial design was smaller for for four more bits. And that was because it was constant size kind of the flip flops. So you needed to have a few a few bits, a few bits slices in the bits slice design before the equivalent, but any close for is pretty small. So generally the serial design will be smaller. On the other hand, the serial designs are slower for several reasons. One is that all of the paths matter. Right. So when we look at the the A and B paths to the to the interest slice outputs. Usually we can ignore those in a bit slice design because all of the bits from a and B show up at times zero. Right. Whereas in a serial design every clock cycle, we get a new bit of A and B. So we have to count those on the flip flop and selection logic, of course, how gate delays inside those. And then whatever is setting the clock speed for the system might be slower than in our serial comparator or serial anything. So that's another aspect there. So when we did the side by side comparison, we found that the serial design was going to be at least five and a half times slower, maybe even worse, depending what sets the clock speed. Okay. So this is kind of where we left off on Friday. We said, well, you know, those are two extreme points, right. You can do one bit slice and use that fully serial. You can do end bits slices and use that effectively fully within a clock cycle. But you can do anything in between two, you can do two bits slices, three bits slices, whatever. And you can also optimize. Right. So you can say, well, let me go do a let me go do a single function that compares two bits at once. So if you look in the notes, there's actually one of those designs. We did a designing class, actually, where we where we looked for powers of two, two bits at a time. Right. So the more bits you look at the better your design will be both an area and delay. But the trade off there is complexity. Right. If you try to look at a two 32 bit numbers and write down the Boolean expression for which one is bigger than the other, it's going to take you a little bit of time. And so higher complexity more likely to make a mistake when you try to build it. But in return, you get better area and better delay. So I wanted to give you one practical example where people have done this kind of trade off in practice. So there was a there was a generation of Intel processors. Think around the turn of the millennium around P4 generation that actually internally it was a 30 it was still a 32 bit machine. So the processor word size most of the operations were 32 bit operations. But they actually made the adders 16 bit adders and they made them clocked twice as fast as the rest of the processor. So typically that was around three gigahertz. So the adders would then go six gigahertz. And the reason they did that is they were starting to include these multimedia operations in the design of the processor and the multimedia operations needed smaller word sizes. Right. So you could actually use these adders to do two different 16 bit ads at a rate of six gigahertz or you could take two 16 bit adders or even one 16 bit adder and run it for two cycles to do back to back ads bring the carry back around just like we did in our serial comparator with the output of the bit slice. And you can actually do a single 32 bit add in one clock cycle at three gigahertz. And so so people do play these games in practice in real systems where they trade you know the speed versus the size and do things in between now those 16 bit adders were not your ripple carry adder. There were three adders just as the 32 and 64 bit adders are today. But same same sort of idea that you can break the break the big adder into little adders and use them serially. Okay, so I wanted to do a second example of serialization. So this was our generic bit slice model. So just to remind you quickly we're working on some end bit operands we've got p bits of input into our bit slice from the operands and we produce qubits of output. And we've got m bits in between slices and then at the end we have some answer that takes our bits that's not shown in the slide. But we have some output logic that takes the last m bits out of the last bits slice and produces our orbits of answer. So in class we did this power of two checker where we looked at two different bits of the of the operand a in one bit slice so we've got two bits of a coming in here. We've got two bits between the bits slices remember those I'll show you the representation in a minute but we needed to keep track of whether we'd seen zero ones one one or more than one one because a power of two has exactly one one bit. And as you may remember think you play with that discussion to so P equals to here output bits down here is zero right all we want to know is the answer so the power to or not and so we don't produce any output operand with bits coming out of the bits slice and then m is to from bits slice to bits slice but at the end we just want to know yes or no power to not power to so we just need one bit for that. So we used an X or gate in our design to get that final answer so this was our representation we said OK zero zero means no one bits zero one is one one bit one one is more than one one bit and one zero was not used so when I initialize my my bits slice design what should I pass in as constant values to the first bit. Zero zero right I don't have any one bits yet just started looking so we want to initialize to zero zero so actually the design is going to be similar to the serial comparator in the sense that our initialization values are both zero zero again so we're going to just use two nor gates again for selection logic here's the power to checker bits slice I showed you a minute ago. Since m equals to we have two flip plots here I guess I can actually go through it so two input operands P equals to zero output flip plots since Q is zero two flip plots to store the bits of M as they come out the M bits of output. These again are initialized zero and f equals one and then finally the output logic to get the answer was to take these these two outputs from the power of two checker X or those together if that's if that's a one then we have a power of two and if it's not we've got we've got no power of two just to flip back a second to the. Encoding the representation so if you take X or these two bits if you don't have any any one bits then that's the power of two if you've got one one bit that is and then if you've got more than one bit one one bit X or one and one is zero so that's also not a power to so that's why we're able to use this X or gate over here at the end. Okay so let's just do a quick answer this looks more or less the same because I'm doing another another four cycle input here n equals eight because in each cycle will take two bits of the number so in cycles zero we start by marking the f input is one and then a and b equal to zero for the first bits of the number what are these which of these values be. Bits good answer yeah so we don't know what those are right and we don't care why don't we care. Won't they affect our other logic. If f equals one what are c1 and c0 zero it doesn't matter what these are right and that's important so when f equals one c1 and c0 both zero so now we can calculate what z1 and z0 should be so this says okay we've got a and b are both zero we didn't see any one bits before. So how many one bits of we see zero still right good. Alright so those z1 and c0 then in the second I'm sorry clock cycle number one get latched into the flip flops and so those will appear in b1 and b0 in clock cycle number one so again I want to emphasize digital discrete time right so we only think about clock cycles so once we're in this in this realm of serialization and finance state machines were doing fully clock synchronous. Clock synchronous sequential circuits so we have discrete time clock measured only in cycles things change cycle by cycle on the rising edge. So cycle number one we have zero zero let's say we put in zero zero one so f is zero and then we have two more bits of the number zero and one so what are c c1 and c0. When f equals zero the nor gates just copy these two outputs into c1 and c0 and so what should z1 z0. One zero that was zero one but yeah so this is the representation for having seen one one. Okay you don't really need to memorize that except you do started to answer the questions so sorry about that so the zero one then gets latched into the flip flops in the next cycle so in cycle two the flip flops will have zero one. So they'll have that for the entire cycle so let's say that we put zero zero zero during that cycle so c1 c0 will be what. And z1 z0 again same thing because we get no more zeros right so the representations basically counting the number of one bits no more ones they should say. So the z1 z0 values get latched into the flip flops and then in cycle number three those will have zero and one again. Put in zero one zero c1 c0 is what? Zero one and z1 z0 one one at this point right because we saw another one now we have more than one one sorry z1 z0 out there's one one that gets latched into the flip flops and now in cycle four we don't know we don't care what f a and b are we might say. We might start doing another power of two check but it doesn't matter right we don't care because we're going to look at these two values through the output logic and get our answer so we don't know what these values are either it depends whether we're actually trying to start a second power of two check. So we don't know these values and we don't care about those yeah. So in order to use this you have to create a system that delivers the bits at one cycle at a time so yes from the point of view designing yes you assume that they're zeroized. Good question. So if I take X or b1 and b0 at the output what I get is zero right so these eight bits do not form a power. So that's a good question the X or is just wired up to these two outputs right so at every cycle we're going to get an answer so we could actually just check and see you know do we see a power of two in fact if we wanted to we could look for this one one pattern and say well at that point we know it's not a power of two. So yes we will get the X or every cycle and if we wanted to we could make the thing stop early right we could look for saying well when when have we seen more than one one bit at that point we know the answer so we could just stop. So I'll do the the timing analysis assuming we don't do that stopping early but you could do it with this kind of design. Yes yes that's right so the the A and B inputs actually represent two bits from a single operand of n bits so this takes only n over two bits slices let's what n is eight but we've taken only four cycles. Yes absolutely so the question is could I have done a three four ten bit single bits slice yes it would be more complicated this one. And I think in discussion section you did a one bit checker was in class we did a two bit checker so you can go the other way to in this case. Okay so let's analyze our area so we've got a bit slice two flip blocks two two input nor gates for selection logic and a one two input X or so flip flop same sizes before so we won't go count them again. This was our design so just pull up the bits slice design so you can see we have three two input gates one two three of them and we have two three input gates so count them as number of inputs. So that's our total so if we add those up we have three let's see three two inputs in the bit slice 16 to inputs in the flip blocks and then two more in the selection logic so it gives us 21 to input gates two three input gates for inverters and a two input X or so that's that's our area I'm being a little more detailed now we're actually changing into transistors to do the comparison so two input gates of four transistors right so it's 84 transistors 12 transistors eight transistors. And this one is is even so we just ignore that one in the bit slice itself we have we only need and over two bits license right so we need three and over two two input gates I mean six and transistors and three input gates another six and transistors and this X or so if you do it it actually is equal at n is nine but we have to do two bits at a time so the serial design is smaller for n ten or more. So if you remember three or four weeks ago we looked at how you actually build and in our gates there are two transistors for input one p type one and type. So a two input gate will have four transistors and an inverter will have two transistors so if you want to go more detail like this you can't count transistors instead of using our heuristic which was an estimate of transistor count anyway so either way is pretty accurate. Alright so let's see so let's look at timing then so a rising edge rise it equals zero gate delays and then we said we're going to wait four gate delays after the rising edge before we assume the output is ready to look at from these things we'll assume the same up here just as we did before so assume these inputs up here come somewhere from flip flop so those are all available at time four gate delays. This thing here then has to go through selection logic that's one extra gate delay so that's now available at time five now to know how long the paths to this power to check our go back to our design and basically everything was two right everything's two gate delays from the input side to the output side so if we go back here so these things up here these are available at four so the a and B paths to the z outputs well that's going to be four points. Well that's going to be four plus two is six but the C's are only available at five gate delays so five plus two is seven that'll be the time at which our Z's become available. I have to look at the longest path as always and then finally we decided we're going to wait for more gate delays at before the next rising edge to make sure we've got enough time to to get the value through the first latch and so we said four before and for after the rising clock edge in the flip flop so for use that timing we've got. We've got at least 11 cycles between the rising edges and then we've also for whatever we're using this answer for we need to realize that it's actually five gate delays before we get the answer. The answer comes at 12 gate delays after the rising edge of the last cycle. Well let's see so the serial design then we've got n plus one gate delays in our bit slice design that's just pulling that out of the notes for the serial design we have at least 11 gate delays for the clock we have to have n over two cycles remember that we're processing two bits per cycle. Yeah that's just a number we chose we chose the same number as we did for the serial comparator there is some there is some amount of delay implied a real flip flop might be a little smaller but I mean you need something to compare so I wanted to quantify so I just picked for it that's good question. So we need 11 gate delays in over two cycles so we've got at least 11 and over two gate delays so it's at least five and a half times slower maybe even slower if this is not the thing that sets the clock which is probably. That was it for a second example Sasha. Yeah so you can you can design them different ways we assumed that the input to the flip flop had to be steady for four gate delays before before the rising edge and that the output would appear for gate delays after the rising edge. Yeah. Oh yeah you know what I'm sorry that actually should be 16 that's a good point yeah that's a typo because until this output becomes visible it can't go into this that's right that's a good point yeah so this would be actually five gate delays into the next clock cycle before the output to be it's yeah thank you for pointing that. Yeah it doesn't what it means so the rising edge can happen when this input to the flip flop has been stable long enough which is 11 gate delays but whatever is using this answer has to be aware that it takes four gate delays before these are visible which we assumed also right we assume these inputs were only available to equals four that they came from flip blocks. So the problem is actually not available to T equals five because after the flip blocks it gets an extra logic five five into the next cycle. So four for the this part and one for that one. Yeah that's right that's right so the next the next power to check could be starting and these outputs at the same time are being fed to the output logic which is then consuming the answer for the last one. So the input in parallel in clock cycle four will be the last one. Okay all right so let's talk about finite state machines so a finite state machine is just a model of a system and it's a assumes that the system moves amongst this finite set of states based on some external inputs and then it produces some external outputs so we'll do a concrete example shortly. Typical typical examples would be things like you know bill coin operated dending machines vehicle control systems that are looking at say road conditions or watching how fast your tire spin to decide whether to turn on your anti breaking system. Computers executing programs things like that actually the computer the heart is a finite state machine as you'll see. So what is it in terms of math well it has five pieces so we have a finite set of states we have a set of inputs we have a set of outputs we have a set of transition rules that tell us given any state and any set of in any given input where do we go next right what's the next state. Finally we have expressions or methods for calculating our outputs now we're going to of course build a finite state machines as digital systems so everything we do has to be mapped to. It's everything's bits right so states bits inputs bits outputs bits this is tricky ready transition rules will an expression thank you outputs calculating outputs I should say more bullying expressions right the rules take take your current state ID which is some bits those are input bits and your. Sorry more input bits to these bullying expressions which are the inputs to the system and create a next state ID which is the outputs of these bullying expressions and so it says well what state do I go into given my current state and my input bits and then the outputs of course are bullying expressions we're going to assume and i'll tell you this several times but we're going to assume that the outputs are only a function of our current state. Now in general they could also be a function of our of our current inputs but in our class will assume they're not. So we implement finance state machine as clock synchronous sequential circuits so that means discrete time and so cycle by cycle things will change so in each cycle the finance state machine will look at its current state look at its inputs and move to an next state. So regardless of anything else in the world it'll just keep going chugging along state to state so given any state and any combination of inputs a transition rule from the given state to a next state has to be defined digital system it's going to go somewhere next cycle they're going to be some bits in the state so that has to be completely defined. Self loops which means transitions from a state back to itself that's okay state can stay in itself but we need to say explicitly under these inputs the state stays put it doesn't go to a new state so we have to completely define it. Regardless what we build will go somewhere right there will always be bits so even if you say oh I don't know I don't care whatever you build will have some will have bits there and so it will pick an answer for you. So let's do an example so here's my example you've probably seen one of these I'm going to be a scene one of these. Most of you okay I don't mean a key yeah so Yale Pat one of the authors of your textbook has a great has a great joke that he plays in a lot of people so he pulls out an intel processor in a block of plastic and he says you know what that is maybe one looks at it but I don't know is that a P4 is like no that's a key chain. So yeah so this is a key but it's also a keyless entry system right so it has some buttons on it and when I walk up to my car I don't have to put the key in the lock it has a little protocol for me with these buttons here which hopefully you'll help me figure out today so I can use my car. So what I want to do is start with a list of states so when I walk up to my car probably the car is locked at least I hope my car is locked now. So you know we can make this list of states I'll call this an abstract list of states the meaning of my first state is well the car is locked and I'll give it a name I'll call it locked so in that case the driver's door will be locked and the other doors will also be locked and the alarm hopefully is off right so alarm is not on. So now maybe I'll do something in my my door the driver's door will unlock so we'll have another state and so this means a new state in the system so when I walk up and I unlock the driver's door then I'll make another state driver's door unlocked is the meaning I'll call that driver and in this case driver's door will be unlocked. The other doors still locked and the alarm is not on and then so you played with these was played with these what happens if I keep pushing unlock all of them open right okay good so I have a third state all of the doors are unlocked I'll call it the unlocked state driver's door still unlocked other doors also unlocked alarm not on. And then you need one more state which is if I get if I get scared someone walks up with a big stick or something there's a little red button there and if I get scared I'm scared to push it because I'm going to get mad at my car and heard it so if I push this button in theory you know move into the state which is the alarm is going off right and that's supposed to scare away an attacker or something so call it the alarm state oh so now I don't know what to do what should I do should I lock the doors are unlocked. Really is I mean is that better so what if I'm running I mean the only place to hide is my car. Oh I can't get in so I mean it's not really clear right well you can't you can't leave it well if you leave it as a don't care whatever you build is going to make a decision couldn't be the worst case driver's door is locked the restaurant locked so you don't want to do that. All right so I'm going to go with the unlock dancer I'm I'm sorry with the lock dancer I tend to think that's a better answer but my point is is a design decision right so you as the engineer you have to make a choice choice might actually make a difference right and in some cases I think in this case it's unclear enough that both both answers might be the right answer in certain conditions but you've got to pick one so so as an engineer they're going to be a lot of design decisions you can build anything you want but realize when you're making a decision because maybe later you'll say well I made this decision we could change it and go back and change the system. Okay so we'll make those locked and now the alarm of course is going to be sounding so those are our four our four states so this is a list of abstract states this is what we get when we sit down and think you know I could probably build a finite state machine to control this thing. Let me start thinking about the states I want so this is just an informal list right we call an abstract list so in particular we could just list the states right we could just write down state names the human meaning is useful if your state names are too generic it's useful to make sure you know what you're talking about in those states. Outputs is also optional but if you if you map each state to an output that means your output only depends on the state now in this class will always assume that in general it's not going to be true in industry people won't necessarily just make that assumption but in our class outputs will depend only on the states not on the inputs so it doesn't matter what buttons I'm pushing what matters is just the state. The buttons will change the state which can benefit the out. Okay so we specify transitions using something called an X state table so let's do an abstract one first so usually in in this part of the design we just go through and figure out what what do we want to be able to do right what's a normal operation so here's my keyless entry system and let's just kind of think about it so normally I walk up to my car and I want to open it right so I push the unlock button. So that'll tell me well if I'm in the on the lock state and I push unlock where should I go. I should go to driver right okay so that's one of my transitions that's an abstract net state table says well if I if I'm in the lock state and I push the unlock button I go to the driver state so what if I'm in the driver state and I push the unlock button. I go to unlock okay well that's now my car is all open so get in I'll drive somewhere then I'll get out and I want to lock it up so whatever state I'm in if I push lock button what should happen. Go to lock and then last if I get scared doesn't matter what state I'm in if I push the panic button what should happen. The alarm goes off right good so that's my abstract next state table right so what's the problem with this. Yeah. I don't know my table doesn't tell me. So it's incomplete Daniel is saying right doesn't tell me everything right so some of the transitions that I might want to know about are not defined by that table and that's okay right now eventually the system that we're going to build is going to be a digital system and it's going to answer all the questions so we should be careful. But this table is incomplete meaning it doesn't specify transitions like the one Daniel asked about it's ambiguous right so what happens if I push lock and panic which one do I go to I can only go to one right and it's actually I mean that part is actually inconsistent right because I can't go to both so but it says I go to both so it doesn't make any sense right now it's just an abstract next state table. What we need to do next is is make it complete make it a real design for digital system so we're going to have to specify those things and answer all of the design questions so we need to make design design decisions it's good to do those early if we know about the decisions we need to make right so don't put it off if you know you're going to need to make a decision do it early because you're your digital logic will define answers for you. So do them early and then when you're done making decisions when you're done implementing go back and see well what actually happened if you did leave any don't cares. Make sure that any don't cares who left are actually acceptable decisions because if they're not you can fix it was if you just assume they were might might lead to problems. So we can represent the same information as that next state table using an abstract state transition diagram so let me show you that so here are four states we draw them as circles we put their names inside and then we start drawing arrows between them so our first entry in the table was well if I'm in locked and I push unlock drawn arrow take me over to driver so in this graph I represent that as an arc labeled with the with the input. So similarly if I'm in driver and I push unlock I go down to unlock I said from any state if I push lock I go to locked so you can see here's our first self loop. So the the black lines are the third element that this was the first the second line of the table this is the third lines all four of these arcs and then the last line of our abstract state table next table was the panic button right then in any state I go from along the red arrows into the alarm state including another self loop. Same information also incomplete ambiguous to some extent and inconsistent I actually broke some of the broke some of the inconsistencies I guess because I made these self loops instead of just leaving them open. Oh no it doesn't because it doesn't say what happens if you push both lock and panic at the same time. Yeah so that's a good question so my comments question is well why don't we just do what we've done before with the glue logic and prohibit more than one input that's one answer I'll use actually prioritization scheme but we do need to do something right to make this a real system we could we could leave it open probably not the safest thing we can make decisions like one button at a time or or ignore your buttons or we can make a decision like prioritization we will need to do something good question yeah I'm sorry yeah yeah so that's a design decision that we haven't answered yet right so the question is wouldn't pushing lock and panically to the alarm state only if we choose to make it so or we happen to have it be so there's nothing in this diagram that says if you push two buttons what happens so okay yeah so panic is a button so if we push lock while we're in the alarm state according to this diagram we turn the alarm off yeah and that's that's already a design decision to right that will come back to briefly later because one other questions what happens if you push unlock while you're in the alarm state which is not answered here yeah okay yeah so this diagram just like the previous one is the same information right it seems leaves the same questions on answer and leaves the same ambiguities and inconsistencies there's no difference just this is a graph that was a table same information okay so exactly same information neither is complete so now what do we need to turn this into bits I love bits I'm sorry all right I'm prevents so how many bits do we need for the state two good four states one base two or four around it up is two okay so we'll call the mess one and S zero as stands for state okay so we've got two bits of state we'll call the mess one S zero what about outputs there three of them I think so we've got driver's door we'll say one means unlocked so zero means lot remaining doors and which will be our alarm one means your alarm is sounding what about inputs three do you have a question I think okay so unlock button one is pushed and P for panic button so three bits of input okay so now we can pick a representation and rewrite our list so here's a representation the order in this list doesn't matter so I want to write in my list of states with the representation and with the output bits mapped into the correct meanings of the output bits themselves so I have the lock state which will represent a zero zero S one is zero S zero is also zero D RNA both of these are locked in the alarm is off right in the driver state of pick one zero as my representation the driver's doors unlocked the rest of the doors are locked and the alarm is off same things down here just just transcribing into bits according to the meanings that we decided on the last slide so the order doesn't matter this is sort of a K map order right so make life a little easier if we copy these things in K maps so you may realize of course that the representation itself does matter right so your representation will affect the logic that you need so for example if you go to try to map these three functions from S one and zero then depending on how you pick your representation you'll have more logic more logic or less logic so so there is something in that and also the next state tables I will have to calculate the next state from the current state and the inputs there again the logical matter the representation will matter to the logic we'll talk more in maybe the end of the week or even the next Monday about how to pick so we're going to introduce a little more notation so we're going to put pluses after S one and S zero what that means is the value in the next clock cycle right so remember we're feeding logic into the flip flops into the inputs those were going to call S one plus and S zero plus those would be the value of the state in the next clock cycle so most of the design work is then after we've gone through all of this process and made the system fully digital is then just going to be solving for S one plus S zero plus in the outputs building that logic and plugging it together so those are the examples you've seen in the homework in the homework you're just asked to analyze them but it's basically just some finite state machines where you calculate the next state as a function of the current state and the inputs and then the outputs as a function just the state. All right so we will we will typically use binary order in the tables I'm going to show you next we're going to use grey code order our axes just for ease and copy the K maps so here's a table where should we start. We didn't answer some design decisions right okay so back up for a minute let's let's go answer some design decisions so let's do these early I mentioned this before but we've got a bunch of decisions that we haven't answered yet for a system so before we start filling in tables we should answer those questions. So for example what happens when the user presses more than one button that we kind of hinted at this actually someone asked as well what or asked a similar question what happens when the user presses unlock in the unlock state so sometimes you'll you'll be able to list most of these questions sometimes you might miss some things may come up later design decisions are going to shape your design right so you should try to make them early they can actually conflict with one another right make make one decision right it down come back later and say well I can't I can't. I can't make both of these decisions the way I want to have to pick one or the other and so it's good to resolve that kind of stuff early and not you know not leave things until you forget about them right so so let's go through and answer all the questions we can. So we're going to start by prioritizing the buttons so we know there's three buttons we know we haven't thought about what happens when more than one of them is push so now we're going to we're just going to answer so we're going to say panic as priority so if you push the panic button you're done right whatever happens when you push the pan. And if it happens when you push the panic button is going to happen the other buttons are ignored if you didn't push panic but you push lock then we're going to do what happens when lock happens right so we're just going to second priority on lock and then unlock is only going to matter when you don't push the other two buttons so that's our priority scheme. So here are the panic states let me look at this table this the next state table you can see that on the left I have the current state which is my two bit s 1 s 0 and then across the horizontal axis I have eight columns one for each possible combination of the unlock lock and panic button inputs. These four columns here these two and these two are all with the panic button pushed so where should I go with the panic button is pushed to alarm state right which is 0 1 so just fill those in so now I'm half done with my table. So that's that let's go for lock button so lock button see all of the ones ending with one are the panic button so these I didn't push the panic button but I pushed lock over here I didn't push either one over here I didn't push either one so what should happen if I push the lock button go to 0 0 the lock state right so then I can fill in those so that's good that was easy. So what if the user doesn't push anything. Yeah it would probably stay in the current state right we didn't actually specify that did we we never said well if they don't push anything we're just going to stay put you probably all kind of thought about it but we didn't say it right so so it's really kind of a design decision probably most of us would have all agreed on but it's it's worthwhile making it clear to so let's all agree if you don't push any buttons stays in the same state. Later in the semester will say maybe after five minutes we should turn the alarm off and we'll talk about extending this design to do that kind of thing on a matter of question. All right so what transitions did we define for unlock. There was one up here right so if it's locked you said we should go where driver okay that was I think one zero right what about from driver unlocked that was one one about these two. More design decisions. So what should happen maybe just stand locked if it's ready unlocked right so here's a here's a slightly more important one what happens if you push unlock when the alarm is sounding. Oh sorry this is this is our earlier design decisions are a little typo in the notes we still have a design decision to make but it's not this one so the so the question is should we unlock the car we should assume that people are still panicking. Maybe they're on the I mean they need to be able to turn the alarm off but do we want them to do that automatically for any button or do we want them to push the lock button only. And so so I kind of felt like well why don't we why don't we make them push the lock button at least then they're they're cool and collected right if they're just hitting buttons. Maybe unlocked should not also turn the alarm off so another design decision but what it results in is from alarm we stand alarm so if you push unlock it doesn't turn the alarm off. Similarly from unlocked we stand on. You have a question. All right so now we're done we've got our we've got our table so you know how to fill it in from here right the wrist is came apps expression and logic so just to just to walk through it a little bit. So we would start by expressing s1 plus and s0 plus in terms of our five variables so you can go looking with the pdf do five variable came apps if you want to or you can play the trick we played with our with our letter checker and you can say well let me just pick one of these variables and split this up into two four variable came out right and then I can put those together with with and gates or I can put them together with a box lots of ways to build it. But basically need to build those five to five variable functions then I'll go express dr and a the output bits in terms of my current state those will be substantially simpler so build all of those combinational logic functions take the s1 plus and s0 plus expressions from this table back here and feed those into my flip blocks to the d inputs of my flip blocks. And then I'm done that's it so you should do that as an exercise we used to make that a homework problem I don't think it'll be a homework problem this time but you should be able to do that right it's basically combinational logic at that point you've been doing that for several weeks now and this will be a little bit more of a challenge but but it's it should be doable and so this is the last step in all of our finite state machine designs doing things you already know how to do. So I want to show you a couple more things before we end for the day so we can also redraw our state transition diagram so complete state transition diagram has the same information that we just put into the complete next state table and so it's defined in terms of bits so what it's going to look like is this so we'll have our states annotated with both the state ID as well as the outputs and so we've got. We've got the state ID in front of the slash and the output bits after the slash so often we'll just put zeros and ones so it'll be implicit that the bits before the zero sorry before the slash are the state bits and the bits after the slash or the output bits and the order of outputs has to somehow be known right so there has to be some order you've decided on or maybe right on the side of your graph or something so that everyone knows the first bit is D second bit is R third bit is A in our case the arcs then are going to be annotated with input combinations so for us that's the unlock button the lock button in the P button sometimes people will write those in some order sometimes people will just mark them with the bits and then again you need to realize you should put them all in the same order and you should say what the order is somewhere. So let's actually do that so here are four states so you can see now instead of just having the name of the state we actually have the state ID bits and then the three output bits for all four of the states and then we can start to annotate our arcs so remember we said well when you push unlock this was our first our first rule transition rule in the abstract next state table when I push unlock and I don't push lock or panic so now to explicit when I push on the state. When I push unlock but not lock or panic I go from locked to driver similarly when I push unlock but not lock or panic then I go from driver to unlock when I push unlock but not locked or panic or I don't push anything then I'll stay here now in order to save ourselves a little time often we will shortcut the this kind of notation so I could write these this input bit here as X zero zero. So in this case I've got a don't care for my you input so what do that means I can have the zero zero zero pattern or the one zero zero pattern and both of those will come back to the unlock state. So I'll mention in a minute or two I have to be a little careful with that notation but you can you can shorten the short and the number of bit patterns you have to list turns out when we get over here actually I have six different patterns so I'm going to start using the shortcut notation on this diagram in the notes it's got all the patterns listed for you so if you want to see it in the notes with all the patterns instead of the short cutting that's fine. So look at the notation on all of these locking arcs so you can see that I don't actually care about the unlock bit on any of them right so unlock doesn't matter on these three also for this one unlock doesn't matter so long as I'm pushing lock so but if I'm pushing lock but not panic I'll go to the lock state from any state similarly I've got zero zero list zero zero zero listed up here that was the self loop when I don't push anything in the lock state. So in this full complete state transition diagram you need to have all possible arcs but you can use the shortcut notation as I'm showing you to reduce the number of arcs you really have to draw otherwise you'd have eight times for 32 different arrows which is a little hard to fall. So these things can get messy if you're not careful alright so this is the last one here most of these are xx1 which means I don't care about unlock and don't care about lock as long as panic is one i'm going to go down into the alarm state right so xx1 here xx1 here xx1 here xx1 here here here on the left it's actually six different states xx1 and x0x so if I'm pushing panic doesn't matter I stay in the alarm state similarly if I'm not pushing locked I'll stay in the lock. I'm not pushing locked I'll stay in the alarm state not pushing lock I'll stay in the alarm state so that's actually six different states each of these is I'm sorry six different input combinations each of these is four so we have to be a little careful right because there's actually in that notation there's actually overlap between these two patterns. But that's okay because they're going to the same place so if we're not careful with the input abbreviations we might end up with a diagram that's still incomplete we haven't covered everything or even inconsistent meaning we've got arcs going in different directions with the same input combination so be careful how you use these abbreviations. The example I wanted to show you the last one we looked at was this labeling and the patterns x0 1 0 0 1 and 1 0 1 both match each of these patterns right and so that's okay in this case because they both go to the same next state if they're going in two different directions that would not be okay that would be inconsistent we wouldn't know where to go in our state. So that's it for today thank you and I'll see you on Wednesday. you you you you you you you you you you you you"
    },
    {
        "ECE120-2016-11-16-LEC-34-slides.mp4": " add. Okay, so I think it's three. Hope everyone enjoyed the midterm. Sorry, didn't ask you to help. Yeah, my more problems four and five. So you've got fun with multiple choice and fun with LC3. So, all right. So I want to finish up. So we'll do a little more review since it's been, I guess, five days since we looked at this program. So we'll go through the last few slides that we saw and then finish up the coding of the letter frequency code. So that'll be our last program. I'm not even going to change it into bits for you. You can find the bits on the website if you really want to see the bits. But that program technically we sort of did in binary. Then we're going to talk about assembly language and then what you can do in assembly language and things like that. And we'll talk about assemblers and how they work. That may take all of today. I have this think pair share exercise. Originally I had it, I had it above the assemblers. But then I thought, really do I want to see binary code? Probably not. I'm kind of tired of it. So I'll put it down here. And if we get to it, we'll do an assembly. And that'll be slightly easier. All right. So this was the problem just to remind you what we're trying to solve. So he said, OK, what if we have a string? String is a bunch of ASCII characters terminated by a null. Is this a zero in ASCII? So we count the occurrences of each letter regardless of case and count the number of alphabetic characters. And then we decided on this high level algorithm where we go initialize 27 bins to zero for histogram. And then we go through the string once. And we look at each character in the string and figure out well, is it a letter, upper case or lower case, or is it a not letter? And we go find the right bin and increment. And so we did a breakdown. I didn't keep the flow chart around or anything like that. It's available online if you want to see it. So we decided, well, the string will stick in at 4,000 hacks. The start of our code will be 3,000 hacks. And then the histogram will run from 3,100 hacks up to 311A. This is 1A is 26. So 1 to 26, 8 is E. And then the non-alphabin at 3,100. And then we have these registers assigned during the counting part of the code. So R0 has a pointer to the histogram, that meaning this value. R1 is a string pointer that goes from character to character in the string, starts at 4,000, goes until we find the end of the string. And that lets us load individual memory elements of the characters in the string into R2. R3, R4, and R5. You remember we needed to identify the boundaries in the ASCII table where the letters start and end. And so we had ASCII constants in here that we've mentioned as we went through what they are. And then we had R6 as a temporary register. And so those were our register assignments. Those you would put in comments. So if you look at either of the versions in the website, you'll see this is all listed out in comments. So you don't have to try to remember it. And this is where we had gotten to. We had actually done a little bit more of this. But this was our last comparison to say, well, is the character we're looking at, which we had converted, or were about to convert into a number from 1 to 26 for the lowercase letters, is that character greater than capital Z? So is it a letter or not? I guess actually we'd already converted it. So we'd ruled out these three. And we're just trying to do this last separation. So we're trying to compare with lowercase Z. So we wanted to subtract lowercase Z. And we'd already subtracted this back quote. So hex 60. And we also had a back quote minus lowercase Z in R4 already, because it's the same as at sign minus uppercase Z, both are negative 26, because there are 26 letters regardless of case, of course. And then we're going to throw away the results stored in R6 so that we can keep the number of 1 through 26 for the lowercase letters, because that was what our increment alphabetic been assumed. We had an R2 to find the right alphabetic bin. All right, so we wrote that instruction. We said, well, take what's in R2, add it to the R4, which was back quote minus little Z. Add those together, throw away the answer, but set the condition codes. So this is like calculating original character minus little Z, throwing that answer into R6. So under what conditions then did we have a lowercase letter? So if I subtract little Z, and my original character value was, say, exactly equal to little Z, that'll give me a 0. And if it's anything smaller, what will that give me? Negative, right? And then what if it's over in this green region, positive? So if lowercase letter then would be the negative in the 0 case, right? So then we can branch on negative or 0 to increment the letter's histogram bins, but we've already got that code, right? So we're just going to branch to it. Now, one thing we talked about, but I want to make sure people all understand, when we write that code, we have to make sure that we write it in a way that it can be used for the uppercase and the lowercase letters independently. And so the assumptions we made with that code were the assumptions of the registers we already had. So we made use of the fact that R0 held the histogram pointer. But we also assumed that R2 had a number from 1 to 26, which corresponded to the letter that was read from the string. So for the uppercase character, uppercase A, capital A was a 1, capital B was a 2, and so forth. For the lowercase character, we've got exactly the same relationship with the lowercase characters. So at this point in our code, if we had an uppercase T, sorry, a lowercase T in the string, that happens to be letter number 20. So R2 will have the number 20 coded as 2's complement. So the bits for the number 20 and 2's complement. So then we can just branch to that code, because we designed it to be reused that way. So the branch condition then is what? We just derived it, right? Negative or 0, right? And then we couldn't figure this offset off, because it's up in the code we've already written. But I'm too lazy to put all the code on one slide. So instead, we'll just leave it blank. We can go do our fun counting exercise on paper. All right, so here's what we have left. So if that branch is not taken, we know that this is not a letter. But we've also written that code, right? So what can we do? Just branch to it, right? In this case, we could say BRP, the condition codes are still set. But just for a force of habit, we'll just use an unconditional branch. Because we always want to go there. We happen to know what the condition codes are, but it doesn't really matter. We don't need to use them if we don't want to. We always want to go. So we do an unconditional branch. And again, we could figure out this offset, because it's code we've already written. And I'm going to leave it blank enough. All right, so those were the five regions. So now we're out of our review. So those are the five regions of the ASCII table with classified, encountered, all of the letters, all of the nonletters. Now we just need to go back and I'm sorry, we finish this box. Now we just need to point to the next character. So remember, the next character is in what register? Remember, I won. So how do I point to the next character? Remember, it's just in a consecutive memory locations, right? So what LC3 instruction? Just an ad, right? OK, good. And what arguments? I didn't ask this on the midterm. So now the one I remember. So OK, R1, R1, one. OK. It's tired actually in the term. All right. So now we're done with counting. And now we can actually just branch back to the top of the loop and get ready to look at the next character. The pointer to the next character is already. So we can just go to the top of the loop, load it into R2, and start again. So in that case, you do another unconditional branch. And again, you could fill that instruction in, but I don't want to. So we do need a halt. So at the end of the program, when we're done, we find the null. We need a halt somewhere in our code. Now, we would branch to that from the start of the program where we solve the null character down to here to stop the LC3. We do need to have that. We also need some data. So here was the number of histogram bins, a negative at sign. I just wrote these out as characters. We'd have to of course code them as bits, but I just wanted to remind you the values logically. And then this 4,000 was a place we stored the pointer to the beginning of the string. So we need all those data in memory as part of our program. So again, the full program is available online. We're about to talk about assembly. There's both a binary version and assembly version. It's the same code, but one is an assembly, one is in bits. So please do take a look at those, play with them, make sure you think they're right. I let you understand them. Oh, and if you use it, actually, the assembly example has an example string coded into it, which is not at 4,000. But it'll work just out of the website. Yeah. You mean why not put it at the beginning of the code? It doesn't matter that much. Yeah, it really doesn't matter that much. I think a lot of it doesn't matter that much to me. There are people, including a number of companies that have a strong dislike for having any kind of terminal flow control hidden in the middle of your code. And that's actually, I have a dislike for that, too, for real terminal flow control. Because then someone who's trying to understand your code might not realize that this thing can stop right in the middle and I have to understand that. So they're trying to look at it as the whole thing. If the thing is very big, it might take them a while to realize that they might just fail to realize it can stop in the middle. And so people tend to put the end at the end. And some companies will tell you, if you write code that doesn't have that, we're going to get mad at you and tell you to rewrite it in terms of that. Yeah. No, not so much. It's really just for code clarity, code readability issues. Yeah. It's not a parallel processing issues. Yeah, it's just a question of where you have to look to know which part of your code's going to run. So is the bottom of your code going to run or not? Do I need to read the middle in order to answer that question? That's what that's going to be. All right. So leave the rest for you, hold the counting, all the bits, all the fun really. OK. So now we can move on and talk about assembly language. Everyone's really quiet today. Are you happy with the midterm? Yeah. OK. I know. I'm sorry to nest for help. I'll do it again on the final. All right. So let's review our programming process. So step one, we have to figure out all the instructions. You have to sit there and think and think and think and figure out the instruction sequence. Step two, the fun part. Map the instructions and the data to memory addresses. We started 3,000. So we go to the top and we're at 3,000, 3,000, 1, 2,000, 2. It's really a lot of fun. Step three, take those addresses and calculate the offsets, often by counting. I mean, what more fun could you have with programming? And you fill in the relative offsets as bits. You can translate those counts into bits and then fill them in. So step one is hard. We're not going to get a computer to help us. So I don't know. Maybe some of you get bored. I really enjoy the counting myself. When people get bored, they start making stupid mistakes. So if I were to tell you, OK, homework 12, let's just change it up. Homework 12 is going to be go by hand and actually count the letter A's in patent Patel. Probably everyone would get it wrong. Even if you tried, you would get it wrong. You're like, page 300. So you get bored with that stuff. So instead, since it's so easy, well, we're not going to be able to get computers to do this part for us. Computers are dumb. They're not going to be able to do that. But this stuff down here that's basically just counting, I mean, surely a computer can count, or subtract, or whatever. So let's figure out, could we get a computer to do these parts for us and just leave this part for ourselves for the humans? So here's a typical real programming process. So the programmer actually will write something in a high level language. So something like C, your Java, JavaScript, whatever. Well, maybe not whatever, because then I'm going to put a compiler on that. Not all of those are compilable languages. But you would then take that language, that program, and that high level language and feed that into a compiler. And that would actually produce assembly code. So when you run GCC and your C code, in fact, that produces assembly code internally, and then it runs the assembler on that assembly code. So that's the next step. The compiler will do that for you by default. But the real program, the compiler, is simply calling another program to do that. Yeah. No, usually it will detect any inability to translate to assembly code and not generate the assembly code very rarely. That would be a bug in the compiler for generated data assembly. So the compiler is designed to take this program and produce this program. And if it's unable to do that, it should tell you that. It should tell you it's unable to do that translation, not produce broken assembly. So if it produces broken assembly, that's a bug in the compiler, which sometimes they do. Compilers are not bug free any more than any other piece of software is bug free. So OK, so you get your assembly code out of your compiler. And then you feed that into an assembler, and your assembler produces your binary program, which then in order to get pulled into memory on the computer, usually is pulled in by what's called a loader program, takes your binary off the disk, puts it in memory. Once it's in memory, the operating system can transfer control to your program and let it execute. So this is your typical programming process, Ro. So if the simpler database assembly is called the error, the longer it is, the better. Yeah. Yes, there's also a symbol table, which I didn't draw in this process. I mean, in the start notes in section one of the class, there's a more complete diagram. This is a simplified diagram. Yeah. So this is kind of the core that we've looked at so far. All right. So down here, this is where you did labs 10 and 11. Right? So you said, OK, I'm going to go write some binary. I'll write zeroes and ones. This is today. We're going to talk about what assembly code looks like and how an assembler works. And then labs 12 through 14, one of which I know you're doing tomorrow. But the next few weeks also, you'll be writing bigger chunks of LC3 assembly code. So you'll make use of what we're saying today and understand how it works to replace you basically steps two and three. So you don't have to do the counting anymore. And then EC220, you'll actually start writing substantially more C code. So you'll actually do a little bit more. I should have said, there's some EC220 in here also. So the very first few weeks of the class, you'll do more LC3 assembly programming. But then after that, you'll do purely C programming. If you take 391, you will have to learn x86 because in order to write an operating system, you have to make use of some assembly code. But you won't have to write binary for x86 if you really enjoy paying you can. I don't recommend it. All right. So here's the assembly code. It's aligned by line format. So the assembler's just going to look at one line at a time. And the line format looks like this. So there's a label and opcode operands, a semicolon before a comment. These pieces here, the label and the comment are optional. They can also have blank lines. But it's a leave blank lines. You can put a label by itself on a blank line, a comment by itself on a blank line. Those two together on a blank line. But any instruction, you will have an opcode and operands. And then you can put these extra optional things as well. So the label is a symbolic name for a memory location. So we'll come back to that a few times. But it's an ability for you to make up a name using letters and underscores and numbers. And so, OK, I want to name this particular memory location. And then I want to be able to use that name in order to reference it, say, with a branch or with a load. So instead of having to calculate offsets and know where things are, the assembler can do all those things for you by you're being able to give names to memory locations. The opcode then is an amonic. So instead of writing 0001, now you can write add. So it'll be a lot easier to write your code because you won't have to remember the opcodes. Thank you. Very good. Bye. Even in data? Yes, normally because of the LC3 in particular, you would put it at the end because it starts your PC at the start. In other assemblers, you could do it either way, but typically people will put the code first and then the data down at the bottom. If you look at the output of a compiler, sometimes it will associate some data with functions. And so it will interlead them. But typically when it's when it's assembled, those two will be separated into different regions of memory. I see. I see. Yeah. Okay. So here are a couple examples. You understand that one? So there's a label over there. There's an opcode, an upper end, and there's a comment. So what does that do? Yeah, it's infinite loop. Mohammed. Okay. You're just going to answer. Okay. Okay. Yeah. So there's just an infinite loop. Right. So how about this one? What do you think this does? Yeah. It does a load of what? Yeah. Whatever bits this branch is, those bits get loaded into R3. Right. This label here references this memory location. So this says, well, take the bits in this memory location and pull them into R3. Now, if you really put it in this order, this one would never run, right? So, all right. So labels name memory locations. Right. So if there's a name of memory location, it's mentioned over here. This is the one that defines it. These are uses in the operand cases. Right. So you can use it as a target for your branch. You can use it as the offset of your load instruction, or your LEA, whatever. Okay. So assembly language also supports a couple things called directives and pseudo ops. Even in the book, they treat these as the same thing. I treat them slightly differently, but most of the world doesn't. So don't worry too much if you don't learn my meanings, but I'll use them this way. So directives are basically they provide information to the assembler. So we'll look at a bunch of examples, but they tell the assembler, well, here's something that I want. You know, you need to know in order to assemble my code. And that's provided by the programmer, of course. And pseudo ops are basically just shortcut notation. So there's something you want to do. And so rather than typing a bunch of bits or whatever, there's a shorter way to do it just to make it easier to write assembly code. So we call it pseudo ops. So let me give you examples. So first we'll do directives. So the dot orage directive, all of the directives and pseudo ops start with a period. Okay, so dot or IG for origin. This tells the assembler, where do you want to start your program? Right. So instead of putting one address like you do in binary, you put a dot orage directive at the start of your file. You can put comments above it, but you can't put any instructions above it. And there can only be one of these. So you say, well, here's here's the start of my program. For example, 3000 hex. And you have to do that once. Again, before any, any actual bits, any lines that would generate bits. At the end of your program, you put a dot end. So second directive dot end. This one you should be careful with because the assembler, when it sees it, it says, okay, I'm done. You told me I'm done. So I'm done. You put other stuff after it. It's done. It doesn't read it. Okay. So I mean, here's an example where you really wouldn't want to put this in the middle. This is not the same as halt, but if you put dot end in the middle of your code, half your program simply will not be assembled. And you know, you can look at it as much as you want, but nothing you write there will be flagged as an error. You can put the multiple instruction down there. It won't get nothing will happen. Yeah. So the assembler will stop reading your code. It's not the same as a halt. Right. So if you don't put a halt, you just say dot end. The LC3 will keep running through whatever bits are in the memory after your program. It'll keep going. So you have to tell the LC3 to halt by putting a halt trap. Not don't expect dot end to do that. Okay. So let me, let me stop you before you finish your question. So if you branch over the end. So the assembler is just taking your assembly code and producing bits. Right. So you can certainly, you can certainly say branch a hundred memory locations forward and not write that part of memory. Not write that many more instructions and enter assembly file at which point the assembly that program is going to branch off into some other part of memory. If you put bits there, that's great. Then it'll do that. That would have to be in a separate file. I think you would load separately into the simulator. But you can't, if you put a dot end, it just stops reading your file. So if you've only put five more instructions, it will not write anything in that hundredth memory location. Even if you put after the dot end, even if you put, you know, 500 more instruction like lines. It will ignore those. Even if they're valid. Yeah. And it's really just telling the assembly, this is the end of the file. And then you really shouldn't try to use it in interesting ways. It simply stops reading the file. Yeah. I mean, LC three, because it's an educational architecture, there's really not much support for having different chunks go in different parts of memory. Right. You can do it by hand in the simulator. You can say, oh, load that file now. Load this file now. Load that file. But it changes the PC every time, right, to the start of whichever file was loaded last. So it's really, it's really kind of a pain to do things that way. And it's not meant to be used that way. Most real assemblers, you would actually have another step in the process that I didn't show you called linking where you would take multiple object files and then build them into a binary. That's in the, in the more detailed version, if you want to see it. And not quite sure. No, no, the problem is just that the software infrastructure doesn't we don't have a file format that allows you to specify multiple non contiguous regions of memory. Yeah, it's it's purely no one bothered to build it. It's all software software. It's not there. Okay. All right. Third and last directive blank words. Blank word directive says, okay, skip some memory for me. Leave them blank. Now, you know there are no such things as blanks or bits, right? What are those bits? You should think of them as bits. What they really will be will be probably zeros. In fact, they will be zeros because they'll go in the binary file and they'll go as zeros. So that's an unfortunate thing. You should think of them as not being filled with zeros because some assemblers will not put zeros there. And so if you use those other assemblers, you could get burned by this, right? If you assume they're zeros. So when you say something is blank, you should assume that it needs to be initialized if you want it to be zeros. So what can we use that for? Well, remember, for example, when we let a user type a number at the keyboard, we wanted to put that number in memory. We just need a place to put it, right? We don't need that place to be initialized any value. We're going to overwrite those bits anyway. So for that, we could use one blank word, make that memory location with the blank word instruction or blank word directive, rather, and then store the answer that they typed into that memory location. So that's a kind of thing for which we'd use the blank word directive. Okay, so some pseudo ops. So what if instead you said, well, sometimes I want to put certain bits, right? So when we did that typing in a number code, we wanted negative ASCII character zero, right? Because we wanted to use that to convert from digit zero to number zero and whose complement digit one to number one and so forth. So what we can use in that case is the pseudo op called dot fill. And that'll let us write a one specific 16 did value. So for example, we can write dot fill hex ff d zero and that'll write these bits ff d zero into the next memory location for us. So if we put that directive in our assembly, we will get one memory location filled with ff d zero. So if you want other numbers, you can put dot fill whatever. So remember that the assemblers just looking line by line, you tell it where to start memory location 3000. And as it goes line by line and sees instructions, it just puts them into consecutive memory locations. So we'll look at that process a little later, but whatever the current memory location is when it sees this directive. I'm sorry, pseudo op, it will drop those bits into place. And that's all. Yes, I'm sorry, okay, screwed up. Yeah, you see remember I mentioned cut and paste bugs. It's a cut and paste bug. I cut and paste my slide and forgot to fix it. Sorry, thank you. I'm sorry. By next, I just mean whatever it's currently writing. So the assemblers just going to generate a bunch of bits. So whatever whatever place it is when it sees this pseudo op, it will simply stick those bits in. So that's what I meant by next. Yeah, so bear in mind, I'm the only one who uses this as a difference. But pseudo ops, pseudo ops are just shortcuts for actually generating bits of some sort, right? Whereas directive just tell the assembler something they don't generate bits. So the blank word is supposed to just skip some memory locations is not technically supposed to generate anything for them. The easy way to do that is to generate zeros, which is why that's what it does in practice. But conception is just supposed to skip. So it doesn't necessarily correspond to an instruction. These bits are not an instruction. This is a trap op code, but a trap instruction has to have zeros here. So it doesn't need to correspond to an instruction. It can be any bits for, for sure. And so when you have pseudo ops, some of them will correspond one to one with instructions. For example, you've already, I already sort of mentioned the halt, pseudo op, right? And halt will correspond to trap 25, one trap 25 instruction. So some of them do correspond one to one. They're just shortcut notation. And that one in the sense that you no longer need to remember 25 hacks when you want to halt. You can just say halt. Okay, so I leave this one to look at that. I left them all. Okay, sorry. Cut in case there's stringsy pseudo op tells the assembler to write a no terminated asky string. So for example, you could write the string hello. And what that would do, you can also include things like backslash end for carriage returns, et cetera. And it will turn those into carriage return characters for you. But it take these characters one at a time out of the string and store them in consecutive memory locations. So each seven bit asky character will get zero extended to 16 bits stored in one consecutive memory location. And then we'll put one more memory location filled with a null, which will be a 16 bit zero after zero extended. But asking all is seven bits to. All right, so don't forget strings. He always writes the null. So number of characters is number of characters plus one. So for example, how many memory locations? Seven, right? So there's three, three letters in the word three periods. And then one more for the null is seven. How about this one? Maybe five, right? Three for the letters one for the question mark one for the null on this one. Okay. Occasionally we ask you to calculate things like this. So you should know how to do it. So the LC3 assembler also supports pseudoops. They got it right here. No cut and paste there. For trap instruction. So the three that you know are get see, which is trap 20 hex out, which is trap 21 hex and halls, which is trap 25 hex. So you don't need to remember those numbers anymore. You can just use them. Oh, yeah. Of course you can have a computer do that. But that wasn't what I wanted you to do for your homework. So now I can assign it, right? Yes. Good point. All right. All right. So what's the advantage? Why do you why do you want to use this stuff? So let's pretend that we're going to write our letter frequency program with assembly now. You can actually get this code, but I sort of want to just pretend that we're writing it's sort of highlight. You know, how much easier it is as you write it. So let's get started. So the first thing is we'll start our code at 3000. So this is not really that significantly easier right before you just had to write 3000 as binary. Now you can write it as hex big deal. But, you know, maybe I don't know the initialization stuff. I just haven't wrapped my mind around it yet. Let me just leave some comments in the code. It doesn't matter because the assembler is going to do all the counting of how long that is, right? So I don't care. Even if I have branches that cross over this stuff, for example, from my initialization code, I have to load the number of bins for my data at the end. It doesn't matter how far away that is the assembler will figure it out for me. And if I change the answer by fixing bugs in the other code, it'll figure it out again. And I don't have to count. I don't have to do anything. So I can just come back later to write this initialization code. Yeah. Yeah. So the question is, are you still limited? Well, there are LC3 instructions, right? So the assembler doesn't change the LC3 ISA. It can only produce LC3 instructions. And so if somehow you get to the point where you tell the assembler produce something that doesn't work as an LC3 instruction, what do you think it'll do? We'll come back to that one. I'll let you answer it later. Okay. So let's write the counting part. So here's our counting part. Remember the first thing we did is we read the first character or rather the character pointed to by the string pointer into our two. So as offset zero, we used an LDR. Remember, we need to come back to that eventually so we can just make up a name. So just make up a name before any more code. I'll call it count loop. Okay. So if we find a null, we need to go to the end of the string. So should I leave this blank and come back and count it later? Let's just make up a name. I can just make up names now. It's kind of nice. I can just go down and write that code. In fact, right? I can just go write that code. It doesn't matter how many instructions it's going to take me to write the rest because the assembler will figure it out. Right? And if I make if I get it wrong and I have to fix a bug, this assembler will figure it out again. And I just don't even have to care. So as long as I make up a name here and I use the same name down here, it's fine. So much easier. Right? So label represents an address. So I do want to make sure you understand this. So this instruction, this LDR is at this address. What is this address? The assembler is responsible for figuring that out. Right? We don't need to care. It's an address. It's some address and memory. The assembler will figure it out and the assembler will make use of it. Same thing here. Right? This label is at some address and memory. When the assembler is going to generate this instruction, it needs to know how far is this away? Right? We can calculate an offset, but that's its job, not our job. Yeah. Yeah, it's sort of similar to see identifiers, except it's not case sensitive. So you can you can. I don't remember if you can start with an underscore. So start with a letter, not a number. I think you can use letters numbers and underscores. I think you probably want to start with the letter. That's right. That's right. Yeah. So done represents an address, but here we need an address to do the offset calculation. Right? So normally if it were us, the humans calculating the way you do that is say, well, what address is BRZ? What will the PCB will be BRZ's address plus one? What address is this at done? Then I would subtract or count one way or the other to get a done address minus PC address, which is branch address plus one. And then get that offset and then put that into the instruction. Yeah. Possibly. I'll show you how. Yeah, the question was, will you ever be asked to make a symbol table? Possibly. I mean, look, the assembler's not doing anything harder than you've done 20 times in your head as we went through code, right? So it's really not hard. All right. So what's next? We wanted to compare with capital A. So we can write some code. This was the code we wrote to do that. Again, we have a branch. This was in the case where it was capital A or bigger. Well, again, just make up a name. We can put put that code down there or we can just wait till later to write it. And it doesn't matter. As long as before we invoke the assembler, we've written this label somewhere. That's good enough. Okay. So once we find out once we do the branch, sorry, I probably could have deleted that. Once we do the branch, we're going to reuse this code. We may not realize that we didn't say that the first time we're writing the code. We always come back and add this label, but that was our code to increment the non alpha bin. Right. So we had this instruction to read the read the non alpha bin, add one to it, write it back. And then we had to branch. And again, just make up the name. Every time we need to go somewhere, I want to just make up the name. It's good enough. We do have to make sure the names match. Right. So when we get around to writing the other piece of code, we have to make sure that the names are identical. And the assembler is not going to figure it out. So what about the data. So after the code, we had to write things like well, the number of bins was 27 negative at sign is this the string start. Oh, look at this thing. What does that mean? So this thing here that says, feel string. So this is an address, right. So here's the address down here. I don't want to need to know. I just want the address of this string in memory to be stored here so that I can load it into a register without an LEA with an LB. So here's my histogram. Right. I made the histogram be just part of my program now just a bunch of blank words, place to store my histogram. So now that we have an assembler, this kind of stuff is easy. Right. Before if I said, oh, well, I want to put my histogram at 31 38. Oops, my program's too long. I've covered it. Now I got to go change it. Now I got to go change a bunch of other stuff, such a pain right here. Let this somebody figured out doesn't matter. I've got a name for it. Some other piece of code wants to use my histogram. Use the name list. It'll find it. Okay. Yeah. Blank, we're just skips 27 memory locations. Well, whatever you ask. So here we ask for 27. So remember, we needed 27 bins for a histogram. So this says, leave me 27 memory locations. I'm going to do something with them. The first one is named his. The others are his plus one is plus two. The string would be the address his plus 27. That's right. Yeah. Yeah. That's something you should know how to do is figure out how many, how many memory locations will each suit up or instruction take. Right. So this one, for example, would take one, two, three, four, five, six, seven, eight, nine, right. One for the null. And so if you had another label under this one, it would be string plus nine. Yeah. It is certainly possible. But if you put that, that would be blank words equal to the address here, which would probably be a fairly large number of blank words. I mean, as long as it's, yeah, you owe you me a copy of this value. No, there's no easy way. Yeah. No, no, we can't. And I'll see if you're. All right. So how do assemblage work? Same same way we do for this purpose. We can do other things. Assembly just does this one. Yes. So you can write code to do it. But, but I believe Daniel's question was, can you write the code in such a way that they're both initialized to the same value without copying the value in your code. And I don't think there's an easy way to do that. Okay. So step one, figure out the instruction sequence, step two, map instructions and data. So this will be the first pass of the assembler. The way the assembler is going to work is it's going to look at the program twice. The first time what it's going to do is just go line by line and say, well, this, this instructions at this memory address. Next instructions that that memory address plus one and so forth. Just write the address is next to it. Then it'll fill in the offsets. How will it do that? Well, look at the addresses. It wrote next to the bits going through the program again, the assembly program again and calculate all the offsets and write the bits of the instructions. So two step process. So here is the first part of the code. I chopped up the comments explaining things and then there's a lot more code underneath, but this is the first part of the assembly version of the letter frequency code. So you can see, we can start counting. This would be the first pass. You can see up here it says, or just 3000, right, dot or just 3000. So we'll start there. And the assembler will say, okay, here's an LEA. Well, that LEA is at 3000. Okay, good. Here's an extra instruction down here. This is just a comment. Next instructions that 3,001. Here's the next instruction. Guess where? Yeah, you guys are good at the counting. Are you sure you want an assembler? All right, 3,003. Right. So keep going. When we get down here, we see there's a label. So whatever the current count is, right, the place this instruction would go. That's the value of that label. Okay, so HF loop. This was histogram fill loop is at 3000. So what the assembler's going to do in its first pass in addition to all this counting is build a table called a symbol table. So here's the symbol table. I left some of it out because it's a little big for this program. Here's a symbol table for that code, right. So you can see HF loops of 3000, 4 count loops of 3000, see non alpha, 3,0010, blah, blah, blah, blah, histograms down here at 3028. And that should be plus 27 to string 27 decimal, which is what 1d. Yeah, these are in hex. So, yeah, 1b maybe. Anyway, okay. So that's our symbol table. So in the second pass, what's the assembler going to do? Well, it's going to start counting again at the beginning. Right. So see the dot origin 3000. So okay, started 3000. There's LEA R0 hiss. And so wait a minute. What is hissed? Let's go look it up. We have the symbol table from the first pass. Right. So in the second pass, when it needs to generate the bits for this LEA, it's going to say, well, I got to go look this symbol up in the symbol table. So where is hissed? Ah, so it's down here, right. So 3028. So go back here. Pist is 3028. What's the PC when this LEA executes? 3000, 1, right. Okay. So then what's the offset? X 27. Good. And that's it. Now we have enough. Right. Now we can write the bits. Or rather the assembler can write the bits and we don't have to. Okay. So what happens if the assembly file has a mistake? Oh, good luck. Yeah. So I guess really? Yeah. I had you going with that one. Yeah. All right. So yeah, you get to fix it. Right. I mean, it can tell. Yeah, this is not going to work. And it just says error. And then you go fix it. So what kind of things can it detect? So in the first pass, it can tell if you put bad mnemonic. So, you know, if you get excited, you see, multiply. Now, sorry. LC three. Or bad off range. I want to use our 42. Or you say, I want to add 1000. Right. No. Out of range. Sorry. Not going to work. What about label? So is this code? Okay. This code should be okay. Right. Just that, you know, this label that I want to go to is down here. So what? Oh, it is a memory location. I don't have to have code there. It's okay. It's a memory location. This branches forward. So in the first pass, when I get to this line, it's not in the symbol table. Right. This label is not in the symbol table because in the first pass, we haven't seen this line yet. So there's no label in the symbol table. So in the first pass, you can't you can't say, oh, there's no such label because maybe it's just down further. So you can't have that error. But reads a file in order. You may not find it when you go look if you look in the first pass, but that's okay. Right. Yeah, you're going to have a second pass. So in the first pass, you cannot detect undefined labels because it might just be lower in the file might be branching forward. What about this code? So, well, so that you're trying to make it do something smart. So, I mean, maybe these are maybe a little confusing because they didn't put anything in between. So this probably this should come up to the same address. Right. And I think, oh, that's okay. But it's not okay. The computer's not that smart. Normally, if you have two two definitions, those are going to be different addresses, right. Most often they would be different addresses. And they'll see three in the assemblers not going to make a choice for you. Right. So it'll just say, well, you got multiple defined labels. So if when you go to the symbol table, you find the symbol already there in the symbol table, that label appears twice and it just generates an error. I'm usually not completely for all label types. There are local label types in some assemblers. Yeah. Yeah. But not an LC3 or something. Okay. So, multiply defined labels the last first pass error. All right. What about the second pass? What can go wrong? We saw one already, right? We decided we couldn't find. So find his where's his. Oh, it's not there. We had a typo, right. We got down the bottom of our histogram instead of his. That was a kind of similar, right? One, one, the assembly just say, you probably meant this. No. So it'll just make an error, right? So the label is not defined. It'll find out in the second pass. It'll say, well, where is this label? Look in the symbol table. It's not there. There's an error. There's nothing it can do. But what else might go wrong? Okay. You already asked about this. Yeah. So what's wrong with this code? Yeah. This is just taken out of the middle. So imagine I put a dot origin, a dot end. Not a whole program. Just a little piece of snippet of code from the middle. How about this bad, bad style? Right. So if I asked you to turn this into bits, what would you get? So yeah, it's very good. Good answer. Perhaps even involving 42 and X. All right. So this alliation, not be a problem, right? Because PC is pointing here. And so the offset will be down to here. What about this stop? So that's 4200 plus 1 4201 ahead, but PC points here, only 4200 ahead. So you just put the offset 4200 into the branch. It's yeah, you only get nine bits in a branch, right? So is there such an instruction? There's not. Right. So that's bad. So the LIA would need more than nine bit offset. Yeah. Yeah. So what you have to do is you have to, you have to use jump instead. And so you'll have to. I'm not sure I would call it elegant, but that's the only way to do it in LC3. Which is to branch over over a jump and then use a jump. You may have to load a register first. You might even have to put the data next to it if your data is very far away also. But load the stop address into register and then jump to that register. So generally, but the assemblage not going to do that. That's rewriting your instruction sequence. I think they're there. You could change branches together to avoid using a jump, but I would recommend that you don't do that that you use jumps instead. You never have to do that. Jump can go anywhere. Sorry. Oh, this is a label, right. But the assembler can't figure out how to insert an offset that's too big into the instruction. The assembler does. And if the count is too big, too bad. Right. It can't fix the problem for you. Here, it can do the counting. But the answer is 4200 hex for this for this branch. Sorry, this one. This should say the branch not the LEA. The LEA is fine. Yeah. So the branch offset is broken. The branch offset is going down to the stop. This stop label. And that this is 4200 memory locations. So that would have to be an offset of 4200. You can't fit an offset of 4200 into nine bits. You can't be able to deal. Oh, now there's no local labels in LC3 assembly. Okay. Any other questions? I think we're slightly over time. So if you have a quick question. So I think it says label out of range or address out of range or something like that. Yeah. So I'll leave that up. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you."
    },
    {
        "ECE120-2016-09-30-LEC-16-slides.mp4": " section. Okay, so if anyone wants to chat with me, feel free to stop by. Policy update, as of the trouble with the lab, not this week, but last week, you'd lowest two labs on the LAMB drop instead of just your lowest labs and GWS, I guess, killed our software, all right, before the deadline. And then I just wanted to do a quick review, because a couple of people that asked me about finding all the notes and videos and stuff like that. So if you go to Google and if you can remember how to spell my name and type it, then you can find my homepage, and then you can go down here to classes 120, oh, sorry, it still says 198JL, that's the original name. F16, you go there, and then on this links page, you have all the online exercises, you have all of the PowerPoint slides, have all of the recorded video lectures from the class, and then the C code examples, and then some extra stuff if you want it. There's also a copy of the reading notes here, so if you're looking for those, they're here. It's easier to read like this, maybe. Or PDF viewer doesn't want to do what I want right now. Anyway, so those are there, and then obviously the top thing takes you to the wiki where all the rest of the class resources are. So hopefully everyone knows how to find everything. So just do a quick review. All right, so today, oh, now it's in, it looks funny. I won't went to that log. Anyway, so we're going to start by doing a checker for uppercase letters, more examples of building with abstraction. Then talk about multiplexers or moxes, spend a little time on decoders. We may start sequential logic today, or we may not get to it until Monday. I didn't put it on the list, but we may get there. So I want to do another example and show you a few different ways that you can break up problems to make them easier than going all the way down to K-Maps. So let's start with one where we say, well, let's have an ASCII character, seven-bit code, C, C, 6 down to C0. And let's make a piece of hardware that will tell us whether that ASCII character is an uppercase letter. So you may or may not remember an ASCII A is this bit pattern, which is hex 41. Capital Z is this bit pattern, which is hex 5A. And so how do we check? If I give you these six or seven bits, rather, how do you tell me is this a letter or not? Yeah, that's exactly. That's one answer, right? We can use some comparators. I'll put that off. I'll do it a slightly different way, but that's a good answer. Yeah. So these numbers here, we're going to have to feed into the comparators somehow. Okay, so we'll come back to that answer. So here's another way we can do it. Go down to truth table. And it helped me out. Is this one an ASCII character? No. Okay, what about this one? Okay, there's a lot of slides here. So that's where you're out. All right. So maybe, maybe, I mean, a lot of these are zero, right? Maybe we can just skip to the ones that matter. So what if we just take our truth table and we break it up into pieces? So we got 128 rows, but most of those rows are zero, right? So let's break it up into eight of them. So each of those eight pieces of 16 rows will be one value of C6, C5, and C4, right? The three leading bits. And then we can solve each of the little pieces, the groups of 16 rows with the K-map on four variables, right? So we could do it that way. So maybe we don't need a K-map for some of those, right? Maybe we don't need to do eight K-maps. So remember, A is this thing, Z is this thing. So what about this truth table? So C6, C5, C4 equals zero, zero, zero. What's the function? Zero, right? So you didn't need a K-map, right? You want to go a K-map? I know K-maps are fine. So maybe we do it now. Let me just skip it. By the way, I want to make sure you know when I write something like this, this means C6 equals zero, Antify equals zero, Ant4 equals zero. So we'll write that increasingly often. So no asking character with those up for three bits is not per case letter, right? So that function is just zero. So that was relatively easy. So which of the eight functions are not the zero function? Yeah. So any time we have C6, C5, C4 is one zero, zero, one, zero, one, some of those are letters. All the other possible values of those three bits, those are just the zero function, right? So out of eight different K-maps, six of them are zero. We're done, right? We've got two more. And so if we break up the truth table, then we can we can solve a lot of it pretty quickly, right? Well, six of them are zero. So let's call that function T4. The four I'm getting out of just this number here, right? So one zero, zero is four and indecent. So we call this one T5, and that's it. So let's just do the K-maps for those two. So here's the K-maps for T4. What do you think? That's O-P or P-O-S. No, P-O-S? Okay. So max term, right? So what is it? Yeah, add them all together, right? That one? Okay. Okay. Good. We're done with T4. So it gets pretty easy at some point. Okay. So here's on a T5. I claim P-O-S is slightly better again here. So what are the loops? Yeah, I want to do P-O-S again. Yeah, sorry. So this one here. Okay. What is that one? Like that? Okay. And what's the other? The two horizontal zeros? Okay. And that one's this. Okay. Okay. So that's it, right? Those two factors. All right. So then how do we put them together? So we've got T4, we've got T5 with six zeros. We could write down if we want. I won't write them. So T4 applies when C6, C5, C4 is one zero, zero, T5 applies when C6, C5, C4 is one zero, one. So what should I do? All right. So what if I, let's see. So I want this one to apply when this is true. Can I write an expression for this? So I need to add T4 with C6, C5 prime, C4 prime, right? So if I write C6, C5 prime, C4 prime, that means these three are equal to those three, right? So and T4 with C6, C5 prime, C4 prime, and T5 with what? The six, C5 prime, C4, okay? And then do what with those two results? Or them together, right? Okay. So that's my answer. So it looks nasty, but it's not really that bad, right? It's pretty small, pretty fast. It's not too level logic. It's a little more, but we still have to do a little bit of work, right? So you already know the easier way. So this is the question we can think of it as, right? We know how to build comparator. So instead of saying let's go build this expression, we can instead say, well, I know how to build a comparator. I know this is a contiguous range because on homework number one, we ask you some question about why did we put digits in a contiguous range? We said, well, you could do translation to binary numbers, right? And well, why do we put letters in a contiguous range? So you could do this kind of thing. So you need to check well is C greater equal than A and less or equal than Z. If it is, well, then it's letter. If it's not, it's not an uppercase letter. So here's two comparators. So I built two seven bit comparators using our bit slice approach and just flop them down in my, in my diagram. In both A inputs, I put the C, the character and ask you that we're comparing, into the left comparator, I'm going to put hex 41, that's the letter A, remember? And the right comparator, I'm going to put the letter Z, that's five A. And then I have to go back and look at my representation, which I didn't rewrite for you guys, but remember that if you've got Z zero on, that implies that C is actually less than 41 hex. The A is less than B. The Z zero output is one. And if the Z one output is one, that implies that the A is greater than B. So C is greater than five A. So if either of those conditions are true, it's not an uppercase letter. And so if C is less than the letter A, then it's not an uppercase letter. Or if it's greater than the letter Z, it's also not an uppercase letter. So I have a nor gate down here that takes those two Norse them together and gives us our uppercase function. So fairly simple, fairly easy, probably could write it down in a couple of minutes. The hard part is going back and looking at the representation to figure out what gate to put there. Okay, what about this? So you're not going to build adders, right? You could do it with adders. So last lecture, we saw how to build subtractors. So these are actually being used as subtractors, right? So this thing here is what's BE4. Well, that's 41 hex, one's complement form. And so this is one's complement of 41. This is carry in of one. Remember that when we take C, this is zero extended to be 8 bits, when we take C and we add it to not be plus one, that gives us C minus 41. So C minus 41, if that overflows, I'm sorry, yeah, if we get the carry out, that means no overflow. If we don't have a carry out, if carry out is zero, that means that C was less than 41 hex. And so if we get a zero carry out that comes down here, goes through an inverter, changes to a one, forces U to zero. We can order a. So in other words, if C is less than letter A, capital letter A, we'll get a U of zero. Similarly, over here, A4 is one's complement of 5A, I think. I took that wrong, didn't I? Should be A5. Sorry about that. So that should be A5. Yeah, the way, do we need a, let me think here. So we get this one minus 5A, maybe it's for the greater equal. So 5A, yes, inverted sense. So this is C minus 5B. And so if we get a, if we get a carry out of that, it's 5B or more. So that's why it's off by one here. So this has to be the greater or equal to 5B. That's what the carry out means. If that's true, it's not an uppercase letter. And so we're getting a greater equal then when we flip the carry sense. And that's why this is one's complement of 5B instead of 5A. Does it make sense? Okay. All right. So with these two adders, basically each adder is checking one bound of the range, same as with the comparators. So we can build it this way too. You can say that answer. So what's the trade off? Well, those are kind of large and slow compared to our first solution. If you write it down as gates and you show how many gates you need for that first expression, it's really not very many. It's pretty fast, few levels of logic. As compared to our seven-bit comparator, where it's going to have maybe order 14, 15 plus the logic at the end, so 16 or so gate delays. So substantially slower, substantially bigger for the comparator approach. Same thing for the adders. You've got to wait for the carries to ripple through if you build them as ripple carry adders. So they're slower and bigger. On the other hand, the CAD tools can optimize a lot of that overhead away. So if you look back at the adders, we're actually throwing away the sums. So we build these adders and then we calculate the sum and then we just ignore it. So the CAD tools can look at that and say, well, you didn't use those. So any gates I used to generate those bits, I don't need those. So it already start trimming down the design that way. But it can also do a little bit of optimization for you. The other way to look at this is this is like XML parsing or something. If you're going to do XML parsing in your data center, which lots of data centers are doing 24 hours a day, seven days a week, 365 days a year, all the time, what are those doing? Well, they're using software. They're saying, oh, compare this incoming character to capital A, compare it to capital Z, actually, probably with 32 or 64 bits at a time instead of eight bits. So we're actually doing that all the time in much less efficient ways in software. So this kind of hardware, if you build something like this, if you can get it sitting and doing XML processing, for example, it's more complicated task than just checking characters, but it can actually be a lot faster even with the slower and bigger design. They're using it using process or process. Yeah. Yeah, possibly. And that would be an argument for doing it in software. The computers you're using in software are part of the processor and you can use them for myriad other purposes. But in reality, even 15, 20 years ago, with TCP IP, network processing, before everything was XML based or HTML based, if you looked at a typical data center, a lot of your processor cycles. So on the order of 10 to 15% of your processor cycles were spent doing this stuff. So there's actually a reasonable amount of research in what people call TCP offloading, trying to process networking protocols, TCP IP offloading, networking protocols, in hardware off the main processor so that you could have your processors actually run internet services instead, and reduce your cost that way. So yes and no. There's benefit to it, but getting the generality you need, especially as the protocols evolve over time, is sometimes difficult. So people have tried it, have tried the TCP IP thing at least three times in the last 30 years. And there's some of it now, I think, in the industry and real data centers. But it's hard to get right in a way that can survive for a long time. And that's partly because that once you put it in hardware, you can't change it. It has to be the same. Good question. Yeah. I'm not in this class, but you can do it. It's a good question. Yeah, I wouldn't ask you to do something that complicated in that class. But yeah. So we want you to understand how to do it and how to approach these kind of problems, both in the sense of if you want to go down to the level of building out of gates, to know how to do those things, but also to know how to use the components that you can pull out the shelf to build things. So right now we're looking at examples of the ladder. It's a solve problem as you can take pieces of known solutions and glue them together and do that very, very quickly and only optimize afterwards. If it's something that's that is too slow or too big, then you can go make it smaller and faster by spending more time on it. So we want you to understand both strategies. Do you want to answer the question? Okay. Yeah. You look ahead in my slides. Yes, yes, we can. Hold that thought. I won't repeat it for the camera because it'll come up again in good question. Anything else? Okay. So multiplexers. So here we go. You didn't have to hold it for long. So what if we want to take a lowercase letter? So lowercase letters are 61 hacks through 7A hacks. Remember that uppercase were 41 through 5A. So can we reuse our solutions? We just do what was it you said? Right? So you'll notice if you put them side by side that bit c5 is flipped. Sorry, I took down the representations, but they couldn't all fit on the slides. We had this answer before by breaking up the truth table. So I'll go back. The only difference here is bit c5 here is a 1, bit c5 here is a 0, c5 is a 1, c5 is a 0. So look to c5. So change c5 here, c5 here to c5, sorry c5 prime, c5 prime to c5 c5 were done. We've got a lowercase checker. Oh, sorry, I thought you were raising here. And if you want to use the comparator for that purpose, right? And all you have to do is change these inputs up here. So change that one from 41 to 61. That means Z 0 equals 1 now implies C less than 61 hacks. Change this one from 5a to 7a. That means that Z 1 down here equals 1 implies C greater than 7a instead of 5a. And then we have a lowercase checker instead of an upper case checker. So very, very easy to just go change that answer. So what if we want to design one answer to one piece of hardware that does both? And so we did that a couple times on Wednesday. We did a unsigned and two complement comparator by exorring the sign bits with the signal s. We did that with an adderance of tractor, right? Where we put them together by again having control signal s. But what if we want to have just logic that allows us to have some control signal s that just selects between two arbitrary signals? So we'll design this logic and then go apply it to our problem here of designing one piece of hardware that checks both upper and lowercase. So if I want to do that, here's a full truth table. So I have a select bit s, right? It could be 0, 1. I have two data inputs. They could be 0, 1. And those are the eight possible patterns. And so if I select bit 0, that pulls out d 0 and I get a 0, 0, 1, 1, 0, 0, 0, 0, so forth. But I could probably make it a little shorter, right? So instead of drawing this big truth table, I know that if I select 0, I don't care what d1 is. So here we're putting x on an input, which is different than putting x on an output. This says in this truth table row, d1 doesn't matter. d1 can be 0 or 1 and q will still be 0. So this row here then represents these top two, I'm sorry, not the top two, this one and this one here. The first and the third, the second row then represents the second and the fourth. It also says, well, if selected 0, d1 doesn't matter. If d0 was 1, q was also 1. So we can have an abbreviated truth table. I mostly wanted to show you what it means to have a don't care symbol on the inputs. So it means that we're merging multiple lines with the same output. You have to be careful because if you have more than one overlapping set here in your rows with different outputs then you have an ill-defined truth table. So you got to be careful. I enlarge something. So this is what implements this function. So this output to you is the result of a multiplexer. But I'll show you logic diagrams in a bit. We'll derive them. So it's the thing that allows us to answer this question down here. Use one control signal to pick between two arbitrary signals. So the answer we call a multiplexer. I debated whether I should put it in the titles, but that's what we're building towards. Yes. Yeah. Although I call them d1 or d0. Okay. So here in this abbreviated one, what I was telling you, unselected inputs don't matter. So remember, s is select. So the ones that are not selected in the if s is 0, then d1, if s is 1, then d0, will mark those with don't cares. And furthermore, I could even, in this case, I could write the truth table in a really compact way. So I could say, well, if s is 0, the output is d0. So whatever, this is now an input, but I'll say, well, that output corresponds to this input, then I just have two rows. So as we go forward in the class, it'll be more and more necessaries. We build bigger systems to start writing truth tables where we take advantage of the short cut notations. So I just wanted to introduce a couple of them. All right. So let's go ahead and solve this problem with the K-map. So first we'll copy. So I put d1 and d0 on the top. So we're going to go across, and then we'll just copy from q into this K-map. So start with this one and then go downwards. So we've got 0, 1, another 0, but remember, we need to hop over one and copy. So 0, 1, 1, and then 0, 0, 1, 1. So 0, 0, 1, 1. So what are the loops? So we could do this one, but we're going to, if we look at this one, for example, we have to have this loop, right? Yeah. So remember, this was the example we were similar to the one we used for consensus. So we don't need to have that one. Those two loops were done. So yeah. It doesn't actually matter, right? They're equivalent in this case. So you're right that I probably should take a look at that and make sure that I think that, well, visually solve them and see that I think one is better than the other. If it's close, I may solve them exactly to compare them. Right? In this case, there's symmetric. So it's going to be identical. Yeah. So the question was SOP versus POS. They're the same here, terms of complexity. So we'll solve this one with SOP. So we'll write it down. It's S prime d0 and S d1. So I could have done that a little differently. I could have started with my small truth table and said, well, when I have S 0, I get d0. So S prime, that's the min term for S, S equals 0, sorry. S prime, and it would d0 gives me this row. And then S, this min term, and it would d1 gives me this row. And I order those together, that's my function. And in that form, it's maybe a little easier to see that, well, all this is letting me do is, when S is 0, I pick d0 and when S is 1, I pick d1. So this is a device, which we call multiplexer that allows us to pick between two signals, whatever they might be. And I'll forward one of those signals, depending on our choice, which is S, to the output Q. So here's what it looks like. All I did here is implement it the logic that we had on the last slide. So this is how a 2 to 1 months is implemented. This is how we draw it as a trapezoid with data inputs 1 and 0. And then which of those gets forward? It just Q depends on S. Yeah. Yeah, so the question is, what are we going to use this for? And the answer is, well, when we want a piece of hardware that does more than one thing, we have to tell it which thing we want to do. And so we can control which inputs it looks at using something like a multiplexer. So I'll come back and actually put that in front of our devices. But yeah. Good question. Like this? Good question. What if we have four expressions, for example? So we have 3, 2, 1, and 0. What should we do? So yeah, one answer is to use hierarchical moxons, right? So we can start by using 1, 2 to 1 mox. We'll control it with a signal. Let's call it S1 for now. And let's decide between D3 and D2. D3 or D2 will go into this input. And D1 or D0 will go into this input. No. D3 or D2, the way of numbered this. Yeah. Eventually. Yeah. Yeah. So the next question then is, well, how do we get D3 or D2 to go into this input? We're going to use a mox, right? So how are we going to deliver two expressions? We use a mox. Control by S0. Okay? So here on the top, we pick between D3 or D2 using S0. One of those two will go into the input to this second level of moxons, which is just one more mox. Okay? Down here, we're picking between D1 or D0 also based on S0. And this choice here is based on S1. So if you think about what ends up happening, I'll look at it in more detail on the next slide. But S1, S0 is basically a two bit unsigned number that chooses between input 3, input 2, input 1, and input 0. Sorry? Yeah. Yeah. Okay. I really like it. No, no, no, it's great when you guys are predicting this slide that means you're early on top of things. Okay. Yes, you can do it with 4N gates. And each of ways, each of these is a min term, right? So if you think about what's going on here, each of these 4N gates is producing a min term, ended with one of the, with one of the D inputs. Okay? So let's go through those. So this top one is D3, ended with S1 and 0, which is the min term which you could think about as number 3, right? It's the 1, 1 min term. So those get handed together and produced by this AND gate. The next AND gate is D2 with S1 and 0, prime. And that's 1, 0. That says, okay, I want input number 2. Down here, D1, ended with S1 prime S0, that's 0, 1. So that gives you the D1 input. And then down here is D0, ended with S1 prime S0 prime. So that gives you the D0 input. The outputs of all four of those, only one of these 4 min terms can be on, right? S1 and 0 has to have one of those 4 bit patterns. Only one of these 4N gates will produce a 1, ever, right? So then we order them together, that gives you Q. Yeah. I thought it'd be easier for you to understand if I draw it this way. I'm sorry, I forgot to include that slide. Yeah, okay. So I mean, you should know, I know actually a few people had some trouble with this on the homework. So anytime you have two level SOP, you can just literally go replace both levels of gates with NAND, it'll be the same. So I mean, I want them to be NAND just draw NANDs in place of these. I didn't do it, sorry. Yeah, sorry. So that's an interesting question. So the question is, well, could you just connect these four outputs together? Remember that these are active, what we call active logic. And so if you think about the if you think about the way this is these gates are working, you are actually connecting one of them the high voltage in the other, or maybe to high voltage if it outputs a 1. The other three are connected to ground. So if you connect the outputs, you've created a path from high voltage to ground. I will show you later in the class how to do what you're saying, where you actually electrically disconnect some of the outputs from a wire and then you can use multiple outputs to drive the same wire. But you have to have electrical disconnection, not connection to ground, which is what you get out of the gates. Good, good thinking though. Okay. All right. So here's the symbolic form. Bigger trap is always labeled with the four different values, two bits of select input, so crosshatch with the two. And of course, we could then further generalize, right? So you can build a to one moxies, you could build them out of four to one and two to one, you could build them out of and gates. At some point your or gate at the end gets too big, so you'd really have to have multiple levels there. But but conceptually it's it's the same. You can build 16 to one 32 to one, so forth. So anytime you want to select from two to the n, where I'll name that p to make the notation down here easier, with the p minus one down to d zero inputs, we need n bits, right? The log of p, log base two of p. Yeah. I mean, in theory, it's infinite and practice usually at about four, you'll you'll want to put more than it depends on the depends on the semiconductor process, but usually it's around four. You mean how do the CAD tools do? Yeah, so the CAD tools are actually, so there's a set of engineers who are working on the fabrication and and we'll go and measure the fabrication capabilities and the speeds and the timings of the transistors and things like that as well as the capacitive load of different wires. And then all of that gets fed into the CAD tools with with process, semiconductor process specific information that the CAD tools then used to optimize. So so there's a lot of information that's that's not even available to the public, right? So unless you're contracting with that particular fabrication facility, they won't even give you those numbers. Those are those are proprietary numbers that that you would get out of them. So the CAD tools are obviously designed to use that kind of information and sometimes you'll see some of it if you're working on hardware. Okay, the rules of thumb have been sort of similar for a while, right? But the details are all hidden. All right, so so we can use sets of muxes also another way to generalize the multiplexer instead of just thinking well we could have bigger sets. We can use multiple many copies of the same kind of multiplexer using the same select bits to switch between groups of bits. So for example, well, let me generalize it first. We can we can have an end to m multiplexer, which is actually m copies of n over m to 1 muxes, right? Each with log base log of log base 2 of n over m select bits and typically n over m is some power of 2, right? So for example, when we did our subtractor design, we said well we want to we want to take B or complement B, one's complement of B. And we did some optimization there. We could have instead just used muxes, right, and put B into one one input of the mux B prime into the other input, but we'd have n copies of the 2 to 1 mux to do that. And they would all be controlled by the same selected either we want all of the bits complemented or none of the bits, none for addition, all for subtraction. Now when we talked about it, we actually did a little bit of optimization for the mux implementation. We said well because we're putting B and B prime in, we just need an x or gate, we don't need a mux, but we could have just put a mux down. And actually the CAD tool probably would have figured out to replace that with an x or gate anyway. It's simple enough logic that the tool could figure it out. All right, so let's then back up a step and think about our ASCII character checker. So let's say now instead of just upper and lowercase, I want to check for four different kinds of comparison. So I want to say well, let me check for control characters, those happen to be the range 0 to 1, fx. Checker lowercase, so 41 to 5a, 41, not 40, sorry, 41 to 5a hex, uppercase 61 to 7a hex, and digits 30 to 39 hex. So I want to check all four types with one piece of logic. So what should I do? Yeah, mux is what kind? Yeah, so a set of 401 mux is, right, a 28 to 7 where each of the ASCII characters is compared against one of four possible lower range values, 0, 41, 61 or 30, and one upper range, 1f, 5a, 7a, and 39. Which of those four I put in is actually just controlled by the same two bits, right, for all 14 of those four to 1 mux. So the same two bits make my choice for me between the four different possibilities, 0 to 1f, which gives me control characters, 41 to 5a, which gives me uppercase letters, 61 through 7a, which gives me lowercase letters, and 30 to 39, which gives me digits. And then I just look down here at the output to see for the range I chose was the answer yes or no. And if you use the same hardware, it's an accent, yeah. What are you relying on to give you what I'm sorry? So the S input, right now we've only done combinational logic, right, so this is just like any other input to our logic, right, so somehow we need to tell this piece of hardware which operation we want to do. So later we'll see how we can store state actually will start it shortly. But eventually we'll build full computers and then it'll be up to us to make sure that the answer to your question gets routed to these two input bits at the right time so that we perform the correct comparison. At this stage, probably not too much, right, at this stage we're designing something that is usable, right, that the human can can arrange to have the right to input bits. I mean, humans can make mistakes everywhere, right, so you can design an adder and they put the wrong bits into the adder, they get the wrong answer out. So in all stages of all kinds of engineering design, you have to think about, did a human make a mistake someone. There are sometimes other sources of error too, but humans are responsible for most mistakes. Yeah, when it seems like a computer is responsible for most mistakes, it's actually the programmer who... So yeah, occasionally there are things like cosmic ray strikes that will cause bit flips that will... So there are hardware, hardware software slash errors that come up because of nature. Most bugs are because of humans in some way. All right, so one more piece actually before we start sequential logics, maybe we won't get to sequential logic today. So decoder, so it's going to be a little bit abstract, this will make more sense when we get to memory. So what if we have designed a representation within bits, I mean, we did a bunch of them when we did bit slicing, right, but what if we have an end bit representation of something and we want to know and we have a value in that representation and bits, we want to know which of the values is it. So one signal that tells me, okay, this was the mango ice cream or this was the leechee or this was the pistachio or whatever, one signal each. Okay, so what am I going to do with that? Well, naming sets of bits. So again, when you see memories or register files, probably three to four weeks out, we'll need this, right, this will be one of the primary components in the construction of a computer memory. Okay, so we will need to have the coders. Another one is actually generating arbitrary functions, logic functions dynamically. So this was used in old reconfigurable logic. So called programmable logic arrays basically. So I'll show you how that works, but for many years that was how we built dynamically reconfigurable hardware and did hardware prototyping quickly. So in other words, given a set of end bits, I want to generate a signal for every possible combination. So those signals then of course correspond to the min terms. And so for every min term, I have a signal and exactly one of those will have the value one. So decoder generates all the min terms and one of them will be one. So you might remember we saw that in the mocks, right? So there's a similar structure. So here's a decoder, two to four decoder. So it takes two input bits and generates all the min terms here. I've added an enable signal. So in fact, for this decoder, if enable is zero, enable goes to all four of these and gates and so all the outputs are zero. Right? If enable is one, each of these becomes a min term of s1 s0. And so one of the outputs will be one and the others will all be zero. And so this is decoder. And if you were then to be mean and ask me, well, this is not man to know. And it's not too level. I'd say, yeah, it's not quite accurate, right? You're going to need extra inverters to make this a real circuit for CMOS. Because if you use the Morgan's law, you'll get extra inverters on this side, which you can easily just swath the inverted and in non-inverted lines here. But I guess you'll get a bonus inverter and enable. Yeah. I'm not sure if I understand what you mean. I mean, a one gate, a one input nan gate or an or gate is an inverter. Right? If you think about the parallel versus the circuit, if they scale it down to one transistor, that's then an inverter. But unless you have two in a row, they don't just cancel. So when, yeah. Yeah. Yeah. Okay. I'm not sure if I understand. I mean, I can use a two input nan and connect both inputs to the same thing. I see. But that, but I can do the inverter with one input. I mean, I can also have three inputs or ten inputs. It's all the same. It's all an inverter if I connect them all to the same input. Yeah. But what I can't do is when I change this to a to an or gate in order to make it CMOS, I get inverters here. So all of these will be inverted. So these two inverters will be flipped. So that's fine. It's the same cost, but I'll still have one inverter that I need for the enable. So I'll have one extra inverter in the nan more design if you if you work that out. Okay. So this is what we how we draw a decoder. It's the trapezoid going the opposite way. So the end bit signal usually comes in from the from the smaller side, not the narrow ends, but the smaller side of the trapezoid and the outputs then come out from the other side. If the decoder has an enable signal, not all of them do, but it's pretty common, I it'll come in from the from the narrow side. And so this symbolic form of the decoder. I do want you to notice that this this structure is very similar to the mocks, right? So in the mocks, we then and at each of these min terms with one of the data inputs and then we'll order all the results together. But we have the same end gates to generate all the min terms. Okay. So so they're they're very similar in that sense. The decoder allows these min terms to be used separately. So for example, if you were building a bending machine and you wanted a bunch of products coded in some representation and each of these outputs could then control the mechanical release for that product. And you you'd release exactly one product based on the product that the bending machine said, okay, time to release a product. And you you probably want to release one at a time, rather than having you bending machine drop a random subset or something. Yeah. Well, so there are no there are no two to the end data inputs were in as the number of select bits, right? So there's nothing actually get it and getting ended in with the min terms other than the enable signal. So that's one difference. And the min terms are not being or together. So in a practical sense, the way that's used is we can compose arbitrary functions by oring together the right set of min terms. So it's not very interesting for two bits. But if you built a bigger decoder like three to eight or four to 16, you could then pick out the right min terms or them together and compose an arbitrary logic function. And so that's how the old reconfigurable logic was built, right? By composing logic functions out of min terms. And you can actually do that. So let me finish this not get your question. You can actually do that for more than one function, right? Because you have the min term wire. So you can have one function by just oring the right set together and then a different function by oring a different set together in the third function and fourth function and so forth. Whereas with the mocks, those min terms are all or together into one wire. So you can't then use that to construct arbitrary logic. You can use it by putting zeros and ones to the input, but one mocks will get you one function. Whereas a decoder, you can then add or gates outside the decoder to get to any number of functions. Yeah, so the primary application other than memory was the was the programmable logic. Yeah, I mean, I'll show you when we get in about two and a half weeks, I will show you an application, which is a vending machine, which is, you know, you pick a product and then there's internal logic that decides, am I going to actually deliver that product to you? Have you put enough money in? Right? And so that goes to the enable of the decoder. So if the answer is no, you didn't give me enough money for that product, then nothing gets released. And if the answer is yes, then we decode the signal and then we take each of these and send it to a mechanical release. So you can use it for that kind of application. The primary use, though, outside of outside of memories, which we'll see in a few weeks, was these programmable logic arrays, which have now been superseded by FPGAs. Yeah, FPGAs use a different mechanism to look up tables. Oops, really? That was it. Okay. Hmm, a few minutes left. So let me give you a little start on any questions on this before I switch slide decks. Yeah. Yes. So based on S1 and S0, there'll be four different in terms and it will generate exactly one one for one of those midterms. Yeah. Yeah. The enable. Yeah. Yeah. Would. Yeah, the S1, S2 would be the product choice. That's right. And then each of these lines out would control whether a different one of the four products got dropped out. So a mox, no, a mox is typically used when you need to choose between different functions. Right? So for example, when we did the adder subtractor, when we did unsigned or two's complement comparator, you can use a mox when you want to compare different ranges of ASCII, you can use a set of mox as to choose which type of character you're looking for. Right? So there will be many, many cases where we want to have the ability to choose between two things or four things and we'll use mox in all of those cases. In fact, we'll see it probably Monday or Wednesday when we design registers. I see. So in a different sense, so this is telling, this is giving me one one signal for each pattern, whereas the mox is unifying many signals under one wire. Right? So do I want to add or subtract? I want the answer to come out in the same place. Right? So when you want to combine things into one output, use a mox when you want to split something that's already been coded into individual wires, use a decoded. Yeah, it's trying to give you the ability to tell which of the patterns here was the one that was actually present in the bits so that you can then do things with each of those individually. You mean if you wanted to build a bigger decoder from a smaller one? Yeah, then you have to. Right? So the question is, can you build bigger decoders from smaller ones? You can. You do need to have decoders with enable because if you think about, well, how could I build something with eight outputs from two of these? Well, you can't if both of, if both of these always output one one. Right? Because in the eight, you want one one also. If you've got one one from each of these, then you have two ones and you can't do it. Right? Without adding some extra gates afterwards, which would be a pain. On the other hand, if you have the enable input, you can make one of the two two to four decoders output all zeros. And so if you take two two to four decoders with enable, you can build a three to eight decoder out of that with with a little bit of extra logic. Makes sense? Okay. I think that might be in the homework. Be careful. Yeah. Yeah. So if you're if you're really designing it in CMOS, then you know, you need to change these and gates into nor. And then for I mean, you can change them into NAND, but your outputs would mean different things. All right. So let's just stop there. We'll start the quantologic on Monday. Thanks."
    },
    {
        "ECE120-2016-11-18-LEC-35-slides.mp4": " during the break, then you can do lab 14 early if you want to. I don't go up early. I know all of you are just itching. You do more LC3 programming. There's also this sprite ASM file on the wiki, which is what the other lectures are doing. So if you want to see it in action, you can want Professor Harmil's lecture. But you can also just go grab the code and take a look at it if you're interested. What we're going to do today is do some ASCII screen art, because I just like art. And so I'm going to ask you to write a program for me, and I'm just going to type. But it's going to be this program where actually, so I'll reveal who at the end. But someone sent me a file with two pools of physicians on a screen and ASCII characters. And so we're going to take that file and figure out how to print it. So that's what we'll do today. I have a think-par-share too. But I think I'll just skip it, especially because there aren't that many people here. So if you're interested, I might post the slides. Think-par-share is, I ask you to get together in small groups during class and think about things. I used to do a bunch of them in 190, the predecessor to this class. I don't do so many here because we kind of oriented the entire discussion section around that style of interaction. So you're already doing it every week. So we don't do it in the lecture very often anymore. But I thought it'd be fun just before break to go and develop a code together. So when we get my paper out, I told you never to start coding. So even though I have this part ready to go for coding, we're not going to do that first. So you have got notepad, my all-purpose programming tool. And I've got Sigwin LC3 tools here. So this file, we will write LC3 code here. So I learned the, I can type pretty quickly now, but when I learned to type, I didn't know enough to do what my department had did to me, which was, you know, I said, oh, you know, I can type now with more than two fingers. And he said, yeah, well, I use the double-egal version of typing. Oh, wow, Dick. This is Dick Blahed. Wow, that sounds really impressive. What is the, I'm a faculty. So I don't just say, oh, thank you. Double-egal, amazing. So what is the double-egal version? So tell your friends and family, I'm a double-egal type of staxionary. Yeah. All right. So let me see how quickly they can switch. I think it's not too bad. All right. So what I want to do is we're going to get this set of tuples. So it'll be an array of three tuples. So what it'll look like is basically consecutive memory locations like this. They'll be an x location, a y location, and some ASCII character. So for example, it might say, well, at position 5x, at position 10y, we want to draw the letter a, for example. And then after that, it might say, well, at position 5x position 11y, we want to draw the letter t. So I'm putting them in quotes for the ASCII characters. Of course, they'll be ASCII-toded. So what we want to do with that, when we're done with that, the end of the array. So we want to know how big it is, but we'll get an x value of negative x value, which will be the end of the array. So that's how we'll know where the end is. Like when we're looking at a string, we know the end because we see a 0, a null character, and ASCII. For this array, it'll end with a negative x position. So if we get a negative x position, that means we're done. So what we need to do is figure out how to take this array and get it onto the LC3 screen. So here's a picture of what I want to draw to the screen. So you remember with LC3, the only things we have for input and output are basically send a character to the output and read a character from the keyboard, right? So we don't have a nice screen art where we can say, well, I want to move over here on the screen and put something there. And then I want to move up there on the screen and put something there. So in order to make this work, we're going to have to play a couple tricks. In particular, what we're going to do is break this down into a few steps. Let me switch briefly back over to PowerPoint. And I will show you those steps. I was going to review this. But I'll just skip that. So this is our array with that exposition, y position, askeh characters. That's what I was drawing on the paper for you. So here's how we're going to tackle the problem. So instead of just drawing directly to the screen because we can't control where we draw, we can just draw sequentially. What we're going to do is we're going to build up and memory a picture of a screen. So we're going to do that as a bunch of strings, one string for each row. So we'll start off by just filling that fake screen in memory with a bunch of spaces. I'll actually use a null at the end of it because I'm kind of lazy. And I want to use put s-trap, which I hadn't told you about. But the put s-trap will send a whole string to the display. So we put r0 to the first character in the string. We call the put s-trap, and that prints the whole string for us. So we'll make a bunch of strings, one per row of the screen. I'll draw that as a picture in a minute. And then we'll parse the array. We'll go through the array and say, well, here's a character at position 5, 3. We'll figure out where that should go in our fake screen, and we'll put that character into our fake screen. And then at the end, we'll dump the screen to the real monitor to see what it looks like. So those are the three steps. So let's go back over here. So here's our fake screen. So the idea is, well, somehow, maybe we've got some width here, we've got some height. So when I see something, so first, I'll fill this with spaces. So first fill the spaces and put an all here. That's not part of the screen. So an all here, an all here, an all here, each row will have its own null. And each row is one set of spaces followed by a null, width spaces followed by a null. So fill it with spaces and write the nulls. And then step two is parse the array. So for example, up here, I said, well, x position is 5, y position is 10. So if I were to draw all these positions, then let's see. Well, count this one as 0. This one is 1, 2, 3, 4, 5. And then this one is 0. This is 1, 2, 3, dot, dot, dot, dot, dot position 10. So here at 5 and 10, I want to plug in an a there. And that would be parsing the first three tuple from our array is to go say x position 5, y position 10, put the a there in our screen. And then once I've gone through this whole array and put all the characters in, then my screen is ready. And I could just print all the screens with put s, one at a time. So go through the array, one, two, pull at a time, until I find the end of the array, that's step two, parsing the array. And then step three is print the strings of the fake screen using put s trap. OK, so those are our three steps. So let me switch over here and we can get started. Just putting a few things in. OK, good. It didn't. All right, so we'll do the first part first. But before I can do anything, this is LC3. So let me write my, say, can't actually type now. I'd brag too much. All right, here we go. So put my dot orange. I'm going to give it a little space. And then first step, build a screen with spaces. So let's see, we want to have width and height parameters. So put those down at the bottom. So for width, we say, I don't know, 40 spaces for height, when we say 26 spaces. We could change those later if we wanted. We'll use them as parameters that will store in memory. So how do I write a bunch of, oh, I better make a space for this. So let's put our screen somewhere. So let's put our screen at 4,000 hacks. So our codes at 3,000 are screens at 4,000. Let's say I raise it 5,000. So just put those in at the bottom of our code, and we can make use of them in our code. So the first step is fill the screen with spaces. So right now, there's just a bunch of bits in that memory. So I need to go through and somehow create one row, one string for each row. Yeah, Nathan. Really? Remember, that's 1,000 hacks. Four kilobytes. That's a good check, though. It's good. Someone's doing the checks, because if you make one clobber, the other one happens. The LC3 just does what you tell it, which means that you would overwrite the array with your spaces, and then you'd miss part of your array. So good call. But in this case, we're going to have a lot of space. So good call, but in this case, we're safe. So good check. All right, so if you make width and height too big, then we're in trouble. But for now, they're OK. I think we should put a comment there. OK, now we're safe. No one would ever change those to be more than 4 kilobytes. All right, so let's think about what we need to do to fill the screen with spaces. So switch back over here. So here's my screen. How's the screen going to go into memory? Which way? I mean, this is an array. So let me draw a smaller screen. So let's pretend we've got 3 by 3. So I want a 0 here. So let me call these A, B, C, D, E, F, G, H, J. Let's skip I. So what should go first in memory? A, right? What's next? D. OK, so we're going to go across the first row. And then we're going to go down after the 0. So if I screen this 3Y, I'm going to need four memory locations. Wonderful, that extra 0. And so to linearize this in memory, it's going to look like this. A, B, C, 0, D, E, F, 0, G, H, J, 0. OK, so this one is with a 0. Plus 1, right? And this whole thing is with plus 1 times height memory locations. So that's a thing that can't take more than 4K. And it is that product there. OK, so how should I break this down, filling A through J with spaces and putting those zeros in? Is that an iteration or a sequence or a conditional? It's a loop, right? An iteration. So loop over what? Rows or columns? Probably good to do rows first, right? Because then, actually, if I do rows first, then I'm just walking through memory and I can have one pointer that fills things. If I do columns first, my pointer to what I'm writing has to jump around a lot. So maybe let's make our life easier. So we'll do the rows first. So we'll say something like for every row, for every column, fill a space and then increment the array pointer. And at the start of that loop, then I can say array pointer initialize to what was it, 4,000? OK, so if I initialize my array pointer to 4,000, and then for every row, for every column, I fill a space and increment my array pointer. That'll write the letters up there. What about the zeros? I'm sorry. You probably shouldn't assume that about LC3 memory. I mean, yes, it's true in the simulator. But yeah. Yeah. Like, you had a 3,000, but you'd be like, I think, you'd be like, yeah. Yeah. Well, so for one thing, our program is not going to go up there. Right? Our program is down to 3,000. So our program's not going there. And yes, the simulator will fill the rest of memory with zeros. But you'll probably be safer just not assuming that kind of thing, because it'll tend to come by to you later. Yeah. We're going to end up having to put a carriage return, but I was going to put that in the front loop. We want the zero, because we're going to send, we want to know, because we're going to send the entire string using put S. So we do need the zero. So we're going to have to write it there. So where should we fit that into our structure here, our loop structure? Yeah. We can put a zero in a register. So where would I put it in the memory? I'm sorry. So I want to put one for each row. So after I do my entire column, maybe down here, but after I fill a column, OK, so let's see what this is doing. I should have kept more pins out. So this is one row up here. So this loop here will fill that row. So after I do that row, then I want to put one zero. So fill one zero and also increment the array pointer so that I don't overwrite it. So this is now something I do for every row. So if I add that little bit of code down there, that will write my zeros in for me. So these will be my spaces. Whatever my width is, I'll write that many spaces. I'll put the zero at the end of each row, and I'll do that for a height number of rows, and then I'll be done. That makes sense. OK, so what do we want to use for keeping track of these? OK, so what do we need to keep track of first of all? So we need a row. We need a column. We need an array pointer. Someone said we should have a zero. That's a good idea. Oh, it's going to have my laptop once you reboot. Maybe not reboot. I think it's time to go to sleep. Hopefully I can get it to wake up. And oh, what other thing do we need? We need one more thing. What else would be convenient to put in a register here while my laptop comes back? Anything? Yeah, so hide and width, we can maybe use the pointers and just count down, because we just need counts. So we could initialize it. That's a good idea. But I think we can count the other way, and then just use one for the row and column in this case. What about this one? Anything you might find convenient for filling a space? How are you going to write a space and a memory? Yeah, you probably wanted it in a register, right? Because space is 20, so 20 hats. So maybe we'll put 20 hats, which is a space character. This is null. Well, maybe we're not going to be able to write code today. Going on with my laptop. Oh, I have a light. I'll try to get it to go to sleep and then wake up again. Into another register. Oh, I'm sorry. Those A, B, and C initially will be spaces. Yeah. Those I just wanted to illustrate the mapping between the screen we're trying to build and the memory organization. Yeah. But initially, we want to make them all spaces, and then we'll fill them with real characters from the array. So we have to have a drawing canvas, right? So the drawing canvas is a bunch of spaces. So the array is mapped like this. So each of, depending on the width and height, the number of memory locations, one row is mapped, is organized linearly in memory. And you have first row followed by second row, each of them with the 0 at the end. So this array is 3 by 3. So the first row is ABC. And so in memory, it's the A, B, and C characters. And then there's a null looking. Yes. So the three tuples are organized sequentially in memory as x, y, character. The last one is a negative x position. And then the x and y positions are given according to this mapping. So 0 and 0 is the upper left corner. x positive is that way. y positive is down. Yeah. Yeah. That's the g is 0. x, y, y, y, y, y, x, y. Oh, yeah. They're unsorted. Yes. They're not sorted. Yeah. Yeah. And so that's one reason that we have no way to control moving around. We can only print linearly until C3. No. No, no, no. We make the blank canvas. And then we put characters in wherever they happen to fall. And then we have a picture. And we dump out the picture. Yes. Yeah. So we're going to use the step two. We're going to go calculate the screen position for each array element, put the character there, and then we'll dump the screen in one big operation in part three. Basically, print a bunch of string. I mean, this is actually technically similar to how real graphics work. Most of the time, the graphics cards are drawing the next frame in the background. They're not drawing it on the screen, because it makes it flicker. So yeah. Do you want to, like, let's say, work in the image, or do you think it's like, or that it's walking around? Oh, yeah, yeah. I mean, all you have to do is treat them as opposite values. Yeah. So if you want to do an image transpose along the diagonal, although the characters are not square, but yeah. You can do that easily. Sorry, my laptop did decide it had to be rebooted. So we're waiting for it to come up, and then we'll type the first code. Okay. Oh, I didn't save my code. Wow, that's sad. All right. So what did I have with? What did we say? Okay. So what we decided we needed in memory, we need a row. Why don't I use this one for the zero, this one for the space? Okay. So R2 can be R0, R3 can be R column, R4 can be R array pointer. I think that was all we needed, huh? So let's first initialize our variables. So how do I get a zero and R0? And good. And then how do I get a space in R1? Yeah, I could add, right? I'm kind of lazy though. I think it's less typing for me. But yeah, I could do add 10x. No, I can't add 10x. I'd have to do three ads, wouldn't I? Because it's 20. Yeah. I'm just going to fill two ways that are types of many ads. All right. So for the row, let's see. So let's start the row at height. So this will be our row loop. And then I'll have to re-initialize the width every time. So let me load that here. And this will be our column loop. So then I need to store a space, right? So where's my array pointer? I better initialize that too. How do I initialize R4? I want to initialize it to point to the, oh, I'm sorry. I really should call that screen at this point, huh? I want the screen pointer here. I will need the array pointer for the next part. So for now, I'll just leave that blank. So how do I initialize R4 to point to the screen? So the screen's at 4,000. I don't think I can get from down around 3,000 to 4,000. I do have it down here in this memory location, though. So is there a way to get it from how can I get this value that I've stored down here into R4? Just another load, right? OK, good. Yeah, the assembler will take care of the offset. I could try to do an LEA, but I would not to calculate the offset myself, which is a pan. And then it's also probably out of range from this code, which is another pan. Yeah, I wouldn't be able to jump. I won't be able to LEA either. OK, so if I load it from here, then that'll give me the value. Oops, but I don't want it there. I want it up here. OK, so that's got those ready, zeros ready, ones ready, two is ready, column was supposed to be three, not one. I should leave bugs for you. All right, so now I need to fill a space. How do I fill a space? How do I write a space to my current screen pointer? Yeah. Not unless it takes me a lot of code. I mean, the PC offset is 9 bit, right? Yeah, yeah, that's just the value of x4,000. No, no, no. OK, so someone said store. What kind of store? Really? OK, so ST from my space register to where? Yeah, I probably store register, right? I could use STI to this, but then I could only fill one space. I'm actually going to change our four. Our four is going to go through the screen and fill each place with a space. So I'm going to change our four. So let me use our four offset here. And then I can increment our four, right, to point to the next one. So that'll give me one space for one column. And I just made the advance the screen pointer. So the next time I fill one, there'll be a different place to put a space. So now I need to count down my column loop. So how do I decrement? Ah, yeah, STR, good. Thank you. So how do I decrement my column number? Add negative 1 to which register? Or 3, right? OK. Good. And then what? Ranch, what condition? So if this were 5, right, then first time through it before, then 3, 2, branch positive, right? So as long as we still have a positive number, we're going to go back for more. Where should we go back? Good. OK. So now we have one loop. Sorry, one row done, but we didn't put our null yet. So how do we put the null? From R0, which is 0 to where? 4. 4. Good. Yeah. So we're just writing into this screen that we're creating, right? OK. And then I better advance the pointer. Really should leave bugs for you. I tried to leave one, but you caught it. All right. What do I do next? Just branch back to Roloup. OK. Branch, what condition? What do you want? So what do I want to do? Add R2. I just want good. OK. And then branch positive like that. Hmm. Good. But we should be done. Try that. Hmm. It worked. At least it compiled. It assembled. Let's see. I can dump 4,000. It looked at a bunch of spaces. Cool. Did it get it right? A lot of spaces. I think the code works. So when you do this kind of stuff, you probably want to make your life easier. Probably that one's easier to check, right? Let's do that. OK. So now there are a few less. I don't know. Can you read this font? There's one, two, three spaces and a zero. One, two, three spaces and a zero. One, two, three spaces and a zero. So it looks pretty good. Actually, it's probably a bad idea to pick three and three. Why is that? Yeah. If I get them mixed up, I won't be able to tell, right? So maybe I'll do it a little bit differently. I'll make it four wide and three high. And then we'll run it one more time. And then we'll go back and do the second part. OK. So we have now one, two, three, four spaces and a zero. One, two, three, four spaces and a zero, one, two, three, four spaces and a zero. And then a bunch more zeros. If we really wanted to be careful, we could write non-zero's into some of these memory locations to make sure this last zero was actually written. But at this point, I think we're pretty good. Yeah. I think that information was really great. How do you get on that? How do you get off the phone? I don't know. I don't know. No. Bang just repeats the last command starting with whatever prefix you follow it with. So yeah. So bang LC3S means whatever last command issue is starting with LC3S, do it again. So I don't have to keep typing it, because I get tired of typing my fingers gets sore. All right. So good. So we're done with first part. We have a second part to do, right? OK. So let's copy our registry table. We don't need all of them anymore. We'll just change the registers potentially. So we need to row in a column for each of the elements. We'll need the array pointer, too, now. So maybe we don't need the space. So let me make this an array pointer. Let's see. What else will we need? Any ideas? We need a screen pointer. We need an array pointer, a row in a column. We need something for the ASCII character. We put that here. All right. The one that we're going to write into the screen, we probably need some other temporary. But maybe we'll come back when we need them. Just to make sure everyone's following. Let me switch briefly over here and say, OK. So here's our array. So basically, in order to parse this array, what we're going to need to do, I need to pull it down to work and reach it. What we're going to need to do is walk through these three tuples one at a time and look at the x position, the y position, use those to calculate a position in our spake screen, we just created, and then put this character at that location. So how do I figure out the position given the x and y coordinates in memory? Yeah, mom. Oh, yeah. But would I multiply the x and y coordinates? Maybe not, right? So let's take a look at this drawing over here. It has the disadvantage again of width and height being the same. But where does the second row start? How many memory locations down from the first? So if I look at the difference between a and d, how far ahead is d, 4, right? Or width plus 1, right? What about if I go two rows down? It'd be twice that, right? What about three rows down? Three times that. So if I multiply the vertical position by what? width plus 1. And then I can add the column, right? So let me write that formula down. So if I say my y position times width plus 1, plus my x position, and then I add that to my base. So my base is here, the address of the first character, which is just 4,000. So if I calculate this expression here, that will tell me where to put the character, right? And you understand why, given the pictures? Makes sense? Yeah? OK. X is, remember, each of our two pulls has an x position, a y position, and a character. So the x position, if it's 0, then that would be the first column. The second column would be 1 and so forth. So if you add that offset, you'll get the position within the column. We're going to assume that the two pulls know how big our screen is, that they don't give us bad values. We won't check the values. OK. OK. So we'll have to calculate this expression, then. And other than that, we just need to go through and look at each of the triple values. OK. So let's see. So let's make a loop. We'll start. It was R4. Oh, we better reset R4, right? Because we advanced it as we were writing. We used R4 to write our whole screen. So R4 is no longer equal to 4,000. So let's set it back to 4,000. And then we could add it in later, too. We'll do a loop. When we're done, we'll come down here. We need to point to the array. So let's see. How do I get my x, my first x out of the array? Remember, they are x, y, and character. So if R1 points to my next array element of this three tuple, so x is offset 0 relative to R1. So if I go in LDR, I'm going to add a value. So this will give me my column. Right? So this will get my data out of one three tuple. The offset 0 is the exposition. I'll put that in R3. Offset 1 is the y position. I'll put that in R2. Offset 2 is the ASCII character. I'll put that in R0. And then I'll add 3 to R1 to point to the next tuple for the next iteration of the loop. When is my loop done again? How do I know my loop is done? When I've reached, how do I know when I've reached the end of the array? Sorry. X is a negative number. So where should I branch? Right after I load X. What branch condition should I have? Branch negative. So if I get a negative exposition, I shouldn't load the other ones. Where should I go? Or it's done. So in other words, if I see a negative X, then I just quit. And I just come down here. I'm out of my loop. I'm done. So if I don't see a negative X, then I will load the y and when I'm giving myself more space, load the y in character. And now I need to calculate where that should go in my screen. So let's see. I have to multiply y by width plus 1. So maybe I'd better start using some temporaries now. So multiply y by width plus 1. Let's see. So let me put width into r5. And let me put a 0 in r6. Unit root 12. And there we go. Add- Oops. Okay. What do you think of that? And go, OK, what do you think of that? So what I did is I put a 0 and r 6 for my sum. So I'm going to sum hopefully with plus 1 times, or I'm sorry, sum y plus 1 times. So I'm going to put width into r 5. Oh, I did that the wrong way, did my. No, I did it the right way. I did width plus 1. Yeah. So you have to go back to the picture of the, remember, these are the tuples. So in memory, each tuple has, in the first memory location, the x position, then the y position, then the asky character, x position, y position, asky character. So r 1 initially points to this one. And so plus 0 is that memory location, plus 1 is that memory location, plus 2 is that memory location. Then we add 3, so the next time through the loop, we'll point to v3. So there are just 3 tuples with x, y, and asky character. Yeah. Yes. Yeah, we're not going to check. We will not check that the x and y coordinates are inside our screen. We just assume that they're OK. Which if they're not, then we'll end up writing outside of our screen. And we won't see those characters or something worse could happen. So it's not the best way to do it. But just not to have too much to write in the space of an hour. All right. So put that over here. Hopefully we can get this part written. All right. So what does this do? So it puts a 0 and r 6. And then how many times do I go through this loop? Ask it that way. With plus 1. So in the easy way is if you start with with 0, then of course you'll come through this once because you don't branch before. And then you'll add negative 1 to 0. You get negative 1. You'll stop. So if you have a width of 0, you'll get 1. If you have a width of 1, you add 1 to negative 1. You get 0. But 0 goes back again for a second. So you get width plus 1 times. So if I take width plus 1 adding r2 to r6, then I get width plus 1 times r2. But r2 was the y position, right? Yeah. Yes, probably. Given that depends on the relative size of your screen. But generally speaking, the screen will be wider than it is tall. So yeah, that would be faster. Yeah, so you could do it either way. Your way would be less of fewer instructions. Good point. OK. So now we have that. So let's add in a couple of other things. So that's in r6, right? So let's add in the x-off set. So now I claim r6 points to the place where we should write our ASCII character, right? Because we've included y times width plus 1. Then we added in the x-off set. So that's our formula. But we needed the screen base, which we had in r4 up there. So if we add those three pieces together, we get the place where we want to put our ASCII character in memory, our ASCII characters in r0. So how do I put ASCII character in r0 into the memory address of r6? Yeah, did I screw that up? OK. Let's see. x-off set. Yep. There it is up there. In r3, not in r1. So good call. Add that in r3. Thank you. Everything else work? OK. So how do I get my character from r0 into memory address 0.2 by r6? STR again, right? Good. So source register is what? r0. Remember, we put the character in up here. We didn't change it. So it's still there for us. r6 is the pointer. Offset is 0. Good. So I just put one character. Maybe I should go get the next one from the array. So how do I get up there? Branch, what conditions? All, right? Always. Where? That'll go get the next one. We only come down to parse done after we're all done with the loop, which is when we find the negative x position. So this should parse the array. Let's see. So we've got a few minutes left. I'm sure we'll be able to make a fake one, I think. OK. So no errors in the compilation. Oops. I can't type this one now. No, it's OK. I'll do it quickly. OK. So we'll put the letter A at 1, 1. And then maybe at 2, 3, or 2, 2, we'll put the letter B. That should be enough, just to standard you check it. We'll put it at 2, 3. How big did I make x? There we go. OK. Yes. Thank you. All right. One of these little arrays quickly. I'm sorry. Still minus 1. It's OK. That's the terminator that gives us a negative x position. OK. So let me read in my fake one. And then read in my at 1. And then I can look at 4,000. Oh, so where did I put the fake one? So 1, 1. So here's my first row. It has nothing in it. On the second row in position 1, I have the letter A. You can see the A over here, maybe. And then my second row in the third position has a letter B. So that worked. Good. OK. So our code worked. All right. So the question is, can we dump all the strings quickly? So our strings are ready. So all we need to do is add loop. So let me get the register table. Keep those. We need a row. We don't actually need a column pointer. We need a screen pointer. And our zero is going to be our string pointer. And actually, we want to need a screen pointer. So let's start by putting, let's do this. So let's put screen in our zero. And then with plus 1 in our 1, and then we can do a put us trap. So we want rows. We want height in our 2. We'll put us trap. What did I do? And I want to add height plus 1 to my string pointer. So I'm pointing to the next row. And then I want to add minus 1 to my loop counter and branch back. That looked good. OK, sorry. I had to write that pretty quickly if we're going to finish on time. So put a screen pointer in our zero. That's a pointer to the first string. Remember, the strings are spaced at width plus 1. So every width plus 1 spaces in memory is the start of a new row string. So I'm going to put width plus 1 into r1. And then I'm going to keep adding it in to get to a pointer to the next string in r0. Put us as the trap that prints a string to the screen. Our string's already end with nulls. I'm going to do one row, one string for each of my rows. So I load height into r2, add negative 1 to it, branch until I've printed all the rows. So I think this should work. There's no line feed. Thank you. Good call. OK. So I better put a line feed. So after the put s, I had better oh shoot. OK. Then I need r0 for a line feed, don't I? So let me put this in r3. And then, sorry, let me copy it over to r0 there for the put s. And then I can get a line feed. Thank you. OK. So get a print. Oh no. Thank you. OK. So that printed that screen. OK. So now I can decode this thing or we'll set me last night. Except for one thing, I better make my screen bigger. OK. So let's change our screen back to something realistic. Ready? What? I'll put a tab or something. Ta-da. There you go. Happy holidays and enjoy your break."
    },
    {
        "ECE120-2016-12-07-FIN-review-slides.mp4": " All right. So, someone Daniel just asked me, what's going on in the holiday party? Why is it so important you go there? There's a, I just, I was just there eating wealth. You guys were waiting outside. I told ECES Act to come down here and announce it. I don't know. I think they sent it out on Twitter instead. So if you didn't get the tweet too bad. No, you can still go there till 4.30. They're doing like a gingerbread house competition. So if you can do a better house than everyone else in half an hour and post it on the, I think on the ECES Act Facebook page, then you can win. But free cookies, free hot chocolate, stuff like that. So you should go up and hang out. This is just, you take the elevator third floor, turn left. There's a big ballroom like area. And that's where it is. Okay. Not quite as fun, but office hours next week, 12 to 2. And then today, I'm just going to finish up the advice and then, and then talk about review. So we'll do a little mini review session for the final. Maybe not mini full hour or half an hour, whatever I left. Final exam coming soon. Coverage. You've seen this. It's been too much time on it. Again, and you know, this is in the video too. So if you, if you didn't write it down or whatever, one party each on. So one question really. Part one, two and three of the mid of the class. So each of the quarters. And then four parts on the last few weeks. So the material since midterm three. Oh, I don't need to push buttons here. All right. So this one I talked about trying to do a big project in the next few years. This is actually means kind of your own project so that you're in charge and you make decisions. And you can learn how to design things and think about how to constraint things too. I'm learning to use a debugger. I learned to use tools. Avoid optimizing prematurely. Remember who it was. I think Donald Knuth, who's a famous computer scientist, said. You know, premature optimization is the root of all evil. But it was it was mostly in context, but. But the main point is is valid, which is that. So there's some other context involved, but the main point is that. You know, you really don't want to spend time. Making things smaller or faster or better that are not. A significant part of a bigger design. Right. So don't waste your time doing that, which you end up getting is a very complicated piece that maybe you have to throw away later anyway because someone has to modify it. And no one understands how it works because you spent so much time making it complicated so that it would be smaller fast. So don't be careful about how you optimize. Make sure things work. Do all the debugging and testing and things like that. So you figure out, well, what's the part that actually takes the time or takes the space or takes the power or whatever you want to optimize. The thing that's taking too much and then go make that part smaller faster, use less energy or whatever the metric is, right, or set of metrics. So use your time wisely in that sense. All right. So this is the one I stopped on. So, Seymour Cray was the inventor of the supercomputer. There was a series of companies he found it actually based on supercomputing, but for many, many years in all the national labs and other places that wondered you do high performance computing, they bought Cray computers and that was basically the only thing they bought. But he lived in Minnesota and actually Cray computer by name. There's still companies up in Minnesota. But he would, you know, there are a lot of lakes in Minnesota. So every, every spring, he would start building a boat to go sailing on the lakes. And in the summers, he would sail around and come fall. He would pull the boat up on the beach and burn it. And then next year, he would start over using all the stuff he'd learned by building as both the year before and the year before that here before that. So sometimes it's worthwhile as you're building systems, whether it's softer or hard work, both just say, you know, I've learned a lot by putting this together, but it's better if I just start over and just chuck it and start over and rebuild it. There are other ways to do things and you need to learn those two, but this is one useful lesson is, well, when do I just need to start from scratch and do my own design, even though I've done this kind of thing before I can do it better now because I know more. And so it's worthwhile building even just a prototype and saying, well, what did I learn by that? What was the hard part? What was the easy part? Where should I put more time and energy and thought? So best designers are the best testers and debuggers best debuggers. So, you know, we tried to talk about this when we when we introduced programming in the last part of the class that you want to think about what your program's supposed to do before you sit down in front of computers, start writing code. The, you know, the people that think about it and draw pictures of their data structures as they tried to do for you is we're developing code just before break. Hopefully everyone at least watch that video. I know you're enjoying eating and relaxing over the holidays, but. But, you know, the people that think about, well, what is what is it I'm trying to build and have that model in their head, you're going to be a lot better at making sure that that's what's actually in your code. That's what your code is doing and making sure that there aren't any bugs and that the code is really doing what you intended. So, so do think about that as you go forward and build your systems. Good code is like good pros. It should be easy to read your programs. Right. I mean, sometimes it's, you know, you say, oh, I can save an instruction or something. That's fine. If you find some clever way to do something, but you know, put a few comments in. Right. If it's easy for people to read your code, then, you know, they can keep the code around. You can reuse it. Right. Later when you say, hey, I need something that does this. Well, this old code I wrote is almost right. Right. But now I understand how I made it work so I can change it. If your code is hard to read, right, for whatever reason, you don't put any comments, you make it cryptic, you do complicated things when simple things would have worked just fine. Then you won't be able to do that. You'll go back and you look at it and you say, well, I don't know, or you're worse. You'll say, maybe you'll put it in and it won't work. Right. Or worst of all, you'll say, maybe you'll put it in and it won't work, which you won't realize it. And then you'll give it to someone else in the laughing. Now, I guess worse is where someone actually gets hurt because you've been broken. But trying to make your code easy to read. And then you're going to have a team project. So one of the reasons I want to put the old slides in as a review is you might think, wait, this is the same thing, but it's not. So you should have a project for yourself, but you should also make sure you have some chance to work with some other people. Right. So one of the big changes actually between 190 and which is the old version of the first class for EC, students in computing. And the main class for EC, students, maybe is better way to sit is that in that class, our discussion sections were kind of more like traditional discussion sections, which you probably had here where or maybe you're not because a lot of our departments are changing their interclasses now. So basically it's a little bit like a lecture, right. Your TA stands up and maybe does some examples or maybe just answers homework questions or whatever, but it's not you getting together in groups and working on problems together. So we changed that. And part of the reason was for many, many years are alumni and company reps and everyone's been saying, oh, EC students don't have enough soft skills, right. They know how to solve problems, but they don't know how to work with other people. So we've been trying to put more and more teamwork, but we still want you to build up your own skills. So, you know, we did that in this class in the context of discussion sections, you should also do it outside in your outside projects. Right. So you should find some friends and build something together in the next few years just for fun. I mean, not just for fun, for excitement and you can even make a profit out of it if you'd like to, but fun should be a part of it. All right. Don't be afraid to break things. There's a lot of stuff available to you as an EC student. You know, a lot of the independent study projects and labs and things like that. There's some budget lying around here or there. I mean, don't break your spence of equipment in the lab. Don't be afraid to take code apart or look into things to figure out how they work. Right. You know, if people never did this, we'd never have new inventions. So don't worry too much about, you know, if I do this, it's not going to work. Go and said and see what happens, right. Figure out how it works and play with things. And so last part, hopefully you've seen examples from this. I'll mention one in a second, but look for opportunities to turn dreads work into inventions. Actually, I'm pretty sure I don't want to mention the one I just thought of on video. But you'll find, you'll find, you'll find lots of opportunities in your life where, you know, you're doing something quite repetitive and you might think, well, gosh, a computer could do this. In fact, I could teach a computer to do that. Well, certainly you can make your life easier by then doing that. Maybe also other students, now it turns out to be your ecxx homework. Maybe that's not such a great idea. But I had an xxx, you know, replace with whatever you want. But there are lots of opportunities for that sort of stuff. So that's where things like assemblers came from, right. People got tired of writing binary code and they said, well, couldn't we just write something simpler. Right. Maybe we could write asky characters and we could write a program that turned that into bits for us. Right. And then the whole language just came from. So that and lots of other things in the world now all came from this idea of, well, why do we need humans to do that? Right. Couldn't we couldn't we automate that? Couldn't we make that easier for people by having a computer help them out and do the easy parts. So look for opportunities for that. And if you come up with good ones, then you know, make them available to your friends or more broadly. So that's it for the advice stuff. And unless anyone wants to ask questions, we're going to review session. No. Okay. That's it. Let me turn this off. All right. So we'll switch over here. We'll do our customary survey of topics. So what would you like to talk about for review or did you just want to go upstairs and eat? Yeah. Yeah. See programming. So part one of the class will be one question on the exam. The systematic decomposition, which is what I consider to be kind of the key, the core of programming, which is how do you take a task and break it down into pieces? Yes. That's part of the most recent material. And there will be programming in that sense on the exam using LC3. Probably assembly more than binary, just because although we think it's amusing, we know it's painful. So there'll be a little bit of binary, but programming there will be some of. See programming, though. It's possible that one problem might include a little bit of it, but only at the level that we actually taught you, which was really one statement level, kind of on the first midterm. Okay. There is a summary slide in the PowerPoint too for that, but I'll go through it. Yeah. I thought that's start stuff. Yeah. Run through the concepts we should know. Okay. That's it. Let's see. Where did my. I'm. Okay. Skills from part one. You should be able to do those things. I think I even got it all on one page. Okay. Okay. What level of detail do you want? Okay. Yes. You should. I mean, so we didn't cover that many sequential components, right? And Muxes and decoders, I would think you know to know how to use it is sort of to know the equations, which is to know how to build it because you know how to build combinational logic. I would hope you could reproduce it even if you haven't memorized how to draw it. I mean, you should in real life, you probably never unless you go and actually do the cell design for a new process or something, you probably never have to reproduce it. You could probably just drop it in place or even write it as hardware design code, but you should know how it works and to me to know how it works is to know the equations, which means again, you know how to do combinational logic, so you should be able to build it from gates. And it's actually not impossible that you know, say carbon nanotubes actually become viable as a replacement for CMOS that you know more than one of you might actually be in the business of saying, well, how do we take a bunch of carbon nanotubes and build them into a box. Okay. There's actually a list over here hidden right now, so I will put it back up in a second. And then, so this is just the summary, the other half of the summary then is just knowing what these words mean. Thanks. You read my, you want me to read my mail now? Yeah, this pop up that attachment. Okay. So I'll be taking the final tonight. You've caught on to our secrets. All right. So yeah, I mean, there's a terminology list, right? So you should recognize all of these. Yeah. Yeah, and actually put that on there already. So let me switch over. I'm going to zoom out a little. Okay. Anything else we should add to this list for today? I'm 320, so about 40 minutes. Okay. Okay. Yeah, so. Okay. Let me put those two together and then put it on the list. Okay. Anything else? Should we vote? Okay. So we'll let's see what was the first one. So see programming with the two, three. Okay. To pass process for the assembler. About 12 hazards. Yeah, you got a vote for your own two. Okay. Control signals. Okay. Okay. So a bunch maybe 20, 25. Microsequencing. Okay. 30 to 40. Floating point to decimal. About four. By no, I'm in model. And we have about eight. And for floating point to decimal, by the way, there is a, there is a tool that, you know, you can look at the videos for review of examples over the PowerPoint slides, but there's also a tool that'll help you do some examples. So, I'm going to do a set of code. Three. Hardware micro versus micro program control unit design. Okay. Okay. So maybe about 10. Okay. So let's talk about micro sequencing then. So maybe I will, I need probably, well, I don't need, but it's probably easier to do with pictures. Okay. So, I'm going to do a definition first. So, first I wanted to just redefine the problem. Make sure everyone knows what it is. So mapping the mapping of control signals, which I think we'll end up talking about again anyway. That's just a question of somehow figuring out how to look at the current FSN state of the control unit and produce the right bits for it. So once you've mapped everything into RTL for each of the states and the right sets of states and the sequencing between them with this transition diagram. Let's call it for now. Then you have a couple problems. One is creating those bits, right. And that's the one we've had last, which is, well, do I do it by combinational logic, which is a hardwired design, or do I do it by treating it as a little program, which is a micro program design. So we'll talk about that later. So the micro sequencing problem then is, well, I've got the state diagram and the finite state machine has to go from one state to another in that diagram following the arrows and following whatever branch decisions I put in there. And well, how do I, how do I build that logic? Right. How do I make it go from the right state to the right next state so that it produces the right control signals to process the instructions for me. So that's the problem of micro sequencing. So if we take a look at this is the patent Patel state diagram, right. So here's here's the level at which we've already completed the design so far. Let's say so you can see each of the finite state machines has FFM's FSM's RTL in it rather. And we have the arrows and we have the branch decisions saying, well, you know, here we're going to wait for the results to come back from memory. And if we get it memory ready signal will go on to the next fetch state. If we don't, we'll stay in this state. Right. So we some way of building logic that controls those state transitions and we can separate that out from the output logic, which is implementing the RTL through control signals. So those are two separate logic. We want to say logically, we can kind of split those up into two pieces, right. One is, well, how do we generate the control signals and then how do we generate the next state. Just like we generate outputs versus next state logic and when we design simpler finite state machines, that's the same sort of separation of concerns. Now at the end of the day, you might end up, you know, sharing gates between those implementations, just like in our designs, we just said, well, let's let's put all of those bits into the same memory. But you can think about them as different problems. So let's see. So we did a couple of these maybe, I felt like this one was simpler. So I was going to skip ahead here and just look at the patent Patel micro sequence again, or do you want to look at this one again. Go back to patent Patel. Yeah, this one is also in the notes with a couple tweaks and also in the PowerPoint slides. Pat Patel is also in the book and also in the PowerPoint slides. Okay, so let me skip to. All right, so this is, this is actually the, the micro sequencing part of the patent Patel design. So in their micro sequencer, they do it as follows. Actually, let me show you the state diagram. So remember that in these kinds of processor state diagrams, like, they're way to stuff in these kinds of processor state diagrams. Usually we only have one or two next states. Right. So most of the time, we don't design them to have some three or five or seven next states. They just make very simple decisions about how to process the instructions. Maybe they're looking at address mode bit or something. I mean, suppose you could design an ISA that had three address mode bits. But if you wanted to, you could branch on two of them and then branch again on the third and the next fine at state machine state. Right. So it's not too hard to get it down to one or two next states for almost all of the states. The exception then generally would be decode where you're figuring out, well, what kind of instruction is this? Let me branch into a bunch of different execution paths, right, for each of the op codes, for example, in the LC3 architecture. So in order to put those things together, patent battel for their micro sequencer said, well, we're going to have to have one next state ID. So generally we've got at least one next states will have one ID for that next state. And then somehow when we're going to branch will name a condition. So there are five branch conditions in their design, right, five different reasons for branch to two different next states instead of one other than decoding. And so we'll name one of those five conditions for that will need three bits. So we'll put the six the six bit next state, the three bit condition. And then in order to handle decode will put one extra bit that says, well, should we should we branch like a decode state or not. And so only one state will have this bit set. So the decode state and all the other states are not the decode state. So all of the next state decisions can be made from these 10 bits, right, first you say, well, is it decode if it is, then I'm going to go to a particular state for that particular op code. If it's not decode, I'm going to go to this state modulated by this condition. And so how does that. So these are the conditions Eric. Yeah, yeah, sorry, I'll give you more detail. I'll show you the implementation again a second. So these are the five conditions. This is the the unconditional meaning that some state has only one next state. So a state has only one next state. You just set the convits for it to zero, zero, zero. If it branches on memory like the one we're looking at a minute ago, you set the constate to zero, zero, one, if it's your branch state and it should branch on the branch enable bit, then you set it to zero, one zero. And then there's some others in instructions and concepts that we didn't talk about in our class, but that are implemented in the full LC three design. So there's some other conditions for that. This table I'm pretty sure is included in not in this form, but I think the information is in the bits that are given to you on the handout. But it's not double check and email me that I'm almost positive. Yeah, I can't visualize that part of it. And it has a tape to pull it up now. But, but does anyone have that one here? I don't have laptops. So check it if you don't mind well or well or live. I mean, we don't care if you memorize this. I'm pretty sure we give it to you. There's really no value in your knowing. Oh, the LC three. Ah, PSR 15 would be checked if you just set those convits to one, whatever. So, but we want to know that you know how to, you know how to use these tables and fill in the control member. So we may well ask you to do this sort of stuff. All right. So this is the implementation. So what you can see here is bottom line. If you have a decode your J in your conge don't matter. Instead, what you're getting is zero, zero followed by the op code. And that's your next state. So remember, we set up those 16 chains based on the op codes starting with state zero, one, two, three up to 15. So it's something we didn't study. It's basically the way that hardware enforces a separation between the operating system programs and the user programs. So it's, yeah, it's something if you take 391, you'll see how it works in x86 and you'll need to use it when you go build your operating system. But the design in the LC three. I didn't like it very much. It's you can read about it in I think like section chapter eight or nine or something like that. I don't remember exactly which chapter that's in. So basically just to protect the machine, the operating system from malicious or buggy user programs. So it's a hardware state that that separates one from the other. Okay. So all right. So there's decode and that that overrides everything else. So you have the decode state though, what you'll do is you'll take your J value that was a six bit next state value spread out this way. And for each of those bits, one of the conditions. So this is kind of like an exploded mux. Again, they're not in order, I think. So here's memory ready. So this is cond to equals zero, cond one equals zero, cond zero equals one. But the condition says memory ready. Then if the ready bit is set, the only time this this and gate will output a one is the cond is the memory ready. And memory is actually ready in which case, J sub one gets or with with one. So so that's how their micro sequence or works. Each of the conditions turns on one bit in the next state address. So of course, when you when you have a branching state, you have to have two next states that differ only in that bit, meaning the bit that corresponds to the particular condition that you want to on which you want to branch. Right. So you have to you have to look at the look at the diagram, look at the bit that's going to change and then pick two states that different that bit. And then the one with the zero in that differing position has to go into the J value. And the next state that has the one bit is the one that'll that'll happen when the condition is is true. So it's fairly constrained design. So J is the is the six bits that you put into the next state ID. So these are all these 10 bits you specify for every state and then you store them in the control route associated with each state. So they're just like control signals. So remember that the to get these these bits, you simply apply the current state ID to the control room and outcome, all the control signals, 39 for the full design plus these 10 bits. So 49 bits and all for LC three full design. Yeah, that's a process. Yeah, yeah, so the implementation. I think I have a picture of it or did I just. Sorry, not in these slides. So basically this implementation is just a 39 plus 10. So 49 bit addressable read only memory. And number of addresses is a six bit state ID. So it's two to the six addresses. So 64 by 49 bit memory. And that is the control wrong. And then the implementation is take the current state, which is a six bit register, apply it and then use logic like this to find the next state and then latch that in to the register every cycle basically never. There's no need to have a pause as we did in the design and put into my slides or into the notes. Yeah, they do pauses by self loops in the hotel design. Yeah, so the 25 was after we took out interrupts and privilege. So with interrupts and privilege there 39. So if you look in the in a pendix, see if you look at that list, that'll be 39 bits. If you look at the list, I give you in the notes that's 25 bits. And that's just a subset of those which don't pertain to interrupt and privilege implementation part of the data. Yeah, and the 25 we used in class were the same as the 25 in the notes and yeah. And the same as the 25 you didn't discuss in section, I think last week, same set. Same subset, I should say. Okay, you should move on and more questions on this. Yeah, I don't know if they draw it in the date of path except in the more detailed. So try to look at the most detailed one. The PSR. Yeah, it shows up in the simulator to the prince of value. So this is the logic. So the J bits are simply or together with one bit for each of the possible conditions, but only one of those conditions can be true. Because this is this is like these are minterms on the concerts and then ended with the conditions themselves this year. J five never changes. So your next your next states always have to have J five in common. Yeah, these are going these are next states. So your next state depends on J depends on condes depends on IRD. The 10 bits are used for micro sequencing. So these are just the so I know people in the back can't see these sorry they're in the diagrams that you'll get and allegedly hopefully there are pretty small ponds in hard copy too. These are the state numbers of patent pedal assign. So for example, in this state, this is 24 and 26. So you would put 24 into the J value and then because this is condition for memory when memory was not ready to stand 24 and memory is ready to go to 26. And actually there's some examples of that worked out in these slides. So I went and worked out LDI so let me go to that one was memory to the good and LDI. So here. Yeah, so LDI that was actually maybe just the one I showed you. Yes, this is 24 and 26. So the J value is 24 the condition is one which means memory and the IRD of course is zero. And so what this does, thinking back to that logic is the bit here will change when memory is ready and you'll go instead of this. Otherwise, you'll stay in this state. I know, no, no, current state has to be a register. Right. So the current finite state machine state now in this design is a six bit register. And so every cycle you calculate a new next state and you store that into the into the register that register value those six bits are then applied to the control ROM, which is two to the six addresses. So six address bits go in there outcome. I think it's 51 but by this math here it's 49 bits which are 10 bits of micro sequencing the J, cond and IRD and then 39 bits of control. Yeah, yeah, so there's a six bit register that holds the current finite state machine state ID. Yeah, it switches into privilege mode. You can see it in the full state diagram. Now this has nothing to do with the bus. This is all micro sequencer inside the control unit. Yeah, in that box marks control. Yeah, yeah, this is the implementation of the finite state machine. Okay, I think we probably should move on. So let's see next on here was control signals. So maybe just switch over. So we won't ask you to do the interrupt and privilege control signals. So don't worry about that. So maybe I'll go back to the examples we did. I know you did some like this too. So let me just kind of remind you what the rules are as we go through them. So this was the fetch and decode example. So I just mostly want to remind you of the rules rather than drive them all again. I mean, you can look at the slides easily to see the answers. So remember what we're doing is we've got five different groups. Right. So one group is the register loads. So. So what we do here is we just look at the RTL and there's some registers being written in order to be written the load signal has to be high. Right. And you don't want registers written unless the RTL says they're supposed to change. So if the name doesn't appear here, it should be zero. So the easy way is you say, well, okay, there's a mayor. So go to L the MAR put a one. There's PC. It's also written. So go to load PC. I put a one. Those are my ones. Everything else is zero. And so that's your first group. Second group. You really have to look at the data path. So this is probably the trickiest part. So spending some time here just kind of understand the different types of instructions and how they actually get implemented in the data path might be worthwhile. So what do you need to understand this? Because if you if you figure out which way the instructions flow as I've drawn for you here for the for the first fetch cycle. You know, then you can tell what are the muxes have to do. Right. Do they have to do anything? What what value has to go on the bus. Right. So if you kind of know, well, when I want PC to get into MAR, how does it get there? Is there some funny wire that runs through the middle of the diagram. Go straight to MAR. And maybe I don't need to do anything. Well, there's not. Right. So you kind of have to look at the data path and know enough about what's possible. So you can figure out how to implement the RTL. Once you do that, you know, you'll end up with something like this, right. So I would suggest scribbling on the data path instead of trying to just put it in your head. So, you know, scribble on the data path say, well, PC is coming across the bus going down to MAR. So that means they've got to have gate PC on PC is also going around this way through the plus one back in through PC mux so that I can increment PC. So it means PC mux better be set correctly, right. Not to take whatever say this input is from the adder. So, so then we have the second set of signals, which is our gate signals, only one of them can be set. Remember, these are a bunch of tri-state buffer groups. Right. So if we turn more than one of them on, we're going to get shorts. So we should always have it most one. Only one thing can cross the bus. If you think you've implemented the RTL by making two different values across the bus, you did it the wrong way. Look for some wire inside that let you route the other bits a different way. Yeah, sometimes you might be able to do that if you were able to actually put two values on the bus, but of course you can't it doesn't doesn't work physically. So in our case, we said what was it PC right so PC is one everything else is zero. Again, go back to the diagram and say, well, what about the muxes the third group is our muxes. Here's PC mux. We care about that. The other mux is three of them here for address generation. Those are address one mux address two mux. I'm sorry, that's not a mux at the adder. So these three are address generation muxes. So we don't care about those here. And the other two were not in the diagram. They're controlling what goes into the destination register and what comes out of SR two. So those two we don't care about either because the destination the register file results and inputs are unused. So we only care about the PC mux. So we have to go look up in the table what value it has. I don't have the table here, but this is the right value for PC plus one. And then the rest, we don't care. So I just want to remind you for each group. So you've got you've got the register loads, which is mostly will look at the RTL find the registers that change the ones on the left mark the ones that change as one market is zero. The gating for which you have to figure out what's going across the bus. The mux is for which you need to figure out well which mux is actually carry some of the bits you want to move back to the registers you're changing. And whether the ALU is used, which is mostly just for ALU operations like and and add. Sometimes we need to pass something through on to the bus, but that's kind of rare. But there is that option. So a couple of the couple of the finite state machine states will use it. It depends what else you're doing. Right. So I think the other path you can take. So, so if you need to get SR one on to the bus somehow. Well, one route is down to the ALU use pass A and then gate it through gate ALU. I think the other route would be to send it over to address one mux through the adder put in zero here. So that gives you SR one on these wires, which you could then if you need to store it in PC, you don't need to put it on the bus. But if you want to put it on the bus, you can go through Marmux. So if you need to write, I guess it depends what you needed to write into PC. Let's say you wanted to take something out of the adder and put it in PC. Well, then you could not go this way. So depends what other RTL. I don't remember that problem. But that was probably one of the things I wanted you to think about is try to do a couple things at the same time. If the only thing you need to do is what you asked, and yeah, either answer would be fine. Yeah. Good question. Absolutely. Either way would work. As in as in real life, you have many options, all of which work. And sometimes there are metrics that will differentiate them. But in this case, there are a bunch of bits in a control route. And so as long as the bits you choose make it work correctly and implement the RTL, it doesn't matter. Yeah. Yeah. So sometimes you'll have equivalent options for all intents for everything you care about. Yeah, I mean, you could say, oh, maybe we should simplify the data path and we could save some transistors by not adding all these different ways to do the same thing. But maybe you need both of those past for something else anyway. So there's this ALUK control. So that's the next group. So if you didn't need to use ALU, there are four different choices and there are add and not and pass a. And those are those bits are all given to you. So if you need the ALU for something, you'll have to set the ALUK bits. Otherwise, you don't care. Yeah. Yeah. Do take at least a few minutes before the final to go back and look at that resource sheet. I didn't print it for you again. But it's if you go to resources, LC3 handout or something like that. If you look at the old exams, it's just two pages with this data path, the state transition diagram, all of the bits we're talking about and some other things too. So make sure you know what's on there. So when you're preparing your your crib sheet, you know what not to bother to put. Anything else on this one? Okay. So that's the fourth group is ALU that Muhammad was just asking about. So, oh, and I put the fifth group here too, which is memory. Right. So in this case, fetch is not using memory memories down here, we're just putting things in the MAR. We're not actually using the memory. So, for memory, we turn it off, which means the read, write control for memory doesn't matter either an ALU doesn't matter. Should we move on and try to do one more quickly? Alright. So the next one, I think actually two process had slightly more. So let me do two past process for the assembler. Let me just find the assembly summary. Alright. So remember what the assembler is doing is going through your code one time, line by line, top to bottom and generating what we call a symbol table. So for every label that you make up in your assembly program, the assembler says, well, let me start. See, you told me or three thousand. Okay. First thing I see is that 3000. That's a one memory location instruction. The next ones at three thousand one. And this next ones at three thousand two, it just counts. Right. So it goes down the line. Finds a label. Food. Okay. Food is at whatever that current address is and it puts that in the symbol table. So it makes the symbol table in the first pass. That's all it does. It also checks as much as it can for you. So if you, if it sees that you've tried to do the multiply instruction will say, ah, there's no multiply instruction in LC3. That's bad. It'll tell you as soon as it can when it sees something wrong. If it said, if you see, you know, R 42. Hey, I want to put in our 42 or nine, whatever, right. Something that doesn't exist. It'll tell you that doesn't exist. If you try to do a load from, well, let's say an ad. Let's say you try to add 300. You can't add 300 and LC3. It'll tell you you can't do this. Um, so any bad operands, wrong kind of operands, wrong, wrong mnemonics, things like that. It'll tell you in the first in the first pass. The other thing it can tell you if you tried to define the same label in two different places. And it's already in the symbol table. So a second time it sees it says, hey, that's already there. I can't add it. So it'll tell you, okay, too many. Those are the kinds of mistakes that'll tell you in the first pass. Then it says, okay, I got this symbol table. Let me go through the code again. Count from the beginning again. And now when I see something like branch and Z to done. Well, then I can say, well, where's done? I'll go look in the symbol table. And if I find it in the symbol table, then I can get the address for the label can subtract it from my address with the right arithmetic for PC plus one, et cetera, and generate the offset. Now, if that offset is then bigger than the nine bit value I can use for branch, well, it just gives off and gives you an error. If you say, branch 5,000 locations away. Sorry, that's not an LC3 instruction. So you can get a couple kinds of mistakes. One is, well, it didn't find the label in the table at the symbol table doesn't have that label. So where should it, where should it go? It's not going to guess. So just tell you, okay, you didn't define a label or the target address is too far away. So those are the mistakes and get in the second pass. How do you undefined? No, you can't because the assembler just scans from top to bottom. And so the label might be defined later. And you can't know. And so if it goes and looks in the table for the label in the first pass and it doesn't find it, well, is that because the labels below it or is that because the label doesn't exist? You can't know until later. So doesn't try to make a guess. It doesn't try to wait until it finishes the file that just says, well, we'll figure it out in the second pass. So that's why the undefined label only shows up in the second pass. I'm sorry if it does it. It looks for the definition of the label to assign the address. Yeah, I mean until it finds the definition, you know, the place on the left side is where you define the label. Yeah, the use of the labels might happen many times. Yeah, but the left side of it. So the reason it's in order is because as it finds them in order, it puts them in the symbol table in order. Yeah, pretty sure it prints them out in address order and the LC3 symbol table. Yeah, I mean, sometimes some tools will do things like alpha, but ties your labels, right? Because maybe some maybe that's easier for some people to read or something. Any other closing questions? Okay, so hopefully see you next Wednesday. Thanks for next Tuesday for office hours. Don't forget to go get some cookies and hot chocolate. Thanks for watching. Thanks for watching. Thanks for watching. Thanks for watching. Thanks for watching. Thanks for watching. Thanks for watching. Thanks for watching."
    },
    {
        "ECE120-2016-09-07-LEC-07-slides.mp4": " So we're going to pick up where we left off talking about expressions and operators and see, talk about basic IOs, a print-f scan-f and then talk about statements. Hopefully you had a chance to take a look at the email that I sent out yesterday. So we have an online automatic feedback tool for programming and what we're hoping is people will play with it. It's used in 220, so if you get familiar with it, it will help you in 220 also. But it's basically a computer tool that will help you find bugs in your code. So I can tell you more about it if you're interested in office hours. But we have an undergrad who's doing his thesis, creating exercises for 120. And so those are available to you. Has nothing whatsoever to do with your grade. If you don't want to do it, don't do it. Signing up doesn't commit you to anything. So if you think you might want to play with it, sign up. We encourage you to do it because it's supposed to help you. But if you don't want to, that's okay too. But I do encourage you to try. All right, so let's see. Daniel was somewhere here. Usually there you are. You asked this question about Unicode in C identifiers. I want to look it up. Apparently it's been in the standard since 1999, but compiler still not really quite well supported. So if you use these flags in the lab, standard C99 and F extended identifiers, you can use this type of code. So this one everyone understands. How many Spanish speakers are there? Do you know this word? Mianna, yes, thank you. Gas, good. And how about Chinese speakers? Anyone speak Mandarin? OK, can you read this identifier? Yeah, it's Ming Tian. Yeah, yeah. So not exactly what you might want. So if you want to use it to change regular text like the commented versions into universal character notation, which are the things you can compile, their tools that can do that. There's some instructions on this web page using Pearl. But in 120 assignments, use ASCII. Please don't put UCNs. All right. So do a little bit of review before we dive in since it's been five days since we talked. So we're going to cover four types of operators in our class, arithmetic operators, which we already finished, bitwise Boolean operators, relational comparison operators, and the assignment operator. We're also going to take a look at logical operators, briefly. The couple of the online exercises that use them. So if you want to do all of the online exercises, you'll need to remember what they mean. But you shouldn't need to use them otherwise in the class. So these are the bitwise operators, bitwise and or not XOR. And then the shifts we hadn't talked about yet. So let's go ahead. I wanted to put actually one slide with AND to show you these things written out in bits. So we did the AND last time, but it's maybe easier if you translate the hex into bits, or maybe harder, since you have to write 32 bits down. But essentially, all the AND bitwise AND is doing is going one at a time through each of the pairs of bits, taking the AND bitwise for each pair, and producing that AND, and then that's the answer. So if you expand 120 in bits, that's the top line. 42 in bits is the second line here. If you add those together, get the bottom line, which evaluates the 40 or 28 hex. So that's what it's doing for you. All right, so left shift. Left shift is basically shifting all of your bits to the left. So what does that mean? It's like multiplying by 2 to the n. So if you shift by N bits, it's like multiplying by 2 to the n. So for example, if you declare A equals 120 and B equals this hex number, and you shift left by 2 for A, then let's see, that would be 2 to the 2 is 4, so you should get 480. And in fact, you get 480. So with this pattern B, if we shift by 4, that will shift 4 bits to the left, so we'll get 4 zeros on the right side, and then the F on the left will fall off. So the shift will overflow. So it turns out we get kind of what we'd expect. Instead of 6Fs, we have 5Fs. There's an extra 0 on the right, and we've lost the high bits. By shifting them off to the left, because we can only have 32 bits in the answer. That number is actually smaller than the original B value, and so that's an overflow. It's not multiplied by 16, as you'd like it to be. So shifts can overflow. Shifts by 32, by the way, are not defined and C. So be careful how you shift things. I forgot to mention that. It shouldn't come up. So what bits appear on the left when you're shifting right? So shifting right just means take your bits, move them down towards the small end. But what bit should I put in the high part? Zeros? Yeah, so in this case, I want to get divide by 2 to the 2 or 4, so I should put zeros in, that'll give me 30 in two's complement. What if I want to shift this bit pattern 4 to the right? If it 1's or 0's on the left? Sure. So which one is it equal to? Is that negative 256 or is it this big number here? I didn't tell you the type, right? I just wrote some bits. So it depends on the type. Well, it's bits. I didn't tell you the type, right? I can make that an unsigned or a 2's complement. So if it's a 2's complement number, it represents negative 256, in which case, if we wanted to divide, we'd like it to divide by 16, get negative 16, we'd insert ones for that. If it equals this big 4 billion number, divide by 16, you got 268 million sum on the left, we should insert zeros. So how does a compiler decide what looks at the type? So if this were not just a bit pattern, but we're a type, and yeah, it's true. If you type that bit pattern in, the compiler will assume 2's complement. But if you put it in a variable, the compiler will use the type of the variable. So if you have a 2's complement representation, it'll do what's called an arithmetic write shift, which means copy the signed bits. If you have an unsigned int, unsigned representation, it will insert zeros when you do a write shift. Yeah, that's true. Yes, int is 2's complement. Yeah, if you want unsigned, say unsigned int, that is, I've written down here. I'll give you the unsigned int. Okay, so write shift then will use the type and end up dividing by 2 to the end. Now, of course, that can overflow or underflow 2. It's always going to, it's always going to round down. So if I take a up here, negative 120, and I write shift that by 2, divide by 4, I should get what? Negative 120 over 4. You get negative 30, right? So you can see it's put some extra ones in up at the top. And if you look at the bit pattern, you'll see that it's basically just shifted by 2. What if I shifted by 10? It's like dividing by 1024. So I'll be getting, it's a 2's complement number, I'll be, and it's a negative 1. So I'll be getting ones in at the left. So what am I going to end up with? Negative 1, right? So it'll be all 1 bits, which is negative 1. So you can think of that as divide by 1024, that gives you negative 120 over 1024 around that down, that gives you negative 1. So I didn't wait for you to tell me, okay, if I shift this bit pattern 2 to the right, I put 0s in at the left because it's unsigned for B, and I get this bit pattern here, where I've just taken the bits and shifted them 2 to the right. If I shift 10 to the right, I get more 0s on the front. So it's just moving bits left or right in the bit pattern. Yeah. So to know why these are the right answers, you will have to mentally translate from hex to binary and then do the shift and then translate back from by new to hex. Yeah. So I don't expect you to be able to do this in your head. The reason I put the decimal values up here is to make sure you understand it is dividing by 2 to the n. And I written these as decimal, it would also make sense, except it would be a huge number. So at least I wouldn't be able to do it in my head. Good question. Okay. Usually what shifts we're thinking about bits, we're using our numbers to represent bits. So you can use it for multiplication, it's slightly different than, right shift is slightly different from division because most division will round towards 0 and right shift will round down. Yeah. Question? Yeah. That's right. It doesn't matter. So if you think about the representations, it never matters. So to multiply by 2, whether you have positive or negative number for a 2's complement, you put a 0 on the right side. So. And the same for unsigned. I mean, there's no negative unsigned. Okay. So that's it for the shifts. We also have six relational operators. So less than, less or equal to, equal to, not equal to, greater or equal to, greater than. You can't put spaces in these. One thing that's a little strange and see, in order to do a comparison for equality, you have to put two equal signs. And so you'll see later, one equal sign means something different. It means the assignment operator, particularly. So you need to not put spaces in these and remember that to compare for equality, you need two equal signs. And see anything that 0, 0 bit pattern is false, anything that is not 0 bit pattern, anything else is true. The relation operator is evaluated to 0 if they're false and 1 if they're true. But didn't see anything that's, anything that's not 0 is considered true. So that'll come into play when we look at logical operators. So if I make these declarations, so I make two integers, a negative 120, b 256, and I say, well, is a less than b. So clearly, if I define them this way, yeah, of course, negative 120 is less than 256, right? But if you're then put the same bit patterns in using an unsigned representation, and they would, they would look like this in hacks, and you say, well, of course, this one on the left is much bigger than that one on the right. So if I compare less, it should be false. So again, like shifts, see compiler will take the type that you declare of the variable, and it will use that to make the decision. So even though the bit patterns might be the same, the outcome might be different for relational operator, depending on whether the type is two's complement or unsigned. Okay, so that's it for relational operators. The last operator is the assignment operator, so you can change variable values with the assignment operator. So for example, you could say, well, a equals 42. That's an expression. What that expression does is it takes the bit pattern for 42, and it overrides whatever bits are currently in the variable a with the bit pattern for 42. So you can write any expression you want on the right hand side. So you could, for example, write a plus one on the right hand side. That'll take the current bit pattern of a, add one to it, and write that new bit pattern in the sum back into a, so increment a by one. So any expression you want on the right side is fine. On the left side, not so much. The C compiler cannot solve equations for you. So if you say, well, a plus b should be 42. Go figure it out. The compiler will say, I don't know how to figure anything out. I'm a computer. It'll actually say that much more cryptically, but that's what it's really trying to tell you. Because I have no idea what you want to. Change b. So you can't write things like this and see. So you get a compilation error. So for our purposes in EC120, the left hand side of the assignment should always be a variable. OK, so just take a variable, put on the left, right hand side, any expression you want. Including the current value of the variable, like a equals a plus one is OK. One pitfall with this, because it looks like algebraic equals, people often accidentally when they want to do equality comparison, they write one equal sign instead of two. So if you do that by accident, so let's say that you want to compare a to 42, you're supposed to say a equals equals 42 to do that comparison. But let's say you make that mistake and you say a equals 42. Sometimes the compiler can figure out, you probably didn't mean to do that and give you a warning, in which case you know, go fix it. OK, but it's probably better to get in the habit of not writing your comparisons that way. So if, for example, you write your comparisons with 42 on the left and you say 42 equals a equals a, it's the same comparison. But if you make a mistake, you'll get 42 equals a, the compiler will say, I can't do that assignment. That will always happen. So if you put the expression for an equality comparison on the left, the compiler will always tell you there's a mistake and you can always fix it. So it's just a good habit. I started doing it relatively recently, but it suggests you get in this habit too. I will try to make all my examples follow this rule. All right, then the last operator is I want to show you, and again, you can tell by the stars, it's not something, not something critical to our class. You will use it into 20. There's actually some subtlities we won't talk about here that you'll also learn into 20. So logical operators. So and or and not, they're different from bitwise and I'll explain that in a minute, but they just operate on truth values. So remember zero is false, anything else is true. So the logical operators will look at their arguments and they'll say, well, is it zero or not zero? If it's zero, that means it's false. If it's not zero, that means it's true. And they'll return, they evaluate again, either to zero or false or one for true. So for example, if I declare a couple of variables, A and B, 120 and 42, then I can write these logical operators. So zero is greater than A or 100 is less than A. True or false? So is zero greater than A? So zero is not greater than A, right? A is 120. Is 100 less than A? Yes. So if I or those two together, I get a true, right? Okay. Good. And what about the next one? So is 120 equal to A? Yes. So does it matter what the other one is? It does, right? It's an A. Good. And is 3 equal to B? No. So what's the answer? 3 or 1? Good. So what about this one? Here, it says compare A to B and then complement the answer. But 1, because A is not equal to B, right? Good. All right. So is zero less than A? Yes. Is zero less than B? So is that A and true? And then complement it, so what should I get? Zero. Good. And then the last one is B plus 78 equal to A? Think so. Yeah. Okay. Good. You know how those work? So here's a task for you. There's a C expression. Think about what the answer is. You ready? The tough one, I know. Good seven? You didn't get seven? I hope you get seven. So I'm pretty sure everywhere I've talked to people from everywhere around the world, the rule for precedence on multiplication and addition is the same. So hopefully it's the same everywhere. But usually we're told, okay, you do your multiplications, then you do your additions. So this one is relatively clear. It should be, hopefully. If it's not, you can add parentheses and C code two, that'll be fine. So the order of operations is called precedence. Which one comes first is called precedence. So here's another one. Here's another one. Excuse me. Sorry about that. Here's another one for you. You're 1.67? No. Is it someone's birthday? Maybe it's a divide by zero error? So like if you do that two over three, you get a zero, a 10 over zero is divide by zero. Maybe it's one. You see the left one first. If you can't tell, and honestly I don't think there's any way, I don't think anyone's ever written this in elementary school or high school or college. No one writes that kind of expression. Don't look it up at parentheses. I won't even tell you how to look it up. Seriously, never look it up. You could, but then your code, no one else will understand it either. Because they won't know the order either. So if you don't know the order, put parentheses. That way your code is readable. Never go look up precedence orders. If it's not obvious, and I think probably the only one that hopefully is common enough is this multiplication versus addition. Maybe that one is not even obvious. Okay. Any questions on operators or expressions before we shift gears a little bit and talk about IO? All right. So we're going to look at input and output. Input is going to come from the keyboard. Output is going to go to the monitor, which means basically a terminal, like you've been using in the lab. So you can send ASCII text out. You can read ASCII text in. Those are the basic IO operations later, not in our class, but later you'll learn how to manage graphics and things like that. So to control input and output, we use two functions. When you want to use those functions, you have to put this line at the top of your C program and says, well, I want to use the standard IO functions. So just put that line there. If you want to understand it, there's some start section in the notes that'll talk a little bit about the preprocessor, but don't really need to understand it at this point. You'll have plenty of time to play with it in your time here. So this directive tells the C compiler basically, hey, I want to use these standard IO functions, which I'll tell you about shortly. So to write text onto the display, we'll use a function called printf. So the f stands for formatted. So the first thing you have to put is your desired format inside quotation marks. So for example, you've got this function called down here, says printf, parentheses, close parentheses over here, semicolon. Here is an example inside quotes. What that does is it sends the string or the characters between the quotation marks to the monitor. So it'll print out here as an example. It will not print the quotation marks. If you want special characters, so for example, if you want a line feed, you need to tell, well, it's not easy to put those between quotes because then your code looks funny. And so you need to put those, mark those special characters with this escape character, the backslash. So for example, the line feed. If you want the output to start on a new line, you need to print and ask your line feed character in order to do that. Inside the quotes, you put this backslash n and that will tell printf that you want to print an ASCII line feed. So if you want a backslash, well, you have to put two backslash. Two backslashes will become one. The first backslash says, okay, there's some special ASCII character coming. And then if you put another backslash, that's one backslash printed out. But backslash n will give you a line feed. You can put as many line feed as you want in your format string. So for example, if I print this format string up here, the output will appear here. I've also stuck a backslash in just to illustrate it. So it comes out on three lines and it actually has a backslash n at the end. So if you do another printf, that will start on a fourth line. Now, what if you want to actually print some variable values or some expression? So for that, we use what are called format specifiers. So here, I've included three of them in my format string, in my between the quotes. They're all percent D in this example. So all of the format specifiers will start with a percent sign. The D stands for decimal. So it will print an integer, a two complement number, indesimal for you. So here, I've just written some expressions separated by commas after the material, after the format between quotes. And so each of those expressions will be evaluated. So 6 times 7, of course, is 42. That will then be matched up with the first format specifier here. And it will be printed as decimal number 42. Second, the percent D will match the next expression in the comma separated list. So the 200 plus 17, prints is 217. And then the last one here will match this expression, 32 bitwise, and with 100. And so that will end up being 32. And so what will print out is this line down here. And at the end, you can see there's a line feed. All right. So what are the other format specifiers you can use? So if you want to print an ASCII character, you've got percent C. The percent D is what you just saw, take an integer, two complement number, printed as decimal. So ASCII decimal representation of the number will go out to the display. If you want a double, printed as scientific notation, you use percent E. If you want it printed as decimal, you use percent F. If you want a percent sign, percent percent. These are all, by the way, in the notes. So I'm going kind of rapidly through the format specification. So that's a bitwise end. So if you think about where the bits in 100, you've got the 64th place, the 32th place, and the 4th place. So this is the power of 2. So this is just the 32th place. So if you write them as binary, and you line them up, there's one bit, which is the 32th place, that's on in both numbers. So the end takes that bit and turns it into 1, everything else is 0 to the answer is 32. I know that would be a logical. So 1 ampersand is bitwise, 2 ampersand is logical. So if you were to put a logical operator here, 32 is not 0, so it's true. 100 is not 0, so it's true. True and true would be true, so you get a 1. But bitwise will give you bitwise end. So those are different operators. So that's a good question. That's right. So if you do not include percent Ds, the compiler will not, some compilers will give you a warning, but the compiler will not prevent you from compiling your code. It'll just warn you that you've got extra expressions. Those expressions will be ignored. I'll mention that a little later. If you were to evaluate these expressions and put the answers in quotes, then yes, whatever material you put there is going to be printed. But if you want the compiler to evaluate expressions, here you could do it in your head in advance and simply write the numbers. But imagine these were the values of variables. And you can use variables in those expressions, which you won't be able to calculate in advance. You're wrong. I think on both counts. So let me go forward. So x is for hex. I don't think h will do hex. And I'm almost positive that b will not do binary. Print-in-f implementation is different. So I'm not, for example, sure what the visual studio print-in-f will do versus GCC. These are all standard and pretty much any system you use will implement these. But there will be extra ones available on different systems. So as far as I know, there is no binary. You have to write that yourself. There is no standard binary printout. There are standard hex printouts, which are x and uppercase x. If you want something printed as unsigned, you can use percent U. And then if you want to see more, look at the man pages on a lab machine. And that will give you the full definition for print-in-f on the lab machine. Any other questions? All right. So let's take a look at a couple of issues. So one pitfall, if you want any spacing, you have to include it in your format. So if you print percent U, percent D, percent D, and then these three expressions, they just happen to be numbers this time, what will print is shown down here. There's no spaces. You didn't tell it to print spaces. It didn't print spaces. So your numbers are all jammed together. If you want spaces, you have to include them in the format string. So be careful about that. Anything that isn't a special ASCII character or a format specifier will print exactly as it appears between the quotation marks. So whatever you want, you can put there, and it will just come out as part of your output. Yeah. All right. So you can put a dash in your format string. That's fine. Do you mean backslash? Yeah. Okay. So backslash is two backslashes. So you can see up here, we have two backslashes between text and has, and when it prints, it comes out as one. So if you want to backslash, it's two backslashes. If you want a percent sign, put two percent signs out, we'll come one. That's right. That's right. So if you write percent percent f, that will print as percent f. It will not be interpreted as a format specifier. Yeah. So if you don't end your format with a percent end, then the next time you print something, it will come on the same line immediately after it was printed by the first printout. Yeah. And that's useful sometimes. So you'll see a lot of programs in our class where you print a prompt. You know, please enter some numbers. So if you don't want the numbers that they type to appear on the next line, you don't put the backslash in, and then it will appear on the same line when they type it. So it's a useful thing to be able to do. Yeah. Yes. Flow is a single precision. Yeah. So I didn't mention it here. Actually, when you use a floating point expression in a print app, the compiler will implicitly convert it to double. And then the print app will treat it as a double. But you don't really need to worry about it too much. It'll be automatically done transparently for you. And that conversion, there aren't too many ways it can confuse you. So I didn't mention anything. Yeah. Observation. In when we, when we see scan app, you have to explicitly tell it whether you want floater double, because very, very matters. All right. So that's one pitfall. Another pitfall is passing the wrong kind of expression. So here, what I've done is I've said in my format, well, I want to print an integer in a floating point number. And then I passed a double in an integer. So I passed them in the wrong order. Okay. Now, the output is actually system dependent, but it's generally not going to be what you want. So my laptop, I think it was printed at both of zeros. And clearly, that's not what whoever wrote this code wanted. Compiler may be able to warn you, but be careful about it because sometimes it won't. If you pass too few or many expressions, if you pass too many again, compiler may be able to warn you. It's not so bad because it'll just ignore them. And then if you look at what's printed, you'll say, well, where my expressions go. And then you realize you may have enough format specifiers. If you pass too few, it will print bits. It will go find whatever should have been there to print and it will take them. They will be bits and it will convert them. So the behavior is unspecified, maybe able to warn you, may not be able to warn you. And so again, be careful. So that's it for print out. When we want to read input, we're going to use a function called scan app. So this will let you type things into the keyboard. The way it works is it won't actually read anything until you push the inter key. So you can type as much as you want. You've put backspace. And then eventually you push the enter key and then scan app will get some things to look at. The F again stands for formatted. Scan app also takes a format in quotation marks and a comma separated list. This time of variable addresses. So you can put as many variables as you want separated by commas. All of them you need to put this ampersand in front of the variable name. So the only this operator we're not going to talk about other than to tell you to use it in scan app. What it means is here's the address of the variable. That's where scan app has to put the bits that it gets by converting whatever you type into say a choose complement number. So it has to put those bits somewhere in memory. The address of a is the memory location where it stores those bits. Yes, you need to put ampersand in front of every variable name. So if you had two or three of them you would put ampersand a ampersand b ampersand c separated by commas. Yes, so the percent d means decimal interpreted as choose complement. So you type in some decimal number and ask you and it translates as the choose complement and stores it in whatever address you've given it here. Which here is the address of the variable a so a will now equal whatever number you typed in decimal. There is no there is no scan function so it'll simply give you a compiler error. Yeah scan f is there are other functions but scan is not one of them. So you need to use print f. Scan app reads from the yeah so you would you would first call print f and that would give the prompt and then you would call scan app that would allow the computer to read from the keyboard. Yeah good question so what happens if if the human does something wrong. So let me come back to that because I have a slide on on what the return values are so when you make a function call it's like an expression it evaluates to something so I'll tell you what they evaluate to when you call print f and scan. Good question. So scan f is going to ignore the white space that you type so for example if I if I asked for two integers here a and b and the user could type five space 42 and that would be fine and a would become five and be would be 42 or they could type five enter 42 enter and the same thing would happen. So scan f will ignore extra spaces extra tabs and so forth and so on. If you put other characters in your format string the user has to type them exactly so this is rarely rarely useful. I mean maybe if you want them to enter a time and you want to insist that they type a colon maybe that's okay but you know if you put you put something like this where I put these brackets in here then the user actually has to type those brackets exactly like this. So you can put some spaces. Actually if they put a space using this format scan f will ignore those characters because the space was does not match that less than sign and so then b will be unchanged. So I actually will not process the input as you as you would like so it's rarely useful to put extra extra characters in. So this is a list of conversions. They're very similar to print f the difference is that if you want to convert to a float use percent f if you want to convert to a double use percent LF for long long float. So that's the major difference here you can use unsigned you can use hacks. Yes LDS along and LLD is long long in. You mean if you did not put the ampersand on yes then it would take the value of a as the memory address which means it will write to some random memory address which is kind of outside the scope of our class but writing bits to random memory addresses you can tell is probably not a good thing. That's right that's right. Yes so for every for every format specify you put in your format you want to have one expression in the comma separated list of expressions just like on the print f when you told that you wanted to print an expression you have to give exactly the same number as you have in your format. These are simply variable names I just decided to make them capitals because I thought it was easier to see on the slides because they can be any variable name. They have to put a space anyway to separate numbers but putting a space between the format specifiers makes it actually a little more flexible so it's probably a good habit to put spaces between your format specifiers and scan up the resulting input will be a little more flexible but but for example. You can't type 542 with no spaces and expect the computer to understand that you meant 542 as opposed to 54 and 2 or 542 and I'll type something else later right so you have to you do have to separate them with spaces already even if there were no spaces in the in the format. No and so that's one case where you might want to put that literally in the string that if you want them to type 0x or to be able to type 0x you'd have to have that explicitly in format this will simply take the ask the characters and treat them as hexadecimal. So you pretty it's percent asked for a string but that's outside the scope of our class because you need to understand pointers and memory and so you'll learn that into 20 actually you're learning about it at the end of our class but you learn about it and see into 20. Alright so let's see same pitfalls is print up match format specifiers and ordering to variable types match number specifiers to the number of addresses and don't forget to write the ampersand because otherwise what will happen is as Daniel said a little interpreter your variable value as an address and then it'll write to some random memory location is not a good thing. So what do these things return so this is this is what Sasha asked about earlier so when you call print up it returns the number of characters printed so whatever this whatever output it translates to it will count the number of ask you characters it sends to the display and it will return that number of characters for you so it'll tell you how many characters are printed. It has uses but probably not so much with this particular calls of rarely will you see it someone actually using it in code with scan F on the other hand you should always check the return value so scan F returns the number of conversions that were made so for example if you ask for two things and the user says hello and you ask for two integers the user says hello and will it can't figure out how to convert hello to a two complement number and so scan F will fail and will return minus one. If you type something like 42 space hello it will convert the 42 and then again it will fail trying to convert hello to the second number and in that case having converted one number will return the value one so if you want to check that the user type the right thing you can simply compare and we haven't talked about this if statement yet but this is something we'll talk about hopefully before the end of the day. If scan F does not evaluate to the number two so if two is not the answer returned by scan F then something went wrong so scan F should return the number of format specifiers that you asked for if it returns something else the human did something wrong there are more graceful ways to help the human fix that but the easy way for our purposes for 120 is to say well if they do something wrong and the program tell them to run it again. So most of the code you'll see will be this this simple terms of how we handle errors. Does that answer your question? All right. I want to try to cover statements and then on on Friday we'll look at code examples so mention I do have handouts you're feel free to take one if you want to look at the code in advance it's on the links page two if you'd rather look at it just online I do want you to have a handout in class on Friday so if you take one please bring it back so that we have enough I think there should be enough as long as people aren't taking two or three or something. And it is online to and the codes are online if you want to compile them so you can play with them as much as you want. So remember I said last week a statement tells a computer what to do right so let's look at the kinds of statements we've got three kinds and see so a statement can actually consist of other statements which can consist of other statements so big C program will have many very deep recursively nested statements. So the other ones will look at the fairly simple so the three types of statements you have what's called a null statement which does nothing so it's just a semicolon all by itself. A simple statement I'll show you some more kinds in a few slides but one kind is just using expression follow it with a semicolon so for example a equals B it's an expression but I want to do an assignment but a semicolon after it that says OK my statement is done go do the assignment for me. A print out it's a function call also an expression so expression followed by a semicolon makes a statement simple statement. You need to have a semicolon I think someone asked on last week you know what if I leave the semicolon out the compilable complaint. Compilable say I can't compile this for you. Alright the third type of statement is a compound statement and this is a sequence of statements so you might think oh that looks a lot like my main function in fact it is the body of main is simply a compound statement. So you have a list of a list of statements a sequence of statements that execute an order so you can put whatever you want so here I said OK radius will be 42 my variable C which is maybe circumference I'll calculate as the you know two times pi times the radius and then I'll print that out. Inside a compound statement you can actually have additional variable declarations if you want to you put those above the statements so you can have variable declarations with the start and then statements inside. We won't use that often in our class so you want to put too much detail. So how do these execute so there are three three things to think about one is a sequential sequential execution so the function body of main is a compound statement and they execute in order. So if you have three statements the first one executes first in the order of appearance in the file the second one execute second and the third one executes third. And when the program is started all the program does is execute the statements in main in order in the order they appear and then the program is done. Here's another one you actually saw this one already but but I want to make sure you understand it so you can also introduce what's called conditional execution so this illustration is a flow chart the way it works is you're going to execute the statement the first thing you do is you evaluate an expression so there's some of the expression you evaluate. And it will either be true or false remember true is anything that isn't zero false is zero if it's true you'll have what's called a then statement which is a block of code corresponding to when this statement when this expression is true and you'll execute that statement. So the expression of values to zero it will instead execute what's called the else statements so I'll show you how this looks and see but basically it's just a choice you do the then or do the do the else. So it looks and see so use what's called an if statement you put if you put the expression you want to evaluate here and then if that expression is not zero the code that you execute will be in this in between these braces and you put the else keyword and you put another pair of braces and if the expression is false then this code down here will execute. If you put any expression you want and you can also leave off this else if you'd like to so you can't leave off the first block but you can leave off the second block and the else keyword. That's a comment. So that's just how the sea language is defined so the sea language is defined to follow what we call this this is called a flow chart so what the sea compiler does is it translates this piece of sea code into instructions that execute this flow so it says okay first calculate the value of the expression. And if the value is zero go down to the else statement is the values non zero go to the end statement and so those statements are arbitrary code their compound statement so you can put whatever code you want there. Does it make sense? So you don't always have to put the else you can say if expression do something and if the expression is false don't do it don't do anything just fall out of the bottom and keep going with the next statement. So here's an example so I could say well I want to calculate the inverse of a number but if that number is zero I don't want to divide by zero so first I'll check well is my number not zero and if it is I will say inverse equals one divided by number otherwise I'm going to print an error message. That's what this little if statement will do the test is up at the top here zero is not number if that's true in other words numbers not equal to zero then I calculate inverse otherwise I say something went wrong. It doesn't really matter but if they're in since it's not terribly interesting. Yeah so if they're in since this will generally come out with inverse equal to zero right so if they're floats they wouldn't cause divide by zero but you would get an infinity which maybe is also not what you want so you maybe think of them as floats. So the thought was to set the variable value and then to use it later so we'd also I mean I'm showing this one statement in isolation you'd have inverse equal to something else later you could add the print F inside as you said so the less of things you could do with it but I just wanted to show you how we used it. Good question. Yes yes so this is a style thing so anytime you have a compound statement you should increase your level of indentation by whatever your standard is I usually use for a lot of people use for some people use two spaces some people use eight and it doesn't really matter what you pick but you should everyone on whatever team is working on a program should use the same style. The compiler will not give you an error but we will mark up points. It makes it really hard to read your code right it makes it very difficult there actually tools that will automatically indent it for you so you know if you're worrying about it you can you can run it through an auto indent tool but they'll also do things like decide whether to put braces on or things like that rewrite your seat code for you to make it look nice. Any other. Here's another example so let's say I've got a variable size is an integer let's say I want to make sure size is not bigger than 42 so here I don't have an else 42 is less than size I'm going to change size and I'm going to tell the user hey I change size so I'll print up size set to 42 and I'll assign 42 to size if size was already less than 42 or equal to 42 I don't need to make any change. Another another way we could use an if statement. Yeah so in this case there is no else block so if this condition is false it simply comes comes down to whatever is the next statement after the if I wanted to give you an example with and without an else. Okay then the last statement I want to look at is this iterative statement so if I want to do something more than once and the number of times doesn't have to be defined the way I'll decide to stop is I'll have an expression so if I want to do something more than once I can have this structure here so first I'll have an initialization expression then I'll have a test expression the computer will produce instructions that evaluate the test expression and if it's false I'm done if it's true I'll evaluate what's called the loop. Body then execute an update expression and then go back up and do the test again so go around this loop as many times as is necessary until this test expression becomes false now that can be infinite right so if you write right a loop badly it just will never finish. Sometimes that's what you want right you might want a program that never stops right so for example you probably don't want your operating system to say you know what my loop finished and I'm just going to I'm just going to do nothing now I'm moving on. So an operating system or an online service or something you would have an infinite loop as the main as the main construct right just say okay keep paying attention to people and doing what they ask. But so you can do that easily with a loop and you just make sure that test expression never becomes false here's what it looks like and see we're only teaching teaching you one but I'll show you another one so this is the for loop so you've got your initialization on the left they have four open parentheses initialization expression semicolon test expression semicolon update expression close parentheses and then a compound statement for your loop. So just to make sure you understand how the flow chart works I wrote it out is just a list so what happens is first the computer evaluates a net after devaluates a net it evaluates the test expression and if that test expression evaluates to zero then it's done it skips to the end of this list and it moves on to the next statement. Otherwise if the test is non zero that means true then it evaluates the loop body executes the loop body that's a compound statement so do a bunch of statements if you put a bunch of statements in there. Then it will evaluate the update expression after it finishes the loop body and then it will go back to step two and evaluate test again and go around to three four to three four to three four until test evaluates to false. Here's an example so from one of print the multiples of 42 from one to a thousand I'll start by setting n equal to one then I'll check that n has not gotten bigger than a thousand because I only want to go up to a thousand. So in the first time we execute this loop body and will be one and will continue to execute this loop body a thousand times until n is a thousand and one at which point this test will be false and will finish. The value of n from from one to a thousand will check is n mod 42 equal to zero that would mean n is a multiple 42 so if it's true we print that number n using percent D followed by a character term so this loop will print all the multiples of 42 from one to a thousand very important set of numbers. Yes, but that's beyond the scope of stuff I want to talk about. Yeah, let me not ask me afterwards I'll tell you why. So one more loop we're going to look we're actually going to do this loop in class on Friday so a while loop basically it's the same thing but we don't specify the init or the update so we're we don't want you to have to learn this in EC 120 but you might see it so maybe just look at these slides will go through the Fibonacci loop as a program on Friday so this will come back and feel free to take the handout if you'd like to. Thanks. you you you you you you you you you you you"
    },
    {
        "ECE120-2016-09-12-LEC-09-slides.mp4": " to build logic gates. We may get to optimizing logic expressions, otherwise we'll start on Wednesday. I'm pretty sure we're not going to get to fully in terminology. Someone pointed out that my factorial code also had a bug. So whoops. But also Professor Verredan will guess lecture on Friday. I won't be here, so he will let you in my place. I noticed, unfortunately, I didn't notice during the lecture, the mic cut out very shortly after the start of the lecture on Friday. So unfortunately, there's no sound in the video. So sorry about that. If I find time, I'll try to re-record those and personify and post them for you. But the slides are there. So you can look at those. So before we get started, I wanted to remind you that our first midterm is coming up real soon now, a week in a day, 7, 8, 30 p.m. location, check the wiki. If you need to take the conflict, you need to sign up by today. So please do that through the wiki. The coverage is basically everything in part one. So if you look at section 1.6, it gives you a list. The exception is truth tables. You don't need to be able to read them or write them. I know you can all do it, but the other classes didn't do it. Didn't cover that in class, so it won't be on the exam. Oops. Yeah. Yeah. If I went on to the fifth section. So it points you to compass. And I didn't follow it to compass because I think it uses here. So you followed it and it didn't go there yet. Yes. OK. So it should be up tomorrow, hopefully. Yeah. Sorry. It's not up already. We have the rooms. I think Professor Harmiyo will do assignment by name or something, too, or maybe by section to room. And so I think he just hasn't posted it yet. It'll certainly be there before Tuesday. OK. So next Monday, we won't have class. So you're not obliged to come. We will have a review session. So here's how to work. You suggest topics. I will write down a list of topics on the board. And then I'll have you all vote on the topics. And then I will cover them in decreasing order of popularity until we run out of time. And then it'll be on the video. So if the mic stops working, tell me. Because I've actually lectured in this room plenty of times with no mic and my voice is loud enough. So I just don't even notice. I just talk louder. And if you want to get still hear me, I think everyone heard me last time, right? OK. All right. So other resources, practice online tools, watch the videos. There are actually two videos. Attend any of the three lectures, assuming there's space in the room that is can't override the fire marshal. Can't be unsafe. Go to office hours. There is an A to cap a new review session. A to cap a new is the electrical engineering honors society. The only problem, we can't vouch for them. So if they make a mistake, not saying they will, but if they do, it's not, sorry. Nothing we can do about that. So if we make a mistake and then that affects your test score, then we'll give you points back. But we can't do that for them. All right. So usually it's probably worthwhile. So how can we build gates? So the first thing we did is we said, well, we've got electrons. We can measure voltages. Give us a bit, binary digit. And we said, well, let's look at representations based on bits, based on the electrons here and there. Then we said, OK, we can do functions on bits with Boolean algebra. But we kind of skipped over the device level. So today we're going to start looking at, well, how do you take devices like CMOS transistors? I'll tell you what CMOS means later. I'm sorry, CMOS gates, MOSFET transistors, and build these Boolean functions out of them. So that's what we're going to start looking at today. But first, I want to run something by you. This is just so exciting. I had a really great idea. I call it a torch. Just a pointy that you're going to light you up. It'll be so nice. You could point at the podium. It'll light up. No, it's a light. I mean, you see it says, lamp. It's not a laser. Actually, Nikoloney, I gave a talk and he had a visible light LED that was still under the danger level. But you didn't know that when he said, see, look how bright it is. And he said, oh, don't worry, it's safe. Thanks, Nick. So good idea. What do you think? I don't know. What? But you want me to do what? Like this? But people already make those. They can't patent that. They call it a flashlight. You've never seen this? All right. I don't know. All right, I had another idea. Here's another idea. You like switches? A bunch of switches, together, a lot of switches. It'd be good. I'm going to be a play video game. See, this will be great. Good exercise for you. When you change your bid, you just flip a switch. You're the hand-operated computer. Sound good? Good idea? Yeah. Yeah? OK. We're going to do that? OK. You don't like that. I know some of you didn't like it. Some of you like it. I got to say, if you want to be a video game champion, it's only in the training. So if you don't want to do the hand-operated computer, I understand. But with a voltage-controlled switch, then one switch can control another switch. And that switch can control another switch. So we can put two billion switches all together in one circuit. So that's a really cool idea. I'm getting tired just thinking about that something. Let's take a little break. So the person who invented that cool idea a long time ago, 70 years ago, almost, John Bardeen and Shockley and Bretain, one of them's a manager, but you can read about that if you want. But they invented it, Bill Labs. Four years later, John Bardeen joined our faculty, also the physics faculty here. I got a Nobel Prize a few years later. After that, maybe now they're 16 years, they got a second Nobel Prize for a PCS theory, superconductivity. This is where electrons pair up and act like bosons, allowing them to move without bumping into things. The his first PhD student, then Nickeloniac, invented things like the Visible Light LED. So all the lighting you see all over the world, basically stems back to one of our faculty members, Nickeloniac, who I mentioned a few minutes ago. He also invented things like laser diodes for CDs and DVDs if you have ever used those and dimmer switches and other things like that. Here are some of the things that he was awarded. You can find a much longer list on the web if you want to look. Next first student, I think it was his first student, Greg Stilman also joined the ECF faculty invented things like avalanche photo diodes elected to the National Academy of Engineering. This is actually the most prestigious honor for an engineer in the US. It's basically being called to serve the country as an advisor, as an engineer. He founded the MNTL lab, which was just right next to us, and was its first director. His first student, Milton Fang, also joined the ECF faculty and burned into terror-hards transistors. So very, very fast, right? Much faster than your typical computer these days. Also the light emitting transistor, both of these were done with Nickeloniac and the transistor laser. And he just retired actually this fall. So you could have worked with him had you come last year. Actually, he's still around doing research. But not just faculty, so just to mention one of our students, how many of you are gonna get a BSE? The others are BSE, right? Okay, people don't wanna raise their hands today. I know we've got more ease than that. Anyway, but now you're feeling shy because I'm putting killby up there. All right, so he got his BSE in 1947. 10 years or so later, invented the integrated circuit at Texas Instruments. He also invented things like the thermal printer and the handheld calculator, National Academy of Engineering and of course, Noble Prize or Physics. So now you know why we expect a lot of you. Yeah, seriously, I'm not kidding. Okay, so, all right, so that was just a little bragging break so you know more about Illinois history. So digital electronics today is based on MOSFET. So what's a MOSFET? The materials, metal oxide, semiconductor and the technology is a field effect transistor. So the voltage basically turns the transistor on and off and it's a voltage controlled switch. So the two kinds which are named after the charge carrier, so the electrons, so if the electrons move, it's called a negative type. And if the absence of electrons, which we call holes move, it's called a positive type, I think not too many of you've taken quantum mechanics, right? So a few of you. So if you think back to, I think probably most of you have high school chemistry. So if you think about what happens when you have valence electrons, you know, you can put two in the same orbital, right? And one is spin up and one is spin down. And if you have one absence, then it acts kind of like a positive charge. If you have an extra one in a orbital, acts like a negative charge. So it's the same sort of idea that in semiconductors, you have energy states and if some of the energy states are empty, they act like holes. So if the holes are moving around, it's a p-type. If the electrons are moving around, it's an n-type. Just a way to remember P and N, positive or negative charge carrier. So how do these things work? You can learn a lot more in EC440, I guess 340 now. If you want to take that class later, but I guess all the EEs will probably take it, but compies it's an elective. So an n-type MOSFET turns on when the voltage between the gate on the left here and the other terminals, it's a symmetric device, but between the gate and the other terminals exceeds a threshold. So the voltage is smaller, the transistor turns off, and then current cannot flow between the other two terminals. Historically, they were called source and drain, but that implies a direction. And this again is a symmetric device. So we need two voltages. We're going to do binary digital systems. So we need a ground, and that's our binary zero value. And we need a VDD, which today is about 1 and 1-and-a-half volts. That's our high voltage, our binary one. It used to be about five volts. Actually, the stuff you'll play with in the lab in maybe about five to seven weeks will be five volts TTL chips. But on modern processors, it's usually about a volt and a half. So we can use these binary voltages to control, say, an n-type MOSFET. Now remember, it only will turn on when the gate voltage is high. So the voltage has to exceed a threshold. So if we put 1.5 volts, and then one of the other terminals has zero volts, as you see on the left here, the current can flow, and then the top terminal can get pulled down to zero volts. So to turn on an n-type MOSFET, you put high voltage, binary one in on the gate. And then if you have one of these connected to ground, then the other side will come down to ground as well. Because the transistor will turn on. This is circuit terminology, you say the circuit's closed or open. I'd prefer to say on and off. I find it less confusing, but either one is fine. So this one, when we put zero volts on the input, remember that in our binary voltage system, the full range of voltages is only zero to 1.5. So you can't have anything lower than zero over here. And so you can't exceed the threshold. So essentially, whenever you put a zero onto the gate of the n-type MOSFET, it will turn itself off. OK, so p-type MOSFET, the voltage goes the other direction. So if the voltage from these terminals on the right to the gate terminal exceeds a threshold, then the p-type will turn on, which means current can flow between the two terminals on the right. And if the voltage is smaller, it turns off. So the voltage just goes the other direction. So here's the same diagram with the p-type. So in order to turn it on, we need to put our ground voltage in on the gate. You'll notice, by the way, that there's this inverter bubble thing here on the p-type. I'll explain how that'll help you. Remember which one is n-type, and which one is p-type, and how they work in a minute. But if you put zero volts on the gate, and you have high voltage on one of the terminals, the p-type transistor will turn on. And this high voltage can pull this terminal up to high voltage as well. If on the other hand, you put high voltage on the gate, then you're not going to have any current. Remember that the whole range of voltages here is 0 to 1.5 volts. And so you can't get a higher voltage here to turn the transistor on. And so the p-type will always be off if you put 1.5 or a binary one on its gate. Uh-huh. That's fine. Yeah, so as soon as you get a voltage with the p-type, if the voltage from this point to that point, is greater than a threshold, and the threshold is, say, about 70 or 80% of the high voltage. So maybe 1.2, 1.3 volts. So if the voltage difference is sufficient, then this is this a wire between the two terminals, just like down here. And if the voltage difference is below that threshold, which it always will be if you put high voltage on the gate, then it acts like an open switch. Turned off. I love it. You will not learn. This is the level of detail we'll cover in the class. The question is, will you see P and P junctions? If you want to learn more about transistors, then 340 is the class. Yeah. So they'll cover semiconductor devices, basically. You can give you a lot of detail on this. You'll see a little bit more. You'll see an ID curve, current versus voltage curve in 110. So you'll see a tiny bit more in 110. OK. So the drawings will actually help you remember how they work. So you notice on the P type, we have this inverter bubble on the gate. So you should just remember that that means if you put a 0, it turns on. Whereas the N type, you don't have the inverter bubble, the little circle. So N type turns on if you put a 1 on the gate. P type turns on if you put a 0 on the gate. It might not be so helpful to remember the names, because at least for me, they're sort of opposite of the binary digits that you put onto them to make them work, because they refer to the charge carriers. Yeah. Yes, this is an illustration of the on and off of P type, and two slides back was on and off of N type. OK. So how do we actually build gates? So to build gates, we're going to use what are called complementary structures of P type and N type MOSFETs. So we'll have an equal number of each type of MOSFET. And the top will put our P types, the bottom will put our N types. We say that digital systems are based on CMOS, complementary MOS. So pretty much every digital system you'll see, except for some high speed, high speed networking equipment will be based on CMOS. So all of your cell phones, all of your computers, most network routers. So what does this gate do? So here's the simplest one. We put one P type on top, one N type on the bottom. What does it do? So let's go through and analyze it. So let's start right at truth table. So first we'll put in voltages, and then we'll change it later to zeros and ones. So start with A equals 0 volts. So what about the top transistor, on or off? It'll be on, right? P type has a 0 volts on the gate, so that'll be on. What about the bottom one? Oh, off. OK, so now we have a basically a connection going from Q, the output up to VDD. So now, remember I said, well, if one of the terminals at 1.5 volts and the gate's at zero, it can pull the other one up. So this will pull the output up to 1.5 volts, so we'll write that in the truth table. What about the other case? So if A is 1.5 volts, put the labels on top transistor, bottom transistor, on, good. So now we have a path down to ground, right? So here, the end type is pulling Q down to ground down to zero volts by just connecting it through its two terminals, because it's gate input is 1.5 volts. So it's zero volts. But now let's convert those voltages into our binary values. We get those, so it's an not gate, right? Yeah, no. So you'll see the bottom transistor is on, top one's off, so the bottom transistor acts as a wire. So now this is ground down here, this little triangle. Sorry. Yeah, it's connecting the output Q to ground when you put A as 1.5 volts under these two transistors. Yeah, so the P type MOSFET, so it's not a gate, this whole thing is a gate. But the P type MOSFET has the circle on the input. MOSFET is metal oxide semiconductor field effect transistor. You don't really need to know. Yeah, transistor. Good answer. Yeah. Okay. All right. Yeah, we won't quiz you on that. Although I used to give out candy when teaching the networking classes, there's so many TLAs, because no TLA, right? Yeah, good. Three other acronym, exactly. There's so many TLAs that I told my networking class. Well, if I give you an acronym and you challenge me and I can't tell you what it means, I'll give everyone in the room candy. They actually got me a couple of times, so this is fairly embarrassing. I'll give you the same deal, because I shouldn't do that to you either. But you have to remember, I won't remind you. Yeah. Yes, yes. So this thing down at the bottom is a general symbol for ground. Yes. And this up here is a general symbol for high voltage. So ground, high voltage. Yeah. This up here is high voltage, and this is ground. Yeah, sorry. I forgot you might not have seen those. Okay. So that's our not gate. And of course we draw it like that. So this is how we actually implement an inverter with two MOSFETs, one P type, one N type. Let's do a little more complicated gate. So let's go through and analyze this one. So we'll start with A and B equals zero. So there's A. So what about that top transistor, on or off? Good. Bottom one? Off. Good. Okay, let's put B's labels. It's also a zero. We're going to do the first row, the truth table first. So what's this upper B transistor on in the bottom one? Off. Good. Okay, so path then goes from Q where? Yeah, up to VDD, right? Yeah. Okay, so we get a one. Good. Run. Seem to follow that. Same like it. Okay. Feel free to ask questions. So let's see. Here, the A values the same, right? We're going to look at the zero one row, the second row. The A values the same. So I just left the markings on A. You already told me the answer is there. So let's just change B. So B, sorry. B will have 1.5 volts. So what about B's upper transistor? Off. Good. So now where does Q connect? Down to ground, right? Good. Okay, so what's the answer? Yeah. Good. So now I'm going to skip a row of the truth table because I just want to change one bit. So I'm going to go down to the one one row. So now B is the same, right? B is still one. So I've left the B markings there. So now let's put A markings for one. So 1.5 volts. So top transistor? Off. Bottom left? On. Okay. Okay, so Q still actually now has two paths down to ground, right? So that'll still be ground. And then let's do that last row. Here again, from the bottom row, A is the same. It's still one. So I'll leave those markings and we'll put the B markings for zero back. So you already solved this, but let's just go through it again. The upper B transistor. On. And the bottom one. Off. Good. Okay, so we still have a path down to ground. Right? Let's steal zero. So what is that? Yeah. So not put together with O. Right? Or together and then invert the output of the O. That that equation. So that we call a NOR gate. Stands for not O. And it looks like this. So you can see it looks like an OR gate with an inverter bubble on the front. Yeah. Oh, it doesn't matter. It's just two ways to go down to ground. They're just electrically connected. Yeah, the thing you have to think about, the thing you have to worry about, rather, when you design gates is you want to make sure you never have a path from high voltage down to ground, at least for any long length of time. Because if you do that, current will flow very quickly in your chip will melt. So you need to make sure that you never set up your transistors in a way that it's possible for current to flow directly from high voltage to ground. Yeah. But in this case, having two paths to the same voltage, that's okay. It actually will just go down to ground faster. It has less resistance to ground. Oops. Okay, that's a NOR gate. One more. So let's do this a little more easily. So let's just say a equals zero. So I won't even tell you what b is yet. So let's just look what happens if a equals zero. So what's the top transistor going to do? That one's on. The other a transistor? Off. Do I need to look at b? I don't, right? Because I have a path already from q up to dDD. So any time a is zero, q is what? A one, right? Good. Now, what about b equals zero? The same, right? The circuit is symmetric. It has the same behavior for a and b. Let's just walk through it. So it will put zeroes and b, top transistor, on bottom one, off. There's a path, right? Okay. So also one zero gives us a one. So then we have one last case, which is a and b are both equal to one. So what about a, what about that top transistor? Off, bottom, on, and then b, also 1.5 volts, off, and on. Good. So we've got a connection down to ground now, right? What is this gate? An and, good. And it looks like that. And gate with a bubble on the front. So you do the end, and then you invert the output. I'm sorry. Combine it with a non-crease. Yes, you can combine it with a not gate to get an end gate. So you can take the nand and put a not on front if you want to build an and. In most of the systems, we'll design, actually, you'll see that usually you have more than one level of gate. And so you end up using pure nand or most of the time whenever you can. Because otherwise you're using more transistors than you need to. Yeah, you could, you can make an end gate by just adding an inverter on the front. Okay, so. So there are some rules. Same number. One side's parallel, at least for nand and nor. One side's parallel, the other serial. I'll explain duels. Maybe the end of this week or next week. But for now, it's enough to know the parallel versus serial construct. So. I want to switch over to the tool and then maybe you can help me out. Let's see. Yeah. Okay, you want us now or I can switch back. Good question, but let me come back to that one, actually. Yeah. I have to convince my laptop PowerPoint doesn't like you to look at other things. Okay, so now we're going to go down to the CMOS gate layout tool. And you'll see that I actually pre-wrote. We have to go away. So why don't we do the nand? Okay, so there's an end gate with two inputs. You can check it by saying, hey, I think this is an end gate with two inputs and whoops. And pushing check answer and it'll put it all green meaning it's correct. You can go click on these rows and it'll put the. Put the values. At each of the junctions. But let's extend this and make this three inputs. So actually here is a three input and an exercise. We can check answer. And so at least one of those is wrong. If I have three inputs, well, it's not even paying attention to C. So what do you suggest I do to make this a three input and end gate? Yeah, so add one p type and one n type controlled by C. So where should I put them? So appear somewhere. See this thing turned to s. I mean short. This is what you don't want to do. I didn't do it where I will said, yeah, this is not his fault. But I connected the top through C. And so now I actually created a path from high voltage down to ground. So in this case here where I've got one one zero and a b and c. Yeah, yeah, because I didn't protect the bottom to connect to ground. So now I have to do the other half of what Rahul was saying. And I will snip off this ground. Add another n type down here. Connect those up. Label that C. Back to the other side to ground. So hopefully you understand this side is in series. If you wanted three, you put three, if you want four, you put four. Four is about where it gets a little too slow. And so typically gates will scale to about four inputs. And then you'd want to use multiple gates. But you can you can generalize these if you want to. If you want to play with it, you can go to the tool and make sure you understand it. Build whatever you want. You can actually ask the question you ask there, Daniel also. Maybe what I'll do is just reload it. It's easier than trying to delete everything. But for example, if you put the. N type on top. Then you'll get these things L and H. Which if you look down on the legend here, you'll see stand for soft, soft zero and soft one. So if you think about the way these things work. Usually people ask this question. So it's good you asked it. But if you think about the way these things work, remember for example, the n type up there. The voltage has to exceed a threshold for it to turn on. Right. And so if a is at high voltage. Then it will turn on so long as the other side is not at high voltage. Right. Once it comes within the. Within the threshold of high voltage, it will actually turn itself off. And so the output there, the thing that comes out the other side. Is actually a little lower than the little lower than high voltage. I think I misquoted before the threshold is usually on about 20 to 30%. And so what comes out here is about 70 or 80%. And we call it a soft one. And that soft one will be then slower in pulling up the next gate up to high voltage. And if you keep building things this way, eventually they just won't work because they won't be able to exceed the threshold voltage. So. So because of the way MOSFETs work, typically we're not using this kind of approach often directly. Instead we build with NAND and NOR. This is how you would build NAND and NOR if you wanted to, but people rarely do this in practice for that reason. Yeah. Yes, the complimentary complimentary structures. So you've got at least one of each. So there's no gate that has fewer than two. The not gates are simplest. So this was actually a comment also along the lines of your question, Daniel, that if you swap them, you do get these soft zeros and soft ones coming out. They don't quite work properly. That answer your question. All right. So. What I want to do next is take a look at a function and think about what we can do to get a nice way to express the function. So let's see what kind of hard to understand that probably at this point. So let's start by doing something we know. So when we did the logical completeness proof, we went and we looked at each of the lines with a one and we wrote down a Boolean expression for each line. And then we ordered them together to get the function. So let's do that. So here's a row. How do I write a function that gives me that row? Yeah, a b complement c. Remember that we've got each of the variables. So this one is a one. So I'll have a zero give us b not and c will give us c. So that'll be a b prime c. So what about this row? A b c prime. Good. What about this row? A b c. Good. So if we take those three and we orm together, we get f, right? So turns out I could also write f is a b plus a c. So you can verify that if you want, the ones where a and b are on are these two down here, right at the bottom two. And of course, you have ones there and the ones are a and c are on are the bottom one and then the sixth one down from the top or the third from the bottom. And of course, those are both one also and together those two sets give me all three of the rows of one. So that's the same function. And if you remember distribution, right? Distributivity. Well, this by have a times b then I'll give me that term a times c that give me that term. So all three of those are the same. Which one's the best? I just made it up for now. I just said, hey, I just happen to know what this is. I'll show you way later. Good question though. Yeah. Okay. That's one way to count. Good answer. Okay. So you also like the third one. Sorry, but we didn't agree on a metric. If we don't agree how to measure things, then all answers are wrong. It's the same sort of game you can play with. You know, add the numbers between one and three or something. So until you talk about a metric, it doesn't really make sense to say what's best, right? And there are actually quite a few metrics people care about. And so in digital design, usually they care about the first three at least, right? What's the area? Because that'll be the cost of having the chip. And so how big is it? How fast does it go? If it's very slow, maybe it's not worth making. It's got to be competitive. Power energy consumption. If your battery on your cell phone is only going to last half an hour, you're probably pretty unhappy. So all three of these are important. Which one's the most important depends on the context. Depends what you're trying to do. And as an engineer, you're usually going to have to balance between them. Yeah. Not necessarily no. So in our class, we're only, we'll talk about it more in a few minutes. In our class, we're going to talk mostly about area and performance. And you can trade those off pretty well against each other. And the last one is complexity reliability. So I'll talk about all four of these a little bit. But we need to use heuristics. So why are we using heuristics? And what are heuristics anyway? So in practice, actually making a measurement, saying, well, look, let's just build all the designs. And then we'll go measure them. That's kind of expensive. So in particular, if you were a cell phone manufacturer and you want to create a new cell phone, and you need to do some chip fabrication, that process with all the engineering costs is about $50 to $100 million. If you're going to sell 5 million of those cell phones, yeah, big deal. That's okay. So we can always perform, yeah, we could cover that. If you're not going to sell a few million of those, you're not going to be able to afford it. Just building it, just the mask costs, the thing that allow you to fabricate the semiconductor chips will cost you a few million dollars these days on the high end processes. So instead, we want to make a guess before we go build something. So will you something called a heuristic, which allows us to estimate a measure? What makes a good heuristic? Well, you'd like it to be reasonably accurate, but maybe more importantly, you want to be monotonic relative to the real measurement. So if I get a bigger number out of the heuristic, I should get a bigger number out of the real measurement. And as long as it has that monotonicity property, probably reasonably good heuristic. But let's take a look at a couple of heuristics for our class. So here's one for area. So take your expression and count up the number of literals. Literals are variables or their complements. So count up the number of literals and then add the number of operations, not including the complemented literals. So just ends and ors or other operations would be fine too. So why does that work? Why is that a good heuristic? So if you think about what we just saw with gate design, every time you have an input to a gate, it's going to be two transistors, one in type one p type. So get kind of a transistor count operators and operators if you have an and gate feeding into an or gate, same thing that output to the input to transistors in the or gate. You basically transistor counting wires also takes space. So this is not the best heuristic in the world, but it's a pretty good one for just looking at it looking at expression and figuring out how big it should be. So let's go ahead and calculate area heuristic for those three forms of that. So what about the first one? How many literals do I have? So you have to count all of them. So this term alone counts for three. So just having a twice, those are going into different gates. So each of those will cause two transistors, two transistors, two transistors. So just literally count the number of letters. You get nine, right? How many operators? So here it's a little trickier. Don't worry about the number of inputs. So for example, this or is one three input or in the and for the for the min terms, those are one three input and each. So you have four, right? Three ends and one or. So total about 13. What about the second expression? How many literals? Or how many operators? Three. Two or is in one. I'm sorry, two ends and one or so total seven. And then the last one. Three literals. Two operators. Good. So five. So from area point of view, our heuristic tells us, okay, that last one is probably the best and few is transistors. Now, second metric you might care about is speed. So here's a way you can estimate speed. You look at here, we only have one output. But in a bigger system, you might have many outputs. You look the longest path in terms of how many gates from any input to any output. So you might count complemented literals if they're free. Sometimes they might not be free. So you kind of have to know what you're using the system in. Why does this work? Your gate takes time, right? For currents to flow across wires, they're not instantaneous. It takes time. So the time it takes one gate to change its output, we call a gate delay. It will change with a with a semiconductor process. It gets faster over time. But it'll always be finite. It'll always take some amount of time. So we'll call that time and gate delay. And if we count gate delays in our design, we can estimate the speed in which we could use that system. Let's do that again for our functions here. So in the first one, we have maybe these compliments, so that could be one and then going into the ends, and then that goes into the ores. So two or three. The operate in the area. Yeah, so. So basically an end consisting of any number of terms of any number of factors is one. Same thing for an or so the ores are a little trickier to figure out that any sequence of terms with pluses between them is one. So that would be a multi input or gate basically. Yeah, here we leave out the compliments. You'll see in about maybe three weeks that often these are free. So often if you have a you'll also have a prime available on a different wire. So that's why. I know it's not clear now why, but just don't count them because they're usually free in most digital systems. So here in the first one, we have three midterms each of those requires an and gate to calculate it and then we have one or to bring together all three. Yeah, so three ends and an or this one is two ends and one or this one is one or followed by one and. Alright, so let's go now count delay. So here we've got in the first line again two or three. We've got the ends. We have the or and then we might need to calculate complemented literal so let's just say two or three. Here we have just and followed by or there's no compliments so definitely to whether they're free or not and then the last one we have an or followed by an end so again definitely to no compliments either. So here these last two designs are the best for delay. Yeah, so we're just counting counting gates. So I mean it's I thought about drawing them for you, but but which will make it easier to just point at physical gates. But the B plus C for example is one or gate right that output of that or gate goes into an and gate the output of that and gate is F. We have two gate delays similarly for the for the bigger ones. Yeah. So so the simple heuristic is you simply count the number of gates along the longest path. And so you're just counting gates and you just say it's gate delays. Yeah. In real systems if you want more accurate estimates you know things with fan in or fan out above four will be slower. But we don't need to worry about that for a class. So the two end gates can be can execute in parallel. So it's the the longest path from any input to any output. But the one one path will go through one end gate from any of the other path will go through a different gate that both paths will only have two gates on them. So there's the second equation right so for many anything on this side basically it'll be two gates to get to F. Okay. So in this case we have a clear winner. Yes. Yes. So three three input and gates and one three input or gate for the first expression. For the gate delays that's the compliments would be the third one. And so if they're free it's two and if they're not free it's three. Yeah. But these these expressions don't have anything complemented so they're two regardless of whether or not the compliments are free. Okay. In this case we have a clear answer. The answers are not always that simple. If you want a simple expression where you have to you have to choose between speed and area. Just look in section 211 of the notes and there's an example there done out the same way where one is faster and one is smaller. So you have to pick. We'll see a lot more of that kind of trade off later in our class too and in practice this is the kind of thing people have to do all the time. So there's a start section I took from one of our former PhD students PhD thesis showing trade offs for computer processor architecture designs. So you can see the graphs and you can see the kind of things people do in the research. It's a start section right so don't feel obliged to read it but if you're interested in thinking about how you do this kind of stuff. There is a little bit in there on that. Okay. Another question? Yeah. Just slides back. Okay. So remember when we talked about the complimented literals I said you should count. I don't think compliments if they're not free. Right. So if they're not free have to use an inverter and inverters a gate. So that's a gate delay. So. God this one. Oh, this one's bigger. Okay. So they're the a b prime c. And then a b c prime. And a b c right. And this is f. So this is the first expression. So you can see now the inverters take a gate delay. Right. So if those are free. If the complimented inputs are free I don't have to pay for the inverter. So that would be two. If the complimented inputs are not free I have to invert the a the a and b inputs. And that'll take a gate delay. Yeah. No, because that's an assumption. So in this diagram it's not free. In the diagram I drew them explicitly. If they were free then I would simply connect c prime to here. So I mean I can change the diagram to explain it that diagram assumes they're not free. Yeah. So the question is can you break your complex circuit into pieces and analyze each of the pieces. Absolutely. Yeah. So as you'll see even in in a week or two we're going to start to build components. And so often people will design pieces. Back most designers are using a standard gate library. So they're not really going down to transistor level and optimizing a couple companies. Intel Samsung Apple actually do custom logic these days but almost no one else does. Yeah. And even beyond that when you get into 385 you'll be writing something secored like to design your hardware. So you'll say plus and that'll pop down and add her for you. In office hours if you want to. Okay. So our complexity. So I just wanted to talk briefly about these you'll notice the stars at the top. So on the scope of our class to talk about power consumption it's too too complicated to throw into 120. But if you're interested you know when current flows current flows when you switch your transistors on and off. Current has to flow to bring the voltage at the output down or up. And so that that consumes energy goes through their burns heat in the resistance. And so you can get the number of times that happens in a simulator and use that to estimate your power. So that's what a lot of the design tools do for you. In 385 you'll see that and you can play with it. Complexity the fourth measure I mentioned is kind of hard to measure no one really has a quantitative way to do that. So it's usually based on experience. It's based on people knowing how hard would it be to make this work. We just have a couple minutes left in practice is a lot of funny stuff in the industry so. For example a lot of the intel processors had what were called chicken switches so they implemented for example multi threading parallelism in their processors and then they released them but they were worried it would break so they didn't turn it on. So they just left them off and a year or two worth of processors they just had it turned off and everything was ready. It had all the logic circuits that had all the transistors ready to go just they were scared that it would break and then you know they would lose a lot of money by customers getting angry and so they turned it off. So there's a lot of that actually in the real industry and a lot of that is just based on whether people think it's going to work and whether they think it's going to be viable to actually develop it and test it and make sure it works in the hardware. So I'm sorry. Oh of course they tested it and they found that it wasn't reliable enough for them to turn it on in the product and they wanted to get the product out the door. Yeah so of course they tested it. Yeah they always test it don't worry. There's actually a lot more testing in hardware because bugs can be in the design but bugs can also be in the fabrication process. All right so let me stop there and we'll pick up on Wednesday. Thanks. You You You You You You You You You You You You You You You"
    },
    {
        "ECE120-2016-10-14-LEC-22-slides.mp4": " Okay, so let's get started. So today we're going to spend the whole day doing examples of finite state machines. So we'll do one quick one, which is a two-bit grade code counter. Just to familiarize you with this process, we talked about at the end of the day on Wednesday for designing finite state machines. Then we'll do a slightly more complicated one color sequence, or has some don't cares in it. So we'll look at that one. And then I think maybe about half or maybe even more, we'll talk about the finite state machine that you're going to be building in the lab. So you've already been kind of playing with that for a couple weeks, several weeks now, and you'll be building it next week and a half to two weeks. More examples of finite state machine, section three, three of the notes, as examples, probably we won't cover most of those. There's actually more examples than three, two also. So if you're looking for examples, you want to make sure you understand it. Look at those. Also under midterm three review materials, there's a whole bunch of old test questions for which I wrote answers. So I think it's kind of down, scroll down a little bit, and it says old EC 190 exam questions on finite state machines, mostly. So you can get lots of examples there with solutions. Of course, I recommend you solve them and then look at solutions instead of doing it the other way. All right. So another reminder, here's the midterm. You've seen this slide many times now. The review session will do on Monday and class, so come prepared with questions or topics anyway and questions. So just wanted to then remind you of other resources. So there's still online tools for this player of the class. So you can practice your skills, watch the review video, or also Professor Harmiyo's. Attend any of the three lecture times, assuming the fire marshal doesn't get mad. Go to office hours, and there's this 8-A-CAPA-New Review session, which is Saturday 2-4 PM and 10-13 in this building. Same caveat as yesterday. So I will go over that. Same as last time too. All right. So this was the sixth step process that we talked about using for designing finite state machines. So we start out by developing an abstract model, spec the I.O. input and output, but complete the specification since we're building with digital systems, any input combination, any state will go to a next state. There will always be outputs. There's never any blanks or anything like that. Everything's built out of bits and boring expressions. Once we've finished completing the representation, making whatever design decisions we need, we'll pick a state representation. I gave you some ideas of how to do that, and now you'll see some examples. And then we'll calculate logic expressions and then implement with flip-flops and gates. So those were the six steps. So let's go ahead and use that approach to design a fairly simple counter, a two-bit grade code counter using this methodology. So what's our abstract model? Well, it's just a counter that goes through four states. So start in one state, go to the next state, go to the next state, go to the next state, and it's a counter. So go back. So that's good enough for an abstract model. We've got four states. The inputs then, well, it's a counter. There are no inputs. So we're done. The outputs, well, we said it's a grade code counter. So let's go through a little grade codes. We'll start at zero, zero, then zero, one, and one, then one, zero, then we'll start over. So two big grade code counter. Completing the specification, well, there's no inputs. So every state here has one outgoing arc labeled with nothing because there are no inputs. And the specs actually are already complete. So there's nothing to do, no design decisions to make or anything like that. We know the outputs. I didn't write them in here yet, but basically this is count A, count B, count C, count B. So next step then is, well, what do we want for a representation? So anytime our output bits are unique, that is, every state has a unique pattern of output bits, one choice is, well, let's just use the outputs as the state ID. Now, sometimes that's maybe not the right thing to do. If you have 500 outputs, but you only have 10 states, well, you only need a few flip-flops, right? So to say, oh, I'm going to have 500. That's kind of silly. But usually it's not going to give you such a bad answer. In this case, it's actually optimal, right? We've got four states. We need two flip-flops for the state, and we've got two outputs. So we can use the same two bits that we have for output as we use for our internal state. What that implies is we have no output logic, right? So for each of these states, remember the states on the left, the outputs are on the right. So you can see, they're always the same by design, by choice. And so the outputs are simply S1 and S0. So that's why this is a useful approach. When you need to generate output bits, you do it without output logic. Now we have to worry about as the next state logic. So from this design, this is a complete state diagram, complete state transition diagram. So we can just go ahead and write a truth table from this. So let's write our truth table. So from 00, where do we go? 0,1. And then 0,1, we go 11. And then from 10, where do we go? 0,0,0. Good. And 11 to 10. Good. So now we have a truth table. And you can see, sorry, I put this one up. You can just basically read these off. I'm not going to bother with K-Maps for this example. So S1 plus is, here's a 1, and here's a 1. You can see it matches S0. So it's just S0, and S0 plus is what? Not S1. Good. Okay. So those are our next state equations, right? They tell us the state of the system in the next clock cycle. Remember, that's what the plus means, right? So discrete time, next clock cycle, if the system state is currently these values in the next clock cycle, we'll have these values, right? So we can design it by just implementing the next state logic, which is just wires, right? So S1 plus is S0. Here's S1 on top. So the d input comes from here, which is the S0 output. So next state will be S0 for S1. And the next state for S0 is S1 prime. So here's S1 prime coming out, going into the d input of S0. So just hook two flip flops together with a couple wires, and you have your two big breakthrough counter. So that was a fairly simple, easy example just to get us started. So now I want to do another example, same process. So I put a review slide in here, but I mean, I saw it a couple minutes ago, so it won't spend much time on it. So what's the color sequence? So imagine that you have this LED, excuse me. Sorry, it will be one of eight colors. So you get a three bit input, red, green, and blue. And based on your three bit input to your LED, it produces one of these eight colors over here. Okay? And this is actually what old computers used to use about 25 or 30 years ago for their color displays, was eight different colors. As a long term ago, before you were born. So let's build it, now you can get an LED that does that instead of a computer. Let's build a color sequence here that cycles through a set of these colors. So imagine we've got this light and our FSM will basically drive these output bits, RGMB, and produce the colors on the LED. So what's our abstract model? Well, again, it's a counter that's going to go through five colors, in this case. So like this, say that we start in red, I get to pick the colors. So we go to green, we go to cyan, we go to white, we go to blue, and then we're done. So that's our color sequence. So we want to design a finite state machine that just goes over and over through these five colors. So you can imagine you put it out in front of the building, and wait, someone beat us. Okay, so they did something like that, right? You can do this in the lab if you want. You can put it inside that thing. All right, so what are the inputs? Well, it's a counter, right? So we're staying with simple examples. So outputs, we're just going to use the RGB color, right? So we're actually told what we need to do to produce these colors. So the outputs we need, say for the blue state will be 001. So we'll just inherit those bits for output. So let's add those. So red was red, green, blue, 100, good, greens in the middle, right? 010 cyan is green and blue, so 011. A white is all three, so 111, and blue, red, green, blue, 001. Okay, all right. So now we have our outputs labeled on our states. So what's next? There's no inputs, right? So when we say, well, let's complete our specification, there's nothing to add. Every state has already all of the arcs leaving that state. And there's no decisions to make or anything. They've already been made, rather. So our spec is complete. Now we can pick a state representation. What do you think we should use? Maybe the same thing, right? We've got unique output patterns here. You know, if I picked green down here, right? If it went twice through green, then we couldn't make this choice. Because then our outputs are not unique. And of course, the next state from green would have to be one next state. And so if we had two similar colors or identical colors, rather, on our loop, we could still build that finite state machine, but we couldn't make the choice of having the outputs also be our state IDs. Okay? But I didn't do that. So let's go ahead and make that choice. So the outputs are unique. So we'll use them for our state IDs. So we'll add them in. So red, we'll add that in green, add that in cyan, white, and blue. Okay? So now this isn't fully specified, finite state machine, state transition diagram. Right? It's got all the bits on it. And we can map it again to a truth table. Question? Yeah. So remember in the machines we're going to look at, it's always state bits followed by outputs. And I probably should have put it somewhere near this diagram, but the outputs in this case are red, green, and blue. And the state bits are always going to be largest bit. So it'd be S2S1S0. Yeah, but that's a good question. Yeah, there's no implicit order necessarily for the outputs. Right? So make sure that you label your diagram as someone. I know I left it out here. It was kind of in the previous one. Yes? You'd have to have two states with separate state IDs. So the question is, what if I did make, let's say I change this to green. I can no longer, the output bits have to be 0, 1, 0 to drive our RGB for both of those green states. So I can't have 0, 1, 0 for two different states. I would have to actually pick a different state ID for one of those two green states. All right. So it's only the fact that these are unique that allows us to do this. All right, so time to fill in our truth table or next state table in this case. So let's see, let's do it the easy way this time. So from 1, 0, 0, we're going to go to 0, 1, 0, right? So 1, 0, 0, go to 0, 1, 0. Where do I go from 0, 1, 0? 0, 1, 1. So fill that in up here. And then where do I go? 1, 1, 1. So where was 0, 1, 1 here, right? Okay. Good. And from 1, 1, 1, 0, 1, down to here. Okay. And then from 0, 0, 1, I go to 1, 0, 0. What about 0, 0, 0? We don't care. Good. I don't care either. What about 1, 0, 1? Okay. 1, 1, 0. I care about that. No, I'm kidding. All right. So we don't care. Good. Okay. So we'll fill those in. And now we can copy to K maps. Right? So we'll start with S0. So here's a K map for us. So the same order is always. So I put S1 S0 on the upper one so that I can copy horizontally. But remember, grade code order in the, I'm sorry, grade code order in the K map, binary order in the truth table. So we're going to go first, second, hop over here for third and then go back for the fourth. So X0, 1, 1, X0, up over 1, put the other one there. And then 0, X, X1. So 0, X, hop over X, and put the one there. What loops? S2 over this one, right? Okay. Good. What is that? S1? Okay. Good. So S0 plus is just S1. That's easy enough. I like that. All right. Let's go on to S1. So fill in our K map again. So read them off for me. X0, hop over 1, 1. Okay. In the next four, 1, X, X0. Okay. Good. Loops. Is there a square? Oh, there is. Yeah. Oh, that's better than my answer. Sort of. All right. That's not my answer. You get another answer? Please show you my answer. I like that one. You're right. The square is sort of better than that one. But I can add this one. And then I get this thing. You see what the square is better. But that's an X0. So this square might be better. Yeah. This square might be better. Yeah. This square could be better. All right. So let's do this. So we'll have this one for the S1 plus, S2S, X or S1. What about S2 plus? So do the same old thing. Copy K map. So read them off. X1, 0, X1, 0. Yeah. Sorry. Don't switch them because I put them in the hopping order here. And then 1. Okay. In the next row, 0, X, X, 0. Good. Okay. What do we have there? Just the two on top. Right. I actually, yeah, I think sorry. I wanted to go back and look at what were unique. So do keep in mind if we're making choices. Right. I kind of made a weird choice last time with the X or. But I think actually that one might be unique if you want the way you're going. But I'd have to look at it again to verify that. Okay. So here we have, sorry, I should have let you read this one off. It's S2 prime S0. Right. So S2 prime on top. And then S0 to isolate these two from the outer ones. I'm going to rewrite that as a norgate because I'm going to map this into CMOS. So this is one norgate where I take S2 or it with S0, S0 prime. And then take the complement of that. So that's a norgate. Right. So if I draw this thing, I have one norgate for S2. Remember it took S2 here. And S0 prime down here and it north those together. And that's S2 plus S1 plus was S2 X or with this one here, which is S1. And then S0 plus was just S1. So it comes down this way. Okay. So that's our implementation. S3 plus S2 gates. I'll let you get some. So not one that I know off the top of my head because I think I have extremely limited Arduino programming experience. In general, you can as. Really put this. So with hardware software, generally speaking most of the programming languages are what we call Turing Complete, which means that you can express any computation. So if you think back to the first day of class, we said that computers are all the same. What that really means is that a computer that's able to. If we can map it systematically from one computer to another in terms of its capabilities, which is generally true of all the computers we build, but not necessarily all of the programming languages, we say that computer is Turing Complete. Most programming languages are Turing Complete. So you can define your language any way you want and then figure out how to map it. Now hardware is actually a little more difficult than that because you have lots of space and speed constraints. So it's very easy to write a language that is hard to map the hardware. And so for example, most high level languages, it's very difficult to build hardware for most. So I think the Arduino language is more constrained, but I couldn't tell you the exact mapping off the top of my head. Okay, so. So there's an implementation. So excited. You probably want to go to the lab, get your prototype out. Takes a while. Yeah, good. You know what to do, right? So I don't care. Don't care. It's good answer. What did happen to those don't care states? We love those don't care states mine around and we didn't check what happened. So let's take a look. You can just plug into equations. If they find that easier, it's fine. It's the same. I'm going to plop up our K maps. So we've got the K map for S2 plus what do those X's become? All zeros, right? Because the only loop is this one appear the X's are outside all the loops that means zero zero good. So the X's become zeros for us to so let me write that as this. So we've got these three unknown states. So one of them is zero zero zero. So we're going to go to zero something something. We've got one zero one that's going to go to zero something something we have one one zero that's going to go to zero something something also. So we figure that one out what about S one plus where those X is going to go. This one is what this is zero. What's this one one and what's this one zero good. So we've got one of them going to one the one zero one state goes to a one. So now we can plop up these three again. We got zero zero zero goes to zero zero something one zero one goes to zero one something and one one zero goes to zero zero something. So we take a look at S zero. Where are those X's going? But this one this one and this one good. So we again have one X different X this time going to a going to a one. So we're going to go into our final next state equation we got zero zero zero goes to zero zero zero one zero one zero and one one zero goes to zero zero one. So what comes after zero zero zero. And what comes after zero zero zero. So you know I can't I shouldn't say you write something mean and you say but if you're not that thing and read the other side and then you write the same thing on the other side and you see how many times your friends with it over. Okay so let's add those states. So there's black it has a self loop right there's violet it goes to green there's yellow it goes to blue. So if we're going to add a little bit of violet and yellow maybe we don't care so much we turn it on if the flip flops start in that state in one cycle it's just going to fall into our state and it's just the light right so they're okay fine. But if it starts in black it's going to stay in black right if we turn it on and the light is black lights going to stay black and it's not going to it's not ever going to change because of our primary state machine design. So we're going to have to add some way to initialize right we can pick some specific hardwired initial state picking zero maybe is not the best choice here because that's black stable. There's an easier way to design that fsm. So we can use muxes right so we can say okay let me put a mux in front of every flip flop and then I can put an initialization bit in and then I can choose using one input to control all three muxes do I want to force my finite state machine to to display a specific color in any cycle. And so it can always put it whenever state I want using those muxes or I could just pick one signal and force the system into into the loop so for example I could add a mandate to to the s zero flip flop input right so that it was s one prime and it prime. So this would be an active low and it signal and that would let's see when that's zero a mandate would force that to one right so that would force s zero to one. Which I think would push us back into the loop. So we go here here here or there and all four of those cyan white violent blue all of those fall into the loop right so for that initialization gate one gate then we could force the system into the states that eventually into the states that are valid. So the only thing we could do is just go back and say well now let's go back to our came apps and let's pick specific specific ways to fix this problem right so go to zero zero zero and change one of them to something that isn't zero and then solve again. That may take a couple of iterations because you're going to change the loops and you may just create new problems with new loops right. And also just choose specific next states for all of them and so they will let me just design the complete system on both of those approaches are going to add logic right so regardless of whether you just try to think it through well could I limited to one gate somehow or could I just go back to the to the drawing board with my came apps and play around with it till I get it right doesn't really matter. At some point you have to go back and add some way to push it into a valid state right so just be careful with the don't cares because if you end up in a state that goes in a loop outside of the loop you want you may never get back into the loop you want depending on the design. Any questions on this one pretty straightforward and understandable. I expect to go out I go build this in the lab. Yeah so so in this case I picked a specific solution right so knowing the design I looked at the design I said well if I can push it into one of the states that ends in s zero equals one. Then from those first states let's see cyan white and blue are ready in blue by let we know once I once I turn initialization off will go to green and so it'll also be in the loop so if I can force s zero to be a one then I can push it into the states that I know work. So what I did is I said well how do I force s zero to be a one originally I had s zero plus equals s one right so now this is a net low active low so if you put a one here then you get s one prime prime so it's still the same thing I didn't change the actual functionality of the finite state machine by adding this mandate because I switched s one to s one prime so now that flows through these the same answer before when it is one. When it is zero this and in here is zero complemented I get a one s zero plus is always one. So it's an active low initialization signal so this one is is custom tailored to our design which enables me to use just one extra gate. Anything else where we are in time okay. So we are going to have input produced by coin so you put coins into the into the physical machine which will be about the a bag on the table then it will produce inputs for your finite state machine the outputs then specify well should the machine accept your coin or send it back to you and then also should a product we released. We couldn't get the products into the lab so you can't buy anything but there is a signal that you have to generate so the design is pretty simple right because we want to you're going to be building this out of TTL chips and so we didn't want you using 20 or 30 or 100 chips we wanted to eliminate to a few chips so that's why it's fairly simple design. What's the point of this so Doug Jones and I designed the class so Doug's view was that he wanted everyone here to understand the connection between the real world of building stuff with wires and chips and the paper world of lines and boxes right so he wanted to make sure all of you understood that connection and the way to do that is you know get your hands on to something real and build it to represent or rather build the thing that you've represented on paper as a finite state machine. My point of view is I want to make sure that you understand that the knowledge you're getting in this class actually will enable you to go out and do real world stuff like sensors and actuators right so you know finite state machine you can go build a bending machine like a real one for you. Or you can build a robot you can go lots of stuff with sensors and actuators. So Doug Jones designed the original finite state machine the derivation and this in move the slide layer the derivation in these slides is a little different from the ones in section 34 of the notes so read read both and if you understand one better than the other that's okay. So we'll end up with the same design so that's what you have to implement in the next couple of weeks. Chris Schmitt who you may know from 110 or something else he did the original prototype hardware so he did that for us who worked for a first few semesters. And Bob can do tenko who's also taught this class many times help the design as it scales so he did read it some of the design as we had more and more students you know we had fewer people to help with issues in the lab so and professor harm you and Casey Smith who's the instructional. Instructional person in ECE did the current design to eliminate basically all of the issues actually one remaining issue which is these are optical sensors and I'll try to remind you later. So please keep the shades down because otherwise the people with benches near the window will get light coming into the optical sensors from the sunshine and that can make noise right and so it might not work for them because of the sunshine so just be careful working near the window and try to keep the grinds down but that's the only remaining issue that we know about. So here's the physical system so you can see there's the there's the coin slope so you put the coin in and it rolls down and there's a gate here that your finite state machine controls so it can either drop down and then the coin comes down here and is accepted or can stay up and then the coin rolls through and falls out the other side that means the coin was rejected. So those are your two your two choices here's the interface ribbon cable to your proto board the optical sensors are here but let me zoom zoom in in a second so these will produce your clock signal and your T input which is which type of coin. This gate is controlled by your output so let's zoom in a little bit so you've got two optical sensors one is for the clock which is here and one is for the type of coin rolling in a put two types of coins so one is a dime for those of you might not be familiar with US currency yet the dime is a very small one it's worth 10 cents and a quarter is very big that's the other coin so when the dime rolls through it will hit the clock but it will not hit this T the optical sensors generate a one. So when the when the dime rolls through it will generate a clock high and then low so will the quarter but the T signal will only be generated by the quarter so that in order to know whether you have a dime or quarter you look at the T signal when the when the clock edge goes up so I'll show you that in a second. We've also got LEDs on there so when clock T and your acceptance putter high for output or high LEDs will will light up on this on this board here and this is this is the place that the coin rolls by. So here's a dime in action so you can see the dime rolling there so dime rolling into the machine you can see that it's hitting the clock signal there so the clock is high and that LED is lit up on the other hand T is low the T sensors up here remember so it's still it's still actively stable connected to the other side and here is the dime's timing so what I want you to notice here is the T signal just stay is low right the dime doesn't hit it at all the dime's too small to block that. So time T stays low the clock signal in the ahead of time goes up for a little bit and then once the dime passes this optical sensor it drops back down. So we'll talk a little more about the clock in a couple of slides. Okay so here's a quarter so a quarter is going by now and you can see that clock is high again but in this case T is also high because the quarter is blocking this upper optical sensor so down here is a quarter's timing so you can see that the T signal goes up first right so T is going to be stable on the rising edge of your clock which is important because of course you're going to use positive energy to flip flops and so you will sample T on the rising edge of the clock you can see here for the quarter. It's a one and over here for the dime is zero right so that's the T input to your to your finite state. All right so the clock is a little weird right so the clock is not a square wave it's generated by an optical sensor only when the coin rolls in front of it so how big is that pulse will depends if you shoot the coin in it will be narrower right if you let it roll slowly it'll be wider. Humans can't make the coins go fast enough to matter right so don't worry about that. But it's not periodic right the cycles in our clock are defined by when you put the coins in right they're not they're not periodic it's not a square wave yeah. So asynchronous is always with respect to something right so this is a clock signal and your finite state machine is synchronous with respect to this clock signal it's just your clock signals kind of strange it's and most clock signals the periodic their square waves even right. This one is api orotic and you get a cycle every time you put a coin in yeah. And it will change synchronously with respect to your coin insertion so coin insertion will give a rising edge and your finite state machine will take one transition. So so it's exactly the same from the point of view of everything we've talked about with clock synchronous sequential circuits nothing to worry about that good question. All right so yeah I was just kind of going through this it's sufficient for our needs right you work with these positive edge trigonicity flip clops and so because the way their optical sensors are positioned T is stable it'll be zero for dime one for quarter when the clock edge rises. So you get the right input. I should mention by the way I meant to say it but you know all the work that Professor Harmio and Casey did also means you can more or less get this entire thing working at home and then bring it in and just tested in the lab. We do recommend that you test it in the lab there shouldn't be any issues. So if you if you have a working at home it should work in the lab as well unless you're sitting in sunshine so be careful about that. All right so so let's talk then about the finite state machine. So what's a sequence recognize we actually built one already or designed one already was even just Wednesday it was Monday. We developed a zero one sequence recognize it looks for a pattern of bits in a serial input right so remember we talked about machine models it was Wednesday and we looked for a zero and a one. We can think of the of the bending machine that way as well. So for the lab we can treat the sequence of coins as a serial input right we get zero for dime one for quarter so zeros and ones come in. And then the sequences that we want are zero one and one zero because in the in the machine we're looking for totals of 35 cents. So part of making it simple was to use this combination of coins only two types of coins total of 35 cents you always have to have one diamond one quarter. So you can put the quarter in first you can put the diamond first but you're going to get either a zero one or one zero. So if t is our serial input we have to produce a product release output p equals one whenever we see zero one or one zero. So it's not quite the same but if we use this process we'll get the right answer because if you. Maybe it is. Yeah I take it back it is correct. If you put a bunch of quarters in right then after the first quarter it'll reject those and then you eventually have to put a diamond in in order to get the product right because it has to be 35 cents. So at the end of a bunch of quarters you put a dime then you've got a bunch of ones and a zero so that one zero at the end will be recognized and produce a product. Alright so we're going to use this following process to to build a sequence recognizer so we're going to start from a start state and we're going to then build out the sequence for each of the sequences we care about by just adding one state per bit. Then we're going to complete it by saying well for each of the states what happened what do we want to happen if the other type of coin is put in and for the end states will what if we put any coin after the after the end state. And then finally we'll take a look and try to get rid of states try to make it a little narrower and then after we've designed that abstract model will come back and assign state IDs that will complete the lab or rather that'll get the lab to the point that you have to do the rest of the design as you know. So I needed I wanted to make this a little clearer in the slide so what I'm going to do is I'm going to use zero. I'm sorry a black arc for the dime and a red arc for the quarter so that's the T input and then for the outputs which will mark states with slash AP a is accept so if you have an output of one that means the last coin that came in is accepted by the machine it's kept by the machine. And if you have a zero that means the coin gets sent back and the machine doesn't hold it anymore. P releases the product and so if you send an output of P that means you've collected 35 cents and you should give them whatever you're selling. I know what you've been by for 35 cents. So in the beginning is start state so then we're going to we're going to go through the dime the dime sequence first so if we send a dime and then a quarter well in our state diagram we're going to add a state for that dime so this black arc again means I put a dime in and then I'll be in this dime state so this one I left the outputs unknown this one I need to accept that dime but I'm not ready to output a product of only taking 10 cents. So then when the quarter comes in will that'll be a red arc so this means quarter and that'll go to a state I'll call paid one and there I need to accept the quarter and then also output a product because I've gotten the dime and the quarter. So the other way this can happen is I put a quarter followed by a dime so I'm also going to add states for that sequence so those will be going down. So here's a here's a quarter state so first I put the quarter in it's a one zero sequence so here's the quarter and again accept yes and then put a product out no so the next state then I'm going to call paid to accept the coin and will put a product out because I've gotten first a quarter then a dime 35 cents. Remember this is noted as AP right so a is accept so you want to accept the dime but not put out a product yeah so all of these are AP so these two you accept the coin but you don't have enough money yet the paid one and paid to means they paid fully so you still to accept the coin in order to have the money but then you also give them a give them the product. So that's a good question so this is you know eventually we will merge those because we don't care we don't need them to be separated so you've already noticed that and you know once you get experience with this process you could do that too. The basic process is for every sequence you just write down a spring of states and then you worry about merging the method right now we're just following this fairly simple process of every sequence I want to recognize make a separate state for it that doesn't always work because you may have sequences that share some sequence and then of course they have to share states from the start state. So for example if we said zero zero one and zero zero zero one those two start with zero zero right so we can't split on on one common input we'd have to go to the same state for the first zero in the second zero. Okay so so here we are so what's next so now we need to complete our specification our transitions so what happens when someone puts into dimes what should we do zero zero right so reject it and don't put out a product obviously you didn't get any more money for rejecting the coin okay so what is it where did we go so we've had one dime we should accept the first time right okay so we've got the first time and then from dime right now we have a quarter arc so now we need a black. So now we need a black arc out of dime and it should go to a new state that rejects that has AP equals zero zero so like that right so reject d for dime yeah rejected all right so what about three dimes about four dimes five dimes keep looping right we just keep sending the dime back the user keeps putting it and we keep sending it back the user enjoys that they can do it all day okay good design all right so eventually so why don't we just finish this one up what happens if we're sitting in that reject the state and someone puts a quarter in what should we do go up to paid right so that kind of finishes the sequence so let's do that okay good so we've now we've now got the way to look at this is every state should have a red arc in a black are coming out of it right because every state you could put a dime or a quarter next so this one's done this one's done Let's see those are the only two that are done right okay so let's do the same thing next for quarters right so if we put two quarters and want to reject the second one right so I've reject q I don't know how to pronounce that But again, it's rejects the coin and we don't have enough money, so we're not going to give them a product. And then if we give them some more quarters, again, keep sending them back. And what happens when we get a dime? Go over to page two. The finishes are quarter than dime sequence. Okay, good. So let's see. So these three are now done. So now we need to finish up these other four. This one doesn't have any arcs going out. So what's left to specify? So paid. Okay, so how about that one, right? So I'm from paid. I shouldn't have told you whether. If I put in a dime from paid, I'm sort of just starting over, right? I've already just given out a product and just got a new dime. That's now 10 cents. I'm storing. So just go to the dime state. So draw a black arc over there. What if I put a quarter in paid? Go to quarter. Good. Okay. So what about. Let's see. What about down here? Where should I go for a dime? Time. Okay. What about quarter? Quarter. Good. I think we're done now actually because I realize these also were finished already. So that's it, huh? So there. Okay. Yeah. There's our complete step two. All of the states have two arcs coming out of them. So we can take a look and merge things. It suffices when you want to merge to find a couple of states with identical outputs and identical next states. Sometimes you can merge more, but it's harder to verify. So. So let's take a look. What do you think I can merge? Okay. You guys are too fast for me. Can I. But dime and quarter have the same outputs, right? It only matters next state. Outputs and next state. So they have the same outputs. But the next states go different places, right? So they can't merge those. Let's see similarly. Let's see. Something has the same outputs. That's okay. Oh, paid and start of the same. Anyway, all right. Paid one and paid to good. So there's paid one and paid two together. What about merging and start? Because you can see now they have the same. This one's unknown. Paid goes here and here, but start also goes to the same places. Can I merge those? You don't want me to. Okay. So I'm going to merge them anyway. The issue is when you turn it on, if you force it into this start state, then P equals one, you might think, well, so when I turn it on, I get a free candy bar. That's, you know, that's something you should know about. You should try that. So that never works. But in our design, it made it a little simpler to do that. So we're going to just merge, start and paid together. It does have this strange side of that. But it made the lab machine a little easier. So for an educational thing, we just decided to go ahead and do that. So there's the five state abstract model. So now we need to assign states. So what we're going to do is instead of the output approach, which actually you can see doesn't work here, right? Because we have a two reject states that are different. And we've got our two diamond quarter states that are also different with the same outputs. So clearly, we can't just label things with outputs. Aside from the fact we've only had two outputs. So we have five states. So let's instead use human information. So what I want you to think about, you've got the sequence of coins. And let's call the last coin we put in T zero. So it's T is either a zero for a dime or one for quarter. And T minus one is the one before that. T minus two is the one before that and so forth. So I wanted to define the state bits as follows. So S two is just T zero, whatever I put in last. S one is going to be a one if out of the out of the coins I put in before the last coin and since the last time I paid, I released a product rather. There is at least one quarter. And similarly, I should say dimes, sorry about that. If one or more dimes are inserted before the last coin. And then after the last product release, then I'm going to have S zero equal to one. So this will record earlier quarters. This will record earlier dimes and S two will record the last coin. So let's fill this stuff out. So for a dime, if I'm in the dime state, that means since the last time I sold something, I've gotten exactly one dime. So what was the last coin I got? A dime. A dime, right? Zero. Good. What did I receive any quarters? No. So a quarters. What about dimes other than the last dime? There's only one, right? So the dimes you need. So the dime state needs to be zero, zero, zero. So here's a little state table or state ID table over here. So dime will be zero, zero, zero. What about quarter? What's the last? So if I'm in the quarter state, that means what have I received? One quarter, anything else? I can't have received anything else. So what's the last coin I received? Quarter. So what about any extra quarters? No. So zero. What about dimes? Okay. So one zero, zero. Fill that in over there. So now we have two state numbers. So this is, I mean, this will find strategy, but if we end up with the same state IDs, we're going to have to change something. Right? We can't have the same state IDs. But let's see what we get. So for reject dime, what does that mean? We've seen at least two dimes, right? To be in reject dime. And we haven't seen any quarters. Because as soon as we say a quarter, we'll, we'll go, let them get a product. So we've got two or more dimes. So what's the last coin we've seen? Zero, right? A dime. What about, have we seen any quarters? No. So this one should be zero. And if we seen extra dimes. Yes. Okay. So we got zero, zero, one for reject you. So those are still unique. So that's good. What about reject q? Last one's a quarter, right? And what about the next bit? Extra quarters, right? And what about the next bit? Zero. Good. No dimes at all. Right. If we're going to reject q. All right. So one one zero is our state. State ID for reject q. Now pay is a little trick here. Right? So that's the last thing since we emergency states. Now, which, what's the last coin? Let's just pick one. Let's say it's a quarter. So what's the last coin in that case? What's the quarter we just made about assumption? So what about, what about s one? Extra quarters zero. Right. We don't have extra quarters. Oh, I'm sorry. Zero. Yeah, yeah, zero. What about, what about dimes? One. We might have even extra dimes. Right. It might be they put a dime in six times and then put a quarter in. But that's okay. That's the means the same thing there. So we could use one zero one for paid. But what if we did the other assumption? What if we had a last dime? Then what's s one? So s one is extra quarters, right? So had at least one quarter. And what about s zero? Zero. So zero one zero could also be. Okay, that's okay. And we can have two bit patterns if we want to. Turns out it's it's convenience in this case to use both bit patterns. It doesn't matter. It is two states in the finance state machine. So in our abstract model, we were able to reduce it to one. But we've got to use three bits. So we've got eight possible bit patterns, eight possible states. There's not really any value other than simplifying logic to making those kind of things don't care. Right. So if it simplifies the logic to make both of these states mean paid, that's equally useful. So in the lab design, both of these are going to be paid states. So I ended a little early. So the rest of the design is up to you. So you remember, I'm sure having to go through and actually draw came apps and solve this. And then you'll be building it. I think there's a spread out due date from like the 25th through the 28th or something. So a couple of weeks. So do bring enjoy your weekend and do bring do bring questions on Monday. So we can have a fun review session. Thank you. Yeah, this is for lab nine. Yes. It's really all the labs. And the sense you'll be doing metrographic stuff in eight. Thank you. you you you you you you you you you you you you you you"
    },
    {
        "ECE120-2016-11-02-LEC-29-slides.mp4": " handout. Is there anyone sitting that doesn't have a handout already? He can even in the middle. So let me try to pass a few around. And also come grab some candy if you'd like. So these are two 25 and back. Let's see. You didn't know. Okay. That's, yeah, I want to be each one on the top one on the bottom. All right. So let's go ahead and get started. Actually, yeah, let me go through this. So we'll talk mostly about LC3, ISA today. And then we might spend some time doing an example, otherwise we'll work through the example on Friday, our example is counting to 10. I'll show you in a second where all the code are just put up some more code for the next week or two. I may add some examples to that too as we go. So the two handouts, one is the LC, LC3 reference sheet. That's what will be attached to your midterm three handier final. And the other is the counting example code that will work through together in class. Let's see if, let me switch over here. So now you can see that. All right. So if you go to this links page and you go to the bottom, I added this LC3 code examples. So somewhere in PDF, if you want to play with the code, you can download it from the binary version, meaning LC3 binary, that you can then compile with a tool. There's also assembly versions. We're not going to talk about subroutines in our class, but I just put the subroutine version up there if you're interested. There are also PDF versions. So you can just look at the code if you'd like to. So you can click on any of those. Let me go back to this mode. Okay. So those are all on the web page now. This one again. So I just keep reminding you to the deadline comes next Friday. All right. So the LC3, as we've talked about a little bit last time, LC3 has three different kinds of of op codes. So there are operations that use the ALU. Are there data movement where we move bits to and from, well, between registers and memory, and then there's control flow where we'll conditionally change the program counter. So control flow, if you remember, when we talked a little bit about C, we said, well, you can break things down in sequences. That's what we get normally. Right. We add one to the PC and in fetch, and then we just walk through memory and execute, execute, execute. But if we want to do something like a condition or a loop that we do in C, well, we need some way to change the PC, right? It can't all be one line straight line of code through the memory. So that's what those will be used for. So let's see on Monday, we talked a little bit about the operations. You reminded you that, well, the ALU and the LC3 data path only does these three things. Add and did not on 16 bits each. Both of the, all three of them rather have a source register and a destination register. And then add and add have a second input operand. And we said, well, there's two choices. We can either have another register, which is what you'd seen in detail in some of the earlier examples. Or we can have an immediate number. And so we looked at how that got encoded. There's the op code, which is either one for add or five for and. There's the destination register. These three bits from zero to seven. And then source register one. And then if mode bit here, I are five is equal to zero. Then that's the second register operand. So there are these next two bits, I are four and three. Also have to be zero. And then the last three bits of the instruction specify the second register. And so if you have this mode with this bit zero, I are five equal to zero. Then it whether it's an add or an and it takes source register one reads those 16 bits. Source register two reads those 16 bits. Does the operation through the ALU and then writes that result back into the destination register. Yes. On the other hand, if the mode bit is a one, then the second operand is an immediate value, which means that it's a number stored in the instruction. And so that number, since we only have five that left, five that's left, is a five that two's complement number that gets sign extended out to be a 16 bit value. It's when I say it's two's complement that means before you can put it into the ALU, you need 16 bits. So we're going to sign extended to 16 bits. All right. And then we talked a little bit about what good are these instructions. So he said, well, if you want to add small numbers, or you often do that when you're running a loop, right, you're adding one or subtracting one, you can add other small numbers too, but the range is pretty limited. If you want to add a bigger number or subtract a bigger number, then you need to use a two register inputs for your add or your end. You can also mask out low and high bits of a particular register. So you can say, okay, just give me the low bit, just give me the two low bits. And then we've got set the low bit to zero, set the two low bits to zero, or you can put zero in a register. So this one's kind of the most useful thing for AND is just setting a register to zero, because we're often needed zero in a register. And then I think this was the last one we looked at on Monday. So this is the not encoding, not as up code nine, destination register source register, since not does not have a second input operand, we just set all the rest of the bits to one. So let's take a look at the data path now and see how we set up the data path to execute these these operate instructions. So over here is source register one. So there is a little logic that's not shown in this diagram. It's in the notes, but basically those three bits out of the instruction are used most of the time to set the source register, which then comes out of this port. So whatever we, whatever three bit register name we give the register file, it delivers that register to this output port on the right here, the SR1 output. And similarly SR2 would then go into the SR2 input of the register file and SR2, whatever we pick, will come out on this left port report of the register file. Now that's going to be true regardless of which operand mode we're using. As you'll see, we're going to read it all the time, and if we wanted to the immediate value, well, we'll just throw away this answer. So the other thing that we'll always do is actually look at IR4 to 0, the five bit immediate offcode sign extended here. And then you can see this mocks over here. We're going to feed both the immediate value and source register 2 into the mocks. And that's the point at which IR5 will be used to say, well, which one do you want to use? And so if IR5 is 0, this input will get forwarded to the output of the mocks. And if IR5 is 1, this input will get forwarded to the output of the mocks. So in hardware, typically, we'll actually look at both answers, and then we'll just pick one with a mocks. So there's SR2 mocks that decides which of those two is fed into the B port of the ALU. The ALU is then configured here with this ALUK control signal. And you'll notice that each of the three opcodes here have two initial bits. So for example, we could just feed IR15 and 14 into the ALU to decide what we want to do. It's one way to do it. So once we've set this all up, now we get the right answer. It comes out. It actually would go out onto the bus in one cycle and come back into the register file. I eliminated the bus from the figure. But you can see where D argits fed into the register file. So when the rising clock edge comes, this answer is going around the bus and then being latched into whatever register we picked for the destination register. Now, since this is a clock synchronous sequential circuit, you should realize it that I'll just go over just to make sure that you don't get confused thinking about it at the higher level. If your source register and your destination register are the same, that's OK. Even if both source registers and destination registers are the same, that's OK. Because when the rising edge comes, that's when the chain happens. That's when the change happens. So just like a finite state machine, we make sure that the clock skew in the circuit is small enough that all of the flip-flops see the rising edge at the same time. So the old value and the new value, even if we're feeding one back into the other, it doesn't make any difference. All of the clock edges will happen at the same time. And when the register changes, it'll stop looking at the input. So when the register changes, then the output will change also, but that doesn't matter. We'll have the new value latched. So it's safe to have one source register and have the same destination register. Maybe I don't have to worry about that. All right. So let's take a look at loads and stores then. So data movement up instructions on the next kind of instruction with LC3. And we're going to actually have four different addressing loads. They're loads. So a load, remember, takes data out of memory and brings it into a register. And there are also stores. Stores take data from a register and put them somewhere in memory. So whenever we want to do that, well, it's easy to name the register. Right. We need three bits to name a register. How many bits do we need to name a memory address? 16 and LC3. Right. But we only have nine left. Right. After we say we want to do a load or store some sort, that takes four bits. We got to say which register we want. So that's three more bits. We have nine bits left. So in fact, with most of the ways we're going to approach this problem, we can't go anywhere. Right. We can't go to any address. We're going to have to somehow use bits from somewhere else to specify our address. But these nine bits with the different types of loads and stores will generate our address for us. It'll tell us how do we get the address for the load of the store. So let's take a look. So here's the first one. The first addressing mode is called PC relative. So what that means is we're going to we're going to use an address that's near the PC. So we're going to take this nine bits and say, well, let's start at the PC. And then we'll add that nine bit offset as a two complement number. And that'll give us our address. So here's one op code. This is LD. So LD says, well, take PC and the immediate field here. Nine bits of offset sign extended to 16. Add it to the PC. That's then our address. So go to that memory address. Get the 16 bits. This is the load form. And bring those into the data path and store those in DR. And then the store form, of course, goes the other way. So you take for the address the same thing. So you see the address formulation is the same. So you take your PC, take your nine bit offset add, I'm sorry, sign extend that to 16 bits. Add that to PC. And then use that as the memory address at which you store the bits in the source register. So same address generation for LD and ST. They just go in opposite directions. You could use this bit. I are 12. The last bit of the op code as your memory rewrite control, for example, you'll notice as we go through the load and store style op codes that in all cases loads are zero and stores are one. Program counter. That's the address of our next instruction. It's a register. So wherever your address happens to be, remember, federal increment. So whenever you execute one of these instructions, PC will hold the address of the instruction plus one. But in general, it's a register sitting in the control unit. Yeah, you will have to calculate the offset that you need here relative to the PC, which is relative to the instruction. So it's actually all of the PC relative instructions are relative to wherever the instruction happens to be. So it's very, very easy to do and very error prone because it's so simple. So you'll see as we write code, there's a lot of counting involved. So it's good that everyone here is good at counting because it'll take all the skill you have to stay focused. So you need to know that PC when it executes holds the address of an instruction plus one, so you do need to remember that. And I'll go over that several times, in fact, very soon. Okay, so back there it is. But I want to do an example just to make sure everyone understands. So PC is the value after fetch, right, when instruction executes, that's when we evaluate this RTL here. And so it's the address of the load or store plus one. For example, if I have a load at address 1, 4, 8, 0 and hex, and that load is destination register R3 offset nine. So this is just human, human notations convenient. So what would this instruction do? So if we go back and plug into our RTL, we've got memory at PC plus sign extended to 16 bits of hex 0, 9. And then take that memory at that location start to R3. So what is PC in this case? 1481, right, because remember after we fetch the instruction from this address, we'll also increment the PC in the same first fetch cycle. So PC will have value 1481 hex. So what's the answer? 148A I think. So just make sure you don't think it's this. There are a couple ways you can check. Once you write some code, you can go into the simulator and you can say, oh, show me my code. Make sure that whatever you did got the right answer because it will show you the address. So it'll say load from this address when you tell it to show you the code. So you can check that your offset is correct that way. That's actually probably the best way to check is to have the computer check for you. But yeah, that's easier. Okay. So. Difficult. So it's how you could at this. 16 of them. Yeah. Okay. What's the next question? How do we name memory address? That's good. Good. 16 of them, right? So it's a difference. 16 bits, 16 bits. So if you were a computer, what's the difference between 16 bits and 16 bits? Nothing good. So I could, for example, say, well, 16 bits. This could be a memory address. And if I go to memory and I get 16 bits, well, it could be a memory address. And I could keep going and going and going. So it's an important concept and software. And I'll come back to that in a second. But this indirect mode is going to do exactly that. So it's going to do that at one time. So what does it do? Well, it generates the address. As if it were a PC relative address. But then what it does is it said, okay, I'm going to go to memory again. So here, what you can see is, well, we go to PC, we add sign extended immediate nine, just like before, just like PC relative. We go to memory and we get those bits. But wait a minute. There's another M outside of that. So those bits come back from memory. Right. And then we said, well, that's an address. So we go again to memory using those 16 bits as an address. And we read memory again. So we put in the different 16 bits. Those are the 16 bits we then store in DR. So instead of just going once, we then take the 16 bits we get back and we go again to memory using those 16 bits as an address. Then we get 16 bits back again. Those are the bits we put in the register. What about the store? The first operation here is a read from memory. Right. We still have to go generator address by adding PC to the sign extended offset. Then we go to memory to get 16 bits. That's a read operation. Then we use the 16 bits we get back to do the store. So we do one read and one write for the STI. We do two reads of memory for the LDI. Yes. I can. Good call. All right. So why why did they define this instruction? It's purely to make sure you understand what we talked about 16 bits can be an address. And address is called a pointer and software. It's a really important concept for pretty much all of the higher level languages like C C++. They're actually used in some level and other languages like Java, but you'll never know it. So they try to hide it from you. But in C and C++ you use pointers all the time. All of your data structures will be based on pointers and all pointers are as memory addresses. Right. So if you understand what's a memory address, then you understand what a pointer is. How would you do recursive indirect? Well, I'll show you something in a second. You mean keep going and doing it. Okay. I'll show you another instruction in a second. Let me make sure. So you should realize this and indirect does it once right go to memory and get 16 bits use that as an address for your low to your store. Okay. So here's another one which you've actually seen. Once you get some memory bits into a register somehow, then you can use your register as the address of memory. So if you want to keep doing this as Daniel asked, you can use this instruction instead. So what is what is base plus offset mode? Well, your base is specified by another register. So now instead of only being able to access memory near the PC, right, plus or minus 255 or so. Now you can you can use 16 bits of another register to generate your address. You can still add this six bit to complement offset. So what we'll do is we'll take that six bit to complement offset sign extended to 16 bits, but add it to some other register that specified in the instruction. And that will give us our address. So then we'll go to memory read 16 bits out store that in DR. So for example, if you wanted to leverage the continued in direction and often in software, you will build pointer based data structures where you might have to chase down them. You know, even a few hundred times for bigger data structures or thousands of times. But what you can do is put those bits that come back from memory and a register and then use LDR to go get the next 16 bits for those in a register use LDR to go get the next 16 bits and keep going and going and going and do what's called the referencing your pointers in the software language for those of you've done that. And the store side then same address generation take the offset sign extended to 16 bits added to your value of 16 bits from the base register use that for the memory address, but the 16 bits from the source register into that location. So how do you actually get an address into the register in the first place. So one option I'll show you in a second is a fourth addressing mode. You can also use load or store, but the you'll you'll have to put data near the near the current instruction right the things I've showed you so far other than LDR STR which then sort of begs the question of what how did I get some other address at all into the registers so that I can then use that LDR STR instruction. So those allow you to put data nearby and then to load those data into the register using LDR LDI, but. But if you want to just put an address directly into a register, there's a fourth addressing mode known as immediate. So here's an immediate value and what we'll do is generate the address in the same way that we did with PC relative addressing mode, but you'll notice there's not actually a memory access. So this is called load effective address for LIA and all it does is address is the same as PC relative, but the memory is not access. So it's not even really a data movement instruction just generating an address putting that address into the register into dr. We can then use LDR to access adjacent memory locations using the offset. So this is the fourth addressing mode, there is no store form of LIA because it's not really not really even touching memory so it's just loading the address into. Questions on this. Okay, so let's take a look in the data path. So first thing I want to show you is PC relative addresses. So up here you can see the PC is coming around and going into this mux down here. So the PC goes along these wires. This is not the bus, right? So we're not using the bus for this goes into that mux and then goes into the adder. So when we want to generate a PC relative address, sorry, I should have told you will configure this mux to forward the PC input. Here's sine extended IR 8 to 0. So these are the low 9 bits of the instruction. Those are sine extended to 16 bits. Then they go into this mux which we also select for PC relative addressing we select this 8 to 0 sine extension. So those two then get added together. That's where the addition happens in this adder PC plus the sine extended immediate 9 field. That then comes out of this adder and goes into the mux which is then sent forwarded that input onto the bus. So that goes out into the bus and goes into the MAR. So when we want to generate a PC relative address, these are the pieces we use in in the data path to generate the address, the PC relative address, send it out on the bus into the MAR. Then we can simply tell memory go read or go right. We put the if we want to do a store will put the bits into the mdr next those also have to go across the bus. Then we'll tell memory to do a right. I've want to do a read. We've got the address there. So we'll tell memory do you read and then we'll take the bits out of the mdr put them across the bus into the into the destination register. Here's the data. So for load, the mdr after memory is told to read will be copied across the bus and then stored in the register file for a store the ALU actually has a pass. So we'll take sr1 and we will pass it out through the ALU ignoring the B input. So there's a fourth operation of the ALU which was just give output a and put that onto the bus to move it to the mdr, which we can then tell the memory to write at the address in the MAR. So that's the bits of mdr which is the source register. Makes sense? Andy's wearing off, isn't it? So LDI and STI, how can we do that? So there we're going to have to get 16 bits back in the mdr and that's going to be our address. Well, that's actually not too tough. So this is zoomed in on the bus near the mdr and mdr. So all we have to do is say we'll take the mdr after we do the read and copy it across the bus into the mdr and then we can do our loader store. So once we've gotten the first read set up for the LDI or STI, the second step, another read for an LDI or a store for an STI, we simply need to move these bits that we've gotten back from memory in the mdr and then for a store we would use the previous mechanism to put the bits we want to write into mdr for load. So we just go ahead and exercise memory after setting up the mdr and then move the final result out into the destination register. All right. So one more, which is the base plus offset mode. So in this case, you can see here's the base register that falls in the same place as SR1. So that now comes out instead of forwarding the PC from this address 1 box with forward SR1. And so that comes in here, you can see the sine extended 5 to 0 piece, also of IR 0 also goes into address 2 box. So the 6 bit sine extended field from the instruction add that to the base register that gives us our base plus offset and then again that just goes through the marn mocks gets selected to be put out on the bus goes around the bus to the mdr. So that's it for data movement. So the last kind of instruction is for control flow. So after we execute so far what we've seen is we execute it's some address call it a and then the address is stored in the PC that gets incremented in the first days of that. So it'll store a plus one. So after we finish our instruction, we say, well, let's go get another instruction. Well, we go a plus one. And then in first stage of that should again increment a plus to then we finish the instruction will say, OK, let's go get another instruction and start looking at a plus 2 and so forth. But what about things like if statements and loops right we need some way to be able to say, well, I don't want to go just get the next one in memory. I want to go somewhere else because I want to have the ability to branch right I want to be able to do a conditional test and then execute to different pieces of code or do a loop right go back into the same code again. So control flow instructions will conditionally change the PC. So explain what the conditions can be now. The LC3 actually has three condition registers that I hadn't mentioned before we call them condition codes, but there really three one bit registers sitting in the data path called NZP. So these are based on the last value that you wrote to the register file. So if you do an ad that writes to the register file if you do a load that writes to the register file, it's actually only for the operations and the data movement. There's some instructions we're not going to talk about the details that also write to the register file that they don't set the condition codes, just the operations and the loads. So the three choices, well, it's some last value treat that last 16 bit values to two's complement number and then you say, well, was it negative. And if it was negative, you've got this end bit set and if it was zero, you've got the Z bit set and if those 16 bits were a positive number, then you've got the P bits set. So obviously, exactly one of these three bits is one. And many cycle, you always if you've got a 16 bit to his complement number has to be negative zero positive can't be a combination of rum or anything like that. So you've got exactly n or z or p one of those three. So here's a conditional branch happens to be up code zero. What you see here is three choices. So when you write your instruction, you can pick, do you want to look at the end condition code or the Z condition code or the P condition code or some combination there up. So I'll tell you a little bit later, how we combine them. So once you make that decision that gets fed into this branch enable condition and then the branch enable condition will call it Ben. It's a little register also one bit register is used to decide, well, should you change the program counter or not. So the function able is set is the branch taken in which case the PC gets changed to current value plus this nine bit value sign extended to 16 bits. So when you do a branch, the first thing that happens is the process who needs to check well, let me look at the last thing that was written at the condition codes. So you're asking for and if you want to if that sets the branch enable bit, then we'll take this branch by changing the PC. If the branch is not taken, if the branch enable bit is false, nothing happens branch does nothing. And then you go to whatever your current instruction was for the branch plus one current address. So for example, if you have we write the branch instruction as humans with the bits attached so we might write BRNP, it's actually case and sensitive with assembly code, but we write BRNP to mean well, the end bit is a one of P bit is a one and the Z bit is a zero. So how has the bin calculated? Well, it's calculation in the decode state. So the other thing that happens in decode in addition to just doing a transition into some sequence for that particular op code is we actually calculate the value of the branch enabled bit and it's calculated like this. So you take your negative condition code and you end it with the bit of the instruction IR 11 that says whether this branch instruction wanted to look at the negative condition code and then you do the same for Z and the same for P. So you take these three bits and and each one of them with the corresponding condition code bit and then you order those three together. And then that's stored in the bend and the bend is then used to calculate whether or not you take the branch whether or not you change the PC. So let me do a few examples with you. So the first one up there, BRNZ. So when would you take the branch, when would you change? Yeah, and or Z. The condition codes remember only one of them can be true. So in or Z, which generally you can interpret it not positive. So branch if it's not positive. What about the second one? Always. So you can write unconditional branches by just putting all three. One of those three is always true. So if you take all three together, it's always going to branch. But a BRNP. Yeah, not zero, right? Because we left this e bit out. So if it's negative or positive, whatever the last value or the register, if it's negative or positive, you'll take the branch. Otherwise you won't. So by convention, you might run into this. So I just want to warn you, if you type BR with nothing, you might think, oh, that just does nothing. Well, no, by convention, BR means unconditional branch. And so if you type BR into one of the LC three tools, you're going to get BRNZP. Yeah. Yeah, so remember, let me go back to this. So whenever you write something into the register file, we're going to set the condition code. So the reason is, when we want to test, you know, for counting, for example, let's just make it easier. Let's say we're counting down and we're decarimenting our register over and over again. That add instruction will generate a result that's written back to the register file. And so we can test, well, did we reach zero yet by checking when we, when this Z flag, the Z condition code goes high. Because before that, presumably it's a positive number, we're counting down. And so until we reach zero, the p flag will be set. And then on the instruction that that generates the one to zero transition by subtracting one from that register will generate the Z condition code instead because we're at zero back to the register file. So, so anytime we write back to the register file with a load or an and an add and not, then we're going to go set these three, one of these three condition codes based on the value that's written back to the register. I have the data path in a convenient spot. I don't think I do. All right. Here's a data path. So you can actually see it down here. I wasn't going to highlight this for you, but you can see the condition codes down there. There's also a control signal to tell the, tell the data path to load these three. It's not shown here. This actually comes straight off the bus. So it's whatever value is going back to the register file across the bus. You can, you can also tell the condition codes to just look at that value and set one of the three bits appropriately. Yes, it's deciding. So, not so end does not need to. So if you want to know as a number negative, you don't need to look at all 16. Yeah. But for zero and positive, you have to look at all 16. So how can you tell whether number is positive? Well, it can't be zero. Yeah. So both of those two. I mean, you can use the same logic to make the decision. You look at it if it's zero. And then if it's if it's not zero and it's not negative, then it must be positive. That's right. Yeah. Yes. NZ and P exactly one of them will be one. You just change a PC. Yes. So if you, if this branch and able is false, that means whatever the address of this branch is, PC will have been incremented. And so you simply go to the next instruction and memory. If the branch is taken, you can change it to some other address. You've got this offset encoded in the branch instruction. So you specify when you write the instruction, where should it go if this condition holds and you specify the condition also. I'm sorry on your code. Yeah. Yes. Yes. Yes. Yes. Yes. So you have to put some other code elsewhere and then target that other piece of code with your branch instruction. Yes. That's right. That's right. And we'll do that a few times. All right. All right. So let's take a look at this. So here again, let's look at the PC. The mechanism for changing the PC. So we'll take the PC. We're going to add again, sine extended eight to zero, right. Because again, it's an eight or nine bit offset sine extended to 16. So same, same, same, same nine bits coming out of the IR sine extended going through the address two bucks. I address one bucks is set to forward the PC. So we add PC to the sine extended nine bit offset. And that then will not go out onto the bus because it's not going to MIR. It's going back into PC. So this PC, bucks, will be selected to have the output of the adder come through and will set load PC to one. So that'll change the PC now actually the new PC is only loaded on branch enable. Right. So we'll change the PC if the branch is enabled and we won't if it's not. So the branch can only reach plus or minus 255 right. It's the nine bit offset. So minus 256 to plus 255. And then the PC is your branch address plus one. So if you add those all up, it's roughly, you know, plus or minus 255. But what if you want to go further away, right. What if you got a lot of code, you couldn't quite squeeze that target. So you want to go with your branch, couldn't get it close enough. What are you going to do. Well, there's another instruction for you. I won't tell you the encoding. If you want to, if you want to use it, you can look it up. But it's called the jump instruction. I don't think you'll need to write this much code anytime soon. Yeah, so you can hop. Yeah, you can do that. But you have to have a place to put that other branch to. So yeah. Yeah, at that point, it's probably better for him to hop over one jump instruction and use the jump instruction to go further. Yeah, and change the branch condition the other way. And I think that I'm a jumper that I'm voting for the big part of you, but that's like, I don't like trying to reach it. Yeah. Yeah. No, so the idea is this is some arbitrary 16 bit value, you can put in a register. So you can go anywhere with the jump instruction. You can put any any address into a register. And so you can do a jump instruction to any address, whereas a branch can only reach about 512 addresses. What makes sense? Yes, that's it. That's all. That's the RTL. You take your base register. Take the bits. You put them into a PC. Because you then have to put the bits into a register before you can branch. So yeah, and you know, this is unconditional. So in order to use the conditions, you need a branch. There's no conditions on this jump. It's just change, change PC to base register. Yeah. Yeah. So that's two important parts, actually. So let me make sure everyone understands that Eric asked, well, why not just use jump all the time. Is it a more powerful? Well, it doesn't have condition codes. Right. So we would have the same problem we did before. We could all we can make an infinite loop. We could go somewhere else, but we wouldn't be able to make a decision. Right. Because because jump does not have any condition. And the other the other issue is just that, you know, in order to go somewhere, you first have to prepare a register with the target, the new address you want to reach. So it's not not quite as simple as well, just do a jump. You have to somehow get the bits into a register. Then you can do the jump. All right. So one more instruction for the ISA. There are actually a few more. So if you want to, if you want to read them, you can, you won't need them. Some you'll never need some you might use JSR. You'll use in 220. But, but for us, we want to look at trap. So trap is the last control flow instruction will look at. And what it does from our point of view is just in folks operating system services. So again, you know, if you want more details, this is start in a couple of senses. So this is 220 material. So if you want to understand how it works and you want to go look at the operating system code and understand devices read chapters eight and nine of that. So from our point of view, it just invokes one of these operating system services in which service depends on this eight bit vector. So trap has op code 1111. These four bits are zero. And then you can specify any eight bits there. But there are only three useful eight bit patterns for us. These, by the way, are page 543 of Patent Patel their couple others you could use if you wanted to. So one is the trap that I'm sorry, this is a trap vector number. So hex 20 is the get see trap. So what that does is as well, give me a character from the keyboard. So we'll actually wait for the user to push a character on the keyboard and it'll give you that character back as ASCII in R zero. So you call this trap, you first need to make sure that you don't have anything important in R zero, because when that trap finishes R zero is going to hold the ASCII characters, whatever bits you have there are gone. So if you're, you're writing your code in the lab, you know, make sure if you need to do a trap, you don't put important stuff in R zero before you execute a get see trap. The out trap then is kind of the opposite. It says, OK, give me one ASCII character, put that in R zero and then in both trap 21 hex and that will send that ASCII character to the monitor for you. And so this is how you print to the screen is you send send it ASCII characters are using the out trap. Again, you need to have R zero free to do that. So you need to put the ASCII character there. You can't put it in R three and, you know, computer won't figure it out, right? You don't have to put it in R zero. And then the last one, which you should always put at the end of your program is, well, stop my program, go back to the operating system. So think in the lab, it talks about the difference between halt and end. And end will show up, sorry, end will show up in assembly language and tells you assembly that you're done writing assembly code and holds tells your program to stop stop running. So you always need a halt in your program. All right, so those are the three traps we'll look at. There's one side effect of one side effect of trap. I do want to mention and this has to do with how it actually works. Anytime you do a trap, our seven will get changed. So when you write code in the lab for our class, the easy answer is don't use our seven. You got eight registers. Don't use our seven. Now you have seven registers. There are better answers if you really want, but you probably don't need eight registers for the kind of code you'll need to write for our class anyway. So just don't pick our seven. If you do any time you do a trap, it'll change its bits and so that'll be confusing. And also your code will not work. If you cared about those bits. So this is the easy way to handle it for now. And again, if you really want to understand why and how it really works, you can go look at that. Yeah. It's just it's to do with the way it works. What it's really doing. And again, this is beyond the scope of our class. But what it's really doing is there's a routine that interacts with the IO devices. It's a piece of code. And so if a trap instruction really does is it goes to that routine and it executes that code. And then it comes back when it's done. And how does it know where to come back to? Well, it puts the address of your code in our seven. So so now you all know, OK. Yes. Yes. So if you want, you can play with IO registers directly on the LC three simulator has all the LC three OS code so you can go read that by just listing it. There should. And you can download the source yourself if you'd rather read it in assembly language. It's all available to you. Yeah, you get a computer says you're not allowed to execute that instruction. But we're not going to do. All right. So again, this is kind of out of the scope. Computers sometimes run into problems. They don't know how to solve. And so they generate things called exception. So the hardware will say, well, I have some condition. I don't know how to handle. So if you give it an illegal instruction, that's an exception. If you tell it to divide by zero, that's an exception. There are a bunch of others in real processors. You learn more if you take 391. But you know, what really happens when that exception occurs, well, the hardware literally goes to some other piece of software, just like a trap. And then the operating system says, well, what should I do? If you generate an exception in your operating system, typically it'll panic, right? And then because the operating system shouldn't have buggy code. But if you generate an exception in your user level program, typically the operating system will say, well, you're a bad user level program, just terminate. So, but the hardware generates that exception. And it does so on things like illegal instructions, divide by zero. Yeah, we're not going to talk about privilege in our class, but it's mentioned in the books. So if you look at Patent Patel's privilege implementation, if you try to do something where you don't have privilege, and it's supposed to be privileged, it'll generate exception there too. And there are lots of other cases in real processors having to do with more advanced design issues. Okay, we have times, right? We still will. All right, so maybe we can, hmm, cool, and I'm going to get to farm seven minutes. All right, so let me, let me set up the problem. Actually, we're going to summarize first. So, so we just looked at the LC3 ISA and went through went through a more or less complete subset. So the ISA, you know, wanted to give you kind of a definition after having seen one, right? So the ISA is going to answer these three questions. Right? So, first of all, what's possible? Right? So we went through and we looked at all the different, all the different instruction op codes in LC3. So what are the things you can do with instructions? So what does that matter? Well, when you write programs in LC3, a similar LC3 binary, it can only do the things that the, that the ISA defines. Right? So you have to break your human task down to the level of LC3 instructions. Okay? And that's always happening, right? So even if you write something like C or Java, you know, at some point, things have to be broken down to the instruction level for the processor and what you run them. Because that's all the processor knows how to do. So once you know, well, what are the operations that can do? Well, what are the operands you can use? Right? How can you specify the operands for each of these operations? That's another thing, the another question the ISA has to answer. And then finally, well, what is the representation we use? Right? We have to express the instructions to the, to the hardware. How do we encode those? What do the instructions look like? So all of the, the previous slides today where the encodings for the different op codes in the fields. Right? But that's part of the ISA is to tell the programmer, well, how do you actually express these things? And also to tell the person implementing the processor, if you see this instruction, what does it mean? And because the ISA is the interface between the hardware and the software. And so some set of people is building a processor that looks at these bit patterns. And so, okay, when I see that bit pattern, I have to do this set of operations. And then the other part is the people writing, writing the instruction somehow, whether it's because they're writing a compiler or writing assembly or binary instructions directly saying, okay, here's what I want the computer to do. Let me put those bits together and put them in memory. And those two people, they don't even have to communicate so long as there's a clear and well-defined ISA. So here's kind of what we saw for the LC3. We had three operation or operates, ALU operations and and should say add and did not loads and stores. This was the PC relative indirect mode, base plus offset mode and immediate mode. And in the control flow instructions, we just looked at where branch jump and trap, the data types, so I put data types up here. Any time you do operations inside the data path, right, you can, you can imagine supporting different representations, right, when we started a class, we said, well, let's build an unsigned adder. And then we said, oh, look, it's the same as a two complement adder, right. If we built a multiplier, then those two aren't quite the same. When we did a comparator, we also had to change things a little bit. So the question is, well, what kind of hardware do you actually have in your data path? The only hardware that LC3 has, it's all aimed at two complement, all the offsets are two complement, all the ALU, I mean, it does logic operations too, but the ALU when it does add, you can think of it as two complement. Everything about LC3 is two complement in terms of how it operates on values that are passing past around in the data path. The addressing modes we saw for various instructions were register immediate PC relative and directed baseball, soft set. So the three condition codes are provided are negative zero and positive. Some, some processors will give you more condition codes, right. So you'll notice, for example, you can't check whether an add overflowed, there's no overflow bit here, right, there's no carry out that either. So you can't easily check in LC3, whether you're 16 bit addition overflowed, you have to go check it by hand by looking at the bits. That's not that pleasant. The only thing you can do with LC3, you can write an algebraic expression and then you can rework it to compare it with zero, right. So then you can compute the algebraic expression and you can check whether it was negative zero positive. And so when you when you started a high level, you're going to have to cast everything in terms of a comparison with zero, because that's the only thing you can do with your branches and LC3. And then for the encoding, you know, again, you've got it, you've got a sheet that shows you that don't worry too much about the details there, so much is how to use it. All right, so I think we're not going to get too far in this, but let me just say a few words about what will start on Friday. So we're going to count to 10 together. It'll be exciting. There's actually three variants on the sheet. So we'll do indirect addressing together and I'll leave you to do PC relative and baseball, soft set on your own. Here's what the sheet looks like. So there's some starting code, which will decode together. There's the loop body here. Actually, I can walk through this. So the PC, we're going to start at 3000. Then we'll do this code. Second part down here. Some values, some data we've placed in memory. And then here's the loop. Okay, so so we're going to look at how we actually execute a loop 10 times, see what instructions scaffolding we build around that using LC3 instructions to make it happen. And then talk about what happens if we if we change things a little bit. And then after that, we'll do some examples of like typing in a number and stuff stuff that you've seen at the start of class on the website. So let me just stop there and I'll see you on Friday. Thanks. you you you you you you you you you you you you you you you you you"
    },
    {
        "ECE120-2016-12-05-LEC-39-slides.mp4": " Okay, I think it's three o'clock. So what we're going to do to start off is just finish up air correction and hamming codes and then sected codes. And then I'll spend the rest of the time just giving you free advice. So I plan to do this anyway, but I was before I got clobbered by a virus over the weekend, I was going to actually add another piece of material here. Instead, we'll do it all the other lectures do and do a review session on Wednesday. So we'll finish all of this stuff up, I think today and then on Wednesday, we'll do a review session, which is what all the other lectures are doing anyway. I did have to move my office hours. I'm not sure if it was kindness to the instructor, just feeling bad for the students. So when you get to 391, you'll understand you work really hard to do your OS. And right now there are 240 students in there and one professor. I felt like they should have some time explaining what cool stuff they did. So I agreed to spend all day Tuesday from eight o'clock in the morning till eight at night talking to students about their projects. So I won't be able to go to office hours. I was going to shift them, but instead. Three, the three of us still teaching lectures are going to have office hours on Tuesday, 13 December. I think they're starting at 10 and running till four and minor in the middle. Mine will be in daily by there as I think are in 3017. There was an announcement on the wiki so you can look up all the details. But the important thing is, you know, don't come to daily by looking for me tomorrow. I mean, you can try to slip in in the 391 lab if you want. I'll be there all day. But I will be there next Tuesday from 12 to 2. And I moved it to try to try not to overlap the final session because I know that some people might have final starting at 130. So you should have some free time in their regards to your final schedule. This is yeah, third midterm another third midterm. Now they should say final exam. Sorry. So the final exam. Let me try. No. The final exam is as you hopefully know Wednesday of 14 December. For those of you that don't know, I guess some of you still new to the university. The university tells you at the very beginning of the semester how to map the start the first time of your class to the final exam time. And most classes will announce time. So I think we announced this at the first day of class and it's been on the web. But for the most part, you can figure out your whole schedule at the start of the semester. Anyway, ours is Wednesday, 14 December. If that's a conflict for you. And again, if you're if you're new, you should realize that the university has this niceness clause that says, well, no one should have to take three finals in a row. If you have three finals in a row, including overnight in a row, then the university says you're allowed to take a conflict for one of those. So which one will that depends on which classes, etc. We have pretty low priority because this is a combined class, right. We have four lectures taking one final. So it's probably going to be our class. But. But if you have back to back finals, three in a row, you're allowed to take one and take a conflict for it instead. Pay attention to that because otherwise you're well, I don't know, maybe some of you enjoy taking all of your tests in one box, right. Get it done with. But you have that option. So exam coverage section 4, 4, right. Everything since the third midterm in the notes. So section 4, 4 is a summary of that. So again, Wednesday is will be our review session for the final. We'll spend all day doing that. So come prepared to ask questions. And it'll be on video. So once the final is closer, you can go watch it again. All right. So what's the exam going to be in terms of content. So it is cumulative in the sense that we have one part of seven each on parts one, two and three of the class. So one problem on each of those parts roughly a seventh terms of points, maybe not exactly. And about four seventh from the last four sevenths on the last few weeks or the material since midterm three. So as you know, things kind of build up, right. If you still don't understand to his compliment, then you might get hurt on these two. But. All right. So so here's where we left off. We were talking about air correction and I give you kind of a couple of examples of where it might be important. I don't think I mentioned it's actually now used at pretty much every level of memory hierarchy, even the memories closest to a processor, even on your GPUs, the first generation of graphical processing units didn't have air correction. But that people started measuring them in high performance computing and realize, well, they were producing wrong answers often enough that they started putting air detection correction code. So ECC is it's called air correction coding is now used pretty much on every level of your memory hierarchy. So if you're looking at the number of codes and even the ones we'll talk about are used on disk drives because you have to worry about errors accumulating. And if you're not looking at your bits and bits more and more bits will change over time, so the bid error rate goes up. So so for the for the memories and things like that, the codes will talk about like hamming codes or what's in use. So can we correct I wanted to remind you is a is a parity. I'm sorry, hamming distance code to like a parity code is that good enough to correct an error. So this was our three bit to complement with odd parity. So three bit to compliments and black for each of these eight values. And then the odd parity bits and blue. And of course, if we have one possible error. So if we see this pattern, we know this is not odd parity, right, because it has two ones and two is not an odd number. But that could have been originally the value zero, which is coded this way. And then there is a bit flip that changed this zero to a one, but it's also possible that the original stored value was a one, which is coded this way. And then the parity bit got flipped and it was a one. So we don't know if we see this value well originally was at a zero one. And of course, we can't really make a choice, right, making a choice. We have no information other than these four bits. So we don't have any good way to distinguish between those two. So if we have a larger hamming distance than we can. So this is the three copy code. This is a terribly inefficient code, but it's someone intuitive as to as to why this works. Right. So if you take all your bits and you say, well, let me make three copies of them. So here I've done that just with two bits. So three copies of two bits for a two bit unsigned representation. So what's the hamming distance. So you can see between three, right? Yeah, because if you look between any of these patterns, the minimum distance is three actually between one and two, the distance is six. But what matters for the distance of the code is the minimum distance. And so you can see between zero and one, for example, the distance is three between two and three, the distance is three. So depending which way you pick things, you'll get three or six. So the minimum is three. So what happens if one bit flips. This is all still things we kind of glanced at quickly last time. If one bit flips, then only one of the three copies can get changed. Right. If only one bit flips and the whole thing only that bit has to affect one of our three copies. So that means we can always just vote and the other two will be their original values. And so they'll always out vote the wrong copy and we'll get the right answer. So what happens if two bits flip what we only have three copies. So if those two bits happen to affect two different copies in the same way, then we're just out of luck. Now if it were different to bit flips and then we've got three different answers, we would know something went wrong. But there are cases where only two bits change. And now if we try to vote, well, these two zeros will out vote the two and we'll get the wrong answer. So we'll say, oh, you know, we would try to correct. And then we'll say, well, this originally was zero. And of course it was two. Yeah, so if they were both blue, you would be able to correct. Right. So if you flipped the two blue bits, you would be able to correct the answer. That's right. So the answer is sometimes, but in order to have strong air detection or correction properties, you want to be able to detect or correct regardless of which of the bits flip. So in this case, you always want to look for the worst case in your analysis. So in this case, the worst case is that the same relative bit in two of the copies flips. And that way you correct incorrectly, which is that red. Sorry, that value. So I haven't told you the relationship between hamming distance and the number of bits that you can correct, but yes, there will be a relationship. Yeah, so all I've shown you so far is that hamming distance to cannot correct any errors, hamming distance three can correct one error, but I haven't actually haven't even shown you in detail why that's true. So let me, it's a good question. So the question is what's the overhead for doing this stuff. The overhead's not so big, but let me show you a code that they actually use and then we can calculate it from there with a concrete code. Yeah, it's, I mean, the short answer is it's roughly logarithmic in the number of bits, right, which is big if you want to protect two bits at a time, but very small if you have 50 or 100 or something. Okay, so all right, so. So let's try to generalize a little bit. So let's say that we have a code word see. I want you to define the neighborhood, the K neighborhood around code word see as all of the bit patterns that have hamming distance of lesser equal to K from C. Okay, so this is what you get if you flip up to K bits, right, so if you flip up to K bits from some original pattern see what you end up with will be in this neighborhood. So you don't flip more than K, you might flip less than K, but regardless of how many from zero to K, you flip whatever bit pattern you end up with will be in this neighborhood. That's how we define the neighborhood. Yeah, but only in chalk right now, I mean, I drew an illustration, I don't know if it'll help me. All right, so. So okay, if I just start with all zeros, okay, so, so for example, the neighborhood here, if you flip one bit. You'll get one of these four patterns. Right, and then if you flip, sorry, I hope those are legible back if you flip a second bit. Then you would get zero zero one one. So this is flipping a second bit on this one, not the same bit, of course. And then let's see this one would also be able to take you to here, but it would have two other patterns, which would be all of these would all be two one bits down here. So all of those bit patterns together would be the two neighborhood around the zero zero zero zero pattern. So basically anything you get by flipping up to K bits any bit pattern you would include in the neighborhood. Because that would just that I already have that right so that would just give me an example of flipping fewer than fewer than K bits or fewer than what I was flipping. Yeah. So this is the idea that you're storing a bit or transmitting, I mean, it could be a transmission as well. So either I'm storing some bits somewhere and I put some extra bits like parity bit or for air correction, like a triple code is only when you've seen so far. Later, I look at it again, some of those bits have changed. So that's one model. The other is I transmit bits to you, but some of those bits are corrupted and you get them incorrectly. Oh, that's way outside this. People people do things like residue residue computation. So you can, for example, calculate some bits, mods, some prime number. And then when you add things together, you can percolate that through your function unit, your adder, multiplier, whatever and make sure you get the right residue out. But that's outside the scope of what we're worried about. Those kind of errors are much less frequent anyway. So in practice, those kind of those kind of capabilities are not on typical processor design. Yeah, it's a good question, but kind of outside what we're doing. Yeah, yeah, so K, be anything up to K. So including zero, right? So see itself is in the neighborhood as well. So the C is up here. So all of the bit patterns. I didn't draw all of the patterns here, but including, including C, including everything next to C one bit off two spaces away. Okay, so when can we correct errors? So if we assume up to K bits flip in a stored bit pattern to produce a final bit pattern F, we know by the definition of the neighborhood that F is is one of the patterns in the neighborhood around of K bit flips around C. Right. So we know F is in there. When can we if we if we know these two things we know F and we know this neighborhood, when can we say, oh, that must have been C. Well, in order for us to be able to make that deduction, right, we can't make guesses. So unless those neighborhoods don't overlap, then we can't do it. And if they don't overlap, then we can do it. Right. We can say, well, which neighborhood did F fall into that tells us uniquely, well, what is C, as long as those neighborhoods don't overlap. All right, so here's the illustration. So if we want to if we want to correct K error. So here's my attempt to illustrate what I drew on the chalkboard there. So you've got some neighborhood's NK of C, which is all of the up to K bit flips, all the bit patterns up to K, hamming distance away from C. Right. So the farthest ones away are distance K. If there's some other code word that this thing you're looking at might have been, well, that'll be some other code word D. And so they also has a neighborhood around it. So if you want these to not overlap, then the things that are farthest away still have to be distance one. So in other words, the distance between the code words has to be K plus one plus K more. If you want to deal if you want to deal with K bit flips, that will allow you to have disjoint neighborhoods. The neighborhoods don't overlap. So if you say, well, I saw this one here. This was F. You know that this F cannot also be in another neighborhood. You know that it can only be in one neighborhood because the neighborhoods we've disjoint. They don't overlap. So if it's in one neighborhood, it's not in another. So you can uniquely identify the code word that generated that neighborhood. But that's just hamming distance, right? The minimum distance between two code words in the whole code that tells us the hamming distance. So if my hamming distance from my code is at least two K plus one, it can correct K errors. Okay, so distance, the hamming distance D has to be at least two K plus one. If you flip that around, you get K less or equal to D minus one over two, but K is an integer. So usually we might write it with a floor function. So this is the thing to know basically that if you want to, if you want, if you have a hamming distance D, then subtract one divide by two round down. That's how many that's how many errors you could fix. So with three. Let me, let me give a couple more details and ask and answer your question. If D is three, right, three minus one over two is one and round down, you still have one. So with hamming distance three correct one error. With hamming distance four, four minus one is three divided by two is one and a half, but round down. So still one. So yes, there is, and I'll show you that. I think that that's what a sec dead code is, this hamming distance four. So in that, I mean, I can tell you just by the name, it's single error correction, dual error detection. So we'll come back to that at the very end. Good question. All right, so what's a hamming code? So, did I tell you before hamming is I did, right? Okay, so hamming code also named after Richard hamming is a general and efficient code with hamming distance three. So it's a nice way to generate codes is particularly nice because it gives you as you'll see a very easy way to say, well, this was the bit that was flipped. Let me flip it back. It's a very easy to do. And it's a general way for arbitrary number of bits of coming up with a set of parity bits that protect those sets of bits. The parity bits cover subsets of all of your bits, as you'll see. All right, so. So to define a hamming code on n bits, start by numbering the bits from one to n. So not no zero bit start from one to n. And then all of the powers of two are going to be even parity bits. And each even parity bit p. So p then is some power of two is based on the bits with indices k for which p appears as a one and k. So in other words, k and p equals p. So the binary number that you get by writing the parity bits and error as ones then gives you the index of the bit that's mistaken. So let me make this concrete because it'll be a lot easier to follow. So here's a seven for hamming code. So here the bits, right, number from one to seven. So the parity bits are x one x two and x four. So you get to put four data bits in and then you have three parity bits. Now that doesn't seem terribly efficient, right? It's almost a factor of two, but you know, that's because we picked such a small number. If we picked a thousand bits, right, a thousand twenty three, for example, then you still only have 10 parity bits, but now you have a thousand bits of data or almost a thousand bits of data. So it's logarithmic. And if you pick small numbers, it seems big, but if you pick bigger numbers, it's not so bad. Anyway, so in the seven for hamming code, you've got these seven bits again, the data bits, sorry, the parity bits are x one x two x four. So three five, six and seven are data bits. So you can put anything you wanted there. So how do we calculate the parity? So the parity is even. So x one is is the parity on the bits for which the one, the one bit is is one. In other words, the odd numbered indices. Okay, so three five and seven. So x or three five and seven together. And then in order to get even parity, you have to set x one equal to that. And that gives you an even number of ones for those four bits. Makes sense. Similarly, x two. So x two is the indices for which the two bit is a one. So if you, you guys should write these out. Sorry, I should have done this on the slide. So remember, there's no. There's no one index. So the indices run from one through seven. So here you can see, these are the x one. There's a one bit, the two bit and the four bit. So this is x one, which is defined as x three x five and x seven. This is the two bit. So here's x two. But that's defined as x three. And then x six and x seven. So you're just taking the binary numbers and looking where they have ones. So it's pretty straightforward. It sounds complicated in words, but pretty straightforward practice. Okay, so that's where we get the three six seven to define x two here. And then x four is just the is just the positions where the four. I'm sorry, the indices where the four bit is on. So that's these four down here. So here's x four. And then that's defined as x five x or x six or x seven. Yeah, so we'll do that in a second and we'll go do we will plug into these equations. I just want to make sure you understand where they come from. I mean, most of the stuff will ask you to do on exams to would be with, for example, a seven for hamming code, but I want you to know how to do it if you need to someday generate a 31 bit hamming code. Yeah, I'm. Now, these are x or together. So it's even parity across these four bits. So it's x three x or with x five x or with x seven. So those three together that defines x one. Okay, let me, let me. That's just how we define hamming codes. I mean, it's a very easy way to find mistakes, but let me do a concrete example now. So if you want to encode something with a seven for hamming code, what you do is you get to pick four data bits, which are these. So pick four bits for me. 0, 0, 1. Okay, so then we just go plug in these equations. So x one, then is even parity across these four. So this one, this one, this one, and itself. So since it's even parity, the way to figure out the bit is basically to x or the other bits or to count them if you prefer. So it's not one, not one one. So it has two ones. So in order to get an even parity, we should put a zero. Right now if you plug into the x or you have. So first three, one, x or it was zero, x or it was one, which is also zero. So that's where the x one comes from. So you mean which indices that comes from this table over here. So the x one bits are we look at the indices where those indices have a one one written in binary x two when they have a two one written in binary x four when they have a four one written in binary. So if you kept going it be you know x one hundred twenty eight when they have a one twenty eight written in binary and so forth. Yeah. So those are all defined by the construction of the hammock code basically. So they're by the bottom of the top of the bottom. The not even the data bits you can put anything you want in the data bits. Yeah, you put anything you want in the data bits and calculate parity bits to find the code word. Yeah, and then it's protected. So to calculate x two then we would x or x three with x six with x seven. So this one, this one, and this one. So what do we get zero. And then for x four we would x or these three. So what do we get one. So that would be our seven bit hammock word. Okay, and then if something happened we could figure out I'll show you an example of how to figure it out, but we could figure out what went wrong. So if we could figure out a method of up to one of those bits that flip. Here's a graphical version, we used to do this in discussion section, but. So this is the, this is a graphical version that shows the interaction using using well to these fears. of each of these as being the, each of these circles as being the one bit in red, the two bit in yellow and the four bit in blue. So to find the parity bits, you can write your data bits into the three, five, six, and seven positions. And then you pick the parity bits such that each circle has even parity. And then to check the parity bits, you just check that each circle has an even number of ones in it. And to correct an error, you find the circles with odd parity and then flip the bit in the overlapping area that corresponds to which circles have the wrong bit. But I won't go through the graphical model. Let me do the algebraic model. Oops, that was strange. All right. So this graphical approach does, does generalize by the way, but it's hard to draw circles or spheres above two dimensions on paper. So unfortunately, there isn't much further than a seven for hamming code. All right. So here's the algebraic encoding. This is what we just did on the chalkboard. We said, well, let's say we want to store, oh, did I pick the same value? All right. Sorry. Yeah. Sorry about that. I didn't do that deliberately, really. All right. So anyway, so here's the three to five and the seven pulled out. We got it oddly enough. Exactly the same answer as you gave me a minute ago. So this is our coded word. So then let's say that a bit flips. And I didn't tell you which bit, which is purposeful. So this has one bit different. And I guess you can now look over there. But don't do it. So this is something with a bit error. So we start our value and we came back. And one of the bits have changed. Let's see what happens when we try to correct it. So to correct it, what do we do? We recalculate this air bit, which is basically saying, well, for each of our parity bits, does it now have odd parity or even parity? It's supposed to have even parity. So if it has odd parity, something's wrong. All right. So we can take x1, 3, 5, and 7, x4 them together. Believe me, I just pulled these out. I think I'm right. 0, 1, 0, 1, x4 those together. We get a 0. So there's nothing wrong with the 1 parity bit. E2 is 2, 3, 5, I'm sorry, 2, 3, 6, and 7. That's 1, 1, 0, and 1. x4 those together, we get a 1. So something went wrong amongst one of those bits. And then for E4, we take 4, 5, 6, and 7. x4 those together. That's 1, 0, 0, 1. That gives us a 0. And then all I have to do is write these 3 from high to low. That gives me 0, 1, 0. And that tells me this number 2 is the one that got flipped. Which in fact, if you now look at it, you'll see all I did was I flipped x2. So this is what I meant when I said it's easy to identify. All you do is you recalculate the parity bits. You line them up in order. And then that tells you a number in binary, which is the bit that you have to flip to get back to the right answer. There. I'm going to flip it. Yeah. I just want to get the ground for E4 in the memory. So where does that type of type of response come from? Oh, yeah. The LC3 doesn't have ECC in it. Yeah, sorry. Yeah. LC3 does not do error correction. Yeah. I mean, you could have a memory that does error correction all within the memory. For example, attached to the LC3. But there's no ECC in the LC3 data path. Yeah. Yeah. OK, session. So is that the memory of the LC3? Yeah, yeah. So exactly. So what if no error occurs? So this is kind of your question. Why is there no X0? So if there were an X0, if there's no error, we get all of the E sub 1, 2, and 4 values. This should say E sub i or something. All of the error values will be 0, right? Because all the parity bits are still correct. And so your error pattern will be 0, 0, 0. And that has to be able to tell you, well, nothing went wrong. You don't need to flip any bits. So we don't include a 0 bit for that reason. So there is no 0 bit. So if you get that pattern, that means there was no bit flip. You don't have anything to correct. OK. Any other questions on that? OK, so this is the sec-dead code. So let me finish this. And I'll see if you want to do another hamming distance example. I'm saying that hamming distance. hamming code example. So what happens if we add a parity bit to a hamming code? So in general, I won't prove this here, but I think I put a proof or proof outline, at least, in the notes. If you add a parity bit to a code with odd hamming distance, that actually gives you a code with one more hamming distance, which is kind of cool. I mean, it's somewhat intuitive because you can think of the odd hamming distance. They've got to have different parities. So if you add a parity bit, that means anything that was close together now has to be a little further apart. And so the codes that were close together, meaning at the minimum distance of d, are now forced to d plus 1. So now your new minimum is d plus 1. Unfortunately, this is not so simple going from a code with even hamming distance to one with odd hamming distance. Otherwise, we could just make hamming distance arbitrarily large. But we can take our hamming code and add a parity bit, and that will give us a hamming distance of 4. So what's good about that is we can then use that. We can still only correct one bit flip. But what we can do is we can, all I did is I plugged into the equation and got 1. And so we can only correct one bit flip. Sorry, I flipped through that slide too quickly. But if two bit flips occur, what actually happens? So you think about their neighborhoods of 1 bit flip, because we're only going to correct one bit flip. But if two bit flips happen, the thing I see moves out of the neighborhood. So two bit flips will take me out of the neighborhood next to my code word of 1 bit flip away. So what I see, the final answer is not actually in any neighborhood of any code word. So I'll know something went wrong. So if I have a hamming distance of 4, unlike the hamming distance of 3 examples I showed you before, with a hamming distance of 4, if two bit flips happen, I won't make the mistake of correcting to the wrong answer. I'll actually know, well, something else went wrong, I have to give up. So I can do single error correction, double error detection. And so I'll know the difference between 1 bit flip that I can correct and 2 bit flips that I have to give up. 3 bit flips, of course, I'm just out of luck. 3 bit flips, I'm too bad. But people play the probability game. So this is a sec-dead code for this acronym here. And they're actually pretty common, too. OK, so people want to do another example or two of hamming? Yeah, OK. All right, so let me think the next thing was advice. Yeah. So maybe I'll send around these sheets. I don't know if we'll actually finish it today, but this was my printed copy of advice for all of you. And let me switch over to this thing, which hopefully won't take forever. I'll quickly I can set it up. And then the question is, do I have any paper? Wow. We're very limited paper resources. OK, so let's start by encoding something. So pick someone pick four bits for me. 1111, OK. Good choice. All right, so remember this is x7, x6, down to x1. Maybe I'll number them all. Zoom for now. I'll zoom out later. And for the data bits, these four are data bits. OK, so how do we calculate x1? So remember x1 is the even parity across those indices with the one bit set, right, which is just the odd bit. So 3, 5, and 7. OK, so we'll look at 3, 1, 5, and 1, 7, and 1. That's 3 ones. So to make even parity, what should I put next one? A 1. So the other way to do this is as x or, right? OK, what about x2? Oops, sorry. I'm going to have to zoom out a little. OK, so we didn't focus here. Close to auto focus. All right, so x2 will be the indices where the 2 bit is on. Right, so those were two, of course, but 3, 6, and 7. Right? So 2 is defined by 3, 6, and 7. So again, 1, 1, and 1, so what's x2? 1, good. And what about x4? 1 also, right? It's x5, x6, x7. Those are the 3 where the 1 bit, I'm sorry, the 4 bit is on in the index. As you can see over in the tables, to the side there. And 1, x4, 1, x4, 1 is 1. OK, so there's our coded hamming word. So let's say something comes along and flips a bit. Who wants to pick a bit to flip? 5, 5, 1, OK. And then we don't know what the original word is, right? All we see, so I won't even show it. I'll just say, well, what we see is 1, 1, 0, 1, 1, 1, 1. So those are the bits we see, and we have to figure out, well, there's something go wrong. Let me try to see if I can get this auto focus in the way it didn't. There we go. It's better, huh? All right, so let's see, how do we do that again? Yeah, so let's calculate air bit 1. So it's x1, x3, x5, and x7. So what is that? A 1, OK. OK, what about E2? It's 2x-word with what? OK, so that's a 1, x-word with 3, x-word with 6, and then 7. So what is that? 0? Yeah, there's still 4, 1s, right? So that's even parity. What about E4? x4, 5, 6, 7? OK, so that gives me 1, 0, 1, 1. Which is what? 1. OK, so if I write E4, E2, E1, then that gives me 1, 0, 1. So that means bit 5, x5 is wrong. Yeah, make sense? You want to see what happens if 2 bits flip? OK, someone else pick another bit to flip. I hear 3, 2, 4. OK, anyone against 4? OK, we're going with 4. All right. So 6, 7, 6, 5, 4. OK, so two of our bits have flipped. Our original pattern was all 1s, but we don't know that. So x5 and x4 flipped, and we want to go figure out what was this answer. With having this in 3, we can correct a bit. We can detect two bit errors, but we have to make a choice. And having this in 3, I told you, well, you can detect d minus 1 if you have having distance d. But if you choose to detect, you have to give up on all cases. You have to choose detection or correction for having distance 3. So you know this is wrong, right? Some of the parity bits are wrong. So in that case, you could say, anytime I see parity bits are wrong, I give up. So we always detect two errors. But if you choose to correct, and you only have having distance 3, well, let's see what happens. So what's e1? So x1, 3, 5, 7, which is 1, 1, 0, 1. 1, what's e2? 2, 3, 6, 7. What's that? 1, 1, 1, 1. It's still the same. 0. What's e4? Sorry, I can't read quickly. So 0, 0, 1, 1. So what's that one? Uh-huh. So e4, e2, e1 equals 0, 0, 1. So bit 1 was wrong. How we fixed it? Yeah, exactly. So you will get an answer. And if you go change that bit, you will still have bits. You won't, however, know that those bits didn't happen to match the bits you put there originally. So the bits you'll get, by the way, if you look at this, you know that the patterns coming out, if only bit 4 had flipped, the air pattern would have given us 1, 0, 0, bit 5 flips, we would have gotten 1, 0, 1. If you x-ore those two patterns together, get that. So if you x-ore 1, 0, 0 with 1, 0, 1, you get 0, 0, 1. So that's the answer you get. You won't know whether two bits flipped or only one of those, or only bit 1 flipped or whatever. You won't be able to know. Yeah. Yeah, I mean, if you say you want to do air correction, you're going to flip bit 1, and then you have the wrong answer. So you'll flip bit 1, you will not have flipped bit 4 and orbit 5. Because you have only having distance 3. And so if you have two bit flips, what happened in terms of the neighborhoods was this, that we have our original code word, which is this one. And one of its neighbors is, for example, the x-5 that being mistaken. And then over here, we have another code word, which is, let's see, 1, 1, 0, 0. Let's see, 1, 0, 1. And then here, one of its neighbors, which is 1, 1, 0, 0, 1, 1. Let's see if we can get that one. So the way the hamming code works for air correction, it says, well, if you're in this neighborhood, I'll assume you got that one. You came from that one. If you're in this neighborhood, I'll assume you came from that one. But what happens with two bit flips is, well, start here, there's one bit flip, there's two bit flips, now we're in the wrong neighborhood. So if you correct, you get the wrong answer. If you want to correct two errors, you need actually hamming distance 5. If you want to detect two errors, you need hamming distance 4. Then you'll know something when wrong. That's a sec-dead code. Yeah, that's right. Okay. Oh, it doesn't matter where so long as you remember, it's the parity bit. Yeah, it would be parity overall bits in the hamming code. So for example, you put it anywhere, as long as you know, that's the parity bit. Yeah, it's just like I put it on the right side, but as long as you know, it's the parity bit, you could put it anywhere. Yeah. I mean, when people do transmission codes, they tend to put it at the end because that way you can calculate it as you transmit. You transcend all the bits, and by the time you've done, you've xored all the bits together, and then you know which bit to send as the last bit. So people usually put parity bits at the end. And that you're wasting bits on your correction code, to some extent. I mean, usually those will go in higher end storage systems. I'm trying to think of what the actual codes used to format information on the drives themselves are a little different because you're physically writing magnetic fields on the hard drives. And so they're actually two dimensional codes as well, because you've got a surface area that you're writing on to. So so there's substantially more complicated in terms of you figure them out and how you manage air information. Yeah, the kind of the kind of hamming distance five stuff I was talking about is usually for high end storage systems where you have lots of separate disks and then you'll use hamming distance five codes across disks. So if you have a disc failure, for example, you can deal with that kind of stuff. Or if you have bits being crafted over time as well. Yes, it doesn't matter. The order doesn't matter. The order is purely for us to know where to go find the bits to include in each of the equations and things like that. In some areas, but not all. Yeah, sometimes, sometimes. Okay, wow, we're nearing the end of the hour. Okay, I may spend some of the time. Maybe let me get started on some of the advice stuff and then they will finish it up on Wednesday. Switch back. Okay, so Sanjay Patel and I came up this came up with this. Wow, maybe 12, 13 years ago when he started teaching with the book patent Patel here at Illinois and he taught the first first time he taught. And I came up with a list of what we thought we should tell our students as they left the class. Right, and so this list is from that. So I should give him credit for most of it. So one one thing is take on a big project in the next few years. So, you know, the stuff you do in class will be useful and we try to make it fun and exciting and worth your time. But if you really want to learn stuff, the best way is to be self motivated and driven and those kind of things will be good to talk about when you go to career fairs and when you go out and even grad school. So figure out something that excites you and go spend some time on it. You can go to the place next to daily bite. There's there's student offices there. They have all kinds of projects do something with the OH is all kinds of things you can do. Do something do something that you could talk about say, hey, I worked on this really cool thing when I was an undergrad. I'm going to use a debugger. So you've used the LC3 simulator, which kind of helps you walk through things and see what's going on when you start doing see programming. So you can go to the debugger that will help you because it will help you look at state as the as the programs in the middle of executing. And for us, it's hard to know when to give that to you because some students will not need it yet, right. Their mental model of what's going on in the program is so good that the look at this thing and say, so I'm going to spend 10 hours learning that thing when I know how to fix my bugs. Wow, you're crazy. This is a waste of time. And then by the time to go back and realize that what we told you for a reason. And then I had some of the keyboard for a while. And then other students, you know, they could have used it three weeks earlier. So it's always hard for us to know exactly when to give it to you. But at some point, your bugs will be hard enough that a debugger will make your life vastly easier. So there are tools that will help you. They're like the LC3 simulator. You can go step by step. Say, well, what does this next instruction do? Let me watch. They do one instruction. So the same sort of thing, except in a debugger, usually AC statement, do one see statement. Let me look at the rest. Don't put off learning about tools. There are tools that'll be useful for you scripting languages, things like that, MATLAB. Don't put it off because they will also make your life easier. Right. Why are they there because someone ran into some problems that were painful to keep solving. And so they made a tool for it. I'd like you to know how to matrix how to multiply matrices and invert matrices. But if you don't want to learn that, you can go use MATLAB, for example. All right. Avoid optimizing prematurely. So, you know, it's very tempting. Engineers like to optimize right. They like to go down and like make everything perfect. So when you're working on bigger systems, you know, don't spend your time on things that don't matter. Right. Be careful about where you spend your time. If you, if you have something called amdol's law, if you have a program and part of that program takes 1% of the time, and then you make that go 100 times faster. Well, the other 99% still just a slow. Right. And so at the end, you're not going that fast. Right. Don't spend your time making things go fast unless they matter overall. Don't spend. Be careful how you spend your time. There's some quotes on that that maybe I'll skip it. All right. This one has a story attached. So I'll do that one on Wednesday, and I'll try to keep the rest short for you so we can do. We can do review session. Thanks. Oh, yeah, no more material. Unless you want my advice is material. I will. You You You You You You You You You You You You You You"
    },
    {
        "ECE120-2016-09-21-LEC-12-slides.mp4": " I'm going to jump that briefly before we talk about material. People, okay. So we are splitting up the midterms to come up with rubrics. We're going to grade Saturday, the 24th. So you should see your grade on compass, hopefully, about anything. But I look through about 20 exams on my problems, which were two of the six. And people are doing pretty well. So I think overall we were pleased, at least I'm pleased so far. So I think people did well. I was a little surprised. Other people's rooms, I think, left a little earlier than mine. So that I was worried about that, that, you know, it seemed like maybe it was too long if we designed it for 45 minutes. And we hit the 50% mark at about 827, which seemed a little too late. That 50% of the people had left my room by about 827. So, but other rooms, they said, we're leaving earlier. So maybe it's okay. I think that's a lot of people are calling. Yeah. Yeah. Yeah. No. So the comment is that a lot of people were probably just hanging out and taking work. So, yeah, I understand that. But on the other hand, when I've done two hour exams designed for one hour in the past, usually they're not staying at the very end. They're staying, you know, a little extra and then, and then maybe. So we'll see. I think people did well as the main message. So. All right. So today we're going to go over Boolean properties. I'm going to start with duality and use that to kind of look at a few things. So we'll go through several several results of the duality property of Boolean algebra. Then we'll take a look at what we call don't care outputs, which are outputs of functions where we don't care what the answer is for various reasons. So the examples of those. And then we'll actually do an example using don't cares and seeing that we need to be careful about when we say we don't care. So. Yeah, I know that's great. Okay. We'll come back to that in real detail later. All right. So. I wanted to just review and then maybe ask you a question. Professor Veridane said that that he wasn't quite sure that you got one point in the notes. So I'll ask you after I kind of get you back into the speed of things with these couple of slides. So hopefully you remember and you've done several K maps by now. Or maybe you just put off K maps and studied for example. If you remember K maps, you know, your goal is to pick a minimum number of loops of maximum size that together cover all ones that'll give you an optimal. So P form for amongst SOP expressions by our area heuristic for four or a few variables. Sorry for all the caveats, but if you really go to bigger variables than these two metrics are not quite equivalent. It's not really optimal. But for the K maps that will have you solved their optimal in the area heuristic. What you won't see is you won't be able to compare directly with POS or XOR. So XORs will not come out of K maps directly. You'll have to identify them yourself. And POS to do that. Hopefully you remember you draw loops around zeros instead of drawing ones. You make them as big as you can. You cover all the zeros. And then when you when you calculate the the POS factors for the loops don't forget that the variables the literals are all complemented relative to the implicates you would get for an SOP form. So hopefully that made some sense. Unfortunately in the tools he sort of when I wrote the K map tool I deliberately left out POS thinking well, you know the goal is not to have you do tons of exercises with both just to understand that you can do you can do bowl. And you know SOPs kind of the main one just to get some experience with optimization. And then midterm sometimes we'll ask about POS and sometimes I'll ask about SOP and we tend to go back and forth. So if you want more experience you can actually go to the to the layout tool of the logic design tool and that will give you K maps where you can do POS solutions and and the K maps will be marked properly. So use that tool instead. You can also say skip step and it will show you how it will be marked but you can do it and then check the answer. So use that tool if you want experience with POS. So one question professor very to end said he wasn't sure that people understood why a single if you have a function which is a single mangator single norgate you understand why that's both POS and SOP form. And then we can draw it and then the trick is to just you know use to morgan's to move the inverter across the gate and then it's either a single product of several sums or it's a single sum of several products and single literals. So one gate is basically both POS and SOP one CMOS gate. So William algebra has this kind of cool property called duality so the dual of an expression we can find as follows we can go take the expression and look for zeros and ones and swap them. So if you see a zero you replace it with a one you see a one you replace it with a zero and then look for hands and or swap and with or swap or with and that gives you what we call the dual. Right let me give you an example so upon top is an expression and so to find the dual you just do the swapping so replace one zero with one one or zero or the pluses with with multiply and with or vice versa. And what we get is this thing down on the bottom right so the dual of the top is is down here on the bottom and then you say well what's the dual of the dual well of course. If you swap again you get back the original expression and all we're doing is swapping zero and one swapping and in or. So the dual of the dual is the original expression and that's where the term duality comes from and so there's two aspects of the same thing. Yeah that's a good question let me answer that on an up kind of an slide what do you what do you care about this right it's kind of hey that's cool but who cares. Yeah so so literally if you look at these two right the end here becomes an or the or becomes an and the one becomes a zero the zero becomes a one and becomes an or everywhere you see an or you read an end everywhere you see an and you read an or zero becomes one one becomes zero. So it makes sense. So we're good except why do we care. Okay so before we get to why do we care one or two more slides so be careful don't change the order of operations. So I picked that previous expression kind of carefully and put lots of lots of parentheses in it but if you write something like this do not just replace and an or do not just swap those two you need to add the parentheses so that the B. So if you change the order of operations that is no longer the dual. So be careful with that when you're taking a dual. So why do you care so three reasons well let me explain them briefly and then we'll go back to each of them in more detail so first of all when you look at a CMOS gate actually the network on top of P type mouse bets and the network on the bottom those are actually dual bully expressions. So if you're using dual bully expressions and I'll show you a non-nant norgate a little later by simply taking the dual. So that's kind of useful if you want to build a more general gate structure out of mosfets. It's also a quick way to complement any expression so I'll show you a complicated expression and then simply use duality to find the compliments instead of recursively applying to Morgan's which is both air prone and painful. And then finally this principle of duality so let's start with that one the principle of duality says that if I write down an identity or property of bully and algebra. Then the dual of that identity or properties also true. Well if it's false it's also false and it's true it's also true so it has the same logic value. So we're going to use that in a little while to basically expand all of the different bully and properties by simply taking their tools to find new properties and you'll see a lot of the ones that you've already know intuitively are actually duels of one and so we'll use that in a few minutes. Okay so the second one on that list generalized demorgans so let's say we have this expression f and I want to find f prime. So one way to do that is we'll say okay so I put the prime on the outside of that and then I applied to Morgan's and then maybe have to keep applying to Morgan's over and over again until I get rid of all of the different steps inside of that. So that's kind of painful or we can use a generalized version based on duality so right to dual form swap the variables and the complemented variables and that's it. So that's it. So if you can write the dual and then you can go through and you know if there's a variable you can add a add a prime to it and if there's a variable complement you can cross out the complement and you're done. So a little easier than rewriting each step through demorgans laws. So here's an example at the nasty looking one right. If you want you can do this by hand to verify that I get the right answer. So what's f prime. Anyone. Yeah it's not that fun looking is it. Okay so first we'll write the dual. So here's the dual all I did is I took the end that replaced them with or I color coded the parentheses so you can kind of line them up visually. But it's all the same and become or is or is become and there no zeros and ones. And then I go through and a becomes a prime b becomes b prime l prime over here becomes l. So the second step is to just complement all the literals either from uncomplmented to complemented or vice versa. So then we're done that's f prime in a fairly nice form right without lots of extra compliments on anything. Yeah. Yeah so remember on the variables are the compliments of the literals. Did you mean there no zeros and once. Okay. It's okay. It's not that question. Anyone else have a question on this. So at least I think this is relatively easy compared to going step by step right so if you go step by step then first you would. I can parse this you've got this big expression here so you deploy to Morgan's this big and and you get a prime or b prime or complement of this thing right which then if you kept going you'd eventually get this right but you have to go step by step. You can do all the steps at once using the dual form. Yes yes so when you take the dual form you do have to swap zeros and once so normally we very rarely write equations with zeros and ones will do that in a few minutes for our properties but most of the expression you care about don't have zero. How do you change the variable. That's a good question. Yeah only the variable. Yeah so if you think about if you said F F equals zero and then you take the dual you get the dual equals one and then if you compliment it again you get F prime equals zero which is wrong. So zeros and ones you compliment when you do the dual so you don't compliment them again which may be what you're thinking about before. Okay so once you get familiar with this you can just skip the middle step and just write it out and as you go change the change of variables to the compliments or vice versa and change and more. Be careful again about the parentheses right don't let the order of operations change. Alright so this then I kind of find the coolest part so if you look at the CMOS gate structures. The type the network of of mosfets on the top. The P types on top the n types on the bottom those two are actually duals of one another so let's think about the n type and let's assume that we've got a gate where we've got four n type arranged in parallel. So the output is connected through four parallel n type mosfets down the ground. So in that case if any of those four transistors is on then the output is zero right so the out those transistors let's say are controlled by input ABC and D so Q the output is zero of any of the transistors is on in other words if a or B or C or D then Q is zero. So Q then of course is that value complement right so Q is Q is zero when any of those is true that's an or gate for input nor gate. So think about the sorry think about the P type on the same gate so if you've got them in parallel on the bottom there in series on the top right so those connect Q up to the DDD but in order for the connection to be made all four of those transistors have to be on. So when are they on well they're on when each of the inputs ABC and D are equal to zero right having those equal to zero is what turns a P type on so in other words we have to have a prime B prime C prime B prime and that's Q but those two are the same. Both the nor gate so you can actually derive derive the output for properly formed gate by looking at either of the two and what I want you to notice then is that ABCD form right looking at it this way here I have ABCD prime a B or B or C or D complement it. So if I were to then take the dual of of ABC and D and I get ABCD and if I were switch those I get a prime B prime C prime D prime which is I get which is the same expression I get if I derive Q from the P type transistors instead of the entire. So we can get this equivalence two ways one is by just you know deriving from the forms but the reason that works is because the networks of transistors are actually the doors. So in this case the duality comes from the structure of the networks and the compliments come from the use of P types versus ant types right that the P type transistors turn on when we put the when we put the opposite value in and from the ant types right P types turn on with the one and types turn on with a zero. So that's where those two come from. So we can we can make use of that so this sorry this is the explanation I was just giving so the dual form is actually built into the gate design right so the upper and lower networks around the output or actually duals of one another and. So the flipping of the compliments comes from the use of P type versus ant type so let me give you an example of that so here's kind of a strange looking gate that you look at that and you say wow what does that do so you can again derive it from from either expression if you look at the bottom for example. And q goes down to ground if a or b is on and see right so a plus b and it together with c and then complemented because going down to ground means q equals here. You get the same expression by going upwards and saying well q is equal to one if a prime b prime or c prime and you'll find of course those are the same but the dual if you were to instead say well what's the dual of this expression not with the complement but what's the dual of this expression let's a and b or do it see this one down here. You look at the p types up here you've got a and b over here or with c over here and so that's the structure of the p type network so you've got the duality between the p type network and the n type network. And that ensures that you don't have a short and so if you think about well what happens if I don't make them do all right I can put transistors wherever I want. And really if you're not careful if they're not duels you have a pretty good chance that there's some input combination that will give you a path from VDD down to ground which will destroy your destroy your chip. So what was the third use of duality question. Yeah that's where I got this one here from the from the n type network down on the bottom half so the parallel construct is an or right because q can give is connected to this dot here if a or b. Then one of these transistors will be on and q connects electrically down to this point here. Now to get to ground this transistor also has to be on so we end the a or b with c. And that says this transistor is also on so if we have a or b ended with c then q is connected to zero. And so in order to get the actual value of q we have the compliment. Yeah forward backwards. Okay this one. So remember that the so the dual structure comes out of the networks. Okay so this one is parallel and this one is serial. The compliments come out of the n and p types so in order to turn the transistor on for an n type you put the value equal to one for a p type you put it equal to zero. So for all for all of these four transistors to turn on a prime has to be true b prime has to be true c prime has to be true and d prime has to be true because these were derived from the p type transistors. I didn't draw this one so let's let's look at this gate. Here for example if you look at the p types I have chalk. Okay you look up at the p types then what you have is a prime and b prime. Because in order for this connection on the left from q up to b dd to be electrically connected these two transistors have to turn on to turn on a has to be zero and b has to be zero. So this is a prime b prime. And this path here is c prime. So if either of those two paths is on. I get an electrical connection sorry I think I cut off from the left. So this is this is what I get if I write the value of q from the p type network and this one here that I've written is from the n type network that you can see if I apply to morgan's to q equals a plus b. And it was c was it. So remember I would take the dual so I would get a b or c and then complement all the variables. That's the same thing. I applied generalize to morgan. We could also apply it one step at a time if you'd rather which would give you an intermediate step of a plus b prime or to see prime and then when you apply to morgan's again you get this one. You mean if you wanted to produce a gate that had the complement and output. Yeah, so you so you could imagine if I have to write q in a form that has only uncomplmented literals because those are n type MOSFETs and then with a complement at the end I can't express any arbitrary Boolean function that way. So I don't have complete freedom actually. So what you would typically do is if you really needed say this function here without the complement will put an inverter after it. So you you could build it by playing the trick of swapping n type and p type but that would give you problems because of the way they work as we talked about when we first discussed MOSFETs. Well, so the things you can build with with MOSFETs are the ones where you have a complement outside an expression formed of uncomplmented variables. So those are the things that you can build directly. You can build all functions of course it's an in mandinor both logically complete. And so if I can I can build anything with MOSFETs but to build a gate directly the expression I get has to be of this form. So this was just an example of the kind of thing you could do. So one question might wonder is well why don't we do more of this right if you want to build an add or some other circuit why don't we go down all the way to that level. Now let's take a look at the area and speed. So the function here that we just derived to require six transistors and one gate delay you saw the you saw the diagram there's six transistors and it's one gate delay because it's basically a gate the gate like structure. So six transistors and one gate delay now if instead I said I want to build this out of mandinor well then I would have to do this right I could write q equals a prime b prime complement it ended with C complemented that would be a two input n to produce this value. And another two input n to produce q so I could use two two input n's so each of those two input n's is four transistors and it's two gate delays right so eight transistors and two gate delays so it's bigger and slower. Well gee what do I want to just go down and optimize most of the time people are not going to do that right they're just going to use n and nor even higher level when you get into class like 385 you're going to find you're actually writing something like C. You use a language called system very log to describe your hardware you'll say hey I want to add some numbers together go produce an adder for. So in fact people aren't even aren't even getting down to the level of gates much anymore. So why not why not go optimize well the problem is the more time you spend optimizing breaking that abstraction boundary the more likely or to make a mistake right the more likely when you make any change that you've got to then go do redo a lot of your work. So it's a big cost of human productivity at often a small advantage in size and area to the extent you can get your tools to do it your computer tools then the computer tools will do some of this kind of optimization for you but but in general that abstraction boundary saying well I know how to build gates like nand and nor give me a library of those gates let me plug them together or give me a library that includes an adder and I just want to be able to put an adder some of the other components you've seen a few weeks. People are usually working at the higher level in order to be more productive question. So that's the reason right generally speaking if you're willing to go down and optimize by hand you're going to get some benefit but remember a typical processor has billions of transistors right so if you look at every transistor for five seconds you're not going to finish in a useful product time right. Yeah so certain companies do do do custom logic right so companies like intel apple and Samsung together do custom logic for the most part almost no one else does a couple of networking companies but for the most part other people use standard standard libraries in designing the hardware. Yeah. That terribly a lot system very log has a little more object oriented capability also what's what's known as high level synthesis the ability to describe things in a more flexible way at the possible expense of not being able to synthesize them so sure people who use them every day would argue vehemently that one is just nicer than the other practically speaking you can do pretty much anything in either system very log is a newer language and also gives you this high level synthesis benefit which which has some some advantages and some disadvantages right kind of similar to this actually that I'm not sure let's take it offline and I'll see if I can find ways to get you something to play with. Okay anything else. Okay so let's take a look at some boolean properties so these are the easy ones you probably already know them intuitively but they're kind of useful to commit to memory if you haven't because when you take a look at a circuit as you'll you'll end up doing several times in in our class many times in our class being able to analyze it quickly is useful. So we'll ask you to look at something and tell us what it does and being able to just go through so for example you probably remember that if you or one with some variable outcomes of one right so any any time you have an or gate you put a one in you get a one out similarly this is the dual over here so if I take the dual I get zero zero and I get or replace by and so it says well if you take and you and something was zero you get zero right so those two properties are actually dual someone brother the similarly if you and something with one you get that something if you or something was zero you get something those are also tools if you or something with itself you get it back if you and something with itself you also get it back if you and with its complement, you get zero, if you or something with its complement, you get one. So all of those properties, relatively simple properties. But if you memorize them enough that you can spot them quickly, then you can start crossing out pieces of circuit and thinking about what happens in partial cases. So the kind of useful properties to memorize, and they're pretty simple. Demorgans laws are also dual forms. So they're two demorgans laws. So if you write one of them, you get A or B complemented equals A prime, B prime. And if you then take the dual of that, you'll get the other demorgans law. And so they're just duals of one another. So I walk through that one. So what about distributivity? You probably remember this from algebra. So if I write, if I say, well, if I take some number A, and I multiply it by a sum, B plus C, well, I can distribute the multiplication over the addition. So I get A times B plus A times C. That also works as well as an algebra. And distributes over or. So here's kind of a weird thing. So what if you take the dual? What happens if you take the dual of this just distributivity law? Or distributes over and. So that's kind of weird. It's not intuitive. So if you're trying to manipulate Boolean algebra, you'll want to remember this. I mean, I don't think you have to manipulate Boolean algebra much. But this is what it would look like in our usual algebra. This is just wrong. But in Boolean algebra, it's right. So because of duality and because of the way Boolean algebra works, you can actually take this or and say, OK, A, A, B, plus A, C. I'm sorry, A plus B times A plus C is the same as this expression here. It's tributy big or over the end. All right. So one more property called consensus, which is just kind of not intuitive. If you have intuition looking at this, good for you. I'll show you graphical reason to try to give you some intuition. But I find it a little bit difficult to understand. But basically, the way it works is if you have two terms where you've got two variables and then the other variable is a complemented variable. And then you've got a third term, which is those two variables and it together, you can just throw that one away. You can just cross it out and you get the same expression. So on the right, all I've done is I've taken the two left terms and then dropped the right term. So this is called consensus because when these terms are true together, this one is implied. That's where the term consensus comes from. The consensus of these two terms implies this term. So I find it not intuitive algebraically. So I'll show you KMAP. So the green ones are the two terms that we're using on the left. So AB is the vertical green loop here. A prime C is this loop, the green loop down here. And BC is the black loop. So you can see, well, if I put ones for those two loops, then this loop is also true. It's also an implication. So that's consensus visually. Using it algebraically, you've got to spot the matching between the variables and the complement. But at least, hopefully, after this, you understand why it works in the algebra. I don't. I don't. But you've got some expression in general. It could be more than a variable, but it's B here. It could be an arbitrary expression, but another arbitrary expression, C. And then, ended with those two, you've got a variable and its complement. And then the third thing that you need, the thing that you're going to cross out is the two expressions B and C ended together. Yeah, B and C can be expressions. And I think a complement could also be expressions, A could be an expression complemented. Yeah. Or distributes over N. So you know the principle of duality. And you take this one and you get the dual. How it actually works is here you've got an OR that you would normally apply after the N. And instead, you take the OR across each of the factors in the product and then you multiply those ORs together. Which is what you get on the right. And so you take A OR with B, A OR with C, and multiply those two together. If you had BCD here, there would be A plus D. Makes sense? Yeah, it's somewhat not intuitive, of course, because you would never do that in our normal algebra. Yes, yes, yes. The principle of duality says that if you have an identity, which means an equation, or a property, and you take the dual of that, it has the same truth down. Yeah. Yeah. Yeah. Yeah. So the A's have to match except this one is complemented. And then this B and this C have to show up here. So you can have variables. You can replace A, B, and C with arbitrary expressions, but those would be harder to spot. Yeah. So we're not going to have you do a lot of hand-based bullying algebra optimization. These days, the CAD tools will do it for you. But if you write the next generation of those tools, you need to understand this stuff, because you're going to have to write programs that use these optimizations to manipulate the expressions internally to the program. Yeah. All right. I mean, the underlying math is yes. So what's done these days is there is something called binary decision diagrams that try to split the space somewhat optimally. So you look at your function, you try to pick something that will divide it well evenly. So you pick one of your variables, and then you say, well, this is the best variable to look at first. And then you do the same thing recursively. So those are what's used in modern commercial tools to talk about functions and to compare functions. And it's well beyond the scope of the class. So don't worry if you're OK. So this was the consensus illustration. And consensus, of course, has two forms. You can take the dual. So if you take the dual, you'll get this one down here, which I won't show you came up. All right. You could do that one too. So that's it for boolean properties. Yeah, I think the main ones to learn duality is useful in practical sense of designing gates and also taking the complement of arbitrary expressions generalized to Morgan's. But I think the short identities for analyzing circuits just knowing that if you put things together, you've got a one with an end. Well, you can ignore that input. Zero with an end, a zero comes out. Those kind of things. Those will help you analyze circuits quickly. Some of the others are just useful for doing algebraic optimization or equivalence. All right. So let's talk about don't care outputs. 15 minutes or so, little more. So sometimes we don't care. So we've got a function. We don't care whether particular input combination generates a zero or one. So when would that be the case? So in some cases, we may say, well, that input combination can't happen. So for whatever reason, it's just impossible to get that input combination. So the output doesn't matter because we're never going to generate it. Our system will never generate that output. So who cares what it is in the equation? Sometimes also you'll get designs where your hardware is part of a bigger system. And you know that if you get that particular input combination, whatever your system outputs is ignored. So who cares what you output? It doesn't matter. So there are a couple of common cases where we don't care what the output is. So what good is that? And in such a case, we can mark the output as an x, which means don't care. So instead of writing a truth table with zeroes and ones on the outputs, we can put x's. And that says, well, either zero or one is OK. Now be careful, because whatever you actually build will not generate an x. Hardware does not generate x. It generates zero or one. So whatever your design ends up being, it will generate zeroes or ones. So you need to make sure before you go putting x's that it's OK to have any combination of zeros and ones for those outputs. Because if some combinations are not OK, you actually do care. So why is this useful? So more choices means a better answer for pretty much any choice of metric. So say you optimize a k-map for some function f. And then you say, well, maybe I don't have to use f. I could use g or h or j. So the best answer amongst those four is always at least as good as the answer for f. Because you could always just say, OK, I'll pick f after all. So you're never going to get worse. You might not get better. But in general, you can get better. And you can never get worse if you look at more functions. OK. So using an x actually means that you're looking at many functions. Each of those x's gives you two choices of function. You could pick the function that has a zero in place of the x or the function that has a one in place of the x. So if you have n-axis, that means you're picking from 2 to the n possible functions. So if I put 4x's in, I've got 16 functions I'm picking from. And I'm going to pick the best of those 16. And so often, that's going to make my logic simpler. So that's why instead of saying, well, I don't care. Let me just put a zero or let me just put a one instead by putting an x and get better answers. Let me show you how that works. So here's an example of a function. And what I've done is I filled in the answers I care about. So I filled it, I've partially specified my function. I put some zeros and ones in. I'd say I need to generate this function. And I don't care what the outputs are here. So let me put in x's there. So actually, let me show you what happens if I do something different. So if I put in zeros, say, OK, I don't care. But I'll just put zeros. Then let's solve this K-Map. So what do I get for this K-Map? What loop should I circle? The one-one loop, if I did that one first. Yeah, one one. I thought I understood, but maybe I didn't. I circled that one first. It's one-one at the top. Yeah, bottom left wrapping around is the other one. Good. So we've got those two. And I think we're done. OK. So that gives us a, b, ord with b prime c. Yeah, that's not too bad. I say, OK, it's a nice function, not too challenging, a few gates. But we didn't have to pick zeros. We could pick other values. So what if we pick a 0 and a 1? So let's put a 0 and a 1 there. So now what do we get? Let's solve. So we still get that one. We still get that loop. And then the one on the bottom goes all the way across now, right? So now our function f is just a b plus c. So we got rid of a literal. So if instead, I mean, again, I didn't care about these two outputs, right? So if I'd picked a 1 here instead, well, then I'd have 1 if you're a literal couple, I save myself a couple of transistors, a better answer. Well, so instead of going through all four possibilities, here there's only four. If you had more unknowns, more, I'm sorry, more don't cares, then you'd have to go through lots of functions. Instead, let's write x is into our k map. So now we're going to have slightly different rules. So the rules are going to be, I want to still grow my loops as big as I can, but instead of only covering ones, I can also cover x's. X's can be 1. So I can also grow a loop to cover x's if I want to. And I still have to only cover all the ones. I don't have to cover x's because x's could be 0's. So that's the modification to our rule. Grow loops as big as we can, possibly including x's, just still cover all the ones. And the same thing if you wanted to do a POS solution, grow loops as big as you want around the zeros, you're allowed to include x's, but you don't need to cover the x's. You only need to cover the zeros for PLF. So same set of rules. So now if we solve this function, now we're actually able to grow out to the left for this loop. So instead of just this loop here, now we can include these two x's. So it's gotten bigger. And then on the bottom, we can also include this whole row. So what's the answer? Well, b plus c. And that's the best of those four. So instead of drawing four different k maps, solving them all and then comparing, I can just write x's into my k maps, modify my rules for solving it slightly. And then I'll get the best answer amongst 2 to the n. And here is 2, 2 x's. Yeah. Yeah, so that's a good question. So what actually happens to the x's? Because as we talked about earlier, whatever you implement will generate zeros and 1. It will not generate x's. So the x's, if they're inside a loop, those will become ones with the function. If they're outside all of the loops, they'll become zeros. Yeah. So if you solve the k map optimally according to these rules, and technically you'd have to look both for POS and SOP forms, because those are not necessarily optimal relative to one another. But if you simply solve it following these modified rules, you will get the optimal SOP form. And if you solve it following the modified rules for 0, you'll get the optimal POS one. Yes, but you're doing it in a way that you make your loops as big as possible without adding extra loops. Yes, yes, yes. So the modification has grown the loop as big as you can. You're allowed to include x's. So it's the same rules. You're allowed to include x's, but you don't need to cover them. Yeah. So hopefully that's clear. The tool does allow you to practice and check your answers. So if you feel like you're not sure, go play with it, do a couple examples. Any other questions? And we'll actually do a couple more of your apples in class. OK, so yeah, so you'd ask, well, are these zeros or ones? It's a good habit to put the zeros and ones in place of what you got. Make sure that answer is in fact OK. So these two become ones, because they're inside of a loop. We didn't have any x's that are outside of all of our loops. So none of the x's in this solution become zero. And we also don't have any context for this example. I just said, here's a function I want. Now, if you have a bigger context, you should evaluate this full solution in that context and make sure that it's actually OK. All right, so let's do an example. I'm getting hungry. Let's have some ice cream. The example in the notes has leachy, but I couldn't find leachy. I was a little disappointed, but the stash was pretty good. So it gives like ice cream. OK, so do an ice cream dispenser. I expect this to work by EOH, by the way. So I can eat ice cream at EOH. All right, so three of us are going to do this. So three buttons in-foot. So we're going to have mango. We're going to have three kinds. You can pick mango. You can pick pistachio. Or you can pick a blend. And there'll be three buttons for you to push. You pick which kind you want. And then out will come the control outputs for the actual mechanical dispenser, which will be two bit unsigned numbers that say the number of half cups of mango. And so it could be 0, 1, 2, or 3, half cups. And the number of half cups of pistachio. So we'll design using this set of inputs and outputs. And we'll build the logic in between those two. So let's write a truth table. So help me out here. So what happens if I push M, I want to get one cup of mango. So what should I write for CM and CP? To remember, it's the number of half cups as an unsigned number. So what should CM be? Yeah. So when M is 1, so down here, 1, 0, 0, CM should be 1, 0, I think. We want two half cups. So one cup of mango. What about pistachio? How much pistachio should come out when I put the mango? 0. OK. So the second case, I push B, the blend. I want to get half a cup of each. So where's blend? So blend there, 0, 1, 0. So I push the blend button. How much mango should I get? 0, 1. How much pistachio? Good. All right. So then the third option, I push P, the pistachio button, I want to get one cup of pistachio. So let's see. That one's here, right? 0, 0, 1. So how much mango? 0. How much pistachio? 1, 0. Good. And then the fourth one I have to worry about, well, if I don't push any buttons, no ice cream should come out, right? OK. So that's the 0, 0, 0. So what mango I should get? 0, 0. And pistachio? Good. And what about the rest? Tough. That's it. You know, I just don't care. All right. I don't care. Who cares? I'm feeling the person. Yeah. I don't care. Yeah. Oh, very good question. Let me come back to that. OK. All right. Yeah. This is a problem with trusting the human, isn't it? All right. So we can copy these to K-Maps. So let's start with CM. So to copy to K-Maps, I put these in an order where the last two variables are across the top and then the first variables there. So we're going to copy, well, let me just show you the order. So we're copying these blue ones, the high bit of CM. So the first row is a 0. So that goes in the upper left. And then we're going to copy to the right. Now, this one's gray-coded. So instead of going here, which is 0, 1, 1, we're in binary order over here. So 0, 1, 0 is actually on the far right. So we'll say 1, 2, over to here, and then back. So 0, 0, 0 goes there. The x goes in the 1, 1 slot. So you want to get used to this so you can do it quickly, copying from truth table to K-Map. Remember that your truth table is typically in binary order, your K-Maps, and gray code order. So you've got to make sure to switch them. Otherwise, you get the wrong answer. All right, so for the bottom, we've got 1xx, the 1, and then the x's are just filling the rest. So what's the answer there? Solve that one for me. Let's do SOP in question. In this case, it's actually the same, I think. But yeah, OK, so M, right? But my loop is SOP. OK. So the high bit of the mango output is just the mango button. Good. Not even a gate. So excited about my ice cream. All right, so let's do another one. So what about the low bits? So now I've highlighted the bits of the low bits there. So if I just copy this over, here I've got 0, 0, 1x. So I'll fill that in 0, 0, 1 on the right side, x in the 1, 1 slot, and then 0, xxx, 0, xxx. So what's the solution? D, like that. OK, good. OK, so the low bit is just the blend button. Hey, I don't even have a gate yet. Just some wires. That's nice. We can do pistachio, high bit, 0, 0, 0, 0, 1, 0x, 0xxx. Cancer, B. OK, and then the low bit of pistachio, 0, 0, 1 on the right side, x, 0, xxx, solution. D again, huh? OK. Good. So there's our design. Very easy design. All right, the x's made our life so easy. We don't even have to have a gate. Just take the wires, connect M to Cm1, connect B to both of the 0 outfits, bits, and P to Cp1. We're done. Very nice. Very cheap. So what happens? Mohamedu asked this question. So what happens if the user presses M and B at the same time? Bad human. Who cares? The janitors care. You're going to find out. All right. So we'll put that in. Let's say we put that in. What comes out? Well, 1, 1, 0, and 1. So we're actually getting a 1, 1 in our mango control. So ideally, what that means is, well, 3 halves of mango and 1 half of the pistachio. So maybe it overflows the cup. That's the good case. We hope that what happens is it overflows the cup. Now, unfortunately, the person who designed the mechanical dispenser may have assumed, well, they shouldn't be giving me a 1, 1. So something bad actually could happen. If you give them a control that they don't expect, mechanical systems may not be that flexible. So if you send the 1, 1, ideally, yeah, it just spits out too much ice cream and someone has to get a mop. But worse things could happen. So we do care. Using don't care when some human striving is just not a good idea. You got to be careful. Don't assume that they're going to follow rules. OK. All right. So how can we fix this? One choice is we could pick specific outputs. We said, well, let's just pick zeros. You push two buttons to get nothing. You push three buttons to get nothing. So instead of saying x, we'll say zeros everywhere. And just fill in all of our cam apps. And then we can solve that. We'll have a bunch more gates. And that'll give us one answer. Another way we can do this is to actually add some logic in between the inputs and the outputs to do what Muhammad suggested initially, which was keep the humans from pressing more than 1 button. So actually a few choices there. Here's one of them. So what this one does is any time the human presses more than 1 button, it forces all the outputs to 0. So this dotted box is just some extra logic between our inputs on the left and our outputs on the right. And so nothing has changed except I put a little logic device here. And you can see that this AND gate up here produces a 1. Only when the human pushes mango, but does not push blend and does not push pistachio. And similarly, these two produce 1. Only when the human doesn't push another button at the same time. So that's one choice is to add what we'll call glue logic. But we're running out of time. So let me come back and go through this in more detail on Friday. But the main point is make sure that you don't care. Don't assume humans will do things. If you're working with another piece of logic, you can make assumptions."
    },
    {
        "ECE120-2016-12-02-LEC-38-slides-start-at-22-min.mp4": " you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you So, let's see. So today we will start. I know now everyone wants to talk. Okay. Okay. We want to start with air detection and then talk about parity and hamming distance. So this stuff used to be at the start kind of in with representation. So hopefully you can remember some of the things I'll kind of call back to things we talked about if we start the semester. But we'll look at parity, look at hamming distance as an idea of distance between two bit patterns. Think about air correction and then I'll introduce hamming codes and then sec dead codes which stands for single air correction, dual air detection. I don't know if we're going to finish this all today given that we did ISIS. So it's okay. We'll just spill over onto Monday. So if you think back to the start of the semester, think back to when we first did representations, like first day or two. So we said, well, a bit pattern can only represent a most one thing. So this one on the left where green is 1, 0, 0 and blue is 0, 0, 1. Well, that's fine. That's a good representation. But if we do something like this where we say, well, green and blue are both 1, 0, 0. Then computers that digital systems have no way of figuring out which one did we mean. So this is bad. On the other hand, it's okay for one pattern to be represented by two different bit or I'm sorry, one thing to be represented by two different patterns. So we saw representations like even IEEE floating point that had two different bit patterns for 0. And that's OK. It's also OK if some of the bit patterns are not used. So here in this design on the screen now, we've got four colors represented with the three bit pattern. Six of those are meaningful, some with more than one pattern per color. And some of the bit patterns just don't mean anything. Yeah, Eric? Thank you. I see it. I'm wondering if you set that. It's like you're referring to one more one for the presentable point of one. OK. You can't have two things which the things here are colors have the same bit pattern representation. Because then the representation is ambiguous. So this one on the previous screen where these two colors were both represented by the same bit pattern, that's not a good representation. I know. OK. OK. All right. So it's not symmetric. It's OK to have more than one pattern for the same color, but not OK to have more than one color for the same pattern. All right. So here's an example where we could do something like that. I mean, you've seen some already. But this example, this is something called binary coded decimal. This was used for a long time as the representation behind numbers in banking and things like that in business oriented software. In fact, the Kobo language would encode a lot of things using this sort of implicitly underneath. And then certain ISAs also supported it. So for example, X86 actually still supports it because it was in the original X86 design. So what is binary coded decimal? Well, you take your 10 decimal digits and for each decimal digit in your number, you code it as a four bit value just using the binary representation of that digit. And then these other four bit values, well, those don't mean anything. OK, so you've got six four bit patterns that just don't mean anything. And each of your digits is one of the 10 binary values from 0 to 9. Oh, no. So this is representing larger numbers as a sequence of digits. So if you wanted to have a number up to a billion, you'd have to have 10 digits in each digit would be four bits. So you'd end up having 40 bits instead of 32 bits in a more compact binary representation. So it's less sufficient. But it's easier when you want, for example, to translate this to ASCII, you don't have to do any conversion. Digit by digit, you just add the 0 ASCII character and then print it out in vice versa. So it's easier to use in some sense, but it's less sufficient. All right, so what else can we do with these things? Well, what happens? Let's say we have an error. So we see one of these six patterns. So you have a number stored in your system, supposed to be your account balance or whatever. You see one of these six meaningless patterns. Well, you know something went wrong. So if you have this kind of redundancy in your representations, you can say, sometimes, I'll be able to tell that something happened. So can we use this idea to try to fix errors? Well, so what's an error? So here's an error. I'll meet you right-land it on some things here. This is the crater in Arizona. It's kind of cool to visit if you've never been there. But certainly you can't deal with all errors. So some errors are going to be catastrophic. You can't say, oh, I built this system to be really reliable. If a meteorite lands on ECB, the system is gone. You didn't handle that. Unless you put a copy of your system elsewhere. So you can't handle all errors. Because catastrophes are always possible. And hopefully they're not common. So let's focus on errors that are more frequent. Things that'll happen a lot instead of things like meteorite sitting. So errors are nothing new. So when people wrote on stone, stone kind of weathered and things started disappearing. When people wrote on paper, paper could get wet, get crumpled, and so forth. When people write on flash, well, you put electrons here, and then they tunnel their way to freedom, and then they're gone. If you didn't know that about flash, don't ever put things you care about on flash. They will do that. In 20 years, your data will be gone. Don't do that. All right. So our class is going to use a model that's slightly different. That model I just showed you, all of those examples are what are called erasers. So the data are there. You see that there's supposed to be some information there, but you can't tell what it is. Because electrons got away, or the papers smudged, or the stone is eroded. So those are called erasers. We're going to look at a more difficult type of error where things are actually replaced. And so everything in our class is bits. So we'll look at bitflips. So instead of a 1, you see a 0. Instead of a 0, you see a 1. So that's our error model. So let me show you the difference using English. So this is erasers. I put dots in place of the missing characters. Can you tell me? Very good. Very good. OK. Here's errors. Exactly. That goes this way. Yeah. Now I kind of cheated. If you look really carefully at these, you'll notice they're both kind of compatible with one another. But in general, when you're doing coding and trying to correct this kind of things, erasers are a little easier than errors. Because with errors, you don't know what's wrong. With erasers, you know what's missing. So erasers are typically easier than errors mistakes. But you don't know what's missing. You don't know what's right or wrong. So here is a probabilistic model, sort of a bit flip model. So a bit can change from 0 or a bit can change from 0, sorry, 1 to 0 or 0 to 1. And if we assume that all of the bit flips happen independently of all the others. We have a lot of bits in our system. At some point, each of those bits might flip. We have some very small probability that any bit might flip. So we'll call that probability p. Then if we have n bits, the probability that one of those bits has changed, given the probability p for one bit and having n bits, is the probability that we pick one bit, which is n, times the probability that one bit flipped, times the probability that all the other bits didn't flip. So remember p is small, right? So this one minus p thing is usually pretty close to 1. And the chance of getting two errors is this thing, where this is the way to pick a pair of bits. And then this is the chance that any particular pair of bits two of them have flipped. So if you work out that math and you do the approximations, then this one is about n times p times that one. And in general, we pick np. If we know the probability, then we pick n such that np is much less than 1. And that means a chance of two errors is much, much less than a chance of 1 error. So when we design our systems, you have to guess or know by measuring things, well, what's a chance of one bit changing? And then you use that to decide how many bits you could protect. All right, so let's look at another code. So this is called a 2 out of 5 code. This was actually used in a variety of telecommunication and computing systems and things like that. So instead of mapping into four bits, this maps decimal digits into five bits. And so you might notice the pattern. Each of these bit patterns of five bits has exactly two ones in it. So each of the decimal digits then is mapped to a pattern of five bits with two ones. So it's less efficient. It takes more bits than binary coded decimal, which is in trend less efficient than binary or choose complement. But what's the advantage? So let's think what happens if we take some number coded with a 2 out of 5 code and one of the bits flips. So what bit flips? Well, we don't know. So let's look at all the possibilities. Could be this one flips, in which case we end up with this number here, this bit pattern. It could be that the second bit flips, in which case we get this bit pattern. Could be the third bit flips, that bit pattern. The red in these is just for us to remember which bit flipped. You wouldn't get to know which one. You would just see the bits. Fourth bit, this pattern, fifth bit, that pattern. Do you notice anything about these five patterns? Yeah, none of them have two ones. None of them have two ones. So as soon as you see any of these five patterns, you say, hey, something went wrong. You know something went wrong. You detected the error. So none of them means anything. So we always detect that single bit error. Turns out that regardless of which number I picked, I just picked seven. But if you go back and look at this list, any number you pick here, regardless of what the original digit is, if there's only one bit that flips, you can always tell. So with a two out of five code, you can always detect one bit flip. So that's error detection. Yeah, Eric? That's a pattern marker of bits that it's left by the digit. Like, which is that simple queue? No. Now, let's come back to that, because I'll give you an example. Yeah, so if you have two bits flip with a two out of five code, you can't necessarily detect it. Good question. But we'll come back to it. Anything else? Before we? All right. OK, so first, though, I want to try to generalize this idea. So let me go through that same exercise, but ask you instead a slightly different question. So we started with a two out of five code. This is just one example, the seven. And we said, well, we're going to flip a bit. So let's ask instead, how many one bits are there if we flip a bit? So there's two choices. We could flip a one or we could flip a zero. If we flip a one bit, how many ones are left? One. If we flip a zero bit, how many ones are left? Three. So regardless of which one we start with, now by this reasoning, now you should understand, well, it doesn't matter which one I started with. All 10 patterns had two ones. And so after I flip a bit, all 10 patterns will have either one one bit or three one bits. So it didn't matter which digit I started with. I can detect an error for any of the 10 digits. So what about other, I've just showed you decimal digits. What about binary numbers, letters, colors? Is there some general strategy? I mean, two out of five code only gives me 10 patterns. So what if I want to represent a floating point number? I probably don't want to write it out in decimal digits. So is there some way that we could use this idea to have error detection for arbitrary representation? So let's see. So we started with bit patterns with two one bits. And we said, well, if you flip, a bit flips from one to zero. We have one bit. And if a bit flips from zero to one, we have three one bits. So what if instead we started with an odd number of one bits? So all of our bit patterns have an odd number of one bits. Then what happens if say a one flips to a zero? It becomes even, right? What if the zero flips to one? Also even. So in other words, if you start only using patterns that have an odd number of one bits, then if there's one bit error, that one bit error, I mean, it's either got to flip a one to a zero or a zero to one, right? But after that one bit error, you always have a pattern with an even number of one bits. And then you can look at it and say, well, that's not a valid pattern. So then you know something went wrong. OK? So any bit flip gives what we call a non-code word. The code words are the original valid patterns, the ones that have meaning. So this is what we call parity. So if we add this extra bit, a parity bit to each code word, and choose that parity bit's value, right? If we're going to add a bit, well, we can pick zero or one to put on the end. And we'll pick it such that the number of one bits is odd, just like we talked about. And that's called odd parity. You can also pick it to be even. That would be called even parity. You have to agree on what representation you want to use, of course. So here's three bit unsigned in the black digits with odd parity, which is the blue digit I've added onto the end, right? So three bit unsigned goes from zero to seven, and all I've done is add the parity bit on the end to make this a representation protected by parity. So let's then take a look at, well, I want to define a distance. So if I give you two bit patterns, I want to define what I'm going to call hammy distance as the number of bit flips I have to do to move from one pattern to the other. So here on the left, I have 0, 1, 0, 1, and 0, 1, 0, 0. Those two are only different in one bit. So I'll say, well, this is distance 1 apart. This is top pattern from the bottom pattern. This pattern over here, 0, 1, 0, 1, from 0, 0, 1, 0, I'd have to flip three bits to go from here to there. So I'm going to say this is distance 3. This is what we call hamming distance. Richard hamming was a Illinois alumnus in math. He did his PhD at math, and then he ran Bill Labs Computing Center for a long time. He's actually quite famous. And he has many things named after him in various fields, computing signal processing. So hamming distance is number of bit flips. So for two patterns, the hamming distance between them is the number of bits I have to change from one pattern to get to the other pattern. I'd say hamming distance. So let's also define hamming distance for representation, which I'm going to start calling a code. So if I give you representation, there are some patterns that are valid things. Some that aren't. But for the patterns that are valid things, I want to ask, well, what's the minimum hamming distance between any two valid bit patterns? Any two that mean something. So the hamming distance of the code then or the representation is the minimum hamming distance between any two distinct code words. So it's the minimum overall possible pairs. So it could be hard to compute. Sometimes it'll be easy. We'll do a couple of examples. So what's the hamming distance of binary coded decimal? One, right? You choose two code words, for example, 0 and 1. And here, this is distance 1. So there's an example of a pair at distance 1. You know that any different pair is always at least distance 1. So then you have your answer, right? The hamming distance is distance 1. So BCD is hamming distance 1. What about hamming distance of 2 out of 5? So with 2 out of 5 codes, if we have two different patterns A and B, each of them have to have at least two 1 bits. And they can't have the same 2 1 bits. So that means A has to have at least 1 1 where B has a 0. And because they're different 1 bits, they have exactly 2. And B also has to have a 1 where A has a 0. So those are two bit differences. I didn't put any constraints on which patterns I chose. We've got 2 there. So you've got to have at least two hamming distance for the whole code. And because, of course, I can easily find a pair that has exactly 2 out of 5 code has hamming distance 2. All right, so what about parity? So what if I have a code with odd parity? So I could give you the example of taking three bit unsigned. But I could take a bigger representation. Can I only protect a few bits with parity? What if I had 1,000 bit, 2,000 bit, 2,000 complement? Yeah, could I protect that with one parity bit? That seems kind of inexpensive, right? Yeah, well, how? Yeah, that's right. That's right. Yeah, so that's a good analysis. So there's two aspects. One, the single odd parity bit will work from a single bit flip. But if you make the representation too big, the chance that you actually have two bit flips goes up. And with two bit flips, we haven't shown it yet, but I think maybe we sort of hinted at it. With two bit flips, of course, you won't necessarily be able to detect the problem. So it's not limited from the theoretical sense, but from the practical sense of the error probabilities going up too much for two, it is limited. All right, so let's do this little bit here. Yeah, for small enough number of bits you would. I mean, you would not go to a mega bit with one parity bit. But for something like a 32, 64, 128 bit number, if all you wanted was air detection, a single parity is sufficient. Again, it depends strongly on the error probability. So it depends on the context. For spacecraft, the error probability is much, much higher, because they're being bombarded by cosmic rays all the time. So the whole thing is. Yes, yeah. So you can always have, you can always break things into groups that you protect separately with individual parity. That's a good question. So another question over here. All right, so let's take a look at this. This was just an example of parity and why the hamming distance is two. So if you pick two distinct code words, A and B, we don't know what the bits are, but we know that they have to be different. So let's just assume that they're only different in one place. That would make the hamming distance one. So if we go forward without assumption, well, if that's true, then A has odd parity, we know, because everything has odd parity. But then if A and B are hamming distance one apart, and A has odd parity, then B has even parity. But that can't be right, because we assumed all of our bit patterns had odd parity. So this is a contradiction in our assumption that this location is unique. Therefore, the location is not unique. So for any two patterns, they have to differ in at least two locations. That means hamming distance two. So just a quick proof that with any representation, one parity bit gives you hamming distance two. All right. So this is then just a concrete example. So this is three bit two's complement. And you can see that I've added an odd parity bit on there. And the difference between 0 and 1 is 2. And so the hamming distance of this representation is exactly 2. You know, from the previous slide that it's at least 2 for any parity-based code, but this one is exactly 2. So what happens if two bit errors occur? This was the question you would ask Eric. What happens if two bit errors occur when I have something like three bit two's complement with parity? So here I've represented a 0. And let's say the first bit error comes in, and it flips the 0 here. So now I have 0, 0, 1, 1. And then a second bit flip happens, and I get 0, 0, 1, 0. Except that's the pattern for 1. So if I have those two bit flips happen to my original value, I won't be able to know, oh, something went wrong. I'll look at that and I'll say, oh, the parity's right. It's correct. It's a 1. Even though what really happened was two bit flips. So I won't be able to know it. But this is why you do have to worry about the possibility that more bit flips than you expect will happen. So no error can be detected in this case. All right, so more generally, if we start with a code of Hamming distance d, and then we want to know, well, given Hamming distance d from my code, how many errors can I detect, remember that Hamming distance d implies that if I pick any two code words, those two are at least d bit flips apart. So if I start with 1, and I only flip d minus 1 bits or fewer, I can't get to the other one. So if I start with a code word, and then I flip 1 bit, or 2 bits, or up to d minus 1 bits, I can't reach another code word. And so I always stop at a place that isn't a code word. So as long as there are somewhere between 1 and d minus 1, assuming that's meaningful, if d is 1, then you can't detect any errors. But between 1 and d minus 1 bit errors, I can always detect if I have Hamming distance d for my code. So this is the relationship between error detection and Hamming distance. This is why Hamming distance is a useful concept. And if you know the Hamming distance of the code, how many bit errors you can detect with that code? It's just d minus 1. Yeah, flash. No, no, no. This is a general code. Parody Hamming distance is 2. So it works for parity. But this also works for any other code where your Hamming distance might be larger. So later, I will show you, probably on Monday, I will show you Hamming code, which has Hamming distance 3. So those can be used for detecting two bit errors. You can also build bigger codes. I shall show you also Hamming distance 4 code, which you could use to detect three errors if you wanted to. Up to three errors. Yeah. It always refers to ones, which is equivalent. And the odd parity needs an odd number of ones. You can also have even parity, which is an even number of ones. And there's a one-to-one mapping, right? Because if your characters are only 0s and 1s, if they are for all of our systems, then the number of 0s is the number of bits minus the number of ones. So yeah. Yeah. Yeah. Yeah. And it's a convention. And the convention is necessary. Because otherwise, if I say odd parity, you wouldn't necessarily know whether it's odd number 1s or 0s. And then you wouldn't have a well-defined representation. So it's always the number of ones. Yeah. So these are errors, remember? So you don't want this to happen. But in order to protect against it, you need to make whatever number of bit flips you expect. You need to have a Hamming code with large enough Hamming distance that it can't happen as far as you're concerned. Now again, when you say can't happen, it's a probabilistic argument, right? So typical error rates, the optical fiber error rates, for example, used to be something like 1 in a billion bits per bit. So if you sense a terabyte of information down, you could do the math. Figure out how many bits are in a terabyte. Divide that by, I'm sorry, it was a trillion, it was 10 to the 12th. Divide that by trillion, that's how many bit errors you would expect to see at the other side of your optical fiber. Optical fiber is actually quite good. I mean copper and things like that have much higher tooth or orders of magnitude higher error rates. And wireless is really bad, which you probably know from having just used it. But it's because of the bit error rates and other phenomena. OK, so let's take a look then at error correction. Or at least get the motivation. So sometimes that's just not enough. Hey, I've got an error, right? So well, what happens if your bank calls you up one day and say, hey, there was an error. It turns out there was an error with your account balance. And the account balance now after the error is in there, we can tell because the parity is wrong. But the error says you've got $500. So we're thinking, we've got two options for you. One is, well, maybe the parity bit got flipped, right? So OK, that's fine. You just get $500. But we think probably what happened is the sign bit got flipped. So what do you can pay us the $500? Let us know. And I think hopefully all of you as ECMagers would go back to, no, no, no, no, no. What happened was the big, the highest zero bit and the exponent got flipped. And this was my balance. I just had a big deposit, right? So when you get this money, let me know. All right, so that's one example. Oh, wait, there's a alert. What's going on here? Oh, oh, good. Yeah. So another thing you'd never want to see again, right? So please, if you work on it, we saw in the curriculum committee, we were talking about where our students go. And a bunch of people said they would go into medical devices, right? Please never write this. Use something stronger. All right, so error correction. Can we use redundancy to correct errors? Yeah, but the overhead's going to be higher. So if we want to correct errors, we're going to need bigger, more hamming distance, basically, as the short argument. And we can see more detail on that on Monday. But let me just show you. So here's our odd parity. hamming distance is 2. Why can't we correct an error? So one bit flip, remember, could be from here. So we see this pattern. It might have come from here, right? It might have been that we sent this pattern, or we stored this pattern, and this bit got flipped, and we saw that. On the other hand, it might have been that we stored the one, right? And the one is this number, and then this bit got flipped. So if we see this pattern, what should we pick? It's the same as the banking problem, right? We have no idea what we should pick. We don't know which one it came from. So we don't have a good answer to that. So for hamming distances only 2, we're not going to be able to correct an error. We'll need a bigger hamming distance. So here's an example, a very, very simple example, not a good strategy. But just to show you, what could you do to get hamming distance three, well, I could just make three copies, right? So here's two bit unsigned copied three times. Just for us, there's a black copy of blue copy and a green copy, but it's just a six bit pattern. So now, if we get, sorry, I meant to ask you that, but if we get one bit flipped, then something changes, but only one of the three copies can change. So now the other two copies, you can look at all three copies and do a little voting exercise, and the majority vote wins. Oh, OK, well, I got two, zero, two. OK, that was a two. I'm done. So I can actually correct an error. What happens if I get two bit flips? So two bit flips, then two things can change in different copies. I can do my little voting exercise. Two, zero, oh, this was a zero. Oops, sorry, I should have done that off. So it's important to realize, in this case, if you do correction, you might actually miscorrect things, right? So be careful with that. We'll talk more about this on Monday and show you some examples of good codes for error correction. Thanks."
    },
    {
        "ECE120-2016-11-30-LEC-37-slides.mp4": " and then, and hamming codes, and then also, sected codes. I shouldn't mention, I think it's probably clear from the Wiki, but there's a homework 14, but it's not actually due. So we'll give you solutions. I suggest that you do it because those kind of problems will be on the final. So it'll be the kind of things we've been doing this week. And the things we'll do today and Friday. So you won't have to turn it in, but you will get solution forward and you can check your answers and stuff like that. OK, so you've seen everything in the data path and how it works and how the control unit drives the data path to execute RTL for all of the states. So today, what we're going to talk about is, well, how do you actually go about building the finite state machine that the control unit is? How do you make it work? So I want to go back and say, well, what does the control unit actually do? And so you know it drives RTL with control signals. But well, as you should remember, it goes in. It fetches an instruction. When it executes, that's an instruction. It goes back, starts over. So exciting. It's a control unit. OK, so how can we actually implement that? So let's start by making a simplifying assumption. Let's assume that we can fetch an instruction in a fixed number of cycles. And that we can also execute any instruction in a fixed number of cycles. Not all ISAs is that the case, unless you've fixed numbers very, very large. For example, x86 has a string copy instruction that takes a register as the length of the string. So you can copy a gigabyte of memory from one place to another with one instruction. So that's not the kind of thing we have in mind when we say a fixed number of cycles. It'd be 5, 10 cycles. Some processors had instructions that were 150 cycles. But some number of cycles, that's reasonable. And in that case, sorry, we can use a counter. And so we can actually build our finite state machine around a counter where we say, well, the first few cycles, whatever it takes are fetched. And then the rest of the cycles are executed. And then we'll start the counter over. And we'll start the process over. That's a new instruction. So control unit fsm does the following. So given as inputs, the counter value, and so we're going to build it around this counter, the IR, the instruction register, that of course is going to tell us the instruction. And as you know, those bits are meaningless until we fetch the instruction. And so we're only using the IR in executing the instruction during fetch, we're not going to use it. Signals from the data path. So we'll talk about what those are in the context of LC3. But it could be whatever feedback is coming from the data path, some signals coming out of it. So given those things, then the control unit is going to generate the data path control signals using combinational logic. So if we use combinational logic, we call that a hardwired control unit design. So hardwired just means somehow we're going to design combinational logic. Could be with K-maps. It could be, as you'll see, by figuring out all the bits and putting them in a read-only memory. And it doesn't really matter how we build the combinational logic. What matters is we're going to use combinational logic and implement this control unit that translates these things into control signals. All right. So for a simple enough, ISA and a powerful enough data path arguably, you can have a single-cycle hardwired control. If you can put everything into one cycle and get it all done, probably you need a fairly complicated memory, because you've got to be able to fetch the instruction and execute it. So it's pretty complicated data path and usually a slow clock. So people don't really build things this way. But there is a name for it. Single-cycle hardwired control. The thing that's more interesting then would be multi-cycle hardwired control. So let's start with patent Patel's LC3 data path and their finite state machine state transition diagram and think about how could we build a hardwired control unit that would actually make use of that design. So as you should remember, the LC3 data path in the book, I mean, it cannot fetch an instruction in a single cycle. It takes three states and then the memory state might take many cycles with the weight for memory to finish. And it certainly can't execute in a cycle either. It's got five states for some of the instructions. Like the LDI we looked at is five states long. So we can't fetch or at nor execute an instruction in a single cycle, but we can still use combinational logic for a design. So this is still a hardwired control unit, but it's going to be multi-cycle. So how many cycles do we need in that design? So fetch has three states. Where how many states maybe I'll ask? So fetch has three states. Remember, we went through first you put the PC down into the MAR increment the PC. Then in the second state, you go read memory. And then third state, you copy MDR across the bus into the IR. And then the longest instructions, LDI and STI, take five states. So we saw one of those on Monday. So there's total of eight states. So we can use just a three bit binary counter to drive the core of our FSM. So here's just an example of what those would need. So the counter value will run from 0 through 7. The first three states will be the first, second, and third fetch states. So that's a good question. Let me come back to that in a second. So I didn't put decode up here. And that's a good question as well. Where did the decode go? Because remember in the patent Patel state machine, you've got the three fetch. Then you have a decode. Then you have the different execute states. So here in the counter, I've only allocated counter values for the three fetch states and five execute states. So what happened to decode? All right. So Pat and Patel have a different strategy, which we'll talk about later. It's called micro programming. Their strategy, as I've talked about a couple of times, requires an explicit decode state. Because what's happening is in the third fetch state, we're actually bringing the bits across the bus from the MDR into the IR, that RTL executes on the rising clock edge. And so not until the fourth cycle of the bits actually in the IR. But you want to use the bits of the IR then to go to different finite state machine states. Here our states are kind of implicit and our combinational logic uses these IR bits directly. So in the fourth cycle, once the bits are in the IR, they're going into the combinational logic and we can make use of them to actually execute. Because we're also, we're looking at the opcode and we're looking at the counter value that says, OK, this is the first execute cycle. So the combinational logic just handles that directly and we don't need an explicit decode state. Pat and Patel with micro programming do, because I have to split the state based on the IR and they can't use the IR until the fourth state. Makes sense? All right, so what about the shorter instructions? So remember an ad only takes one cycle. You do your three fetch and then you add and only takes one cycle. We allocated five cycles for instruction execution for LDI and STI because those will take five or five states, I guess. So do we need to sit around and wait? What can we do? So what if I just get here and I finish my ad and I just push my counter vector zero? What happens? It just goes and does another fetch. So what can I do to not wait around for four cycles? Just reset the counter. So I'll add a counter reset signal. So this won't just be a binary counter that just wraps around. I mean, that would work. But then we would have to wait around for four cycles. So add a reset signal. That'll be another control signal. Whenever we're done with an instruction, whether it's one cycle long or one state long or five states long or three states long doesn't matter. At the last state, we'll exert counter reset, and then we'll go back to fetch. So I'll only spend as much time as we need actually executing the instructions. Memory access can be slow. So do we need our clock speed to be slow enough for the memory? Or is there something else we can do? Yeah. So what do we need to do with our counter? Yeah. Well, no, no, no. The counter that we're using to drive this one. We better make sure it doesn't keep counting, right? Yeah. So we need to just stall it or pause it. So let's add a pause signal. So we could call it stall, doesn't matter. Just some kind of signal to the counter that says, don't keep counting right now. We're still waiting for memory. Once memory finishes, which I'll just use in this design, I'll use the same signal that Patent Patel used, which is the signal R memory ready, meaning it finished its access. Once that signal is exerted by the memory, that means we can move on. So somehow we'll use that to decide how long we have to pause, the counter, before we can continue. And then our clock can run at the speed of the logic, which is what we want. OK. So here's the general design. We've got some encycl binary counter. So for LC3, that's going to be 8 cycles, so 3 bits. You've got your IR and your PC feeding into combinational logic, producing control signals that drive the data path. The data path has some status signals that go back also into the combinational logic. We also can have the data path using the IR and the PC directly. But yeah, Mahalo. Yeah. No, because only in the states where you're waiting for memory, do you wait for memory? In the states like add execute, there's no memory operation. And so that takes exactly one clock cycle. And if memory is 50 times slower than their logic, then that's 50 times faster for the add execute state. Good question. All right. So this was our general model. I just added these arcs just to make sure you understand. I mean, these IR and PC are sort of sitting in the data path. You know they're being used anyway, but I didn't want you to think from the figure that they want being used. Yeah. Only if you try to pipeline. And we're not piped line error designs. Yeah, this is just executing one instruction at a time. OK. OK. So how complex is this combinational logic? So we're just going to build everything with combinational logic. And we know the inputs. We know we've got 25 data paths signals plus our pause and our reset. So we also know for LC3, PC does not directly affect the control. And so if you look at all of the different states, we never use PC to make decisions. You use it as data when you do PC relative addressing or you change the PC for branches or other control flow instructions. But you don't actually make control decisions based on your PC. So we have as our finite state machine inputs, these three bits of counter state. We have the IR, which is 16 bits. So that's a lot of state. And we have data path status signals. So maybe that's on around 24 bits or so. It could be around there. So get your KVAP pens ready. Ready for some 24 input KMAPs. So that's a lot. I mean, that's pretty nasty sounding functions. So at that point, really good design kind of comes to the rescue. So Pat and Patel spend a lot of time thinking about, how can they design the LC3 data path and make control simpler? You've seen a bunch of examples of how that works. Things where bits in the instruction encoding may use to specify the source register, for example. And those can then just be fed directly into the register file rather than having to come up with those bits as part of the control unit. So you've seen a bunch of those examples already. So I won't spend a lot of time explaining it. But it's really through their effort that we can make these simplifications. So they design things so that it's easy to move bits around with wires rather than requiring lots of extra logic. So what inputs do we really need for the combinational logic? So if we think more carefully, well, we still need the three bits of counter state. As we walk through the different execute states, it's doing different RTL. So we need to know which state we're in. That's clear. We're really only need the op code out of the IR. Everything else is wired through muxes. And we just need to control those muxes. The data path's been designed to let us not have to worry about those in terms of the states of the finite state machine. So we just really need those four bits. There's actually one instruction we didn't look at in our class called JSRR that uses IR11 as an addressing mode. So in fact, if you want to implement the full ISA, even without privilege and interrupt, you need IR11 as well. So we'll just add that in. And there's really only two data path signals we'll care about. One is the memory ready signal R that I mentioned a few minutes ago. And the other is the branch enable signal, right? The thing that we were calculating before in decode. So that will still have to be calculated at some point. So branch might get a little longer in this hardware implementation, because we couldn't use it until it's ready. OK. Those are our signals. So if you add those up, let's see, we had three plus four plus one plus two is 10, right? So 10 bits of input, that's still somewhat complicated. So let's see. So how many control signals? So 10 bits of input. So control signals, 25 that we talked about on Monday. And then we added counter reset and counter pause. So we've got 27 total. So we still have 27 10 input functions. So I think probably if I said, OK, get out your paper and solve all 27 10 input functions, you'll probably be a little unhappy. So is there an easier way if we have a little bit? So what if instead of really going and building from gates, we just said, well, let's just put a read-only memory down. So let's just figure out the bits, and then we'll put them in a read-only memory. That way it's also nice. If I figure out all the functions and I build it out of gates and then I realize I messed something up and I left out a state or I did something wrong, I might have to go recalculate a lot of my functions, basically start from scratch. If I mess up some bits in a read-only memory, if it's really read-only, well, then I have to get a new read-only memory and program it with the new bits. But I just have to change the bits. You can often get programmable read-only memories and change them. So if you make a little mistake in your design, it just fix the bits that you're done. So the 10 bits, how would we actually use this? The 10 bits of input are going to act as an address. So we've got these 10 bits, the three big counter-state, five bits of the IR and two bits from the data path. We apply those bits as the address and outcome 27 control signals. We need 27-bit addressability, and that gives us this 2 to the 10 by 27-bit memory, and total is over 27,000 bits. So that's not too bad, that's only 32k memory or something, less than 32k. I guess exactly 27k. But smaller memories would be faster. So if we wanted to make this a better design, we should think about, well, are there ways we can have fewer bits in that memory? There are ways we can trim it down a little bit. So let's think a little bit. The data path in Patent Mattel was designed for their control unit. So if we are willing to make a few little changes here and there, we can actually make a better design for hardware control unit. So let's see how we can do that. So what piece is the memory ready signal? What's it used for? Anytime we access memory, whether it's instruction fed or load or LDI's first load or store or any kind of store, actually, anytime we use it, we're using the memory ready signal to wait to see, well, did that access finish? No, just staying in that state until it finishes. So the only reason we use that is to generate our pause signal. So what's going on in this design is we've said it so far is, well, memory ready signal goes in as one of the address bits. And for every one of these states, we actually have two different addresses. One is which memory's ready and one is with memory not ready. And one of them has pause on as one of the bits in that memory location and the other doesn't. So instead, we could just take that logic out of the ROM and put it into the data path. It's pretty simple logic. So for example, let's instead add a control signal called waitmem. So in the states where we have to wait for memory to finish, we'll exert the waitmem signal. And then the finance state machine states its stall. Like I said, they'll set waitmem equal to 1. And then in the data path, we'll just add this little bit of simple logic. So pause, the input to our counter, pause, will be our barb or our prime, and it with waitmem. So the only time you're going to pause is when memory is not ready and you're told from this control signal why you have to wait for memory to be ready. So we cut the control signals by one by removing pause, but we added a new one waitmem. So the control signal is still 27 of them. But now we don't have to put the R signal as an address bit. We don't have nine address bits. So that means now we don't have half as many memory locations, so half the size of the memory. So one tiny little bit of logic added to the data path, we cut the memory in half. So what about branch enable? So branch enable is used in the branch instruction. And if you see the branch enable as false, you go back to fetch. And if branch enable is true, you change the value of the PC before you go back to fetch. Well, so again, our initial design does that computation implicitly by having different addresses. We're rounding branch enable as an address bit. The ones with branch enable turned on will continue and execute the PC change. And the ones with branch enable turned off will go back to fetch by resetting the counter. So instead, what we can do is add two more control signals. One will be branch reset. So the branch instruction will use this control signal. And all of the instructions when they're finished will exert a second control signal, second new control signal called instruction done. So then we can set in the data path, the reset signal will be calculated with this little bit of logic. So we'll say, well, whenever the instruction is done, we'll reset the counter. Or if we have branch reset exerted and branch enable is not true, that means we're doing a branch instruction, but the branch should not be taken. So now we just want to reset the counter immediately. In either of those two cases, reset will be true. So now we have two more control signals generated. We're no longer generating reset from the control rom. So we have one extra so that gives us 28 and one fewer input. So again, cut roughly in half. So now we have one more bit of addressability, but we have half as many addresses. So now we're down to about a quarter, just with a couple of few gates. So there's one more thing we can do very easily, which is this JSRR problem. IR11 is used only for that, only for that particular instruction to decide between JSR and the JSRR instruction. One uses a PC relative offset, the other uses a base register. So decide between those two, what we can do instead is connect the base register, which is an SR1 over to the fourth input of PC mocks, and then use IR11 directly in the data path with another control signal. So if we add that extra control signal and take IR11 out of the inputs, then we're down to two to the seven addresses, seven bits of address, three for the counter, four for the opcode, and then 29 bits of addressability for control signals. So total is less than a seventh of the original sign, a little more than an eighth. These are some details. I don't think I'll go through these, but eventually these will go in the notes. Yeah, I realized, as you'll see, I realized that without doing the simplification, we can't actually get our hardware control design down to 32 states. So we do have to do the simplification to have only five bit addresses. All right. Any questions on that before we talk about micro programming? You'll like you understand the hardware design? Yeah. Okay. So if Jans are, IR is much bigger than... So what we did is we made a more powerful data path, but we didn't have to add much logic, right? So remember PCMOTS had only three inputs connected. So there's a free input. So we use that free input to put SR1 onto that input. Yeah, there's actually a long story here that's the... I think pretty much all of the versions you can find in the Wiki and the webpage and the notes and so forth of the Pat Patel data path are the old version, which has a bug in JSRR, which they're then fixed in later instances. So those would be that have newer books, probably have a slightly different finite state machine implementation of JSR and JSRR. So those can be combined with this little extension so that there's only one state instead of three states. Yeah. No, I'll see three B stands for byte addressable, the choose for 411. Yeah, no, it's not related. Okay, so let's talk a little bit about micro programming then. So the... That was hardwired control. So here's the finite state machine and this is the one, let's see. So in the newer versions, this R7 gets PC, gets copied down into both of these two states. This is the JSR and JSRR implementation here. This one is JSR, this one is JSRR. But that's not kind of the point. I just wanted to show you while we had it up. The point of the slide as well, this is a pretty sparse finite state machine diagram, right? I mean, in theory, you can draw finite state machine diagrams and there's so many bits of input here, you can have hundreds of arcs going out of every state and we said, well, you have to make it complete. But this looks more like a flow chart or something, right? It's got one arc going out of most states. Sometimes you have two. The only place you've got more than two is decode. And everywhere else, there's only one or two arcs leaving. And so it's a pretty simple thing in terms of finite state machine transition diagrams, relatively simple, very few arcs. Yeah, I think. Yeah. So you can get the same. I mean, it has the same utility of jump versus branch, right? It's just longer range because the PC offset is limited. OK, so can we treat this as a program? So what if instead of thinking that this is a finite state machine design problem, we thought of this as a programming problem? So think of the control words. So each state has some RTL. That's what we looked at on Monday, taking that RTL, turning that into control signals. So you can think of those sets of 25 control signals as a control word. So each state has a control word. And maybe instead we'll call those microinstructions. So what the control unit is then going to do is to execute microinstructions. And so the way it'll do that, the program will be this thing. And so each of these will be a microinstruction. And we'll go through and execute those one at a time. We'll store microinstructions in a ROM and use the state ID as the address to that ROM. So we'll read the microinstruction for that state and then use that microinstruction to drive the data path and then go on to the next microinstruction. And so this is called micro program control unit design. So if we ignore, again, interrupts and purvledge and include that extension that I mentioned with JSR and PC Mox, then we need fewer than 32 states. So then we can have five bit state IDs, which was kind of nice. So very tiny state IDs. So our control ROM will be very small also. So control ROM will be only two to the fifth by 26 bits. Remember that extension we added one more control signal. So two to the fifth by 26 bits. So every cycle, this micro program control unit will take these five bit state ID, go to the control ROM, say, well, give me the microinstruction. And it'll get back 26 bits. It'll apply those as control signals to the data path and then go on to the next microinstruction. And just execute one instruction at a time. And so the control unit will really look a lot like a processor. Except instead of executing instructions, it'll execute microinstructions, which are just the states of the FSM. Now notice that IR is not used as part of this address. It's only the states. We don't need to know the IR that's implicit in the state diagram. Each op code has its own set of states. So we don't need IR as input to a control ROM address. So it's much smaller control ROM. So how do we handle these transitions, though? And so we said, well, go on to the next microinstruction. How do we find it? So that problem is called micro sequencing, or sometimes we just say sequencing. So let's look again at this diagram. So there's a lot of stuff in here that we never talked about. So most of these states, first of all, have a single arc. States like memory access actually have two arcs. Here's one going back to wait for memory to finish. JSR had two arcs, although we're combining those. Where's the other one? Oh, here's branch up here. This has two arcs. This is the one branch is taken, goes down, branch not taken, goes back to fetch. So let's add a couple of state IDs to each of these microinstructions. So instead of just having the control signals for microinstructions, let's also store the next state ID. And so how do we figure out what's next? Well, we'll just store the next state ID. So here's an example of what that might look like. So we've got our state ID started at a five bit register. That goes in as the address of this 32 to the fifth by 36 bit memory. Those 36 bits are the 26 control signals and then two five bit next state addresses. So those two next state addresses will go up here. And then somehow we'll come up with some microprogram branch control, but let us pick one of those two addresses and that'll be our next state. So most of the time, we've only got one or two next states. The only exception is decode. So this design will actually suffice for the entire state diagram except for decode. But we do need to figure out, well, what is this? What is this microprogram branch control stuff? How complicated is that? So it turns out it doesn't have to be very complicated. In the state diagram, there's only two reasons to branch. Those states that have two outgoing arcs, they have it for two reasons. One is memory is ready or not. And the other is branches enabled or not. And those are the two data path signals we needed. So those are the reasons for branching. So here is a simple design. We'll take the state ID, we'll compare it to the branch state, and then we'll use the MUX. If the MUX says it's not the branch state, we'll pass the memory ready signal as a microprogram branch control. If the MUX says it is the branch state, we'll crash branch-enable as the branch as the microprogram branch control. So that's fine for the states that actually branch. What about the states that don't branch? Well, we've got two state IDs, we'll just make them the same. If there's only one next state, we'll make the two possible next states the same. And then regardless of what R happens to be, it'll just go to that next state and we're done. So now we've handled everything except decode. So using one MUX, this little comparator for the branch state, and this memory, this is our control ROM, this is a five bit register, this is another MUX. So we've got, I guess, two MUXs. Yeah, Eric. Yeah, so for example, here in fetch state three, the next state is decode, right? And so here in fetch state three, you would set both next state IDs, both of these values here would be the decode state. And so then regardless of what this MUX does, it gets decode state as the next state. That's nice. For every state that does not have two outgoing arcs, yes. Every state that has a single arc, so this one, and this one, and this one, and this one, and this one. So everywhere you see two outgoing arcs, then those would have different addresses. Yeah. So the ones with self-loops are two outgoing arcs, and then this branch here is two outgoing arcs. And then this one we haven't talked about. It has 16 outgoing arcs. So we need to do something about that. So what can we do about that? We'll borrow a trick from Patent to tell. So let's just say that the first state of execution, we haven't done anything with our state numberings yet, right? So let's just say, well, we've got 16 opcodes, we've got 32 states. We need an opcode to start the execution of each, I'm sorry, we need a state to start the execution of each opcode. So let's take the first 16, 0 through 15, and say those are the states where we'll start executing the corresponding opcodes. So add is opcode number one. So state one will be the one at execute state. 0 is branch. I can't remember too many opcodes. 10 is LDI. Each of those states from 0 to 15 will be the first execute state for that opcode. So then we can do this. So I've added the blue stuff. And so I've got a comparator says, is this the decode state? If it is the decode state, ignore the next states, and just put in 0 followed by the opcode. So that will give me the first execute state as this state address, because I just defined them. So then on decode, my next state will be the first execute state for my opcode. For everything else, decode is not that state. So I'll pick the 0 input, which is exactly what we had before. So then we're done. That's our control unit design. So we do actually need to assign the other values. So we've got 16 states left. And we've got, I think, 15 states we'd have to give numbers to. So it's a somewhat tight fit. But then we can just go calculate the bits. And so once you assign all the state numbers, state IDs, and we've got 15 more to assign, then you can calculate all the bits. Control-ROM total was 2 to the fifth by 36. So 1,152 bits, about 30% what we needed with the hardwired design. And again, most of that is that in the hardwired design, you're looking at both the IR, the opcode, and the counter. And so you end up having a lot of redundancy. So if you think about, you've got a bunch of states that aren't used, which are the trailing execute states, when the counter is a high value for opcodes like add and and. But you also have redundancy where all of the fetch states are the same. And so you're ignoring the IR bits, but you don't know what they are. So they have to be multiple addresses in the ROM for that. Yeah. Have the speed you've got to do so that you have 15. You also point out that our flight number is a lot of states are kind of the same sort of corner that you know. Yeah, so to some extent that's true. So let's go back. So in some extent, you've got similar, if not identical, RTL, all of the memory access states except for the store, which is this one. All of the memory access loads. So there are one, two, three, I guess only four. The four memory access loads are the same. And so you can say, oh, gee, can I combine those somehow? The next states are different. And so it would not be easy to come up with a control unit that saves you. You're only saving now four times 30, I guess, three times 36 bits. I mean, maybe you can find more redundancy in the RTL. So maybe it's a couple hundred more bits out of the 1152. But it'd be hard to make that work, because you have to keep the same next states. Yeah. So. Well, you'd have to have some way to make them work properly. You can't combine them in the finite state machine design. So you'd have to come up with an implementation that gave you the same answers without using as many bits, which I don't know how to do easily. Well, yeah, they certainly have to be separate states logically, whether you can come up with an implementation that's smaller easily as a different question. Logically, they have to be separate states because they do have different next states. So the behavior of the finite state machine after the memory finishes its access has to be different. I mean, you don't want your fetch suddenly turning into an SDI. OK. Let's see. Just finish that design. So any other questions on? Yeah. Back to the L. So decode will have to assign some value, right? But it's just some fixed bit pattern. So we haven't assigned a value yet. But let's say we pick 16. Then all this thing has to do is compare these five bits to 16 and binary. And so logically, it's maybe some inverters in an AND gate. Actually, you'll have, you can have inverted inputs out of the register out of the flip flops. So it's really just an AND gate with five inputs. Anything else? And the same is true for this comparator, right? We didn't, at this point, we hadn't even picked a branch state. It'll end up being zero, right? So this is just comparing to see if the state is all zero bits. OK. Yeah. So this is the state ID after decode, right? So this is the numbering of the first execution state for each of the opcodes. So the opcode is 0, 0, 0, 1, which is add. Then the state is 0, followed by 0, 0, 0, 0, 1, which is 1 indecent. So state 1 would be add, state 0 is branch, because the branch opcode is 4, 0 bits. State 15 would be trap, because the trap opcode is 1, 1, 1, 1. For a bit. I don't know if you can see these. I kind of doubt, sorry, I know it's, can people in the back read these numbers? One, I'm pointing to. Can you see those? It's too fuzzy, right? Well, those are the, so this one and this one. These are the first execute states for each of the opcodes. And if you could see the numbers, you'd see this is LDI and this is 10, this is STI, this is 11, this is add, this is 1, this is and this is 5. Those are the opcode values. And those are the state numbers, both in our design that we just finished. And in the patent-patellar design, I'll show you shortly. Except in patent-patellar, they have one extra reading 0. But the numbers for the first execute states are also. Well, they have more than 32 states, so they need six bit IDs. All right, so let's go ahead and take a look at this. With interrupts and privilege, they're gonna have these six bit state IDs, so that was really the point of this slide. So we're gonna have to do a slightly different design. So I wanna look at the one in patent-patellar now and show you how their micro-sequencer works primarily. And then go through and derive sequencing bits for the same states we did on Monday, meaning fetched decode and LDI execution. So this one is the arc for outgoing interrupts. That's actually in a completely separate figure in the appendix, so all of the states that are not shown in this diagram, all of these little numbers here, as I mentioned, are the state IDs, so I know you can't read them, but when you look at the figure or you get the figure in your exam, if you need the state IDs, they're all there. So you don't have to memorize them or anything. So interrupts and privilege at another 14 control signals. So the total control signals is 39. Patent-patell micro-instructions also include then 10 bits of sequencing information. So in the design I just showed you, we added 10 bits as two five bit state IDs, for their design they add 10 bits as one six bit state ID, and condition for branching, which I'll explain in a minute. And then IRD, which is just a one when you're in the decode state and a zero when you're not. And so they add that as a bit in the control word, bit in the micro-instruction. So here are the conditions, only three of these are things that we've talked about in our class, one is unconditional, which means you only have one next state. The other two that we've seen are the memory ready branch, and then the branch enable bit branch. And then the three we haven't seen are the JSR, our addressing mode bit, which is IR11, privilege mode violation, which is PSR 15. This is process status register. It's not even a register we've talked about. So you can just think of these as some one bit signals. And then interrupt occurred is the int signal. So we didn't talk about these three gray ones, these three at the bottom, but it's in their design. So I wanted to make sure you don't feel confused when you see the design. So here's the design of their micro-sequencer. So first of all, it has the same thing that we had for managing decode, right? So they have the IRD signal coming out of those 10 bits. It says this is the decode state. When you're in the decode state, you get two zeros followed by the opcode as your next state number. So the same state IDs for the first state of any opcode execution as we defined for our machine, for our micro-programm control, you know, a few minutes ago, but with one leading zero because they have six bit state IDs instead of five. So they have two extra zeros we had one. But otherwise, it's also the same mux design. Now, the difference here is this is their micro-sequencer for everything else. So what you can see here, this is basically like a decoder exploded for the conditions, right? So for each of these conditions, these are implicit inverters here. But each of these AND gates would be one min term on the conditions. And so they're the min terms in this table, right? So there's no unconditional one, obviously, since you're not going to change anything in that case. But you can see for each of the AND gates, each of the five conditions, and they're not in order, they're kind of scrambled. So you have to kind of look at the thing to decipher it. But for each of the conditions, we change exactly one bit of the, sorry, there's the decode, there's the first states. For each of the conditions, we change exactly one bit of the address, j. So the address, j, which is stored as part of the micro-instruction, that's the next state address. The only kinds of next state addresses we can use are addresses that differ in exactly one bit. The zero bit happens when the condition that we're looking at is false, and the one bit happens when it's true. So we have to pick our state number and somewhat carefully. So let me explain that a little more. So for example, the memory ready signal or is in the bit number one or value two, you can see that here, here's memory ready, that gets ored in to j sub one. So that or is in the value two. So if we want to wait for memory access, we have to pick state numbers that differ in exactly that bit. And we have to have the memory not ready state have the address, the state ID with the zero bit, and then the next state that when the memory access is complete has to have the address plus two or two, which is the same in this case, because that bit is zero. Those constraints have to be obeyed. So you have to obey those constraints when you pick your state numbers if you want to use the micro-sequencer. So of course they did, right? And it's reflected in the state diagram. But occasionally you'll see, as you go study old final exams, you'll see things where we ask you to add an instruction and make use of free states in the patent-pantel design, and you have to look at the micro-sequencer and figure out how to make use of them in a way that works. So we'll go through some examples. Here's another example. So branch upcode is zero, so that's the first execute state. So that's branch execution state is number zero. State zero branches on branch enable. When it's false, the branch is not taken, so the next state is fetch. And when it's true, the next state has to be 18 or four. So the next state has to be 22, which it is. But and that's because it's branching on branch enable. And if you look back here, you can see branch enable goes into j sub two and puts a one into j sub two when it happens. All right. So we have a few minutes left. I think we'll probably have time for this. I don't think it should take too much time. But I wanted to go through and take a look at all of the fetch and decode states and ask, well, what are those 10 bits for each of those states? We already did all the control signals on Monday. But let's look at the 10 micro sequencing bits for each of fetch and decode states. So these are the states again. So now hopefully these state numbers are visible, but I'll put them in the next slides anyway. So here are the state numbers in binary for fetch one, fetch two, fetch three and decode. Fetch one branches on the interrupt signal. The next states are fetch two, which is this pattern. You can see it down there. And the start of interrupt, which is over here. So the bit that's different then is this bit here, the bit number four, counting from the right as number zero. So zero, one, two, three, four. That's what the interrupt signal changes. So what should JB? Okay, so remember in their micro sequence or design, when the condition is true, it's going to change the bit from a zero to a one. So if in J, you make it a ready a one, it will never branch. Oring in a one where something's a ready a one doesn't change it. So you have to pick out of the two next state addresses, you have to pick the one with more zeros. So you have to pick this one basically. So that has to be the next state address. If the interrupt signal is on, the micro sequence here will turn on this bit in J and it will go to this state instead. If interrupt is off, it will go to fetch state two. So that's how their micro sequence works. So as you fill in these bits, for every time you have a branching state, you've got two next states that have to differ in exactly one bit, the bit in which they differ always depends on the condition you're picking, the condition and the bit that differ have to match. And the pattern with the extra zero and it is the one that has to go into the J value for the micro sequence of bits. Okay, so the condition in this case is one zero one for the interrupt bit. So is this the decode state? No, so it's a zero. Okay. So what about fetch two? So fetch two branches on memory ready. Right, fetch two we're going to memory and we've put the PC into the MAR, copy the PC into the MAR, and come into the PC and fetch one. Now we want to read from memory. So the next states are going back to itself, which is fetch two. So it's that address again, or going on to fetch three. So you can see the difference here is in the bit number one. Right, and so fetch two has the zero, fetch three has the one. So when memory is ready, it'll go to fetch three. And when memory is not ready, it'll stay in fetch two. So what should go into J? fetch two. Right, the one with the extra zero. And the condition in this case, anytime we want to branch on memory ready is zero zero one. And then is this decode? Yeah, that one's easy. Yeah, usually you probably want to look these up in the table. Right, so we'll give you all these tables. All right, fetch three does not branch. The next state is decode. So what goes in J? Just decode, right? There's no branching. So what's condition? Sol-zero. That was the unconditional one. And is it decode? No. Next one is decode. That's good. All right. So decode goes from some state from zero up to 15. Right? Decode is where we're branching into one of the 15, I'm sorry, 16 different opcode states to start execution of those op codes. Based on that op code, it picks one of those 16 states. So let's start over here. Is this decode? Yes. Good. What are these things? Do they matter? If you think back, I mean, I can see how quickly I can flip back to the micro sequencer. There it is. So when this mocks goes from here, does this stuff matter? They don't care. So J is a don't care. And condition is a don't care. Because whatever this thing puts out gets thrown away by the mocks. That input is discarded. Because right now we're looking at decode. We're taking this input forwarding that to the next state. So let's flip through this. Yeah. Yeah. Yeah. I mean, you could simplify by not moxing those bits. Yeah. Yeah. So you could do that. Yeah. You could simplify it a little and have two fewer mocks out of the six. Yeah. I mean, I think they just wanted to simplify the diagrams in the book. Yeah. When you actually build it, I think you probably do that simplification. That's a good idea. All right. So. So the other set that I thought would be useful was LDI. We kind of out of time. So maybe I won't walk you through this, but it's in the slides online. So all it is doing is looking again at the five LDI states and asking, well, what are the micro sequencing bits for each of these five states? The one you're going to encounter most of the time is going to be the ready signal. And if we ask you to add an instruction on the exam or something, you know, it's going to be something with a load or a store. You're going to have to do memory ready. You're going to have to have them off by by the difference in bit one. So two and the one where you're reading for memory has to be the one with a zero there. So, so you can look through those and. And I will stop now and leave those to you. And on Friday, we'll do air control redundancy, things like that. Thanks. Thank you. you you you you you you you you you you you you"
    },
    {
        "ECE120-2016-10-07-LEC-19-slides.mp4": " So we will include, I wanted to go over, there's a homework seven has a problem on it where you need to Have some notation. I wasn't going to introduce actually the notation the homework is wrong too, but but I'll tell you the right stuff and how to do it So and then use the wrong notation that they use in the question Then we'll talk about serialization. So this will move into part three of the class So midterm two material ends up here and then we'll look at serialization and do a couple of examples We may finish these they may go into next Monday There's a feedback survey online. I know a lot of people have taken it I haven't announced to yet, so I don't know what fraction of you have taken it, but it's open until Monday night At midnight, so please do take it It's basically just feedback. I'm very resource in the class and what you find useful and what you think could be improved and things like that Um, and I'll read all your long answers Um, short number stuff will just summarize, but I'll tell you what we find from that survey once we've done the stats on it and stuff All right, so here's the midterm reminder. So Tuesday, 18, October the conflict exam if you need a conflict Please let us know through the wiki by Monday um And otherwise it's the same coverage is up to is basically part two of the nodes plus since we didn't do reading writing two stables from part one of the class Uh, that's on part two. So that's the topic coverage Um, we'll do a review session just like we did last time so not the Monday net next after this weekend But the one after at the 17th of October, I will have review session in the same style. So come prepare with questions um So I wanted to spend a little time going into more detail So what we did on Monday was we we built um, what it calls the quintal feedback circuits where the output of some gate goes back directly to the input So instead of having pure combinational logic, you have a feedback loop And this one in particular is a gated D latch. It's one of the ones we did Uh, and we just looked for stable states, right? So I think that's pretty much all you need to know Um, but there's some notation that helps you do a little more. So let me walk you through that and kind of show you how it works Um, and you'll need to do this approach on homework seven problem one. So um, so I want to start by just imagining the feedback loop here There's actually only one we need to cut so it looks kind of like two, but if you cut this one um, then rename this output from Q to Q plus It's usually Q star, but in the homework problem it's Q plus so leave it there um, and then Q is still an input and at that point What you have is combinational logic, right? So you have inputs over here D and right enable the data input and the right Naval input and then you have Q as an input and everything else is combinational logic to produce Q plus P is actually just an intermediate value of your combinational logic Right, so that is now combinational logic after cutting one loop So combinational logic circuit So after I actually erase it maybe it'll be a little easier to see we'd imagine that bottom right nan gate is shifted to the left Now it's just the combinational logic circuit to produce Q plus Right, so let's let's write a truth table for that So we've got D right enable and Q coming in with that Q plus and P coming out and we've got a bunch of nan gates that Kind of pain pain to analyze So let's start from P the intermediate point and calculate this one. So P is nand of Q and R bar So that's Q R bar Handed together and then inverted for the nan gate. So if we then apply to Morgan's law we have um Q prime plus R bar inverted again and then R bar is coming out of this nan gate so we can just invert the inversion again And write that as D prime this input up here and it was right enable Right so P is Q prime plus D prime times right enable Okay The reason I wrote it that way is so then we can then fill in the truth table easily and you can see there two colors So the Q prime um all the zeros in Q imply ones in P So first we can write those in And then anywhere we still have a a D prime and right enable so let's see deep prime is up here Our right enable is down here. So these two lines here the third and fourth lines will be ones also this one's already a one But the D prime right enable also makes this P output a one Everything that's not a one is then a zero Right, so just read off the equation It's SOP form so we'll just fill it in one term at a time with ones and then fill in the rest of the zeros when we're done Uh, then we can go back and fill in Q plus so Q plus is S bar handed with P and then inverted just like that and we applied to Morgan's we get S bar or compliment it again Ord with P prime and then And if we have this complimented that just cancels that inverter there so we have D ended with right enable or to P prime is Q plus Okay, so first term there D and right enable is down here that gives us these two ones the P prime where is it so this zero this zero and this zero But this zero is already covered so we get two more ones from the other zeros of P and then the rest is zero All I'm doing is filling in the truth table. It's just the circuits a little bit nasty So I wanted to walk you through the process once of analyzing All right, so now we have this truth table that gives us a few plus and P in terms of D right enable and Q Sometimes we call this kind of thing the next state table because it tells you what's going to happen Um, within a gate delay or two for this sequential feedback circuit, okay, so Let's take a look at this now what we did is we analyzed stable states, right? So we actually just went through the feedback loop until it's stabilized You can do that pretty easily with this table by simply comparing Q with Q plus If they're the same, that's a stable state the system won't change anymore So if you go look for those states you get these six and so zero zero one one zero zero these are different So it's not a stable state a zero zero one one zero one not a stable state one one So you got six stable states And then we could use those stable states to come up with the truth table that we wrote down on Monday for the for the gated D latch So if you take these um, we get this truth table where I've condensed Um two groups of two into a single row of the truth table by saying well, I don't care what D is right So this line here for example could be D of zero which is up here zero zero zero zero one or down here one zero zero one and so Q plus has gone away in this table So these are just the stable states the summary of stable states of the system And that's what we have on Monday with this bigger table you can also then um Make a more compact truth table So for example if you look at the rows where right and able is one, so these two and these two Okay, you might notice then well, what is Q plus or compact next state table I should have said um So Q plus is zero zero just like the down here Q plus is one one also just like D So in this case uh Q plus is just D so whenever right and able is one Q plus is D So what about right and able equal zero What's Q plus So just Q let's see so the purple one so zero uh Q is here and Q plus is the same And Q is here and Q plus the same so yeah, that's right So Q plus equals Q so we could write this short table here where we say well one the only dependence is actually right Navel and then we write uh We write Q plus in terms of the other input variables So you saw something like that on Monday also but we could write it this way Um having derived it from the next state table here So there's another next state table because we're again writing Q plus in terms of inputs Now you might have noticed um if you look carefully that in these unstable states Not this one, but this one we don't always have that P is Q prime right they're not always compliments of each other And of course they should be for this particular design Um the reason is that these these unstable states actually are just transient Right, so once you go into these unstable states by changing the input actually you then um move into another state In some systems they may oscillate forever, right? So we might give you something where some of these systems they just go from one state to another and they go on forever Um, but in some cases they might actually stabilize by moving from an unstable state these uncolored ones here Into a stable state. So let's take a look at what happens with these two So for this first one we start at um 0 1 1 for Q but we're going to go to 0 1 0 and 0 1 0 is just above it right here So we can draw that that way. So if we start in this state where Q was was initially a one then by setting D and right And able to 0 and 1 will force Q to 0 once Q goes to 0 it's stable And similarly down here um if we start with this input combination where Q plus is then going to change to a 1 that will move to the 1 1 1 state After Q is changed and will then be in this stable state Okay And you'll notice in those states um P is always Q complement Okay, so in the gated D latch the two outputs are always Q and Q bar You could imagine a system where that wasn't true and if you look at this next state table with all of the logic It might be a little confusing. So I wanted to explain that also It's only the stable states that matter in terms of what you'll see coming over Eric Yes Yeah, so they could oscillate between multiple states. I mean if it goes to the same state that's a stable state Right, so if it goes to another state and then that second state comes back to the first state that would be oscillation I'm not sure I understand the questions Toggle between Q and D so this is the gated I mean this is the same circuit we looked at before this is a gated D latch So I can store a bit in it and want to yeah, I can build flip-flops out of it Oh, it's the same circuit. I didn't change a circuit. They just changed how carefully I analyzed it. Yeah Yes, all we did on Monday was we simply looked for stable states Right, we didn't do all this detail But when you have a when you have a different design uh and in particular the homework asks you for the next state table So so I didn't show you how to do that Either one of these is fine if you want to condense it like this This is also an x-table the idea is to map inputs Maybe some of the inputs if that's possible or all of the inputs into q plus So the thing that tells you q plus is a function of inputs is your next state table Yeah Yeah, um not really Unfortunately, that's why the notation here should be q star sequential feedback circuits are not clock synchronous right These are the latches and flip-flops that we're building clock synchronous designs from So the plus notation usually means the discrete time Yeah, but in the homework it uses q plus to mean next state of a sequential feedback circuit So you need to use the notation in the homework Yeah Okay, yeah, the only reason I showed you this was the homework. I mean I You need to know how to do this for the homework You need to know how to find the stable states generally for the class That's but but analyzing sequential feedback circuits gets a lot more complicated too if you have more than one Feedback loop right because then more than one bit can change and actually either of them could change first If you think about all of the paths Yes, that's right. So with q and q plus are the same. That means it's stable. It's not going to move You could certainly create such a circuit not in this circuit Yeah, that's a good question, right? So So P remember in the in the way we broke this up P is is an intermediate intermediate variable and q is actually the feedback loop. There's only one feedback loop So the value of the feedback loop doesn't change no input to the circuit changes I keep P was just an intermediate value Yeah Yeah, so again if you if you go let me go back to the drawing So there's actually only one loop in the circuit. So once we break that loop If q plus gives us the same original value that we assumed on as an input There's no change to any of the inputs and so since there's no change to the inputs. There's no change to the outputs And that means it's stable And yeah, that's why and P is just a side effect right P is just one of the variables you calculate in the middle of that combinational logic And that has to do with the fact that if you look for cycles in the original design There's one and if you break that there are none right in some designs you could have more than one And if you have more than one you've got multiple bits to look at that might change and if any of them change you have to look at Actually all possible paths because either any of them could change first, right? That's why We don't go very deeply into this most most people honestly are not going to use this in their careers I mean not use sequential feedback circuit analysis unless you're designing the standard gate libraries or working in a company that does custom logic You're very unlikely to design this We just want to make sure you understand the ones that you will use every day which are latches and flip flops Okay, so Hopefully that won't pose a problem on the head Okay, so let's talk then about serialization of bit slice designs So if you think back to our bit slice we could generalize it a little bit with an abstract model, right? So bit slice It computes something based on P input bits So we had a bunch of different examples. We had a full a ripple carry adder right where each of the bit slices took one bit from from a and b So it might be P equals two or comparator was the same thing or If the one you did in the homework was an even odd checker, right? You took one bit So some number of bits from an operand or multiple operands and produces some number of outputs, right? Each of the bit slices might produce one output might produce two might produce zero But there's some number of output bits per bit slice and then there are m bits passed from bit slice to bit slice Right, so in the character in the ripple carry adder. It's just one bit the carry information in the comparator was two bits and the power of two checker We did it was two bits in the even odd I think in the one you did in your homework. It was one bit So you can generalize and just give those give those names um And then to handle and bits we previously we said okay Let's just take n copies or if we had a in the power of two checker we did in class we took two two bits For each of the bit slices so then n over two But now we know how to store bits, right? So instead we can go back to I think Sasha asked this question a week or two ago Well, couldn't we store some bits and flipplops and then use the same piece of physical hardware To you know compute the next slice right? So we're gonna go to the other extreme So in this case, we're gonna one copy of the bit slice So this is serial design one copy the bit slice and we'll use flipplops to store those m bits coming out And then we'll just feed them right back into the bit slice and and use the next bit And we'll keep doing that for n cycles and that will give us the answer for an n for an n bit opera or a set of n bit opera We'll call that a serial design So it's not quite that simple because well what about the first bit slice? All right, so if all I do is I wire my flipplops back up to the inputs Well, what's in the flipplops when I turn the machine on? Bits? Probably bits and actually I know I told you it could be metastable, right? So it might not even be bits in this case, but but let's just say bits, right? So So there are bits and that's not what we want, right? When we designed our our bit slice Our bit slice designs we said well, we're gonna put some fixed representation So the adder we usually feed a carry in zero because we want to use a subtractor then we'll feed carry in one All right, so we but we know there's some bits particular bits not just random bits that we want to feed into the first bit slice And also what about the last bit slice, right? So in the in the power of two checker the bit slice didn't actually produce the answer, right? It produced three different messages and then we had to use an Extrologic simple just an x or gate, but we needed extra logic to calculate the answer And so we need my need output logic So here's a picture putting it all together. So there's our bit slice Um, here's the m flip blocks will also latch the output bits So every kind of say this is an adder it computes one bit output will we'll get put in a flip block So some other logic can look at it in the flip block Um, then we'll bring these back over here, but we'll run it through some selection logic That allows us to say well, this is the first bit So we'll take our initial values and feed that into the bit slice Um, or we'll take the flip block values and feed those into the bit slice Once we're all done the last bits out of the bit slice we can put through some output logic and compute the answer So this is the general model of a serial design So Okay, I guess I walked through it So this output logic then is the same as the bit slice design, right? So we were ready to design that for the bit slice designer you just take it from the side of the bit slice design We just copy it into this design. It's not very hard F equals 1 means first bit So usually these things will be zeros and ones right? Usually we don't need to allow them to be real input to this zeros and ones Um, what do we need here for selection? Yeah So I mean we need to choose between the initial values and the flip block values, right? So what components should we put there? Yeah, right? We can put muxes there. Muxes would do would do just fine, right? Um, I'm actually going to optimize it a little more than that, but muxes would be a great answer And they would do just fine So we could do we could do muxes we can optimize because it'll be zeros and ones. So let's optimize a little bit um The m flip plots are going to store Their bits into the selection logic or feedback into the selection logic So let me call those b sub i and let's call the m bits produced by the first bits for the first bit slice c sub i So then we can say let's assume Um, a zero in place the bi for the first bit. So let's say we have some bi and we want to put a zero in for the first bit So when f equals one we want a zero and then we can write a truth table, right? So when f equals one we get a zero when f equals zero We want to feed in the b sub i from the flip plot Yeah Yeah, so b sub i is the bit coming back from the flip plot So between bit slices we'll be feeding the flip plot bit b sub i and that's when it's not the first bit So this truth table says well, it's not the first bit take the flip plot bit when it is the first bit. Let's say there's a constant zero Okay So okay, so if we write this out um, we say okay well The only non-zero term here is f equals zero so f prime times piece of i and I could write that as an orgate and then We just have one orgate, right? So pretty easy logic again if you just put down a mux, that's fine But but you can optimize your mux away for one gate in this case Similarly if we say well when the first bit comes in what if we assume is a one bit instead? We can write that same truth table So now for one we get one for zero. We still get piece of i Uh, now we'll have to use a p o s form So the only place we get a zero is the f equals zero So this is p o s form for that and of course that comes out to be a um, a nant gate So we still need that extra inverter but one inverter and one gate so we can optimize our muxes down a little bit So let me let me then walk you through an example So we have this general model and we have four parameters All right, we've got an n, I guess five parameters um, n bit operands p bits of input from operands q bits of output produce M bits between slices and at the end we've got orbits of final output that are that are not on this diagram, but produced by the output logic Yeah, yes, yes, so I wanted to see what the real size would be as opposed to abstract Yeah, it would be the same right a register is built out of the flux Yeah, yeah, it would be fine. I use an mbit register that's m flip blocks Yeah Okay, so I mean the other the other thing about the register is we in this design and the serial design we want it to load every cycle So having that extra load capability is a little bit of overkill, right? We don't need it Um All right, so here's the parameters for the comparator so this is just bringing up the old diagram of the comparator bit slice So we had two bits coming in So p equals two we have zero bits going out so q equals zero we've got m bits between bits slices So m equals two sorry for this is overloaded m this was bits like number m Um, but the number of bits between bits slices is two and then the number of bits for the final output was also two Right, we need to know well as a greater than equal or less than b And so we needed two bits of final output two so r equals two Um, so this was then the the representation we picked for those bits past between bits slices So which value should I be passing into the least significant bit for the comparator Which which assumption should I make Going into the starting point the first bit slice 00 right we just assume a equals b when I haven't looked at any bits Okay, so we'll set we'll pass in zero zero that'll be our initial values, right? So when we when we put this together This is what we get so I took just the general model a clop down the comparator bit slice here We said m equals two so here two flip blocks so called mb1 and b0 On the output logic was a no-off and actually I can walk through this so input operands There were two of them a and b right one bit of each of the values being compared Um, no output flip blocks since q equals zero so there's no extra flip flops down under the bit slice We had m equals two so those are those two flip flops so there's Z Z1 and Z0 outputs are just latched into b1 and b0 flip blocks This is initialized to zero when f equals one remember that was a single norgate So if f equals one both of these nor gates output are zero and we get c1 c0 equals zero zero Just like you said we should do right if the f equals zero Then we get the b1 Complimented output and we take that into the c1 input Because it's complemented here and then the norgate compliments it again And then down here we get b0 inverted coming out going through the norgate gets inverted again So b0 goes into c0 And then the last thing this output logic does nothing right just empty box because we didn't need to do anything extra in this in the case of the comparator So that's our that's our comparator design So then let's think about well, how does this how does this compare Uh, actually let's walk through and make sure we understand how it works. So So what I've done here is just written down discrete time right so cycle count So in cycle zero These are inputs f a and b. These are the bits of our numbers remember we start with the least significant bit So these are the least significant bits of a and b And what's going to happen then is those will produce let's go back and look at the diagram for a second So we'll put f a and b and then from those we need to be able to calculate c1 and c0 And then um, we've also got b1 and b0 coming back into these gates over here So maybe we need to know what those are first and then we'll produce z1 and and z0 which will go into b1 and b0 in the next cycle Okay, so So what's in b1 and b0 in cycle zero Why should there be zero Bits good answer There are bits we don't know what's in there, right? There's just some bits we just started using this thing There's going to be zeroes or ones in our flip flops, but we don't know what they are we don't know the way that's zero one We can but you don't you don't want to assume that this thing has never been used before right? It should continue to work no matter how many times we use it So whatever's left in there you'll see at the end we don't leave zeros in there So yeah That's a good question. So that's my next question. What are c1 and c0? So your claim is they're both zero So so we can look back. So what's what's the so f equals one and we don't know what b1 and b0 are so if f equals one what is c1 can we know? Um, so f is one and so what's c1? Zero right so yes in that case, it's not a not true if it's f equals zero though All right, so f equals one forces c1 to be zero and c0 also to be zero right they're both in our case It's okay, so we don't need to know what was in b1 and b0 if we set f equal to one we're guaranteed c1 and c0 or both zero So we don't care what was in those flip-flops of first cycle And we shouldn't have to care right otherwise we would need to take another cycle to force them to zero Right and that would take an extra cycle to do the application All right, so now we have all of our inputs to our bit slice so now we do what the comparator does to calculate z1 and z0 So which one of these is bigger a or b? b okay, so you may or may not remember the the representation for that is z1 equals zero z0 equals Is one that says a less than d and that was our representation Those two then get latched into b1 b0 in the next cycle So only in cycle one do these values appear in the flip-flops So that'll be important when we get down to the end Okay, because only after four cycles in the fourth cycle It's starting pounding from zero will we will we be able to see our answer? So the answer is delayed until all of those four cycles have completely passed It's discrete time means a little bit of delay before you get your answer That's right Yeah, okay, so we've done that copying so now we need to decide well what inputs do we want to put into the comparator in the In cycle number one, which is the second cycle So as Rahul just said Act should now be zero for the rest of our computation. There's only one first bit Right, we can do as many bits as we want the way we do it we put f equals one one cycle and f equals zero for as many as we want And you can do a thousand bit comparison with this thing you like We're only going to do four in class All right, so here's some numbers so f equals zero. Let's say the next two bits are one and one So what in this case will c1 and c0 b? 0 1 right because since f is zero basically b1 and b0 just get copied to c1 and c0 and that's how the noregates work the selection And so let's see so this one says a less than b a and b are equal here. So what should the answer be? Um, I think zero one right so a is less than b and then you've got bigger bits that are equals so a is still less than b Okay, yeah, this is a little tricky because it implies actually doing the representation mapping twice in your head So if you don't remember the representation to worry too much we'd normally give it to you on a piece of paper Um, okay, so those then zero one get latched again into b1 and b0 flip blocks Okay, they're already there, but now they're copied again from the z1's your z0 outputs into b1 and b0 in cycle two So here's cycle two inputs now we've got one for a zero for b um c1 and c0 what? Zero one right those are just the same as b1 b0 1 at b0 Okay, so in this case um, remember the smaller bits come in first with our comparator design So now the biggest bits a is one b is zero so which is bigger a is bigger now, right? So one zero means a is bigger than b. Okay, those get copied down. Yeah Yeah, that's right That's right. Yeah, yeah, so the question is what will you ever be able to get z1 z0 both zero again and no of course once They're not equal they can never be equal again, right? And so once you've got zero one or one zero You will continue to have one zero one or one zero until you've done with your computation and stuff the next one Only when they match and all the bits Okay, so we'll copy those down for cycle three But our inputs in this case um, wanted to make it flip again. So now b is bigger, right? So these get copied again because that's still zero. So b1 b0 go straight to c1 c0 And then what should z1 v0 be zero one again? Good Those two bits now get copied for cycle four into the flip blocks Those are now our answer So if you have a four bit two four bit numbers you're comparing after four cycles You'll be able to see your answer on the outputs of the flip block But you have to wait four full cycles because these flip blocks don't latch these values until the fourth cycle starts Remember they latch on the rising edge. That's why we can just write cycles zero one two three four Yeah Yes Um, you mean to reduce it you have to compare Yeah, so in a serial design um, we could do what we do as humans if we were going the other way Okay, so if we were going the other if we were going the other direction Uh, starting from the most significant bit then in the cycle that we saw a difference we could stop comparing Yeah, so that's that's a good point So in a bit-sized design we were we couldn't do that and so the direction didn't make a difference Yeah, but in this design we can as soon as we see a we could put an orgate on these two And as soon as we see the orgate produce non-zero that means we know there's a difference We know what the difference is we can stop and see which direction Yeah, that is one advantage of doing this um, Serially if you could stop early, which I didn't actually point out in the slide Okay Yeah, so remember that the flip-flops um take the the value on the d input at the rising edge of the clock and then store that new bit Right, and so even though these outputs might be ready in the middle of one of these cycles They only appear on the outputs of the flip-flop at the start of the next cycle after the rising clock is Okay, so that's why we have discrete time right you can assume that these the outputs of the flip-flops hold that value for one complete clock cycle and that they don't change But that implies you have to wait for the fourth clock cycle if you're doing four bit operas And similarly if you're doing a hundred grid operas you have to wait for the hundredth clock cycle after the start of the Absolutely, we'll go through in detail. Yeah, so the question is is this slower than a Then the um bit-sized comparator I think you meant right? Yeah, and yes, it will be much slower Yeah, it's a good question. It would be smaller but slower Yeah, so you might be able to shortcut it in some cases so the analysis is going to be a little harder to depend on what data you put in Right Yeah, in this case, it's definitely It It depends what you want right? Yeah, so it is a trade-off and as as always when you have more than one metric It depends on the context if If you do if you're trying to put many many of these on a chip Then you probably need them to be small Right if on the other hand you want speed you probably don't care as much about area and probably try to use the fastest And the context will tell you which which one is a better choice for you All right, so let me fill in some of these so we don't know what comes in In the fourth cycle we're assume we're done with our computation. So let's say I don't care about those Um, I put a zero here because actually the b equals zero Uh b one equals zero and flies at c one equals zero regardless of f But um, but these are actually unknown bits. Okay, so we don't know what's there We could in fact start in cycle four a new comparison, right? So we can do back-to-back comparisons without having any extra time in between We could put f equals one in initially and put a and b values for a next comparison So we can use the comparator without an extra spare cycle in the middle, okay? But from the point of view of our computation up here We don't care what those values are and we don't know what these values are Yeah, so put question marks for I know yeah Well, they will if you put f equals one Um f equals one just like up here f equals one forces those two to be zero We didn't care what the bits were here. They're not zero Here they might not have been zero f equals one forces c one and c zero to be zero That's why we're allowed to start a new comparison All right, so let's take a look then at area first and then we'll do delay So what do we have we've got one bit slice we have two flip-flops and then we have two nor gates, right for this election logic So here's our bit slice design we had six two input man gates and two inverters So Fixed two input man and two inverters for the bit slice What about the flip-flops? So here's a flip-flop Um, we had two latches and inside those latches we had four two input gates and an inverter but Actually, we can we can flip the sense of the inverter if we instead use Nor gates instead of man gates in this latch we don't need this inverter So that one is actually we can get rid of it in fact commercial designs Will actually be smaller so we'll assume the design we looked at but um, but if you really want and looked out That what people use in standard gate libraries are not as big as the design we did in class We can you can do this kind of thing with at the transistor level with fewer transistors Um, so here it would because we've got a common clock and so we would need to actually have the inverse clock to make sure the two are different We wouldn't normally ship around both the clock and the inverse clock If they're coming out of flip-flops. Yeah, yeah, so now now that we've seen where things come from Why they're free we might start counting when we know they're not going to be free when we'll need it inverter But in this case we can absorb the inverter into the latch by using nor gates and latch Yeah Yeah, it would it would cost you and it would also just cost area So the real the real counting you want to just count anything that you would physically need to use So And so here you don't need it because you can change the design of the latch to be an SR latch with no reviews Yeah Well, I mean it goes away so it doesn't Yeah But that would be another issue if we're really adding logic It would potentially Um, okay, so yeah, it's a good set of questions. I mean real flip-flop design Um, people actually do add timing sometimes to give the illusion that you don't have to have to wait for the signal to be latched So we're going to assume that it takes four gate delays of stability before we can before we can copy when we do the delay analysis Just explain that when we get this But people usually shift that by adding delay inside the flip-flop All right, so here's our count so six two input nan two inverter 16 two input gates and foreign voters um And so if we add that up we've got 24 two input gates and six inverters So that's our serial design So here it is down here independent event right doesn't matter how many bits we're going to use We've got the same number of gates there Whereas if we do a bit slice design every bit slice had six two input gates and two inverters Right, so those are multiplied by the number of bits slices So those are about equal when n equals four and for n bigger than four the serial design is small Right, so for any reasonable n if you wanted to compare 16 or 32 bit numbers or 64 bit numbers the serial design will be substantially smaller But the serial design is also going to be a lot slower so why Um, we just saw it's fewer right More gate delays Yeah, you're also going to wait for the clock cycle right so this may not be the thing that determines the clock cycle Right, it might be some other logic so this might be very fast compared to the clock cycle But that doesn't matter you still have to wait for n clock cycles So let me let me put all the reasons So one reason is all of the paths matter So when we talked about the bit slices we said well only the slice to slice past matter because all of the a and b bits come at time zero It's no longer true Those a and b bits are fed in one per cycle they probably come out of flip-flops Right, so they're not they're not coming at time negative infinity or time zero Right, they're coming at the start of the cycle So the past from a and b out to the z1 z zero outputs now those matter more that's one issue Second issue selection logic and flip-flops those are not free either their gate delays inside those and those those count to Right, and we have to pay for those And then the last one is again this may not be the slowest component in the system Right the clock can't go faster than your longest combinational logic So if this one happens to be the longest one well, that's fine then only factors one and two will matter If there's something else that's slower your clock will run even more slowly and as a result your sequential your serial Comparator will have to be slower because it has to go clock cycle by clock cycle So let's look at each of these in a little more detail so Yeah, I guess I kind of said all of this the the paths other than the slice to slice paths and our bit slice design only added constant time Right because all the a and bits a and b bits arrived at time zero And so we looked at that in the first bit slice and then even by the second bit slice in this design They were not relevant anymore Whereas whereas the slice the flight paths every time we went z1 z zero to c1 c zero We had to pay that for each bit slice, right? So that was the thing we multiplied by n Now in the serial design again a and b are coming up to start of the cycle So we have to make sure we pay for them to get all the way to the flip-flops And we have to wait for them to get to the flip-flops The flip-flops and the selection logic take time to store values and to produce values or gate delays on both latches And the selection logic sits between the flip-flops and the bits like so the clock cycle has to be long enough to count for all of those And then finally the longest path I said this a couple times now on longest path through combination logic will determine your fox feet And there's just one clock So whatever that longest path is is how fast you can drive your clock In practice what engineers are going to be doing is going and identifying the complex or important parts of the circuit often in a computer might be the adder Right because you do a lot of arithmetic Um But they're going to figure out what those are and try hard to make them fast or split them up into several cycles So if you look at floating point units for example There'll be fully pipeline meaning they can put a new set of operands every cycle And then they'll go through and take many cycles say eight cycles or more So you compute the answer for one set of operands Okay, so So engineers will work hard making sure those things work well And making sure they're not limiting the clock cycle although at the end of the day they may still be the things that limit the clock cycle Um, so even if a serial logic um Logics design only needs a tenth of a clock cycle. It doesn't matter. You still have to use n clock cycles to compute n bit operands You can't make the clock go faster for this well you could have separate clock clock domains, but um typically people don't want to pay for that Yeah Um People have tried that off and on for a long time to have asynchronous circuits and it's fairly difficult to get them to scale and any useful way Um They're people are starting now to do separate clock domains for different parts of the design partly because they can then turn them off independently More than that they can necessarily change the clock speed independently Although in the multi-process or chips having your processes run at different speed is also useful because the slower clock speed will still get some work done but will be low of power consumption Yes, yes good question. So let me come back to them a future slide The question is can't you put more than one bit slice and do a serial like design or maybe put two three four et cetera. Yes, of course you can So that will let me come back to that these are two extremists Yeah, the question Um, I my feeling is it's more the complexity is unmanageable than that it's um I mean, I've seen her in the research literature at least two or three times in the last couple of decades and never did industry take off with it And they're they're a handful of academics that get really excited about it. You do some interesting stuff But you've got to be able to manage the complexity to the point that engineers can use it in big design process which is difficult Okay, so All right, so let's let's go through and analyze this delay so We can count it gate delays are bit slice for the selection logic. So what about the flip-flops? So let's let's just assume that it takes four gate delays of stable De-input before the rising edge. So let's say we need that that de-input to be stable for four gate delays before the rising edge comes in order to guarantee we get the right value latch And that four delays after the rising edge before the output shows up. Okay, so it would just pick the number four You can pick different numbers and do the same analysis. Yeah No, so let me show you the picture. So this output here will will become available four gate delays after the rising edge So if we start at the beginning of a cycle this b This b1 will not be available until four gate delays later That's what I mean. And similarly if the d input arrives at time n then until we have to hold that for four more gate delays until n plus four before the next rising edge. So those are the two points. Yeah So are we able to measure gate delays much in terms of clock cycles usually gate delays are much shorter in cycles again So you usually not because the I mean gate delays are an abstraction right the process variations will give you huge slings on how long things really take Yeah, I mean the accurate time measurements the first thing to do would actually be go down to the transistor circuit level and do spice simulations But that's beyond our class. Yeah, so So let's assume rising and rising at t equals zero. So now we're now we're using time in gate delays again. Okay, so we're going to calculate gate delays for the minimum number of gate delays for one clock cycle. So these things accused and cubars become available t equals four. All right, so we said we'll wait for for gate delays after the rising edge. So it equals four. We get these outputs b one and b zero. Let's just also assume f a and b those are going to come from somewhere. So let's assume they come from some other flip blocks. So they also become available at gate at four gate delays. And so all these inputs at four gate delays. This thing here. Well, you've got a come you've got f coming in at four. You got these coming in at four one more gate delay for the nor gate. So you get the inputs to the bit slice at five gate delays. So then let's go back to our our bit slice. So this is just a slide for more analyzing it. So a to z one. We had three gate delays ignoring this not. I remember that the a input is going to come from a flip block. We already paid four gate delays. So we're going to get a little bit more. So let's assume we already have a prime b we've got three gate delays and c to c one. We've got two gate delays. So when we add that up. These are available at time five, but the path to the z outputs is only two gate delays. So that's five plus to a seven. A and B are timed for the path to z one and z zero three gate delays four plus three is also seven. So we get z one and z zero at time seven seven gate delays. And then we have to wait for more gate delays before the flip blocks will actually latch those we assume we need for for gate delays of stable input before the last value. So that means we've got 11 gate delays. So if you think back to our analysis of the bit slice design, we needed two n plus one gate delays for in bid operands for serial design. We've got our clock cycle has to be at least 11 and then we need in clock cycle. So we have at least 11 and gate delays for the serial design. And that means we're at least five point five and a half times slower and we may be even slower some other some other part of the system sets the sets of clock speed. All right, so this was Sasha's question. So let me go through this briefly and then and then we'll end. So these are simple designs meaning the complexity is low right we said, look, let's just focus on a bit slice. So we're in this space of pretty easy to do designs, but we're still at two extreme up right one is small but slow. And that's the serial design the other's fast but large that's a bit slice design. You can build anything in between right put two bits slices per cycle. It's very easy to do right just put them to put to side by side and then. And it's probably easier if it's if it's even then if you put three if easier if it's a multiple of three probably you're going to want 16 32 bits anyway. So putting four eight bits slices. That's not hard to do. You get a smaller than fully bits slice design you get a bigger than fully serial design and it'll be basically points in that trade off space as you as you use more bits slices that'll get bigger but faster. So we can also optimize more than one bit slice right we can take two bits slices and just think of it as one function and maybe even get it into two level logic and then that'll also be a faster and smaller design. So you can you can optimize in that sense. It will be faster faster than serial also right it'll still be smaller unless you add in right for whatever anyone it'll still be smaller than bits. Yeah, you can optimize you can optimize that function right so instead of saying well how do I do one bit you could say how do I do five it's your 10 bits right and I can solve that as one problem and that'll be. Yes to some extent the tools will help with that okay so let's stop there and if you want to ask more we can just come down afterwards. So it's over time so I want to keep everyone. Thank you. you you you you you you you you you you"
    },
    {
        "ECE120-2016-08-26-LEC-03-slides.mp4": " Okay, I think it's actually three o'clock now. So let's go ahead and start. So today, I want to review a little bit. I think maybe I kind of sped through the first derivation of two's compliments. I'll back up and start that again. And then also do in addition to the graphical derivation, we'll do an algebraic derivation. So I'll explain why we're doing too when we get there. Then we're going to talk about overflow for two's compliments. So you've seen unsigned addition, you know that a carry out means overflow, meaning that the answer we get is wrong. That's what we mean by overflow. We may get tabullian logic and go through a little bit of that today, otherwise we'll continue that next week. I had a post lecture thought on Wednesday. If someone had suggested that in the range, I think it was 100, 231, we should say 42. And I just completely failed to realize that 42 is 100 based square root 42. So that was good. All right, so these things, I'm going to take it out of my bag. They're not connected. Oh, shoot. Now, technology. I have to follow the rules. All right, let me use this opportunity to take this from my bag and show you. Here we go. So you can buy this thing for $18 if you'd like. You'd be working now. I'm not working. Okay. Sorry, I may end up wandering back and forth. You can buy this thing now for $18 in the EC supply center, which is, you know, walk over to that side, turn left, go down to the end of the hall. Remember, this is free online. So if you're happy looking at it on a computer screen somewhere on your mobile or something, if that's comfortable for you, you don't need to pay for it. If you do want a hard copy, you can get it for $18 or you can print it yourself too. It's always hard to gauge whether you will save or spend more money if you use your print quoted or print class notes, but you have your options. I want to try one more time. There we go. Okay. So remember, we decided we were going to try to use the same piece of hardware. So we've got a piece of hardware, someone's designed to add unsigned numbers, just like base to arithmetic, right? Adding two base to numbers. But this piece of hardware adds two numbers. And what it produces is the correct answer, mod 2 to the end. It's, we saw that the sum that comes out, the bit pattern that comes out will be the correct answer, mod 2 to the end. And we wanted to develop a representation for signed integers that also allows us to use that same piece of hardware. And then we'll be able to use that one piece of hardware to add both signed and unsigned numbers. And that will be the two's complement representation. So you might wonder, what is two's complement? Where does that come from? We'll get there. So here's a circle. What you see around the circle inside are bit patterns. And outside you see decimal values. So this is a way to represent the, to show, to illustrate the three bit unsigned representation. So the bit patterns are inside, the numbers they represent are outside. And if I use the circle idea, then I can think about addition as simply starting somewhere and if I want to add, I'll count around clockwise. If I want to subtract, I'll count around counterclockwise. So for example, if I start at four and I add three, I'll count around three spaces around the circle and I'll get seven. So that's addition using this circle abstraction. And the answer is always correct mod eight. So if we had started at seven and added four, we would go around one, two, three, four spaces and we'd get three, which is not correct. But it's correct mod eight because three equals 11 mod eight. So if we want to subtract, we go the other way. And I said, well, OK, the circle, because arithmetic with unsigned addition is simply arithmetic mod eight for a three bit unsigned right? We can also use this as a way to illustrate modulus. So we'd go around the circle, we'd write down the numbers, just like we did. But we could keep going. So we could keep writing 8, 9, 10, 11. And if we did that, what you'd see is that each of these groups around the outside of the circle are just a bunch of numbers that are all equal mod eight. So you pick one, two, and 10, two equals 10 mod eight. Remember mod being equal mod eight means that I can add or subtract some number of eights and get the other number. So I can also go in the counterclockwise direction. And so I'm basically mapping the whole integer line onto this circle. And so I'll get eight different groups and each one will have an infinite number of integers. The overflow then happens because we can't have a representation where one bit pattern means all of these things. And a representation, remember, can't be ambiguous. Computers are not going to be able to guess which one was the right answer. So we have to pick one label. And when we pick a label, if it doesn't correspond to the correct answer, that's where the overflow comes from. But we don't have to pick the labels we picked for unsigned. We don't have to pick zero to seven in this case. So we could pick some numbers in the positive direction. So say one, two, three, and we could pick some numbers in the negative direction. Say negative one, negative two, negative three. And then we could try some addition. So we could go from negative two, add three, again, corresponds to just going around the circle. So three steps, so negative one, zero one. And you'd see that negative two plus three is in fact one. Now of course we're going to get overflows and the overflows will be different. So for example, we said, well, what's two plus three? So we'd start it two, and we'd go one space, two space, three spaces, and we'd say, oh, two plus three is negative three. Well, that's not right. So we still have overflow problems. It's just that now we have a representation for signed integers. And we can use that using the same approach to arithmetic, in particular the same hardware device to do the addition. So this is one way to derive two's complement. So you want to know, well, what's the bit pattern for negative three? In three bit, two's complement. Well, there it is. So you can get all of the bit patterns for two's complement by doing it that way. So the general scheme, if you want to do it graphically, is outlined here. So you draw your circle, and there's a bigger circle in the notes, but you don't really want to draw the circle, but it's a good way to understand it. You draw your circle for n bits, two to the n points. You started zero at the top. You write your unsigned bit patterns clockwise around the circle down to the bottom. And at those of your positive, well, you write the bit patterns all the way around. You write the positive numbers around the right half of the circle, negative numbers around the left half of the circle. There's your two's complement representation. So yeah, question. So what is this, what is this one zero zero going to mean? Let me come back to that later. Good question. So the question is, well, I didn't label this thing. So what should we label it? Let me come back to that at the end. Good question. Okay, so that's our approach. We can also do it algebraically. So why do I want to show you both ways? So it turns out that most students will understand the graphical approach, or they'll understand the algebraic approach, they'll feel more comfortable with one or the other. They're completely mathematically equivalent. I assure you 100%. If you understand one, it's good. You're done. You understand why we do two's complement the way we do. So don't worry if you don't understand both. If you understand both, that's great. But I do want to show you the other one because some students will understand this one better than the graphical one. So let's do some algebra and see if we can find a way to get the same answer by doing algebra. So an algebra, remember that the adder is going to produce some bit pattern, which we're going to call some. So if I add two bit patterns A and B, then I get the answer some, and that some will represent the value A plus B, but only mod 2 to the N. So it might not be exactly the right pattern because it might not be able to fit the pattern A plus B into N bits. But it'll be equal mod 2 to the N. So when we define N bit 2's complement, the first step is, well, let's define the positive numbers. So we'll define 0 up to 2 to the N minus 1 minus 1, and those will look exactly like unsigned. So half of our bit patterns will turn into positive numbers. And those will be exactly the same representation as they were for unsigned. And then the problem is, how do we find the bit patterns for the negative numbers? So let's see what we can do. What do we need? What problem do we need to solve? So for every number that we have, let's call it a number K. So K is in this positive range. I just talked about from 0 up to 2 to the N minus 1 minus 1. So for every positive number, we have to find a bit pattern that's going to represent negative K. That way we can represent for every positive number we have, we can represent its negative value also. So somehow we have to find that bit pattern. The bit pattern has to have N bits. So if we look at that bit pattern as a base 2 number, it has to be from 0 up to 2 to the N minus 1. If it's bigger, it won't fit in N bits, so it's no good. And then we have to pick the pattern in such a way that if we take any integer M and we add M to negative K, then that's the same as adding this bit pattern we're going to pick to represent negative K, piece of K. So if those two are equal, mod 2 to the N, then the bit pattern K will give us the right answer when we plug that bit pattern into this piece of hardware that someone built for us, right? That does unsigned addition. The other constraint, so let's say we find a good bit pattern. If that bit pattern is the same bit pattern as a positive number, then we have ambiguity, so the bit patterns we find, they can't be the same bit patterns we've already used to represent positive numbers. So remember, we used all of the bit patterns starting with a 0. We used all 0s mean 0, 0 followed by anything else means a positive number. So whatever bit patterns we pick, they better start with 1. OK. So now to solve this problem, we'll do some algebra. So we've got a property up there, I just copied it. So that's what we need to solve. So let's subtract M from both sides. So remember that addition and multiplication distribute across the modulus operation, right? So we can just say, OK, subtract M from both sides. I can subtract M from both sides of the equation inside, and this will continue to hold. So subtract M from this side, to get minus K, subtract M from this side, to get piece of K, and negative K equals piece of K mod 2 to the N. So then I want you to remember that, well, 2 to the N equals 0 mod 2 to the N. If I add 1, 2 to the N to 0, I get 2 to the N, so those two are equal. And then I can add those two equations. So on the left, I'll get minus K plus 2 to the N, or 2 to the N minus K. And on the right, I'll get PK plus 0, just PK. So 2 to the N minus K equals PK mod 2 to the N. That's what we need to solve. Turns out there's one easy solution to that, which is just to say, well, why don't I just pick the piece of K, or a piece of K is actually equal to 2 to the N minus K. It just has to be equal mod 2 to the N. But let's just pick the one where it's actually equal, period, not mod 2. Now in that case, we have K running from 0 up to 2 to the N minus 1 minus 1. So if you plug that in, you'll see that that means the patterns we have are at least as big as 2 to the N minus 1 plus 1, and no bigger than 2 to the N minus 1. In other words, they're all end-bit patterns, and they all start with 1. But those are all the patterns, the bit patterns we didn't use for the positive numbers, and we didn't use for 0. So those are all free patterns. So now we have an algebraic definition. We're done. Negative K is represented by this pattern 2 to the N minus K. So that's an algebraic definition for 2's complement. It's fully equivalent to the graphical derivation. If you do it one way, the other way, you'll get exactly the same answers, and you'll have the 2's complement representation. Having done it this way, you can then use the same piece of hardware to do addition, subtraction, et cetera, for 2's complement and unsigned values. Ready for the name? I'm ready. You can tell. OK. So let's do some sanity checks. So if I take negative K and I negate it, negative, negative K, better get back the same answer, right? So let's just make sure, in fact, I do. So what's the bit pattern for negative, negative K? So we said, well, negative K is given by 2 to the N minus K. So we can substitute once. We can replace negative K with 2 to the N minus K. And that gives us this expression here, negative quantity 2 to the N minus K. And then we can substitute again, because we should just be able to negate that, that parenthesized value. And what we'll get is 2 to the N minus the quantity 2 to the N minus K, which then we can just cancel the 2 to the N's and we'll get K, right? So that gives us the right answer. So that's good. I mean, if it didn't give us the right answer, that would be kind of disturbing. That would mean something's wrong with the representation mathematically. OK. So, so let's do that. So when I want to calculate negative K, how do I do it? Well, I go calculate the bit pattern 2 to the N minus K. So one way to do that is you line them up and you subtract. But you can do it that way if you want. I don't like doing it that way. It's painful. It involves a lot of borrowing. You've got a bunch of zeros there. You've got to do all these boroughs. So instead, remember that I can write 2 to the N as 2 to the N minus 1 plus 1. So how does that help? So let's write that down. So we're going to calculate 2 to the N minus 1 and then subtract K and then add the 1 back in. So for N equals 5, what is 2 to the N minus 1? Well, it's 1, 1, 1, 1, 1, 5, 1s. For N equals 20, it's 21s. For N equals 100, it's 100 ones. So now the subtraction's a heck of a lot easier, right? It's easy to subtract indecent from 9, 9, 9, 9 because you never have to borrow. So here, in binary, we subtract from 1, 1, 1, 1, 1, we never have to borrow. All we have to do is say, well, if I have a zero, I put a 1. If I have a 1, I put a 0. It's called the 1's complement. Adding 1 more gives you the 2's complement. And there's a so funny. Yeah, it's not a funny joke, I know. But that's where 2's complement comes from, at least in my urban legend version. So if you want to remember, it's the 1's complement plus 1. Wow, no one laughed and said, even at my funny laughing. All right, now you're laughing. So I want to just mention this because you will hear a lot of terminology. You know, an engineering, engineers try to be precise, right? We try to say exactly what we mean, we define things mathematically, and we mean precise things about what we're working with. Unfortunately, once those terms get out into sales and marketing and just general use, they tend to get abused and misused. And so this term, it comes from different places, but we'll try to be consistent in the stuff we give you. Assignments, exams, things like that. You will hear the phrase, take the 2's complement, right? And by that, people may negate a bit better. And we'll try not to say it that way, right? Because people do get confused, especially when they're just learning between the 2's complement representation and negation. So taking the 2's complement as a negation operation, you can take any bunch of bits and you can apply this negation operation we just talked about. Now, whether or not the bit should be interpreted as a 2's complement number or not, that's up to a human, right? Bits are bits. Computer doesn't know what the bits are, right? So it's up to you as the human to say, well, these bits are 2's complement number. And so it's okay to negate them using 2's complement representation. So we'll talk about when we want you to do something like, you know, calculate the ones complement and add one, we'll say negation instead of take the 2's complement. And for clarity, I suggest you try to do the same, right? Otherwise, we might have some confusion when we talk, yeah. Does that one? With a 2 add up to 0. Oh, so if you add k to negative k, will the 2 add to 0? Yes, they absolutely will. So if you add one's complement, then they will add up to 1 1 1 1 1, however many ones in your representation, right? Because everywhere you have a 1, you have a 0 and the other and the negate. Yeah, so one's complement actually was a computer representation. And you have to go back and replace the 1 1 1 pattern with 0 because that's 0. So it makes, again, the hardware more complicated. We don't really talk about it in the class, but it is another way to do negative numbers. Question. Yes, Eric. It's a circuit. I'll have a review of the 100 bits by. Yeah, so, okay, so the question I want to repeat it so it's on the video. The question is, you know, am I saying it's different because there are many ways to negate, but 2's complement is a particular style. Yes, and no, 2's complement is a representation. It's a way of saying, for some decimal value, how do I come up with a bit pattern? And so I want to keep that away from operations like negation using that particular representation. So yes, what you said is correct, that negation on a different representation is done differently. So if we just sit down and randomly assign numbers to bit patterns, negation would involve looking at whatever table we drew. Whether it's more systematic because it's designed to be simple so that the negation process is systematic. And negation only applies for 2's complement, the way we defined it. But I'd like to use 2's complement only to describe the representation for signed integers that we've just talked about. Yeah. So that's why I just find it confusing to use it as a verb to say take the 2's complement. Because I don't know, I found students have gotten themselves kind of tangled up in differentiating between operations on bits and the representations, which is just a question of how you represent using a bit pattern, a particular decimal number. Any other questions? Okay, good. Okay, so let's do an example. So as you know, I like 42. We may remember that 42 in 8-bit 2's complement, as well as unsigned, is represented by this bit pattern 0, 0, 1, 0, 1, 0, 1, 0. And so to negate that number, to calculate negative 42, first we'll complement the bits. So I will take 0 and replace it with 1, 0 with 1, so forth. So this is the 1's complement of that bit pattern. And then I'll add 1 to that and that will give me this answer here where I've negated the bit pattern and gotten the 2's complement representation for negative 42. So there's an example. And if you wanted to, you could add these 2 up. I don't have it drawn for you. But if you wanted to add these 2 up, then what you'll see is that you get zeros in every position and that the 1 carries out. So in that high 1, of course, will be thrown away from the end bit representation. So you get all zeros with a carry out if you add k to negative k for any k. Except 0, but negative 0 is the same. So how do we convert between 2's complement and decimal? For any non-negative number, it's the same. The representation is the same. The bit pattern is the same and unsigned to 2's complement for all of our non-negative values. And so converting from decimal to 2's complement for those numbers is identical. You can go either direction, do the same process we talked about earlier in the week. What about negative numbers? So one way to do it is if you've got some decimal D less than 0 that you want to find the bit pattern in 2's complement, first convert negative D. So that'll be a non-negative number. There actually will be a positive number. And then negate the resulting bit pattern. So take the answer you get and just negate it. And that'll give you the bit pattern for D, which is again negative. If you want to go the other direction to convert a negative 2's complement bit pattern into decimal, well, you can start by negating the bit pattern. That'll give you a positive number. And then you can convert that to decimal using the unsigned approach. And then the answer is minus D. So if you calculate decimal D, the answer is minus D. So that's one way you can do it. Students usually find this way easier. And you can see the polynomial up here. And you might think, I don't want to write polynomial. But let me just walk you through it. And then you'll see the answer at the end. I just want to understand why the approach works. So let's say we have some negative number, negative k. And we want to calculate the bit pattern, or maybe we've got the bit pattern, and we want to calculate the value negative k. We know it's negative because the first bit is a 1. But how will we do that? Well, the bit pattern is going to have the value 2 to the n minus k, as we talked about. So we can write our polynomial, which you might remember from a couple days ago. And we know that a sub n minus 1 equals 1, right? Because that's how we know it's a negative number. So if we plug that in, we've got a 2 to the n minus 1 over here. And we could subtract this 2 to the n from both sides. That'll give us this equation down here. This part of the polynomial is identical. The only thing that's changed. So on the left, we no longer have our 2 to the n. And then on the right, we have 2 to the n minus 1 minus 2 to the n. In other words, this thing is minus 2 to the n minus 1. So I can replace that then. I know, again, a sub n minus 1 is 1. So I can say minus a sub n minus 1, 2 to the n minus 1. So now if you look at this polynomial, it looks exactly the same as the one we used with place value for unsigned, except that we put a negative sign on this leading bit. That's the only difference. So if you want to calculate the value of a 2's complement number, you can use this equation. Instead of counting the first bit as 2 to the n minus 1, counted as negative 2 to the n minus 1. And that'll give you the right decimal answer. That's the way people mostly prefer, it seems, rather than doing it as I explained on the last slide. I do want to point out, this way also works when a sub n minus 1 equals 0. So for non-negative numbers, this thing is 0. And so this term just goes away. And then what you're left with is identical to the unsigned equation. So either way, you can use this approach where all you do is negate the first bit's value to calculate the value of a 2's complement bit pattern. And whether it's positive or negative doesn't matter. Does it make sense? Yeah. And if you want to go through the algebra, make sure you understand it. It's fine. But this approach definitely works. I just wanted to illustrate why. Yeah. Yeah, sure. Let's go over to notepad then. Good idea. So the question is, can I show an example? So let's write up a random, somewhat random. There's eight bits, huh? Okay. So our place values then are 128. So rather negative 128, that's 2 to the 7. And that didn't work. Sorry. You wouldn't. Oh, wow. I think it's because I'm on HDMI. Okay. So I will then try to make it bigger. And this will not work well on the little grim. Sorry about this. This is not the best. But I will try to make it big enough for you. Let's just do six bit. It's kind of the same. And I think it'll save me space on the board. So hopefully everyone can see it. Can you see it on the right side? You can see it. OK. So we've got 111001. So the place values here are 124, 8, 16. And instead of 32, negative 32. So we've got negative 32 plus 16 plus 8. The four in the two places are zero, so we don't add those. So we've got negative 32 plus 16 plus 8 plus 1. So let's just add up the positive part. So 16 plus 8 is 24 plus 1 is 25. 25 minus 32 is negative 7. Question. So again, that was, I guess I didn't need to turn this off in that case. OK. It comes back only when I do PowerPoint. That was what we derived as this equation for interpreting two complement bit patterns as decimal. So by this derivation, we showed that we can plug in this equation. So that'll give us the value of negative k of the particular pattern. The negative k on the left, if it's positive, is just the positive part. You don't actually negate it or anything. This equation on the right will give you the right answer for both non-negative and negative two complement bit patterns. But here's an example. This is negative 7. And had we gone the other way, so maybe we'll try to do it on the right. So 111001. You can see this over there. So let's take one's complement. So I get 0, 0, 0, 1, 1, 0. And then I'll add one to that. And I'll get 0, 0, 0, 1, 1, 1. And then if you look at this pattern, this is the force place. That's too small. This is the force place, the two's place, and the ones place. So yeah, those up you get 7. And so again, negative 7. So regardless of which way we do it, we'll get the same answer. I think most people find this way simpler in my experience. So it's OK if you didn't follow the algebra. I'd encourage you to go back and understand it. Yeah. Yeah, so the question is, are we going to ask you to prove this or do we just want you to know why it works? I just want you to know why it works. So let me come back to you in a second. So there's got him George Polio, who used to teach at Stanford, who's has a math dictionary, really. And he thought that the way you learn math and the way you become good at math is to see different mathematical techniques. And then to pull those out of your toolbox and use them. So I will try to expose you to different approaches, different proof styles, different ideas and mathematics that underlie what we're doing in digital design and digital systems. We want for the most part in this class ask you to do a lot of proofs. Honestly, a lot of the optimization and things like that will be automatically done for you these days by computer-aided design tools. But we want you to understand how they work. So there's a certain amount of things that you'll see in the next few weeks, but not proofs. So this one, we just want you to know why this particular equation works. OK, sorry, someone here. Yeah. So first of all, if I just draw some bits for you, have no idea what it means, which is something that hopefully came up in discussion section yesterday. But if I tell you it's too complement, then you can look at this bit and say, oh, it's negative. So one means negative, zero means non-negative. Yes. Yes. So if we go back, I put down my little clicker, sorry. If we go back a slider to, so negate the bit pattern, we did that convert to decimal. We got seven answer is negative seven. Yeah. Yes. That's right. First bit will tell you whether it's actually negative or non-negative. Zero starts with a zero also. OK. Anything else? Yeah. Yeah. Yeah. So if the number starts with one, that means it's negative. And you can do it either way. You can negate the bit pattern, convert to decimal D. That's what we did over here. So the number started with a one. So we took the ones complement added one that gave us the negated bit pattern, calculated the value of this negated bit pattern is seven, and the answer is negative seven. Or we can simply plug into the place values with the first place value negated over here. And add up these numbers instead, and we'll get the same answer. So either approach works. Yeah. The next slide? Oh, the top part. So OK. So if you have a number, so let's say that we wanted to do negative 42, actually, I did it already. Or did I do it? Let's go back. I did it here. So if you want to know what negative 42 is, you start by calculating 42, and then you negate it, and that gives you the answer. That was all. Does it make sense? OK. I'm sorry. I can't hear you very well. Yeah. So the question is, is there a reason that the process works this way in base two? This is not human base two. I mean, human base two, we write a negative sign. This is a particular representation that we chose to use the mathematical idea of modulus to define. And because of the way we defined it algebraically or graphically, you get the same answer, that's why this process works for negation, basically. I mean, if you look at the algebra, well, because we defined it to work for negation, mod 2 to the n. Yeah, by definition, that's why it works. OK, yeah. There is not. There is not. So no negative zero. Yeah. OK, yeah. So there are resources available online. Also, the lectures are being videotaped. And the slides are online. So all of those resources, thanks for pointing out. I mean, calculating the bit pattern for the negative value of what's being represented. So here, this bit pattern represents 42. So if you want to calculate the bit pattern for negative 42, you would take the ones complement and then add 1. And that would negate the value of the bit pattern and give you a different bit pattern. All right, let's move forward. So what did you see that one worked? OK, so now back to your question. So you said, well, what about that last bit pattern? What is that? So what should it be? Should it be 2 to the n minus 1? We could make it be 4, a 3 bit, 2 is complement. Maybe negative 2 to the n minus 1 could be negative 4. We could just say, I just leave it undefined. So what do you think it should be? Yeah, negative 4, why? It starts with a 1, good answer. So that's why. So it's a little imbalanced. But in 2's complement, the 1 leftover bit pattern is always negative 2 to the n minus 1. Because that way, this simple approach of, well, just look at the first bit. And that'll tell you, non-negative or negative still works. If you chose another answer, it wouldn't work. If you chose to make it 4, you would have to look at all of the bits to tell, well, is it positive or negative? So instead of doing that, we always choose, or rather, 2's complement is defined for that to be negative 2 and 2 to the n minus 1. All right. OK, so I added a couple of these in today. And I guess I can't flip and show you the tools because I'm on the wrong interface here. So sorry about that. If you want to practice conversion, there is the online tool. It will give you instant feedback. It will let you do as many examples as you want and choose complement as well. It will also let you do this extension I'm about to show you. And so all of these things, you can go play with the tool, get experience, get feedback on whether your answers are right or wrong. OK, so sometimes we might need to take one bit pattern in a certain size representation, say, end bits, and extend it to an n plus k bit representation. So we might have, for example, 5 bit unsigned and we want to create 10 bit unsigned. So how do we do that? So if I have a 5 bit unsigned number, and I tell you, I want the same number, but I want the 10 bit unsigned representation for that number. How would you find that? Yeah. Yeah, exactly. So add some leading zeros. We base it on base two. We base the whole representation for unsigned and base two. And we have the add leading zeros already. So if you want a bigger set of bits, we'll add some more zeros. Not so hard. OK, good. Good answer. Zero extension. We have a name for it. What about two's complement? Ah, good. So Eric says it depends on the leading number. So for non-negative values, that's the right answer. But let's do it one case at a time. So non-negative values, two's complement is the same as unsigned. All the non-negative numbers are the same. So we just add k more leading zeros, just like we did with unsigned. So that's easy. What about negative values? What do we do there? OK, let's do some examples. So I was going to do these on notepads. So sorry, that's not going to work. So negative five has this bit pattern, 1, 1, 0, 0, 1, 1. We'll do something concrete. So we have these two five bit patterns. So let's see, 1, 1, 0, 0, 1. Is that right? 0, 1, 1. OK, so this is negative five. So how about the 8-bit two's complement representation of minus five? 5, 5, 6, 7, 8, 7, 8, 7, 8. OK, so let's do that. So to get five, I'll go to this one's complement, and then I'll add 1. So this is five. And then you just told me I can convert positive values by adding zeros, right? And then I'll convert back. And I have to add 1 again, right? So this is negative five and 8-bit two's complement. Anyone notice anything? I just added some ones. Do you understand why that's going to be the same every time? OK, so basically going around the top of the circle into the negative part, negative 1 is always going to be the all ones pattern, right? And so forth and so on. They're always going to have the same ending bits. Here, the other way to think about it is when I go back and I add my leading zeros, those just become leading ones when I negate again. My leading zeros become leading ones. So negative five is 111, 110, 111, just as we just derived. And negative 10, what do you think? Good. 111, 10, so what about this space? It's just for us. Computers don't have those spaces. All right, so that was just to make it obvious on the slide. So how do we convert? We take the sign bit and we copy it. It's called sign extension. So if you want to extend from a smaller representation, smaller two's complement representation to a bigger one, you take the sign bit and you make K extra copies of it. You want to go from N to N plus K. Right? OK. All righty. So now we need to start thinking about arithmetic again. We know how to do overflow checking for unsigned. We decided, well, we do the operation. We add two numbers together. We get to carry out. That's going to be an overflow because we have to throw that carry away. We don't have space for it. So what about two's complement? When I add two two's complement numbers with N bits each, how do I know if it's right or wrong? Let's go look. Supposed to be based to additions. Supposed to work exactly the same way. Let's take a look. So here's the first example we did with unsigned. So let's do it again. So I had 14 on top. I got four on the bottom. So there are also the representations in two's complement. So let's add them up. So 0 plus 0 on the right. Good. 1 plus 0. 1. 1 plus 1. 0, 1. Be really embarrassing if I made a mistake. All right. 1 plus 1 plus 0. Here are the 1. 1 plus 0 plus 0. Good. OK. So when we did our unsigned, this gave us the right answer. And if you look at that as unsigned, you say, OK, well, that's 18. And then you're happy. So what is this in two's complement? It's not 18. 18, you can't represent it. So it's negative 14. So something went wrong. So we had an overflow, even though we didn't have a carry out. So carry out is not going to tell us quite overflow with two's complement. Now I want you to notice something. The arithmetic is exactly the same. We didn't do anything different than when we added these bit patterns. And of course, that has to be true, because we defined this representation so that we could use the same process to add numbers. So if someone asked you, well, can you add this in two's complement? Now can you add it in unsigned? Well, you probably don't need to do it twice. It's the same. How you interpret the answer, though, is different. So here, if we interpret the answer as two's complement, the answer is wrong. So this is an overflow. All right. Let's do another example. So this was the second example we did. This one overflowed for unsigned. So in unsigned, this was 14 plus 21. And I said, oh, you should remember that that equals 3. So it's kind of given away what we're going to get. But let's go ahead and do it. So 0 plus 1 is what? 1. 1 plus 0. 1. 1 plus 1. 0 here, the 1. 1 plus 1 plus 0. 1 plus 0 plus 1. 0 here, the 1. And yeah, that one's a carryout. But we've got to throw it away. No space. So what we get is 0, 0, 0, 1, 1. And when we interpret that as two's complement, what was on top was 14. What's on the bottom is minus 11. 14 plus minus 11 is 3. So it was right. So no overflow. It's way to carry out that we didn't get an overflow. So carryout is not overflow, which is complement. What is, how do we tell? And how do we know when something's gone wrong? So I claim that if I add two's complement numbers, and one of them is negative, and one of them is non-negative, that never overflows. That's my claim. You ready for the proof? Good. Get to work. Yeah. OK. Yes, that's a very good way to prove it. So Eric suggests that one way to prove it is that if you look at the range, and you then contain one number to be in the positive range, and the other number to be in the, I'm sorry, non-negative, and the other number to be in the negative range, and then you look at the possible range for the sum, those will always be representable answers. And yeah, that would be enough proof for this claim. That's right. So good, quick answer. So once you do it, you can go see if my answer in the notes is correct. So everyone else should prove it to themselves, and then go read it. OK. So very good answer. So let me give you a long definition. Well, again, without a proof. So if I add these two numbers where the sine bit is A, and the sine bit is B, and I get the answer sine bit is S, and I claim the following. And so let's make sure you believe me, at least in these two cases. So if the two add ends, A and B, or A and B are the sine bits, but if these two things I'm trying to add are both non-negative, and then the answer I get is negative, that's wrong. You believe that, right? If I add two non-negative numbers, I get an in-game answer, or they can't be right. What if I go the other way? So this second case down here, the two add ends are negative. I add two negative numbers, and I get a non-negative answer. Also wrong. OK. So I think people agree with those. The hard part of this proof is actually the other direction, showing that if my answer is wrong, it has to be one of these two cases. So again, proofs in the notes, you should figure it out, and then go read that proof, and check that I got it right. That's a lot of words. Engineers hate words. I was going to joke you should say this five times quickly for me, so you remember it. I won't put you through that. All right. So there's more concise way to write that using Boolean algebra. So I'll explain what Boolean algebra is in a minute, but this is how we write overflow. So overflow is equal to not A and not B and C, or A and B and not C. So A, B and C were the sign bits. So what are these ends and ores and stuff mean? So they're Boolean operators. So what is Boolean algebra? So these Boolean operators were invented by a guy named George Bull to reason about logical propositions about 150 years ago, little more. Originally, they were operating on true and false, but we're digital system designers. So what are we going to operate on? Bits. Good. Everything is bits. Zero false one is true. Be careful not to confuse these operators with English words. They don't mean the same thing, and it's easy to do. So do not confuse them. The meanings are not the same. They happen to be English words, but the meanings are not the same. And I don't think we're going to get through them all today, but I'll emphasize that as we go through them. So I think we can go through this brief, actually, maybe I'll give you examples here. So there are four that I'm going to tell you about. So the first one is AND, and is the all function. So you can have any number of inputs for an AND. And the output is a one if all of the inputs are equal to one. Otherwise, the output is zero. So that's how we define the AND function as the all function. Yeah, so let's say you're operating on four different operands. If any of the, I'm sorry, if all of those operands are one, then the output of the AND function is also a one. And otherwise, it's a zero. So it's all and gives a one if all of its inputs are one, if all of the operands are one. The OR function, that's similar to how we usually use AND in English. That's one reason it's confusing. OR is going to be different. So OR, you should think of as the any function. So we'll have some number of inputs, some number of input operands. And if any of them is equal to a one, the output will be a one. So that's the OR function. So this is very different from English. If I invite you to my house and I say, oh, would you like some coffee, tea, milk, or orange juice? And you say, yeah, all of them. And I might think you're a little rude. Usually, people mean, yeah, would you like to pick something to drink? Not, hey, why don't you just take all the liquids in my house? So in English, sometimes people say that English is exclusive OR, and by that they mean, well, you should pick one of. But we have an exclusive OR in Boolean logic, and it doesn't mean one of. So exclusive OR, let me jump down here. Exclusive OR is the odd function. So exclusive OR, XOR, as we usually call it, returns a one. If an odd number of the inputs are one. So when you have two inputs, that's sort of similar to English OR. But for more inputs, it's not the same. So XOR is the odd function. And then finally, we have the not function. And not is simply the logical complement. So if you say not of zero, that's a one. If you say not of one, that's a zero. So I want to show you the truth table. So this thing is going to help us understand different Boolean operations. There's another tool that you can use to familiarize yourself with truth tables, if you want. You can go play with them. But this is truth tables, what it looks like. So you can see on the left, we have the inputs, A and B. And underneath those, we have all the possible combinations of those inputs. So for two inputs, we have four different combinations, four bit patterns. And on the right, we have space to write the output for a particular expression, for a particular Boolean expression operating on A and B. So usually, we list these in binary order. So we'll start with zero and then zero one, one zero, one one. So what we'll do, I think, starting on Monday, is go through each of those four Boolean functions and build up the truth table for them. So quick question. OK, I'll leave this up. So thanks a letter room, though."
    },
    {
        "ECE120-2016-08-29-LEC-04-slides.mp4": " We're going to pick up where we left off. We just introduced Boolean functions. So we're going to look at that, go through, make sure you understand them all, do truth tables for them, and then talk about logical completeness. I think we'll get pretty far through fixed inflowing point. Not sure we'll finish that all today. On Wednesday, we'll wrap up representations. And then on Friday, we'll start talking about C programming. So that's kind of the look ahead for the week. You have a lab do Wednesday, shortly after class. So if you haven't looked already, please look soon. I decided because one of my colleagues told me that some of our students, particularly freshmen, kind of got panicked a little bit last year or last semester, rather. And so I will go hang out in the lab tomorrow for office hours. So I know a couple of you asked me, and normally I met Miyazaz on Green Street. But instead, I'll go sit in the lab. So if you were thinking of coming to office hours would be a good chance to do the lab. It's like 12 pages of reading. So it's a lot of reading. It's not actually that much work, I think. Many of you have done it already, just out of curiosity. Oh, awesome. Good, great. So if you're one of the people in the room and there's feeling like, wow, I haven't done this, and I'm feeling panicky, hopefully you can make it tomorrow to my office hours, sit down, do it, and I can help you out if you have problems. Otherwise, there are lots of office hours. So look on the schedule on the wiki, and you can find other people. So a couple of reviews. So we talked about four functions on Friday. We talked about the AND, which is the all functions. So if all of the inputs are one and outputs are one, otherwise is zero. We talked about OR. If any input is one, it outputs a one, otherwise outputs a zero. We talked about NOT, which is just complement. Put in a one, get out of zero, put in a zero, get out of one, and we talked about XOR, exclusive OR, and how it expands, which is the odd function. So if an odd number of inputs are one, it outputs a one, otherwise outputs a zero. So those are the four we looked at. And I introduced this idea of a truth table. So again, a truth table is just a way of writing down a Boolean function. So we write down the inputs on the left side of the line. We write all the combinations, usually in binary order, given the order we've listed the variables. And then on the right side, we can put the outputs for each of those lines. So last time, I kind of bungled my management of my display. So this time, let me just go show you. So again, this is the easiest way I know to find things. It happens to involve going through my website. But there on the F16 link, you can find all of these exercises. And down here, there's lecture videos and lecture slides and stuff like that. But just remind you, there's these tools here. And so if you want to practice unsigned or practice 2's complement, you can change the number of bits. If you really want to challenge, you can go to 16. I don't think there's really that much practical utility in doing that kind of long example. But if you really want to make sure that you can do that repetitive translation stuff, you can play with 16 bits or you can do it with as few as 4. You can see at the top, there's also a floating point. So when we talk about that today, you can play with that. There's also bits, which are the four functions that I told you about just a second ago, the Boolean functions. And you can make sure you understand applying those to sets of bits. You can also go do things like extend. So if you want to sign extend or 2's complement pattern, you can make sure, just copy the sign bit. So it's basically just copying. But just to make sure that you understand all the material, there's a lot of different exercises in here. If you feel uncomfortable with anything, it'll give you instant feedback. Let's see if I can get this one right. Kind of embarrassing, wouldn't it? Whoops. OK, looks like I got it all right. So on your mobile, you can push the button. If you're typing on your laptop, you can push the button with the mouse. You can push enter. It'll highlight the ones you got right in green. If you put something wrong, again, it'll show you what you got wrong. So let's just go put a couple of wrong. So those will show up in gray and you can go back and check them. So you can do as many exercises you want, just make sure you understand how things work. So let me switch back to PowerPoint. Oops. Let's look at it. All righty. So those are the exercise tools. All right. So now let's go through our four functions. And I want you to help me kind of fill in these truth tables. So let's start with AND. And I'll also give you some more notational knowledge and how to draw gates and stuff like that. So let's start with AND. So what's 0 and 0? 0. Good. What's 0 and 1? Good. 1 and 0? 0. Good. 1 and 1? Good. So with two inputs, they all have to be 1, meaning both of them have to be 1. So this is the AND function. We don't usually write it out with words. We like to be a little more concise with our bowling expression. So usually we'll use this multiplication notation from normal algebra. So if I write something 8 times b, it means A and B. There are other notations people use in mathematics. It's called a conjunction. So if you end up taking a math logic course or something, you'll see that notation. We also use gate diagrams. So this is an AND gate here. There are two features that distinguish it from other types of gates. So when you start drawing gates, if you're drawing them by hand, make sure that you try to get a flat input and around it output. And then people will know you mean an AND gate. So that's AND. So what about OR? Let's go through and do the truth table first. So remember OR is the any function. So 0 or 0? 0. Good. 0 or 1? 1 or 0? 1 or 1? 1 or 1? Good. OK. So you guys know these pretty well, it seems. So we also use algebraic notation. So for OR, we use plus. So multiplication is AND, addition is OR when we write Boolean expressions. Again, math terminology or math notation. It's called a disjunction written with that little b there. And OR gate, again, two distinguishing features rounded input, pointy output. So if you draw things, just make sure that you get those two sides right. And then people will be able to tell what it is. If you scribble it so quickly that we can't tell if the back of the input side is round or straight, and you scribble the front side. So we can't tell if it's pointy or round. Then we won't know what it is. So just do it carefully enough that you can tell those two things. And then people can tell what you're trying to draw. All right, what about not? So not 0? 1. Not 1? Good. So a bunch of ways we write not. We'll stick to usually the first two. So we'll put a prime when we don't have any video graphical writers handy or chalkboard. Often we'll write a bar over it. So the bar or the prime means complement not. There's also mathematical complement, which is this little thing here. So you might see that in some texts. The not gate is a triangle in an inversion bubble. The thing that actually does the not part is the circle. So if you see it without the circle, that's actually just a buffer. So it just repeats the signal that's used for performance reasons in circuits. So it's the circle that does the inversion. And sometimes people will draw circles all by themselves. So in the book, in the Patent Patel textbook, you can find still a few diagrams where there are inversion bubbles on the inputs to gates. So those are actually knots. And if you built it, you'd have to have a gate for each of those little circles. And they'll fix that in a third version. But the third version, they're trying to save you money because the publisher wants them to produce versions. I really shouldn't save us too much on video. Anyway, so when the third version comes out, those will go away. But for now, if you're looking at the current addition, you still have some of those inversion bubbles on inputs. All right, what about x-or? A, 0, x-or, 0? 0 x-or, 1. 0 x-or, 1. 0 x-or, 1. 0. 1 x-or, 1. 0 x-or, 1. Good. All right. So usually we just write that a plus sign with the circle around it. And it looks like or when we draw it as a gate, but it has two lines on the input side. Sometimes the inputs will cross the first line. Sometimes they won't. It doesn't make any difference. Those mean the same thing. So that's an x-or gate. To generalize, use the definitions that I gave you. So AND is the all function, or is the any function, x-or is the odd function. We just looked at two inputs. If you want to use more inputs, in order to make them communicative and associative, they're defined this way. So let's do an example with three input x-or. So it's the odd function. So what's 0 x-or, 0 x-or, 0? Good. 0 0 1. 1. 0 1 0. 0 1 1. 0. 1 0 0. 1 1. 1 0 1. 1 0. 1 1 0. And 1 1 1. Good. So again, if you look at these, I mean, I think people were mostly following along, but it is the odd function, right? The number of ones on the left, if it's 1 or 3, you're going to output of 1. If it's 0 or 2, you're going to output of 0. And you can generalize to 4, 5, 10 input x-or, if you'd like. I won't draw the truth, too. So there's another way that we generalize these functions, which is by pairing a bit. So a lot of instruction set architectures on computers, and even starting maybe Friday or the day after Labor Day, next Wednesday, you'll start to see these operations in the C language, where you can take two sets of bits and do a Boolean operation on them. So for example, we might write something like this here, c equals a and b, or a is an n bit number, bit pattern. b is an n bit bit pattern. And what we mean by this a and b, where I've written it out with the word, is to take those bits, line them up. So you take a sub n minus 1, b sub n minus 1, you and those together using a two input and that produces cn minus 1. You do that for all of your values of i. And what you get is this number c, where it's a bit wise and between a and b. So this is what you typically use in a computer, where you've got names representing sets of bits, and then you might end whole sets of bits together. So it's another way to generalize the idea of the Boolean expressions, or the Boolean functions that we've talked about. Be careful not to mix the algebraists. So when we talk about bit wise operations, we usually use the words. The reason is that it can get confusing because when we talk about sets of bits, we can do things like plus. We talked about how we define addition on unsigned and two complement numbers. And if we use plus to mean addition, then having plus also mean or gets very confusing very quickly. So when we talk about bit wise operations, try just to use the words. When we're talking about Boolean expressions, plus will mean or, and multiple occasion will mean and. So try not to mix those. Otherwise, people will not understand what you're trying to do, or worse, you'll get confused as you try to derive something. All right, I thought about going back and showing you another tool, there's another truth table tool. A lot of that is actually not things you need to know until after the first midterm, but the first tab in there will help you fill in truth tables. So if you feel like, OK, I want to get some exercise, looking at Boolean expressions and filling in truth tables, there is a tool that will help you do that. Give you the same sort of feedback, same interface, basically. And that's just the next tool down, the two tools down. OK, so now I have a question for you. So how many different functions exist on inputs of input? So I only showed you four. And after class on Friday, people came up and said, well, what about this function? What about that function? Those are all nice functions. So how are you going to find that answer? So let's start with n equals 1. How many functions are there for, let's say, of an input a? How many functions can I define on a? I'm hearing a bunch of different numbers. Let's name them. So what can I define on a? So I hear it 0. So I don't care what a is, the answer is 0. So that's a 1 function. And 1, that's 2 functions. What else can I do with a? I mean, 0 and 1 don't depend on a. There must be functions that depend on a. They're not a, and then just a by itself. So I think that's it. So you've got four functions. OK, I'm running out of fingers. So we're going to have to do this another way. So what about n equals 2? Can I figure out how many functions there are? There are four on n equals 1 for n equals 2. Try this. So here's a true stable. Got some function c as a function of f on a and b. I'm sorry, f is the function, a and b are the inputs. So instead of writing values, let me give those outputs names. Let's call them cci, c0, 1, 2, and 3. Now, depending how I pick c0, 1, 2, and 3, every combination gives me a unique function. So if I were to put four zeros, well, that's the zero function on two inputs. If I were to put four ones, that's the one function on two inputs. Every combination I pick gives me a different function. It's a one to one mapping between choices and functions. So how many choices do I have? 16, right? So I've got two choices for c0. The choice of c0 doesn't affect my choice of c1. So I also pick c1. Each of these is just a bit, right? 0, 1. So I get two choices for c0, two choices for c1, two choices for c2, two choices for c3. I multiply all those choices out. Overall, I have 16, 2 to the four different ways I could fill in this truth table. Each truth table is a different function. So there's 16 functions on two inputs. So what about three? So let's write our truth table. And we'll call the outputs d sub i. And we've got eight of them. For each of them, we have two choices. So 2 times 2 times 2, I'm going to lose count. Eight times. So 2 to the eighth. I want to point out that's 2 to the 2 to the 3. Eight is 2 to the 3. Maybe. Yes. You can do forward at the end. All right. So can we generalize that to end bits? Please don't make me worry about a truth table. All right. So what do we do? So without drawing the truth table, end bits means 2 to the n rows. Right? If you were to write a truth table on end bits of input, it's got two to the n possible input combinations. And so for each of those rows, we have an output variable. We have two choices for that output variable. So you multiply all those two together, you get 2 to the 2 to the n, or 4 to the n, is another way to write that. So 2 to the 2 to the n functions on end bits. But I only showed you four. Yeah. You have a question? OK. Here. So we can have two possibilities of putting those bits together. 2 to the n rows, yeah. 2 to the n possible ways to have input. Whether it's only 8, there's only 8 out of the 2. Yeah. So here n equals 3. So what's the other one? So when n equals 3, we have 8 rows. They're 8 different patterns. And when n equals 4, we'd have 16 rows. n equals 5. We'd have 32. If we did n equals 10, you'd have 1,000 rows in your truth table. Have 1,000 variables to define your function. 1,000, 24. Has this the row to the n possible but the other? So for each row, you have one of these variables. And for each variable, you have two choices. So you multiply all those two together. They're 2 to the n of them. So you get this one. That's where that comes from. Yes. Each output, you choose 0 or 1. And all of those choices specify unique function. Yeah. So it's like the row column of the question would be the important. No. No, it might take us a minute to work it out on our head. Yes. Yes. Yeah. Yeah. So you can massage this algebraically as you like. So 2 to the 2 is 4. And you should know that if I have this power to a power that you can actually do the first one. And then if you plug in a specific value of n, you can also do the other one, right? They're associative. Do that 2 to the n one, which we did already on the previous slides. OK. OK. So now the hard part. So I only gave you four functions. Got a lot of paper. I can see the headline now. Illinois professor single handily destroys rainforest. All right. I can't have that. So your alternate homework. Instead, you can understand logical completeness. It's your choice, really. But I'm not sure you really want to use that much paper. So I have a claim. If you give me enough to input and to input or and not functions, I can compose those mathematically to make any function you want on any number of variables. Do you believe me? Yeah. Really? Why? Why? Why do you believe me? Why do you believe me? I'm not going to profess it. The function is you can set them up back to back where you can see the answer. Yes. Long logic increases. Yes. Yes. So the question is, how am I going to do this? We're going to have to be able to put the functions together mathematically in math. We call that composition. So we put the output of one function into another. I'm actually going to show you the proofs using gates. So we're going to draw it as circuit diagrams. But it's equivalent to mathematical composition of functions. Yeah. So if you're saying that those three functions, if, like, let's say, I want to do some kind of actually use any of the pluses, any of these three functions, and I could get that. Yes. Yes. So the question is, I'm saying, regardless of what function you want to implement, no matter what the function is, I claim I can do it with just these three functions. And yes, that's absolutely right. And so I'll come, after I show you how, so the proof will be what we call by construction. And so in other words, I will show you a way, regardless of what the function you want to implement is, I will show you exactly how to do it using these three kinds of gates. Okay? A way to do it. It won't be the best way to do it. This is just proof of concept proof. Okay? But it will be A way that you can always build any function. So we'll come back to why that's important after we walk through the details. All right. Let's start the proof. So here's a diagram. So you remember, hopefully, this is the AND gate. So if I hook these together, what do I get out of the right side? Okay. So, ABC, right? A and B and C. Good. So it's a three input and, in other words. And if I put, I have three inputs on the left. I put three values into those, into that gate formation. What it comes out is the AND of those three variables. So out of these two two input ands, I produce the three input and. So what about this one? Yeah, four input ands, right? So I'm showing you how to build a three input and take one of those three input ands. Hook it together with one more two input and now I have a four input and. So you probably remember proof by induction from high school or something like that, right? With like the AB. So does it matter what order you do? No, because AND is associative and commutative. But, so you could reorder these and do the diagrams a different way and you get the same answer. Okay. So you remember proof by induction? What do I need to prove? Okay. So what I'm hearing is, if it's true for some N, then I have to prove it's also true for N plus one. Is there something else I need to prove? I'd better have a base case, right? So I have an example from Yale Pat for showing why if you forget your base case, your proof doesn't work. But I'll skip that one because I think people remember going to have a base case. So here's our proof by induction. So by induction, we've got base case of n equals two, for example. You want a two input and, well, that you gave me already. So I'll take one off the shelf and I'll put it down as your two input and that's my base case. You want a bigger, more input and we'll do the construct we just did. So we'll start assuming I know how to build an input input and I'll take one of those. I'll hook together one more two input and down here. And that will give me my n plus one input and. So that's our proof by induction. That for any finite number of inputs, I can give you that AND gate. Happy? Okay. You should believe me when I prove things. Don't believe it just because I say it. I occasionally make a mistake. All right. So a couple comments. So first of all, the functional form is here. So if you want to see it algebraically, you can write it that way instead of drawing circuit diagrams. But this is not a practical way to build bigger gates. So don't go back and say, okay, now I know how to build ten input AND gates. This is not the right way to do it. I just want to show you that it can be done so that later we can talk about, well, once we have this logical completeness idea, now we know what we need to build at the technology layer so that people at higher abstraction layers can make use of any function they want. So I'm giving you a hint at why it's relevant, but it's not practically the right way to approach the problem. It's just a proof right now. Okay. So now I can simplify my claim. So before I said I had to use two input AND, two input ORs, but I just showed you how to build those arbitrary input ANDs and ORs. So now I just cross out the two input because all I need to prove is that with arbitrary number of finite number of input AND, finite number of input OR and not gates, it can build any function. For OR, it's the same idea. Just go through the same proof structure, replace AND with OR. Okay. Okay. So let's start by thinking about functions that produce one one in their truth table. So now a whole bunch of rows maybe, I might have ten inputs, thousand rows, one row produces output of one. So that's a tiny number of functions. It's a very small number of functions. But let me start with those and I'll show you how to build those. So each of these functions, exactly one combination of inputs will produce a one. Any other combination of inputs produces zero. So I'm going to give you an example. So here's Q. Here is one row here. All the other rows produce zero. But tell me when is Q equal to one? Yeah. So you just say, well, I mean the inputs have to be here, right? So A has to be one. B has to be zero. C has to be one. So B is zero when not B is one. But I need that expression to be true. So if I write Q equals A, B prime C, then that's the function. That AND is equal to one whenever A is one and B is zero and C is one. So anytime you have this subset of functions, I can just use one AND gate and maybe some not gates and build a function for you. So to build an arbitrary function, we need one more step. So the first step is, well, look, look at the truth table. And for every row, build the AND function that produces the one for that row. For every row that produces a one, I should say. So that's a good question. So if you plug it in, remember this is an AND function. So all of them have to be one. And so A has to be one. So A can't have any other value. B prime has to be one, which means B has to be zero. So B can't have any other value. And C has to be one. So C can't have any other value. So if they have any other values, this combination produces zero. Yeah. So again, it's an AND function. So remember AND means all. And so all of these have to be true when I use an AND. So for each one of them, that constrains that input to one value. And we have each input appears exactly once. So this is a, there's a name for this that you'll learn later. If you want to learn it now, it's fine. It's called a min term. It's the thing that produces a one for exactly one row of the truth table. And it's a product of all of the inputs or their compliments. All right. So we'll produce those min terms. So for every combination where we produce a one output, we'll produce that AND. Then we'll take all those ANDs, and we'll put them all together into one big OR gate. That's our function. That's it. So that gives us what we call a sum of products, right? Because the OR is a sum. We use plus notation for the OR. And each of the things that we're adding together is a product. Right? It's an AND. So we use multiplication notation and algebra for that. That's a really inefficient way to build a real system. We'll talk about that in about a week and a half. Right? How can you do a better job? But it always works. Right? So in other words, if I give you those gates, you can build anything. And that's kind of the point of logical completeness. Okay? So we say that the set AND or not is logically complete. Because as we showed, you can build any function on any number of inputs using only those three. Okay? So if you want to show that something else is logically complete, you don't have to go to these lengths. Right? If you can show me that given some set of functions, you can build AND. You can build OR. And you can build NOT. And you're done. You don't have to show anything else. So for example, when we talk about circuit technology and the CMOS devices that we use today in all digital electronics, not all, but almost all, what they actually produce is the NAND function and the NOR function. Right? And so the AND gate followed by a NOT gate is kind of the natural thing to build in those technologies. Turns out that NAND, all by itself, is logically complete. So maybe something to think about. How can you take NAND to input NAND and build AND or not from that? Because that one function all by itself can build anything. Yeah, question. It's NAND. NOR is also logically complete. So this stands for NOT AND. And it's A and B complemented or by De Morgan's law. That is the same. That one function you can build anything. Yeah. First you have to show me how to build an inverter with NAND. Yes. I mean, it's not very hard to build. But that's how you would prove that NAND by itself is logically complete, not to go through the whole constructive thing again, but just to show you and get these three. All right. So why do you care? So imagine you're working on a new device technology. It's based on DNA. Maybe you're working with Oguiz and the Lankovitch. Maybe it's based on new semiconductor with John D'Alessassi. Maybe it's based on carbon nanotubes with geliding. Maybe you're still finishing your degree. That would be really embarrassing for me if you're working on new technologies, like before you finish your Illinois degree. So now I'm kidding. You have lots of opportunities here. All of these technologies. So let's say you're doing that. What do you need to do to make yourself to make your technology useful? Well, what you need to do is you need to be able to build NAND or NAND. If you can build NAND or NAND, then people who are designing circuits and components and computer architectures, they can take what you've got and build everything on top. If you can't provide those three functions, then how can they use it? So that's the abstraction. If you can provide those three functions, you can build anything. Any function. If you can't build those three, then it's going to be a lot harder to use. So that's the abstraction boundary. So the technology has to be able to provide those. Again, lots of opportunities here for new technologies. Lots of people working on cool stuff. Think about it in your four years here. Okay. So actually in the notes, if you look online, the slides that I posted, I did three input X or, but someone asked me after class about this function. So I thought, okay, let's just put this one in the lecture. Like I said, any function is fine. So someone said, well, what if I want a function where I have some number of inputs. And exactly one of those inputs has to be a one to produce a one. Okay. So we'll do that on three. So let's write the truth table. So I just make it pop up. So get a feeling for what you think it should be. And I'll make it pop up. So again, if outputs a one, if and only if exactly one input is one or true. So here's the, here's what I thought was the answer. So if you have C equal to one, but a and B zero, you get a one. If you have B equal one, but a and B zero, a and C zero, you get a one. If you have a equal to one, but B and C zero, you get a one. Anything else you get a zero. So let's go through and follow our constructive proof. So what is the function that produces that yellow row up there? So, no, yes. So a prime or a. Yeah, a prime B prime C, right? Good. Okay. Okay. What about this row? A prime B, C prime. Okay. Good. And one more row with one, right? What about that one? A, B prime, C prime. Okay. Good. So those are the only ones with one, right? So for each of those, we produce this min term, this product of the literals. We call that individual inputs literals. So they're complement or also called literals. So we produce these three functions and then we order them together. Right? So if we order them together, we get our function. So you can follow these steps for any function you want. So you can do the function using only and or and not. So now we're ready to start thinking about, well, how would we actually build that adder we talked about in the first couple days of class, right? We can do any Boolean function we want. Addition is just a Boolean function. You take some bits, bit pattern representing an unsigned or a two-s complement number, take another one, you spit out the sum. It's just Boolean algebra. So now you have a way of thinking about how would you actually build that using just and or not? Any questions on that before we put a floating point in? Or pluses or. Yes, these are ors and the multiplication notation is and. So this is a prime. So a prime means not a. The prime means not the c means just c by itself. Those are ended together and then the output of that end is ord with the output of these two ends. Yeah, and it has the same precedence as as your normal algebra. So the end happens before the orr, which is also actually important that I should have mentioned. Yes, yes. So if I ever to write this for you in your normal algebra, you would multiply before you'd add, right? Yeah, so same thing. Okay, all right, so let's go forward. All right, so in binary, we have a binary point. I know internationally people sometimes draw this as a comma. So sorry, if this is not the way you normally write your decimal point. But so if I want to write down pi, for example, I would have that period there. And then after the period, I would have one for the tenths and four for the hundreds and so forth. So if I write binary base two in human terms, well, I can have a binary point. Right, after the binary point, I have the two to the minus one, so the halves place, the quarters place, the eighths place, and so on. So that's pretty straightforward. So let's say that I'm not happy with integers, right? We've talked a lot about how we represent integers. What if I want fractions? What if I want real numbers? What do I do? Well, one thing I can do is I can use what's called fixed point. So I say, well, you know, in the middle of my representation, I've got a binary point. I can just pick something. It can be supported by software. It can be supported by hardware. It can be supported by both. It doesn't really matter that much. It's relatively easy to do it this way because everything is still a power of two. Right, and so it turns out I can use the same adders and multipliers as long as I line things up properly. And sometimes maybe I'll even do that in software. And so there have been a lot of generations of processors that just did all of this stuff in software to have fixed point representations. Some signal processing and embedded processors have hardware support for fixed point. And so it's fairly simple extension. Again, just based on human notions of representations for binary. So we could do that. So, do we need anything else? Was that good enough? Yeah. Yeah, irrational is hard, but the thing is part of the reason it's hard is there's so many of them. And so we kind of have to make do with an approximation because to represent irrational's well when could argue we need infinite number of bits. So that's not quite true. There's some there's some substantially more complicated representations actually was talking with another professor John Dallan about them a few nights ago because in his mathematical physics class he's introducing people to them. There's something called continued continued fraction representations. People have tried to put those in hardware. They're fairly complicated to build hardware. And so what we tend to do is approximate. So what you'll see is an approximation. Good question. Yeah. Yeah, that's a good point. So we do need negative numbers. So we could probably add a sign bit kind of the way we did with two complement or we could do sign magnitude fixed point. Yeah, that's a good question. Yeah, so repeating fractions. We could try to come up with a representation that handled them well. There's a little bit of that that's natural. If you think about translating just decimal to binary, then some numbers that are finite will become infinite in the other one because of the primality of the factorization. Well, people haven't I think come up with a representation that focuses on trying to represent repeating fractions, but it would be an interesting interesting thing to do to see if they're getting leverage. Yeah, yeah. So you could you could have. I mean, if you mean just having more more range, we could throw more bits at it, right? Or we can think about well, is there is their way with the same number of bits we could get a bigger range of possible numbers. So all right. So let's think about all of those in mobile forward and kind of see what floating point gives us. So what is let me just start by saying well, what's the range of 32 bit to complement you guys know it, right? Everyone knew that. If I say okay, write down a piece of paper. Okay, good. I'm glad you did. I usually write it this way. I don't remember. I remember four billion. The rest is a blur. But I think I'm sorry, two billion. Yeah, four billion for unsigned. So so let's write some banking software, right? So forget all this real number stuff. Let's just do banking software. And I say, okay, I'm going to store one 32 bit to his complement number to represent pennies in your account. Anyone anyone anyone have more. So we're done. Got our banking software. Let's say you have a friend who has more. Well, okay, well 64 bits. There's not that much money in the world. So we're still done. Okay, so what about chemistry? Anyone in chemistry? Okay, good. So you got chemistry homework, right? Probably want to use a computer instead of going to the lab and being dangerous with chemical. What's the other guy's number? Okay, that's what I had to. But we'll show. Ten to the third is two to the 10th. So that's about 80 bits. Okay, so who's got a guy's number to 80 bits. It's 24 significant figures. The ones in chemistry, you know this one, right? No. What are we going to do? What are we going to do? Okay, we got to give you some homework. I should let you go early because this is going to take you quite some time. Maybe we can just be close. Maybe we can just make up some bits for the other lower bits. Who is going to tell you you're wrong? Not the chemists, right? So what about quantum mechanics? Anyone have quantum mechanics? Okay, so somebody can do what about belongs constant? Okay, you should use ergs because ergs are cool. No, the physicists use them. So yeah, those have to go after the binary point. It's a small number, right? So we'll need 90 bits after the binary point. Oh, that's 24-minute digits for obligatory numbers. So we really need 170 bits of precision. We need 51 significant figures of obligatory numbers to do our chemistry, probably not. But it would be nice if we could represent both of those numbers. So I think people mentioned kind of a bigger range of numbers, maybe with the same number of bits, maybe 32. So small numbers and big numbers. So what can we sacrifice to do that? Well, let's think about what we do as humans. I mean, we've already done it a few times in these slides, right? We have this notion of scientific notation. So we say, well, what we care about is maybe five, six, seven significant figures, and we have an exponent. But we don't just write all the rest of the digits just because it's a big number. We don't write all the zeros just because it's a small number. We put in this handy scientific notation, which has three parts. There's a sign. There's these significant figures, which I'll call them antissa refers to the precision, right? More, more digits means we know that we know the answer better. And then we have this exponent. So let's make a representation that has those three pieces. So that's what we call floating point. So, uh, Velvo, Khan, it Berkeley really is the is the author of this floating point representation prior to the standardization. There are lots of different floating point methods and different computers and they had lots of different numerical problems. So, so actually I triply floating point is really well thought out and that's mostly due to Khan. Pretty much every every modern computer implements this well, any modern computer that supports floating point will implement implement IEEE 754 standard floating point. So this is what single precision looks like. It's got 32 bits. It has a sign, which of course is one bit. It has an exponent, which it uses eight bits. And as a mantissa, remember those are the significant figures. You got 23 bits for that. It's about six digits. So what is it, value represent? So let me ask you a question first. So what are the values of that digit? Can it be anything? Maybe zero to four, one to seven. What can that digit be? Remember canonical form is something it's not supposed to be, right? It's not supposed to be zero because you can change the exponent. So remember it's supposed to not have zero. You can have anything one to nine. So you can change the exponent if you had a zero there to move it around so that you've got canonical form, right? Unique form. All right. So what about binary? Same question. Now binary. Oh, you gave me the answer. Not zero, right? Is the answer. But that means it's just a one. Okay. So now, how many things do I need to represent one value? How many bits? Zero. It's always a one. I don't need any bits to represent that one. Okay. So the leading one is implicit. So now we can go on and look at how we interpret this number. So if I have these bits, I can plug it into this formula and that will tell me the number. Okay. So negative one to the sign. So sign is a zero. That means it's positive. If sign is a one, that means it's negative. This implicit one here. Remember, it's implicit. It doesn't take any actual bits in the number because implicitly there's going to be a one in scientific notation and binary. Then the mantis of bits, all 23 of them, multiplied by two to the bits of the exponent interpreted as unsigned minus 127. Okay. So we can go all the way from, you know, about negative 120 to about positive 120 to the negative 120 to the positive. It's about 10 to the 38. Sure. Ah, yeah, yeah. So here in, uh, indesimal, the answer was not zero. Right. So we change the exponent to make it be not zero. The answer is also not zero in any other base, right. Because you can always shift the exponent. But in binary that has a further implication, if it's not zero, it must be one. And if there's only one thing to choose from, you don't need to, you don't need to store any bits to represent what that leading digit is. It's always one. There's always a one there. Now there's, there's one caveat that I'll show you in the next slide. But the general interpretation is yes, there's always a one there. Yeah. Um, that's a biased offset. It's so that you can have big and small exponents. Right. So if you want something like plonks constant, you need a very small exponent. If you want something like a vigorous number, you need a big one. Right. So you want to be able to represent big and small. So this just means my eight bit unsigned kind of value in that in that exponent fields can represent big, big exponents and little ones. And the choice of 127 is to make that balanced. Right. So that's why. Yeah. It's unsigned. It's unsigned. It's an, it's actually there's a, there's a different name for it. So if you go read the standard, it's called like a biased offset or something. But if you look at it as eight bits and you translate it into decimal as an unsigned number, then you can subtract 127. That'll give you the right answer. It's not not to his compliment. Yeah. I don't remember. I have to look it up. So if the double, I have 64 bits in total. One, one is the sign bit, obviously. And then the exponent and the mint is split the other 63. I don't remember exactly how. And there's actually now a standard quad, which is 128 bits. So which bit corresponds to a half depends on your exponents, right. But the, the first bit of the mantissa in order appears after the implicit one. And so there, you would just take the bits here and write them out. And that would give you the binary scientific notation form of the numbers. And then back and forth. I mean, on papers, relatively easy. If you can put something in bite and we'll do some examples. If you can put it in binary scientific notation, you basically just copy the bits into the, into the 32. All right. So the one caveat. Well, couple. I triply supports infinity, not a number. You don't need to know most of this stuff. The one thing you do need to know. So it's here in the notes. If you, if you want to look at it, you don't need to use it. The one thing you do need to know is that, of course, we need a zero and zero does not start with an implicit one. So we need to be able to represent the number zero. That's the bit pattern of all zeros. And that was not accidental. So if you have a flooding point number that has all zeros in it, it's the same zero representation as unsigned in two's complement. It's all zeros. So, but the denormalization is kind of beyond the scope of the class. So put it in the slides for you. And yeah, no, no, I mean zero can't have an implicit one. If you write the number zero in scientific notation, you have to put a zero. Yeah. So, so that's the exception to the rule. So the all zero bit pattern is zero in flooding point. The representation is well defined. Right. So we've just agreed on it. So now if you were to go out and build hardware, you know what to do. Yeah. Yeah. So that's, there's a good question. But all representations that computers are going to use have to be defined in advance and agreed upon. Yeah. So this is the one exception. I mean, there's also denormalized numbers, but that's beyond the scope of the class. All right. Okay. So conversion. So let's, let's, you can do this in the tool to if you want to practice it. But it's not actually too hard. You convert to binary, changed the scientific notation and code each of the three parts. So we can do an example. The the integer part, you know how to do. Right. We've done that already. The fractional part is actually equally easy. Right. So you can write the polynomial in the other direction. So it would be these inverse powers of two is our fractional part. And then you think, well, if I multiply F by two and I multiply this side by two, the only way this side can be bigger than one is if this term is is one. Because all of these is a quarter is an eighth and so forth. So the only way for the right side to be bigger than one is for a negative one to be one. So what we have to do is multiply both sides, multiply your number by two. And every time you get a one, that's a one bit. And every time you have something less than one, that's zero bit. So let me, let me walk you through an example. So let's say this number looks intimidating, but I promise we won't have too many bits. So we have that number. First, we write five and binary. We get one zero one. Now we need to convert that fraction. So multiply by two. We get something less than one. So a negative one is zero. So subtract zero. Multiply it by two. Still less than one. Another zero. Subtract zero. Multiply it by two. Still less than one. So that's a minus five is one. And then we'll subtract the one off of both sides. So we'll get half left. And then we'll multiply by two and get one. So a negative six is also one. And then we're done. So we're fraction and binary. So we would give you shorter problems on exams if we were to give you something like this. And we certainly wouldn't give you something where you had to look at all 23. That would just be mean. And you don't want to do that by hand. You want to teach your computer to do that. And I promise the tool is also like four or five bits. So even if they look intimidating, if you work it out on paper, it's just a few bits. So one last step. So we've got it in binary sign. Rather we've got it in binary. So change it to binary scientific notation. And now this one here is implicit. These are the bits of the mantissa. Then you've got a bunch of implicit zeros after that. So the rest of the other 23. So the other remaining bits are zeros. This is our exponent. So into the field, we have to put 129. So then 129 minus 127 is the two that we want. And there's our mantissa with 15 more zeros. So that's it. This one, I think I'll save because I want to make sure you understand it. Floating points a little weird. It's not associative. So we'll talk about that on Wednesday. Thanks. One to three tomorrow. Oh, I still my mic live. It doesn't matter. Thank you. You You You You You You You You You"
    },
    {
        "ECE120-2016-09-19-MT1-review-slides.mp4": " Everything okay put that on the list But anyone want to be more specific? See programming Yeah Okay, I'll just put that as I took a reflux and point I'll put I'll put two in from and see what Flocharts Flocharts Technically you were not supposed to have to make any flowcharts I know there was one on the homework, but that's not part of Part of our learning goals for this Mohammed had one where to go but he put his hand down. Okay. Yeah Sure Let me add that to see programming Remember that logical or technically also not part of what you required to know so only the bit wise ops but I'll say the difference Okay I'll put that also under C anything else. Yeah Sure Yeah So you're sending me an inside Who's compliment as a representation? Okay, oh, I'm sorry. I thought it was a versus Okay Okay Okay, anything else Yeah Okay, anything else to put on the list? All right, let's vote So maybe you can vote as many times as you want but I'm going to order them numerically from my rough counts Maximum to minimum and then what we get to we get to so how many want to see something about C programming? Okay, I'm gonna gestimate about 60 to 70 I triply floating point conversion and it's about 50 I think Flowcharts Okay, about 15 levels of abstraction About 25 to 30 I choose compliment arithmetic and overflow About 10 at the 10 and MOSFETs Okay, about 25 to 30 again Okay, so let's start with some C programming and then do floating point All right, so a couple of topics on there arithmetic versus logical shifts our logical versus bitwise before we start Let me just mention the kind of things we want you to be able to do and see so one is analyze C curd So we'll give you a little program you take a look at it and understand what it does um Yeah, I actually didn't bring my computer thinking we were gonna oh do this all on the board. I could pop up I can write an example but um Probably the best examples at this point would be you know, they have answers with them in the online tools So if you didn't do all 14 of them and you want practice on analyzing C code go there Look at the code figure out what it does write your answer in before you pop the answer because people tend to think they know it when they read the answer Right, so write down what you really think it does and then push check answer. It'll tell you what the code does Okay, we're answer the question that's there on each of the examples or 14 examples So that's one thing we want you to be able to do Yeah, that's on so if you go to my homepage and go down to f16 classes f16 come to the links page for our class And then exercise which is see analysis. Yeah, the online exercise um, so right, you know math formulas I mean I see so those are just expressions and then um write conditional So this is it's And then write loops for loops Okay, so those are the things that we'd wanted you to be able to do um um, so let's think of a quick example So let's say um I think you saw this somewhere already which I'm worried it's on a homework. Let's do you tend to do math homework um So let's say you want to print actually those to get it bitwise too. Let's say you want to print a number as uh Say you want to print a number as um binary in c there's no percent b for binary So let's say you want to enter a decimal number And print as binary For example Okay, so you'd start off you're always gonna start we usually won't have you write this but you want standard IO And we'll write our main function So what's the first thing we'll do? Yeah declare variable so let's have uh We're gonna have to come up and do some more of these but let's say we're making unsigned numbers instead of the decimal um We'll come back and do some more um run out of space though Okay, so how will I how will I get the number the user needs once printed? Yeah, I'll hope to scan that maybe I should ask them for it first So what do I use to ask them for an after, right? Okay, so Please and more variables later I'm just asking them something what do you want converted and then we'll use scan app so Uh, it should return one So let's ask for an unsigned number And what do I what I put here ampersand No, right that's where we want to put it So this scan app remember will will wait for the user to type something and there are a lot of the type of unsigned number It'll convert that unsigned number because I said percent you into 32 bit unsigned Representation and store that in the variable numb Um I don't know just did it's going to print in binary it doesn't really matter It'll work our code will work the ball but usually whenever we do bit rise operators I try to use unsigned because otherwise sometimes it gets a little tricky if you If you do shifts right then you'll be an arithmetic shift if you do choose complement and sometimes you really don't want that We'll cause bugs Yeah Yeah to evaluate so this is a function call we only show to print up and scan up but it has to evaluate the expression And so when you make a function called part of the expression it calls that function in order to get the value back And remember the value that comes back from scan app is The number of things converted for if it fails to convert anything returns minus one Oh, let me just write that down But shouldn't return zero if it doesn't convert anything a little bit in minus one which is an error message Is that logical? Is that thinking of? A little bigger okay Um, okay, I'll try to write bigger it just says what I what I said a minute ago Um, although There are plenty seats forward So feel free to come forward if I'll try to write bigger Um, all right, so that will do our check for us and then if that fails we can just print an error message I'll just make it something simple And then just exit program I don't know I'll pick three Okay, so when otherwise we have a number yeah Um, maybe hey look at that yes, I can Sure, I didn't know I could do that um, there's the first time I've used this dot cam. Yeah Now that's it's just uh um the convention a long time ago was zero for success non-zero for for not success And other than that there was no convention my personal convention is three for you know doing something wrong when you start the program So there's no good answer other than don't return zero that way wherever started the program knows that the program did not succeed something like that Okay So we now have this number now we can convert it in order to convert it We're gonna need to use bitwise operators because we're gonna have to look one bit at a time And so what we'll do we need to look at the at the top that first and then we also want to uh We also want to go once one step at a time through the 32 bits I'm just gonna assume it's a 32 bit number. I could be a 16 bit number on some platforms, but I'll assume it's 32 Um, so we need a we need to be able to pull out one bit at a time So first let me make a loop variable So I'm just gonna make that an int and I'll just call it i that'll be a loop variable And we also need a bit uh that will pull out using it a bitwise and we'll pull out the bit of the number that we want to print Okay, so we should set that I'll make that an unsigned. I'm gonna shift that along step by step So make that an unsigned or call it mask And then I'm gonna set it initially equal to the high bit of 32 bit numbers Okay, so that's the that's the bit 31 if you number them from zero up to 31 that's bit 31 of the unsigned number So now I can do a for loop down here. So how should I make i go from say zero to 31 Okay, so I'll initialize it to zero and what should my test be So 30 I could do 32 greater than i or I could do 31 greater equal to i 801 spine and then update I equal right plus one Okay, so now I will I will let this loop execute 32 times And I'll actually have to update mask as well. I'll just do that at the bottom So in order to tell what kind of thing I have in my number I need to use a bitwise and I'm gonna shift over to another paper and develop the expression So I have this number and I have a mask So how do I pull out the corresponding bit of the number? What operator did I use? So mask remember just consider the first The first iteration mask is going to be this value. So one did in there So if I use what? What operator? An and right so if I do a bitwise and between mask and numb the answer is going to either be zero or it's going to be equal to mask There's only one bit on in there Right, so if I add them together with all the bits 31 out of 32 bits of mask are zero So the answer 31 out of 32 bits have to be zero The one bit that's set in mask may be also a one in number So the answer will either be equal to that number up there that big number or it'll be equal to zero So I can write something where I say if zero is not equal to mask and number In that case Then there's a one in that bit position of number, right and if that condition is not true then there's a zero There's only two possible values for that where that hit wise and it's pulling out one bit That makes sense When you do a bitwise and the answer is also in this case are two unsigned So the answer will be an unsigned with 32 bits in it, but because my and remember this number here if I write it out in binary There's 28 zeros here, right, and so if I write out number in binary I'm sorry Ah, I have a little preview screen. Okay, so if I write number in binary remember bitwise and goes through like this, right? So all of these zeros over here these all come out as zero So you've got 31 zeros in the answer The mask and num this is the expression value And this this one here could be a one All right, but all the others have to be zero and so that's how we're looking at just that one particular bit using the mask So we have one bit set in the mask. We use a bitwise and the answer is either zero all zero or is that one bit Okay Yeah, so it's an unsigned number it's an unsigned number that happens to have at most one bit set so it's either zero or not zero Yes, yeah, yeah, yes, it's an unsigned number stuff Yeah, so it's interpreting it as two of their 31 Okay, but all we care about is zero or not zero because later we're going to change mask to be a different bit All right, so if we find if we find it's not zero, what should we print for that particular bit? A one, right? So it's print a one So we don't need any format spec- any format specifiers would just print the number one And if it's not not zero in other words, if it is zero, what should we print? zero Okay, so that will print one bit of our binary number so we're going to put that in our loop And maybe I won't transfer it over I'm going to try to align my paper so you can read it at the same time That's your full enough Okay, so once we're done with that particular bit now we're going to need to shift the mask over So what I'll do is mask equals mask Right shifted by one Okay, someone asked earlier why did I use unsigned so here for example if I had used a two-se complement number and started with the high bit That would actually be a negative number and when I right shifted I would not get the 30 set I would get the 30 and 31 set because seeing that it's a The compiler seeing that that was a two-se complement number an integer would say oh you want an arithmetic right shift When in fact, I don't and want the logical right shift in this case For unsigned numbers yes, so an unsigned number the compiler would generate a logical right shift Which puts zeros on on the right side if it if it's an integer a two-se complement number It will generate an arithmetic right shift and puts copy the sign bit on the left side So because mask is unsigned it inserts zeros on the left now that I zoomed this is logical in the back Ah, I'm sorry. Yeah, thank you. The loop is actually down here. So Yeah, the mask equals was up there. I'm trying to get it all in the slide for you. Okay Okay, now we have the whole program. Thanks for that correction Okay, so now that we've shifted our mask over if we end our loop then that will change i I think come over here for a minute So we'll go to the next value of i and we will then compare with the next bit by doing another bit wise And after we've shifted mask down and now it's bit 30 set So we'll check a bit 30 of the number and print a 1 or 0 corresponding to that bit's value Then we'll change mask to be bit 29 I will simply count for us once we get 32 of those masks will be down and actually turned to 0 So the other way to finish this loop would be to check when mask gets to 0 because you can shift it right off And shift that one bit right down to the end and out of the number Um, but once this loop finishes we'll have printed all 32 of our bits at that point to be to make it look nice We might want to print a carriage return. So let's just toss one of those in there I'm not sure I can fit it all in the more let me zoom out a tiny bit Ah and return 0 to say we succeeded Okay, so sorry, it's not lined up perfectly but Okay, so I think with this example we managed to cover the other topics. Was there anything else on C program? Any people want to talk about or any questions on this code? Why do I I'm why do I shift mask to the what to the right? So remember that we started mask as the left most bit the high bit and so by shifting it to the right one step at a time We're covering every single bit starting from bit 31 to 30 to 29 Remember when we write bits out we usually write them sorry, I didn't have any chalk there Maybe I don't have any chalk period Okay Um When we write bits out we usually write them as the high bit Down to Bit 0 so when I'm when I'm talking about bit 31 in a 32 bit value That's the left most bit and then we're shifting to the right down to zero As the 32 steps of Yes, absolutely so the question is could you instead Um start with mask equal to one and left shift the problem is that you probably want to print out the way we did it Right, so you probably want to hide it first because people will expect to see the number that way So you could do what you said that you'd have to store the answer somewhere and then print the mountain reverse To make it make sense to the human Yeah Yeah, you can do that but again that would that would go in the wrong direction, right So if you start with a with a low bit that's the bit you want to print last So you could do it that way without being a mask you can also generate the mask on the fly um So you can write Um, not with the eye we have that you can write one left shifted by 31 minus i And so if you use this expression this takes uh, I subtract it from 31s when i zero that's 31 when i is one It's 30 and then that takes the number one and left shifted by that much that's that's actually the mask value We have you didn't really have to have a mask variable to do this one instead So in many ways you can solve the problem Uh, mask was initialized as bit 31 so in hex it's 8 followed by seven zeros Um, yeah, I mean do you need if you need to know what on the exam and you know we would I think we'd give you hint graph But but this this that's bit 31, right? So you can the easy way to do that is the way that I just wrote it That that way you don't have to remember it you can write one left shifted by 31 also If you want to initialize So you can also write this So do you need to remember it? No, you can simply write that in the code and the compiler will generate it will Uh solve that without generating a structure Right Um, yeah, so I think understanding how gates are built is on there right and gates are built out of mosfeth so to that extent Yeah, I can't pull it up easily, but does someone have the Be sure it's in there how gates are how gates are built is not in one six Okay, I can look at it afterwards. It was also low on our topic list. I'm not sure if we're going to get to it All right, any other questions on this one or are you ready to move on Okay, so we'll check that one off So I think we're going to IEEE floating point right and someone wanted to start with two And then I'll see how much interest there is in from So You mad a little bit Okay, so remember The high bit in floating point is assigned bit Then you have an exponent eight bits Then you have 23 bits of mantissa And except for zero, which is all zero bits We have possibly a either sign I'll zero except the sign Um, we have the value is equal to Our negative one to the sign bit times one this one's implicit Dot mantissa So this is binary scientific notation times two to the exponent minus 127 You can treat exponent as unsigned That will give you the right answer Now there are two corner cases that we don't really expect you to know One is if the exponent is zero. It's a denormalized number, right? So you don't really need to know that except for the fact that there's a zero pattern So you need to remember that of course we have a zero pattern So you can't have an explicit one otherwise you can't write zero And then the other one is for infinity is a nance, right? Which you don't need to remember Um So in order to uh find the value just plug into the formula in order to convert to this format You just write your number in binary scientific notation, right? So how do you write something in binary scientific notation This is binary scientific notation I have a little more space Okay, so how do we do that? So say we have a number Um Can't do a lot of fractions of powers of two in my head. So Let's say we have something like negative 15 points 625 That one I can do Okay, so let's say we want to convert this um, so the first step is just to break it up into an integer and a fraction Okay, and then we can convert the integer just using unsigned remember that that the uh The sign is going to go now into the sign bit and so it's more like sign magnitude than it is like two's complement Convert the integer using unsigned and then convert the fraction also using unsigned but as a fraction And then we can put it into binary scientific notation from there So let's start with the 15 so what's 15 and unsigned Well, so is it odd or even? I'd right so give us a one so subtract the one divide by two gives us seven right so odd or even rather than minus one divide by two we get three also odd three minus one divide by two get one also odd and then we're done right one minus one is zero So 1111 So there's 15 And what about point six two five How do we do this one again? Multiply by two so then I multiply by two I get uh one point two five so that's a one right so that will give me a one and I'll subtract the one off Um, and multiply by two again and what do I get? 0.5 so that's less than one so that gives me a zero so 0.5 Not yet minus zero times two is what one is meal one one minus one is zero so we're done So this one goes this direction so that's zero point one zero one Right So if I put those together I get 1111 point 101 So I need to write that in binary scientific notation All right, so you remember how to write scientific notation You just move the decimal point or in this case the binary point over after the first number So we're going to have an exponent of one two three So this is equal to one point 111 101 times two To the three and then remember there was a minus sign in front of it which will just put down there So So now we've converted negative 15 and 0.625 into binary scientific notation From there it's relatively simple to just transcribe This sign This mantissa remember the one here's implicit and this exponent into the floating point format So let's go ahead and do that The tricky part might be converting the number around 128 so what's the sign 0 or 1 One right negative so this are signed it What's the exponent? 130 right so here's three and remember that three is equal to whatever exponent bits are as unsigned Minus 127 so what we need to write there is 130 So probably a That conversion is a little bit of a pain honestly Especially that's small but 010 So let me write it down and then explain So if it's bigger than 128 remember that's the 128 bit And so from there you just need to convert the left over to which is down there Okay, so the 128 the two makes 130 so that's our exponent And then for the mantissa we simply copy so remember This one here is implicit so we don't write it at all so the mantissa is these six bits 11 11 101 And then why 0 so you got six more here if you think what is that 186 so 15 so Yeah, one more there I guess right So zero there and then a lot of zeros down there. Yeah 17 more So I broke it up into 216 to 16 bit chunks right but all of the rest are zeros. Yeah Yeah, so once you've got an binary even before after the binary scientific notation Okay, so after you've got an in binary scientific notation remember from our formula That the actual exponents in binary scientific notation is the exponent bits Uh in the floating point field minus 127 and so basically just invert that formula say well whatever I'm going to put here minus 127 has to equal my real exponent So that was what I wrote down at the bottom. I said okay the real exponent is three. So whatever bits I write Have to be equal to The exponent bits minus 127 have to be equal to three so just solve that equation to get exponent bits equals 130 Still read in Yeah, so I triply rounds rounds off you don't really need to understand a lot of the rounding of the rounding issues Um just understand that it's not exact right so it's it's only 23 bits of precision Um, there are four rounding modes the default mode is round to nearest so whatever the closest answer is it'll round that last bit off Up or down depending what the what which one is closer to the number you're trying to represent Question yeah, go ahead Yeah, so again, um by solving this equation So we saw in the binary scientific notation that the x-maw we want is three and in this in this form Remember that the exponent bits Represented is unsigned minus 127 has to equal to the real exponent Yeah, so remember we wrote it in binary scientific notation and straight there Makes sense okay Yeah Um, you need to know that there is a zero pattern, but you don't need to know how to interpret denormalized numbers So you just need to know there's a zero Otherwise, it's kind of a weird representation if they can't represent zero so you shouldn't know So remember you'd write it first in in scientific notation so 0.75 Uh the fraction 0.75 is equal to 111 and so that 0.11 but you put that in scientific notations this Yes, right it's not it's not zero in front yeah once it's in scientific notation in normalized form yeah The other direction sure sure I can do that You mean write it in decimal we're not that mean We're not that mean um If we do that it read it is two minus 17 But we're not that mean yeah The question was whether we'd ask you to tell us what to the minus 17 is an industrial Because we don't allow calculators on the exam right. I don't know where to the minus 70s Okay, all right, so um Um, let let me get a feeling so such you'd ask that we we do one Um also from the binary into into uh decimal i mean people want to see that at this point Okay, okay, let's just do one then um So You better Okay You know Yeah, we're not gonna we're not gonna ask you on an exam to translate something with lots and lots of zeros and ones and it just mean um All right, so how do I figure out what this means Is positive good so to put a plus sign just to make sure we know we did that so there's the plus from the sign Um now what if we were to ask you something like this on an exam we'd probably leave it up to you to do the markings I did it just to make it easy for us But you need to remember that there's one bit for the sign. It's a the the most significant Eight bits for the exponent and then the rest of the intessa Okay, so that part you probably need to mark yourself Um, so what is what is that exponent value? Anyone know Yeah, so this is 126 so I think if you remember that this is 128 And this is 127 Then I think you can uh you can figure out the rest. Thank you. Sorry. You can figure out the rest from there Um Generally won't be too far off. So this one is one less than 127. So that's 126 So what's the power of two exponent and binary scientific notation Negative one right so the 126 minus 127 is minus one. So whatever this is is times two to the minus one Okay All right, maybe we went beyond my skill in knowing inverse powers of two But we'll do it anyway. So what are what is the the value there in binary scientific notation 1.011 right so we have an implicit one So let's put that implicit one If this one is implicit and then the rest is just the mantissa So we write one and then we copy the mantissa down after the binary point Multiply by two raised to the exponent Okay, and the exponent again is that field Traparate is unsigned. It was 126 minus 127 gives us minus one. So then we can translate that number into just normal binary by shifting Our binary point one to the left and we'll get 0.1011 And then we can translate this one. This is half This is one eighth and this is one sixteen So that to me it looks like 1116 And I'll cheat not right in decimal. Yeah, so that's 816s 216s and 1116 so 1116s Because then I don't remember what a 16th is actually do So you should need to Yeah, so um I think whichever way you end up doing it just as a fraction is fine um Maybe don't write it as an expression. I mean you might have an integral part in a fractional part So so I mean don't don't make us solve equations So you wrote it yeah, so I think turn it turn it first into you know shift the binary point to the right position and then convert that one into integer interaction I'm sorry if the exponents were all one. Yeah, the exponent's all one. Remember is a special case But we don't we don't expect you to remember how to use it. It's infinity and not a number So if the meant is 0 it's infinity and if it's non-zero it's called not a number But that's more than you need to know for this Okay, anyone else for this? Um, all zero bits. Yeah, yeah, and well all zero bits except the sign which could be positive or negative they're both zero They're positive and negative zero is important. Yes Anything else? Okay Okay, so With that we finish Building point All right, so let me talk a little bit about levels of abstraction so I Can't to tell I mean they don't put the electrons but down below the devices were electrons so Okay Okay, so The levels that we'll look at mostly other than the C programming to just give you exposure to the syntax are the hardware levels The devices how we build gates how we then use those gates to build Uh, boolean expressions and then components like adders which will look with start to look at soon But they're not part of this exam Uh, the micro architecture which is the way you you design a processor out of those And then the instructions that architecture will get to kind of at the end of our class That's the interface between hardware and software. So that's what tells you what the computer can do with individual instructions All of the software then has to be compiled when you write C code it has to be compiled down into computer instructions Or in other languages there might be another program that actually interprets your language In that case that program is written using computer instructions Okay, so So the software always has to come down to the level of instructions And then the microprocessor will actually go all the way up to the ISA level in hardware Okay, so the the processor in your laptop or in your phone Well execute some instructions at architecture and the micro architecture then is just the way of building that So remember that with the level of abstraction Um, what you're building you you can build in many different ways, right? So MOSFETs are one way to build gates There were other ways to build gates so historically There were different different transistor technologies that people used to build gates and they built their computers out of those gates Um, so there are many implementations at every level down Similarly the micro architecture there are many ways to build the particular instructions at architecture Right, there are different companies that produce x86 processors for your laptops They're different companies that produce arm processors for your mobile phones Um, those companies don't share their implementation designs, right? They know the ISA they support a common ISA Sometimes different ones like arm or x86 But the company's competing in one space will typically support the same ISA So your software runs on all of their platforms But they don't share their designs the designs are the micro architecture the way to implement Right The idea with the layer of abstraction is that you provide a certain functionality without telling people how things are built Okay, and so that in the case of the instructions at architecture what that means is Forgiven encoding in bits of course of instructions The the computer the micro architecture can execute the intent of those instructions And that you don't tell anyone the details of the implementation Just like when you when you build a water faucet You know people don't want to know how it works, right? You want to just be able to get your water out. There's a simple interface. You maybe turn it and maybe pull it up Whatever it's fairly simple. You know how to get the water out without understanding plumbing, right without understanding how you make water pressure work Yeah Yeah, absolutely. So there's I mean, that's how they compete right they compete in the in the metrics we talked about so Um area right so how big is it which means how much does it cost them to actually fabricate the chip um power and speed and so speed will determine how fast the process of the ground There's also there's also trade-offs like parallelism for I mean, this is one we didn't talk about but how many instructions can they execute at the same time? Right, and so there's there's that kind of design point which also affects overall performance But but the raw performance based on gate delays and in different parts of their design will also affect their performance And um and then power efficiency so you wouldn't want your your typical server processor in your phone because your battery would not last Right, and so there are different different design points there and they compete in trying to find ways of of Being better in all of those Maybe not at the same time So their designs will have different different values in each of those metrics Depending how they go about building them yeah Um, so I think Understanding the idea of the black box where you've got functionality above and lots of waste influence Um and being able to understand that in a way of realizing it Right in other words if we ask you um We might we might not ask you that question directly, right? So we could ask you something about whether Implementation detail should be exposed to things like that So let me answer that somewhat of weekly I mean in this class probably not so much Um in part of what I said the first day that we're trying to uh Trying to to break you gently into the life of an ECMager um, so we're you know, we're shooting for a test average is Like in the 80s right whereas my historical average from all the EC classes was 75 I wasn't really kidding. I mean, I think people didn't do it on purpose, but there have been class averages as low as 30 on exams out of 100 So I mean those classes would be curved right so don't panic and say oh my gosh How am I going to get a 30 on the exam and pass the class right the class is curved so our class we're we're also trying not to curve right Um the problem with the the essay like questions. I like them a lot. So when you get into later classes It's a better way to make sure people understand engineering design and trade-offs and things like that right it's much harder to grade Uh, it's also Much harder for us to get an 80 average or 85 average So when you start asking engineering design questions, it's more challenging, right? So there won't be there won't be that many on our exams in this class But you should expect to see more in later classes All right, well you really have to integrate the knowledge and and be able to answer kind of more open-airing questions Yeah, so it's a good question in our class not so much, but you'll see more All right, so Was that the people that asked originally about levels of attraction you feel like that was enough coverage or anything else people want to ask? Yeah, I mean we also have a um I think that the encapsulation idea is probably what they're looking for right whether you have to understand how it works in order to be able to use it So I think that's that's the biggest issue is that um you provide that level of isolation that I can use something There's a well-defined functionality without my understanding how it's built All right, and so that's that's the value in data day human life too right a lot of what everyone in the room uses you probably couldn't build You might be able to guess at it you can probably look it up then as engineers you can probably even figure out how to do it But if I just sit here, you know, go play you don't get to use the internet build me a toilet Right are you gonna be able to make it work in a way that you know works nicely? I know I couldn't right but you know obviously We know how to use those sorts of things right and so I think it's really the the idea that you want to encapsulate something in a way that you really need No need to know nothing about the implementation. There's a certain functionality that you can expect to use right like a jar or a toilet or a faucet Right and there's a there's an interface that we all know how to use but we don't know how to necessarily develop the implementation All right, let me spend a little time then on MOSFETs before we finish So remember So the main things are two types so there's e-type And there's an n type The names are for charge carrier so I'd suggest remembering how things work based on the based on this bubble or no bubble that the The bubble turns on when there's a when there's a zero Right when a logical zero turns on and that's because the way the p-type works is there has to be a voltage from these terminals This voltage is greater equal to some threshold to turn it on So if you put a if you put zero voltage here and then you put high voltage Then that will turn it on and the only way to turn it on with binary voltage levels is for this one to be zero And then needs to be the high voltage The n type works with the voltage threshold in the other direction so the voltage between the gate measured in that direction has to be greater equal to threshold to turn on So you need to put VDD here and then zero volts on one of the terminals and then the current can flow Across the two terminals in that case and they can pull the other one down to zero volts in this case it'll pull it up to VDD Okay, so VDD is a one in binary on zero volts as ground as a zero in binary So that's how they work and then out of those We use complementary sets of those which in the case of the gates we looked at in class was just uh was just um um Um So we yeah, I'm sorry hold on a second. No, this is uh someone was pointing us out earlier this we did this after see right Okay, why am I spending time on this? Um, this is on the next midterm so you're getting ready too far in advance um anyway you will know how to use how to do those one day Anything else people want to talk about before I stop Yeah From decimal to hex through through binary I wouldn't try it without that Yeah, yeah Um, it can be minus minus plus yeah, yeah, those are the two overclock Uh if you add plus and minus it's always okay. It never overflows You You You You You You You You You You You You"
    },
    {
        "ECE120-2016-09-23-LEC-13-slides.mp4": " went through it quickly, so I want to make sure you understand the idea of sticking some glue logic in to clean up the inputs. Then we're going to start talking about using an approach to design in which we break off one piece at a time and we'll start with a ripple carry adder and just use the human intuition of how we do base two addition to design the hardware. And then we'll generalize that and think about how we can approach these problems by basically using induction, I approve if the answers are correct. So we'll talk generally about bit slice designs. After this we'll start working on a comparator. I don't think we'll get there today. I think it'll be not till Monday. But a couple of comments before we start. I mentioned last time midterm one, we're going to sit down and grade it tomorrow. After lecture on Wednesday, I took my, we're doing a rubric generation. So I had 20 exams. So I graded 20 exams. I think it was Wednesday night, might have been Thursday. But the average, maybe I should want you guess. So I didn't pick this, but somehow my responsibility for creating problems on the exam totaled a certain number of points. Yeah, 42. I was surprised. I didn't pick it. Anyway, so from 42% of the exam, about 5% of the students, so not great statistics, I'd estimate kind of 80 to 90 average. So the big swing there is that, you know, other people's problems may be easier or harder than mine. But mine on average were about 80 to 90%. Given only 5% samples, so there's a little bit of swing there too. So overall, you did quite well. So ice cream. So remember, we started thinking about how we built an ice cream dispenser on Wednesday. And I said, well, we have three input buttons, MBNP for mango, blend of mango and pistachio. It doesn't sound that appetizing, I don't know if I'd have to. And pistachio. And then each of the two outputs, two unsigned numbers, two two bit unsigned numbers for a number of half cups of each type of ice cream. And we realized with by putting in a bunch of don't cares, we could just design it with wires. But the problem with that was, you know, humans are not nice about following rules. So if they come up and push two buttons, then our ice cream dispenser would at best spit out two cups of ice cream instead of one. And it worst actually might destroy something, right? Because some other engineer might have assumed that, well, we agreed you wouldn't send one one, only 0, 0, 0, 1 and 1, 0 were supposed to be meaningful patterns. So I shouldn't have to deal with one one. So we did actually care in that case. So the solution was, so now I'm going to slow down a little bit because I think I went through this too quickly last time. So the question is, well, how do we fix that problem? And one answer was, well, don't put in don't cares. So pick some bit values that you know are not going to affect anything. For example, pick all zeros. So you push two buttons, you get no ice cream. You push three buttons, you get no ice cream. That's one answer. You'll get some more complicated K-maps and you could build your logic and then your guaranteed that regardless of what the user does, nothing bad happens. So don't use don't cares is one answer. Another approach, and this is the one that I wanted to show you, they're actually kind of equivalent in this case at the end of the day, but you can think of it differently. Well, let's take the inputs and let's put some logic there to guarantee that the assumptions we made that the user will only push one button or zero buttons are actually true. So how can we do that? So that basically prevents the humans from ever putting a bad combination of buttons, right? I remember producing a bad combination of inputs. So how can we do that? Here's one way. So we could say, well, anytime a user presses more than one button, the outputs will generate for them will actually just be all zeros. So let's create a little piece of logic that takes the three button inputs and produces three but three output bits that look like the buttons except that if the user presses two or three buttons, they all become zeros. So how do we do that? Well, for the case of the mango button, you can see the yellow and blue networks are B, B prime and P prime, B prime is the blue one here, and P prime is the yellow one, and you can see those both go into the end gate along with M, right? So the output of this end gate says that the user pushed mango and they did not push blend and they did not push the stash of, right? So this output here for the mango is one, that means they only pushed mango. And so the only way you can get a mango output is by only pushing that button. Similarly, if you look at the at the second end gate here, it's taking the yellow input, which is P prime and the green input, which is M prime along with B, right? And so that output of that end gate says, well, they pushed the blend button and they did not push the mango button and they did not push the pistachio button. So again, the blend output now after this dotted box, they could have only pushed blend by itself, no other combination. And then finally, for the pistachio end gate down here, you can see pistachio is going in there, but we also have M prime and the green network and B prime from the blue network. And so this end gate says that the user pushed pistachio, they did not push mango and they did not push blend. And so the only way you get a one out of that end gate is if the user only pushed pistachio. So by adding these three end gates and a human verters, we can clean up our inputs and guarantee that in fact the human, even if they push a bunch of buttons, they can't affect the system, right? The inputs that we see coming out of the dashed box are always at most one button at the time. So this is one choice. And we can think of this as some glue logic in between our inputs and the way we process those inputs, which is just what some wires. So these wires over here are equivalent to the previous design here. And so I just kind of smashed them together, they fitted all in the diagram, but they're fully equivalent to the previous design. And so you can think of this as, well, all we did was add a little logic into our inputs and how we use those inputs. Okay, so that's one strategy. Another common strategy would be to choose a priority. So there's six different ways to do that. I think there's one in the notes so you can take a look at that. But what does it mean by priority? Well, you simply say, well, one button is more important than the others. So for example, if you push pistachio, I just ignore the other buttons. You're going to get pistachio. So you push pistachio with blend, you get pistachio, push pistachio with mango, you get pistachio. Push it together with both other buttons. You still get pistachio. That'll be the high priority. I think I'd rather do mango. And then second priority would be mango, for example. Right? Again, you can pick any order you want. You can design the logic anyway you want. But you just guarantee that what your logic sees is always at most one button. It is kind of a point. So any of these approaches is fine. So in this case, mango might override blend, right? But it would be less important than pistachio. So you pick a strategy. You can also combine these approaches. So there are many ways to solve the problem. All of them are fine. All of them involve kind of design decisions. And so you as the engineer have to decide what's going to be the most sensible thing for some human who pushes these buttons, right? Maybe it's better to just not give them anything and make them figure out that they should only push one at a time. Maybe it's better to just give them some ice cream and send them away. But that's up to you as the engineer. Right? But it's bad to let the system do something unexpected or unknown. All right. So in the case of our ice cream dispenser, you know, if you work it through, you'll probably get about the same answer. If not exactly the same answer, solving it with a priority from the original K-maps or solving it with forcing things to zero from the original K-maps versus thinking of it as glue logic. And in general, you will get variations in area speed power. Right here, we all had wires. But if you put extra levels of logic, it will be slower. Right? Whereas if you solve the K-maps directly, you'll get SOP or POS. You'll get two level logic. It'll be faster. So in general, you'll get variations. But maybe cleaning up your inputs is a little easier to understand. Right? So you get an abstraction benefit possibly at the expense of speed or area. So they are conceptually different approaches to the problem. All right. So that was it for the ice cream example. Anyone want to ask anything about that before we start adding? Okay. All right. So finally, you know, weeks ago, I said, well, what if you had some hardware device to do addition? And in the meantime, since that first discussion, we've actually gone and filled in, I know the truth tables were adding a walkthrough again in a minute. But so I think you know, mostly how to do this. And probably you could do it without my showing you. But let's walk through and do it. So we're going to do it based on the human approach. Right? So remember, we write down numbers as binary numbers and we add them just like we do in base 10, except it's binary. So 1 plus 1 is 10. And that's the carry. But in general, this approach of well, let's start with a human design. Well, often give you a pretty good design. All right. So you can start that way. It's usually pretty easy because if you know what you're doing as a human, turning that into logic should be pretty straightforward compared with making up something abstract and trying to figure out the details. And it often does lead to a good design because humans are pretty smart, right? The way we do addition was the result of thousands of years of thinking about well, what's the best way to teach kids how to do this efficiently? Kind of thing. So usually the way we do things is not a bad way to do it. So you may remember this slide. This is just an example slide from the first time we talked about binary addition. So we did it before 0 plus 0 is 0 0 1 plus 0 is 1 1 plus 1 is 0 carry the 1 1 plus 1 plus 0 0 carry the 1 and so forth. Right? So we got that. We got the right answer. We were happy. And now we need to put some labels. So in order to build a system that'll do say five-bit addition, we're going to need labels. So I've already called this number A, all this number B, this will be our sum S and then up here are going to be our carry bits. Now, this is a digital system, right? So when I was doing base-to-addition by hand, I was kind of lazy when the carry was 0, it didn't go right as 0. But there's no blank bit, right? So those things, there's no blank bit. Those carry bits are going to be 0, not blanks. And so just fill that in, make sure we know that. There's also this carry bit here, right? So if we're going to design one piece of logic that adds one column, well, that piece of logic also needs a carry and it can't be a blank. So we're just going to assume that we're going to put a 0 into the lowest, least significant bit carry. So just flesh out our human approach with the details that we usually just don't bother the right down. I mean, if I'd ask you, oh, what's the carry here? It's a load 0, right? Obviously, a left of blank, right? But there's nothing obvious to a computer. All right. So two extra assumptions, for the least significant bits, we're going to set c to 0. And for the other bits, the carry input's going to come from the length's least significant bit. So this is just adapting our human approach to digital systems. So let's spell that out. So we've got inputs and outputs for this full adder. So the full adder is going to add one bit. The name is historical. There was a half adder that added two bits. And then if you put two of those together, you can add three bits. So but a full adder will have three inputs. So there's going to be one bit of the number a, which we'll also call a one bit of the number b, which will also call b carry input from the next least significant bit or a zero for bit zero, which we'll call cn. And a full adder will then produce two outputs. So one is the carry out, which will go to the next most significant bit or if this is the most significant bit, that'll be the carry out that tells us overflow for unsigned or just carry out for just complement. And then one bit of the sum s. So those are the inputs and outputs for our full adder. So here's our full adder, the way we might draw it. So you can think of it as a bit slice. You can think of it as a full adder, but here's a picture of it. So it's got two inputs coming in. Those will be the mth bit of a and b. So this will be one bit slice for the mth column of our of our addition. We'll get the carry. I put it as a superscript here to differentiate from the in and the out. But otherwise, it's putting it a superscript doesn't really mean anything. It's just the mth bit of the of the carry, the m plus one bit of the carry is an output and some bit m is also an output. So the question is do you have to pass the carry that gets passed from the left, right? So the one coming in is from the one less significant digit and the one going out is to the next most significant digit. But if you're all the way at the end, then I can let me go back to the here. So if you're this last bit here, so we in a five-bit addition, we would have five of these slow adders. So the last one will produce the carry out of the whole adder. Does it make sense? Okay. Anything else? Yeah. Yeah. So for unsigned, the carry out is the overflow, as you might remember, in order to calculate the overflow for two's complement, we would need that add some additional logic to our adder. And in practice, most adders in real processors would have that extra logic and will give you an overflow bit as well. In the LC3 design and the textbook, they didn't bother to add it. So you can you can calculate it other ways, it's just a little more on the list. So we won't add it to our design. It's one extra x or a gauge. Okay. All right. So here's our here's our design. So now in order to implement this bit, we're going to use a K-Map, of course, and the first we'll fill in our truth table. But we need to add a, b, and c in, and then produce s and c out. So let's go ahead and do that. So let's calculate our outputs. Again, the inputs are a, b, and c in, the outputs are c out and s. I've written these so that we can just add the two numbers and then get a two bit, a two bit sum. And then the high bit will be the carry and the low bit will be the sum output bit. So we saw this a few weeks ago, let's go ahead and do it again. So if I do zero plus zero plus zero, what do I get? Zero zero. Now zero zero one. Zero one zero. Zero one one. Yeah, zero carry the one right. One zero zero. One zero one one one zero one. Yeah, one zero. So carry is one one one zero. Sorry, jump ahead. And then one one one one one one one one one. Okay, so everyone remembers how to do this hopefully. So then we can copy over to the K-Map. And I don't remember if we've done this before in class. So let me just remind you in our truth table, we're generally going to write binary order in our K-Maps. We're going to write gray code order. And so the order of filling things in if you're copying here, I put the two ladder variables there on the top. So B and C go this way. So reading downwards, we're first going to go across the K-Map. If you write the variables in different order, you would go down first. Right. But in this in this K-Map ordering, we'll go B and C first and then we'll do the second row as the second half of the truth table. And then the binary to gray code, since only this direction has two variables, we're going to go here, here, and then jump over to this one, which is the one zero case of B-C and then fill this one last. So that said, we can just read them off. So zero, zero, zero, one, and then fill them in. So zero goes there, zero. And then we'll skip over with the third zero there. And then the one goes in the one one position. Okay, so make sure you get this because you know every time you create something, if you make a mistake copying from your truth table to your K-Map, you're only going to catch it after you've solved the whole K-Map. You go back and you say, is my logic right? Did I get the right expression? Does it work? And the answer is no. Right. And so then you'll go back and realize, oh shoot, I forgot to flip these, you know, to start over basically. So just be careful on your copying. So C out on the bottom is zero, one, one, one. So we'll fill it in the same order, even though the ones you could swap them, it doesn't make any difference, but just do things in the right order. It's sense? Question? Yeah. So remember in a truth table, we're just listing all possible input combinations. C in as an input. Yeah. Yeah, yeah, we have to consider all possible combinations of inputs. And the A, B and C in our inputs. And so we've got in binary order, zero, zero, zero, zero, zero, zero, y all the way through one, one, one. Yeah. Yeah, remember in the truth table, onto the left of the line typically as our inputs, into the right of the line of the outputs. All right, so there came out, so we can go ahead and solve this one. Yeah, so let's find loops. So where do we have loops? One one. Good answer. All right, there's a one-to-one. So which one is that? B, C, N. Yeah. Okay, here's another loop. Which one is that? A, C, N. Which one is this? A, B. So you can write that down. Let's call the majority function by the way, because we've got three inputs and whenever two of them are one, then the output is one. Check that. It's not terribly important you know that, but if you're interested, it's called the majority function. So that's our carryout. For the sum, we're not going to do a camap because it's not so easy to, I'll show you in a second, but it's not easy to just immediately know you've got an X or coming out. So I wanted to remind you that when you do the sum, the output bit, the low bit, is an odd function of the number of inputs. So if you're adding zeros and ones, it doesn't matter how many you add, the answer you get for the low digit depends on whether they're an odd number of ones in your sum or not. Here we've got three. So whenever there's an odd number in those three, we'll get a one, so you can check that assertion, right? So here it's even, you get a zero, here it's odd, you get a one, odd, one, even, zero, so forth. But we write that as a X or b X or c, that doesn't come so easily out of a camap. So here's the camap. Just for your own benefit, I mean, we're not going to really expect you to do this, but if you ever notice it, you can write it, which is if you see this kind of checkerboard pattern, and they'll vary depending on what particular X or combination. But the full checkerboard means X or of all the variables. So here you see a checkerboard, and the answer is AX or BX or C. Checkerboard is zeros and ones. Okay, so we can design our full adder. So what I've done is just done the majority function of top with the C out coming out of that. So you've got the A ended with B on top, A ended with C and here, and B ended with C and from this one, or those three end gates together, you create C out, and then S is just one X or gate with A, B and C coming into it. Yeah. Yeah, so for example, if you flip the zeros and ones, that would be X nor, so it would be an X or gate followed by an inverter, for example. You could also have a partial checkerboard where you had, you know, 1, 1, 0, 0, 0, 1, 1, and that would be an X or of not all of the variables. Yeah. And again, you don't have to recognize those. Let's put the stars up here. Right, just if you're interested or you want to be able to pull the X or us out. Okay. So I wanted to also, so this was our circuit. I wanted to show you in CMOS what this looks like. So typically in CMOS, we will build the X or gate and make that kind of a primitive, just because it takes a few, a handful fewer transistors, right? So typically those would be available as gates built out of transistors, kind of like we did the strange gate yesterday. If you want to see how that works, you can go to the tool and build it yourself. I would suggest doing the two inputs, because the three inputs kind of a pain, but the two inputs not so bad. And then you can check that you got the right answer. But again, it's not something you need to do. But if you're interested in seeing why you get fewer transistors, you can do that. So all we need to do for the top part, remember that any and or circuit, any SOP circuit, we can just replace the ends and the ore with man gates and get the same circuit. So that's all I've done here. So this is the CMOS implementation of the full ladder. Yeah, there. Yes. So ore and becomes an ore, so remember, yeah, I could pull up this other slide deck. But remember that first step is to replace this orgate with de Morgan equivalent, which is complemented inputs and outputs of an end gate. And so you have an end gate here with a complement on the output, that's an end gate. And all the inputs are complemented. You then slide those inverters down to the other end gates, and those become manned also. So it's because de Morgan's law is this orgate is complemented inputs and followed by inverter, that makes sense. And if you look back, I think to last Wednesdays, I'm sorry, last Friday's lecture that Professor Verde and gave, those slides will illustrate that. Any other questions? Yeah. So again, it just takes a few fewer transistors in CMOS to do an XOR out of transistors. And so typically because of that savings, people will make the XOR gate available, built out of transistors as opposed to built out of Nandnor. So that's that thing, that's it. I didn't want to illustrate that for you. I mean, it's doing a little too far into the details of how gates are built, but you know, you can do it in the in the online tool if you're interested. And again, I would do the two input version. I myself did not bother with the three input person. I did do the two input, but fine. All right. So, so we have this one bit adder that we just designed using what we learned in the last week or two. So then how do we actually build an adder for N bits? So when we add stuff, we add one column at a time. Right. And one of these adders, these full adders, is going to add one column for us. So all we need to do is then hook them together. So we'll feed zero into the carry input for the least significant bit. The carry out of the most significant bit is the adders carry out. And then for the other signals, we'll connect C out to C in for adjacent bits. Okay. Then we'll take A and B and divide them up. And then feed one bit of each into each of the full adders and collect the bits of S from the full adder. So let me show you that. So here is a chain of N full adders with a dot dot dot in the middle since we don't know what N is. But you can see we're feeding a zero. Is this big enough to see in the back? You see this? Okay. You're feeding a zero into the carry in of the first one, the zero width bit. And then between them, we're taking carry out feeding at the carry in all the way down the chain. And then the output here is the carry out. You can see A of N minus one and B of N minus one going to the bit slice and so forth all the way down to A sub zero, B sub zero. Those are the least significant bits of A and B. And then down here, S of zero comes out, S of one all the way up to S of N minus one. So this is the most significant bit on the left, least significant bit on the right. And so all we have to do is take N copies of our full adder, wire them together, and then we have an N bit adder. So this is a ripple carry adder. Why is it called that? The word ripple is referring to something like a ripple on a pond. So you throw a rock into a pond and you see these ripples spreading out from where the rock hit the water and they move kind of slowly. So the carry information is moving kind of slowly between the bit slice to bit slice till finally it gets over here. So the speed of this ripple carry adder is not great. It's a simple design. It's an easy to build design. In practice, we use actually tree adders that are much, well, they're significantly faster than a carry adder for when you get to 32 bits or 64 bits. So we may get to look at that at the end of the class, but for now, there's a perfectly good way to build an adder. We can also think of it as a bit slice adder because for each of the bits, we have just the same piece of logic, right, and we just copy it. You want a 10 bit adder, let's make 10 copies. You want a 20 bit adder, 32 bit adder, 100 bit adder, makes the appropriate number of copies, wire them together, and you're done. So fairly simple design. Yeah, so. Loop, oh, you mean to speed up the carry? Yeah, so let me move forward a couple of slides. So, yeah, let me move forward a couple of slides. Let me show you first what an end bit adder would look like in a circuit diagram. So once you've built the end bit adder, it doesn't actually matter how you build it. You can represent it this way. So you've got this sort of funny looking beef thing. Typically, you got to label it as an adder. The end bits, you see the input with a crosshatch end that means end bits wide. So end bits of A and bits of B, they're added together. Sometimes people just put a plus. The sum is end bits wide. The carry in is one bit, no crosshatch. Carry out is one bit also. So there's a shape. You can also then, sorry, the illustration of the crosshatching. You can also then hook them together. If you have an end bit adder and you want a two end bit adder, you can simply put them side by side. Again, the implementation doesn't matter. Once you've got the adder implemented, you can put two of them together pretty easily. You can also, as Sasha mentioned, do this virtually in software. So if you take the carry out bit of one physical adder, and then somehow manage to put it back as the carry in. So instead of putting the carry in as a zero for the second part, you can add the next higher sets of bits and then continue that as often as you want. So in a typical processor, you might have a 32 or 64 bit adder, but you can use that to add arbitrarily large numbers. So you can write software libraries that will do arbitrarily large or even quasi infinite arithmetic by simply dynamically using the adder to keep adding the bits until you finish as much as you need. So usually in practice, you would use that to check whether there was overflow. And that would go into a carry register. So at this point, we haven't seen how to store bits or anything. That's another week and a half out. So at the end, right now, we know how to do a build combinational logic. So there's a signal coming out and we can look at it as humans. But in a real design, you would end up storing that somewhere, and then for example, software could look at it and see if there wasn't carry out. Did that answer your question though earlier? Okay. Yeah. Okay. Okay. Yeah. Yeah. So the question is, well, wouldn't it be better if we had a smaller adder and reused it over and over again? It's smaller but slower. So actually, this tradeoff is something we'll spend a fair bit of time on in about a week and a half to two weeks. So we will look at it in detail at the circuit design level, but you can then do the same thing at a broader level. Yeah. Happened if you start with one instead of zero. That's a good question. What does happen? So what difference would it make if you put a one in? So you would get, you would still get a plus b, right? Plus one, right? Well, the answer would be a plus b plus one. So, I mean, if you're, if what you want is a plus b, then it's one too high. But what if you want a plus b plus one? Then it's the right answer. There's a reason I mentioned that, but I won't tell you why now. Oh. The crosshatch, I'm sorry. Yeah, this thing. So this means that there are actually end bits of signal coming in from that wire. Yeah. So b is actually end its y. A is end its y. The sum is end its y. Yeah. Yeah. Yeah. So your typical processor will have either 32 or 64 bit adders in it. Yeah. But they will not be implemented as ripple carry. They'll be implemented as tree based adders. Yeah. Yeah. So what I showed you is not really the way you build an adder. It's a simple way to build an adder. This way. Not in practice really anymore. Okay. So now that we have an adder, I want you to think about what we did. So how many of you can add two digit numbers? Okay, come on, raise your hands. I know you can do it. What about five digit numbers? All right. What about five thousand digit numbers? Yeah. Doesn't matter. Does it matter? It doesn't matter, right? Doesn't matter if I just say some finite number of digits. You can do it, right? You think you can do it. Okay. Yeah. I mean, I can make it arbitrary, right? So I can make it infinite. You wouldn't want to do it, but you can do it. Have you ever seen a proof you're correct? How do you know you can do it? What kind of proof? Proof find action, maybe? So I think when you learn to add, probably you hadn't seen proof find action. All right. You were probably in elementary school and probably no one said, let me show you the proof find action. So you don't get worried about digits, right? You're probably just going to look at works. You can tell. You can keep adding digits. It's okay. But if you really wanted to prove it, well, what do you need? You need to know how to some base case, right? So hey, I've memorized an addition table and I verified it for one digit numbers. And it works. So I'm good as my base case. And I know that if I can add end digit numbers, then I can show based, for example, in place value, that I can do one more column, and then I can add n plus one digit numbers. And I'll get the right answers. And so you can prove both of those, and then you'd have a proof find action that in fact, addition works for arbitrary finite number of digits. Because that it doesn't work so well for infinite digits, but that's a difference. So when we designed a ripple carry out, or we kind of also assume proof find action, and I didn't prove it to you, I just said, well, we're just based on the human approach, and you think the human approach works, so it's the same thing that we're doing, right? But you could prove it by induction. We know how to add a bit. We made a truth table, binary addition table, so it's simple, just four cases or eight cases, if you want to do three bits. And we went through that a couple of times. Given that we can build an end bit adder, we then have to show we can build an n plus one bit adder by attaching one more full adder, a one bit adder to our end bit adder. So those two steps are also something that, I think if I put it on your homework, you would come back having done it. And so, okay, great, I've proven that I could do arbitrarily large adder design using ripple carry approach. So, in 220, so one reason I want to mention this, one is to get you understanding that for these bit slice design, we're basically just doing proof find action. So anytime you have a problem where you can prove it works by induction, you can do a bit slice design, and design a small piece of logic for one or two bits or four bits or whatever, and then put a bunch of copies down, and that'll work. I mean, you need to make sure that that's an applicable approach, or a useful approach for your problem. But when you can do that, it's a simple approach. The other reason I mentioned it is in 220, you're going to write software that does what's called recursion. So the recursive functions are going to call themselves. A lot of people end up finding this confusing. Okay, so it's the same thing, right? So you say, well, there's some base case, we call them stopping conditions in software, for which you know the answer. And so you need to have that base case. And then you say, well, given that you can write a function that works for input of size n, you have to prove that you can write a function that works for input of size n plus one, by handling whatever the extra one is, and then calling the function recursively for the n. Okay? So it's exactly the same thing mathematically, but it tends to confuse people. And I think the reason that it tends to confuse people is there's this assumption in the inductive step. So when you write the inductive step, you say, if you assume that I can do this for n pieces of something, n bits, n's problem size, and software, whatever n is in your proof find action, you have to assume that it works. And it's kind of weird when you say, well, I'm trying to design something. Well, just assume it works, but I haven't designed it yet. But you have to assume it works. Okay? So I think that throws people sometimes, especially when they get into the system, and that throws people sometimes, especially when they get into software, everything's a little more abstract. Sometimes also in the bit slice design. The proof works if you assume it works, and you show that you can add one more step. You don't have to solve the problem for n. All you have to solve it for is, if n works, n plus one also works. Yeah. Yeah. So. How would you actually apply this for the ripple carry adder? So, I mean, you would have to do, I think, the actual proof would be based on something like place value. Right? So you talk about the value of an n bit number. And then you would say, well, n bit numbers have this range. And I know that the addition works. That's the assumption. Is that I can add any n bit numbers and get the right answer. I can say, well, if I put one more bit in front of my two numbers. Can I prove that given this worked, that I get the right answer with the full adder? Yeah. And that's the thing. You have to assume that n works. You don't have to make n work. You just have to assume it works. And then if you, if you do the inductive step, it will work. Everything will work. So that's that's the point. And then if you do the inductive step, it will work. Everything will work. So that's sort of this strange leap of faith you have to make that, you know, your answer works before you actually design it. So you have to sort of mentally get comfortable with that in order to finish your design. And because you can't get yourself started, well, of course, it doesn't work if you don't design it. But you do have to, as part of your design, you have to make sure that you have a smaller number of bits. And of course, don't forget the base case. If you leave the base case out of something, it will work. All right. So I wanted to just mention that because you will do some, some bit slice designs and you will do recursive software designs into 20. So, so remember this. So what is bit slicing? So bit slicing is a hardware approach that is basically like induction. Right? So it means we're going to break off a small part of the problem. So we're going to do a little bit like we did for the adder one bit of each input or a few bits is fine. And then we're going to solve the whole problem by using the solution for the remaining part. Okay. So we'll take one little piece and solve it and then use the solution for the remaining part. And that's essentially a proof find option. So if you can prove that given only a small part of the input, along with the answer for the rest, that you can get the full answer, then you're done. Okay. So in hardware, there's a little bit of a complication in the sense that we need to be able to express that answer for the rest concisely. Right? So if we can't express it in a small fixed number of bits, then the number of wires we need from bit slice to bit slice will grow. Right? If the answer somehow takes n over two bits, well, then we can't design one piece of logic because as we add more bit slices, n over two gets bigger. Right? So sometimes we might be able to do it logically because we just know the answer. We might be able to do it mathematically. But in a hardware design, we need to be able to do it by expressing the answer using a small number of bits. In the adder, it's just the carry bit. Right? The only thing you need to know about the solution for less bits is the carry. Right? And that'll give you enough information to calculate your sum. So what kind of problems can we do? Additions, subtraction, comparison, we'll do next, check for power two, check for multiples, do pattern matching and inputs, bitwise logic operations. So a bunch of different things we can use this kind of approach. There's probably more that these are the ones I could think of and then I worked on before. So when can't we use it? So anytime the answer depends on all of the other bits. So for example, if I say, oh, do a prime number recognize it? Well, nothing you can tell me about these last, well, at least I don't know how to do it. Nothing, nothing I can tell me about these last five bits. Well, tell me whether, whether with some extra bits on the front, this is a prime number. Okay? And you need to be able to do that, right? You need to be able to say, well, given the other bits is my number of prime number looking all only one bit. If you wanted to do a bit slice design for prime number checker, for example. So that's an example of where I don't think you can use a bit slice design. Yeah. So what do you want to generate? So I mean, if you're just adding two numbers, you can use an adder, right? And then get the next one out. Yeah, so that would be fine for bits slicing. I mean, you can use an adder to generate that as long as you're doing the feedback logic to get back to the two end of the sequence and generating the next one in the sequence. Yeah. Anything else? Yeah. So remember that when we designed, when we designed two complement, we designed it deliberately to use addition mod two to the end, which was what we got out of, out of the side. So the adder and subtractor are basically identical for two complemented and so. And in fact, in order to do the subtractor, and this comes back to what we were talking about with a carry in of one, right? If you think about, well, is there a way I could, I could trick my adder into doing subtraction. Yes, negated, right? Yes. But you don't have to add one. You can put a one on the carry in. Yeah. Anything else? And where am I now? I still more so. Powerpoint. All right. Oh, darn it. Oh, then. Maybe we'll talk about the comparator today. All right. So let's spend a few minutes getting started on a comparator and then we'll finish this up Monday. So let's, next thing we'll do is compare two unsigned numbers. Now here's going to make a difference and we'll figure out how later, whether it's unsigned or two complement. But for now, let's just start with unsigned. So which one's bigger top one or bottom one? How do you know? Ah, okay. So you started which side? You start on the left. Okay. So humans go that way. Why? Yeah. So once you get to see zero zero, you say that's the same one one. Ah, so you can just stop. You don't even need to look. Yeah. So when we build hardware, they can't just stop. Right. I mean, you've either you've got wires, right. The wires don't just say, Hey, I'm going to turn now because I know the answer. Right. Yeah. So they can't just stop in the middle. The information is going to flow from one end to the other and the output wires on the end are going to give us the answer. Right. So it doesn't actually matter for the hardware design. If we go the human way, or we're going to go the other way. Okay. So in our design, we're going to go the other way. It doesn't matter which way we go, because we're going to have to go through all the bits in the hardware. We can't stop early. At least not in this kind of design. Once we talk about sequential state and things like that, you, you'll see there are ways for bigger designs to stop early in some cases, but not in not in wires. So we're going to look at the design from right to left. Look at the least significant bit first. So how many answers are there. So there are three, right. Three possible answers. So if we have numbers A and B, we've got three outcomes. We can say, A is less than B. A is equal to B or A is greater than B. So in order to decide the answer for n plus one bits, what do I need to know? Well, I need to know what's the answer for n bits. Right. And then I need to know one bit of A and one bit of B. So here's an example where we can use bits like. And because if you tell me for one fewer bit or the less significant bits, which of those sets of bits is bigger and which is smaller. And then you tell me one bit of A and B, then I can tell you with that extra bit, which one is bigger or are they equal? Everyone agree with that? So we should be able to build a bit slice design. So what do we need to do? So how many bits do I need to pass from slice to slice? Yeah, right. Because there are three possible messages. You need to know A greater than B, A equal to B or A less than B. I can't condense that into two answers because if your bits are equal, well, then you need to know what the answer used to be because it's the same. So if your A and B for one bit or zero zero, for example, then the answer depends on the lower bits. And you need to pass along any of those three answers. And how many how many bits do we need to encode three answers? Two, right? So you need two bits. So here's a figure showing an abstract slice model of our bit slice. So we're going to have two bits coming in from a less significant bit. We'll call them C1 and C0 and minus one bits. This will be the empty bit slice. So they'll get a sub m and b sub m for the numbers a and b. And then I'll produce outputs C1 m and C and C0 m, which internally just to differentiate these two, we're going to call Z1 and Z0. Okay, so the inputs of what's happening from the from the less significant bits will call C1 and C0 internally and then we'll produce Z1 and Z0 to tell the next bit or to give the final answer will is a less than equal or greater than B. Well, so if the only thing we need to know is a less than equal or greater, we don't need inputs of output for anything, right? We just need one of those three answers. So in this case, yeah, it's a good question. In general, for something your bit slice design may or may need some kind of outputs at the bottom for a comparator, you don't need anything for an aderb. You need one bit for the sub. For example, as we sometimes do on homework or as we might sometimes do on evening sams, we could say, well, out of the bottom, we want you to produce the minimum or maximum of a and b. So if we say minimum only thing you need one output wire, if we say minimum and maximum, you need to separate out the wide. So that's a very good question. Good question. I thought of that too. I will represent the answers. You got three answers, right? A less than b, a equal to b, a greater than b. Is there a natural representation? It's not, right? It's just three answers. Pick any representation we want. So our choice will affect the amount of logic when you. So here is a pretty good choice. Actually, after I designed the one, this is from the notes, after I designed this, I realized what probably should have thought of this beforehand, but I went back and considered all the different choices I could have made and made sure I wasn't somehow doing something that was bigger than it should have been. So there's a pretty good representation. If you're doing the, if you're doing the extra C exercises, the optional ones, you'll get to design your own with your own representation and your own direction in software. But, but the software is not so bad because even if you're logic is a little bigger, it's a few extra characters of typing that is opposed to working out lots of area and things like that. But here's a pretty good representation. So we just say, well, OK, the a equals b will call zero zero. A less than b will call zero one a greater than b will call one zero. And then the last pattern, we've only got three messages. So we're not going to use it. So you have actually a fair number of choices, right? You have these three messages and you have four different bit patterns. So how you assign them is completely up to you. Yeah. Yeah, exactly. Yeah. So as Mohammed points out, now that I've said not used here, I can assume safely, this is not a human, right? They're not going to go pushing lots of buttons or anything like that. The lower bit slice will never generate this pattern. So I can put don't care is whenever I see one one coming from the low distance. Good. OK, so let's see, I'm not sure we'll get through this one before let's see if we can do one bit. So let's solve one bit. So this case, there are no less significant bits. So let's just think about a and b. So if a and b are the same, then what's the answer? You already know that you already know the. All right, fine. I'll just skip ahead. You know the representation. OK, so the meaning though or a equals b for zero zero and one one. And then if zero and one for a b, then a is less than b and one zero is a greater than b, right, because these are on side. So the encoding is zero zero. What about the zero? What about this row? Zero one. Good. What about the next one? One zero and the last one? Zero zero. Good. So this is one bit. So then we can go solve that. I want you to notice that these are min terms. Right. So if you look at z, z one, this is a min term, right, just a one in one row. Z zero is also a min term. So if I draw a circuit for that, all I need to do is generate a min term. I don't need to go through K maps or stuff like that. This structure is going to be kind of the core of our comparator logic. Right. So here we're generating a not b for z one and a not. A b prime. You said that way. And a prime b for z zero. If all you wanted to do was compare a and b and say equal or not equal, you could order these together. That would be an X or. And so these, these are the two min terms that you need for X or. And if you X or a and B for one bit of a and B, that'll say equal. But the X or gives you a zero and not equal if X or give you a one. So if you order these two outputs together, it's just like an X or. But this will be the thing that lets us know is a greater than B or a less than B on a on a one bit basis in the full design. So let me stop there and I'll finish it up on Monday. Good weekend. Oh my god. You You You You You You You You You You"
    },
    {
        "ECE120-2016-11-09-LEC-32-slides.mp4": " Okay, I think it's three o'clock. So today we're going to start with systematic decomposition. So try to give you a way to think about breaking problems down into pieces and do that and to get to the level of instructions. You've already done a little of that in the lab, I know that this is supposed to be a little more systematic than it's the name. I don't want to spend some time, probably most of today, just talking about what does it mean to do a good job of designing a piece of software, mostly just to tell you that you'll take classes later. So don't worry too much now. Give you a couple of hints of things you have that you can start to form now though. Then I think either we'll start this or it'll come on Friday. We'll do another big example calculating letter frequencies in a string. So we'll take a string and count up the number of each kind of letter independent of case and also the number of non-letters. So we'll spend some time thinking about how we want to do it. We'll decompose it systematically and then we'll write the code for that. That'll be our last example actually in binary and then we'll talk about assemblers next week after the review session. So review sessions Monday as you hopefully remember. Midterms Tuesday night. I have actually information. So the eight of cap a new review session, they move back an hour relative to last time. So it's three to five now, same day, Saturday, same place. As always, we can't guarantee that they're going to give you correct answers, but usually they're pretty good, but we can't guarantee it. And then there's other resources up here. So I think you've seen these before. You know, there's slide. Two more times. Well, one more time, sorry. Devlines Friday, if you haven't done it, please do it. All right, so how do you write a program? So you've seen a few examples so far, but it'd be nice, you know, given a task, how do you break it down, right? How do you turn it into a flow chart, turn it into LC3 instructions? It'd be nice if there were some systematic way to do that. How did we do it? Well, systematic decomposition is an approach to trying to program. It's basically saying, well, let's take our task and refine it in the book. I think they refer to it as stepwise refinement, but basically take your task and say, okay, let's break that down into simpler things. So let's start, we'll just take the main task, whatever we're trying to do in human terms and break it apart, and then we'll take those things we broke it into, and if they're still too complicated to do with one, two, three, and full of instructions, we'll break it again. We'll keep doing that until the end result is something where every little piece can be implemented with a few instructions, a few LC3 instructions. So it's actually not a bad approach to doing things. You'll see later, it's not actually terribly systematic, but it can help you think about what you can do. So I wanna go through the pieces and then show you how we map those into LC3. You've seen them all before at the start of class. So we'll talk about these pieces, three kinds of simpler tasks, and then look at how we map each one of those pieces into LC3 memory. So before we start that, I wanna make a couple comments about programming in general. I talked to people in office hours yesterday, generally speaking, you really wanna get out of pencil and paper before you start sitting in front of a computer and writing code. Sitting there, trying to look at bits especially, it's really painful and you get yourself very confused. You really wanna go in before you sit down the program, having an idea of how your program will work, and usually what that means is you drew a picture on a piece of paper, you wrote some notes about what each register holds, so you know what's in the registers, instead of just sort of making it up on the fly as you write instructions. If you have your algorithm clear in your head, and when you sit down, you've got your code in the LC3, you can simulate it when it does something wrong. I say when, not if, because everyone writes bugs. Then you can say, well, what was it supposed to be doing here? And then you can figure out why it's not working. Much easier to debug your code. In fact, this is a little bit of a forward illusion because when you get into writing larger programs, it's very, very easy to have a bug in your code and you can't find it, right? Because you look at your code, and you're not actually reading the code. You're thinking, yeah, this is what I meant to do there. So having someone else come in and look at your code, they look at it and they don't know what you meant to do. They only know what the code is. So there's a practice called code reading, where you have someone else come and look at your code. And it's much, much easier for them to say, well, this is broken. Because for you, you can sit there for literally hours. And it looks right. Because you're just looking at what you had in your head. But if you have nothing in your head, then it's even harder. Oh, it's just... So make sure you have a model in your head before you go, sit down and do it. So draw some pictures, draw some flow charts, think, then sit down to write your program. So when you do get ready to write your program, I would suggest, especially when you're starting out, that the first thing you do is take all of that model and write it out in English as comments. So say, well, first I'm going to do this, next I'm going to do that. You're going to want to put those in anyway, right? Because when you hand in your code or when you hand it off to someone else, we expect you to write some comments. So put the comments in first and then write the code around the comments. You'll find it's much easier that way. Don't leave comments. Don't leave comments as an afterthought, right? Comments are not something you add so you can get those last five style points or something. You should try to do it this way. Actually, so there's a story, and I've forgotten the student's name, but it was one-of-one may-whose master's students. So they had some tricky code that they needed added to their compiler infrastructure for x86. So the student came in and he did his master's adding this code to come about a happier year at the code. And then maybe about six or eight months later, I started working on his PhD, and it turned out they had to make some changes to another part of the compiler, and that didn't interact correctly with his code, his module of code that he had added. And so they said, well, can you go adjust it, make changes to meet the new interface of the compiler? So sure, sure. So he went back and he looked at his code and kept looking at his code, and he didn't have any comments. And he realized he couldn't understand his code. So he had to throw it away and start over. And so don't do that to yourself. Make sure you can make some notes about what you did and so that when you go back and look at your code, you can understand it. All right. So systematic decomposition. So what are these three things we can use look like? You've seen them before, actually. So they're just the same flow chart pieces. We looked at what we see code, they correspond kind of to see statements. The iterative construct, you'll see is a little bit simpler. So here's the first one. So you can say, well, I've got my task. And in order to accomplish this task, I need to do several things. And I can just do them one at a time. So it's just a sequence. So I say, well, first I'll do the first one, then I'll do the second one, then I'll do the third one. Maybe there are two, maybe there are five, maybe there are hundred, it doesn't matter. Just a sequence of things. And I can break my task down into a sequence of smaller tasks, each of which is easier to do. So that's first approach, first pattern. The second pattern is the conditional. So we can ask the question, well, what if in some cases, I want to do one thing, in other cases, I want to do another thing, then I can have a condition. So I can have this test condition, phrase my condition so that it's either true or false. Some kind of Boolean expression, not in bits necessarily, but some kind of Boolean expression. And it either is true or false. And if it's true or there is then sub-tasking, if it's false, I'll do this else sub-task. So that's the second pattern, we can take a task and break it down into a conditional. Either of these boxes could be empty. So you could say, well, if the following is true, I want to do something, otherwise I don't want to do anything. That's OK. These boxes don't have to both be filled. So what if you have more than two cases? What if you say, well, sometimes I want to do thing one, other times thing two, other times thing three, other times thing four. Well, you can just keep breaking these things down. So you can take your else sub-task, for example, and break it down into another conditional. And now I have three cases. I've got the test condition. One is true over here on the left. One is false, but two is true here. And both one and two are false here. And if I wanted four, I could also break down the then case over here, or I could break it down, break down this case, or that case. So I can just keep breaking things down over and over again, and have as many different cases as I want, based on these conditions. So the last approach, or last pattern rather, is the iterative pattern. So this one you saw as the for loop and see, this one is substantially simpler. So you say, well, I want to do something a bunch of times. I want to do it until this test condition is false. So I'll test. And if it's false, I'm done. And otherwise, I'll do the thing, the sub-task. And then I'll go back and do the test again. So this is simpler than the for loop. The for loop, remember, had some initialization and some update. You could add those in. You could break this first down into a sequence where you did your initialization. Then add this iteration, and then take the sub-task down here and break it up into whatever you wanted to do, and then an update. And so you can reconstruct the for loop out of this systematic decomposition process. But your basic iteration is, well, test for something. Do a sub-task. Go back, test it again. Keep doing it until the test becomes false. So those are the three pieces. So flow charts are nice, but you can't just kind of cram a flow chart into memory. Memory is this linear sequence of addresses. And you know that the LC3 is just going to go address to address and execute instructions. Maybe that have some control flow or something like that. But you can't draw diamonds or boxes or start things or things like that. So how do we turn a flow chart into a sequence of instructions? Let's take a look at each of these three constructs and we'll then show how we turn each one into LC3 instructions. So sequential is pretty easy, right? I mean, the LC3 in fetch, it'll add one to the PC. So if you just lay instructions out in memory, then here's your tasks. If you say, OK, let me write the instructions for this first sub-task. And then the instructions for the second sub-task, I'll just put after the ones for the first sub-task. And then for the third sub-task, I'll just put after the instructions for the second sub-task. The LC3, if it starts up at the top here, will simply run through first sub-task, second sub-task, third sub-task, and we're done. So this is the simple case. So for the conditional construct, we have to be a little more careful. So of course, there's instructions associated with each of these three pieces. So we might put the test first. So we'll generate the test. And then we can generate the instructions for the sub-task, for the then sub-task, and put those here. And then for the LC3 task, we could put those instructions down here. So what else do we need? Is that OK? Just do it this way. Yeah. So some kind of branch, right? So maybe here, I can branch on false. So I'll set up whatever NZP and bits, NZP bits, based on my test. I'll set NZP to the right values. So this is branch is taken as the branch op code. This branch will be taken if the test is false. So if the test is false, where do I want to go? I'm going to go to else, right? Good. OK. So now am I done? Why? I just want to talk about that. So if this test is true, then I don't branch. And I execute my then sub-task. So that's good. Then, oh, then I'd fall through. Then I'd start executing the else sub-task. OK. So what should I add here? Another branch. What kind of branch? So I'm hearing different answers. So is there any case in which I want to go execute else after them? No. So I always want to jump over the else instructions, right? OK. So let's put 1, 1, 1 for safety. I mean, it might be the case that, you know, as the last instruction, you always load a negative number. In which case, you could have a different set of bits here, but why bother? Don't make it dependent on this code. Just say, OK, I'm always going to branch. Where do I branch to? But down under here. So out of my instructions for this construct of the lab. OK. Good. So this is how I would set up a conditional construct in LC3 memory. So I need a couple of branch instructions. And if these pieces of code get too big, I can't use branches. I'll have to replace them with jumps. But that's something we'll worry about when you start writing huge amounts of code, which won't be in our class. All right. So then the last one is the iterative construct. And this has two blocks of code. So we can write the instructions for generating the task, write the sub task instructions, and what else do I need to add? What should I put here? So I generate the test. Should I then just go execute the sub task? I should branch. Branch on false or true? On false. OK. So if the branch condition, I'll set this up so that the test is false. If the test is false, where will I go? Down here, underneath, right? OK. Good. And so am I done? What else do I need? Ah. So I need to go back from here up to this up here, right? OK. So branch, what conditions? 1, 1, 1 again. So always branch back up. Do the test again. Only after this test is false, do we jump down to the bottom, get out of this block of code. So this is how we linearize our three constructs to put them in memory. All right. So here's the bad news. So systematic, the word in English suggests that you just follow some formula. You apply some rules. You don't have to think too hard. You just methodically go and break down, break down, break down. Unfortunately, that's not the case with this, right? So computers cannot program for us. If this were so systematic, then we could just tell the computer, we'll just break it down. Take the task, break it down, write the instructions, and we're done. But unfortunately, it's not the case. So usually, you'll have a lot of choices, which means you'll have many different ways to solve a problem, different algorithms. And you have to think about, well, maybe some algorithms are better than others. We don't have any even talked about what does it mean to be better? What's a better algorithm? So we'll talk a little bit about that in the next couple of days. But don't worry too much. Learning to program all takes a lot of time. So this is the first class we've seen programming for a lot of you. Don't worry too much if you're not getting the greatest algorithms out when you sit down to write your lab. It's not that big of a deal. We will try to push you to do things like loops instead of making 10 copies of something. But other than that, don't worry too much. So let's talk a little bit more about good design. So a couple of things you should think about just starting off as you start to form habits of writing programs. One is if something is simpler or feasible, then it's probably better. If you're not sure if something is going to work, don't try to do it that way. Find a way that you're sure it's going to work and write the code that way. Once it's working, then you can go do your improved design. After you commit your code distribution and the working version, the other really bad thing is when you get your code working, then you think, well, I can make it better. And then you make it better, but you break it. And then you don't have a copy and subversion. You no longer have a working program. So always, always commit after you make your first code work. But if you have a simpler approach, it's probably a better approach. It's easier to read. It's easier to write in a way that you know your code works. So simplicity is good. Avoid making things more complicated than they need to be. Try to use clear, obvious techniques. Second bullet, you want your program to be easy to understand as well. So take the time to do things like style, structure, indentation, comments. But also organize your functionality. So that it's easy to go test it. Write your code in a way that you can make sure that each piece of your code works. And that you can also do system-wide testing. So I'll give you some specific examples maybe at the end of today. But think about how I'm going to make sure that what I wrote actually does what I wanted. So think about that as you think about your design. All right. So here's an example. Just to get you started thinking. So imagine you want to do a survey. So I want to do a survey of N people in a room. And I want to ask them 20 questions. And they're all going to answer from 1 to 5 for each question. So then I want to take all those answers. And I want to calculate the average over the N participants. So we're doing some important public opinion poll. So how are we going to do this? So you can do this the usual way. We'll call it method 1. So I make a form. And I put all 20 questions on the form with 1 through 5. You can circle. And I hand each of you a piece of paper. And then you circle your numbers. And then we collect them. So then what do we do with that? So we've got a bunch of forms. We've got maybe 80, 90 people in the room. And we've got a bunch of forms of 20 questions on them. And how do I calculate the average? So do I iterate first over the questions? Or iterate first over the forms? So for example, here are a couple of ways to do it. So question first is on the top. So I say, well, for every question, I go through all of the forms. And I add up that number from each form for that question, so f of q. And then when I'm done with all the forms, I divide that number by n, the number of forms. And that gives me an average for that question, which I can then print out, and then go on to the next question. Or I can do the form first. So I can make an array of all 0s or 20s, and then I'll take a form, and I'll add for each question, I add one number into one of my array elements. And then I'll put the form away, and I'll get the next form, and I'll go iterate over forms first. Then when I'm done, I'll take my array, and I'll divide each entry by n, and print it out. And then I'll give me the average of all the questions. So which is better? Well, so if I iterate over questions first, I only have to remember one sum at a time. And maybe even keep the sum in my head. So that's nice, a little easier that way. On the other hand, if you think about just moving paper around, now to go through these forms, all of the forms 20 times. So that's 20 n forms. I have to get out to look up question 15, question 16. I have to look that up every time. That's kind of a pain, a lot of paperwork. So what about this other approach? What if I iterate first over forms? Well, I then have to keep track of 20 songs. I can't keep track of 20 numbers in my head. So I'm going to have to have another piece of paper that has my numbers on it now. On the flip side, I only have one form at a time, and I read the questions in order. So I get a form and a 1, 2, very easy and very fast. So there are pros and cons to both. But well, why did we have to do it that way? So here's another way we could do it. We can have 20 pieces of paper, one for each of the 20 questions. And it could set everyone in the room. Well, make sure that you come up and put a number from 1 to 5 for your vote for each of the 20 pieces of paper. So if we do it that way, then we can do this algorithm. For every form, every question, set a sum to 0. And then for each person on the form, each number written down on the form will just add to our sum. And when we're done divide by n, and then we get the answer, then we can go to the next piece of paper. So get kind of the best of both. So one sum at a time, each paper has one sum. And we only have one form at a time, because you just read all the answers off of you, one piece of paper. So why don't we do surveys that way, which one is better? It depends what we say better, right? So what's better about method 1? I mean, why do you think people don't do surveys the second way? Why don't we just say, look, I'll post a piece of paper up here and everyone come and put a number on there. Yeah, so there's confidentiality issues sort of. I mean, if all you're going to write as a number from 1 to 5, it probably has an anonymous as giving you a piece of paper where I can maybe even coordinate your answers. Yeah. Yeah, so it's more typing. OK, but we're doing all this by hand. Yeah. Yeah, so participation is probably going to drop. And I have no real way to engage it. I've got to form with a bunch of numbers on it. So I can't say, well, you didn't actually do your form, right? Whereas I've been making you turn in a form. I mean, we didn't say this would be anonymous. I could have even have you put your name on it. So if I don't get an answer sheet from you, I say, ah, you didn't want to participate, right? So there's a bunch of different things. Good answer. So easier to organize, right? Because if I really ask everyone to line up and find 20 pieces of paper, it's pretty challenging, right? Just to say, well, did I get all of them? Are you going to remember which of the 20 you held? Probably need a piece of paper to keep track of them, too, right? Easier to avoid cheating. So what about the person who comes down? They really think this question's important. So they write, five, five, five, five, five. Who stops them? How do we know it was them? Participation, too, right? So how do you know whether someone participated? How do you encourage them to participate? Because it works all on the people now. So you've got to go track down that last sheet of paper. So there's a bunch of reasons that we wouldn't want to do it that way. But just out of this simple question, there are lots of different trade-offs for the different approaches. So that's kind of my point. It's not easy to know, well, what's the right way to do something? There are many ways to measure goodness for algorithm design. All right. I hope you're ready. Been a long lecture so far. Yes. No bits yet. OK, you ready? Go. Need your help. Oops. There we go. Get someone help me out here? Anyone? Just raise your hand. Who wants to help me? Yeah, Daniel. All right, let me just say. So B to C, good. I can do that. F, good. G, good. H like that. Awesome. That is good. That is really good. OK. Thank you. I was helpful. Is that OK? He can be assistant walking director. There's a better idea. Is it good? I can do this. OK, teach my computer. OK. I'll see three instructions, anyone. Do I look like I'm in good shape? Yes, it has to be the shortest. I don't want to walk all around. I want to go straight to Strawberry Fields. I'm already hungry. Would you like to talk to me? But I'm not. I'm in my office. This has to be independent of those kind of things. All right. Anyone? Daniel. Yeah. Oh, that's debatable. Thank you. So break down on the library atteware. Oh, so you want to just give me for this map, you give me all the answers? Because I actually have the Google Maps database to just fill in all the answers for that. And with... All right. So I have an idea. Too late. Too late if you know the good answer. So we're going to list all the paths. And so there's a step one, which is list all the paths. Then we'll measure all the paths. Then we'll pick the shortest one. Sound good? Let's try it. So we need a more complex data structure, which is, yeah, that's beyond list all the paths. So let's see. I'm at b. I can go to a. I can go back to a good point. And then I'm at b. How long are you going to let me go here? All right. So that's maybe not the right one. All right. So that was a little silly of me. So let's do simple paths. A simple path in math is one where you only visit any node once. So we'll only list the simple paths. Yeah. This one's infinite. The one I was showing you is infinite. So that would not be a path that would take us. So I won't list them. That would take me to h. So you can end up. Beneurate. Yeah. So Benny's pointing out that if I take simple paths, I may run into a dead end. So that's not a path to age. So I won't write that one down. Yeah. Yeah. But I want to throw very fields today. You guys think I'm so flexible. All right. All right. So let's try this again. I'm going to start at B. And then I'll go to say C. And then I'll go to F. Oh, this is good. This is good. And I'll go maybe over to E. And then how about down to L. And then M. And then N. And then G. And then H. There's one path. All right. Now we've got some more paths. Thank you. Okay. So it turns out. Yeah, that's some bad news. Turns out that for some graph with P nodes, the number of paths is actually exponential in P. So I had another good idea. Are we good? Maybe not. You didn't seem excited. All right. So here, let's try this. This is my last try. So let's have a queue of nodes. And then we'll keep track of the best previous locations. So for every node, we'll say, well, it came from some other node. And then we'll go through the queue. One at a time. A queue is just a line. So we'll go through the queue and process the nodes. One at a time. And we'll add any unvisited neighbors from that node to the queue. We'll just put them into the queue. So show you what I mean. So here's our queue. And so we haven't put anything in yet. Here's the previous for each element of the queue. So we'll start here at CSL. And we'll put that in the queue. And it didn't come from anywhere. That's where we started. So just put a little dash there. All right. So let's process node B. So where can I go from node B? So a first, right? So I'll put that one in the queue. And then. The. All right. And then. And then one more. So I can go to see. Okay. So what we did to process the element is we said, well, for everywhere we can go directly by walking around one edge. Right. We'll add those nodes to the queue. But only if they weren't already there. And so remember this caveat here. Sorry. Only if it's unvisited. Right. So only if we haven't already put it in the queue. We'll get it. Okay. So there was our first exploration. So we're going to get it finished. So now that's done. So let's go on. The next element in the queue is a. Right. So let's explore node a. So where can we go from a? We can go down here. Right. Yeah. We really saw a D. So we're not going to add that to the queue. It's ready there. We can also go to B. B's also there. All right. So we're done. Nothing to do for a. Okay. So a is done. So we can go to the next. D. Good. Okay. So we can go to. Okay. Right. So put K. Now notice that K came from D. Right. We're processing D now. So to get to K will come from D. So put D down there instead of B. Like we did for all these others. All right. So let's see. K. What's over here? Okay. So we can go up this way to B. Been there. Okay. And then we got one more direction. Right. Been there too. Okay. So I think we're done with D. Okay. D is done. And what's next? Okay. So we can go left to. Already there. Go down to L. And that one's not there yet. So we'll add that in and we'll say, well, we came from E. Coming from E to L. We can go over to F. That one's also not in our queue yet. So we'll add it in. So F comes from E also. And then we can also go up to B from E. Right. But these are already in the queue. Right. Then we'll do C next. So from C, we can go to B. But that's there. Go to F. But that's there. So C is done. Right. Okay. Next is K. Where can we go from K? The J. So put that one in. So J comes from K. Because that's a new one. We can also go to L. Right. But L's there. It's already here. And then we can also go to D. And then we can go to D is there. That's where we came from. Okay. Okay. So K is done. Not too much more. But we still haven't gotten to strawberry fields. I'm a little disappointed. All right. So what's next? L. L can come from K. But K is already there. L can come from M. So M comes from L. And then L can also go up to E. But E is already there. So F is next. So F can come from E. But it's already there. M is already there. And we can add in. So N comes from F. Right. We can get there from F. G can add in from F also. And then C is already there. All right. That one's done. So how about J? And then where we can go from J? Just K. Right. We've already been there. That's how we got the J. Okay. Is already in the queue. Let's skip that one. Or rather just process it quickly. What about M? So we can go to L. Right. L's there. N's there. F's also there. So there's nothing to add. So F is the first one is N. Put that down. Where can we go from N? GMF. There's M in the queue already. There's G in the queue already. And there's F in the queue already. So nothing extra. Yeah. Maybe. All right. So here's F. That's already in the queue. And hey, there's H. Okay. H comes from G. Okay. I sort of made this. I'm naturally long. So we got our goal. So how do we get the path? Go backwards. Right. So here's H. So let's see. So H came from G. Right. Where G come from. Half. Where'd F come from? E. Good. Where'd E come from? E. Good. And that's our path. So we got B. F. G. H. And path is before I think. Oh, almost. I think maybe we want to see before. Remember. Okay. Excellent. So now my computer can solve this problem. So that approach is called breadth first search. So it looks at nodes in order of distance. So it seemed like we put a lot of stuff. That's because the place we were trying to go was the furthest away in the graph. Right. So I just kind of trimmed the graph a little. Didn't put anything that was further away. But if you look at the distance in terms of number of number of streets, you have to walk along to get from. And so, you can see that the number of. So you can see that. That's a very good. I think we have C S L at B to these other nodes. You'll notice that for each of each of the elements in the queue, the number of. Hopps as we say or the distance to those nodes is strictly increasing. So to get to A D E and C, you just have to walk along one street. To get to K. L enough. You walk along two streets. They get to J m and N and G. And you can run exactly the same algorithm. And you'd only look at the nodes that are at the distance you want to go. You actually wouldn't walk around the world trying to find things. You would simply look in the local area. And this would work quite well. And so it explores the nodes in order distance. So you can use it with some commercial map database. And it will be fine. So BFS was actually invented by EF more. Who invented also more machines and some other things. And once you've seen it, right. And you could probably do this, right? If I give you another map and I said, well, find a shortest path here. Then you could probably do that, right? Pretty easily. Pretty straightforward. People used to think of it as artificial intelligence. It used to be, wow, there's these great AI techniques. You can do breadth first search. You can do depth first search. That first search, you just put the things at the front instead of the end when you add them in. But it has different properties. So. You know, what's what's the message? Well, finding the best algorithm for something. And I probably, most of you didn't know how to do this, right? When I said, oh, you know, teach my computer how to solve this problem. Probably most of you said, well, I don't know. I know how to do it. I look at the map and I said, go this way. But probably most of you didn't just say, I know, just make a cue. I mean, if you've seen it before, probably you did. Experience will help classes will help. All of the companies have to take these two classes. I know a lot of EEs also take 325. You may also want to take 374. They're both good classes. Don't worry in our class about finding ideal solutions. Right. You'll have plenty of time to learn. And classes and experience will help you in that regard. So what can you do now? So I mentioned a couple of things earlier. Always start with a mental model, write lots of comments, structure code clearly. When you're writing binary, you know, put the spaces in. So it's easy for you and someone else to read. Identification and alignment for C and assembly code. Really, don't leave your spaces out because if you're looking at a group of 16 bits, you're going to have a hard time noticing that one of them is wrong. It's hard enough just looking at them with the spaces. So without the spaces, it's almost impossible. Some other tips. So trying to avoid repetition, it's really tempting sometimes to say, oh, I've got some other code that almost does the same thing. Let me cut it and paste it into place. You're better off kind of generalizing your code. Often bugs get copied when you do that. Chances are good. The code you're copying has a bug in it. And when you do that, you're copying the bug. And people spend lots and lots of time tracking down bugs. They've already solved because someone cut that bug and put it somewhere else too. And so they find one bug and they don't realize it's been cut and pasted somewhere else. And they have to solve it again later. That's also a common thing. And I think people end up doing just because people tend to think the same way and make the same mistakes. So there's something called regression testing. We'll talk about in 220 that will help you get rid of common errors. Do you have a question? Another thing you can do is try to design your code to make it easier to test. I mentioned this earlier. You have finite time. And you're going to spend finite time testing your code, making sure it works before you turn it in, before you ship a product. And whatever your deadline is, you don't have forever. You've got a fixed amount of time you're going to spend. So if your program is easier to test, then you'll do more testing. If your program takes a long time just to get it ready to test in a simple way, then you'll do less testing. Because it's hard. It's painful. So for example, if you look in the lab, you've been playing with the simulator. There's a graphical simulator. There's a command line simulator. The graphical simulator actually just sends commands to the command line simulator. It's on the command line simulator to make sure it works. And then the GUI stuff is actually quite difficult to test. So we don't test it that way. Testing something that only has a GUI interface means that there's some human there playing with a mouse typically. It's really slow compared to having a computer try to test a lot of things at once. So make sure that you have a testing interface that allows you to do testing really quickly. And then your code will be more solid. All right. So we have a few minutes left. Let me get you thinking about this for Friday, because I think we'll spend most of the day developing it and writing code for it and things like that. So let me tell you what the problem is. So let's say that we want to. I'm going to do the following. So I'll give you an ASCII string, which is a bunch of characters in memory, sequentially in memory, terminated by a null, which is a zero in ASCII. And I want you to go through that string and find all of the occurrences of each letter. So a to z regardless of case and count up. So how many a's how many b's so for it and also count the number of non-alphabetic characters. So I want to count for each letter and account for the number of non-alphabetic characters. Are you ready? We'll do systematic decomposition. There. Build histogram of letters and non letters. And we're done. That's my part. You do the rest. Okay. So sometimes people ask me, well, what's a histogram? So let me make sure everyone knows that. Histogram is a function on a set of categories. There's one way to explain it. So here's a couple of examples. So here are the number of leaves on my favorite tree in September. And this many were green. And this many were yellow. And this many were orange and red and brown. And then I measured again in October. Maybe state of. But I met. I measured again in October. This. These are both histograms. Right. So they show you for some categories here. Leaf colors or whether they're falling off the tree. What's the expected frequency or what is the measured frequency of those categories. So those are histograms. So what we want in our problem is account per letter. Right. So for the string. How many a's either case? How many b's either case? How many z's? So how would you do this? Yeah. Yeah. 42. Yeah. So that's one thing we're going to. We're going to have to do inside. Subtract 40 hex maybe, right? The below letter. Yeah. All right. So. But. But what I meant was how would you as a human solve this problem? So let's. Let's do this string as an example. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. So you can Eric saying you can. You can basically check for a and then. And then maybe check for b and so forth. I think what Nathan was saying is you can actually subtract and maybe use that difference from one to 26 as an index in the memory, for example. So there are a bunch of ways you can do it. So all of those are good. Good answers. What I'm looking for though is is a higher level process, right? So if I literally said, well, do this example. Give me the histogram for this example. What are you going to do as a human? And maybe we can model a program based on what we do as humans. So how many a is. Three. The string is try this string as an example. It's three a's, right? Okay. How many bees? Oh. All right. How many sees zero? Good. How many d's? Good. How many ease? Two. Good. All right. That's enough. All right. So maybe something like this is probably what you did. So for every letter. It said account is zero. And then go through each character in the string. And if you see that letter, add one to your count. And then store the count for that letter in your histogram. And so when I said, oh, how many a's, but look for the string. There's an a. There's an a. There's an a. There's an a. There's an a three. And said, how many bees you went through the string again? We went through the string 26 times or 27 times. That's a lot of times of the string, right? Here's another example. Everyone have their textbook. Okay. How many a's in patent to tell? Everyone got that number, right? How many bees? 42. Exactly. All right. Oh, yeah. So the real question. If I had asked you to do that, let's see you were getting paid. You're getting paid to count the number of a's and bees and seas and patent to tell. How would you do it? Would you do it the way you did it with a little string? Would you say, let me look for a's? Okay. I'm done. A military bees. Or would you do it a different way? Yeah. Yeah. Yeah. So you can go through the whole book. And then maybe I don't need to use sophisticated data structures. Maybe I can have a piece of paper with letters a through z on them. And every time I see the letter a, I'll make a mark on a. When I see the letter c, I'll make a mark on c. And then I just go through the book one time, which is a lot faster than going through patent but tell 27 times, I think. Although you should enjoy reading patent but tell. So maybe not 27 times. So here's another algorithm. So for longer string, maybe what we do is we set all our histogram to zeros. And then for every character in our string, we'll go through it once. And then we'll just increment the appropriate histogram. So if we see the capital letter t, we'll go to the t increment. If we see the number five, we'll say, well, that's not a letter. We'll go to the not alpha bin and increment. So figuring out, well, which bin, that might be a little complicated. Right? So, so we're going to have to figure that out. There's one more I want to show you. We have a few more minutes. Okay. Good. So what if instead we did this? What if instead we said, well, let's make the inner part simpler. I don't want to do a lot of calculation. I want to just make it easy. So let's build a bigger histogram. Let's have, let's see, ask you as 128 characters, right? So I have 128 characters. And then what I'll do is I'll go through the string one time. And every time I read an asky character, I'll just say, oh, that's asky character number 35 hacks. Let me go to entry 35 hacks, add one to it. And so do no computation at all to figure out what it is. I'll just go add them up. Whatever the index is, whatever the character is. I'll use that as an index into my array of 128 things. Add one to it. And then when I'm done, well, there's lower case A and upper case A. So I'll add those two numbers together. And that'll give me my A. And lower case A, upper case A. I'm sorry, low case B, upper case B. Add those two numbers together. Done. And then I'll add up the rest of the things that aren't letters. And that'll give me my now and now. So now finding the bin is easy, right? It's just, well, whatever the character is, there's 128 of them. I'll go to the right one, add one to that memory location. But then I have to add some extra initialization. Instead of 27 bins, I have to do 128. I have to do a little extra work down here. And so there's some trade-offs. It's a little more work at the beginning and the end. A little easier in the middle. So. What's better? So maybe I'll leave you with this. We'll talk about a little bit. I'll leave you to think about it. So. You know, what, what is the metric, right? When you get into later classes or maybe some of you have seen this, you might talk about things like computational complexity, right? Which, which usually math to something like, well, how many instructions does it take? Right? Or how much time does it take? How many cycles, clock cycles? How long does it take to run your program? That's going to have a lot of, a lot of factors that change the answer. But basically, if you're looking at how many things you're doing in your program, then that's a measure of complexity. And you can measure it explicitly with number of instructions. You can measure it explicitly with number of clocks, cycles, wall clock time. Another way you can measure things is, well, how much memory do I need? Do I need, you know, only a few bytes? Do I need a kilobyte? Do I need a megabyte or a gigabyte? Or do I need a terabyte? Do I need to have blue waters to run this thing? Hopefully not, right? Because there's only one of those. So if you need that much memory, maybe it's not your best approach. But those are all trade-offs, right? These are different ways you can measure things. So what about for our problem? Doesn't, doesn't make a difference, do you think, for long or short strings? It's certainly probably you would approach it differently for long string and a short string. Again, I mean, try to think about it seriously. If you wanted to do patent-potel, you really don't want to do that first algorithm. But if you're going to do a short string, is it really worth getting a table and saying, oh, this string is an, that starts with a T. Okay. For the short string, it's probably easy enough to just look at it a whole bunch of times, right? Look for specific letters. So, you know, maybe the answer depends on all the string. What if your string is sorted? And what if all the letters are in order? Yeah, that's kind of crazy, right? But it'll make it easier. Then you just count a's. And when you get to the end of the a's, well, then you go to the b's and you count all the b's. And you count all the c's, you're still going through the string once. A lot easier. But why would, you know, the string wasn't sorted, right? Except you can sort it. And you can sort things. And you can do that in linear time for this particular type of problem. So, in fact, meaning, you know, length of the time proportional to the length of the string. That's what I mean by linear time. So, I could sort it first and then use a different algorithm. Right? So, there's always lots of different ways you can solve these problems. So, let me leave you with that thought and think about, you know, what's good in these things. Until Friday. Thanks............."
    },
    {
        "ECE120-2016-10-05-LEC-18-slides.mp4": " Okay. Hello. Test. Okay. Sorry. A little late. The batteries. No one apparently replaced them. So. All right. So we're going to pick up. With talking about static hazards. Well, I should talk a little bit briefly about other kinds of hazards too. I should have put a star here. Sorry. All the hazard stuff is timing detail. I just want you to kind of see it so you understand that the types of behaviors that real, real circuits have that we will have to. Well, we don't have to. We're going to sweep under the work under the rug in our class and just use discrete time, make our lives a little easier. A lot of these problems are actually also simplified and in typical real processor architecture design, for example, but often you avoid thinking about timing by using a common clock. So a lot of digital system design. We push these issues off on the circuit designers and just say, well, give us give us a common clock and then you know, fetch your job and then we go off and have fun with discrete time. So I just want to give you a few, a few pointers about that. I think there's still things we have to think about timing in EC 385. So you will need to have a little bit more understanding of these later in your career. But for our class, it's just for your enjoyment. And also to see, see some of the complexity. Then we'll spend the rest of the day probably talking about registers. We may get a little bit of into serialization, but that's supposed to be the third part of the class. So we're going to start that on Friday, definitely, but that's kind of where we're headed. So I wanted to do a little bit of review. So this was our flip flop. So this is a master slave, positive edge trigger, deflip flop. So it gives us the notion of discrete time. I have a timing diagram again just to show you, but it's basically two of these D latches with one inverted on the right naval sense from the clock signal. So the first one copies from D to Q when the right naval is low. Right? So rather than when the clock is low, sorry, where it enables high. And the second one copies when the clock is high. And so what this effectively gives us is when the rising edge of the clock comes, this first latch here will have been copying during the low phase of the clock. And then when we switch to the high phase of the clock, whatever value was less stored there is locked in place, because the clock has gone high, which means this one's right naval is low. And then at the same time, this latch starts to copy from its D, which comes from this first latch is Q. It's called x, I guess, from x to Q here. And so whatever value was present on the input, right when the rising edge starts will actually be stored here in the flip flop for a full cycle. The second latch will not change value again until the next rising edge, because this first latch can't change until the falling edge. But then at the falling edge, this latch is again no longer copying, because when a clock is low, this latch holds this value. And so effectively, what we built here is something that gives us discrete time. So once a cycle at the rising clock edge, we copy a new value from D over to Q, we keep that value for one full clock cycle. And so everything about, well, time is continuous, you have to worry about timing issues. This lets us just ignore that. And so we build out of these flip plots. And so it gives us the discrete time. And we're going to assume that between integer values of time, nothing's going to change, right? So all of our flip flops will have constant output. You will in your lab see a non-square-wave clock signal. So we wanted to do something in the lab where you interact with the real world. So you can have fun doing sensors and actuators and realize that you can, you know, you can build robots and other things with what you're learning in 120. But you'll do a finite state machine that interacts with the real world as a bending machine, sorry, right? You put coins in. And it's actually the coins that will drive your clock. Right? So when they go past a sensor, that'll drive the clock signal one direction and when they pass the sensor, the clock will fall in the other direction. So that'll be your clock signal coming from the coin rolling past the sensor. So that'll be more continuous time. But logically, it's the same discrete time that that gives you one clock signal. So you can read about that ahead in the notes if you'd like. There's a section on how the lab was designed in that relationship. Okay. So all of the designs in a class will be clock synchronized sequential circuits. You do need to know a little bit about sequential feedback circuits like latches and flipplops. So you should understand how they work basically. So in class on on Monday, we looked at the design of the latch and the design of the flipplop. And we did the analysis where he said, well, what if we start with a zero on this loop? How does the feedback work and how does it settle into a stable state? So we expect you to be able to work through those kind of things that will give you a different design. But we won't give you very complicated designs, usually one or two loops. All right. So let's talk a little bit about static hazards. So again, you only need to understand the basics of timing. So how to estimate delay is gate delays, simple heuristic for delay of circuits. How to check for stable stable states that I just mentioned. And in later classes, you will have to have a deeper understanding of timing and probably even run into timing bugs in some of your designs. And even if you're building hardware on FPGA, sometimes the tools may not actually get the timing perfect. And so your synthesized version may actually exhibit timing errors, essentially, where something hasn't finished before your clocks as well. I'm going to grab the new value. So let's take a look just for preview of how timing can matter. Why do we care? Why is it not just all easy, even if we have more complicated timing? So I'm going to give you some terminology first. So if a circuit may have a problem. And so if I have a circuit design in that circuit may have a timing issue, we say that circuit has a hazard. So that doesn't mean it shows up. It just means that circuit may have a problem because of timing. If it shows up, if some output from my circuit becomes a variation in my output voltage, we say that that circuit exhibited a glitch in its output. So a hazard is a potential problem. A glitch is a problem that actually happens in the output. And then if you have a sequential circuit and that circuit changes its state in a way that was not designed to do. Not because you built it the wrong way, but because of some hazard or glitch, we say that it had an error. So hazard glitch in error. Now typically if you have an error, it could just be a bug in your design, right? Whatever you built was just wrong, but assuming that you built it correctly, typically if you have an error, that means that something in there had a glitch. It actually changed the output bit and that bit got latched, got stored in a latch or a flip flop. And a glitch implies a hazard, right? So you don't get a glitch unless you have a hazard. So you might have a circuit that has hazards, but it doesn't matter because they can't turn into glitches. Or you might have a circuit that exhibits glitches, but they can't have errors. So for example, when we assume that we only look at at the rising edge is the only point at which we sample our data input. Well, even if that data input has glitchy behavior, even if it's bouncing around. So long as it's stable at the rising edge of the clock, we don't care. So that's one reason that you don't have to actually solve some of the static hazards we're about to talk about. And because in the space in which we're designing clock synchronous sequential circuits, we only care at the rising clock edge. And so the fact that it's something input to our flip flop might be bouncing around beforehand, that doesn't make any difference. So it's okay for your combination of logic to have the static hazards. I'll show you because you're working with clock synchronous designs. All right, so if you want to read more section 263, 4 and 5 are the three types of hazards, static hazards, I just want to give you a definition. So with a static hazard, the idea is that you've got some combinational logic circuit. And you're going from an input combination that produces say a one to another input combination that produces the same value. So again, a one and so you think, well, if it's supposed to start at one and end at one, it should always be one, right? It shouldn't go bouncing around. If your circuit has a static hazard, that might not be true. It might be possible that even though one input combination gives you a one for output, second input combination also gives you one in between drops down goes to zero. So that's the hazard. That one is called a static one hazard. It's also static zero hazard, supposed to be zero and zero, static bounces up to one and goes back down. So static one static zero hazards. Yeah, Eric. So the static refers to the fact that the output is not supposed to change. So both of the two input combinations are supposed to produce the same output value. Either one, which makes it a static one hazard or zero. So static refers to this static nature of the output. So we'll go through a detailed example. Yeah. Yeah. So. Okay, so let me be careful here. Yeah, so the question is what's the cause of a static hazard? No, it's not metastability. If that's what you're thinking about. But it is the case that if you have multiple levels of logic, different gates may actually be changing from one to zero and zero to one. And those gates might be input to another set of gates. And so the output of that additional set might be bouncing around. And so that'll be the example I give in a few slides. That was a good question. All right, so before I give you the static hazard example, though, let me also define other types of hazards. I won't go through examples of these in the class. There's substantially more complicated to understand and figure out static or relatively easy. Dynamic hazards. And here again, dynamic refers to the output. So in this case, the output is supposed to change. We have an input combination that say produces a one. One of the inputs changes and the new input combination is supposed to produce a zero, for example, so what we'd like is a clean transition, right? We'd like the input to start it. I'm sorry, the output to start it one and then it sometimes go down to zero. And that's it changes once. If you have a dynamic hazard, the output may actually bounce around. So it may drop to zero, then go back to one and drop to zero, may do that many times. So hazard just says that it might not change cleanly, may bounce around before it settles to its final value. That's a dynamic hazard. Again, there's an example in the notes, but I'm not going to do that example in the class. It requires more. Deeper circuits, more than two level logic to actually have any dynamic hazard behavior. So there's an example in the notes if you really want to go understand it, but I'll show you static hazards in class. The last one is actually quite important, but it occurs in sequential circuits. They're called essential hazards and they're related to the function that you're implementing. So for static and dynamic hazards, you can change your design in a way to get rid of them. So you can say, well, I don't want to have static hazards. So let me change my design. I'll show you how. And that will get rid of my static hazards. So I don't have glitches from static hazards. Similarly, again, it's harder, but you can change your design for dynamic hazards so that you don't have dynamic hazards anymore. Essential hazards. There's nothing you can do. Having the essential hazard is part of the function you're trying to build. And there's no way you can build it and not have the hazard. So they're quite problematic in that sense. They can't be eliminated. On the other hand, by using the subtraction, this clock synchronous sequential design sequential circuits, what we're doing is taking all essential hazards in any design we do and manipulating them so they show up as clock skew. So the only essential hazard you'll have in a clock synchronous design when we have common clock going to all of your flip flops is clock skew, which again, we're going to push off on the poor circuits people and say, well, good luck. Eric. Yeah. That's how you implement the function. You can change and we'll see that with a static hazard example that if we change the implementation, we can get rid of the static. It's not always easy, but you can do it, whereas essential hazards, you can't get rid of them. There's nothing you can do. You can change. You can change where they show up. But you can't get rid of them. You're always going to have potential. The reason this matter is actually, by the way, so when you build a chip, it's not just design that goes into your chip. There's also variations. These are quantum phenomenon. So if you've taken quantum mechanics, this will make a lot of sense. If not, think of it as we've got now maybe 10 atoms of thickness between our transistor and the part that would let it leak electrons out into the world. Sometimes it might be nine. Sometimes it might be eight. Sometimes it might be 12. But that's a 20% variance in that transistor. So that's a huge sling because of quantum mechanics. That they're quantum devices. Similarly, there's a small number of dopant atoms. Those things also, there's a discrete number of atoms. You never have three and a half atoms. You've got three or four or five. And so the variations that we see now in modern processes are pretty big. And so even though you design your circuits so that it should work, you can get timing behavior because of the variations. And so that makes it very, very hard to design it and have all of these problems be solved and guaranteed to be solved. That's why we have to do very careful testing of chips that we build because the variations can affect their behavior a lot. So I think on Monday, I was talking about speed bending. That's one of the one of the side effects of having process variations and the semiconductor. Those are all research topics too. So, so you know, you don't need to understand them too deeply for our class, not at all. But, but it's fun. All right, so let me give you the static hazard example. So here's a, here's a little circuit. So built out of couple and burgers and a few gates. So what is s in terms of a bnc. Yeah, so a and b in this and gate and this is b not c not and then we order those together. Okay, so now let's think about. So what happens when we move from a b c 1 1 0 to a b c 1 0 0. So take a look at the function and verify that you think the answer should be one in both cases. You agree? Okay, so in the first case, we've got a and b equal to one. Right, so this should be one and then or it was something that gives us s 1. And over here b 0 and c is 0. So b prime c prime should be one or one with something we get a one. And so we should get one in both of those input combinations. Only one bit has changed. Only the b has changed. So let's take a look at what might happen. So b changes. Let's say that's step one b changes from one to zero. So what happens as a result of b changing. So this one changes right because that one went this was one and this is zero. So and gate now produces a different value. So that's going to change good. So the end output's going to drop to zero. What else happens. Yeah, there's an inverter down here right taking b. So that's going to change so that not output rises to one. That happens roughly at time two, let's say these could be gate delays. I would have made this one zero in these one. Right, so wait a minute now this not outputs going to go to this and gate. So what's going to happen over here. I'm going to go to zero because this and gates currently output zero right when we're in this state this and gate was output zero. So now this has got zero or zero what zero or zero. So the or output is going to drop briefly to zero later it's going to come back because this and gate now has one and one it's going to produce a one it's going to turn the or gate back on. But for a brief amount of time that and gate at the end sorry the or gate at the end is going to give us a zero. So that's the that's the glitch. So here it is in a timing diagram. So you can see you can go verify that I got these answers right if you want to but this is the transition that we're talking about with a equals one equals one c equals zero. So that's what's currently one and then B drops down that causes B to go low briefly. And then when B prime goes high out of the inverter that drives us back up so this is our glitch. So in the past when I was when we're introducing those ideas it was let's look at combination logic and isolation and so often you're building combination logic between sets of flip flops right and so if it's a flip flop coming in as you saw yesterday. I'm sorry not yesterday but Monday then you can get both Q and Q prime for free right without a gate delay they're both available at the same time so that was why they were free. If for some reason you don't have your logic coming out of flip flops or your I mean here we're we're we're not assuming we didn't assume that we had this for free partly because I wanted to show you the glitch right so I came up with an example that would show you a glitch so you got me but one can imagine making a different circuit where we didn't have that or in some cases in fact we won't always have the have the complemented inputs if the if the values are not coming directly from flip flops or latches. So in this case it was a little bit contrived and so that was why I wanted to count it but to show you the glitch but there are designs where you might not have the availability of complemented inputs in which case you do need the you do need to count the inverter. So in fact even in the bit slices right where we're going bit to bit we don't produce complemented outputs so really we should have counted the inverters there but I was trying to make life simpler at that part of the class. Good question yeah. Yes so I showed you something with the latches and the flip flops timing diagram so it's clock skew is we assume that the rising clock edge edge arrives to all of the flip flops all at the same time. So we have a common clock and the rising edges arrive at each flip flop at the same time now that's one that's not really possible to do and to it actually doesn't mean anything in the real world because special relativity tells us the same time in two different places doesn't have meaning. Which if you haven't learned yet you'll have fun learning but if they arrive sufficiently far apart in time that information can propagate between one flip flop and another then that can actually cause us problems in the behavior. Because one flip flop may change its value and then its output may affect the input to the other flip flop and so the clock edges don't arrive simultaneously to all of the flip flops that can cause problems and that's clock skew is the is differences in the arrival time of the rising edge of the clock. Yeah. Well so I'll show you a fix in a minute but the yes the delays through the circuit as designed are opening the possibility or are hazard and open the possibility for a glitch. Now if we just assign different amounts of time to these to these various gates we could set it up so that the so that the glitch never showed up right so this is a hazard doesn't necessarily ever show up as a glitch. But this circuit has has a hazard regardless because if I put the wrong amounts of time through these gates then it can show up at the output right so this path from here through here is slower than this path through here then it'll show up. Yeah. Yes and there in more particularly there are two separate paths from B to S and the timing of those paths maybe such that even though the N value of S is the same the timing of those paths creates a downtime in S. Yes it's the longer delay along this bottom path through the inverter in this handgate in the sword gate. Yeah. So all we really need for the glitch to show up is for this path to be slower so I didn't even really need to add the gate I just need to have that path be slower for whatever reason. But that's that's harder to explain I mean I don't really want to have to have everyone understand process variations but it's possible for even without this inverter even if I had the compliment available for that path to happen to be slower than the top. But this makes it I think easier to understand that we can just count gate delays. Alright so what can we do? Briefly yeah just like this depends what you're doing with it right so you know humans for example are pretty good at catching flickers right because our lives used to depend on catching the predator flickering amongst the leaves right. So you know if you're driving some output that a human can see they might actually see that it's doing something weird right if for some reason whatever you're whatever you're doing might also use this value and expected to be constant and if you have something that realizes it's gone low and does something in response it will also react it doesn't have to be human could be some electronic circuit. So that's one answer I mean as long as I guarantee that my clock edge doesn't come in the glitch. As long as I as long as I wait long enough to make sure that all of the paths have have settled through my circuit and so I can count like you said I can count the count the paths find the longest one make sure that my my clock between the change and the and the latching of the output is sufficiently long that all of my paths have settled. And I can use a deep flip flop and I'm guaranteed never to see this behavior and that's practically what we're going to do in our class right is to say we're going to ignore this kind of stuff because we always wait long enough to run our clock slowly enough that we just never see the never see the glitches. Good answer but I can actually change the circuit to so I don't see the. So how about this let's take a look at the came up. So those are the end gates and those two loops are the end gates so remember there was a b which is this one here right and there was b prime c prime which is this loop on the left. So the behavior we're seeing is this input combination so 0 1 0 I'm sorry 1 1 0 so a is 1 1 0 going to 1 0 0 so you can see it's crossing between loops so in other words one of the end gates is going to switch from producing a 1 to a 0 the others producing 0 to 1. So how can I how can I prevent the output which is the ore of these loops from going down. Yeah I can add another one right let's add a new loop another and gate cost me a little extra area got to have the extra and gate but now this purple and gate here there's new loop that's one for both input combinations so that and gates going to always produce a constant one which is going to go into the or gate. Or gates going to produce a constant one also. We can imagine this is substantially more complicated if you have more than two levels of logic it's more complicated if you have to draw extra loops between all of your loops to make sure there's never a transition that isn't covered right so it's not necessarily easy but you can do it you can add extra gates and get the answer so that new and gates going to stay at one so can fix our static hazard that way. So it's going in any transition so when we when we analyze sequential circuits we assume that that inputs don't change simultaneously that only one input changes their time so what that means is a K map is moving from adjacent box to adjacent box right so you only move from one input combination to adjacent boxes of any time. So all of the transitions you have to analyze are the edges between the boxes in the K map and a static one hazard would be to go from any one to any one so you then look at all of the all of the loops you have and make sure that that anywhere you can go from one to one it's always inside some loop and that will be an and gate that produces a one constantly during that transition. And if you did POS you would do the same except that for all of your zero to zero transitions you'd always have a loop that encased every in closed every transition and that would guarantee that those those or gates would always produce a zero for that during that transition for static zero hazards if you do SOP design you don't have static zero hazards because none of the end gates is on. Going from no end gates to no end gates to the word. Alright so that was I think that was it for our fun time was hazards. Any other questions before we go back and talk about registers. Generally speaking we always assume with any kind of sequential logic analysis that only one input changes at the same time that the that the transistors react quickly enough that any tiny little difference in changes will be seen sequentially that one change will happen before the other so we simply ignore that possibility that would that would correspond to two box change. So we assume that never happens. Yeah again we assume that one input changes at a time that that even if they're very close in time that transistors react very quickly and so they're separable and serial and so we assume that only one input that changes at any time never simultaneously. We assume that the same thing is the same as in the transitions. It's not always the perfect assumption but as I already mentioned with latches right if they happen if you let with an arbor as bar latch if you let them both go up at the same time you might get menace stable states right so it doesn't always work but that's generally the assumption when people analyze the sequential circuits. Okay yeah. It can bounce yes yes so if you took if you took our circuit here and you connected s to another piece of combinational logic while you're changing the input right so the outputs of course can also change yeah that's right. These changes if you connect this to more combinational logical propagate through and that's where dynamic hazards come from so if you look at the example in the book you take a static hazard then you add some logic to it and then that can create a dynamic. All right so let's spend a little time on registers then all right so so far we talked a lot about representations right we had usually bunch of bits together in groups like unsigned to complement floating point asky and we talked on Monday about how we store a bit right so flip flops going to store one bit well what if I want to store a 32 bit unsigned number well let's build something to let us do that we'll call it a register so it's a storage element. We're going to build out a flip flops and it's going to store things groups of bits again all of our flip flops will operate on a common clock. Now a flip flop stores a new bit every cycle with a register we want to have some control we don't want to just store some new bits every cycle we want to be able to say well in this cycle I want to put a new 32 bit unsigned number my register and I wanted to stay there until I tell the register to put a new value and again later. So I'm going to add a load input maybe L.D. or load so when load is one on a rising clock edge the register will store new set of bits otherwise it'll just keep the same bits so the only time it's going to change is when load is one on a rising clock edge otherwise constant value store. So here's an attractive option and might seem attractive so I'll hide the rising clock edge you don't want to see the rising clock edge you don't want to change your bit so hide the rising clock edge I can add some logic down here. You probably don't want to use this until even a few years ago it goes in phases so for a while people were doing clock dating then they realize as I'll talk about a minute it adds to clocks you and so they said don't don't do this because it makes the circuit people's lives miserable so for many years we said no never do clock dating just rule it out completely. There are power reasons if people are starting to think about it again it can save you power sometimes but for our class never never think about doing clock dating it will introduce clocks you and so it will introduce ways to have nasty subtle but subtle bugs with essential hazards and if you do it in your lab good luck don't do it. So here's another reason you have to actually be kind of careful with how you how you manage your load signal so load affects your clock your perceived clock see so your perceived clock is now this signal see here. So your perceived clock you can get specious rising and falling edges so for example here while the clock is low if I raise load I get a specious falling edge that doesn't matter because I have a positive edge triggered deep flip flop this was a real clock edge so that's okay but unfortunately if I if I lower load if I lower load while clock is low I get a specious rising edge so in the middle of my clock cycle I do a load so if you're not careful you can you can make your flip flop store value. Even in the middle of the clock cycle it's probably not what you want to do so you have to manage your your various signal timing in addition to thinking about the clock and so and worrying about clock skew so that's the main reason is the extra logic contributes to clock skew it slows the rising edge to the clock so you want to avoid doing that. So we will have one application that uses a different clock for some flip plots it's called ripple counters you'll see it in maybe one or two weeks but otherwise you should always assume common clock signal to everything and you shouldn't try to build clock gate. So what should we do. And with the input so and what with the input but then that would load a zero right. Yeah so you're you're building up to something that we've seen so we want to pick between keeping the old value and taking a new value what should I use if I want to make a choice. They allow a mocks good okay there's a mocks and it's true Peter what you were saying that inside of that we're ending the load signal with one and ending the old value with another min term of the of the load signal I should say and that's how mocks works internally so you're on the right track. But let's just plop it down as a muck so what happens here when load is equal to zero we take the q output of our flip plot which I probably should have drawn there and bring it back that's a zero input of the muck so the mucks forwards the old bit and that just gets stored again so just retains its value when load equals one we take in. Wow that was fast we take in and we copy it to D and then a rising edge de-stores that value for us so this is one bit of a register and then we'll use that design as a bit slice okay so for an end bit register we'll have n of these n mucks and flip plots. So here's an example for four bits this design here we say it uses parallel load okay so we've got four input wires and they're coming down the load controls all four of the mucks is so when load equals one the entire four bit register stores a new value when load equals zero same four bits are stored there until load equals one again and it sees a rising clock edge again common clock at some point I'll no longer even draw the clock signals right now I'm still drawing it just to show you there's one signal that goes. All four of this with a 32 bit register same thing one clock signal with all of them when load signal to all 32 mucks is and then 32 separate wires for parallel load for the different bits. So that's a register now sometimes we want to load registers one bit at a time instead of loading them all at once in parallel so we have a notion of a shift register for that so here's a shift register so you can see what happens. We have a serial input on the left that's the thing that puts a value into this flip flop here this flip flops value stored value in the next clock cycle is then shifted over to this flip flop this at the same time at this flip flops value shifted to this flip flop and so far all the way through the shift register so if you think about cycle the cycle what's happening is we have the input we're putting one bit at a time and those bits are just shifting through our register that's why we call a shift register at the end we have a serial output so we can see the bits coming out one one bit at a time from the serial output or we can look at all the bits at once if we want to yeah. So those are the parallel outputs so if you want to look at the value of the shift register you can simply look at these output wires and then I'll give you all of the bits at one in one time. Eric. So I'll talk about a couple of applications in some cases we want to look at the bits in parallel and in some cases you want to look at them in serial so it depends what you're trying to do you can look you can look at a shift register stored value in parallel or you can look at it in serial and depends what you want to do with it is the way you want to look. So let me give you couple examples so there are lots of applications one is 30s so optical networks for example go at about 100 gigabits per second you can't clock the typical CMOS processes 100 gigahertz. So what happens is you get the optical fiber coming in it's producing 100 bits per second and 100 bits per second you could probably do in CMOS. So 100 billion bits per second and you use other you use other semiconductor processes to build this logic but you put that into a shift register so they're going in there at 100 billion bits per second and then you you pull them out using these parallel wires say you built a 25 deep shift register you pull them out it for you. You pull them out at four gigahertz right so every 25 cycles of 100 you pull out 25 bits and so now that's clocked at four gigahertz which you can do on CMOS so you hand those to a normal CMOS chip and you get 25 wide at four gigahertz instead of one wide at 100 gigahertz. So this is a de-serialization of the optical signal you also use a similar strategy for serialization when you want to go from from a four gigahertz processor to 100 gigahertz per second 100 gigabit per second optical line you do a serialization process. So it's a similar application. So that's one thing to use shift register for. My postdoc was actually using shift register as a couple of weeks ago so I thought I just mentioned it he's working on computational genomics applications we get data coming in from memory let's say at one clock cycle but then we need to feed this computation with different parts of the data at different clock cycles so how do you delay it we'll put it into a shift register when delay at two cycles put it into a shift register to do each bit gets delayed to two. Two cycles right you want to delay at five cycles five deep so it's good for delay applications as well. All right so we can also design them to stop shifting so of course if we want to shift register that we can say well in this cycle I want you to shift next cycle I don't want you to just hold your value for a while well of course we could just put a muckstown. So if we want to shift equals one this behaves like the old design shift equals zero just freezes and holds its value as long as shift equals zero. Some other things we use shift registers for so the serial load idea that we use with the shift register is critical when we don't have a lot of wires right so for example. So if you go to 32 bit register you have to fill 30 you have to have 32 wires to fill it on a chip for example we have a hundred thousand flip blocks so if you want to test the chip and you need to fill hundred thousand bits you don't have a hundred thousand pins and nothing will give you a hundred thousand pins into one chip these days maybe a few hundred. So how do you how do you fill them will use shift registers right so you use fewer pins and you shift bits in through the flip blocks one flip flop to the next you fill them all up with bits to test your chip you run your chip for one cycle and then you shift out the answers where you shift in a new test factor. So we're using shift registers to test our chips reconfiguring hardware so how are how are field programmable gate arrays use in 385 how do you configure them to execute hardware well again we don't have so many pins just to shift everything in in one clock cycle would also melt the chip but. So we shift things in using shift registers right so all of your hardware designs that you build and synthesize in 385 will be shifted into the FPGA through shift registers in order to configure the hardware to simulate your design so both of those applications you shift registers. Alright so i wanted to give you some terminology so you can do left shift right shift yeah. So you're you're filling up your shift register with 25 cycles of 100 gigahertz and then you're pulling that out I mean the rate at which you take data out is for gigahertz now you don't have. One what is it a quarter of an anti second you don't have a full quarter of an anti second pull it out you've only got one 100th of an anti second 10 picoseconds to pull it out but once you get it out then you can treat it as as a normal four gigahertz clock once you copy it out of the shift register. Now you pull all of the bits out simultaneously using these wires down here. And no because you wait for it to fill up again I mean here we're only showing four but if you wanted to do it 25 to one you would have 25 deep you fill out 25 using a serial input whole 25 bits out fill out 25 whole 25. Makes sense. Alright so let's see so this one we talked about alright so right and left just with corresponds to what we might put in in terms of representation so if it's on a piece of paper they correspond to the piece of paper if it's in if it's in a representation it'd be from least to most would would be left and from most to least significant would be right. Hopefully you remember the difference between logical and arithmetic shifts so if you have a shift register that's supposed to operate on unsigned values then you would use a logical right shift if you wanted to operate on to complement values use an error arithmetic right shift which would copy the sign bit. It's a remember logical you shift in zeros arithmetic you copy the sign bit when you shift right both directions shifting left you shift in zeros. And then there's also applications of cyclic shift registers we bring one bit from the serial output back to the serial input sometimes going through another register that allows you to build bigger shifts so typical modern processors will allow you to build save 64 128 arbitrarily large shifts by doing 32 or 64 bits at a time so you do a cyclic shift you bring one bit out into what's called a carry register and then the next set of 64 bits let's say you shift to carry register in on one end. Pull another bit out go to the next six of set of 64 and keep doing that so so that's why processors often support this this idea of cyclic shift it's just a circle new shift register. Alright so we don't have to pick one design right so let's build one register that does one of four things. How can we do this. I want one register I want to control wires C1 and C0 and if I put in 0 0 I wanted to hold its current value if I put in 0 1 I wanted to shift left from load of high bits from one zero I want to load a new value parallel load from I'll give you some wires in sub i and then if I have one one I wanted to shift right from high bit to load it how can I build something like that. When I want to pick one of four answers. A mux right yeah a decoder will give us the minter so you could you could do it and then you could use logic the minter you get you get the same effect but the mux already gives me what I need to bring it together so. All I'm going to do with that output out of those four possibilities is put it into my flip lock right so next cycle it's going to store one of the four answers so I can do this with the decoder to and then and then put the extra logic to bring the four outputs together and put that into the but mux already does it for me so usually if we need to pick among several things we're going to use a mux. The decoder is only when we need to do separate operations on the four outcomes so here let's take a look at this design make sure it actually works so I said zero it's going to hold its value right so if I put zero zero here I pick the zero element that comes from its current value and so this is my bit slice any time I set C equal to zero zero then this register here is going to just keep its value as long as I said C equal to zero zero. If I set C equal to one zero one in particular then this comes from q i i minus one and so that's a less significant bit so that's going to shift left from low to high so this q i minus one is the next bit over here it's going to take its current value of that bit and copy it into that the bit that I'm showing on the on the slide so that's a left shift if I set C equal to one zero the number two. In decimal then it's going to take this input wire for this particular flip flop and store that into my flip one so that's a parallel load. And then last if I set C equal to one one three then I got q i plus one so that's some bit I haven't shown over to the left so we're shifting now to the right we're taking the high bit shifting it down to the next lower bit so that's a right shift which is what we had on our last diagram. So by using this four to one mocks and wiring it up correctly for each of our bits slices we can build a register that does any of these four operations and does whatever operation we tell it in each of the cycles. So you can do arbitrary combinations of these things right if we were to ask you on a homework or an exam okay we want you to shift left we want you to do arithmetic right shift we want you to do logical shift left we want you to do cyclic shift just any combination really all you have to do is this this mocks and then maybe some logic at the end if we say arithmetic versus logical right shift right you have to decide what to do with that input on that side. But but for the most part this this mocks design will allow you to combine arbitrary register designs pretty easily. Alright so I think that was the last slide on registers there's a little more there's a few more pictures of these things built out into into multi bit registers you know with the bits slicing in the notes if you want to see that it's sort of the same as the earlier ones I showed you but it has this bit slice in it. Alright let's see we've got a couple minutes so just give you the idea of what we're going to do here so more on on Friday now but if you think back to bits slices right each of the bits slices we worked with would have some number of inputs operands like the comparator had two operands right the adder would have two operands a power of two checker would have one operand right but we actually did it two bits wide so it had two bits. That's why it had to produces some number of outputs for each bit slice at the comparator produce nothing and adder produce just the some bit the power to checker also produce nothing down here and then some number of bits between bits slices right for an adder just to carry bit for comparator we had to for power to checker we had to between bits slices. So you sort of a general model with p bits in cubits out and m bits in between and then what we're going to do with that is use flip plots to produce a serial design so remember when we're talking about this initially someone said well can we can we instead of putting you know n bits back to back with hardware couldn't we use fewer bits and then you software to make the bits flow through them we can in fact we can make the bits cycle through the same physical hardware in hardware also. So what we do on Friday is think about how can we use flip plots to take our bit slice design and turn it into a serial design so we'll have one copy of the bit slice just one and we can do arbitrarily large operations by just using it cycle to cycle for in cycles instead of building a big design so we'll trade a smaller area for slower speed.. You you you you you you you you you you you you you you you"
    },
    {
        "ECE120-2016-08-24-LEC-02-slides.mp4": " cover for the day and kind of let it sit there before we start. So these are the things we'll cover today. We're going to finish up abstraction layers and digital systems, talk about representations and bits, and maybe get through some of the energy representation. One thing I didn't mention last time, but I wanted to make sure you understood just because I tend to talk a lot and talk quickly. And I'll tell you stories, things like that. If it's important, I'll write it down. So if I just tell you something, or I mean, sometimes you might ask a good question, in which case, the answer is important. But if it's something I'm planning to say, and it's important, I'll write it down. If I'm just telling you a story, it won't appear, and it's OK, it's not going to be test material, or anything like that. It'll just be for your interest, or to help you better absorb the material. But important stuff will be written down, either here or in the notes. One other thing I wanted to mention, there's a rule that I wanted to explain why this rule is there. So tomorrow you have your discussion section. Remember, those will be working groups. So you need to arrive on time, because if you show up late, then you kind of disrupt your group and delay the start. And so people will be unhappy with you. So as a result, you'll lose a few points. So that's the rationale. It's not my favorite rule, either. But please show up on time. All right, so a couple of review slides. We started talking on Monday about abstractions. About abstraction layers. Each one provides some functionality to layers above it, and then is implemented on layers below it. And we looked at digital systems as seven layers. We didn't get through this whole diagram. But we had gone through problems and tasks, and I pointed out that there was ambiguity. It's probably no one in the room realized that when I say time flies like an arrow, what I meant by that. But now you know. You might have thought it meant something else. So there's ambiguity in human language. So how do we implement our problems and tasks in digital systems, whether each problem or task will map down to what we call an algorithm? And for any problem or task, there are many algorithms we can choose from. What is an algorithm? It's a step-by-step process. So it's a step-by-step process that has three characteristics. One is definiteness. So we got to get rid of the ambiguity. When we talk about human tasks, like what's the sum of numbers between one and three, there's ambiguity. What do I mean by between? Do I mean integers, real numbers? What am I trying to ask you? With an algorithm, all of those questions have to be answered. We have to be specific and definite in terms of what we mean. We also have to have effective computability. Computers are not smart. They can only do very simple things. Add two numbers, move some value from here over to there. And we need to express our algorithm in terms of very simple steps. So that's called effective computability. And they also need finiteness. So how many of you know how to count? Good. I was teaching you in Vietnam a few weeks ago. Whenever I'd ask them a question like that, no one would raise their hand. So I'm glad that all of you know that. How many of you have finished counting? Really? OK, I need to. I need some people are saying they've finished counting. I always thought it was impossible. But I guess maybe I'm just not smart enough. Yeah, so it needs to be finite, right? The task, the algorithm needs to be finite. It needs to finish in a finite amount of time. Maybe you need to finish because it's, you don't really need to do it. You'll find later in our class, we're going to use counting. So each of our algorithms, we can implement on many different computer languages, right? So some examples, there are actually thousands to choose from. So thousands in the research literature, thousands of prototypes, actually probably hundreds of commercially available languages that you could go writing algorithm in. Some examples you may have heard of, C, C++, Java, Python, some you may have used, JavaScript. We're going to use C in this class, in the second class, to 20. Why do we do that? One is there's an easy mapping to low levels. So by the time you've done with this two sequence course, when you write C statements, you'll understand exactly how those are turned into instructions, which is going to be the next layer down in the hierarchy. The instructions are what the computer actually executes. What a computer actually executes. So you'll understand that mapping to lower levels. C is also a subset of some of these other languages. So once you know C, you can learn more about those languages, but you can already do everything with those languages. It's just there's extra syntax in things like Java and C++. But the mappings are not as simple. Yeah, question? So C and Java, they're fairly similar in terms of syntax in terms of what the code looks like. But Java has, the way you write Java is more object-oriented. And so you build things around data structures. And so the way you approach problems is slightly different. And so that's why people like Bihar and East Shrewstrup, who invented C++, believe that that's fundamentally you should start with something like his language, C++, because it's object-oriented, where C doesn't force you down that paradigm. So I think by learning the basic syntax, at the end of the day, most C++, most Java code will have to be written in small procedures. And those, you will know how to write after learning C. So I feel that this is the right way to do it. But not everyone in the world agrees with me. Yeah. So I'm going to go for LC3. I know that there's some leads in later. You can come up here and come up with a server for that. Yeah. I'm wondering, is there any meaningful chips that are like a product that you can use for your own? OK. So the question is, is there an actual chip that implements LC3? So I don't remember whether anyone actually ever did it in 385. There's no commercial LC3. LC3 is an educational architecture. But some of our students have been so excited about having fun with LC3 that I think they may have done it in an FPGA. And if not, you can do it. You can be the first. Yeah? OK. So next level down, we take our computer languages and those get mapped into computer instructions. So there's a layer that we call the instruction set architecture, which specifies what are the things that can be done by the computer. So that's the interface between software and hardware. The software has to be expressed in instructions. We can have things like C, things like Java. But at the end of the day, the only thing the computer knows how to do are instructions. Add two numbers, put the results somewhere, put the sum somewhere. For example, it would be a typical instruction. Examples here, x86, most of you laptops, most of your desktops, have probably have an x86-based processor in them. Arm, most of your cell phones. If you have a smartphone, probably have an arm processor in them. Power PCs and other embedded processor, your car may have a power PC in it. For example, below that, oh, and of course, computer languages can be implemented by many instructions at architectures. We can map computer languages to many ISAs. We can also map ISAs to many micro architectures. So once you have the instructions, you can build something to execute those instructions in many ways. The way you build it is called a micro architecture. So for example, the x86, there are i5, i7 from Intel, Optron and Phenom, from AMD, for ARM, you've got Cortex A15, Cortex A9, Kinetic, K. So there's many different implementations. We call those the micro architecture. So what is our class cover? We're going to build from the ground up through the ISA level. That's where our class will go. We're also going to dally briefly in week three at the C level doing a little bit of C introduction. So we put that into this class because our students in the predecessor classes had trouble picking up programming in the space of two thirds of a semester. Now, when we first taught this class, because there's going to be just a little bit on every homework to try to keep you absorbing the C syntax so that you can learn programming more slowly. Some people might be tempted to say, I'm not having fun with that part. Let me just ignore it. That will be at your expense. The expense will not be a few points. It means you will have to learn to program more quickly later. So please do the little parts of the homework that are go into the lab and play around with C, write a couple lines of C, that was deliberate so that you can absorb that more slowly and be in kind of more level playing field with people in the room who have been programming for a while. So we'll do that briefly in week three. Future classes like CS374 for the Compies and we'll teach you algorithms. I think it's worthwhile for everyone to take that, but as an EE, you have to choose among many options for Compie required to take 374 the algorithms class. So that's kind of where things fit in with this diagram. Now, we've been working on trying to figure out how to get human tasks into digital systems more effectively for somewhere between 50 and 200 years. So in a few years it's your turn. So we'll be with that. But before we start the next section, I got to say, I'm disappointed with Illinois students. Because MIT students, what was it, 1967, did it put her on there? I think it was 1967. They came up with this idea of the big screw award. So where, who gets the big screw award? It's whoever screws over the students the best during one year. Right? I'm a little disappointed. So one student, one professor there actually taught the class in French in order to win the big screw award. But this is Illinois. So here people might actually speak French. Not like MIT, no one there. So I don't want to waste my effort. So instead, I'm going to use this code. Anyone here know this code? Perfect. Perfect. All right. So the rest of my lectures will be in this code. I hope you're ready. So what's a representation? Often we need to represent one kind of information with another. Inside a computer, you'll see we don't have many ways to represent things. But we'll get to that in a few minutes. But we need to represent one kind of information with another kind. So maybe physical quantities, patterns, like the drawings I just showed you and so forth. So English letters represented by some drawing. Or that's what you just saw. Colors represented by variations in radio amplitude. Some people call that television. The mapping from one form to another, we call a representation. And I think my day here is done. I'm going to watch a video while you do that. OK? All right. I'll give you a little hint. Give up. No, that's not give up. Bingo on word one. Oh, I hear someone clapping. Good job. All right. All right. So representation. When I was a kid, we used to send secret notes in this code. So I'm a little surprised. Surely you had some code to use to keep the teachers from knowing what you were writing to your friends. You don't want to just pass it in normal writing, because then they can read it. You get in trouble. All right. So wherever representation, what makes it a useful representation? Was it useful when I just showed you the code? I mean, it seems no one got it before I showed you the how I mapped letters into patterns. So for it to be useful, especially for computer, computers are not smart. For it to be useful, we need to agree on this mapping, the translation, before we try to use it. So our purpose here with representations, particularly in this class, is not obfuscation. So we're not trying to hide things. What we're trying to do is communicate, but we need to express the form of information that we want to use into some other form in order to do that communication. So we need to have this translation in advance, and it needs to be well-defined. So that's one property. So what about this one? Here's another representation. So I take the English letters, and I represent them with digits. So the letter P, I think I have a laser on this. Not a very good one. The letter P, I represent with the number five. So what does 143 mean? OK, so I heard bed. Let's see. Yeah, I got that one. What else? I hear box. So really LEDs up there? Oh, I should have picked that one. Don't it. Good call. Why does it have to be some acronym you recognize? Couldn't it be VIN? What's wrong with VIN? So computers are dumb. They can't guess. So it has to be well-defined, unambiguous. When we use representations with computers, every given pattern, whatever that pattern is, can only represent one thing. So over here on the left, you see I've got green represented by four, blue represented by one. That's good. On the right, I've got a representation where green and blue are both represented by four. That's not so good. And in that case, a computer or digital system is not going to know when you put four, did you mean green or blue? Just like in the previous slide, when we put 143, did we mean bed, box, LED, VIN? What did we mean? Computers are not going to be able to just guess like we could. Now, some patterns may not represent anything. We'll use this in the end of the semester, but I just want to make sure you understand what the rules are for representations. So for example, here I have a representation where each of these five colors has its own digit, but there are five other digits we could use if what we're using are digits to represent the colors. And those digits just don't mean anything. That's OK. That's a valid representation. So those are the two things we need with our representations. We need them to be well-defined and unambiguous. Inside digital systems, inside computers, computers are based on electrons. The only thing we have to represent anything, whether you want to represent ice cream flavors, or you want to represent makes and models of cars, or student ID number, whatever, the only thing we have, electrons. That's it. So what can we ask about electrons? Well, we can say, OK, at this point here, how many electrons are there? It's closely related to voltage. I think people have probably in maybe high school physics seen voltage with electrons and things like that. So we can look at a particular place, and we can ask, what's the voltage there? So we'll pick some ground, and that'll be zero volts by definition. We'll pick some higher voltage. We'll call it VDD. I'll push the wrong button. Sorry. So at a physical location, we can say, what's the voltage? And if the answer is, well, it's close to VDD, we'll call that a one. And if the answer is, well, it's close to ground, zero volts, we'll call that a zero. So that location, that's gives us a binary digit, either a zero or one, which we call a bit. Now, each bit is in some particular place. So it's pretty easy, pretty natural, then, to use what we do as humans with our number system, to use positional value or place value. So in decimal, we have the ones place, we have the tens place, we have the hundreds place, thousands place, so forth, and so on. In binary, we've got the ones place, the two's place, four's place, eight's place, 16's place, powers of two. Those are powers of 10 for decimal. These are powers of two. So keep in mind, as we go forward, the only thing we have inside computers, inside digital systems is bits. That's it. There's nothing else we're using to represent information. So as humans, we talk about abstractions. We talk about using hexadecimal or something like basic 16. That's not what's in the computer. Only thing in the computer bits, zero's and ones. Blanks, no multiplication signs, nothing else. No colors. All computer representations are based on bits. OK, so now some questions for you. So if I have numbers in the range zero to 31, integers, I'll tell you that. So otherwise you'll tell me infinite. So if I have the numbers zero through 31 whole numbers, how many bits do I need to represent one of those numbers? Five I'm hearing. So why is that? So we have 32 different integers, right? Zero through 31 is 32 different integers. And remember, representation has to be unambiguous. So for each of those, I need at least one bit pattern. So that means I need 32 bit patterns. If I have five bits, that gives me two to the five different bit patterns. And 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, and so forth and so on. There are 32 of them. Those 32, I can uniquely assign to the 32 numbers, and that would give me a representation. So I need five bits. What about the number 0 to 100? Seven, right? So again, 101 different integers, in this case, seven bits gives me 128 patterns. 27 of those won't be used, but that's OK. OK, do not use patterns. It's not OK to assign one pattern to two numbers. So I have to round up. So seven bits for those. Good. All right, so here's a trick question for you. See him nice to you. I tell you when I'm going to ask you a trick question. So two books here. The collected works of eE Cummings, an acronymistic dorm mate, who you should read, because he's a good poet. And our textbook, Pat Patel, whoop, great books. You should read both of these. How many bits do I need to tell you which of those books you should read tonight? Good answer. Wow, you're good at these trick questions. I left my controller over there, and so excited. All right, so yes, that's all right. One bit, right? Two books, one bit. What matters is not what those things are. What matters is how many things we want to represent. In this case, there are two, so we need one bit. That's it. So whenever you're thinking about how I'm going to represent the set of things, all you need to do is count. Count how many there are. That'll tell you how many bits you need. So let's go through and do a few more examples. So let's see. Number from 1,000 to 1,000. Seven, right? Same as before. It doesn't matter what the numbers are. There are 101 of them, so seven bits. Good. 199 flavors of ice cream. Sorry, I clicked ahead. But I think sounds like people are getting the answer. So what about the next one, living person? Zero. So what is, OK, I guess it depends on you interpret that. I guess the way I thought of it is someone living means a person living on Earth. I don't think there are too many, well, there aren't people we know of off of Earth. So at least I don't know anyone off of Earth. So how many living people are there, roughly? Seven billion, right? So we got to round up a little bit. So 7, 8 billion people, so 33 bits. 33 bits is just over 8 billion. OK, what about the last answer? If I don't tell you the number, I just call it n. OK, I'm here in good answer. So log base 2 of n rounded up. So this ceiling notation means the integer that's at least as big as what's inside, OK? Good answers. OK, so let's go on and talk about what we can use to represent integers. So we've been thinking about different numbers will need. But what if we want to make a representation, how should we go about doing it? So we can represent anything with bits. So using zeros and ones, we can represent anything. Interpreting integers, real numbers, human language characters. I want to make sure before we go forward to emphasize, and I think you'll get tired of hearing me do this by the end of the semester. But computers do not understand the bits. From a computer point of view, there are some zeros and ones. So when there are some zeros and ones, what do they mean? Well, it depends how we interpret them as people. So you can tell the computer interpret this as an unsigned number, or as a signed integer, or as a real number, or as a color, or an ice cream flavor. But unless you do that, or someone else, another programmer, or a hardware designer, someone does that and says, these bits mean this kind of thing and build that into the system, the computer will have no idea. So if you tell your computer, here's a representation from ice cream flavor to bits. And then you tell the computer, please add mango to strawberry. It will simply add the bits, and you'll get something structure. So it'll just do what you tell it. It's not smart. So what number should we represent? If we want to represent whole numbers greater than greater equal to 0, what should we represent? How about we can go around the room, we got 150 people some odd. Each one can pick our favorite number. My favorite number is 42. You know why, I hope. Because I can ask you, what is 6 times 7? And I can ask you, what is 33 plus 5? I'm hearing some 42s, but I'm hearing some wrong answers. So what you need to know is you can need to tell the professor what they want to hear, which is 42. Because 33 plus 5 and base 6 is 42. All right. So can you give us a set of integers maybe, instead of just picking our favorite numbers, might be better, maybe we should start with 0. So let's think about what are we trying to do with this stuff. Maybe we want our computer to do arithmetic. A lot of people use computers to do arithmetic. So what does that mean? Let's say we just pick a range. Let's say, OK, I'm going to represent the numbers 100 to 131 with 5 bits. Well, someone picked a number from that. Just show me that. OK, 42 is not in there. Good choice, though. I like that. I like that. 120. OK, good choices. So if I add 120, we get 220. It's not there. So if we add two numbers, it's never there. So maybe we should pick our numbers in such a way that at least sometimes when we add them or when we multiply them, the result we get, products, some, whatever, is also in the range so that we can represent it. Because if I add two numbers from here, I can never represent the sum. If I multiply two numbers from this range, I can never represent the sum. It's not so useful for arithmetic. So maybe we'll pick a contiguous range, including zero. So at that point, I want to say in general, when we have human representations for the same thing, usually those are a pretty good starting point. So as humans, when we want to write down a number, well, we use decimal, but probably in high school, you might have seen base two. So there's base two from mathematics. We could use that as a starting point. Remember in base two, we just write ones and zeros. So here are some examples. 17 in base two is 1,0001. 42 in base two is 1,01010. And 1,000 is those numbers there. In human representations, we use these subscripts to tell you which base we're in. So when I said 33 plus 5, I really should have said 336 plus 5,6 equals 42,6. But here are three different numbers. Is this OK? Can we use this in a digital system? Why not? They don't have the same number of bits. So in particular, we've got this blank space here, right? There's no blank bit. Zero or one. That's it. There's no blank. You can't say, well, this is a small number. So I'll have some blanks. There's no such thing. Zero or one. So that's not such a tough problem. We'll put the leading zeros. So we'll put leading zeros on our numbers. That'll fix the number of bits to some n. And we'll get what's called the n-bit unsigned representation. So if I take my previous examples, and I write them as 8-bit unsigned, what I get is what you see here. So if I take 17, then instead of just the 1,0001, I get three leading zeros, and I get 0,0001, 0,0001. 42, I just need two leading zeros. How can I represent 1,000 in 8-bit unsigned? I can't. I needed more bits. So I can't do it. 8-bit unsigned does not represent 1,000. So then you can ask yourself, OK, well, if I have say 8-bit or 10-bit or whatever, what values can I represent? So if I want to use this unsigned representation, what's the range of numbers that I can represent? The smallest number, of course, is going to be all 0. So that'll be 0. We kind of chose that already. What about the biggest number? Yeah, so I'm hearing some 2 to the n minus 1s. It helps me to remember that if I put 1 followed by n-0s, well, that's 2 to the n by place value. And then if I subtract 1 from that, that's n bits. This is actually n plus 1 bits here, 1, 1 digit, and then n 0 digits. And so then I have n bits left, all of them 1s. That's the biggest value. So as people said, 0 up to 2 to the n minus 1. So that's the range of an n-bit unsigned representation. This is one of the common representations in almost every computer you want. So this is a real computer representation. So let's think about, as humans, sometimes we'll need to go back and forth from decimal into unsigned. So just think for a minute about how we do that. And I want to actually show you the tool if you want to practice. So you can calculate a decimal number from a bit pattern using this idea of a polynomial. So your decimal number, I'm sorry, your bit pattern will be some set of bits here of drawn 6. So you can think of those as coefficients on a polynomial. Remember, they have place values. So the rightmost, which I called a 0, that has place value 1. A1 has place value 2. A2 has place value 4. These are powers of 2. So you can write it out this way. You can write it out with the powers of 2 written out, a5 times 32, a4 times 16, and so forth. Or you can just remember they're the powers of 2. So that's how you can translate from bit pattern into decimal. So let me go over here and remind you, oh, I thought I left my Google open, but I didn't. OK. Remind you how to get to this page. Sorry. I turned off my Wi-Fi. That was foolish, because I knew I wanted to do this. All right, so we'll come back to that. Well, it brings my Wi-Fi up. Hopefully it won't, will not make me log in. OK. So what about going the other way? I'll show you the tool in a second. Sorry about that. I turned off my Wi-Fi not thinking. What about going the other way? So if I give you a decimal number, can you tell me the bit pattern? So if I say, hey, I want the 8-bit unsigned bit pattern for the number 193. That seemed harder than going the other way. And the other way, you need to look at the powers of 2, add them off. All right. So it turns out it's actually not that hard. There's a pretty systematic way to do it. So remember that every bit pattern represents a different number. So the bits we use, the a sub i, as I called them, those are unique. So if you write that down, you say, OK, well, my decimal value is equal to this polynomial. All of those terms on the right side are even, because the powers of 2, all the way down to 2 to the 1, those are even numbers. So if I multiply whatever the coefficient is times those powers of 2, I get even numbers. The only odd number is maybe this one. If a 0 is 1, this one is odd. It's 1. So if d is odd, then a 0 is 1. If d is even, then a 0 is 0. So I can just look at d and say, well, is it even or odd? And if it's even again, a 0 is 0. If it's odd, a 0 is 1. So then I can subtract a 0 from both sides, divide it by 2, and use the same reasoning until we run out of digits. So let's do that just for a quick example. So if I start with 37, for example, that's odd. So a 0 is 1. Subtract out the 1, divide by 2. On this side, subtract out the 1. You can see the a 0 has gone away, divide by 2. What's left is this new polynomial. And on the left side, 18, you can see, again, we have 2 to the 0 now attached to the a 1 term. So all you need to say is, well, is 18 even or odd. It's even. So a 1, 0, do the same thing. Subtract 0 divided by 2. I'll get 9. Subtract the polynomial. I'll get the new polynomial. Now the 2 to the 0 terms on a 2. So that's where I was. 9 is on. So a 2 is 1. I can roll forward on this. Do all the math. And if I put them back in order, that's what I get. Of course, depending on what size, how many bits you want in your unsigned representation, you may have to add some leading zeros. But your bits will come out from low to high in this process. And you don't really need to write down the polynomial. That's just for make sure you understand why it works. So for example, if I ask you, well, what about 137? How can I get the unsigned pattern for 137? Well, that's odd. So gives me a 1. Subtract 1 divided by 2, I get 68, gives me 0. It's even. Subtract 0 divided by 2, 34. blah, blah, blah, blah. Go on, go on, go on. OK. It took me longer to write the slide than it. So don't worry if the. So now which direction should I read those? Well, remember, we get the small bit first. So I want to read from the bottom to the top. So those are my bits. So if you want to know what's the unsigned bit pattern for 137, it's 1,000, 1,000, 1,0001. So not as hard as one might have originally thought. And the systematic way to do it. Let me see if my Wi-Fi came up because I do want to show you this tool. So if you feel like you want to spend time making sure you understood that, then there we go. OK. So remember, write my name into Google. That'll give you my homepage. And then go to the, oh, this one doesn't, there we go. Go to the F16 link there for fall 16. And that will give you this page. Now, what I want to show you is down here, we have these JavaScript exercises. So the first one is representations and logic. So if you click on that, you can do this on your mobile too. You will have a little tool that will let you do translations and will give you check answers for you. So here, for example, we have the number 70. And we're supposed to convert that to the unsigned representation on 8 bits. You can see up there, you can go up to 16 bits if you'd like to. You'll want to use maybe a piece of paper for that. But if you want different examples, you can click this new example. It'll give you as many examples you'd like to play with. So it'll just keep changing the number. Well, let's get a nice number. So how about 113? That sounds good. So then we can go over to go over to here. So is that even a rod? Odd, good. OK. And then I take 113 minus 1 divided by 2 as I give me 56. OK. So that gives me 0, right? And then 56 minus 0 divided by 2, 28. And then 28 minus 0 divided by 2, 14 divided by 2, 7. So that's odd. 7 minus 1 is 6 divided by 2. It's 3. That's odd. 3 minus 1 is 2 divided by 2, 1. That's odd. And then we get 0. So we're done. So it looks like 111, 0, 0, 0, 1. And then I'll have to put the leading zeros. So let's see. So go here. I think that was it, right? OK. So let me make something wrong just so I can show you this. So if you push Enter, if you go push this check answer button, it will highlight the bits you got right and put the bits you got wrong in this darker color to tell you you got that one wrong. So give you feedback instantly on your answer, and then you can go and correct it. And it will tell you they're all right. And if you push Enter again, it'll give you a new problem. So feel free to play with those tools. There's actually quite a few choices in terms of different representations, different exercises, but that will help you hopefully make sure that you know how these things work. So let's move forward. OK. So that's the unsigned representation. So what about negative numbers? As humans, we write minus sign, right? So if I want to say minus 24, I'll put a minus sign. And I can do that in base two, just as well as I can in base 10. I can put a minus sign. But there's no minus in a bit, 0 or 1. You might think, well, that's OK. I can say, there's actually implicitly, if I write 24, there's implicitly a plus, right? So how many choices of sign do I have? Two, right? I could have minus, I could have plus. I could use a bit for that, right? So we just say, OK, 0 means plus, 1 means minus. I'll have a special sign bit. That's called the end bit sign magnitude representation. And then I'll give me numbers from this blue part will give me a remember 2 to the n minus 1. I'm sorry, yeah, 2 to the n minus 1 minus 1. And then the sign will let me make that negative or positive. So my whole range is from negative 2 to the n minus 1 up to 2 to the n minus 1. So that sign magnitude. But that actually was used in some computers a long time ago, like the IBM 754. Wait a minute. If that's the range, and I calculate, well, how many numbers are there? There's only 2 to the n minus 1. What happened to our other bit pattern? Yeah. So this is a bit pattern as opposed to the bit, right? So we got one left over bit pattern somehow. Yeah. Positive and negative 0, good answer. There are 2 bit patterns for 0. That's OK, right? Remember, we said it's OK as long as every bit pattern means something unique. It doesn't matter that you have multiple bit patterns for the same number. Again, there were computers built using sign magnitude representation. They work just fine. It does make the hardware a little more complicated, which is why today none of the computers use sign magnitude in practice. But people use this for a while. Because it's a natural human representation that you can easily turn into bits. So then that begs the question of, well, so how do you know you make up a representation? Is it a good one or not? Now, this is a little unfair because some of these questions, this question you can't really answer. So I'll give you the answers. In particular, the second one, how do you know what's easy and fast hardware implementation when this class is supposed to teach you how to design hardware? So that's not a fair question. So I'll just give you the answers this time. What is efficiency? So unary where we make these hash marks, that's not efficient. Because if I want to represent the number of million, I have to make a million hash marks. And you know, if you go take log base two of a million, you don't need a million bits to store a million. You need far fewer, about 20. So you don't want your representations to be inefficient. You want them to store numbers effectively and basically use all of the patterns, or at least most of the patterns, most of the bit patterns. You do want them to be easy and fast implementation. So we'll come back to that later. One thing that I think is fair is, well, what if I told you I can come up with a representation for sign numbers where I can use the same hardware as I do for the unsigned representation? So I get it for free. Clearly, that's better than another representation where I don't get it for free, where I have to have another piece of hardware to do additions of signed integers that would be separate from my unsigned integer adder. So here's an unsigned adder. So imagine we built something. It adds two bit patterns of an unsigned representation. So if I feed in the number 2, 0, 1, 0, and I feed in the number 3, 0, 1, 1, then outcomes, 1, 0, 1. How it works for now doesn't really matter. I build this thing and I ask, well, can I actually use the same thing to add signed numbers if I pick the right representation? The answer is yes. So how can we pick the right representation? So first, let's think about addition. What does it mean to do addition on unsigned bit patterns? Well, since we drew the unsigned representation from the base two representation for humans and math, we can use the same sort of arithmetic. So if I asked you OK, write down some base two numbers and add them up, you'd line them up just like you do in decimal and then you add them. So you can start, though, with a single digit addition. So if I say, OK, what's 0 plus 0? 0, good. 0 plus 1. 1, good. 1 plus 0. 1, good. 1 plus 1. 10. There are 10 kinds of people in the world. Those who understand binary, those who don't. OK, that was a bad joke, but it's an ECE joke. You have to laugh. All right. So yeah, so this is the whole table. I mean, you remember in elementary school, you had to memorize that big 10 by 10 table. It's a lot easier in binary. You don't have to memorize a big table. You just have to memorize four things. And probably you can read-arrive them. So it's pretty small. And then from there, well, you do need to know what's 1 plus 1 plus 1. We'll see why in a little while, which is 1, 1. All right. So here's what we do. We line up our numbers, and we just add them up column by column with carries. So here's two numbers. The top one is 14, and the bottom one is 4. So we start on the right. We say 0 plus 0 is 0. You told me, right? 1 plus 0. 1 plus 1. 0 carry the 1. So put the 1 on top. 1 plus 1 plus 0. 0 carry the 1. Good. And 1 plus 0 plus 0. 1. So we add those up. We get this number at the bottom. That represents 18. And lo and behold, we got the right answer. So we're happy. Everyone happy? Yeah. The only thing that's that bad is how that was going to be. Ah, good point. So we only got this answer because we chose our representation in a way that we can use this arithmetic process to do arithmetic. And that's absolutely right. So because we decided to use the human representation to design our unsigned representation, we're allowed to use the human arithmetic process to add unsigned numbers. So we'll build hardware that simulates this human arithmetic, and that will add unsigned numbers for us. But that's a good point. If we had chosen some other representation, we would have to design a more complex piece of hardware, likely. Good point. All right. Now there's a problem, though. Even if we follow the human rules, the unsigned representation, we have to pick N bits. We have to say what N is. It doesn't just grow. So sometimes we'll add two numbers, and we can't represent the sum. So what is that condition? So I claim that that only happens when the most significant bits generate a carry. So if a carry comes out of the left side of our addition, then we'll have an overflow, and we can't represent the answer. If a carry doesn't come out as it didn't in the previous example, then we get the right answer. Then we represent our answer with the bits. So let me show you an example. So let's do this example. So on top now we have 14. On the bottom we have 21. So if you remember, five bit unsigned, we can represent up to 31. You add those two numbers together. It's bigger than 31. You should expect this not to work, because we're going to have to try to represent 35. So let's take a look. So 0 plus 1 on the right is 1. 1 plus 0. 1. 1 plus 1. 0 carry the 1. 1 plus 1 plus 0. 0 carry the 1. 0 carry the 1. 1 plus 0 plus 1. 0 carry the 1. Yeah, so we have no place to put that one. So we have overflow, exactly. Exactly. We don't have any place to put that bit. If we want to use five bits to represent our numbers, we're out of luck. We cannot represent the sum. So instead, we get three. So remember for your exams, 14 plus 21 is three. I don't think it'll help you if you should remember. So the carry out tells us that we have an overflow. What we added together, we can't represent with those five bits, with that five bit unsigned representation. We have a way to decide by looking at the carry out is the answer right, or is it wrong? So it turns out that unsigned arithmetic corresponds to something we call modular arithmetic in math, or unsigned addition. So it's related to the idea of remainders and division. And it's defined mathematically, as I've shown here. So if I take three numbers, a, b, and m integers, a and b are said to be equal mod m, if and only if a equals b plus some k, another integer, times m. So k can be negative or zero. So two numbers are certainly equal if they're the same number. But a and b will be, it's a symmetric relationship, because the two k's would be negative of one another. We can also write a equals b mod m. That's how we say that this relationship holds. So that's the definition of modulus. It's like remainder. So you can think of it as if they have the same remainder when you divide, if a and b have the same remainder when you divide them by m, then they're equal mod m. You can think of it that way. I should have written that down. It's an easy way to remember it. So let's think about what we get when we add two unsigned bit patterns. So if we add two unsigned bit patterns, if there's no overflow, then this thing we get will call it sum. So if there's no overflow, then the sum is just equal a plus b. So without overflow, we get the right answer. On the other hand, if we get an overflow, the problem is that there's that carry out. That carry out is, it should have gone in the two to the end place. But we threw it away. So it went from one to zero. So if we take what we get to sum and we subtract off or what we should have gotten, a plus b, we subtract off two to the end, then we get what we actually got for the sum. So if you think back to our example, was it 14 plus 21, should get 35, subtract off two to the end, two to the fifth is 32, 35 minus 32 is 3. And that's what we got. So in both cases, you'll notice that whether we overflow or not, the sum is equal to a plus b mod two to the end. And in the upper case, the multiplier is zero. They're actually equal. And in the lower case, the modifier is minus one. The minus one times two to the end added to b gives us, I'm sorry, added to a plus b gives us the sum. So they're equal. So whatever we use to produce our answer is going to give us the right answer mod two to the end. So we can use that idea to produce a signed representation, a representation for signed integers, so including negative numbers, that uses modular arithmetic. If we do that, we can use the same hardware to add unsigned numbers and to add signed numbers. That representation is going to be called two's complement. So what's wrong button? Oh, really? Did I finish it all? OK. Well, let me open another one then. I didn't think I'd get this far. I don't know if that's the right one. There's one. OK. Push this one. Think. OK, so here's our strategy. So we want to use modular arithmetic to define a representation. We're not going to be able to finish this one today. But we'll think about it a little bit. So we're going to use modular arithmetic to define a representation for signed integers. OK. And by doing so, we know that we'll be able to use the same piece of hardware to do addition on unsigned as well as signed integers. The computer's not going to know which one. It's just going to blindly put bits together and add them. But because the answer will be correct mod two to the end, the answer will be correct regardless of which way we interpret those bits. So what about the name later? So here's an illustration of three bit unsigned. So on the outside are the decimal numbers and the inside of the bit patterns. And I claim that adding a number corresponds to going clockwise around the circle. So for example, if I start with four and I want to add three, then four plus three is seven. And the answer is always correct mod eight. So if I say, well, what's six plus three? Well, six, seven, zero, one. So six plus three is one, which is equal to nine mod eight. So it's always correct mod eight for three bit unsigned. So that's one way to think about it is the circle. You can also realize that this is a quality mod eight. So if I do addition, I go clockwise. If I do subtraction, I go counterclockwise. And we can also, I'm sorry, we can, we can extend our numbers. So what I've done is I've added labels. Let me go through that again. Sorry. We can extend our numbers in a clockwise direction. So in addition to zero, we can write eight. We can write nine, ten, eleven. All of those, all of those groups are equal mod eight. Right? We can also go in the negative direction. So by seven, we can write minus one by six. We can write minus two and so forth. So we can add labels. So all the groups, each group is all numbers that are equal mod eight. Overflow happens because when we pick a representation, we have to pick one of these labels for each bit pattern. Remember, we can't have ambiguous, ambiguous representation. So any representation we define, we can only pick one meaning. We've got to pick one of these outside numbers. For unsigned, we pick zero, one, two, three, all the way up to seven. But we don't have to pick those. So we can't have to pick one of these out, we want. And we'll get something that works mod eight for addition and subtraction. So what if we pick a different set of labels, the arithmetic doesn't change. So let's pick positive and negative and try some addition. So here's a set of positive and negative numbers. If I take minus two and I add three, you get one. So before when I, when I picked six and I added three, I get overflow. But if instead I pick negative three up to three, I add three to negative two and get the right answer. If I could pick differently. And that's what gives us a two's complement. So if I choose my labels that way, by picking an equal number of negative numbers, positive numbers, and the zero, as the labels for my representation, then I get two's complement. Now again, because fundamentally the arithmetic we do on that circle is, is correct mod two to the end. Sorry, I'll stop in a second. Because it's correct mod two to the end, that means I can add numbers in two's complement, add numbers as, in unsigned. And I'll get the correct answer using the same piece of hardware. So stop there. I will go over it again on Friday. Thanks. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah."
    },
    {
        "ECE120-2016-10-28-LEC-27-slides.mp4": " three-year stuff and a little bit of philosophical Prattle to start off one clarification too, that's worthwhile for the moreous lecture. Then we'll dive into the binomial model and then look at LC3 as a binomial machine. And then I think we will manage to get through most if not all of this instruction format stuff. After that, and Monday we'll start talking about instruction processing. Suppose there's some small chance we may get to that today. So before we do the clarification, do this. So if you're feeling now, if you haven't gotten your midterm back, my TA, if I hadn't had this TA, I'd have gotten half the score, then nominate them. Even if you don't show that way, nominate them. Because you should be proud to be in 120. And otherwise the 210 TA's will land or the 2, 3, 10 or some people like that. And they just don't deserve it. Our TA should win. I mean, they're good, but they're not as good as ours. So seriously, unless you feel strongly and you don't want to do it, at least think about it, because we have some good TA's and it's nice for them to get the award. The award is something like a couple thousand dollars. Sometimes I don't know if they split it if they give it to two people. They have given it to two people sometimes or if they give them each 2000. But it's a pretty nice chunk of money for TA and more importantly, nice recognition for a job well done. So please do consider nominating them. I won't actually start teaching in Tiktok, even if you don't, but I may track whether you nominate them. Thank you. All right, so I want to make one, oh shoot, sorry, I love this animation. I want to make one clarification about this stuff. So I realized after talking a couple of people after class, that these RTL, these remember our FSM outputs, but they go to the data path. So the data path is basically all clocked logic, it's a components. So these actions happen at the rising edge of the clock. So the actions take effect in the next clock cycle. So there's a little bit of difference from how we wrote the state tables before, because they would have external outputs listed in the against each state. Whereas these actions are actually not external outputs, but outputs from the FSM to the data path. And so they take effect not in the current cycle. They're not outputs that are visible externally, but they're actually outputs that control the action of the data path. And so they take effect in the next clock cycle. So I know there's a little bit of confusion about that, for example, how when we get into the compare state, how count is equal to zero, well that's because we set it to zero here. And then in the next cycle, when we're in the compare state, then count starts to zero, and then starts counting up. So sorry about that confusion. Just wanted to make sure it was clear for everyone before we move forward. Because we'll use the same kind of notation in the LC3 finite state machine. And we'll have the same meaning that in a particular state, when you say the RTL for that state is such and such, that RTL will not actually happen effectively until the rising clock edge, at which point you're in the next state. So just bear that in mind in terms of the meaning and the timing. OK, and someone I think with my home will ask me, so why would I want to give you a hard problem to do? So I wanted to answer that. So this is just philosophy. So you seem surprised that I'd want to give you a hard problem, not really an exam and an exam is a time that I don't care if you can do it fast. So here's another problem. So write an assembler in C for the LC3. So take assembly code, which you haven't really seen much of. So I wanted to come up with some problems that maybe you can think about how hard they'd be. So write an assembler. You're seeing it in the lab now, if you've played with the lab. And that assembler can take LC3 assembly code and actually do the encoder. So after a few weeks of assembly and a few weeks of C, you think you do that? Here's another one, a couple more. So how about a simulator? How many of you played with LC3? Sim in the lab? OK, so a few of you. So you write that simulator. Same few weeks of C, so you have some assembly. Same good? Yeah, OK, good. I hope you think you can do this. I can say I'm not sure if you think you can do this. You might think it's hard. So what about LC3 code generation? So the back end of a compiler. You can do that, right? OK, so here's some quotes for you. So here's someone with Pete Sauer. So apparently, we faculty didn't realize that in order to win awards, we had to be nominated. So that was actually quite helpful. So they created this faculty awards committee. Turn out to be true. So turns out also that if you don't try something, you can't do it. So it's probably not me. I'm sure there's someone more famous. Here's another quote. So this is my former colleague, Nesha's at MIT, but we used to work together. We started together. So what does she mean by that? So I would contend these things. I agree with her for the most part. So if you've never tried something that you couldn't succeed at, that your teacher or professor, whoever, gave you the problem, you didn't know, OK, this is completely doable. I'll be able to do this in a certain amount of time. So I'm my homework. So of course, I'm going to be able to finish it by the end of the week. How are you going to know what you can do? If you never try something that you're not sure if you can do it, not even sure if it's possible, no one else has done it before. So these things that I mentioned, those are about 1,000 lines of C code. This one, code generation, it's only a few hundred lines of C code. But it uses recursion. So usually, that's more complicated. So we'd put that after these. But those are real assignments. So in the old programming class, which is one semester, we give them a few weeks of assembly, a few weeks of C, then they'd have to do those things. So and most of it instead of them did well. I'm pretty happy. So. And they seem really hard at first. And people would be scared of them. And then they do them. And they think, wow, that's really cool. I can go build those tools I used at the beginning of the class to play with the LC3. So it's a sense of accomplishment. So all of you, as I told you at the start of the semester, you're all smart. You can all do incredible things in the world. So I suggest you try to solve hard problems. And sometimes you'll fail. So what? Sometimes you'll succeed. Sometimes you'll find out, oh, those aren't so hard after all. But you're always smart. So that's why I want to give you that kind of problem. Because it's really not that hard. I thought of a couple of them. I might write one out to men if you want to challenge yourself you can. Actually, I'll just tell you. And then you can conceptualize it on your own. And you can make whatever assumptions you want. There was one I was going to do in the LC3 data path, but you'd actually have to read ahead and write some other stuff on your own first. But try to do like a microwave controller. Just 10 buttons, let's say, set some time, push go, run the microwave for a few minutes, whatever it says. Count it down, show the display. Anyway, that's an idea. All right, so that was my philosophical problem. So let's talk about the von Neumann model. Hopefully you remember this diagram. So this is the seven layers, abstraction layers from Patel Chapter 1. And so far, we've gone up to a few of these. I'll put an error on this in a second. But remember, up here is human language. And then we have software in green and hardware in blue. And so so far, we've kind of worked up to how a computer works. We spent a week number three talking about the C programming language. But basically, now you're ready to see how does a computer actually work. So to remind you, the micro architecture, this is the implementation. This is the thing that executes instructions from an ISA. So that's sort of the implementation of the computer. And that's going to look a lot like that finite state machine we designed. So they'll have a data path. It'll have a control unit, which is a finite state machine. And it'll execute instructions. So to look exactly like the thing we did on Monday and Wednesday, the core is an FSM. And then we're going to cover it kind of briefly. We'll go over it today and maybe on Monday, a little bit more. And then we'll dive into the instructions. And then we'll talk about actually programming. At the start of the semester, when we talked about C, that was just so you could start using C, get familiar with the syntax. But not really how to program. Programming is breaking things down to the level that a computer can execute. And which is pretty low level, pretty simple things. So we'll start thinking about that in the next few weeks. Then above that is the ISA, the machine or instruction set architecture. So that's the interface between the green, the software, and the hardware and blue. Examples are things like X86, ARM, PowerPC. And we're going to follow Pat and Patel and develop this LC3ISA. I'll tell you what that means in a few minutes. So in 1946, John Van Neumann invented this model for computer organization. So he said, well, here's how maybe we should building our computing platforms, long before people had computers and their pockets and their desks and everything. So he said, well, it should have five parts. So one part is memory. So there's a memory. What's that memory look like? It's the same that you saw last week. So it's able to read or write every cycle, maybe take several cycles, but it's able to read or write. The computer's instructions on the program, the computer's going to run. We're going to put it into that memory. And so that's part of the model. You could put it in a different memory. There were other models that had the program somewhere else, for example. But in the Van Neumann model, the program and the data and everything will go in this one memory. So the memory is going to use two registers. So remember, we've got address and we've got data. So we're going to use some registers to manage moving data in and out of the memory. And so we're going to have an address memory address register associated with the memory. And that's just going to hold the address that we want the memory to read from or to write to. And so there's what we call M-A-R, memory address register. And there's also what we call the M-D-R memory data register. So when we want to do a write to memory, we'll put some bits in the M-D-R, and then we'll put the address in the M-A-R, and we'll say go. And the memory will store the bits from the M-D-R at M-A-R. And when we want to read, we will set the M-A-R to the address and say go. And the memory will put the bits from that memory location in M-D-R, and then we'll take them out of the register and do what we want with them. So that's how our memory will work in combination with these two registers, just to help things move around in the data path. We're also going to have a processing unit. So the processing unit's going to do all the operations, and it's going to define what we call the word size. So you've probably heard mostly probably about operating systems these days, but the underlying hardware also has a word size. So your processor might be a 64-bit processor, a 32-bit processor. Usually your laptop, your desktop, or probably 64-bit processors, your phone is probably a 32-bit processor. The processor in your watch might be 8 or 16 bits, in terms of the word size. So what does that mean? Well, if it hasn't added, if it has a multiplier, those are usually 8 or 16 or 32 bits, it depends on the word size. I'll show you some other pieces that will also usually depend on the word size. So typical word size is a 32 and 64 bits, but you can go out and get small microcontroller chips that have still 8 and 16-bit word sizes. So inside the processing unit, we're going to again have two things. One will be what we call the arithmetic logic unit, for the ALU, and that'll do the work. It'll handle the operations like addition. We have multiplication. We'll have that too. It depends what operations we want the processor to be able to support. So we'll talk about that for LC three later. The processing unit also has a register file. So the register file is going to have actually flipplops or registers. So it's not SRAM. It's actually registers. And that's basically going to just give us a place to put values temporarily. It'll be faster than the memory, faster even than SRAM, but it'll be smaller. So faster but smaller. So let me give you some details. So as I mentioned, it's going to use flipplops. So they're actually on the same clock. So typically, you'll be able to read things out of the register file in one cycle. That's not usually going to be true from memory. Even SRAM, sometimes it's going to be slower than a cycle. So it's faster than SRAM, much faster than DRAM. But there's usually only 10 or 100 registers. Yeah. Not quite. Cash is usually SRAM. And a cash is also not usually visible architecturally, meaning that from the writing of the program point of view, you don't know whether there's a cash or not. It's purely for implementation performance purposes. And yeah, but let me give you an analogy. So you guys probably have your patent patelle sitting on your work desk in your apartment, or your dorm, or whatever, right? When you go back, you frequently need to do 120 work. You probably got your box too, or you did until this week. And it's right there next to you. That's kind of like the register file. You have very few things on your work desk, but those are the things you use a lot. You probably also maybe have a bookshelf. And so you got your old calculus book, or maybe your current calculus book. But some other things, some other things that you might want to look at once in a while, maybe even a dictionary. Well, I guess you do that online now. But you've got some things you don't use that often, but your desk or your desk is here, and your bookshelf is there. And then probably most of you, I still have this stuff too, back at your parents house, you probably have a room full of stuff, right? And that's where everything you've ever collected, you still have there, right? Takes a while to get there for most of us, right? But it's big, right? So that's kind of like the register file is your desk. The cash is sort of, it's not nameable, but it's sort of like your bookshelf, right? And you need things, things come off the shelf on your desk, you use them there. And then the memory is more like your parents house, right? Takes a while to get out there. Actually hundreds of cycles sometimes to get to D-R-N memory compared to a processor. So we have a memory hierarchy in most digital systems. And it's made up of the register file SRAM and D-R-N. So the details of SRAM you'll learn in how it's used in cash is you'll learn in 411 if you take 411. So all right, so there usually only tens or 100 registers again for speed reasons, right? If you build something with 1,000 or 1,000,000 registers, usually that means you can't complete things in a cycle, or rather the clock speed of getting something out of that with the big muxes is too big for what you want the clock time to be the cycle time. All right, so as you might expect, registers in the register file are named both bits, right? So there's a bunch of them, maybe eight, maybe 128, we name them with bits. All right. So data moves between the memory and the processing unit. We'll do stores to move data into memory, loads to get it out. So these black arcs, the data moving between the pieces of the fun-no-amon model. So computer also needs to be able to get input from the external world and also give output to the external world. So for example, keyboard, monitor, mouse, disk, printer, network, so forth. Someone asked me early in the class why I keep talking about the number 42. And there's in the same set of books, there's a story about people building a computer to answer what is the meaning of life. And so for the first generation, they built the computer and they ran it, and they ran it, and they ran it and took several million years, right? So the people who built it, they didn't get to know the answer. But the people, when the computer was ready to give the answer, they found out that the designers were got to include output. Start over, second generation. Yeah, so not with fun-no-amon, it was fun-no-amon, we're gonna have input in output. So those are two more of the pieces, some kind of input, some kind of output to make the computer useful. See if they'd only studied 120. I wouldn't have done that. Okay, so what's missing? Gonna have a control unit. Okay, so we're gonna have two registries in the control unit in addition to the finite state machine. We're gonna have a program counter. So the program counter is gonna say, well, where is the next instruction? It's a memory address, right? Where is it? So that way the control unit can go get that instruction and execute it, right? So when it gets the instruction, it's gonna put it in another register called the instruction register. So we're gonna have some representation for instructions. We'll go get the bits of the instruction out of memory at the address specified by the PC and we'll put it into the IR and then the finite state machine will look at the instruction and do whatever it says. And but the bits of the instruction will go in the IR. Probably. Yeah, but historically it's been named counter, but it isn't address, yes. So you can think of it as pointing to the next instruction. Yeah, so for those of you who don't have much experience in the software world, there's a notion of pointers and languages and it's one to one with addresses and memory. So a pointer is just an address. And so when you start, I mean, in 220 you'll make use of that, but it's important to understand that a memory address is a pointer and vice versa. So counter may be not the best name. Instruction register to, yeah, in fact, the Intel term for PC is IP instruction pointer. So if you play with x86, you'll see that. Okay, so control arcs going from control unit to everything, control units in charge of everything. So that's our von Neumann architecture. So here's just a summary slide. So we've got the five pieces processing unit, memory input, output, control unit. Yes. So yes, it does actually. I mean, there are signals on data path outputs that will come from the processing unit. I should have drawn them, but I didn't. Their data path outputs, they're not really control because the control unit decides what to do with them. So it's kind of data. So I should have drawn a data arc coming from the processing unit to the control unit. And also the control unit is fetching instructions from memory. So if you wanted to, you can think of it as data coming down here. Good question. Anything else? All right, so let's then go back through this and think about LC3ISA and we'll put numbers on each of the pieces and talk about a little more specific detail for the computer that we're gonna look at. So what is LC3? So little computer 3ISA was developed by Yale Pat and Sanjipatel basically as an educational tool. So the design is every aspect they thought about, well, how is this gonna help people learn? How are we gonna avoid putting them off in the wrong direction so that later they can learn more, but make it simple enough that they can do it in one year. The book's meant to be a one year sequence. So as Yale says, it took them three tries to get it right. So they tried three times in the third time it stuck. So this is LC3 as opposed to LC1 or two. So that's where the name comes from. In our class, so LC3 is an ISA. It's only instruction set architecture. The book also has a micro architecture. So you could build it any way you want. The ISA and the micro architecture are two separate abstraction layers. You can build an LC3 processor any way you want. There is an LC3 processor implementation in the book. So we're gonna look at that and build up towards that eventually in our class. There's some alternative strategies outlined in the notes, a little bit simpler maybe, but the one in the book is kind of the one we'll build towards. We can understand how that'll work. I put this slide in here just as review, but we just saw it. So let's start again with the memory. So in the LC3 memory is two to the 16 by 16 bits. So part of the ISA says, well, here's how big the memory is. So two of the 16 addresses, let's call that number X, X is 16, and 16 bit addressability. Meaning every memory location has 16 bits. So let's call that 16Y, both of them are 16. The reason I want to give them separate names is I want to ask you questions like this. So you want to remember the MAR stands for memory address register. So it's specifying if we want to do a load or a store to memory, it's telling us what's the address. So how many bits do I need X or Y for an address? So I have this many addresses. So how many bits do I need here? X. And I have this many bits added address. So if I want to tell you an address, I'm going to need 16 bits to tell you which of these. So that's what I called X. Add each address are 16 bits. So see, that's why I want to just separate them out because it's easy to get confused. The answer is you're going to be 16 all the time. Right? So on an exam, you just write it 16 or 42. But I'm sure it's the same in some days. Maybe not. All right, so here, though, what matters if I want to specify an address that I want to do a load or a store, I have to be able to tell you which address. And there are two, does this 16th of them. So the number I need is this X, right? This 16 here. I have to tell you which address. So I need log base two of two to the 16, which is 16 bits to specify an address. So same question for the MDR. So MDR, memory data register, when we read memory, the bits from memory come back from one location and then go into the MDR. Similarly, when we write memory, we put the bits into the MDR before we send those bits to one memory location. So how many bits for MDR? 16, go. X or Y. Y, right? Good. OK. All right. So I just want to make sure, because you can design an ISA that has a byte addressability. In fact, if you take 411, they'll do LC3B, which stands for byte addressable. And the memory there is 8-bit addressable instead of 16. And so then you have to think about, well, it actually still has the 16-bit loads. So you still need an MDR of 16 bits, but you could have an MDR of 8 bits instead, because the memory is 8-bit addressable. All right. So the ALU in the LC3 supports three operations. You can do AND, I'm sorry, add. You can do that's a two-s complement add by the way. You can do AND, and you can do not. All on 16-bit numbers. Can I do anything with these? OK. We've had a name for that, right? Logically completeness. OK. So you know the answer. You just forgot the name. So what about, oh, I don't want to show you that yet. What about OR? I thought what we proved was that. Should you be answered, don't it? OK. Well, hopefully you knew this answer, too, right? We proved the AND OR and not together, who are logically complete, right? We also talked about NAND by itself, the NOR by itself. So you can kind of get at that here. You say, well, I can build NAND. I do the AND, and then I invert it. But AND did not also, of course, are logically complete because of demarcant small. And if I want OR, I do A complement, the not, not B and those together complement it, that gives me A or B. So this was purposely chosen as a set of things from which you could build anything just to make the point of, well, you can build anything out of this. And some mean person, I don't know who's responsible for making the homework, but you can enjoy doing X or out of these things. And it's an upcoming homework. It wasn't me. OK, it was me. The register file has eight registers. So LC3's register files, eight registers. So what do you think we're going to call them? That's probably a good guess. Oh, no, sorry. Ron, sorry, holidays are coming. Just getting excited. Yeah, R0 through R7. The R's just for humans, the computer calls them 0 through 7. But what we'll refer to them as R0 through R7. You'll see in the instructions, it'll just be three bits, 0 through 7. Yeah, R0? Yeah, so register renaming is useful for getting rid of false dependencies and things like that. And it's way out of the scope of our class. That's 411 material. So happy to talk about it later. But yeah. OK. So LC3's word size is 16 bits. ALU operates on 16 bits. Registers are all 16 bits. Input an output. So we're going to have one input device. It's a keyboard. We have one output device, which is a monitor. That's it for the LC3. Monitor display. I always call it monitor. The book always calls it display. So football, little extra information. This is all 220 stuff. So you don't really need to know this. But the way things interact, the keyboard, humans are kind of slow compared to a computer. So there's only a key when a human pushes a key. So there's also a keyboard status register that says, well, the human pushed a key. So that's what this status register is for. KBSR says, OK, human pushed a key. So your program can look at that and tell when a key is coming in. The programming will do. There are some operating system services that handle dealing with all these registers. So you don't need to know this, really. But if you're interested, the keyboard data register then in the LC3 delivers that key in ASCII. So if you push the letter A, that lower case, that would be 61 hex. So the keyboard status register would tell the LC3, hey, there's a key ready. And then when your program looked at KVBR, it would get the ASCII character for the letter A. So that's how this works. It's in chapter A if you're interested. So there's also a display status register. Again, the process is much faster than the display. And if all you do is pump data to the display, the display is going to drop some of it on the floor and it won't show what you wanted to show. So you have to ask, are you ready for another character? You use the display status register for that. And then the display data register with the LC3 is set up. So you give it an ASCII character, and it prints that ASCII character to the display for you. And so that's how the devices work on LC3. But again, you don't need to use that until 220. You'll see it in the first three weeks or so of 220. Let me take that class. OK, so remember the program counter stores the address of the next instruction. And LC3 memory is 2x by y bit, or xom y by 16. So how many bits do I need in my program counter? x. It needs to tell me an address. So it doesn't matter how many bits are at that address. What matters is how many addresses are there. So there are two to the x addresses. So if I take log base 2 of 2 to the x, I get x. So I need x, which is 16, everything's 16. All right, so the instruction register then stores the encoded bits of the instruction being executed. How many bits in the IR? Am I asking you? Because I want you to think. OK, so why shouldn't you know the answer yet? You're making some assumptions. So how do you encode instructions? So you can encode instructions using some variable number of memory locations. So the next 86, for example, an instruction can be from 1 to 16 bytes. In the LC3 ISA, every instruction is 16 bits. And that was deliberate. It was a deliberate choice to say, well, let's make the instructions all fit in one memory location. So it was a design choice by the authors of the textbook so that each instruction would fit in one memory location, makes the instructions at architecture and the micro architecture substantially easier to understand for the first one you're looking at. You don't have to do it that way, but those were design decisions by the architects. OK, so yeah, the IR requires 16 bits for those reasons. If you change the addressability of the memory, you could then ask, well, should we change the ISA completely? If we make it 8 bits, should it be an 8-bit instruction set architecture? Wherever instruction takes 8 bits, should we just keep it at 16? Should we go to 24 or 32? Many, I mean, basically anything you want, right? If you're designing the ISA. So these were just choices they made to decide that every instruction is going to require 16 bits. All right. So here's what the data path looks like for the LC3. So this heavy black line here is a bus. I'll zoom in on a few pieces in a minute, but generally speaking, everything in this diagram, you know how to build from transistors. OK, so you can see the bus, if you look at the things going on to the bus, sorry, it's a little hard to see before I zoom in, but you can see there are tri-state buffers, creating things going on to the bus. So basically, there's a distributed box that says, well, which thing do you want to put on to the bus in any given cycle? And of course, the control unit is sending out control signals to decide that. Right? So in a given finite state machine state, the control unit will say, well, maybe I want this ALU to put its answer on the bus. And then that answer will go back over here, and I'll store the sum of my addition back into the register file, for example. So this part here is basically the control unit in green circle. This part's the processing unit. The memory is down here, and then this part over here is IO. So you can kind of break the data path up into pieces. So let's take a look at those pieces and make sure we understand them. So here's the control unit part. So let's see. So up here is the program counter. The instruction register is down here. So I think on Monday, I will show you how the control unit uses the PC, puts it out on the bus to go down to the memory, reads the instruction out, the bits of the instruction, then go into the IR, and then you can figure out what the instruction is and execute it. Yeah. What's a bus? Ah. So remember when we talked about tri-state buffers? I said that you could hook all the outputs together. And if you did that, if you just had a bunch of wires with different tri-state buffer outputs onto them, you could call that a bus. So it's basically a bunch of wires with multiple pieces of logic gated with tri-state buffers that you can put their answers on by signalling the tri-state buffers. That makes sense. So, yeah, let's take a look here. So for example, I can take the PC, and I can write the PC's value onto these wires by having these tri-state buffers copier. I can also take, let's see if there's another example. Yeah, there's Marmux. This is calculating the memory address. So you can see there's another set of tri-state buffers here. So I can take the value calculated by this Marmux, and I can also write that onto the bus. I can go back a step. You can see the ALU output also has a set of tri-state buffers. So this is basically the thick black lines are 16 wires that go around the chip. That's it. It's 16 wires. And there's a bunch of things, logic outputs, that we decide which of those should we write to those 16 wires using tri-state buffers. And that's what we call a bus. It's not any more complicated than that. Yeah. I think I mentioned it when we talked about tri-state buffers from home. That's right. They're just wires. And just like all other things, you can't short them. That's why they have all the tri-state gating in here. Ah. Ah. So we use the same, you may consume in on it. So you see there's an LDIR for that register. So just like when we built our data path, we said, well, the register is not going to load every cycle. So when the control unit wants a new value in the IR, it tells the IR to read the value from the bus and store that value. And when it doesn't, it sets LDIR to zero. Yeah. And so pretty much everything that takes its value off the bus is gated in the same manner. There will be a load signal of some sort. Yeah. Sorry, I'm not sure what it is. I mean, that would be a point-to-point network. So I mean, a lot of modern chip designs are moving more towards point-to-point networks on the chip. But a bus is a shared medium. I mean, that's the other aspect to keep aware of a bus is it is a shared medium. So all of these things can write to it, but if more than one write to it, in the electrical case, that'll be a short. Right? So it's a bad thing. Yeah. So as long as the finite state machine follows the rules that it doesn't try to set gate PC to 1 at the same time that it's gate Marmux to 1 or any other tristate buffers gating things onto the bus to 1 at the same time, then there's wires will not create shorts. So the finite state machine is responsible for guaranteeing that only one of the gating signals is 1 at the time. And so that's part of the FSM design at that point. Makes sense? Okay. Yeah, such. Yes. Yes. So just like when we draw a mocks like this one, this is actually 16 to 1 mocks as remember. We said, well, this is not just one to 1 mocks. We've got 16 here, 16 here, 16 coming out. This is actually 16 to 1 mocks is controlled by the same signal. When we draw a tristate buffer across a wire that should have a crosshatch on it. Sorry about that. I just took the figure from Patent to Tell. It should be crosshatch with 16. Each of those is 16 tristate buffers with the same enable signal. Yeah. I'm sorry. Yes. The bus has 16 wires because the word size is 16. And so everything we do, you know, when we add things together, we're adding 216 bit values and getting a 16 bit answer. When we move data from memory, it's 16 bits coming out, doing the store data from two memory, it's 16 bits going in. So that's why there are 16 wires. But everywhere here, there are 16 tristate buffers because there are 16 wires in the bus. Yes, that's right. That's right. And it's up to the finite state machine to guarantee that all of the tristate buffers other than one set are in high impedance mode by sending them zero as they're enabled. Yes, the control unit controls every open signal you see here. So the address, max input, the marmux input, the load PC, the load IR, the load condition code down here. Every control signal in the data path is up to control unit to control. Yeah. Yeah. So in that sense, it's identical to the data path that we developed. There are set of control signals. In this data path, there are a lot more than the six we have. But it's up to the control unit to set those for each of its states. And we'll look at that in more detail later. We'll look on Monday at the process of fetching an instruction and then decoding it and think about how it'd be executed. But we'll look in detail in a few weeks after we do some programming at how you would actually execute one or two instructions on this data path. If you want to read ahead, section four, one of the notes will talk to you. We'll show you specific control signal implementations on this data path. Okay. So program counter instruction register. So this is some miscellaneous instruction execution logic. It'll make more sense once you've seen what the LC3 instructions can do. This is our finite state machine generating all the control signals. So there's the state in here and it basically sends out all the control signals. They're not wired up just to keep the diagram from giving to cluttered. They drive all the control signals in the data path. Okay. So let's also take a closer look at the processing unit. So this was on the right side of that figure. This is just the bus coming around. You can see that you can take the ALU output and put that on the bus. The register file can read a value from the bus and short into a register. So here's the ALU. It does these three operations at and not all 16 bit to complement addition. There's the register file with the 816 bit registers. So one thing I want to make sure, because we didn't cover this explicitly in class, but I don't think it's that hard to do. So if I have eight registers and I have a three bit number telling me which register I want to read, can you build that for me? On the reading side, so you've got eight registers and I want one of those registers to come out and say on this set of wires. I want to pick one of eight. How do I pick things? A mux, right? If I want to pick things, I use a mux. So I want to pick one of the eight registers to read. I'll have eight to one muxes. I'll have 16 of them. And that'll give me one output. And then I'll have a bunch of other eight to one muxes for this output. On the right side, right? When I want to write to one of those registers, then I need the decoder. When I need the decoder to tell that register, you should be storing the value. So I can route the input to all eight registers and then use a decoder to tell one of those registers, well, you should do a store now. You should load a new value from your input. So this register file is capable of doing one write and two reads all in the same cycle. All right, so let's take a little look at the memory here. So here's the memory to the 16 by 16 bits. There's the MIR. There's the MDR. You can see the MDR is gated, but it can also take data off the bus and store in the MDR. So for load, what we'll do is tell the memory to give us bits and those bits. There's some address logic associated with the IO, but they'll come back and go into the MDR. And then from the MDR, we can copy them onto the bus and put them wherever we want them. For a store, we'll first write the bits to the bus and put those into the MDR. And then from the MDR, we'll put those into memory for the store. So we can do loads and stores with this arrangement, with the MDR, MIR, and the memory down here. And the details of the IO, I have it in the diagram, but leave it for a 220. Okay. So the questions on, more questions on data path. We talk about instruction permits. So how do we represent instructions? Good. Good. Okay. So instructions encoded by some representation, right? Whoever's going to design the ISA says, well, here it is. Who's the representation we're going to use? Design decision. 16 bits. That's a big representation. Should get some paper out and writing all the instructions. I take a while. You got 65,000 choices. More. All right. First, I want to do a little exercise. Yeah. It will be bits. It will be bits. Yeah. It will be bits involved again. Yeah. It will be bits involved again. It's here. It's in good. We're on. Okay. Good. So I'm. Since you're all on board. Here, let me tell you what I want. You put in a quarter. You pick one of your favorite flavors. I mean, now there used to be another flavor here. It was a beverage. It looks. Yeah. It's not legal for some of you. So it's no longer here. So now we have cola lemon, orange and grape. A little dull. I was a little worried about putting another copyrighted one trademark twenth moment. I'll leave the design to you. I just need a little help. All right. So four, four flavors. And I want you to dispense one of those four flavors for ten clock cycles. Okay. So let's, let's count states. So let's see. So when you come up to the machine, the machine's off. And then you put a quarter in. And then they'll go to a half coin state. So that's two. Okay. So help me out here. So if you're going to dispense cola for ten cycles, how many states do you need? Ten. Ten. All right. Ten. Okay. Ten. Good. What about lemon? I really like lemon. How many? For lemon. Ten. But I like lemon. Be sure it's not 12. All right. What about orange? I hear 42s. This one takes three. They're making fun of my slides now. Okay. Okay. So let's make a table. Did you get that? I heard this earlier. Awesome. I'm happy. Can you help me out here? I'm hearing some sixes. Six. Six. Okay. Whatever you guys say, six is good. I have a suggestion. Instead of six, can we do seven? Because six sounds painful to me. I'm not sure if you can do seven. Maybe you can try it. But I like to use seven. I want to have one bit that says, you know, did you put a coin in yet or not? I want to have two bits that say, well, we've got four flavors. Which flavor do you pick? Right? I have four bits that'll just be a counter that will count to ten down or something. So here's how I think it'll work. So you put in your quarter. That turns on the coin bit. And you pick a flavor. And that goes into the flavor bits. Right? Otherwise, you have to put a coin first. So you pick your flavor. That loads ten into the counter. And it sets the flavor that you picked. And then the counter will start counting down. And then to dispense the soda, we'll have a decoder. Put the flavor into the decoder. And then it will put the counter non zero signal, which we can just easily, you know, do an orgate out of the counter bits or something. And we'll put that into the decoder enable. So that if the counter is not zero, we'll get soda from one of the four flavors. And if it's zero, we won't get soda. One decoder, handful of gates, and an extra flip-flop of a six bit solution. Yeah. Yeah. Yeah. So you might need a priority encoder. It's true. Good point. Okay. So put priority encoder down here too. Or just keep the humans away from the machine. All right. It's only for me. I promise not to push more. All right. Okay. Good point. I'll go. Okay. Okay. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. So why does this work well? All right. So adding these extra bits lets us organize. Adding one extra bit in this case. Let's just break the bits into meaningful groups. All right. So we can have the coin bit. We can have the two flavor bits. We can have the counter bits. And relevant here. that's some function of the counter bits. We don't have to look at the coin bit at that point. But relevant is based on these meanings. So by making these things meaningful and separating them into groups, we actually not only make it easier for ourselves to understand, but we make the logic easier too. So remember when we talked about how do you pick representations for finite state machines? And they said, well, often you want to try to use human meaning. Now it's going to be much more important. We have a 16-bit representation to deal with for instructions. That's a lot of bits. That's a lot of meanings. So we're going to break things into what we call fields. So this is the real point. So pretty much any ISA you look at, maybe X86, which is a little funky because it's grown over 30 or 40 years now. But most ISAs, and even there, where they have this simplification. So you'll have a bunch of fields. So separations of those bits and the encoded instruction. And the first one will be your operation code. So there'll be some bits that'll say, well, what do we want to do? What is the operation you want to do with this instruction? And then the other fields will tell you what the operands are. So well, you want to do an add? What do you want to add? Usually add two things. So what are those two things? Those will be separate fields in the instruction. So we're going to use this idea that we just developed with our soda dispenser of breaking things into groups in order to design our instructions at architecture. So you'll see that when we look at LC3 instructions. So here, for example, is an LC3 instruction. So it's 16 bits. So over here, in green is the opcode. So it turns out that's an opcode that's known as LDR for load register base, which you don't need to know yet. Just show you some examples. We'll go through the ISA in much more detail next week. So that's three other fields. One is the destination register. So what are the possible values here? 0 through 7, right? One of the registers. Good. So there's another register, base register. A possible values 0 through 7. There. And there's a six bit offset, which is a two-s complement offset. So what are the possible values there? So it's two-s complement. So the smallest one, the biggest one would be 0 followed by 5 once. That would be, I think, 31. And so negative 32. So here's what it does. So it says, OK, take this offset. Sign extended to 16 bits, add it to the contents of this register. Go to that memory address, load the bits from that address, and copy them into the destination register. So in words, it's kind of long. That's why we're writing an RTL. So you want to know what the RTL means, because otherwise, you don't want to have to write this. So again, take the offset. Sign extended to 16 bits, add it to the bit stored in this register called base register, named by these three bits. And then go to that memory location, get the 16 bits out of that memory location, and copy them into the DR. That's one instruction. All right. So here's another instruction, which is add. So this is the add-up code over here. It also has three fields, and then three things that have to be fixed to 0. So there's a destination register. That's where we're going to put our answer, 0 through 7. There's one source register, also 0 through 7. Good. And then there's another source register. So it says take two registers, add them together, put the answer, the sum, into destination register. That's all. What are the zeros for? So that's a good question. So why not just let those be don't cares? So there was a commercial architecture called the 6502. Let those be don't cares. And it turned out that those don't cares produced some bizarre effects when software people used those instructions with different bits, because they just built a finite state machine, and they left them as don't cares. And so it did something, right? And turned out it did something sort of interesting that the software people decided that they really wanted. And so they put those non-existence instructions in their software. And then when the 6502 architects wanted to produce a new generation, they found that in fact, people had used bit patterns that didn't exist in the instructions that architecture. So the modern view of that is don't ever make that mistake again. If you ever want to extend your instructions that architecture, it's really useful to have undefined bit patterns. On the other hand, having software that takes advantage of a particular microarchitectures don't cares mapped into something is not so attractive from a design point of view. So let me stop there. And we'll look more at these next week. Have a good weekend."
    },
    {
        "ECE120-2016-10-26-LEC-26-slides.mp4": " Okay. We're ready to start. So not much on here. Since this is a kind of complicated example, we'll spend most of the day, I'll try to spend all of the day actually finishing up this example of building a finite state machine to implement some C code. If I don't manage that, we might start on a new model, but otherwise we'll do that on Friday. And that's patent to tell chapter 4. This example is the notes, 3.7. So I wanted to just go through this a little bit, what we talked about. So we set out to develop a finite state machine to implement a piece of C code. And we're going to take our strategy to build with abstraction. So we decided we were going to store our variables from the C code and registers, counters, things like that, sequential logic, what you've learned a few weeks ago. And then execute the statements using components like comparators. So here was the C code. So what this thing does is basically just find the minimum of 10 numbers. So this remember is an array of 10 integers, 32 bit, 2's complement values. And the way this code works is first we take the first value, value sub 0 and copy that into min. And then we look at the other nine values from 1 to 9, according to this loop control. We compare each one with the current minimum. And then if it's smaller, we replace the current minimum with that value. Once we look at all of the other nine, we were guaranteed to have found the smallest of the 10. And so when this loop is done, we'll have the smallest of the 10 values in this variable min. So we built up this flow chart to show how it works, sort of the same thing, just in color-coded statements. So initialize the variable min and then start the loop. So initialize index to 1, compare to 10. Once that's false, we're done. That's the whole program. But as long as it's true, we go around this little piece. This blue is the if statement. So check if the thing we're looking at values sub index is less than the minimum. It's so copy it into minimum. Otherwise, just update the loop by incrementing the index and go around nine times. Okay, so we decided the array was going to become a memory. We know how to build a memory. So we'll use a memory for that. Other variables we decided would be registers and counters. The if statement will be a comparator. And I said that we're going to use a serial comparator. So I just wanted to kind of make clear why. There's no good reason. The reason is purely to show you that just like before, when we did the keyless entry extension, where we had a hierarchy of states, we showed you the high level four state diagram. We kept that throughout. Even after we'd done the extension, we still had that same state diagram at a high level. But the alarm state became something like five billion states. And of course, we didn't draw five billion states on paper, where we had a hierarchy of states. Here again, we're going to have a state that uses the comparator. In order to use a serial comparator, we have to compare one bit at a time. These are 32 bit values in our code. So we're going to execute for 32 cycles looking at one bit at a time. And when that's done, at the high level states will move to the next state. But we'll also have that one high level state for comparison that takes 32 cycles. And it's really 32 different states. So I just wanted to illustrate that for you. Again, that's why I decided to use a serial comparator in this design. So in order to use a serial comparator, we needed some other components. So we need two shift registers to put bits into the serial comparator. Remember the way it works. It looks at one bit every cycle. We have two shift registers to give it one bit every cycle that it can compare. And then we also need a counter. How do we know in 32 cycles are over? Well, we have to count them. We have a counter for that. So those are our pieces. Now I mentioned this, but I kind of realized talking with people in office hours, maybe it wasn't entirely clear, it's hard to make it clear without having you actually do the process. But whenever you're doing a design process, you don't just make decisions and then that's set in stone. Typically, you're going back and forth. So we talked about components. The components we chose affect how we can pick the states, how we can design our states, how we can break up the pieces of the flow charts into states. And then vice versa, the way we want to do that affects which components we need. So it will be clear at the end, you'll see how things fit together. But usually when you do this kind of thing, it's not that you just say, okay, let me throw some things down and then I'll just straightforward break the states up. Usually you're going to say, oh, well, there's this other thing that I don't know how to resolve given the components I put into my data path. Let me go back and add something or go from the components to the states and figure out how you want to fit the states to the components. So it's really a back and forth design process. Now this is what we did with our flow chart. So we broke things up into five states. So the first state, remember, let me just explain it a little more. So in this init state, we're doing three different things. So the three things we're doing is we're putting a new value into the min register. It turns out index will actually be a counter, but it doesn't matter. We're putting a new value into min, a new value into index. Those are separate pieces of logic. So in one cycle, we can put a new value in both of them, and it doesn't matter. That's why we're allowed to put two different pieces of our flow chart into one state that actually happens simultaneously. But what about this one? Well, the first time we go through the loop, index is one. And you know that 10 is greater than one. So you don't need to do any work in your finite state machine to figure out that 10 is still greater than one whenever it runs. So that's why we're able to pull that in the first time. So I wonder, well, what about this part where we come back after our loop is done and we check it? So what's going to happen there is index is just a counter. So we can look at its value when we're in this green state, the copy state down here. And when it's equal to nine, then after we change it, it'll be 10. And 10 is not less than 10. So instead of doing anything here, we can simply make copy, go directly to done the weight state when index is nine. So that's how we're going to resolve the other use of this box here. So you'll see that as we walk through the design. But basically, we never really have to do this comparison. It can all be done ahead of time and using in the copy state, using the index's value comparing it to nine. So I'll show you how that works. But just wanted to go through it more slowly. All right, so this is what we got generalizing our state machine. So we'll start in the weight state at the ideas that we've got this finite state machine. Some other logic is going to fill the memory up with 10 different numbers. Then we're going to say go or start rather. And the start signal will tell the finite state machine, okay, go out of weight and start doing your initialization. So that was the gray states on the previous slide. Initialization takes a cycle. So the next state will always be the prep state. Remember, that's where we had to set up to use the serial comparator. Right? So we're putting values into the shift register and we're resetting the counter so that the serial comparator can do its work while the counters counting to 32 for us. Right? So that's a prep state. Then we'll let the counter run. So prep also takes always one cycle. So then we'll go to compare. Compare will take 32 cycles. So we're going to look at the counter value and into the counter says 31, which will be the 30 second cycle. So the counter says 31. We're just going to stay in compare. When the counter says 31, we're going to move to copy. Now, in that cycle, when we're in copy, the comparator, the serial comparator, will be telling us whether A was less than B. Right? In other words, or A was greater than B, I think is what it ended up being. But it'll be telling us whether min is greater than the new value we're looking at from the array. And that's the case in which we want to copy that value into array. We'll use that serial comparator output as the load input to our register to perform the copy. So this one copy state does both the then case of the if as well as logically sort of the comparison. Right? And also the update of index. And that was shown in the flow charts. And we flip back there. So the copy state will do this copy if it's appropriate, if we came down the true arc. And that will be stored as the comparator output. And it will also do the index equals index plus one. So both of those in one cycle. So once we're done with copy, I mentioned we would look at index. The index register, if it's not nine, we still need to keep going. And if it's nine in the cycle in which we're copying, then by adding one to it, we'll make it 10. That's when the loop is done. So if it's not nine, it's not the end of the loop. We'll go back and start to look at another value. If it is nine, we're done. And that's it. So this is our high level state diagram. And this is where we kind of left off on Monday. Okay, so that's our abstract state diagram. So now let's talk a little more detail. Now the way of an idea of what we're going to do with our finite state machine, let's put a little more detail into the components and what they need to be able to do. So we said that index in the C code is a 32 bit choose complement value, right? And int. So what we're going to use instead, we're only using it to count from actually one to nine. So let's just use a four bit binary counter. We don't really need it to be a 32 bit value. We just need four bits, right? Just goes from one to nine in the loop. Now in copy, we're going to increment our index, right? That was a state where we're at the end of the loop and we do the loop update. So we want to count input to control the counting because we're not incrementing in every state. Just once we go around the loop, which is multiple FSM states, right? So we'll have this count input that says go ahead and count. And if that zero, the counter won't count, it'll just hold its value. Now similarly, if we want to in the weight state, we can reset the counter to one. And then in init, instead of having another way to set it to one, we can just let it count. So normally you'd have a reset input that resets it to zero. We can use a reset input in that way in the weight state. Go back here. In the weight state, we'll set the counter to zero, the IDX counter to zero. And then in init, it'll go from zero to one. And then here in copy, it'll be incremented, right? So we're using the count input. So those are the controls we'll need on the index counter. The reset for setting its zero and count to tell it to go ahead and count up one. But what about the array? We need 1032 bit to complement values. So instead of just having enough cells to store 10, let's just stick down a standard memory, right? So some power of two addresses all round up. So we've got 16 addresses, each of which stores 32 bits. And so you hopefully remember how to build this kind of memory. But we've got read right here. We've got address here. I didn't put a chip select down just because it's always going to be on with our finite state machine. So you could hardwire chip select to one if you had a memory with a chip select. We're only going to read. Right? The only thing we ever did in our finite state machine was read those values out. So from our point of view, obviously someone else is going to have to override this at some point. But from our point of view, we could just always set this to one. Now before I had this as right and able, here I have it as R W bar. So here a one means the R. So it just means always read. And if you look back at the code, whenever we read from this memory, we always read value sub index. Right? So in particular, in the first state, we read value sub zero. But remember that in that first state, in init, the counter index, we decide to set it to zero. So if we read value sub index, we're always going to be reading the right value. So in other words, this input here for address, I can just take the value of the index counter and hardwired in there. And then I'll always be coming out down here, value sub index. So I don't need to do anything with that other than connect the wires. And you'll see that in the full data path in a minute or two. Makes sense? OK. Let's keep going. Almost to the data path. Just need to talk about a couple more components. But what about this min register? So min keeps track of the smallest number we've seen so far. It's a 32 bit to complement value. So we need a register. We'll have a 32 bit register. We'll call it min. So I'm using the fonts here. So this is the C code variable. This is our register in our data path. But otherwise they have the same names. So what do we need for that? We need to be able to change it. So once in a while, we write a new value into min. So let's have a load input, like a parallel load input for a register. And so of course, we have to have it coming from somewhere. Well, where does it come from? So in copy, we copy value sub index into min. And in a knit, we copy value sub zero into min. But in a knit, as I mentioned on the last slide, index is zero. So we can take the output from the memory, which was value sub index at all times, because we're going to hardwire the address port to the output of the index register, or counter, sorry. We just take that and put that directly in here. And whenever we set load to 1, min will copy value sub index. So another thing we don't have to do anything to control in our finite state machine is always the same. Anytime we set this load signal to 1, min will then copy values sub index. Whatever index value is that'll go into the address port of the memory, it will come the 32 bits stored at that address, and that'll get copied into our memory register. I'll go over this in the data path too. OK, so then we had a couple more shift registers. Shift registers A and B. Now we decided we wanted to put values in those in one cycle. It's a little bit painful if we try to shift them in a bit at a time. We need to also count how many cycles that took, right? So we need something to just do a parallel load, let's say. So we've got a parallel load input on each of these two shift registers. They're right shifting, and then the bits will come out here. Remember that our serial comparator looked at the least significant bit first. And so we want to look at the least significant bit first and work our way up to the top bit. So we're going to write shift those bits out of these shift registers. But when we want to load them in prep, we want to do a parallel load using this load input here. The 32 bits will come down from the top, get latched into the 32 bits of the shift register, and then they'll shift out one bit at a time during the compare state. So now those only load one value, right? A is always set to min, B is always set to value. So bindex, so again, we can take them in register and take its value and just copy it directly into a, just wire it down here. And value subindex, we can wire directly down into b, and then whenever we want to set those values, we just set load and load to 1. OK, last piece before we show the whole data path. So we need this counter to drive the serial comparator for 32 cycles. So we'll use a five bit binary counter. We'll call it count. We'll need a reset input, right? Because again, when we're going to prep for the comparison, we need to reset that counter, so it can count for us. Remember that the comparator here has a first bit indicator, right? So we have to tell it this is the first bit of the comparison. So that will be generated by a zero signal. So when the counter holds the value zero, it'll generate zero equals one, and that will tell the serial comparator that the first bit is coming out to be compared. There's also the bits coming from the A and B shift registers down into the serial comparator. And so it's always just comparing the two serial output bits of the two shift registers. All right, so there it is in its full glory. So all this is, then, is the pieces I've shown you, and then a couple of other parts that we'll talk about later, like this done signal and this last signal and the then signal here. But you can see the memory, right? So the memory is always reading. It's taking its address from index. Here's our binary counter index. So it's driving the address port of the memory. The value subindex, then, is copied both into min and to b, but only when they exert their load signals. So if we want to copy value subindex into min, we set min's load to 1. If we want to copy value subindex into b, we set b's load to 1. The shift register A copies from the min register here. Again, only when we set load to 1, A and B then feed the serial comparator. And then here's the counter that counts 32 cycles. Yeah. Yes. So remember that the way this finite machine will be used as some other logic will fill the memory with values. And then it will exert the start signal in the finite state machine, which will take it out of the weight state and started doing its computation. And then once it's done, it'll go back to the weight state and the external logic, whatever that might be, can come read this register value, and that will hold the minimum of the 10. Any other questions on this one? Yeah, Eric. Yeah, so we'll come back to this. We'll come back to this. We're going to use this. The counter will count from 0 to 31. And then when it equals 31, we shift into, we're out of the compare state into copy, and that will have been 32 full cycles in the compare state. Yeah. That's right, that's right. After 32 cycles, the comparator's done. All right. So now we have all these components. We have them wired up nicely. So how does it actually relate to this finite state machine, state transition diagram we drew? What's the connection? So not all of the signals in the data path are fixed. We still have a bunch of load signals and things like that. I'll highlight them in a second. What's left, those remaining input signals, are what you can call control signals, or what we call control signals. So the control signals tell the data path what to do in any given cycle. And it's the finite state machine that will decide what values the control signals will take. So the finite state machine will have as outputs, those control signals. They're going to be six of them in this design. So using these signals, these control signals, the state of the finite state machine will cause the data path to perform the actions associated with that particular state. So I'll show you what I mean by that. First, let me show you the control signals for our data path. So on index, we've got index reset. And the finite state machine has to decide, do I want to reset the counter now or not? Similarly, do I want to make the counter count now or not? For each state. Again, for, let's see, min, there's minLD. Do I want min to load a new value? There's also a, the a register. Do I want a to load a new value or not? So just ones and zeros. B, do I want b to load a new value or not? And then there's one more which is counter reset. It's down here. Do I want to reset that counter? So by generating those six bits, the finite state machine controls all of the components in the data path to execute the whatever action those particular states want to take. We haven't defined those. We've just talked about that. All right. So how does the finite state machine then move between states? Well, aside from the logic we've already talked about that well, after a knit, we always go into prep. I mean, that one's easy. We don't have to look at any inputs. The data path generates a few signals that the finite state machine can use as inputs for its transition. So there are three that we're going to care about. And there are these. So there's a done signal, which says, well, we're done with the last loop iteration. We've done this comparison nine times. We started with the first value. We compared the nine other values and we're just done. The whole loop is done. We should go back to weight. And that's when index equals nine. So I'll show you that again in the data path in a second. There's the last signal. So that's raised in the last cycle of the counter. Counter is going to go from 0 to 31. When it gets to 31, after that cycle will be 32. So in that cycle, that's when we want to transition the state machine out of the compare state into the copy state. So that last signal will just be equal to does the counter equal 31. That's all. And I'll show you that in the data path in a second too. The then signal says that a new minimum value has been found. We did the serial comparator. And it says, well, a is greater than b. We were comparing min to value subindex. And so if that's the case, we need to copy value subindex into min. And so this is the comparator output that says a was greater than b. These signals are going to be inputs to the FSM. So here they are. So here's done. You can see we take the index value, we compare to see, is it equal to nine? And if the answer is yes, then done is one. If the answer is no, done is zero. Here we compare the counter value to 31. If the answer is yes, then last is one. If the answer is no, last is zero. And then using the representation for a comparator, which you can look up in the notes, or just, so this is the right answer. Z1 out of the comparator means a greater than b. But the design we did in the notes. So this will tell us that, in fact, the two values we put in the shift registers, min and value subindex, min is greater than value subindex. And that was the condition under which we want to copy value subindex into min. So those are our three outputs from the data path that we'll use to drive the finite state machine. So why didn't I bother saying much about these? If I were to ask you to build this, would it be hard? So I said, OK, get out a piece of paper. You have five minutes to build this. You could. So what would you do? What's nine in binary? 1, 0, 0, 1. So that means the four bits of the counter have to be 1, 0, 0, 1. That's all. So it's just a min term. So it's OK, take the high bit. I don't know, call it index sub three and that with index sub two prime, index sub one prime, and index sub zero. If the pattern in the counter matches 1, 0, 0, 1, it's equal to nine. Otherwise, it's not equal to nine. So it's really maybe an AND gate and maybe a couple of not gates. That's it. It's same thing down here. In fact, I think this is just an AND gate for all ones of the pattern. Those are easy. This is literally just the Z1 output. All right. So everything in the data path, you know how to build. So let's go through then and make an abstract next state table. So we have five states. I want to use something called register transfer language. So what is that? It's just a way of describing how bits are moving around in our data path. So for example, start with a weight state. So for example, I'll show you RTL in a second. What does a weight state do? So weight is the state in which the FSM sits when we're waiting for some other logic to fill up our memory with values, right? So we can go compare them. Yeah. So if you remember the way our serial comparisons worked, the first F is first. Yeah. F means first. So for the first bit, you give it a 1 and for all the other bits, you give it a 0. All right. So weight is going to be the state we sit in. So what do we do? Well, when we get to a knit, remember we wanted IDX to be 0. So we'll set IDX to 0 and wait. That way, when the start signal comes, index will always be 0 in the init state. And then we just sit there in the weight state until we see the start signal. So that's all this weight states going to do. So we'll write that index gets 0 and RTL as follows. So you can see the thing you're writing into is on the left. You have a left arrow. And then the thing you're writing into it, the bits on the right. So this could be some other register value on the right. That's what you'll see in some later RTL examples. But it's very simple. So there's an assignment operator, which is this arrow. So let's write that into the table. And then we'll have two next states. So the condition for the first next state will be, well, let's see, we see the start signal. We put one up there for you. So on start, we'll move to a knit. So if we see the start signal, we'll go to a knit. What if we don't see the start signal? We're saying stay in weight. So if start is false, then we'll stay in weight. And that's it for an X state diagram. For this particular state, our next state. OK, let's look at a knit. So a knit is going to perform two different actions. So one is it's going to copy value sub 0 to min. And it's going to set index to 1. So how's it going to set index to 1? Well, just by telling index to count. So it'll actually set index to index plus 1. And then the next state from a knit is always going to be prep. So let's go back to our state table. So knit does two things. So sets min to value sub index. Remember index in the state is 0. So this is the RTL that's actually executed is to copy value sub index into min and index plus 1 copied into index. That's the way we express things in RTL. So there's one thing I want to point out here. So in RTL, things are happening in the same cycle. So we might have a whole bunch of different actions. They'll happen at the same time in parallel. The order that we list them cannot matter. So here, you see I'm changing index. So if this were like C programming language or something, if I put this line down here in front of the other line, you might think, oh, I should use the new value of index when I go read the array. That's not the case with RTL. Even if you swap this order, you get the same result. Things happen at the same time. And there's a piece of hardware that happened in one cycle, you take the old value of index on all of the right sides. It's the fact that you're changing index that happens in the next clock cycle. So just make sure you understand the notation. Because otherwise, when you try to understand the diagram and the data path, and then later in 385, you'll also get confused. So in RTL, everything, all the actions happen in the same cycle. So just make it just to be clear. So it doesn't matter what order we put them here. It means the same thing. All right. So the next state then is always prep. Makes sense? Good? OK. Let's go on. So the prep state, we have to do three things. We have to copy min to the a register. We have to copy values of index to the b register. These are both the shift registers. And we have to reset the counter to 0. And then we're always going to move from prep down to compare. So let's go back to a table. All in one cycle, all three actions. So condition always next state compared. Yeah. Cool? OK. Yeah. So remember, the counter, C and T, is what keeps track of the 32 cycles for a comparison. So by setting it to 0, we're getting ready to start counting. If we don't reset it, it's going to have some random bits in it. Good question. All right. So let's go like a compare. So when we get into compare, A and B are ready to go. Right? They got the 32 bid values that are ready to shift out the first bid. The counter is just reset to 0, just as we talked about. So when we enter this state, that's what's set up for us. So all we need to do is just let the serial compare to do its work. We just need to sit there and wait. Don't do anything on anything else in the data path. The comparator in the shift registers will just keep shifting one bit at a time. Into the comparator, comparator will keep pranking away, saying, well, what do I think about this bit? What do I think about these bits? No, keep doing its thing until the counter gets to 31. So this is a little easy to get confused. So maybe they look at the extreme. If you wanted this to operate for one cycle, then on the first cycle, the counter value is 0. And so if you compared counter to 0, that would mean you spent one cycle in compare. So compare to 0, you spend one cycle. Compare to 1, you spend two cycles. Compare to 31, you spend 32 cycles. So we compare to 31. And then at the end of the 30 second cycle, we shift over into copy. And that means our serial comparator is fully done. And the comparison output are latched into the output flip plots of the serial comparator. So we can then compare was a greater than b. Remember, a was set to min, and b was set to value subindex. So when we're done with that, we'll go one counter 31 on the last signal. We'll go over to copy. But there's nothing to do in the data path, right? No RTL. So what are the next states? So what if last is true? Where do we go? Go to copy. What if last is false? Just stay and compare. I didn't draw the self loop on the diagram, but just stay and compare. OK. Yeah. Now, the shift registers are always shifting. We didn't put control. Only if you need to do something. Yeah. So the question is, do we need to do anything to make our shift registers shift? If we had had a shift input where we allowed ourselves to say, well, if I set the shift input to high, then they shift. And if I don't, then they don't. Yeah. The shift registers we put in are shifting every cycle all the time, regardless of what else is going on. So we don't need to take any action. Yeah. So that was a more complicated shift register, just to show you how you could do the mux to do the different kinds of shifts in the same register. We don't need anything so complicated. Yeah. We only need a right shift register. That's capable of parallel load. 32. Yeah. So remember, these are all 32-bit values. And this is a serial comparator. It compares one bit per cycle. So to compare 32 bits, we have to wait for 32 cycles. Why does the counter start from 0? Because we reset it right here. OK. So why did we compare to 31? So imagine that instead you compared to 0, how many cycles would you spend here? But when you first cycle, you come in. It's set to 0, right? So then in the first cycle, you would immediately move to copy. So if you compared to 0, you would spend one cycle here. If you were to change it to 1, compare to 1. You would spend one cycle with counter at 0, counter would count to 1. And after two cycles, you would move to copy. If you compare to 2, 0, 1, on 2, the third cycle, you'd move. So whatever you put here, you'll spend this number plus 1. So by putting compare with 31, it means we move on the 32nd. Yeah, this is easy to get confused. So when you design these things, it's easy to be off by 1. Same thing in C code, actually. It's very easy to be off by 1. So those are the kind of mistakes that people make all the time. And it's important to go through and look and make sure that you're really doing exactly the right number of cycles. Because if you compare for 33 cycles, you'll never have the right answer, right? There'll just be some random bits coming out of comparator. Actually, that's not true. The way our comparator works, it'll shift more zeros in. So our comparator is forgiving, but most hardware won't be. All right. OK, one more state. So this finite state machine is going to move to prep or wait based on the data path output done. So remember, done was going to compare index with 9 to see if we've looked at all of the array values. So done is equal to 1 when index is equal to 9. Copy then is going to, before it moves, it's going to increment index. And it's going to also copy values index to min if and only if the then signal coming out of comparator is 1. So let me show you how we write that. So you can see there's two pieces of RTL. So again, they execute in parallel. So this index on the right and this index, OK, this thing is getting flaky. The two index values on the right, I'll stop using my laser. Sorry. The two index values on the right are the same. And the old value of index index only changes in the next cycle. So again, RTL is parallel. The two different statements happen at the same time. The then colon notation means that the action after the copying value subindex to min only happens if then is equal to 1. So this is how you write conditional statements in RTL. You put the condition, you put a colon, and you put the actions that follow. So this says, well, if then is equal to 1, will copy value subindex to min. If then is equal to 0, we do nothing for that first statement. And there's no else clause in RTL. At least usually, I suppose you could write L's and then do something else. Normally, you would write a then prime clause instead. So you'd have multiple conditional clauses. The index equals index plus 1 is not conditioned by then. So the counter will always increment. Now, when we see the done signal, we go to weight, get my laser to work. When we go to see the done signal, we'll go to weight. If done is off, we'll go to prep. We're never sitting in copies for more than one cycle. Here. That's right. These are the, on the right here, these are the transitions. And these are the actions inside the states. So if you remember when we wrote next state tables, before we had state output and next state, these are actually the coded outputs. The RTL is the coded outputs. We're going to translate that in a minute into the data path control sequence. So each statement and RTL, we have to be able to translate into data path control sequence. And that's the part where you might have to go back and forth. If you realize you don't have components that can execute what you want done, you might have to change your components. All right. So it's time. I know you've been waiting. You're excited. Oh, I did you the answer. How many bits do we need? Three? OK. Is that OK? Two flip-flops. I can give you two flip-flops. So we're going to do something called a one-hot encoding. And why we're going to do that? You'll see shortly. You'll see what it makes easier. So here's what it means. So in each of our states, there will be one one in one flip flop. All the other flip-flops will be zero. So it's one hot. There's one one. So the weight state will be one in a bunch of zeros. The unit state will be 0, 1, 0, 0, 0, and so forth as you see there on the table. So let's fill in the control signals. In weight, we have to set index to zero. So what should we do for index reset? Put a one there. That'll force index in the next cycle to have the value zero. What about count? Probably safe to do zero. We didn't actually define the behavior for our counter. If we tell it to count and reset in the same cycle. So let's just set it to zero. For the rest of them, they're probably actually don't cares. But I'm just going to make things simple and just set them all to zero. Because we don't want to change any of those other things. We don't want to change men. We don't want to change A, B. Otherwise, we'd see it in the RTL. So we don't need to reset the counter. Let's just set all of those to zero. So here's a knit. We do two actions. So we're going to set men to value sub index and indexed index plus 1. So what about index reset? What should that be? Zero. We don't need to change index. What about index subcount? Or we do need to change index, but we don't need to force this to zero, I should say. What about index subcount? 1. What about min load? 1. So wait a minute. So all I did is min load. How do I make value sub index get into min? But if you think back to the data path, anytime you set min load, it's always going to load the same thing. And the same thing is whatever's on its input wires, which is always value sub index. So in the way we built the data path, anytime you put something new into min, that's something new is going to be value sub index. That's just the way the data path works. All right. What about a sub load? Zero? Don't want to change a, right? How about b? Zero. Count reset? Good. All right. How about prep? So in prep, we had three things to do. So set 8 and min, beat a value sub index, count to zero. So what's index reset? Zero. Index count? Zero. Min load? Zero. A load? One. B load? Good. Count reset? Good. OK. So compare. We had no RTL. What's index reset? Zero. Keep going. Zero, zero, zero, zero. Good. All right. There's no RTL, right? The way we set this up, the zero compared in the shift registers, they just do their thing. We don't have any work to do. So we just send all zeros as our control signals. What about copy? So here's a, this one's a little tricky. So we need to increment the counter. And then conditionally on the, on the data path output, then we need to copy values of index into min. So what's index reset? Zero. Good. What's index sub count? One. What about min load? Then, right? Good answer. So somehow we need to make sure that this min load only happens when the then signal is true. So we're going to use then as the bit that we send. Good. What about a load? Zero. B. Zero. And then count reset. OK. So now you'll understand why one hot encoding is nice. What's index reset? Come on, hurry up. S4. Good. That was easy, right? That's why one hot encoding is nice. What's index count? S3 or S0? Good. What's min load? S3 or then S0? Good. And then what's, so what are the rest of them? S2, right? Pretty easy, right? No K maps at all. So often if you do the one hot encoding, you have this table of control signals. You just write it down here done. It's very, very easy. That's for two flip flops, we saved ourselves a lot of time. If you want, you can go back and do this the hard way. OK. Why don't you use it all the time? Once in a while, you might want to have a more compact. If you really want to minimize your design, you know how to do it. But this is easier. Also, we have only five states, right? If you had a thousand states, maybe you don't want a thousand flip flops, right? It depends on the complexity of your system. The trade-off is still exponential, right? But the exponent here is tiny. So yeah. Why is what? S0? Because you have to be in this state in order to, yeah. So each of the states has its own S variable. And this one, we have to end it with then in order to make sure we're in copy when we apply the bit. All the other, well, not all of the other bits, but the three other states here. If we just put then in, we would have all of these four states included. And then output, you know, the comparator is always outputting 0 or 1, right? So we don't want to change states. I'm sorry. We don't want to change min just because the comparator happens to output of 1 bit in some random cycle. OK. So let's see. Next state logic is also pretty easy. But in order to figure it out, we have to look at the incoming arcs. So let's do that. So here's the weight state. What are the incoming arcs? So I didn't draw the self loop. But whenever you don't have a start signal, you stay in weight, which is an incoming arc. And it also comes from copy at the end of the loop. So that's on the done signal. So you've got two incoming arcs. So to write that, we'll say we're in the weight state S4. And we don't see the start signal. So S4 ended with start prime. Or we're in the copy state, which is S0, and we see the done signal. Those are the two cases in which we're going to move into the weight state. Now, again, it's really easy here because we just have to calculate the cases in which S4 is 1 in the next state, which means the incoming arcs. So this is the answer for S4 plus. So what about S3 plus? Start ended with something? S4. We want to make sure we're in weight. We don't want to just go there anytime we see a start signal. So S4 ended with start. Good. Is S3 plus? What about prep comes from a knit, right? And from copy, but only one that done signal is on. So what should S2 plus be? S3. Yeah, OK. So this is S3, right? Or S0 ended with done? Done not. Sorry. Good. So S2 plus. What about compare? Well, I did leave the self-loop out. So S2 will bring it from prep, or with S1 ended with what? And last. Then remember is the then statement in the original code. So it's the thing that changes if we find a smaller value. Changes men if we find a smaller value. All right. So copy then comes from compare when we see the last signal out of the counter, right? So what's the S0 plus? Last one and last. Good. OK. We're done. So this is a pretty complex, confusing design I know. But hopefully one through it, carefully enough that you feel like you understand it. It is in the notes. A lot of finite state machines will look like this. But kind of more importantly, this is what a computer is going to look like. And so we're going to break up our computer into a data path, which will have a bunch of components that can execute instructions. So instead of taking a fixed piece of code, we're going to have little pieces of code which logically do small amounts of processing. And those will be our instructions for our computer. And the finite state machine then, all it's going to do is it's going to say, OK, I'm a computer. I'll go fetch the instruction. You're going to store all those instructions in memory that'll be your program. So the finite state machine will go fetch an instruction for memory. Look at the instruction, figure out what you want it is to do. There'll be a representation for your instructions. And you're like, OK, I can do that. It'll go through a few states to execute that instruction. And then I'll start over. You know the instruction. Do what's thing. Oh, another instruction. And that's a computer. Just infinitely, finite state machine, fetch an instruction, decode it, execute it. Fetch it, decode it, execute it. That's right. So, like, uh. Hmm. That's it. Yeah, modern calculator will have a processor inside it. And the processor is doing that. It's running a little program that corresponds to watching key entries and displaying. The computer processor itself is based on FSM. The program is written as software as encoded instructions and stored in memory. And the processor is basically the finite state machine in the data path. Finite state machine will look at the instruction, right, fetch the instruction, look at it, decode it, and execute it. And then do that over and over again forever. I don't know. No, because next is my Norman model. But I want to just make sure if anyone has any questions about the design or anything, too. Any questions on that design? Feel like you understood it well enough? I know it's pretty fast, and problem. No, I mean, realistically, we couldn't ask you to design something that's complicated on an exam. I wish I could. But, but, you know, there are, so actually, OK, so in terms of the exam, the thing to look at is the examples from previous exams. A lot of it is analysis, right? So there is, I think at this point, we won't have time to cover it in class. But there's an example of analysis of a traffic light controller in the notes in section 3, 3 at the end. And, you know, part of the point of that is helping you to learn how to go look at the diagram and analyze it, understand what the human meanings are, and things like that. There's also a little bit, like, there's a little mistake there. So you want to go through, I mean, it's purposely, there's a mistake in the design. So you can do the analysis and understand how it's supposed to work and then understand what the issue is. And it will lead you through that. We often have that kind of thing in homeworks and exams, right? So, I mean, it can't be as complicated as the one in the notes that'll take you a while to work through. But, but you'll see, if you look under midterm 3, there's a whole bunch of old 190 problems that I solved for you. And so there's a couple of packets, one of the problems and one of solutions. And so I highly recommend people go through those. There aren't online tools for finite state machines yet, right? So look at all those examples, solve them. If you don't understand the solution, or you find some of the other old exams with examples, I'm sure you can, I'm happy to talk about them in office hours. You know, I'll come show me your answer and we'll talk about it. But, but I think, you know, do spend some time on it because we probably will have an analysis kind of question where we say, here's the state machine, you know, figure out what it does and figure out how it works, right? Which would be, you know, look at the data path and figure it out. Yeah. And on the final two, I mean, we're going to start looking at the LC3 design. And on the final, you'll be expected to understand that well enough to make use of it. But we have a few weeks for that. Yeah. All right. Yeah. Yeah. Yeah. Mm-hmm. Yeah. Yeah. So how do you figure out how to break things up? It's partly, again, dependent on the components. So what you can do is just try to map it onto the set of components you're thinking about using. And if you can't make it work in terms of control signals, then either you add components or you add states. Right. And you have to do one or the other. So it's up to you to make the match, right? But you have more freedom than I showed you here, right? Because you can also add components. You can make more sophisticated components. We could have started out, as I mentioned, on Monday, and said, oh, you want to compare 10 things? I know how to build a 10-offer and comparator. We're done. Right. Find a state machine. Run comparator. Get answer. Done. Right. We'll start over. OK. Does it make sense? OK. And I think we're out of time. If you want to ask more questions, come on down. Otherwise, we'll start by knowing men on Friday. Thanks."
    },
    {
        "ECE120-2016-10-21-LEC-24-slides.mp4": " example, just an example of how we build a finite state machine with components. And then what I'm going to do is actually we need to do memory before we look at a finite state machine with more components and think about separating, separating how we control those components from our finite state machine design, which will then take us into how we build a computer. But for that design, we want to have memory. So I thought maybe we'll move that forward. And then if we have extra time relative to the other other lectures, maybe we'll just do a finite state machine analysis example in class. But first, let's finish the vending machine. Then we'll talk for whatever we can get through out of these memory topics. So first, I'll give you an abstract model. Talk about SRAM cells. I'll tell you what's in a DRAM cell. There's a picture in the notes if you want to see one. Talk about how we build bits slices and do coincident selection. And then try state buffers. And eventually we'll look at bigger and wider memories. Be sure to start lab 9 early if you haven't started it. And when you go in the lab, don't let the sunshine in. Because your engineer is not for any other reason. No, remember that the optical sensors, if the sunshine hits them, might generate noise. And then people in the sunshine will have trouble with their lab. So try not to raise the blinds while people are trying to turn their lab. All right. So this is just a little review what we were building on Wednesday. So we have this vending machine that we wanted to use components like registers, adders, muxes, decoders. We built a new component called the priority encoder. That's not really when you need to know, but it is one that's used for various purposes in practice. And we'll do one module today specific to this design, basically just to translate our coin representation into a value in nickels. And so we can add that number in. I remember we decided to have the state of the system be some register, a six bit register, and which represents the number of nickels held by the machine out of money the users put in so far. And inputs were this coin input, which is a representation, three bit representation telling us what coin just came into the system. Product selection buttons for the three products that the user might want to buy, one, two, and three. And then the machine, generally its outputs, one coin except kind of like the one in the lab, but there's a more complex vending machine saying yes or no, I'll take this new coin or I won't. And if it's rejected, the coin mechanism will return the coin to the user. And then if we want to release a product, we've got three product release signals, our one or two or three. So we then decided or pointed out that since our finite state machines in our class, always have outputs dependent only on state that we wanted to calculate the outputs based on the current input and the current state. But then we just buffer those in flip flops or cycle those don't affect our state machine design, but it means they're delayed a little bit. And so we've got four flip flops that will basically just keep track of the release outputs and the accept output and hold those higher low for a cycle after the state in which they're created. We decided to prioritize our input events. We had 48 arcs we had to think about and we decided, well, let's make it easier on ourselves. So we'll just strictly prioritize the eight different types of input event and the one no input event. So we decided that purchases are the highest priority. So item three, item two, item one, and then coin inputs are all distinct. Right, the different patterns on the C input. And so we just prioritize purchases and then if there are no purchases, we'll do a coin input. And this was a specific example given three prices that are sitting in registers, a specific example of what our real state diagram next state table should look like. So we said, well, purchase three is the most important. So if I ask for item three by pushing button three, none of the other inputs matter. And in this case, I only had 50 nickels. I needed 60 to buy item three. And so I just sat in state 50. So we went through this table on Wednesday. So I won't go through everything again, but you can actually derive or given set of prices, you can derive a full next state table at this point. So that's where we were. All right, so. So now it's time to start thinking about how we're going to implement. We decided that purchases have priority. Right. So the first thing I want to do is say, well, how are we going to decide which purchase they ask for? And I remember I said, well, if they pick button three, I'm getting to know everything else. But if they don't pick button three and they pick button two, well, then I'll ignore button one and the coins. Right. And then button one has the lowest priority amongst the purchases. So to put those together, what I'm going to use is something called a priority encoder. So this kind of thing is actually used. For example, in deciding, well, if I have 10 devices that might need attention from my processor, and they can give me a one bit signal, hey, I need some attention at the disk drive or I need some attention at the printer or I need some attention for the mouse. Each of them gives me a one bit signal. I'll use a priority encoder to make a decision about which one the processor looks at first. So they're actually used and in situations like that. What we'll do is a four input priority encoder. So we only have three inputs we care about, but we'll just use one with four lines. And what it will produce is one signal P that says at least one of the inputs had a one. So whenever someone pushes a button, P will be one. So we'll put the buttons into these priority encoder inputs. And also the two bit signal encoding the highest priority active input. So it has four inputs. We'll call them 0, 1, 2, and 3. Surprise, surprise. And the output s will say 0, 1, 2, or 3 if P equals 1. Otherwise, we don't care what s is. So if they don't push any buttons, if all four inputs are 0, we should just ignore s. So let's write a truth table for that. So here's the truth table. So the first line says, well, if B3 is equal to 1, then I want P to be 1, because they pushed a button. And I want s to say, well, button 3 was pushed. And in that case, none of these others matter. B3 has the highest priority. The next line says, well, B3 was 0, B2 was pushed, then nothing else matters. I want P to be 1 still, and s should say number 2. Similarly, so forth and so on. So 3 and 2 are not pushed, but 1 is pushed, ignore button 0, say something was pushed. So P output is still 1, and here we say, well, button number 1 was the highest priority. And then this line says, OK, only button 1 was pushed. So we say, yes, I'm sorry, button 0. So a button was pushed, but it's number 0. And then last, if none of the buttons are pushed, P equals 0, and we don't care what s is. That s should be ignored. So there's our truth table. We can then copy that into K-maps. So here's K-map for P. So what are the loops? It's an easy one, right? There's a min term there. So here's some loops if you want to do as s, O, P, and you get that. So a pretty easy circuit. How about this one? Pretty easy also. So you guys know how to do this. OK, good. I'll skip this then. So this one is B3, B2. S0 is tiny bit. Where's the other one? The square around here wraps around good. OK, so if you write that one down, it's B3, or with B2 prime B1. OK, good. So there's an implementation. So not too hard. So this is a four-in-foot priority encoder with priority on the three. You can build a, you can build 16. You just figure out the equations. And it's pretty straightforward, as you saw. All right, so we can then plug that in. So this implementation now, this will only do purchases. So I want to build something that's only going to do purchases. We decided to remember we're going to use an adder. Hopefully this is legible. And people will not read this. I think you know. Yeah, that's good. OK. All right, so here's our register N in the middle. So that's our number of nickels. We've then got our priority encoder. We just looked that up here. So the buttons are coming into the priority encoder. They're producing the P signal down here and the S signal up here. Remember, this is the register N, the number of nickels. So up here, there are registers storing the prices. Remember, we said that instead of hard wiring specific prices, we would put each price into a register. So actually, these registers don't store P1, P2, and P3. What they store is negative P1, P2, and P3, so that we can simply feed them down here into an adder. So when we make a purchase, P will be one. But S will also decide which of the three registers gets forwarded through this mox. So you see P, I'm sorry, S here, is the select, is used as the select lines on this 401 mox, or set of 401 mox's, which then outputs the price corresponding to the item that was selected by pushing one of the buttons. So the priority encoder, if you push more than one button, will only give one. And S will say which one. So wait a minute. What happens if I don't push any buttons? What's S? What is 0 in the equations I gave you? But we said don't care. So some bits come out of there. The mox forwards one of these down to here. So we better make sure that if we don't have P equals 1, this output is ignored. Because we don't really, that was the way we implemented priority encoder. But if we go by one, who knows what'll come out if P equals 0? OK, so this adder then, whatever price comes out of here, will then go into the adder. You can see n is fed into the other part of the adder. So this adder now for a purchase will compute current number of nickels minus whatever price was selected. So the carry out then, since we're adding negative P1 to n, the carry out will equal 1 if and only if n is greater or equal to the price. So it's like a subtractor. So it'll overflow, meaning carry out as 1. These are unsigned values except we negated one of them if we have enough money. So if we have enough money, carry out will be 1. If we don't have enough money, carry out will be 0. So then if you look over here, we have an AND gate. So it says, well, if the carry out was 1, that means you had enough money to buy the thing you wanted to buy. But you also have to look at, well, did you try to buy something? Or if you didn't try to buy something, some garbage is coming out of this muck, some bits. So we don't really care what happened in this adder. We want to make sure we ignore it. So unless you tried to buy something, unless you actually pushed a button, P will be 0. This AND gate will produce 0. So if you did try to buy something, AND you had enough money inserted into the machine, R will be 1. So R means do we approve the request? Is it allowed? So R means request is approved. P is purchase requested. It says that one of the buttons was pushed. All right. So if R is 1, you'll see that R comes around here and controls this mucks right here. So what does this mucks do? If R is 0, which means either you didn't push a button or you didn't have enough money, so if R is 0, where does that one come from? Comes straight from N. So we stay in the same state. So if either of those conditions is true, we stay in the same state. On the other hand, if R is 1, well, that means you did push a button and you had enough money. So now the one input comes from the output of the adder. Well, that was N minus the price of the thing you wanted to buy. So now that's the right state to go into. That's fed back up into the register. So our next state is N minus P of whatever you tried to buy. All right. And then the last piece down here, you can see S, the thing that you picked, the item that you picked is coming down here to this decoder. The enable is enabled by R. So if R equals 0, no purchase made, because it was not approved, or because you didn't ask, then this decoder outputs all zeros. So you don't release anything. These are going into flip-flops, one that registers, that will then control the release signals in the next cycle. And so that's where we're storing our output bits. If the purchase is approved, meaning you tried to buy something and you had enough money, and we changed the state to reflect that, then this decoder will have 1, 1. And then the 1, 1 will correspond to the item that you bought. So one of the release signals will go out as a 1, and the item will drop out of the machine. And that'll be selected by S, yes, which is the output of the priority encoder. So if you push B1, B2, and B3, it'll say, OK, you get 3. And assuming you have enough money to buy 3, it'll take your money away, and it'll output a 1 on the 3 output of the decoder. Any other questions? Yeah. Yeah, so remember that we don't want our inputs to directly affect our outputs. And so we have to make a decision on the current state as to whether we're going to give them the product or not. So we make that decision, and that's r, right? But we can't just immediately give the r output. What we need to do is because we want to build machines that don't have inputs directly as a function of outputs, is we simply add flip plots after those outputs. So we're storing that output, which could have gone directly, but then it would have been a different kind of a finite state machine. And in our class, we're always only going to change the outputs and make them dependent on the state. So this becomes part of the state. We latch those output values. They're held high or low for a cycle, which sometimes is important. So in the lab machine, for example, right? If you don't latch the gate output, then it'll just go down and up. And so whether you accept or not won't matter, it'll be too short to actually control the mechanical gate. So here, it might also be important. So we decide it. We'll latch them into flip plots for that reason. Anything else? In real life, of course. That's why in an exam now, we wouldn't be that mean. But we have had a fair number of problems where we have to analyze things, maybe slightly less complex than this. Yeah, designing it, we might ask you to design part of it. The other problem is if we did a full design like this, there would be so many different answers, it would be nightmare to grade. So we might ask you to design part of this on an exam. There is actually, so under exam three, there's a bunch of old exam problems from on finite state machines. So you can see the kind of things that you'll be expected to do. All right, so I think I went through that one. All right, so now let's think about what can we do to add the ability to put money in the machine. This machine we built, well, it's kind of cool. It handles purchases, but you can't actually put any money into it, so how could you over buy anything? So let's figure out, what do we need to do to handle purchases? Well, the first thing is we've got this coin input. So we've got the adder. So when a coin's coming in, we can use that adder to add the current state to the value of the inserted coin. The adders are already there. So we might as well use it for that too. And then write the sum back to the register if the sum doesn't overflow. Remember that if the sum overflows, we're going to have to either take away their money or not take their coin. So we decide to be nice and not take their coin. But what is the value of an inserted coin? We only have this three-bit representation. So here's our three-bit representation. I showed you the table before, but before this was number of nickels. And now this is a five-bit unsigned number, which is the value of each coin in nickels. So this is the number that we want to add. We've got a six-bit adder. So we're going to have to zero extend this out one extra bit. But let's convert from these three bits into a value. So how do we do that? Well, it just came out. So here's B4. So there's our one loop. And here's the equation. There's B3. There's one loop. There's an equation. There's B2. There's one loop. There's an equation. So this is pretty straightforward. I'm going fast because on the harder came out, she told me it was too easy. So OK. So there's a big box for this one. So this is just C1 prime. And there's B0 with this. This one could be what? Yeah, it could be XOR. I just did the C2 prime C1. Here's the implementation using those equations. So down here, you could have replaced this with an XOR2, and then not had to use the inverter. But OK. So here's our coin value module. So this is specific to our FSM. It takes the representation that we were given of what coin is this and spits out a five-bit coin value in nickels. OK. So this is the kind of thing you did do on the midterm. So yeah, you would have this kind of problem. But until midterm three, we won't put it inside an FSM. All right. So the blue stuff is the new thing. So the black stuff is the old purchase only implementation. And so the blue color shows you what's been added. I know if you got the printed book, by the way, the blue doesn't show up too well. So you can look at the online version. You can see the colors. You want to see them. So what's in this diagram now? So up here is our coin value calculator. And you can see it's been zero extended. So this notation here, you can see this is five bits wide coming out of the coin value calculator. This is six bits wide going into the mucks here. The fifth bit five, so these are bits four to zero. Bit five is a zero. So this kind of notation here means put one zero in front of the other five bits. And that'll become the six bits. So you can see the bracketed bit indices there as notation. This mucks then decides, well, are we going to put in the price? Or are we going to put in the coin value? Because we're going to use our adder for both adding value as well as subtracting out purchase prices. So how do we decide which one to put in? Well, we have this purchase signal p. Remember, they have priority. So if you push a purchase button, you put a coin in. It just ignores your coin, sends it back to you, and the vending machine sends your coin back to you, and ignores it. So in this case, we want to just look at the purchase price. So if p is one, we take our price out of this mucks over here and forward that to the adder. But if p is zero, that means you didn't try to buy anything. So now we can look at the coin value and forward that to the adder. That gets added again into the current state, the number of nickels. And then comes down here to this mucks. So we have to decide, do we want to accept the coin? So how do we decide whether we accept the coin? We're adding the coin's value to the current state. So if we're going to be able to store the answer back, some has to fit in six bits. So how do we know? We'll just look at carry out. And if it overflows, carry out will be one. So if we get a one out of this adder, that will make this norgate go to zero. This norgate is generating the accept signal A. So if carry out is one, we have to reject the coin. Similarly, if they made a purchase, we always want to reject the coin. So if p equals one goes to this norgate, also outputs is zero. So the only time you accept a coin is you didn't try to buy something. And putting the coin in didn't overflow the sum. So if those two conditions are true, the norgate will give a one. And that will come down here and get latched into this one bit register, just a flip flop. One bit register A. So same reason as for the R outputs. We're going to hold it high for a second. All right. So there's a little bit of logic left down here. There's this thing. So what is this thing? So whether or not we now stay in the same state or not, depends on whether we're trying to make a purchase or trying to insert a coin. So in the case that we are trying to make a purchase, then this R signal might be high, in which case, that will go and control our mucks just the way it did before. So remember, in order for R to be high, p has to be one. So the only time this gate matters is when p equals one. And the only time this gate matters is when p equals zero because if p equals one, this gate outputs a zero. So that going into the orgate won't matter. So if p is zero, that's putting a coin in, no purchase. And so this gate then outputs except. And if we accept the coin, this orgate outputs a one. So this orgate is either saying, well, we either decided to allow the user to buy something or we decided to accept their coin. So those are the two cases where this mucks takes its input from the adder and routes that back to be our next state. In the case where either we said, no, you're not allowed to buy that thing, you don't have enough money. Or we said, we don't want your coin. This n input goes into zero input of the mucks. And we're picking zero so that goes back and we stay in the same state, same number of nipers. I think that's it. Yeah. Yeah. Yeah. So this this norgate basically is generating the accept signal. Right. You can see a is being latched out of this norgate. Right. So when do you accept a coin? Well, there are two conditions. First of all, we said purchases have priority. So if they try to make a purchase by pushing the button, then the answer is you never accept it. And so you can see priority encoder has the p output that says they pushed a button. Right. That comes down here to the norgate. So one input to a norgate means a zero output. So in that case, since p was one, if they were allowed to make the purchase, then then we'll still change the state to n minus whatever the current, whatever the price of the item they tried to buy. But if that purchase was rejected, we'll stay in state n. And similarly, if they didn't try to make a purchase, then this norgate reflects whether this carry out overflow or not. Under an overflow, that means we can't store the current state plus the value of the coin. And so we rejected and we stay in state n. Yeah. Yeah. So remember, we, what, yeah, exactly. So if we had, for example, 60 nickels already, and we tried to put a quarter in, well, we can't store the number 60 plus five is 65 in six bits. So we'd have to reject that point. And that would show up as a carry out, because you do a six bit add of 60 plus five, you get a carry out. Yeah. Yes, that's right. So, so if you don't push anything, what actually goes on? So P is zero, right? So you're picking the coin value calculator. Let me flip, see how quickly I can flip back. So maybe I played a little trick here, which is that when you put nothing in, you get the value zero out. Right? So I specified that in my K-Map. So that's definitely true out of our coin value calculator. So then the number zero comes down to the mox, P was zero, so we pick it, we add n plus zero that comes down here. And in that case, let's see what will happen. So no overflow and P was zero. So the norgate will give us a one. This will give us a one. We'll pick n plus zero. Go back to there. So yes. Yeah. So every cycle that will add n to zero and write it back. Yeah. A does not affect the coin value calculator at all. So the logic is the other way. So you, you look at the value of the coin, you see if adding the coin makes your amount stored overflow, which is down here, the accept signal. And that is then stored. That is sent back to the coin mechanism, which is responsible for returning the coin. If you say you don't want it. Yeah, just like in the, in the lab that you're building, there's a gate mechanism that you had nothing to do with. You control it. You didn't build it. And. So there's some mechanism that some other designer builds that says, I'm going to look at your a signal. And if you say, don't take this coin, I'm going to give them back the coin. And if you say, take the coin, I'm going to put it in my money box. Yeah, so that's, that's an output. And this one is an input from the, from probably the same mechanism that says they just put in this coin. It has this, this type. This is a, this is a, this is a, this is a, this is a, this is this type. This is, this is the analog of the T input, right? It's more general because we allow many different types of coins. And this is the analog of the a output in the lab. All right. So this is an output back to the mechanism like the gate in the lab. So they're held high for a cycle, higher low for a cycle. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. So a is controlling whether the mechanical system accepts or rejects the coin. And, and is, and is the memory in the finite state machine of how much, how many nickels we hold. And these are signals tell the mechanical system let go of that product. So they get it. So I have. So these are just your sub here. Okay. So, so yes. So when we talked about mucks is we talked about generalizing them. So you can see there's actually six inputs into each of these four for this four to one mucks. So in this diagram, this is actually six copies of a four to one mucks. And so anytime you see any time you see a mucks drawn with cross hatches on its inputs and outputs. That's multiple copies of that kind of mucks. Yeah. And this in particular would be six here. And if you wanted, if you wanted to make, you know, changes into eight bit price registers, eight bit nickel storage or whatever, then you would have eight boxes. So it's not much larger. Yeah. So I think the. Trick wise, I think it's basically to break it up. Right. So the. The way to the way to work through these things is to try to figure out the human meanings. Right. So usually there's some documentation on what the meanings are. And to logically break it up into pieces. So that's what I tried to do for you walking through it. Yeah. Yeah. Yeah. Yeah. Yes. This is one to one two to four decoder within an able. This is one six bit atter. You can build them anyway you want. This is six two to one boxes. This is six more to the one boxes. I mean, I showed you a gate diagram. So yeah, usually something like a priority in code or you can usually pull off the shelf. I mean, same thing for adders registers. Yeah, most of the things you've seen the implementations, right? You should know how they work. But but usually people will will provide these elements for you when you're building. Yeah. In fact, once you even get into three to five. I've mentioned this a couple times, but a lot of the most of the most of the building will be based on. On writing something like something similar to C code. Right. So you'll say, oh, add a and B. And it'll the tool will figure out that well, I mean an adder if you want me to add things. And so it'll put an adder down for you and route a and B into the adder. And then it'll, wherever you tell it to put the song, it'll route the output of the adder to that place. Okay. Those are saying that this line here is taking its low bits from these five and the high bit from that. Yeah. All right. So go into memory. So I had a little bit of a memory block trying to get into these slides. It will help. You guys can help me. Anyone? You're not that tired. I know it's Friday. Any other names? We're going to have a number of places. So I got a, b, c, o, d. Anyone else? Come on. I don't like those much. What else? E. Yeah. What else? Right on. That's six, right? Yeah. Okay. I think we're good. This might take you the rest of the hour. Really? Yeah. What? Did someone say bits? I heard someone say bits. I don't know. Bits. Really? You want to name things with bits? Really? I don't know. So our names will be 0, 0, 0, 0, 0. All right. All right. Fine. Do it your way. All right. So we'll use bits for names like you wanted. So we can probably build a circuit for that. Right. Now we have bits named things with bits. So let's. The circuit will let us read and write the bits stored in each of the 65,536 places. Right. So instead of having registers named a, b, c, 65,000 of them, and they'll have names like, I really don't want to say 0, 16 times. Imagine it. So a bunch of zeros or a bunch of ones or 0, 1, 0, 1. So every combination of bits, let's call it an address. Okay. So you got a 16-bit pattern. We'll call that an address. So we'll have two to the 16th different addresses. Right. And that'll let us name our all of our places. And at every address, we'll have 32 bits. And we'll call that the address ability. So here's how we're going to use it. So if we want to read one of the places, right? Each place is 32 bits. So if we want to read those bits and do something with them, then we're going to tell our circuit, well, here's the address of the bits that we want. Right. So we'll give it 16 bits. And we'll say, these are the bits that we want. Somewhere there's, you know, that'll name one of those places. Then we'll wait for those 32 bits to come out. That'll be a read. If you want to change the bits in one of those places, then we'll tell the circuit, here's the place. Here's the 16-bit address. And then we'll give it the 32 bits. And it'll go put those 32 bits, store them at that place. The one we name with the address. Oh, and we also need to tell the circuit, do you want to read or write? I need to say which one you want to do. So let's give these some, some IO names. So we'll say, well, the address will tell the circuit what we want to write to. Or read from, read or write with address, ADDR. When the data come out, we'll have some data outlines. When we want to write the bits, we also have to give the address. We can use the same bit in the same input lines. Right. It's just an address 16 bits. In the case we've been talking about. And then when we want to give the bits, we'll have some data input lines. And then we'll have a write name, or signal that says, either one wanted to do a write. In this case, write name will be one, or want to do a read, which case write name will be zero. All right. So here's a picture. Here's how we might draw it. We'll call it a memory. It has this one. I generalize the number of addresses and the number of the address ability of this memory. And so this one has two to the K addresses. So they're K address bits. So K could be 16, for example. And it has N bits at each address. So N could be 32, like we've been talking about. So that N bits at each place also means data input is N bits wide. And data output is N bits wide. And then it has this CS thing that we didn't talk about. There's write enable. There's CS. What CS? CS means chip select. So often with memories, we're going to make use of many memories at a time. So we have a special control. It's like enable on some of the other components we've looked at. It's a little stronger than that in the sense that if chip select is one, the memory is either going to do a reader write as we tell it to do. Right. So we say chip select is one. Right enable is zero. It'll do a read. Chip select is one. Right enable is one. It'll do a right. Chip select is zero. Right enables the don't care. It won't do anything. Okay. So if we turn chip select off, our memory will just not do anything. That's what it's for. That way we can, we can have multiple chips and then decide which one we want to take action. Based on the chip select. No, no. So that's. Yeah. So there's a good question. So the question is, you know, if I turn chip select off, does the memory just get erased? No, not at all. It just means that it's not currently active. It's stored bits are still there. Good question. Go ahead. The realistic answer is, is actually not sure. I think a lot of them are initialized to zero. I think when you power them on, they will, they'll do for the purpose of testing. They'll do some initialization and they'll end up all being zero bits. There may still be memories that are just random bits when you turn them on. But I think most of them will be when you power them on will be all zeros. Yeah. So they're more. Yes. Yes. Each, each memory will have its own chip select. Oh, that's a good question. Let me come back to that one. Yeah. So when does data out become available? So yeah, there's. It's kind of a complicated answer. So let me come back to that. So the memory we're going to use in our classes, random access memory or RAM. So you may have heard of RAM. So what does it mean? It means that you can read and write addresses in any order. And that more or less the time to access any address is the same. Okay. So this is as opposed to things like tape, right? Where one piece of the tape is next to the read head. And if you want to read other addresses, you have to turn the tape until you get close to that part of the tape. Okay. So those are serial memories. Random access memories. It doesn't matter what the address is. You can go read whatever address you want in any order, or more or less at the same same time access them. In our class, we're only going to look at volatile forms of memory. So what does volatile mean? That's the part where they lose their bits. So if you turn off the electrical power, all of the memories we talk about. All the bits are going to go away. But, but turning off chip select will not remove it. It's just turning off the. Okay. So there's two kinds we're going to care about. One is called static RAM. It uses the two inverter loop you've seen. Right. So if you remember when we talked about storing a bit, we drew a couple of inverters back to back. That stores a bit. That stores a bit in SRAM 2. And I'll show you exactly what that looks like in a minute. So those will keep their bits indefinitely as long as you keep them powered on. So as long as you give them electricity, they'll keep their bits forever. In contrast, there's something called dynamic RAM or DRAM. This has a capacitor to store a bit. And so there's a couple of charged plates, really tiny charge plates. There's some electrons on it. Remember, transistors don't really turn off. Transistor keeping the charge on those plates. They don't really turn off. So electrons can kind of go through the transistor even when it's supposed to be off. So eventually those bits on the capacitor will go away. Sorry, the electrons on the capacitor will go away and you lose your bit. So DRAM, the reason it's called dynamic is you have to rewrite it every so often. Where every so often is typically tens of milliseconds. And so you have to go rewrite every bit every so often. And so that's one issue with DRAM. I'll tell you more about it in a second as to why people use it because that just seems kind of like a hassle. But they're big big benefits to DRAM also. Both of these are volatile. So again, you turn them off, turn off the power, all the bits are gone. So S-harmon is faster uses the same semiconductor process as logic, which means you're designing a processor. You're designing the logic you've been working on for the last what eight or nine weeks. All of those are able to be on the same chip, right? But it's much less dense than DRAM. DRAM is slower and the refresh interferes with using it. If you have to refresh it, you might have to wait to be able to access it. But it uses a separate semiconductor process, okay? So there are different chips and not on the same chip usually. But it's much, much more dense. So you've more more bits for chip area. So what are they usually use? What are most real systems use? Well, both and other storage types as well. So where is S-RAM? S-RAM is close to your processor. It's on the same chip. Your cash is and things like that. Don't worry if you don't know what it cash is. So the memory close to the chip for fast use is S-RAM. The main memory of your computer, if you say, hey, my computer has 16 gigabytes. That's DRAM. You don't build usually 16 gigabytes of S-RAM. That costs a lot of money still. And it wouldn't be on the same chip. It would be a box. So some storage, fast storage companies might use that kind of thing. But of S-RAM. But a desktop or a laptop, this kind of size would be DRAM. So most systems often also have non-volatile memory, right? Your phone, your laptop, your desktop servers. They have their own non-volatile memories. So some are flash or solid state disks, magnetic storage or hard drives, optical storage, DVD drives. Often you have all three, right? So. All right. So what do you need to know in this memory stuff? So you need to know how to use memory. Right? So the interface we talked about a couple minutes ago. The terms we just talked about a little bit about how memories are built, which I'll show you shortly. So what S-RAM induced DRAM cells are inside the capacitor versus a double inverter loop. Use of decoders to select cells. I'll show you how that works. Coincident selection. I'll show you how that works also in a few slides. And then how to build bigger memories out of smaller ones. So if I give you a memory chip, can you put them together to build bigger memories? This is a common use. So we'll show you all of those things. What don't you need to know? Memory systems are analog circuits. So you really don't need to understand exactly how they work. I'll tell you a little bit about them and I'll star them as we talk about them. Star the slides that are extra content. But they're fundamentally their analog designs. So understanding exactly what's going on is beyond 120. And also the details of DRAM operation, even how you interface the DRAM. If you're interested, section 364 will give you a brief introduction. All right. So here is promised is the double inverter loop. So this should look familiar, at least the circle part of it. What you won't necessarily understand yet is, is well, we're using these n type MOSFETs to connect these to what we call bit lines. At the bit and bit prime, because they're going to be opposite values, because of the way the double inverter loop works. So we have those, the MOSFETs are then controlled by select. So when we turn on this select line, these two inverters are connected to the bit lines. And when we turn off select, we set it to zero. These two MOSFETs will turn off. And then this double inverter loop will just store a bit. So to write a bit, what do we do? So we hold these bit lines at opposite values. And then we turn on select. And we force these, we force these, these inverters to accept our new value. So this circuit does something that we've told you never, ever do. If you notice it. If I'm going to set bit to one, and this thing is a zero. It's not oscillating. It's just short, right? Because inside those, inside those inverters, we were wiring this thing to ground. And this thing we just said is wired to high voltage. So we turn this transistor on. We have a short here and a short over here. But I didn't, I didn't extend those. But at these points, we're actually creating shorts. So that's one of the reasons you've got to design these systems carefully. Thinking about well, exactly what's going on at the transistor level. You know, make sure these short circuits don't last very long, right? Because the short is going to generate power or get hot. So people have to think about this as an analog system. You don't just treat it as a digital system. Yes, yes. In murder, there's nothing, there's nothing mysterious here. This is exactly the way we showed in murder when we learned it the first time. I can, but I don't have a slide that does it. Let's do it after a class of work for you. So it's a major issue, right? Because you don't want to generate too much power. So the design, not to require too much power to store the bit. And you can do that by sizing transistors and using things like resistors in the right places. But it's an analog problem. It's not a digital problem at this point. I don't think you use two different selects. So the reason we don't add a bunch more transistors in general is because that would be bigger. So the more transistors you add, the bigger this cell is to store one bit. So there are ways and there are actually, this is the most common commercial cells. It's called a 60 cell. I have them on the other slide. You can add, you can add more transistors to try to eliminate some of these problems. But in the end, it's still an analog design problem. So there are, there are things you can try to do. But if you, if you do it by making like an 80 or a 12 T cell, then you've taken twice as much space for your one bit. And so it becomes less and less efficient. So there are some trade-offs there. But they're kind of outside the scope of 120 also. Yeah. Yeah. Yeah, a latch is much bigger. Right. So a latch was four nan gates and a inverter. No, as long as we drive it the right way, we do two nan gates. So that would be eight transistors there. So yeah, maybe I shouldn't overemphasize these. It's an analog design problem. So the way they build it, it's not that big of an issue. But you need to understand that you can't approach this as a digital design problem and just expect to put gates down. Because you won't be able to solve it correctly. So at that point, you need to understand, you know, transistor sizing, IV curves is a function of sizing and things. And it's well beyond the scope of 120. That was kind of my point. So don't worry too much about it. Just realize that it's more complicated than you will see here. And certainly more complicated than when you do the discussion section, you'll see a pretend version that you can, you can use, but it's all digital. So it's, it would be huge to do it that way. All right. So in order to read this bit, when ends up happening, again, it's analog, but you can, you can think, well, all I do is I make these connections. I leave these bit lines floating and then these inverters drive the bit lines either to zero one or to one zero, depending what bit is stored. In practice, these days on SRAM or DRAM, always on DRAM, but in the last 10 or 15 years on SRAM also, these lines are actually charged to VDD over two and precharged before you, before you turn select on. And then as there's something called a sense amplifier, which basically watches the voltage from the, from one bit line to the other. And as soon as it starts to drift away from zero, it pushes it all the way so that the voltage is digital zero one in one direction or the other. Well, digital one in one direction or the other. Yeah. No, it's mostly size. And then SRAM size is important. So here's my slide. So how many transistors is this? Six, right? So this is called a 6T cell. So you can add transistors, but if you add two more transistors, then you've got only. Let's see, it would, it would add 33% overhead, right? You've got about three quarters as many bits stored for the same area. And if you make it 12 transistors, you've got half as many bits. So the two shown to per and bird 60 cell. So it's good reliability, small size, and it's one of the most common and pretty good power to. So here. I think we're going to probably end up stopping soon. Let me talk a little bit about the bit slice. Yeah, I'll get about a minute. So this is a bit slice. So you'll see down here, I've labeled it with our abstract symbol symbolic memory labels. I'll walk through it next time, but this is how you could build, for example, a 16 address, one, one bit address ability memory. So you can see there's the analog logic over here. I think I did it in the next slide. So in this diagram, the select lines are vertical. The bit lines are now horizontal. And all of the cells are sharing one set of bit lines. So we're only going to read and write one cell at a time. And this over here is our sense amps and other analog circuits. So we're going to balance between the length of these, the length of these bit lines. So usually they'll be bigger. We'll have lots and lots of cells per bit slice. And then for that is this logic here is relatively expensive compared to the cells. So we want to drive as many cells as we can with one copy of this logic. So let me stop there and we'll pick it up on Monday. Thanks. Thanks for watching............."
    },
    {
        "ECE120-2016-11-07-LEC-31-slides.mp4": " Okay, wow, I'm loud. Okay, I think it's three. So let's go ahead and start. Okay, I think a good weekend. So midterm material three is over. So everything we talk about today is for the final but not for the midterm. Details, I'll go through that in a second, but details, it's probably best you look at the midterm three page because there's a little bit of midterm four or rather section four that we covered them last week that we're going to include on the midterm three just to kind of make it a little easier than having a full midterm on finite state machines honestly. So we're going to have the LC3 ISA, so doing things like decoding instructions, you'll need to do a midterm three for example. So today we're going to go through another example. How to type in a number. So say, well, how do we let the user sit down and type in a number? It'll come in and ask you from traps, one character at a time and we'll convert it into a two complement number. So we'll figure out how to do that. That'll be a big example. Then I want to spend a little time saying that computers are dumb just because it makes me feel good as a human. I'll give you some examples. We may or may not get to this today. Eventually by either today or Wednesday we'll talk about how we break down problems and we will give some examples of that too. And then we'll do another long example and then go into assemblers. That's kind of the next four or five lectures. I may add some more examples because the programming stuff before we go back and play with control units, we're going to spend another five lectures through all this week. Review session Monday. So in then two more lectures next week on assembly or LC3 binary and assembly programming. So third midterms coming soon next Tuesday night. I know you're all excited. You've been having so much fun with finding it state machines. So same rules as before same time. Places will be up on compass. If you need a conflict, do make sure to sign up today through the wiki if you didn't already do so. Coverage section 3.8. And then the left half of the terminology, which is LC3 I say, of annoyments, stuff like that. And then a few of the bullets which I copied into the midterm three page. So it's, you know, know how to decode LC3 binary instructions like we did last week. And look at those three details. All right. So review session on Monday just like before. So come prepared with questions and we'll do the same thing. I'll sit there. You tell me what you want to talk about. We'll vote on it. You'll vote on it. I promise not to vote. And then, well, it's not next week. You should vote this week. But then we'll do that just the same way. Okay. So vote tomorrow. Then vote again on Monday. All right. This slide, you know, where it is going to be there till Friday. So let's solve a problem. So yeah, I believe so. They usually try to. The question is, is Ada Caponew going to hold another review session for you? They usually try to do that for most of the core classes. So I believe they will. I don't, I don't have the time or place. My guess. The first two were exactly the same time and place relatively speaking, right? So it was Saturday. I think it was 2 to 4 p.m. But I'm not positive. If you look back at the lecture slides, I've put it in there. I think it's on the wiki too. So it's probably going to be Saturday, 2 to 4. And I think it was in 1013 B. So 1013 ECB rather. So probably all the same. But I'll tell you when I know. Yeah. Good question. So let's see. Yeah, I'll do that. I'll do the, the slide I had on resources again. I mean, it's things like, well, you can watch the video lectures. You can watch Professor Harmio's lectures. If you want to, you can go to the other review sessions too. All of the four lectures will have review sessions. So if you want more review, you can go to those. Ada Kapinus review session. Okay. So, so let's see how we can take a problem in human terms and translate that into LC3 instructions. So for this one, for the most part, I'm going to do it for you. I may ask you to help me out here in there. But for the most part, I'm going to show you how it's done. And then later we'll talk about how we do it. And then I'll, on the bigger example or another big example, I'll ask you to do it for me for the most part. So we're going to start by identifying, well, what do we need to keep track of? Okay. So I'll tell you what the task is. I'll actually do first. But then we'll say, well, what do we need to keep track of? Those are things we're going to put in registers, right? We'll find it. State machines. We had registers in a different sense. Now I mean registers in the register file. But when we were designing FSMs, we would identify information and then put it in registers encounters or state bits. And then we would figure out how we move between states. Here we're going to assign registers from the register file to those stored values, draw a flow chart for a code roughly with one box corresponding to one or two or three instructions. And then write those instructions in some human readable form and then convert them to biners. And so this program we're about to do is available to you on the web page. When I can bring it up, but it's the links page. So if you've got it bookmarked or something or type my name into Google, it'll take you to my homepage and then go to fall 16 120. At the bottom, there's a bunch of programs in LC3 or several programs in LC3. This is wonderful. So you can download it. You can run it in the lab if you want. Type in a number. One caveat if you run it in the lab, I forget which way, but I think it's the GUI that actually changes the character that gets pressed when you hit the enter key. So the code may not work in the GUI because we only check for one key. And it may be a different key that comes in from the GUI. I don't remember right now. So here's what we want to do though, which is, nothing user type in a number. So someone comes up and they're going to type in a number. Maybe there's a prompt, but we won't even print a prompt. The type of number from zero to three, two, seven, six, seven, using the keyboard. And when they're done typing their number, they'll press the enter key. So you can imagine why I picked three, two, seven, six, seven is the upper bound, right? Okay. Good. Yeah. I mean, it's the biggest two-s complement number. We can store in one memory location. So we're going to read in the number converted to two-s complement, store it in one memory location. And if the user does something crazy, like presses the letter L for the meta or something, we'll say you're a bad user and go away. Give them a error message. And if they type 100,000, then when they hit that last key, instead of 10,000, it becomes 100,000, we'll say you're a bad user, go away. And that's it. So we'll give them error messages to trade if they break the rules. So what do we need to store? Before we answer that question, I just kind of wanted to point out that, well, this is a lot like when we were developing finite state machines, right? In fact, you can think of a program as a finite state machine. Your state in that case will be your variables in a C program in LC3. It's going to be the things you put in registers or the bits you put in memory locations. So we need to think about, well, for this one, the keys are the inputs, including the Enter key, the error messages are the outputs. The type number typed is eventually read out. I mean, we'll put it in memory, but then if this were a bigger program, we'd take it out of memory and use it for something. So our program is kind of like a finite state machine. So what do we need to keep track of? Or what other values might we want to keep around in registers to solve this problem? So users going to be typing in a number. See, so they're going to press the key, right? So when they press a key, that's some number they're pressing. So maybe we need a place to keep track of that, right? So they're pressing key that are put that some more. But there's also some number they're typing. And so even when they're pressing, say, the third key, they've already pressed two, so we better know what they typed, right? So we better keep track of, well, what number did they type from their previous keystrokes? And so there's a couple of things. See, what else? How about FFD0? Do you like that number? I like that number. You know why? Now do you know why? So when we want to convert their ASCII keystrokes into, into choose complement, right? How will we do that? So there's a homework problem ages and ages ago, weeks and weeks in semester time. It's eons. Remember, we can subtract this number 30, right? So remember if we type a number, a digit and ASCII, it's from 300 for 0, 3, 1 hex, sorry, 300 hex for 0, 3, 1 hex for 1, and so forth up to 3, 9 hex for 9. So if we subtract 300 hex, that'll turn it into a two's complement number from 0 to 9, right? So this is the number we want to subtract if we negate that number, we get FFD0. So that's why. If we've done that with ads, we'd need three ad instructions, right? Remember that the LC3 is immediate ad operand, only goes to, it's a five bit, two's complement number. So the most you can subtract is 16 or 10 hex. So you'd have to have three separate ad instructions. So instead of doing that, we'll put FFD0 in a register and then we can use one ad instruction to subtract 30 hex when they want to convert. And then I also want to have a temporary register. You'll see it's useful. Sometimes I just want to do calculations and then throw them away, right? So when I'm doing comparisons, for example, I need to, I need to set the condition codes, but I don't need the answer. So I'll have a temporary register. So let's put the things we want to store into registers. So we know when we use the GetSewTrap 20 hex to read a character, the keystroke is going to come back in R0, right? So whenever we call the operating system and say, okay, let the user type something now, the answer is going to come back to us in R0. And we need to store that somewhere. So let's just keep it in R0, right? Why make troubles so we have to move it somewhere else? We're just say R0 is the key they've pressed. Okay, so that was pretty easy. R1 could be the current value of the number. R2 can hold this FFB0 constant and R3 can be our temporary. So it's pretty straightforward. As long as you only have a few values, we have eight registers. Remember not to use R7. It doesn't really matter which ones we pick. So another question before we go on. So this one I need to help with. So when the user presses a key and we're keeping track of the current number that they typed, how do we update it? So let me get, oops, sorry, I'm going to give you an example. So let's say that the user is pressed 3276. So the number they've typed so far is 3276. And then the user say types of five or something or seven. So now they've typed 32767. So how do we take the 3276 and the seven and combine them? Well, this is multiple, I don't think this is a multiply by a power of two. Multiply by 10. And then add this one, right? So let's see. So like that. Oh, yeah, that's okay. We'll figure that later. All right. So we have to multiply by 10 and have a new digit. Is that right? People agree with that? Maybe you already know how to multiply by 10. You could. Yes? That would be one answer. All right. So let's figure it out later. Let's do this flow chart. So I'll just draw a flow chart for you, but I'll put it together piece by piece. So when we start, the first thing we're going to do is initialize our variables. Generally speaking, anytime we start a program, when we have things we're storing, we need to think about all of them and think, well, do I need to put some specific number in that register before I start? Or can I just leave it as bits? Okay. So let's, we'll go through and do that. But first, let me, let me go through the whole flow chart. So this is the first piece as well. Let's make sure if we need to, we initialize any variables like R0 through R3. The next step then is, well, let's go to the keyboard or rather go to the OS and say, hey, let the user type of character. So once they type a character, then we have to ask, well, did they press the enter key? And if they press the enter key, then they're done typing. So we should store the number and finish. So if that answer is true, the key they pressed is enter, then we're going to store the number and then we're done. On the other hand, well, what if they didn't press enter? Well, if they didn't press enter, we have to ask, well, did they press a digit or not? Did they press something else? And if the answer is no, they didn't press the digit, well, then we should print the error message and then we're done. We're not going to just, we're not going to ask them to start over anything nice like that. We just quit. Very simple program. All right. If they do type a digit, then we have to do our multiply by 10 thing, add in the new digit and, oh, check for overflow. We said, well, if there was overflow, then we'll print an error message. And if there's no overflow, what's next? Read another one, write, but I'm type something else. Okay. So that's it. That's our whole flow chart. It's not, it's hard to cram into a PowerPoint slide. It looked a little nicer in paper, but hopefully it's not too hard to follow with the animations. Yeah. If the conversion with the new digit has caused overflow, yeah. Yeah. Because remember, we can only go up to 3, 2, 7, 6, 7. We'll go beyond that. We're not going to be able to store in one memory location. Anything else? All right. So here, now we're ready to write instructions. So we'll start with this one. So let's step back for a minute. Well, which ones do we need to initialize? So here's our table. So what about R0? Do we need to set that to anything? Why not? It's going to get filled in for us, right? We don't need to put any bits there because when we call the trap to get a key from the keyboard, that trap's going to overwrite whatever bits we have in our zero. So there's no point putting anything in there. So that'll get filled by Getse. What about R3? Just a temporary, right? So skip R3. Well, R2, we better set to FFD0, right? Our code's going to assume it's got that in there. So we better set that. Oh, what about this one? What should they set that to? Oh, it doesn't good. Took me several slides to figure that out. All right. All right. Fine. All right. So how do you figure that out? Well, you've got the rule that we developed earlier. And you say, well, when I start, if the first thing the user does is presses a key like five, then we want the new value of the five. So we need to solve this equation, right? Five is the thing we're going to calculate, the new value. And that'll be 10 times whatever we initialize current value to plus the key we pressed, which was five. So if you solve this equation, you get current value of 0 to 0. Right? So you want to initialize current value to 0 has a strange side effect that if they run your code, you immediately push enter, then you get the number zero, right? Which maybe you want to give them an error message on that. But I'll let you extend that in the code if you want to. So we'll initialize our one to zero. This code won't do it. There's a code on the website either one through it. So now we're actually ready to write some LC3 instructions. So how do I get a FFD0 into R2? Well, one way is to use a load instruction, right? It can put FFD0 somewhere in memory and then I can use an LD instruction to take it out of memory and copy it into R2. So let's use a load instruction. There it is, destination R2. And what's the offset? Yeah, we don't know where it is, right? Because it has to go after our program, but how big is our program? How many instructions is this going to take? We have no idea. Right? So we just leave a blank line and we'll come back to it and fill it in. Right? Because we don't know where it's supposed to go right now. So we'll leave a blank line in that code. So for R1, if we want to put zero in a register, we can use, for example, the AND instruction. Session? Oh, you could. Yeah, that's one idea, but I kind of have the same problem. It's a little easier. So I could build backwards knowing that this is at 3000 and anytime I need something, I could put something earlier and go and change the start of my program, make it earlier and earlier. One issue will be that when you load a program into the simulator, at least, the PC will get set to the start of your code. I'm sorry, not the server code. So the start of that block of bits. So if you set, for example, if you put it at 2FF, then when you loaded your program, the PC would be 2FF, not 3000 hex. So it's a little bit of a hassle with the tools we have. It's a perfectly valid way to do things, but it would be a little bit of a hassle with the tools. Yeah, good question though. Yeah. Yeah, so you can do that. We try to discourage you from interleaving code and data just because a human tends to get confused by the sort of thing, right? So it's good habit just to try to separate out your code and your data. And when you're really writing binary, it's a little bit hard, but as we get up into assembly language, it'll be much, much easier. And it's just good practice because when humans look at things, it's easier if you say, well, the data are in one part of my file and the code isn't another. It's a little easier for people to read and understand most of the time. Yeah, it's a good question though. I mean, sometimes that's not true. Sometimes there'll be data that are very tightly associated with a particular piece of code. And so those you might still put next to it, but literally putting, you know, okay, I need to load something. Let me just branch over it. That kind of thing, people try not to do. It's also extra instructions, right? It's an instruction you didn't need to execute. So your code will run a little more slowly because you did that. Does it make sense? Yeah, so that is what Sasha was saying is we could, our code's going to go down, right? Because so Sasha was saying we could put it at 2FFF, for example. And we could do that. It's a little bit of a hassle with the tools you're going to use in the lab. So I don't want to just, I don't want to encourage it because it might lead to confusion. So there's a continuous, there's a continuous set of bits. And so they have the tool has no way of knowing which things are data and which things are instruction. So it sets the PC when you load the continuous set of bits to point to the first set of the first word. So when you loaded your code, it would then the PC would point to your data. You'd have to change the PC before you ran your code. Okay. And I think the other thing is we're going to have lots of offsets and not all of them would benefit from the solution of saying, well, okay, let's put it back. We're also going to branches in the code, right? So we'll have to go to different pieces of code. Those we won't know where they are until we write them. So my point here is just to have these blanks because later once we've written the code, we're going to have to go do counting and fill in the offsets. So even though, yeah, we could fill this one in, we won't be able to fill them all in. So that's kind of the point. All right. So there's, so for our one, we'll use the AND instruction. So AND R1, R1 with number zero. So that'll force a zero into R1 and satisfy our initialization. Okay. So now we've finished initializing the variables. So we can move on and read a character. So to read a character, we just use trap 20, right? So 20 hex that is. So right, trap 20, get C, and then we'll get a character and bring it back in R0. It'll actually wait until the user presses a key. So our program will stall until the user's pressed a key. Then when it continues with the next instruction, there'll be a key and ASCII in R0. Keystroke in ASCII in R0. So there I want to do this. What is that? You want to know? And why would I want to do that? Yeah. So this one is the out trap. So that will actually send that key that they pressed back to the monitor and have it show up on the monitor. So when you read a character from the keyboard, it doesn't just echo to the monitor. If you wanted to write a video game or something, you don't want all the keys they're pressing to move whatever, you know, echoing back onto the monitor. Right? So it's a separate trap. But when they're typing a number, it's kind of nice if they can see what they type, right? So we're going to have an echo that key back to them so they can see it as they type it. So it's not necessary, right? We could make them type their number blind, but it's a nice thing to do to echo it. So all right. So that's reading the character. So now we need to check that character for enter. The enter character is, or the enter key produces ASCII could 10, number 10, the decimal 10. So R1 is the key pressed. So we're going to have, sorry, R0 is the key pressed. So we're going to use an add instruction and subtract 10. And where should I put the answer? Maybe R3, right? I don't need the answer for anything. I just need the condition code. So I'm going to throw the answer away. So I'm going to add R0 to negative 10 decimal and put the answer in R3. So now my condition codes are set, right? If they press the enter key, the zero condition code will be set. Otherwise, some other condition code will be set. So I can branch on negative, I'm sorry, branch on Z. That'll mean I'll go somewhere if they press the enter key. So where should I go? I don't know. We didn't write that code yet. Okay. So we have to leave it blank. That code's somewhere in the future. I mean, we could write that code next, but then we'd still have the same problem, right? We'd have to figure it out how to branch around that code. So we'll branch for when they press the enter key and we'll leave it blank. So remember, this instruction writes to R3. It writes to all of the bits of R3. So nothing reads R3 here. So whatever bits we're in R3 gets run away. Good question, but we never use the bits of R3. The first thing we do is throw them away. So there's no point in setting them to anything before. Yeah, yeah, we, that's, sorry, go back. That's next, right? Up here. Yeah. So I'm just going through the flow chart in some order, but definitely following the errors. Okay. So we did a branch. We got a blank label. So now what's next? We could go either way here, right? Because we made a decision. We decided to go this way to is a digit. This code will have to come back later and write this code and fill in the offset. So let's go up and check if it is a digit. So how do we check if it's a digit? So let's see. So R2 has negative ASCII digit zero, FFD zero in it. So I could, for example, convert convert the key to binary, right? So we've got R0. So let's convert that R0 into a binary number. And if it's a digit, it'll be zero to nine. So how do we convert it? Well, we just add R0 and R2 and store it back in R0. So now R0 will have an, if they type a digit, it'll have a number from zero to nine. If they didn't type a digit, if, for example, they press something, if the answer is below zero, that wasn't a digit, right? So we can branch negative and we know it's not a digit and we can go somewhere. We don't know where, right? Because we didn't write that code yet. So we have a blank. Okay. Now at this point, R0 holds the original ASCII character minus 30 hex, right? So if that was a digit, it's zero to nine. If it was less than zero, we already went away. So now it has to be anything from zero up to nine, but it could be bigger, right? It could be they pressed a letter and now it's bigger than nine. So we need to figure out, well, they press something like a letter, something beyond the digit nine in the ASCII sequence or the ASCII code. So to do that, we could say subtract 10 and discard the result. And so we'll add R3, we'll throw away the result, destination register R3. So we'll take what's in R0 now, add negative 10 to it. That'll produce a number from negative 10 up to negative one for digits, a negative number. And for non-digits, it'll be zero or positive, right? So we can then say branch on zero or positive somewhere. Okay. Does that make sense? We have a simple copy, what you think. It's multiplied by 10. Okay, you want to switch. X86. So it would be good for three in anyone. All right. So here's some code. It's good, right? Okay, it all works. All right, let's try again. So let me, let's use V to denote the original value of R1. This thing appears a comment. So anything with semicolon is a comment. You'll know and love them because they'll explain what's really going on without you having to look at bits, at least hopefully, where they'll match. So here's the first instruction. So it says, well, let's take R1, that's our current value, and add it to itself. So we'll call that V. So now after this instruction, I have V plus V, I put that in R3. All right. So now after this instruction executes, R3 has 2V. All right. The next instruction was add R3 to itself, put the answer back in R3. So R3 had 2V before this instruction. So 2V plus 2V is what? 4V. Good. Okay. So then we have this instruction, and that's R3, which is 4V, and R1, which is still V, right? We didn't change R1. So 5V. And then we have this instruction. What's the end? 10V? Good. So now you happy? All right. You're adding 10 times. So that would have been a fine answer. All they six more instructions. No big deal. If on the other hand, you wanted to add a thousand, then do it my way, please. A thousand times, you mean? Yeah. Yeah, you can do this generally with any multiplication. It's basically just shifting and adding. Okay. Yeah. The number of lines should be roughly the number of bits in the thing you're multiplying plus the number of 1 bits, roughly, and then minus 1. All right. So now we need to add the new digit in. So that's pretty easy. The new digit remembers in R0, and then our current value times 10 is in R1. So to add the new digit, just right back into R1, R1 plus R0. We already converted it earlier when we were checking the bounds to make sure it was a digit. We also converted it from ASCII into binary, right? Into a 2-complement, 0 to 9. Okay. So we can just add it in from R0 and R1. R1 remembers 10V at this point. So this is our final equation value. We store it back into R1, now we've updated current value with the new key. Right? Yeah. No. Okay. Let me go back to where you can see the code. Yeah, we threw that number away. Right? And that was important. We didn't want to have to add 10 back to it. Yeah. So when we checked the upper bound, we did the calculation, but we threw away the answer. We just used the Z and P conditions to check if it was above the digit nine. Yeah. But the answer, this one stayed the same, R0 stayed the same. So it still has our digit, which we know was a digit now from 0 to 9 in 2-complement. Okay. All right. So now we can check for overflow. Well, okay. We can't really. So for example, you know, the first thing we did was was add. Right? So if we had, let's see, let me think for a second, if we had 10,000 and we multiplied by 10 and added 0, let's say, then we'd have 100,000. And the answer is always correct mod 2 to the 16th. Right? So if you subtract 65,536 from 100,000, you get something, actually, is that, yeah, maybe that's too big. So 90, 90,000 or so, right? It's still a positive number, unfortunately. So if you wait until the end of the computation, there's no easy way to check for overflow. So what you have to do is you have to check basically after each of the ads. So for some number, you're typing each of those ad instructions, you have to branch if it becomes negative, right? It's overflowed if you add those two positive or non-negative numbers and then they become a negative number. So it's easy to check. We have to check after each of the five ads. So the code online actually does all of those checks for you, but you can't wait till the end. You have to do it in the middle. And so rather than adding all of those instructions, we'll just skip the overflow check here. And so in class, we're not going to do it. But the code that I've given you online does all of the checking and error message printing. So if we're going to skip the overflow check, it's time to then just go get another digit, right? So what kind of branch should I use to go get another digit? So in this case, I always want to go get another digit, right? Yeah, we did nothing to allow them to type a negative sign. Yeah, and in fact, we said that the range would be limited to 0 to 32767. So they could try to type some, if they were to try to type, for example, 40,000, one could have allowed them to then store that as an negative number, 40,000, whatever that is interpreted as a two-seater complement as a 16-inch value, right? But we didn't. We decided that would instead print the overflow message. And that's what will happen if you run the code that is online. Okay, so let's just use an unconditional branch, right? We always want to go back. So we'll say, okay, BRNCP, and then we'll figure out the offset later. So this part over here, we're going to leave on the webpage. We didn't do it. But we need to store the number. So we can use an ST instruction to store it nearby. The number is in R1. So source registers are 1. Where to store it? Again, we don't know the offset yet. So leave it blank. And then we're done. Except we have a couple of, well, first a halt trap. Right, so we want to stop our program. So trap 25x to halt it. And then we need a couple of things for data, right? So we need FFD0. So let's just put that in memory here. And then we also need a place to store our number. So let's like a little place there for our number. So that's it. That's our program. And we have all those blank lines. Yeah, you ready? Were you going to say bits? I know, I'm sorry. Don't worry. One day we'll get to bits. All right, so there's that one up there. Where's that going? I wanted to put FFD0 in R2, right? Where's FFD0? Oh, it's down here. Okay, so there should go from here to there. Where's the PC when I execute this load? 2001. Good. Okay, so there's PC. All right, I gotta put my coffee down. This is hard. All right, so starting from here, you have one, two, feel free to count along. Three, four, five, six, seven, eight. Don't get too excited. Nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen. No, I'm trying to trick me. All right, so that's eleven hacks, right? So eleven. Okay, good. We're not done. Seventeen is eleven hacks. The one is sixteen and the other one is one, sixteen plus one is seventeen. Instead of writing number seventeen, I don't know, because we're going to change into bits. So converting, I mean at some point, it's much easier for me to convert from hacks into binary. So I try to go from decimal through hacks into binary. Why is the offset seventeen? That was the counting part. We counted. Yeah, but the offset, so remember in the load, we're going to do PC relative addressing. So we'll use the PC, which points here, and add seventeen to it, eleven hacks. So if you add eleven hacks, you get three, twelve. Okay, so we could subtract, but it's much more fun to count. And actually subtracting, I don't know, I always find it hard, unless I use the nine's complement. All right, so where is this branch? So this was the case where we didn't get it. No, sorry, this was the Enter key, right? So this should store our answer. So where is that? Yeah, this is the code to store the answer, right? So we want this branch to go here, and where's the PC for three thousand five? Three thousand six. Good. Okay, so we're ready to count. One, so we started, this is zero, right? So if we set it to zero, it would just come to this add instruction. So one, two, three, four, five, six, seven, eight, nine, ten. Okay, that's XA, right? Yeah, okay. All right, this one, what is this? This is checking our digit, right? So if this is negative, this is not a digit, so I'm going to make that come down to here. But I'll imagine I wrote my air handling code afterwards. We're not actually going to write it. It's in the, it's in the code online, but we're not going to write it in this code. So let's see, so PC is where? Three thousand eight. Okay, so one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve. Let's see, right? You notice I'm getting better at counting already? All right, this one was also air checking. So I'm going to cheat a little bit. Let's see, so this is two down, and so if I subtract two from this offset, I should still get the right answer, right? So 12 minus two is ten, which is A hex. Okay, all right, what about this one? Where does this go? So that's our branch to go get another character, right? Up to here, three thousand two. This is reading a character, so should go up here. Okay, good. So PC is there. So starting from here, I've got negative one, negative two, negative three, negative four, negative five, negative six, negative seven, negative eight, negative nine, negative ten, negative eleven, negative twelve, negative thirteen, negative fourteen. Okay, so I'll write that this way, X negative E. Unfortunately, the negative XE doesn't actually work in the assembly, so, so put that there. And then this one is easy, right? So where is this supposed to go? There's a place down here, right? So we wanted to go there, and a PC is where. Are you getting tired of counting? I think this is the most fun we've had all semester. Okay, fine, two. Okay, so we're done. Now we can write some bits, right? Oh wait, there's a bug. We forgot the overflow. Okay, let's go do the counting again, sorry. Yeah, now you know how much fun it'll be. Okay, so if you make any, if you have any bugs or anything, like you need, you realize you're, you left out one ad, then you have to go recount and re-calibrate, right? So it's really kind of a pain. You'll get tired of it soon, if you're not already tired of it. So here's the first instruction. This notation, by the way, is assembly code, I think I mentioned that before. So it's very human friendly, but we need to turn this into bits, right? Because the computer only understands bits. So what is this opcode? LD, you know, 0, 0, okay, and then that opcode has two fields, right? So the first one, we want it to be R2. So what are we right here? 0, 0, 0, and then what are we right here? Okay, do you get it right? Oh, so, all right. Yeah, the, as I think I said last time, you know, once you type all these in, so a couple notes. So one, when you type them in, include the spaces in your program because you want to make it easy to read, right? For yourself, as well as people who are grading it or whatever, right? So just include the spaces and add a comment, the semi-colon thing. I'll actually show you an example in a second. You can use the assembly notation, you can use RTL notation, whatever, just make it clear what those bits were supposed to do. So I'd like something like this, right? And so forth, I just the rest of the code. Your program, by the way, starts with a starting address. So this is 3000 in hex, or rather in binary, there's 3000 in hex over there to explain it to the humans. The other, the other comment is, even after you've done it this way, you're very prone to typing one instead of 0 in vice versa or leaving out a 0 or something. The tool will warn you if you don't have 16 bits, but if you manage to transpose digits or something, it can't, it doesn't know, right? If you have 16, it just says, okay, great. But what you can do is then once you run it, you can take it into the simulator and you can list it and make sure that the instructions that it shows you are the instructions you meant to happen. And it will show you, well, it'll show you hacks, but it'll also show you assembly code. So. And if it does something strange, like turn one of your instructions into a dot fill, that means it wasn't a valid instruction. So usually it'll show you instructions, but for 16 bit values that don't correspond to real instructions, it'll do dot fill or something else when you list it. Okay, so one more, and then we'll we'll just let you do the rest. So here's an end instruction. What's the op code? 0, 1, 0, 1. And so, and has a couple of a few fields always, right? It has a destination register. So what is that one? 0, 0, 1. And then source register, 1, 0, 0, 1. And then which mode? The one immediate mode, right? So once we have immediate mode, then there's a five bit two's complement field. That's the last field. And what should we put in there? A bunch of zeros. Good. Right? So there's our last or a second instruction. And I'll leave the rest for you. So I think you can manage it. Or you can just look it up. We have the code online. If you want, if you want the exercise, though, you know, do go through and change a few of them and you can compare it with the results in the code. Right? So you will have to do this at some point, both in the homework. You would have one exercise this week, but you'll have more in the future, but then also in the final. So in the in the midterm is just decoding. But in the final and that'll be encoding as well. All right. Any questions on the example before we continue? You like the name. I like it too. So the handout I gave you, which I didn't bring with me, but that sheet with the data path and the finance state machine and the encoding diagram with all the RTL, that's exactly what you will get on the midterm three and on the final. So if you want to know, do I have it or not? Just look on that sheet. It's also on the on the wiki. If you lost it, it's under resources, LC3 sheet or something like that. And so that way if there's anything that's not on there that you want, you can add it to your crib sheet. Okay. So computers are done. So think way way back to the first day of class. I mentioned church during hypothesis, which tells us that anything a human can can compute a computer can also compute and vice versa. And so you might think, so what's the difference? What's the difference between humans and computers? They're they're equivalent. So here's the answer. Humans are smart. Computers are dumb. So what is this? Can you do that one? Anyone? 42. Good. All right. Computers can't do that. Seriously, computers can't do that. So it's very difficult to do that in fact. And what you did is your brain recognizes digits because you think whatever I scribbled up there probably has to make some kind of sense if I'm asking you to think about it, right? And then you say, oh, it kind of looks like digits and oh, it looks like 19 plus 23. And I know how to do that. Yeah, it's 42. But no one seems to know how to explain that to a computer. I mean, a lot of things our brains can do. We don't know how to systematically solve. And so because no one can get a computer to do things like that quickly, we can we can put things like that up and call them captures. And then if it happens quickly, if we get an answer quickly to, well, what text is here? You know, solve some little problem or do something like that in fuzzy bizarre looking text. Usually that means there's a human doing that as opposed to a computer robot who just wants to create lots of accounts on your website. So that kind of technique is just an example of many kinds of things that somehow human brains do really well and quickly, but we still don't know how to describe it. So and computers can't figure out themselves. So if a computer is going to do it, some human has to figure out how to do it systematically and break it down to the level that a computer can also do it. So I may have said, and I might say in the future something like, oh, the LC3 only understands two's complement. So, you know, what does that mean? LC3 is not human. LC3 understands nothing. It's a computer. It just bits. So what am I trying to say if I say something like that? Well, the LC3 hardware and instructions that architecture have a bunch of fields that our two's complement fields and the hardware has a bunch of sine extensions, right? So part of the LC3 ISA interprets bits as two's complement values, right? When we add an immediate value, when we add an immediate value, when we add a PC relative offset, right? All of those are two's complement values and they're interpreted as such because of the definition of the ISA and because of the hardware in the in the data path. On the flip side, when I say it only understands two's complement, what I mean is well, if you want to do floating point, good luck, right? You're going to have to write all of that in software. There's nothing in the LC3 instructions that architecture to help you. It is complete, right? You can do anything. You can do any Boolean expression and so forth, but any other data type, you have to translate operations on those data types into instructions. So you have to write software to do those things. So here's an example of a software representation. So over here in memory, I've shown you three addresses. One of them has an ASCII one digit. One of them has an ASCII nine digit and then the last one has an ASCII null, which is just a zero. This is often how we store strings in memory. So if I want to store the string one nine, then I would put the one nine and the null in consecutive memory locations. And then when I wanted to talk about this string, I would just tell you, okay, my string is an address 4012 hex. And if you wanted to read it, you'd go to 4012 and you'd look at the memory and it's like, oh, there's a one. And then you'd look at the next location and say, oh, there's a nine. And then you'd look at the next location and say, oh, okay, there's a null, that's the end. All right, so if I wanted a longer string, I'd use more memory locations and so forth. So that's a string. So here's another string. What is it? 23, right? Okay, good. So say that the LC3 does this. So you tell the LC3, okay, this is string one, it's 4012. So put 4012 in R1 and string two is 7196. So put that in R2 and then add them. What's R3? B1a8. If you tell the LC3 to add 216 bit numbers, it adds the 216 bit numbers, right? It doesn't know what they're meant to be. So what started B1a8? Bits, good answer. Bits. So unfortunately, you know, I've actually met quite a few people who have never seen representations and don't know how computers work and they make this kind of mistake in the programming languages and then they're just baffled. I don't know why doesn't that work? I told you to add my two strings. Oh, I need your help. I pushed it out. Which one's the biggest? This one here? This is the biggest of these three? No, this is 41,062. I guess you're probably right. Okay. What's the smallest? So that's the smallest and then that's one's the middle. You sure? You think that? Are you sure? Maybe double check my kind of strange. Really? Okay. So you, because the computer said this is the smallest and this one's the biggest. Alright, let's put them side by side. Alright. What's bigger? 49. Good luck on the midterm. Alright. Yeah. So 9874 is the biggest, huh? Okay. Okay. So computer one, students, how about these two? Let's see. So 4 is equal to 4. 1 is equal to 1. What about comma and 3? So comma, comma is smaller than 3. So the middle one is 41321 and then the biggest one is, I'm sorry, the smallest one is this one here, 41962. So it seems the computer is right. Yeah. So it turns out if you sort strings and ask the order, then that's the kind of answer you get. Okay. So you might think, well, okay, that's cute. Kind of silly example, but yeah, whatever. So take a look at the index."
    },
    {
        "ECE120-2016-09-16-LEC-11-slides-varodayan.mp4": " I'm covering for Professor Lameda today. I don't know where he is, but I think he's not in the country. So, you may, some of you may know me. I teach the 1 p.m. lecture of this class. So you might have seen me in office hours. You might know me as an academic advisor as well. So, anyway, I'll try to do my best to cover what he wanted me to cover. And so, these are the topics for today. So, as I understand it, you did a little bit on K-Maps last time. But we'll do a few more examples. And then move to the connection between the SOPs and POS to two-level logic. We'll do a kind of digression on optimization of different circuits and what that actually means. And I don't know how far we'll get into this stuff. But before we begin, let me see. I'm a little bit disoriented with these slides. Let's see, before we begin or after we begin. Okay, yes. Reminders about the exam next week. Right? So, exams 7 to 8.30 p.m. Unless you're taking the conflict, the specific time and the location of your exam have been uploaded into COMPLIS. I believe it's where you check your grades. You'll be able to check the location and time of your exam. We'll be doing a review in class. Well, Professor Lumeta will be back here on Monday doing a review in this class for the exam. Each of the instructors will do a review. But this weekend, on Saturday 2 to 4 p.m. There is an 8-cap in U review, which is done by students as a service to other students. As such, we in the class do not endorse it. Right? Because it's whatever they decide to present and if they are wrong, it's not bad. But on Sunday, our undergraduate assistants in this class, you know, hired by us, will also be doing a review session 2 to 4 p.m. again in this building. So all the details about that are posted on the course webpage under exams. And actually, Professor Lumeta did want me to point this page out to you again. Right? So all the details for the review sessions, the exam time itself, the contents of the exam. It seems that and practice, practice problems as well as links to old exams, some of which have solutions. Okay. There's also the page above it, exam. So he told me that someone asked the question, what can you bring into the exam? Is that right? So it's all specified on this page. But in particular, it's a closed book exam. No calculators or other electronic devices. What you can bring is one let usize sheet of paper with handwritten notes on both sides. Right? And so there are a number of things that you might want to jot down on those two sides that you can bring to the exam. Yes, Rahul. So you're not going to be able to bring in just the files of the order. Well, you can not bring a piece of paper as well. And you will not be forced to have a piece of paper. So yes. Okay. Any other questions though about the logistics of the exam? Yes. Yeah, no calculators on this test. For the homework, there are definitely some questions that require a calculator. You can expect that similar questions on the exam will be set up so that you don't need to, you know, raise two to the 10 power. Oh, to the 10 power sign to two to the 16th power or something like that. Yes. There will be an example we printed with one sided. So we encourage you to use the back side of the exam. And general advice. If you have scratch work, you can note it down in the sections where it is so that the greater can find it. Otherwise, you know, it's lost and we cannot grade it. There should be enough space on that to do your work. Right. Yes. The ASCII table will be provided to you if necessary. Yes. So you don't need to, that's one thing you don't need to put on your age sheet. That would be a waste of space and a waste of time to handwrite it. Thank you for asking that. Yes. How many questions can I answer that question? Six, there are six problems on the test. Yeah. And you have one and a half hours. Maybe the last question. Yes. Hexidescent values are pretty easy to remember, but it's a, that's certainly a good thing to put on your age sheet. Right. So because it's also something easy to get wrong. All right. Very last question. I think we give both both both characters and that the ASCII table includes both characters and hexadecimal. Yeah. Yeah. It does. You know, you will be given a table that you can use that the question, you know, in the way that a question would want you to use it. That's what a thing is pointless to memorize and also pointless to write down on an HE. We'll provide it to you. Okay. So good. Good. I hope that clarifies what you need to prepare for the exam. Okay. So back to back to slides. Let's see what's up next. Okay. So you did cover K maps in at least you had an introduction to K maps and and the goal of a K map. A K map is just a tool. I can't know map is just a tool to basically minimize bullion functions or another bullion function is just another way of expressing a logic circuit made of and or and not gate. And so the way this tool works is that given a K map, you're trying to create. You know, look at the ones in the in the grid and group them together in a minimal number of loops and each loop should be as big as it possibly can so that you cover all ones. And the result will be an optimal sum of products expression according to in some sense, the area that such a circuit would occupy. So let's do a few examples. That's what Professor Lumeaux wanted me to do. He actually pointed me towards his tool. But you know, the tool is good because it generates random examples, but I also don't like making mistakes. So I prepared examples that I know exactly how to do ahead of time. So that I won't be caught by surprise. And these are actually the examples that I present in my in my section. So I just pulled up. So let me just make sure. And I guess I'm going to have you propose how to do this. Not Rahul because he was at my lecture and he saw this exact example. Just to make sure that you know, you are way where I think you are. So here is a four four variable function. And this is the K map for it. So I hope you understand that a K map is no different from a truth table, right. A four variable truth table has 16 rows. And those rows are represented as 16 cells here. So remember, I'm trying to cover all the ones using loops of allowable size, right. Loops that have a dimension of powers of two. I cover all the ones with as large loops as possible using as few loops as possible. So where is what's a loop I could draw? Can someone describe that? Yes. Right. Right. These middle two columns. Right. So that isn't allowable loop because it is a. It's four by two. So that that that four by two dimension means that it can be represented by a product term. A product of literals term. And it's called. So any loop that covers ones is called an implicant. Right. And this one is a prime implicant because it doesn't get any bigger than this. If you make it any bigger, you start to include zeros. Right. So for example, this little guy here, these two together, that's also an implicant. But it's not a prime implicant because it can grow to this big one. It can be totally covered by by the bigger one. So is there another implicant that I should identify here right right here in front of the top of corner. That right. The two ones in the top left corner. All right. So that's definitely an implicant because it covers one. But is it a prime implicant? No, this one can grow. Right. You can grow it to the square, which is an allowable size. Right. So you can grow to the square. Can we grow the square any bigger? Right. So it's not right to grow the square to a two by three rectangle. That's not. That's not an allowable size. Yes question. Right. Okay. So this is this is great. So these are my notes. So this is new new stuff for you guys. I mean, you probably saw this in a different form with hypercubes and stuff. Basically, so I did I did this example in my section where if you start out with the function, you guys probably already know how to fill out a truth table right row by row. You figure out where the zeros and one goes. So to fill out the corresponding. So this is a map is no different from filling out a truth table, but there are shortcuts with the came up. Right. So if we're looking at say this term imagine this was empty in my class, this would have started out empty and empty grid. This term, this term turns to one if B is zero and D is zero. That's exactly when this turns to one. So B is zero corresponds to the two to the so this is a B over here. This is a equals zero B equals zero equals one and so on. So this row has B equals zero and this row has B equals zero. Right. So that's the B equals zero case. But I also need D to be zero and it turns out D is this column corresponding to that zero and this column corresponding to that zero. So the top of those two is this two by two here, the full corners, which is if you wrap it around is it's a two by two square. Right. So so in this full by in this full variable grid. So if you have a product of two elements, you're going to get four ones that corresponds to four ones either in a two by two grid or a one by four like an entire row or an entire column four by one. So in similar reasons, every kind of product term that you get is going to end up with a shape that has that's one of these sizes. Right. So no three basically when you so that's that's why when we're going the other way, we have to make sure we draw loops that correspond to these sizes so that we get terms like this. That example should show you that wrapping around works to. And so why do we want we want the biggest ones that we want the biggest loops that we can make because the biggest loops use the fewest literals. You can see this big loop here is just one literal, whereas the small loop, which is just two ones uses the most literals in the end. And you want the fewest loops altogether because each loop corresponds to a term. Right. So you want to you want to minimize the, you know, the number of terms and the number of literals within each term to make a simplified expression. Okay. So back to back to the example. So yeah, what remains now is to so both of these are prime implicants, right, because they cannot go any bigger. We also check whether they're essential. I don't know if this was brought up, but an essential prime implicant is a prime implicant that has certain cells in it, certain ones in it that are not covered by anything else. So, so this one is essential because it has these two ones which are not covered by by the other prime implicants. Right. So, so this one is needed and this one is needed to because this covers a bunch of ones as well. So now it's a matter of me writing down the terms that go with this. So how about we start with the biggest one. Can anyone tell me what what term I should write down that corresponds to making all these eight ones. Okay. A few people call it out. It's it's Z. Right. So if you're not catching on. Let me tell you why. Right. So the ones in here. They don't depend on w and x because you can see w and x can take all different values in here and it doesn't depend on why because why is zero or one. But what it does depend on is Z. Z equals one for this entire column and this entire column. Right. So this is this is represented by Z. So, one is a different shape. It's two by two. And if we look at this, this, these ones belong to the w being zero. Right. These two rows intersected with the wise being zero. So these two columns. It gives you those four ones over there. So, let me come back to your question. So I'm going to say or w equals zero is not w and not y. Okay. So not w not y gives you this square. And now if you all them together. You get the all these ones. Right. Because either this is true. Either Z is true giving you all these ones or not why not not w not wise true giving you these ones. So, you still have your question. No, no, then so in strange situations. Actually, I have an example about that one and I show you that. So, so I had this example. The same grid on the left and the right. And it turns out that there are several prime applicants here. Right. So this cannot grow any bigger. This cannot grow any bigger. But nor can this one or this one. So those are the five prime applicants that can be drawn in this pattern. But to identify the essential ones only this one and this one is essential because this one has these three ones uncovered by anything else. This guy has this one uncovered by anything else. The others are not essential because the green one in the middle is covered by the one on the left in the green one is covered by that one. The one on the right is covered by that one. Right. So if I only take the essential prime applicants. I just get this in this. I still have some ones uncovered. So I have to look at my other prime applicants and try to cover those two ones as efficiently as possible. As you can see, I would just use I would just use the green one. Yes question. Yeah, I don't. Yes, I mean, yes, you are looking for. No, no, that's also wrong. Kind of hard to put into words and it's to even think about implicants, essential implicants, primal, it's a little bit overkill. If you do enough examples, you'll get you'll get a hunch. I think my next example. So maybe I'll make this my last example shows you that overlap is actually good sometimes. You want overlap sometimes and other times overlap is wasteful. So it's not that's probably not a good way to think about. All right. So here's another example again for variables. Can anyone tell me one of the prime implicants. All right. I think you answered the question before but I'll let you do it again. Good. For corners is a favorite right because it's one that favorite. I'm going to say favorite when exam questions are made. It's a favorite. So for corners is a two by two pattern and this one cannot grow any bigger. And then another. I mean, clearly these ones need to be dealt with somehow. How should I group those ones together? Yes. The entire row. So let me come back to this overlap question. Right. I could just do these two. No overlaps. But this can grow bigger. And if I grow bigger, it does overlap with the other one. But bigger is better. In this case, because when you have a larger. A larger loop, you express it with fewer literals in the end expression. Right. So we're about to write down what this is. Right. So what is this is true. If w equals zero and x equals zero. Right. So actually that's not w. Not x to make that to make these row of ones. If I just wanted to specify this to these two, I'd say not w not x. Z. Right. Z equals one. But I don't need that Z there. So this in this case, I want to make it bigger. So looking at overlap is not really helpful. So that gives me that row. And then the four corners. If I look in terms of rows, that's when x equals zero. Right. So not x. But I also have to intersect that with the first row and the first and the last. First column and last column. So Z equals zero. Not not Z. Okay. So there's a lot more to, I mean, there's a lot more to say about. K maps, but I think that will come later. We'll talk about don't cares. Actually, I think that's on the schedule for Wednesday after the exam. So you'll get a lot more practice with K maps. So so hopefully you you understood what I'm talking about today. You'll get much more practice at this. So don't stress out too much. Yes. There's definitely other ways to write this. So this is what let me emphasize that this is the minimal. So I think that's the key expression. Right. There are POS expert. There's a way of doing minimal POS expressions by looping the zeros. I'm not sure if that was covered in this class. I haven't covered it in my class yet. So by looping the zeros, you can kind of think about things and exactly the dual way like complimentary way and get a minimal POS and sometimes a minimal POS will be more efficient than the minimal SOP. And sometimes there'll be a minimal way which is neither POS or SOP. And came up and are going to help you find that. Right. So. There's a lot more subtlety to this than than even what I'm showing you. But this is a handy tool to get a minimal SOP or a minimal POS. Okay. Yeah. I don't want to do the next example. So I should point out that notation is slightly different. So I noticed this with Professor Lumeta. So what I would write here in this example is, what would I write? Right. B, B D here and AC up here. But Professor Lumeta does like he indicates that the B is one in these two rows. Right. So that's why I know the B comes first and the D is one in these two rows. So that's the D comes second and likewise, right up for the C in the a. So just a difference of notation. The industry doesn't do came apps came apps are a teaching tool and they're really fun to make questions about they're really fun to solve to. But came apps don't really extend well to more than four variables. And if you were designing something in industry with four variables. Probably need to find another job. That's not that's not interesting. So the way to do it in industry is to use software and you learn a lot about that in EC 385 like you'll be designing more complex stuff. I don't actually know a lot about what it's they don't do it optimally they use churistics because it's a really hard optimization problem. So they do good enough instead of perfect and they they may use the hypercube as some kind of data structure underlying all that. Okay. So where are we did we cover this we covered this. No, where are we? Okay. So. So s. O. P. I mean, so came apps what I just showed you gets you a minimal form, which is an optimal S. O. P. expression where we care about the the area right we're trying to minimize the area but minimizing the area of the circuit is not the only possible metric right. We could also minimize for the speed of the circuit. So the speed of the second let me see if that comes next. Right. So apparently you've already learned that the speed of a second has to do with the number of gates that between any of the inputs and the outputs right to the maximum number of gates along the chain from input to output is a rough is a rough approximation for the delay. So. And actually we're going to assume that the complement operation does not require a delay. There's a reason for that which you'll see in a few weeks that we usually get if we have X. We usually have not X somewhere else in the circuit. So we don't need to create it with a gate. It's already there somewhere. So if you only have only allowed one gate delay what what functions can you implement. I guess this is a question for you. So you're only allowed to use one gate basically. What can you implement? Nand and nor actually that's that's right. So you can implement nand and nor because those are like the basic gates. A not is kind of you can make a not out of the nand and nor so that's what's being said here. The one input nand is a not a one input nor is a not so you know very simple very simple functions. So you know a single man is a kind of a trivial S.O.P. Expression right because a single man does that make sense. Single man is an S.O.P. Expression and a POS expression. What's meant by that. Let me write that down somewhere so I can make sense of this. I just know this is that's kind of a way of thing to say. An and what is a man. That's a man. I kind of disagree that this is S.O.P. or POS. Anyway. Not. I'm not sure what he means by that. Okay. Perhaps I'll skip over this slide. I'm not really sure what the what the message is. All right. All right. The most functions. I think this is this is this is this I believe most functions cannot be expressed as a single man or no gate. Okay. So I think we hit we dealt with a very simple case and made some claims about it, which I wasn't sure about. So but how fast is an S.O.P. Expression? How many gate delays in an S.O.P. Expression? Remember this is you know if you think about the expression itself, it's a sum of product terms right each of the product terms is and is an and gate right. So you have a whole array of and gates for each of the product and then you all them together right. So it's actually only two delays a bank of and gates all connected to an all gate. Right. So it's two gate delays and and followed by an or. Okay. And the any not gates we just ignore because we assume we have the complemented inputs for free. So it's just two gate delays. But if you remember when we talked about CMOS and an all were not fundamental right the fundamental gates that we we had were NAND and all so is it right to say that they're two gate delays because you know might be a little bit more than that. So let's explore that question. If we have an S.O.P. Expression and we can only implement it with NAND and nor how many gate delays does it take. So two gate delays with and or how many gate delays with NAND and nor. Well it turns out that we're going to have to do a little bit of math here. You're going to have to use a formula called the Morgan law and we'll see this a lot in this class which says that. And is actually so a b at the man of a and b is actually the or of not a and not b. So you can replace the man operation with an or operation as long as you invert or complement the inputs before you use them. So it's actually a nor operation which is or followed by a not is the same as using or using and with complemented inputs. So you first complement a compliment b and them together. This is the same thing as nor. So if you want to prove this it's pretty easy. Why don't I actually do that. So let's prove one version of demogem's law. Okay. So I'm actually I'll make a truth table out of this. So what I want to do is prove that a nand b is the same as not a or with not b right that's and all I have to do is. By brute force look at every single case is only four cases here because a and b can only take four different combinations of values. So we know that the meaning of nand is you know you take a and b and complement it so a and b would be all zeros with a one here so nand would be all ones with a zero. So what I want to show is that you get the same pattern in this column over here. So you know I'm going to do some intermediate steps here not a is just the opposite of the a column. Not b is the opposite of the b column. And now I'm oring these together so to make you know to to an or is equal to one if either or both of the inputs is equal to one. So you can see that the first three. The first three or one here because we got one or one one or zero zero one and it's only here that you get a zero. So this is a proof that a nand b is is this is the same as this is a proof of the Morgan's law right we just check every single case. So. So that's what that's what he's talking about here you can do the other proof you can do the other demogins law proof and you can actually do this for more than two variables as well right so the man to three inputs is just the or of the complemented inputs. Alright so why are we doing this we were trying to compare and and or to nands and nords we're trying to establish a relationship and so this math tells us that there is a relationship. And this is just what I just said actually I should doing this this is what I when I just said right man is the same as or on the compliments of inputs nor is the same as and on the compliments of inputs. So what's neat is that we can express this graphically right and this is a little complicated but but and can be turned into nor right this part is nor if we compliment the inputs and or can be converted into man if we compliment the inputs right these bubbles kind of mean compliment right so. These are not real symbols like you wouldn't see them in a circuit diagram just for convenience we're just putting little bubbles on the input right there. So if we have an s.o.p. Okay if we have an s.o.p. expression it can be written as a bunch of and a bank of and remember all connected to an all gate and we said there are two gate delays right with two gate delays in this one gate here one gate here but we want to turn all of these into nands or nords. Because nands and nords are fundamental in terms of the underlying transistors so what can we do is this is this animated right we're going to use the Morgan's law and what we can do is we're look at the all gate and we know that all gates can be replaced by a nand as long as we invert the inputs. Alright so we've got these these little bubbles here into a nand gate so we got a bank of and gates some extra inverters and and an and gate but what is an and gate followed by an inverter. That's a man itself so you can basically slide slide these bubbles over to here that one there that one there and what you end up with I think this is an animation as well. Is a bank of nand gates followed by a nand gate okay so what you have is you converted the and all structure into a nand nand structure and this is still two gate delays right and this is based two gate delays based on nands and nands are simpler than and in or in terms of underlying transistors. So that's a neat thing and you'll be expected to really understand that right right so this was the punch line we can build any s op function instead of using ads and or so we just use only at only nands okay we use only nands to build the entire structure and it's still two gate delays of nand. Yes we don't need naws to yeah it turns out that our construction didn't use naws now if you start with a p os instead of an s op so I don't know if this is an off topic now but if you start with a p os then you start with all gates here and an and gate there and then you would convert the and gate here. Into a nor and then you would get naws so a p os becomes nor logic and s op becomes nand logic I'm sure you'll explore this if not in class in your homework you'll be doing these conversions right and that's exactly what comes next so great question right so you can use two levels of nand to build an s op expression you can do the same thing. For a p os expression two levels of nor okay and so any p os expression also requires two gate delays nor and nor assuming that the complemented inputs are free they don't cost any gate delays and later as I said later in the class you'll see why they considered free because we'll get them for free. Okay so how do you make a p os expression using a minimal care p os expression we talked about using k maps to find minimal s op expressions so what we did before was we tried to make big loops with ones in them right and that led to a minimal s op expression. If you start with the same k map you can look for zeros and try to make big loops out of the zeros just the same operation and each of those loops will well each of those loops one correspond to a maximum single zero correspond to a maximum but a loop will correspond to a sum term. Okay so do we have examples of that okay maybe I should do an example here agree I don't see an example coming up so let's go back to this and see if I can do a good example here okay so. So let's let's look at this this picture again right so suppose I want to loop the zeros together optimally i'll do it's a bit quick here's one loop that we could do of zeros to cover zeros and here's another loop to cover zeros so I think this is the optimal way to cover the zeros with two loops so. The question will be if I want to write f of x y z as a product of sums what is the sum that goes with this loop it's actually a pretty trivial sum it this becomes zero when x becomes one this becomes zero when x becomes one I have to get this right sometimes I get confused so I think that's a sum term x. Right. Or is it not x i'm confused I haven't prepared this I'm going on the fly right x x equals one makes this zero and so I should do not x to make it one. I'm a little confused let me see whether this gets the right answer so if it let's see if x is equal to zero. X is equal to if x is equal to one this becomes zero and it makes the whole thing zero because I'm going to multiply it with other stuff so actually it's a. You have to go and find the value of x and then invert the term when you find the the sum terms it's a there's like one more step of thinking than then finding the product terms you got to invert a little bit so this one for instance is zero when when w is equal to one so I need a not w in there not a w but a not w. Or when z is equal to one so that's not z. And so this is the so this is the product of some expression so it's a little bit harder to think about I think you get practice with it on the homework and you should also reason about it but actually it's pretty we haven't learned Boolean expressions yet but if you could factor this expression you get this expression you turns out that you can you'll see that soon so they're actually the same it turns out it turns out to be really easy to see that this is the same as this as long as you can factor out not x. Okay so that was an example I'm sorry I didn't prepare that one so I wasn't back clear about it. Let's see but this yeah this this this this warning here is exactly what was tripping me up right the maximum has all variables complemented relative to the mentor and so the same you know the in other words the product. But the the sum term has all variables complemented relative to the product term as well so if you have a box corresponding to mintem a b not c that's equal to one when a equal to one b equals one and c equals zero if you take the or of those same variables but each complemented that is equal to zero in the same place so the same cells correspond to mintems like this but max terms with the complemented inputs that that's the tricky part and the part I was tripping on. Okay how am I doing I'm actually really slow but that's okay because Professor Lumetters ahead of everyone else. So right so to find that this is the I did this approach right to find the ps form POS form create loops find the prime influence and essential prime influence it's just around the zeros instead of the ones and then build up your POS expression by multiplying those those sums together right make sure that you don't forget to complement the literals because of the kind of the duality between SOP and POS and then it's a each loop is a sum and you multiply them together again examples will be you know the best way to understand this right so what gives a better area SOP or POS well it depends on the function right so if we go back to the example that I had which one is better I guess that I guess I would say this one is better this one requires an AND gate and AND gate and an all gate but this one requires just an and all gate and one AND gate right so this one is slightly better than that but in general it totally depends right it's there's no general rule depends on the situation as to which one is better and in fact neither maybe the best neither of them may be the best there may be an entirely different solution that is that is better than the SOP the middle SOP and the minimal POS so this brings us to this topic of Pareto optimization and as you can see with the star here it's it's not actually going to be tested in this class is just additional information so it's kind of good that in the last you know seven minutes I can kind of basically describe the idea quickly so what happens in this situation when you have a task to do and you come up with a bunch of different solutions how you decide which ones are better than the other ones right so in this scenario here you're an intern you're designing some hardware to execute dense neural networks whatever they are right so you're trying to optimize your design and you have two metrics let's say your boss says it's going to be small and so you have a score of precise one to a hundred where one is the smallest 100 is a large size and you have a delay as well right and so the delay can have a score from one to a hundred small numbers are better in both metrics smaller better so if you have a design called X let a of X be the area and d of X be the delay so if you have two designs how do you choose between them what's more important area or delay well it depends I don't know which one is better you know so it depends on the context whether area is more important delays more important so one way to handle this and I'm just going to kind of skip through most of this is to create a waiting factor to wait whether area is more important than delay or not right so make a big make a function like this and and try to optimize this function right but that's going to depend on the context it's going to depend on your engineering judgment but how do you pick the waiting right so it depends on judgment and you may not be even if you are the engineer working on this you may not be the one to have the judgment that might be like a more of a managerial call than like an intern and interns job right so what do you do if you don't know what's what's better so if you're if you only have two options just tell your manager both of them and let let you know let let your manager decide but what if you have like 10,000 different options right you've created them algorithmically right you you have different parameters that you can change and you can it just becomes a huge number of possibilities do you report all of them to your manager no you're going to have a pretty annoyed manager so so what can you do right so I think some of them you can rule out immediately right so suppose you have a design X and Y where the area of A is better than the area of Y and the delay of sorry the area of X is better than the area of Y and the delay of X is better than the delay of Y right so what does that tell you why is out of contention right so X is better and so in this context what we say is that design Y is dominated by design X in particular it's dominated by design X right so this is just an example with two metrics if there are N metrics then why must be worse than X in all dimensions right to be perado dominated so yeah as we said anything that is perado dominated by another solution can be discarded and only the designs that are not perado dominated by other designs need to be retained and presented you know to your manager the remaining designs form what's called a perado curve and if you take some e-con classes you also learn you know about this concept of perado so if this is the space of all designs and I guess let's say this is the area score and this is the delay score right the ones towards the origin are better than the ones away from the origin but in particular if we look at solution P we can see that P dominates all these points right so if you if you found a solution P those can be discarded right and so if you do that with with all the points what you find out is that you get left with these several possibilities that that are not dominated by each other you can sort of see this is the perado curve that you get right so they all represent different trade offs between minimizing area and minimizing delay and so these are the ones which need further consideration right so the point is in many design environments whether it's hardware design or any kind of design problem the designer and undertakes this exploration tasks right so there are a bunch of parameters area speed for example you generate a bunch of solutions and then you trim your solutions by using perado dominance you throw away the ones that are definitely worse than some solution and and then you show your boss the surface the perado this is a if you have three dimensions like area delay and power consumption instead of having a single curve in two dimensions you'll have a surface in three dimensions a surface of possible good solutions okay so I think the next topic is Boolean properties I'll let Professor Lumeta take it from there are there any questions in the last couple of minutes about the exam or about what we talked about today yes Raul okay so you're asking how do how do things get minimized I mean there are a lot of different ways and a lot of different like you know the transistors can get better the designs can get better and so on but I think we shouldn't just restrict ourselves to area and delay there are questions of reliability or verifiability like the does this thing actually work so the cost right that does that how much money you want to pay your engineers so they do a good job how many engineers do you want to hire so there are a lot of considerations it's very complicated out there in the real world okay all right all right so when is the undergraduate of the the review sessions are there is one tomorrow at there's one tomorrow at 2 to 4 p.m. in 10 13 ECB and that is done by Ada Capignou so it's not official and then there is the official undergraduate session on Sunday same time same place to the 4 p.m. 10 13 ECB and then of course on Monday you have your lecture again for review so there's plenty of review sessions and down the bottom it actually says that for the Sunday session the TA the UA will be talking about the fall 2013 exam so you can practice that exam you can you know after you practice the exam you can look at the solutions and then you can come and ask questions about it in the review session as well you you you you you you you you you you you you you"
    },
    {
        "ECE120-2016-11-11-LEC-33-slides-start-at-11.5-min.mp4": " you you you you you you you you you you will now So, the next lecture is just seem to be off. So, rather than just stand around for another 20 minutes, we'll just go to chalkboard. All right. So, last time we talked about this letter decomposition. So, the idea remember was we want to have a string. And we want to turn our string. So, the task is turn a string into a histogram. By counting letters. So, we want to have a list of case. And counting all the non letters in the string as well. So, we wanted to just go through the string. We had a few different algorithms. So, one algorithm, for example, was. If we can set each letter. And non letters. Non letters being one category. For each character in the string. So, we could set some sum to zero here. If the character matches the letter or the non letter. And then set some to some plus one. And then when you're done looking at the whole string. Then you can print or save. The sum as that particular letter or as the all of the letters. So, this is the way we typically do it as humans. If we looked at a short string. I'd say, well, I want to look for a's. I just look at the whole string. See how many a's I see that report that number. On the other hand, if we wanted to do patent battel, we decided we might like to do something a little different. Instead, which would be something like the following. So, take a 27 bin histogram, fill it up with zeros. And then go through the go through the book once. Go through the big string once. Look at each character. Decide what kind of character it is if it's a particular letter or non letter. So, we're going to go through the one to the right bin. So, for each character in the string. Increment the appropriate bin for that character. So, this we called algorithm to. I won't write algorithm three. This one we call algorithm one. And then we talked for a little while about the differences between them in terms of amount of time spent memory required things like that. We're actually going to implement this one. The reason is mostly I wanted to show you. Show you how some of the control works. And as we're doing the systematic decomposition. I wanted to. I wanted to be able to make use of conditional structures repeatedly in terms of classifying these these characters. So, we'll make use of that. I'm going to try to turn this back on and see if it works. So, now it's going to take. Take my space away. That's convenient. Well, let me try to keep talking with half of a board. Sorry about this. No crime is fled to China. So, we can't try to down. I feel crime design is building. The mic doesn't work unless the system's on. So, if I'm not talking loud enough, tell me. I'm not talking about the mic anymore. It's on actually. But until the system turns on, which takes another five minutes or something, it won't pick up the mic. All right. So, the reason I wanted to pick that problem was again, I mostly wanted to show you a complex control decision using conditionals. And. Let's see if it'll. No, it's not going to let me. Let me plug this one back in and see if it. See if it will switch over for me. All right. So, oh, was it the mic? That's the mic, right? So, already our high level diagram gives us the first step of the decomposition. Right? So, we said, well, first we need to initialize the histogram. We also need to initialize some registers. So, we haven't talked about register usage yet. All right. How we'll use the registers. This seems to be failing again. This thing you've been trying to turn on. Not as far as I can tell. So, I think I'm going to toss the screen up. And if you can get it to work, then great. And we'll bring it back down. But otherwise, I will just continue to work on the chart. I am on the left. But I'm going to get the screen out of the way. Yeah. If you make it live, then we'll go to that. But otherwise, it's okay. All right. So, remember with the algorithm we're picking, we've already got this sequential decomposition and implicit in the code, the pseudo code we wrote. Right? We said, well, first we're going to initialize, then we're going to go through, oh. Apparently, I'm not good with technology. What did you do? All right. Nice. Yeah, yeah. I want to. Okay. We're good then. Yep. Okay. Good, good, good. Thank you, sir. Is this live? Can you hear me? Or should I? Maybe if I'm flattened this up, it'll be better. All right. Sorry. I will flip back. Sorry for the mental burp, but I want to cover this briefly. So we're going to spend a second going over through administrative. So in addition to all of section three eight and the left half of the terms, these were the bullets. I put them on the web page two, but reading and understanding programs in LC3 binary. And then also being able to explain basic organization. So, the one-noiming machine and things like that. Right. And the basic steps of instruction processing. Mostly like I said, when we when we discussed it in class, mostly fetching decode, but having some idea of what those things are. This one, I just really wanted to read type. I'm sorry. Yes, absolutely. That's all in that's all in the summary section three eight. All of section three is about the FSM. So yes, absolutely. That's on the midterm. These were extra bullets that were not in section three because we have a week that is moving from section four of the class to section three. So the topics for the midterm or that list, which matches the list, identically matches the list on the wiki. So, but I wanted to give it to you in class of this once. All right. So this was review. That was a third algorithm. The answer to. All right. Already then so there is our first step that we talked about. So we can also break the counting down. That's already also in the pseudo code, right? So when we did the pseudo code, we we said, well, we're going to walk over all of the characters in the string. So we can walk over the characters in the string. When do we stop? Well, at the end of the string, the end of the string we said is defined by a null character asking null, which is just a zero, right? So when we find a zero, that means we're done with the string, then we've counted all the characters we can finish. Otherwise, we need to count one character from the string and then keep going. All right. So how do we count one character? Well, we have to do two different things. So we're going to use another sequential decomposition. One of the things that just figure out what the bin is and increment it. So increment one bin in the histogram. But then we also have to move our pointer forward, right? We have to get ready to handle the next character in the string after we count this one. So we're going to increment the pointer also. So that'll look like this, just another sequential decomposition. Yes, we'll have those two buckets. And then we can start breaking down this one, right? This was the complex one. You know, how do I know if something's a letter or not a letter? How do I know which bin to increment? Well, I have to look at the data, right? So how can I do that? So we're going to have to use conditional construct somehow. We certainly don't want to have 128 different options, right? We don't want to say, well, if it's in the first half, we'll do this. In other words, that'd be kind of painful. So let's try to make it a little simpler. Let's take a look at the ASCII sequence. So this is the ASCII table. I've broken it up into five regions. So the blue regions are the letters, right? The left blue region is the uppercase letters. The right blue region is the lowercase letters. And then all the other numbers are not letters. So all the other things are what we would want to count in our non letters bin. So all we really have to do is break things up along these vertical lines, right? So our conditions can be can be based on these vertical lines. And that'll let us separate non letters from letters. They're just breaking up into the blue and green regions. So for example, if we look at the character in the character is less than the letter A, and ASCII, well, then it's never a letter, right? So we can compare with the letter A, capital letter A. And if we find that the answer is less than A, we can go increment the non letter bin right away. And so that's one thing we can do. So we'll say, well, here's a conditional. Is the letter less than A? If so, increment the non alphabet. Otherwise, it's something A or greater. So count something A or greater. Now I have to figure out how to do that. So now the A or greater part, we know it's not here. And because we already made that comparison. So what's left? Well, these four regions. So let's go ahead and handle capital letters next. So what we'll do is we'll now compare with Z. We'll compare with capital Z to a conditional based on capital Z. And if it's less or equal to capital Z, then that means it's a letter. Because we know it's not over here. We've already handled that case. So we'll break this box that was on the right into this conditional structure. We'll say, well, is the character greater than capital Z? If it is, we still don't know what kind of thing it is. So we'll just put a box. It says, oh, somehow we'll figure out how to count something greater than capital Z. But if it's less or equal, if this condition is false, if the, if the character is less or equal to capital Z, well, then we know it's a letter. So then we just go and increment one of the letter bins, whatever the letter is. So mark that as increment alpha. Makes sense? So now we've done handle that region. We know the characters at least this left bracket. So what's left is these three regions. So where should I split? Where should I make my condition? Maybe a little letter A this time, right? Okay. Good. So let's handle the middle region. So break the character greater than Z box into another conditional, a third conditional. Say, well, is the character less than little A? If it is looking back at this diagram, if it's less than little A, and I know it's not down here, because I've already taken all those characters out, then I know it's in this region. And if it's in the middle region, the middle green region, then it's not a letter. So I can increment the non alpha benefit. This condition is true. The condition is false. I still don't know if it's a letter, right? It might be past the big, or little Z. So I just say, well, count character greater or equal to little A. So then one step left, which is split these two regions, right? So I'll use little Z. I'll say, well, is the character greater than little Z? If it is, then it's not an alphabetic character, go increment that bin. If it is lesser equal to little Z, then I'll increment the right letter of bin, whatever the letter is. So what about initialization? So we have a bunch of things for initialization. One is fill the histogram with zeros, right? So that was the part in our code. But we also have to put any values we want into registers. So remember when we were typing in a number, we wanted FFD0, which was negative ASCII0, so that when we needed to convert the number of users typed and ASCII into a binary number, or a two-compliment number, we could just subtract 30 hex, right? Subtract the digit zero and get a number from zero to nine. When we're working with letters, you know, those boundaries, we're going to want the same thing, right? We want to have values and registers that allow us to check, well, is it bigger than little A, is it larger than big Z, stuff like that? And so there might be some numbers that are useful. We'll figure out what they are later, but we might want to put those into registers. And then the third thing we want to do is, well, we better point to the start of the string. If we're going to walk through the string, then part of initialization is get some register pointing to the start of it. So those are the things we'll need to do. What about filling the histogram? So it's going to be an iteration, right? We've got 27 bins, so 26 letters, one non-alphabetic bin. So we're going to do an iteration. Okay? So again, we'll need a pointer to the histogram. So we'll point a register to the histogram and then iterate over all the bins, right? Overall 27, and fill each one with zeros. So once you break that down, I didn't turn this fill histogram with zeros into an iteration. But this is the full flow chart. So you can see the control structure that we had where we did four different conditionals, one breaking down each of the last, right? So four conditionals in order. These are the five different regions of the ASCII table in here. And then this is the initialization, the left column, and the counting with the loop up here and the incrementing the pointer down here. If you want to look at this flow chart, it's, well, I think I printed it, but maybe I didn't put it on the page yet. But it's in the old 190 manual. So you can get it there if I didn't link it properly on the page yet. If you want to look at it in the detail. So now we've decomposed our problem. Now we can actually write some LC3 code for that. So this is just a review of the problem and the algorithm that we're taking. So we've already kind of talked about that. So let's start out by by picking some places. So we're going to need a string. It's going to have to be in memory somewhere. So let's just say, well, the string is going to start at 4,000 hex. We'll write our code. We always write it at 3,000 hex. By convention, right? So we'll start our code at 3,000 hex. Where do we want to put the histogram? And let's just put it at 3,100 hex. The code's not actually going to be too long anyway. It's about 30, 40 instructions, something like that. So so it'll be it'll start at 3,100 hex. And then the alpha bins will be in order starting at 3,101. So 3,100 will be our non alpha bin. And 3,101 will be a 3,100 hex. And then the redisters, we also need to assign. So when we're counting, let's just make R0 histogram pointer. We're not doing any traps, right? There's no IO here. We've got the string in memory. We're going to have to store histogram in memory. So we're going to have to store histogram in memory. And then we're going to have to store histogram in memory. So we don't need to use R0 for reading characters in or sending them out to the monitor or anything. So we can use R0 to hold the histogram pointer. R1 will be a string pointer. So that'll move through our string. We'll start at the beginning and we'll just increment it, going character by character until we find the null. Whenever we pull a character out of the string and put it in a register to look at it, figure out what it is. Why don't we put it in R2? We said we want some asking constants. We don't know what those need to be yet. So we'll just say R3, 4, and 5 can be asking constants. And R6 will be a temporary register. So whenever you're starting to write a program, you really want to make this kind of a table, probably on a piece of paper, also in your comments in your code, just so you don't have to try to remember what did I put where, or get into actually a worse habit, which would be to just put things in some register kind of haphazardly as your right code. Try to keep track of things, keep them well organized. All right, so now it's time for you to write code. So we need to initialize R0 to 3100. What do you think we should do? So we could use an LD, right? We could just put 3100 in memory somewhere. Is there something else we can use if this is the address? LIA, right? So it's close enough that we can actually use an LIA. So what's destination register then? R0, and what's the offset? Remember this is hex. So 99 but in hex. Well, not really 99. The analog of 99. FF, right? 100 hex minus 1. All right. So right, the PC when this LA execute will be what? 3100, right? So if we add FF, we'll get 3100. Okay. So that'll be the instruction. We won't put it into bits. I'll leave that all for you. Actually, it's done. It's done for you in the version on the web. So you can actually download that if you want to play with it. All right. So what's next? We need to fill the histogram of zero. So I actually need a couple registers for this. So I'm going to. I'm going to kind of break my rule, right? And part of that is, well, we need more registers for this program than we have registers in the LC3. And so I need to reuse registers. But do it at a very high level if you need to do something like this. So we'll have a different meaning for the registers during initialization than we have during counting. Right. So the ones I showed you was during the counting. During initialization, we're going to reuse R1, R2, and R6. Okay. So R1, we're going to use for a loop counter. It's going to have to do 27 iterations because we have 27 bins in our histogram. R2 will be the current histogram bin to fill. So we're going to scan along in the histogram bin going bin to bin, putting zeros in them. So that'll be our loop, our pointer to what we want to put a zero into. And then R6 will just have a zero in it. Right. I don't have a good way to put a zero in memory unless I have a zero in a register. So put a zero into R6. And we can store R6 to put a zero into a histogram. Okay. So time for the first row. So we need to initialize R6 to zero, R1 to 27 decimal, and R2 to 3,100 hacks. So let's do those in order. So how do I put a zero in R6? I can do an AND. Good. Okay. So AND, R6, R6, zero. You've seen stuff like that before, right? All right. So how about R1 to 27? Hmm. Can I do plus 27? So LC3 immediate for an ad only goes up to 16. So I could do two ads. I could add 16 or 13 and 14. But, but instead maybe I'll just do an LB. That'll mean I have to have the number 27 somewhere. So let's just start in memory. Somewhere and use an LD. So LD, destination R1, what's the offset? We don't know. So it's going to be down somewhere at the bottom. After all of our code, we can put some data in. But we don't know where that is. So let's just leave a blank for now. How do we get 3,100 into R2? Yeah, I could do another LEA. That's a good idea. That's not what I did, but that's equally, equally good. I already have an R0, right? So how can I get it from R0 to R2? Yeah, good answer. So add R2, R0, number zero. Right? So add R0 to zero, put the answer into R2. And so that'll copy R2 into R0 for us. I'm sorry, copy R0 into R2 for us. Good. So now we're ready to actually fill the histogram bin. So we set these up already, these three registers. And what we need to do is write a zero from the R6 register into the memory location, 0.2 by R2. Right? R2 is pointing out to our histogram. It's a start of our histogram. So we need to take R6 right into that memory location. Then we need to increment our, to point to the next bin, which means add one to R2. And then we need to decrement the loop counter, which is R1, and keep doing that over and over again, until the loop counter, R1 gets to zero. Right? So that'll fill all 27 bins for us. Okay. So write one zero from R0. I should say R6, sorry. To the histogram bin to which are two points. So no C3 instruction for that. What? STR, right? Store register? Good answer. Okay. What's the source register? So you want to store a zero, but R0 doesn't have a zero in it. Right? This was wrong. This was a type R6. And the base register? R2. Yeah. So remember, R2 is now pointing to the histogram. It has the address of the first bin in the histogram by design. That's what we loaded into it up here. This put the address of the first bin into R0. This copied the address of the first bin into R2. Each time we come back in this loop, we'll be pointing to a different bin. So R2 is going to point to one of the bins. We're going to store from R6 into the address, the memory address, pointing to by R2. Okay. And the offset then is zero. And so that zero gets added into R2. R2 already points to the right place. So we don't need to change that. Yeah, actually almost, almost never do you need to write anything other than zero for your offset. So there's a few times, but pretty much not very often. Okay. So next step, point R2 to the next bin. I'll see if there's an instruction for that. Add. Add what? R2, R2, one. Good. And then decrement the loop counter. Add. Good. R1, R1, negative one. Okay. Branch backwards until we've written 27 bins. What's the condition? Branch positive. Good. Okay. Oh, so I wanted you to remember our one started at 27. So after the 27th time, it gets to the zero. Right. So if we branch positive, like you said, don't have to do that. You should be able to answer this one. So where's PC? I always have to count. Alright, so we're going to start here. Right? So here. And then we want to go back to where? 3000 for. So one, two, three, four, but going backwards to negative four. All right. So we're going to go back up here. To where we stored. Oops, sorry about that. Yeah, the pointers wrong too. So another brain oh on my part. Okay, so yeah, it should not point here. It should point to the to the str. Sorry about that. All right, so now our histograms filled with zeros. We've written eight instructions so far. So I wanted to just make sure you understand when we write this kind of stuff. These memory addresses over here. These are just for us. These do not appear in your code, right? In fact, well, I'll come to the next point. These memory addresses are just for us. So we have some idea where in memory our code is falling. Just the convenience. You don't actually even write these in your program when you write binary, nor when you write assembly. And so the only time you're going to see these would be in the simulator. Or in a piece of paper. The other thing I want to make sure you understand is these instructions. Well, those are not bits, right? And at least for now, until next week, you have to write bits. So when you write your programs, these will be bits, right? Next week, we'll talk about assembly language and talk about assemblers. And then you can start writing code like this until the computer turned into bits for you. But for now, you still have to think about this. It's not quite true because I'm not going to turn the bits for you. But in theory, you should be thinking about how to turn it into bits. All right. So we started a little bit of work to do for initialization. So we had all these registers. And we needed to set some of them up. So we initialized our histogram. We already initialized our zero, right? It's pointing. Yeah. Yeah. So it turns out the string is stored one ASCII character per memory location. So it's zero extended up to 16 bits and then stored one character per memory location. In, in, not in binary. So it's a pain to write a file with a string in binary. But in assembly language, there's a directive called dot string Z, where you just put a string in your assembly file. And then the assembler actually writes one character to memory for you. One at a time. So it's actually relatively easy to do so long as you're using the assembler, as opposed to writing it out my binary. Yeah. If you looked at the, at the typing in a number code, the read the messages, the error messages there, I did those by hand in binary ASCII in order to make it realistic for what you knew. And it's relatively painful. So, so if you want to play with this code, figure out how to write a string and ASCII. So you can do something interesting with it before you don't, don't do it in binary. Yeah. All right. So we've got these other registers, right? So we have to initialize the string pointer. We need to point that to, I think it was 4,000 hex. Current character from the string will just read that in, in our loop, right? These ASCII constants will have to set up. And then this temporary, we don't need to initialize. So we need to initialize R1, R3, R4, and R5. Here's some code. What do you think? But good? Is that good? Are those all loading the same value? Why not? It's all PC relative, right? Good. So all this means is somewhere in memory, I put in the real offsets for you, real offsets, meaning if you go download the code, these are what they are. But somewhere in memory, I've got four consecutive memory locations that have the initial values for R3, R4, R5, and R1 in that order. And so these four load instructions pull those four sets of 16 bits out of memory, copy them into R3, R4, R5, and R1 in that order. So I just want to make sure you understand, you know, PC relative does, does mean something different, does mean a different place, depending on where the instruction sits. All right, so finally we're ready to actually do some counting. So we can do some counting. So let's see, what's the first step? So we said, okay, we need to check if a character is null. So before we can do that, we have to actually get the character out of the string, right? So where was the string pointer again? Remember? Yeah, so I think but we loaded into a register, right? R1, okay, so how do I go get the thing at R1? LDR, okay, so LDR, and I want to put it in R2, right? So LDR, what's the destination register? R2, and the base register, R1, and then the offset's just zero. So this will go to the address R specified by R1, so whatever R1 is pointing to, we started it at the start of the string, Sasha. I see because I'll show you I'm going to play a little trick to use one constant twice. Basically it's because, you know, there are 26 letters in both sets, right? So you need one constant for the difference between those two sets, and it's the same. Yeah, so you can reuse that one. All right, so this is going to go to the memory address specified by R1. We started that at the start of the string, we're going to move it forward, right? So we'll look at one character at a time, R1 will keep adding one to it, but every time we go get one character out of the next string location, copy that into R2. So then how do I check to see if that's a null character? Do I need to do anything? I just branch, right? Branch on a white condition? Oh, sorry. I forgot they're connected. Okay, so if I get a zero, that means I found the end of the string, and I can go to the end of the program, but I don't know where that end of the program is, so I'll leave it blank. All right, so now we're ready to classify our character and increment one of the bins. So the first conditional we had was, well, is the character less than capital A? So let's define R3 as negative at sign. Why negative at sign? At sign is down here. So if I subtract at sign from my letter, what that'll give me if I have a capital letter is a number from 1 to 26. So again, if I have a capital letter, one of these, and I subtract 40 hex at sign, then I'll have a number from 1 to 26 left. And I can use that to tell myself, well, which bin in my histogram do I want to increment? Because remember, those are also in order from 1 to 26 for a to z. So we're going to store the difference of our subtraction back into R2. Well, let's go ahead and do that. So we'll add R3 to R2 and write the sum back into R2. So add R2 or 2R3. So now I can check whether the character was in fact less than capital letter A. So if I subtracted 40 hex and I want to branch forward if the character was 40 or below, what branch conditions should I use? 0 or negative, right? So branch, ah. That's for letter. I'm sorry. I screwed this up. Oh, I'm sorry. Yeah. So this is the opposite condition. Yeah. So we're going to handle the case first, which is the non letter case. My apologies. So your answer was correct, mom. But, but we're going to do the other case first. Let me go back and be clear on the diagram. So we're going to do this case first. We'll write the code for this first. So we're actually going to branch in the false case. So the condition for this being true was negative or zero. And so the to go the other direction, we invert that just flip all the bits. So instead we get branch positive to skip ahead to the rest of the calculations. So we'll branch over the code will right next with a branch positive, but we don't know yet how long that code is. So if I find a character that's in the left region, the non alphabetic region. So then I'm over here, right? So I just need to increment the non alpha bin. And that bin is at 3100 hex. And I have a pointer to that bin. So I can just increment it. So increment memory location. What's the instruction? Is there one? Yeah, I got to read it right. I can do a load, add one to it and then store it back. Right. There's no LC3 instruction that'll do that in one. And so I'm going to have several. And the first one. Load what kind of load? LDR, right? Because here's here's the address. I've got that address in our zero. So I can use R zero is my base register. Right. Where should I put it? Where should I put those bits? Our six right I said, OK, our six will be my temporary. I don't want to clobber some useful value, but I need somewhere to put it while I'm adding one to it. Let's put it in our six. That's a good idea. So no instruction. So let's do an LDR. R zero off said zero and then put the value in our six. And then how do I add one to it? Add our six, our six one. And how do I put it back? Where? Yeah, from our six to our zero base register of said zero. So these three instructions together will go to the memory location pointed to by our zero, which we know is the non-alphabetic bin. Add one to it and put it back. So that will increment our non-alphabetic bin. So now we're ready to we're finished counting that character. Right. We knew it's a non alphabetic character because it was less than capital letter A. We're done with it. We just need to go point to the next character. That's some code down below. We haven't written it yet. So we need to we need to branch. And so how branch condition should I have? Just always go there, right? So branch and ZP. But somewhere going to where you so we'll leave that one blank. So one thing we can do. We can actually fill this one in now, right? So what offset should that be? I hope I got it right this time. All right. Let's do our counting. So where's PC? So we're going to fill in the offset for this branch. So where is the PC when this branch executes? So I should be clear. Yeah, 3010. Right. And where do we want to go? The 3014, right? Okay. So we'll start here. And we'll say one, two, three, four. Worked. Always. Or like. Yeah. So these are when I'm writing in sort of this is actually assembly language. So any time we're writing an assembly language, you can use human notation. The X means base 16, the pound sign means base 10. But you don't have to put leading zero. Now, they are all two complement values. So you can put negative signs. You can also just put the the one bit. So there are a few ways you can write it. Now this is branching forward. Yeah. This is branching forward. Okay. Any other questions or if you like. All right. So now we just handled. We just handled the non alphabetical case on the left of the ASCII table. And take a look and see if our characters greater than capital Z. And if it is, we'll increment the alpha bin. I'm sorry, if it is, we'll go forward and handle this other set of three sets of characters here. If it's not, if it's less or equal to capital Z, we'll handle it as an alphabetical character. And so we want to subtract capital Z, but we already subtracted the at sign. And remember, we subtracted the at sign. We stored our character back having subtracted the at sign. We stored the result back in R2. So now in order to compare with capital Z in order to subtract capital Z, what we have to add is at sign minus capital Z. And so this, Sasha, this is where it's going to come in that later we're going to have back quote minus the little Z, right, which is the same number because there are 26 letters in both cases. But anyway, that number, let's just put that in R4. And we're going to throw away the result, right, I just want to know, I want to know is, is it a letter, but I want my numbers from 1 to 26 to use to find the right bin if it is a letter. And so I'm going to keep the numbers 1 to 26 if it's a, if it's a capital letter. And so I'll throw away the results of this sum. I'll just use the conditions I get out of it to check whether it's in this blue region or somewhere over here. All right, so we'll compare with capital Z. So we'll add R4, which is at sign minus capital Z to R2 and write the answer to sum into R6. So add destination is R6. And then the source registers are R2 and R4. So now if the character is not a capital letter, what should my answer be? It's not a capital letter. So if it is a capital letter, then it should be negative or zero, right. So if it's not a capital letter, it should be positive again. And so again, what we just calculated was original character, this ad calculated original character minus capital Z. So if that answer is negative or zero, we know it's a letter, a capital letter. If it's positive, it's something else branch on positive to somewhere. But we don't know where yet. We've got blank. Okay, so we know I should across this one out results not positive results a capital letter. So what been should we increment? So we have an R, what is it? R2, we have a number from one to 26 in R0, we have the 3100 hacks. Yeah, that's right. And you would not have positive. No, remember we threw the answer away. We just use the condition code. Yeah, the number in R2 is still one to 26. And that's important because we want to use R2 as one to 26 to get the offset indoor histogram. So our histogram pointer, the first bin is 3100, that's an R0. Okay, so here's a hint. R2 now holds this. Remember, R0 holds 3100. The A bin is 3101. Right. So how would you get 3101 when R2 has a 1, R0 has 3100. Just add them together. Right. Well, what if what if I had 26? Right. So the Z bin is 3100 hacks plus 1A, which is 26 and decimal. Right. So 311A. So could I do the same thing? So all the time I take R0 add R2. That now gives me the address of the right bin. Right. That letter's bin to go increment. So 3100, that's an R0 and then plus R2. So R0 plus R2. Oh, okay. So you said add, right. So let's add. Where do we put it? I could put it in our six, but then I'd run into problems because I need someplace when I'm going to go to memory and add a number, I need someplace to put that one. So I guess I could use R7, but I told you never to use R7. Yeah. So that's a good question. What about what about R2? Do I need that anymore? I mean, now I figured out what it is. Right. This is a capital letter. So I know what it is. Can I just overwrite it? I don't need it anymore. Right. Once I find the bin, I'm done with that letter. So let's just overwrite it. So just throw it away now. Now we'll put now our histogram pointer bin pointer into R2. So now I need to increment the address pointed to by R2. Now of course the answer is no. There's no LC3 instruction for that, but you know what to do. Right. So what do we do? LDR. Same thing we did before. Before we wanted to point just to R0. Now we point to R2. So LDR, where should we put the answer? Remember, we need a place. We just want to add one to whatever is there. Right. So we just need a temporary register to store this value while we're changing it, adding it one to it. So let's put it in our six. And the pointer is R2. So that's our base register. So this will go to the memory address R2, which remember now is the correct bin for whatever letter we just saw. And it'll pull those bits out of memory, the current count for that letter. So now we want to add one to that. And then put it back. Let's put it back. That's here. Good. So now you can more easily maybe see the reason that I didn't want to put our pointer in our six, right. Because when we need another place to keep track of the count when we're adding one to it. So if we put that pointer in our six, then we have to put this this set of register somewhere else. So since we didn't need our two anymore, we just reuse reuse it here. All right. Good. So we're done with that one. Now we need to jump down to the code to point to the next character. So let's branch always so we don't know where yet. But we can fill in that offset. So what is that offset supposed to be? Good. You're getting you're getting better than me at counting. Where's the PC? 30 16 and where do I want to go? Down here. So let's see. One, two, three, four, five. You're right. All right. So now we can check. Check whether the letters less than capital A. Right. And if it is, we'll increment the non alpha bin. And if it's not, then we have to go do some more work. So we know it's not in here. We can compare with little a if it's less than a little a we know it's in this region. Right. So how do we compare that? We already subtracted at sign. So we'll add at sign minus the back quote. Right. And that will give us the same thing we had before number one to 26. This time if our original character was a lowercase letter. So get the same mapping for letters as before. But now the sorry, the lowercase letters will be one to 26 characters down here will be zero or negative numbers. And then up here, we'll have to figure out later whether we've got one of those. So let's see. So we'll add our five and store it back into our two. So I'm going to store this value in our five that was our third constant. So add that offset on our two, put it back into our two. That'll do our comparison. So under what conditions do we have a character here after that add? Yeah. So negative or zero. Right. Because we're subtracting this thing effectively from our original character. So in that case, in the end and Z case, I want to increment the non alphabet. How do I do that? Yeah. We already wrote that code. So can I just use a branch? Well, that's a good question. I think you want to I think the answer is you want to write your code so that they're not. Yeah. So in this case, we're just incrementing the non alphabet. We don't need to know anything else about the character other than well, it's not a letter. Right. So this code's relatively easy to get right. For the letter code, we have to make sure that remember we assumed that our two was a number one to 26, depending on which letter. So if we're going to reuse that code, we have to make sure the same condition holds. That's a very good question. Yeah. So in this case, we met your condition though. We know it's not a letter. So and we know that all of all of the other registers we don't we never change or constants are pointer to the start of the histogram stuff like that doesn't change. So let's just branch to it. So we'll branch what's the branch condition again branch and Z, right. And then we met we actually know where that code is, I think, but it's off the screen. I didn't want to try to cram all the code on the screen. So we'll just save it for later. Besides, I'm getting tired of counting. I'll be back to you. Right. So one last condition. So I know we're getting over getting very close. All right. One last condition. So these are actually pretty easy. Right. So one thing to to notice, we want to subtract little Z. So basically, we already subtracted back quotes. So we need to add this number back quote minus little Z. But that number is the same as at sign minus big Z. Both of them are just negative 26. So we already have that number in our four. So we'll just add that number in again, throw the answer way. Just use the condition codes. But under what conditions do we have a lowercase letter. So I've just calculated original character minus little case lowercase C. Yeah. So energy, right. Okay. Good. So I can, if I want to go increment a letter bin. Oh, being Muhammad's constraint, which is that well, we better make sure that we have the same rules for the code, which we do. Right. Our two now holds a number from one to 26, just like it did before. And so that tells us which bin we want to include. So then we can just branch to it. So, you know, we designed that code to be reusable. So this is, this is what you're asking them. It's important that you do that. That you've got the same set of register value assumptions going into the code, regardless which way you go into it. Very good. All right. So let's handle the OK letter is branch condition was n z go to that. Otherwise, just leave that blank otherwise, we know it's not a letter. And so then we can go to the code that handles not a letter. Right. Just branch unconditionally. We're done. There we go. OK. So let me stop there. And we'll talk about the rest of it on Wednesday. Sorry for the long break. If you want to just look at the code, it's online. You can download it. Play with it. You You You You You You You You"
    },
    {
        "ECE120-2016-10-12-LEC-21-slides.mp4": " Okay, so I think it's three. So today we're going to start off with binary counters. So we can start doing some finite state machine designs. It looks like their amplitude is up. So we'll talk about synchronous counters. We'll talk about ripple counters. Synchronous counters are clock synchronous sequential circuits and ripple counters. So I'm going to turn this down slightly. Okay, I think that that's better. Then we'll talk about machine models. So in our class, we'll assume that outputs are never a function directly of inputs, but I'll show you a machine model where that is the case and talk about the differences and why we choose not to allow that dependence in our class. And then finally, we'll go through a six step design process for finite state machines and use that for a small example. On Friday, I think we will cover mostly the design of the lab FSM that you'll be building in your protobords. You've already started building that, but actually implementing it in the protobord in the next week and a half. Yeah, maybe two weeks. So that's the plan. We did get your feedback surveys and we have the tallies. I read through most of the written comments. The only thing is they didn't correlate the written comments yet with those which are from you versus those from other students. So I'll look at it more deeply over the weekend and come back on Monday. So reminder, we have midterm coming up, which will pull you know next week, next Monday, we have a review session. This slide you've seen a couple times. So I'll spend too much time on it. Oh, there is one other bit of information I have, except that I should have written it down from the email. Eight of cap and news running another review session on the weekend. It's on the 15th. I think it's on the 15th. I'll give you the details on Friday, but you can probably also find it out from eight of cap and new people. Or posted on their site or something. As always, we can't we can't endorse if they make mistakes in the review session. We can't endorse that unfortunately, but it should should be useful. All right. So what happens if we think about a finite state machine that has no inputs. And so it's going to start in some state. And then where's it going to go in the in the next clock cycle? There's some other state, right? There's no input. So there's exactly one art going out of the state goes to some other state. And then what will happen next? Go to some other state. Well, keep doing that, right? But at some point, it'll run out of states because of finite state machine, they'll find out many states. So eventually, it's got to go back to one of these states. So eventually it's going to go back to a state. So let's just go back to that one. And we're going to get a loop. Sure. So it doesn't have to change state. That would be a loop of one state. So it also be a loop. So you can decide how many states you want new loop. It could be one. It could be four. It could be a thousand. But it has to be finite. Okay, so it'll go around in some loop of some number of states. Now, if we have such a finite state machine, we call that a counter. Now counters sometimes will add inputs to them. So we might say, well, I want to, I want to be able to start and stop my counter. So I use an input for that. Or maybe I want a counter that counts up and down. So both ways around the loop. So maybe I'll add another input for that. Sometimes maybe I want to reset it. So I want to force it back to a known state, maybe a lighting input for that. But generally speaking, when we talk about counters, we're talking about something with one loop. And it's normal operation is just around that loop of states. So we're going to talk about two kinds of counters. One is synchronous counters, which are cloth synchronous sequential circuits. So these are the same kind of designs we've been talking about for the last couple of weeks. We use flip flops to build them. We use a common clock to all of the flip flops. And they all change state and allow us, they all change state on the rising edge of that clock and allow us to think of time as being discrete. And so times just an energy. We'll also look briefly at ripple counters where the flip flops of some, I'm sorry, the outputs of some flip flops are used as the clock signal to other flip flops. We're only going to look at binary counters for these simple designs. So the reason we'll look at them is they can actually save you a lot of energy. So let's do, let's start with an example of a counter. We'll do a synchronous counter first. So here's a state transition diagram with eight elements. And if you look at these, these are just counting from zero and unsigned zero, one, two, three, four, five, six, seven, go back to zero. So this is a three bit binary counter. So in order to build this thing, first thing we'll do is just copy that into a next state table. So what's the next state from zero, zero, zero. Good. And then. Good. Keep going. Good. And we realize this is very easy for this one, right? Generally speaking, it's not too hard for a counter. What if I had six states, what would I do with the other two rows? Just put Xs, right? Because I don't care. Now, we'll look at a design like that. Probably on Wednesday, because on Friday, we'll do the lab design. We might get to it on Friday, Monday's a review session. So we'll look at a design where we have some Xs later. So let's just do K max. So we'll start with S zero. So here's a K map. So let's copy. So remember when we copy what I did that they put S1 as zero on the cop here. So right across the rows as S1 is zero changes. And then since this is great code order here in the K map binary order here, I'm going to go first, zero, zero, zero, one over to one zero and back to one one. So one zero, one zero, one zero over to here, one and then back to the one one slot zero. And then one zero, one zero again. So one zero, one zero. Okay. So what's the what's what loop should I circle there? The square on the outside. Yeah. Okay. I'll do all of these SOP, by the way. So I think that's the S zero prime loop there, which you could also choose to write as S zero X order with the one value. You'll understand why later. So that's one plus so throw up a K map copy so zero one one zero zero one one zero and then zero one one zero again. What are the loops here? Yeah, so these two and these two right. Okay. Good. So that's S one S zero prime S one prime S zero. And that's just S one X order with S zero. Okay, so we have S one. So what about S two? So I'm sorry zero zero zero one zero zero zero one and then one one one zero one one one zero. This one's mess here. Okay. So there's one. What else? Okay, so over here on the left. Okay, and then to again, okay, good. So if I read those out that's S two prime S one S zero same order. So that's this one S two S one prime is this one and then S two zero prime is the one that wraps you out there. Okay, so that's a little messier looking. Maybe we should try to do five bit and see if it gets uglier. So I want to ask you a different question. When you count. Have you been counting recently? Yeah. Counting is important. When you've been counting, when is the place value change? So for example, you're counting along and you get to what number that say the thousands place value changes. 999 like here. So you're zero 999 sorry, I'm a computer engineer so put a reading zero. So then the thousands place changes right or if you're at what's the next one? 1999 or 2999. What about the 10,000s place? When does that change? So 09999. So like that right. So you see the rule. What's the rule? All the lower digits have to be nine. So that's when a place value changes. So what do you think that rule is in binary? All one's good. Okay. So. So what looks to be the answer. So so far we have these equations. So we have s zero plus is s zero plus x sort of one s one plus is s one x sort of s zero s two plus is this nasty thing. Any simplified. Remember it's going to change when the lower digits are all one. So here there are no lower digits. So the lower digits are always all one. So s or s x or the digit with one here the lower digits is just s zero. So we x or the digit with the lower digits with just x zero. So here we've got two lower digits. So we should x or s two with what? That's one s zero. So leave it to you to verify that these two are the same. I think they're the same. Is it that easy? Okay. Yeah. If you apply to Morgan's, I'm sure you'll get this one out. Okay. I can't see it that quickly. I'll believe you. So let's use our general theorem to build a bigger design. So what if we wanted a four bit four bit binary counter. Do we need to draw a came up or can we just write down s three plus. Sure. What is it? Like that. Okay. Good. And then s four. Sorry. Skip the head. Okay. And what's s five. Okay. So we build an arbitrary big counter. Right. So here is a counter using what's called parallel gating. And so you can see that in this design we're basically just using equations. So here I just fed. And then we're going to convert it out, but back. So that's equivalent to x or with x or in with one. Right. Here I am x oring the current value of s one with s zero. And over here. Notice that I've drawn these flip plots kind of backwards. Right. So the least significant bits now on the left. I did that just because it's easier to draw the logic. So we can get bits over on the right. The next digit we've got s one and with s zero out of these two flip plots and x or with s two and then the last one ends all three of them together before feeding into the x or so these are just the equations we saw. Yep. That's okay. Good question. Here's an answer. Here's a serial gating. So what you should notice is that we'll point it out. So now we have instead of let me go back a second. So here we were starting to build up. Right. This this and gate has three inputs. If we continue the next and gate would have four and get after that would have five. So this s five plus right it has an end gate with five inputs s six plus sort of six inputs s ten plus sort of ten inputs right bigger and bigger and gates. So instead of doing that we can build in this serial approach where it's the same label but you can see I'm using s one as zero I'm reusing the output in order to calculate s two s one s zero. So these are serialized so that each of these and gates instead of getting bigger and bigger is not only two input. So I'm saving a little area and the expense is from will also pointed out is that well now I have to wait to go from here through here through here through here instead of in the parallel design taking the outputs and all merging them into through this one gate. Now of course the gates are actually going to be limited in number of inputs so we couldn't really build it exactly this way so in practice. So parallel gating gives bigger gates so more area and less delay serial getting give smaller gates or less area more delay I practice or gate sizes are limited you can't have 20 inputs so use a combination of the two. So usually it's a function of the actual semiconductor process so the process technology will tell you which which implementation would be faster and and there's actually usually you're also leaving things like transistor sizing for the tools to finish off for you so so it's really without going into into those proprietary parameters in the process you probably couldn't answer that question precisely so it's it's now in terms of rules of thumb usually maybe four inputs and drive four outputs. About the point which you want to go to more gates instead of bigger gates for more outputs. Okay so that was a synchronous binary counter and so what does that mean so counter one loop of states binary just means the outputs are binary inside numbers and going in order and synchronous means they have this common clock so now let's go take a look at a binary ripple counter in order to get the look at a binary ripple counter in which the clock is not shared. So now the flip flop plots will not have all the same all the same clock input. The flip flops are not at the same clock inputs so in a ripple counter we're going to take the outputs from some of the flip flops and use those as the clock input to other flip flops. I'll show you an example in a second for a binary counter binary ripple counter why are we going to do that so remember when we talked about power I mean I said mostly it's outside the scope of the class so don't worry too much but remember when you when you change a transistor you're going to have electric current slowly right so you're going to change some of the electric current from zero to one one to zero electric current is going to flow is going to generate generate energy basically flowing through resistance it's going to take energy and going to take power so to increase power consumption. And so by clocking the flip flops more slowly than what happens is we reduce that power consumption so total energy is reduced so in a lot of embedded systems people use ripple counters the trade off then is that the changes to the internal state instead of just happening in the same way that the same way we're going to do that. And so we're going to be trying to make sure that the same thing in the same rising edge of the clock in order for that change to happen throughout the counter well what you'll see is the change has to go through one flip flop in the next flip flop in the next flip flop and so on until it gets to the end. So the changes just like a ripple carry adder going to ripple through the counter will be much slower. We won't actually we won't quantify that but you'll see that it's slower than synchronous counters. So the thing you might think about. Let's take that offline and basically higher voltage is the bigger is a stronger electric field so let trans will move more quickly. So you're fighting the delay issues. As you'll see that it will be a bit slice design so yeah it's a good. I wouldn't say that in general you couldn't do anything more complicated but for our class the only one will look at is a bit slice. So what about clocks you read we said well let's avoid clocks you in general could be an issue we're just going to look at one simple design and honestly more complicated ripple counters as long as you're operating as long as the clock is just manage within the counter. You can say well you know as long as the circuit person to gives me a level clock edge into my ripple counter i'll manage the clock delivery within that counter so it's not really as hard as you know general circuits problems. Alright so here's the ripple counter we're showing so you can see this is a simple bit slice so each of these is just replicated four times and then what's going on is for each of the bits are again backwards so least significant bit takes the real clock and then the next least significant bit takes the inverted output of the first bit of the lowest bit as its clock input. And then the second bit does the same third bit does the same from the previous bit so SI plus one takes its clock input from SI inverted SI. So that's these circles down here also notice that SI prime is also the de input so for each of these flip plots the bit slice takes the inverted output and feeds that back into the de input. So what that means is every time any of these flip plots sees a rising clock edge it's going to toggle its value if it's holding a zero it'll become a one if it's a one it'll become zero. The initial state of q not if we if we assume that the bits are starting all zero then the initial state of q not would be one. So so let's take a look at a timing diagram so that we can understand what's going on so up here I've drawn a square wave clock and these dotted vertical lines are the rising clock edges of the clock so that clock is going into Z Z not. So these are the initial values of the three bits we're storing so they're all starting low so at this rising clock edge what's going to happen to Z zero. It's going to flip right remember that on all of these we fed the value complement back into the de input so any time we see a rising clock edge we're going to flip the value what about this rising clock edge. It'll go back to zero right good about that one up to one good what about the next one zero and that one one good and one one good all right so then let's think about well what about the Z one so remember Z one CZ zero inverted as the as the clock signal so when you've got this rising edge in Z zero that's a falling edge for Z one's clock. So when a flip clock sees a falling edge what does it do nothing right these are positive positive edge triggered flip flops just like we've been using right so when it sees a falling edge just ignores it Z one stays the same what about one Z zero drops here what happens. It's going to flip Z one good what about when it rises nothing good balls flip okay and then I'll skip the next one because that's just another rise which when you invert that sees another falling edge in zero and clock so what about this last one here flip again. Okay and so Z two then remember CZ one inverted as the clock signal so Z one is flat so this one also won't change right what about on this. But it follows these zero so Z two the only clock it sees is Z one inverter so Z one inverted doesn't change here at this dotted line so it's just a solid Z one inverted is a solid one so that clock for this flip flop does nothing but stay high to this dotted blue line the first dotted blue line so Z two doesn't change what about when Z two goes from low to high. I can't ignore it right because remember it's Z one inverted is the clock input for Z two so this is a falling edge for the clock of the two so get the more and this one is flat so ignore that what about this falling edge in Z one it's going to flip right because the falling edge in Z one is a rising edge in the complement of Z one. So that'll change the two and that'll stay fixed because we don't have any other falling edges in Z one. Yes so the observation or all made is that basically the period of each of these flip flops if you look at it as a period so this one is twice the clock period right so for clock for example where gigahertz this would be flipping at half a gigahertz this would be an A and so forth okay so what that means is basically if you remember summing up exponential powers if you've had an infinite infinite number of these bits the first one flips flips half the time the next one flips a quarter the next one flips an A so if you add all of those up and you say well on average how many of my bits will flip it will be two right. I'll show that in a second but thank you. Yes it's counting but but the point there was two bits will flip on average right whereas if you're toggling if you're toggling all of your clocks then internally those latches will be changing a little bit every the clock will be recognizing that the flip flops will recognize that the clock input has changed some of those transistors will turn on and off and as a result you will be burning energy. Here you're only flipping on average to you're only showing the clockage to two of your flip flops on average and so you're using a lot less energy for that reason so let's look at the counting comment so I want to make sure you understand how to read these so I'm going to draw a line down in this clock cycle to the left of the first dotted line so remember this is the high bit right so this is zero zero zero so that's a zero what about this one here this clock cycle zero zero one. Zero zero one right so that's one this clock cycle zero one zero is two zero one one three one zero zero four one zero one five and one. I see we're going to put counting on the exam okay yeah so so this is a rip it's a ripple counter but yeah so you're worried about the speed yeah and then the speed is going to be slow or keep in mind it's only rippling here through three flip flops right so it takes the clock speed may be limited by the by the delay of rippling through three flip flops so that may be the longest delay in your system so that may let me face clock speed. It wouldn't be one it depends what you're trying to do if you're talking about an embedded so the question is is this useful for a 32 bit processor you know if you have an embedded system at the low power design so your clock is probably not multiple gigahertz anymore right and so since you're not trying to press your clock speed high it doesn't matter that this part is relatively safe and it also saves you a lot of power so I think the you know it depends in context of embedded systems the low power designs go sort of hand in hand with slower clocks you really don't need your intellect breaking system sampling it you know 100 megahertz even human human real world events just don't happen at that speed so you don't need a processor that runs at that speed and you don't want to drain your battery even less just your car battery. Okay so let's then talk a little bit about machine models so there are two machine models these are mostly names of historical entrance so we've said a few times now the FSM outputs in our class are going to depend only on the state right so FSM outputs could depend on inputs but in our class will only depend on state so historically that kind of finite state machine was called the more machine and the more general model in which these outputs could also be a direct bull in expression of including the input variables was called a melee machine. So in practice once you go on the industry and you start building these things even in even in 385 I think you can always use melee machines right to the point that most of most of my alumni in industry come back and tell me why you still teach these things I don't even know what they mean so the names are really just to start more interest there's reason for this and I'll kind of illustrate why and also want to tell you also if everyone is using this one in industry why are we teaching you the simpler version so if a designer was an output in industry or in practice let's say if you want an output to be independent inputs will use simply right equations that don't include the inputs right you want them not to include the inputs will write equations that don't include inputs you're done so it's not that hard so why do we use why use the general model in industry and in practice well inputs carry information there's information in your inputs and if you use that information sometimes your finite state machine will be a little smaller a little faster and so forth so people say well of course we're going to just try to use it so why not why don't we use it in our class so as you'll see in a second if your outputs depend on your inputs what that means is your output timing depends on your input timing right and so now instead of having this nice model of discrete time now we've re-opened the timing issues and so instead of allowing that to happen without thinking about it to carefully we simply use the more model and say well output should not depend directly on inputs so let me give you an example to illustrate the timing issues so let's say that we want to recognize the sequence zero one on an input so the idea is we've got some serial input every clock cycle there's a new value on this sorry this should say in not be and this should say out not Z so whenever the input is zero in one cycle and one in the next we want our output to be equal one so this is something we call a zero one pattern recognizer here's a design for it so this is a melee machine to solve this problem so we've got a flip flop we're going to ampage so we've got the input here goes into the D and then we've got the end gate with the complement value of the stored bit and the current input so output is now a direct function of input so what is the next state equation here what is s zero plus just whatever goes in here right so what is that just in not meant to be hard all right what's the output equation so what's out in terms of this one of that one so in and it with s zero prime right so if you look at the output equation in means as the current input value is one and s zero prime means that the last input was zero so we said we're going to do zero one recognizer if you take these two conditions and and them together you've seen a zero one and output is high otherwise you didn't see a zero one so you have to put it as low so remember that we are assuming still on the s o values these only change of the rising clock not so easily not so easily because then you'd have to factor in all the gate delays and go back to continuous time no if you do full simulations that the you can do full simulations and do in transistor simulations and IV curves yeah I mean you don't need it but you probably want to if you can do it by hand if you want but it's not very common so let me extend them into some extent that's what we're doing when our counting gate delays right so I mean you do the same thing you can't gate delays I think that's an estimate okay so all right so let's then draw the state diagram for this thing so we have two states right we have s zero so just one flip plot so we have a zero and a one state now state diagrams are going to look a little different right because outputs so here you'll notice there's no output bit and that's because outputs now depend on inputs so we can't it's not a function of the state anymore right depends on the input to and if the input changes the output will also change so we can no longer label our states with output values so instead those are going to go on the arcs in the transition arcs so now our states will just have state bits so this is s zero equals one this is s zero I'm sorry s zero equals zero this is s zero equals one and our arcs will be labeled with input in slash output out let me add some arcs here so when I get a zero I'm going to go into the zero state and when I'm going into the zero state well that means my output is always zero also so this is zero slash zero so input an output of both zero when I'm already in the zero state well I stay in the zero state my deep input is still zero so I've got a self-loop from zero back to zero labeled zero slash so what about if my input is one if I'm over here on the zero state and I have an input of one well then my next state is one in is one and my current output is is one also here so that's one in one so my output should be one so the arc here going from zero to one when I have a one input will also produce the one output that means I recognize the zero one combination all right going to have a self-loop one zero so again if I see a one on the input my next state is one but if I'm already in the one state now this output is low and so my and it produces a zero so this is the complete state transition diagram for a zero one recognize or as a melee machine so let's take a look at what that does in timing so remember out is in and it with zero prime so first of all in this diagram you see a rising clock edge here that rising clock edge causes s zero to accept input as it's out as its current value so after this first rising clock edge s zero is zero okay once this input then goes from low to high so s zero is zero so this output is high once in goes high this output now produces a one so this input rising edge produces a rising edge in output even though the clock cycle is not changed we're still within the first clock cycle now that output stays high only until the next rising edge of the clock as soon as the rising into the clock comes input is high so s zero will change to one that means the output will go low again so once we get over here the output will drop back down so I've drawn this pretty thin and the thing is that well if that rising edge on input came later it'd be even thinner in fact it can be arbitrarily sin it's with depends on the timing of this input rising edge here and if that arrives at some arbitrary time with respect to our clock we can't put a lower bound and help thin that output pulses and so it could be very very thin that we only produce this little tiny bit of one output so usually that doesn't matter so much so if your inputs come from some flip flops on the same clock and your changes arrive early enough in may limit your clock speed but usually it doesn't matter if you're coming from some other some other flip flops on a common clock and you using flip flops rather you're driving other flip flops with a common clock with your outputs it's not going to make much difference which is why in practice people just use this model and don't worry too much about it the problems will come if you have inputs that are external so if there's some human user producing inputs or some other system with a completely different clock producing inputs or if your outputs are used by some other system that's not on the same clock in that case you really do have to worry about the relative timing so when you start putting things together in later classes or in industry or something you will have to worry about these kind of things at the edges of your designs and not in the same clock domain and in our class you don't have to worry about it so how do we fix this should we just go redesign it all with a more machine should we do can you turn this into a more machine for me how about this just throw a flip flop in so if I just add a flip flop now there's a more machine right I mean this is the state bit so I can affect the output with a state bit wait a minute that's sort of delaying things in fact if you think back to our serial or serialized designs we always delay things right the output of these machines is never is never reflecting all of the inputs until the next clock cycle so let's take a look at the timing diagram but I claim it's no different from the things you've already seen which is a factor with using more machines so let's take a look at it so what this is going to do by adding this flip flop here we're actually logically splitting this one state into a one one state and a zero one state now the one in the zero different and they call this one s1 so that's the high bit so we've got three states now and now we can put our input our outputs into our state so we've got the zero zero state which is zero here and zero here in that case remember output is just s1 so s1 is zero so output is zero here's a one one state output is just the same as s1 so the output is one and here's a zero one state again zero is just equal to that zero there so now the outputs are part of the state just like you saw when we talked about finite state machine transition diagrams on Monday and that's because there's a more machine so here sorry I meant to do this analysis first well Ian is just going to s zero right so if I have a zero on my in then s zero plus will be zero right because I just go straight there similarly in goes over to this and gate so if my input is zero that's one plus will also be zero so that's why any zero takes me from any state into zero zero state so I have these three arcs all going into zero zero what happens when in equals one so then s zero will be one and so s zero plus will be one so if I give a one input my next s zero plus bit will be one and let's see s1 plus will be one ended with s zero prime so s1 plus will just be s zero prime so from here I'll go to one and then s zero is zero so to one one right so if I see a one in the zero zero state I'll go over here now I claim that's actually my recognizer so to be in this state I should have seen a zero right and after that zero I saw one and that'll produce one cycle of my output one and that's what I wanted right I wanted to recognize zero one so what if I see another one well I shouldn't produce another cycle one right because that would say well zero one one so I shouldn't I should stop producing the equal or output one at that point so if I get another one I'll go from here or here in both cases s zero is equal to one so s zero prime is equal to zero and so s1 plus is also equal to zero and so both of these states on a one are going to go down to this state and not produce a one output yeah well that's a good question so that's why I didn't put it on the slide so why did I put a one zero state on the slide I'm sorry zero one state one zero one zero state that should be one zero yeah why didn't I put the one zero state on the slide it's not reachable right so this is the full state diagram for these states you can see there's no arrow going to one zero once you're in these states you can never go to one zero when you turn on the machine it may start in one zero but after that first cycle it'll never be in one zero here so that's why I didn't bother to draw it here I thought it would be more confusing than to the thinking about what's going on okay so let's take a look at the timing diagram so here we have our new more design we have the same issues right so here at s zero this rising clock edge input is low so s zero becomes zero at this rising clock edge but now even though input goes high here the output doesn't change that just changes s one plus and s one is ignoring that input right now until the right in the clock edge s one does nothing with that input this flip clock is nothing with that input so when the clock edge comes then output goes high right so you can see this is slightly delayed right so instead of seeing the output equal to one as soon as the input goes to one even though we know there's been a zero one we delay that that output until the next time is a zero on the flip side we then keep output high for an entire clock cycle and the output has no the width of that output post does not depend on when the input arrives and it's always full so that's that's the nice timing aspect so that gives us discrete time on our outputs right we've got a full clock cycle of one but it's a little bit delayed so that's the price we pay so out is high for a full clock cycle. So to summarize the more machines that we're using in class the outputs depend only on the state not on the inputs the melee machine outputs also depend on inputs in practice everyone uses melee because you can get a smaller design but you might have these thinner output pulses to fix it it's pretty easy you just throw some more flip blocks down and then you've done right so okay any questions on that so we'll use the we'll use the more machine throughout and the rest of our designs so you can always assume that that inputs will never directly affect your outputs outputs will only get a function of state. Before the output yeah so you can certainly do it that way right. You're not going to be able to make that output visible earlier in that kind of design so you might be able to get away with your flip flops if you rethink your entire design I mean not in this one but in a more complicated design you might be able to manage to use fewer. Whether that's a worthwhile exercise or not depends how much you need to think about your area. Anything else. So what I want to do in the last 10 minutes or so is give you an outline for how you design a finite state machines we really kind of walk through this on Monday with our keyless entry system but now I want to give you an overview of the process this is mostly just to give you a way of thinking about what are the steps you need to do to design a finite state machine. So here's a structured methodology six steps so develop an abstract model of go through each of these in more detail so develop an abstract model specify your IO behavior complete the specification remember that for a digital system it has to be complete digital system just runs on bits there's never blank bits or anything like that so we need to make sure we think about what's going to happen when when something is outside of the intended behavior. So we'll have to complete our spec choose the state representation that's going to affect our logic so talk a little bit about how we think about doing that. Calculate logic expressions for next state logic and output logic and then just implement with flip flops and gates so those are six steps. Alright so the developing an abstract model this is really just thinking I want to build something I know what I want to build in human language but I have to turn that into a model and I have to have states in my model that can be eventually represented with bits. I know need to know what desired behavior I want right so when I talked about the keyless entry we talked about well my car's locked I walk up to it I push a button a couple of times and I'm locked certain number of doors then when I leave I want to push another button to lock it back up. I get a little scared sometimes so I want to alarm to sound right so you think about the different things you want your finite state machine to be able to do you think about the behavior how you want the inputs to affect that that internal state. It just makes some notes about that and list the states and so list the states of the system maybe right abstract next next state tables to talk about how you move from one state to the next but pretty abstract process at this point. The next step then is to start to formalize by thinking about I always bits right so what are the inputs what are the outputs those are going to be need those are need to be bits and you need to think about what representations you're going to use for your finite state machine. Sometimes your finite state machine will be getting inputs from other systems right from other parts of your of your bigger design might also be controlling other parts of your of your design. So for example when we when we talked about logic combination logic for an ice cream dispenser we said well we have to produce two bits that control how much ice cream is going to come up. Now actually that would have been a timed process so an FSM would be a little better for that purpose right what we did was just give two bits more or less constantly based on the button but. But we have to use whatever spec is there usually we're not in charge of all of the other parts of the system so we have to agree well what bits will our finite state machine produce what bits will it receive right so we have to interact with other systems for that purpose. Once we've done that then we can go back and say well let's now think about all the corner cases right so we know what we wanted to do but what about all the things that might happen right so go through and complete the spec think about well what are all the combinations of inputs make design decisions right so in the keyless entry example we said well we're going to prioritize the buttons we could have also done what we did with the ice cream dispenser and say well now only one button at a time you push more than one will just ignore it and you can make any design decisions you want but you should make some. And try to complete the spec make sure you've handled all of the cases right any implicit assumptions you may to be written down we could leave some behavior at this point as as don't care but if we do that carefully right and then at the end come back and check that it was in fact something that was acceptable. Once you've completed the spec then it's time to pick a representation so you can implement with flip flops they store bits later maybe you can implement with with registers or things like that actually we'll do that next week or so but for now think of it as just flip flop store the bits there's some ways to choose so sometimes the output patterns will be unique in that case well the store bits can also just be the output bits and you don't need any output logic right you just simplified half of the data. You've just simplified half the problem so that's one way to choose you can map states to a hypercube such that your transitions are just along edges of a hypercube that will tend to simplify your logic but one of the best ways for bigger designs is just group your state into meaning for human what that does is it's separate your bits into groups such that most of your logic will only depend on one of those groups and so you can ignore the rest of the variables so I'll show you several examples of this but in the end. But in fact when you get to the design of the LC3 processor in the book you'll see that a lot of the design of the LC3 processor was done with this in mind right using human meanings for the different parts of bits that flow into the finite state machine which controls the computer. All right so step five this one's relatively easy I mean it's something you've been doing for several weeks now so once you've completed your spec you've got next state tables that tell you your next state in terms of your input and your current state you've got outputs in terms of your current state and all you need to do is build combination logic so if you have lots of variables you might want to break up your truth table use a box some of the tricks we've looked at you can you can use components as well if you find it helpful you can build it any way you want to do it. You can build it any way you want and all you need to do is build combinational logic to implement those equations or those sets of those tables basically. So let's say you know state bits that have human meaning will also help you and because again if there's some bits that have well so let's think about some kind of ice cream dispenser bits that specify flavor don't have anything to do with how long we output the ice cream right we can have a counter that controls how long we output the ice cream separate bits that specify which flavor by screen right so now when I decide whether I want to keep I don't need to know which flavor I just need to know if the counter had to reach zero whereas when I want to know which flavor should I dispense I don't need to know how much more time I just need to take those maybe two or three flavor bits put them into a decoder and then one of those lines will tell me well yeah it was strawberry or mango or leechy or something each of the decoder lines would give me one output for different flavor. So the last step then is implementing with flip flops and logic so state bits are then going to be stored in flip flops and your logic is just built into this combinational logic there's nothing really special it's just the same thing we've been doing so do it the same way. So this next state logic then feeds into the inputs of the flip flops and the output bits or functions of the flip flops state the story state so so let's go we actually only got a couple of minutes so maybe I'll save this one this is the example it's already posted so if you want to read through it now for continuity you can find it on the on the web but I will go through it on Friday first thing and then I'll stop one minute early okay thanks. Yeah. you you you you you you you you you you you you you you you you"
    },
    {
        "ECE120-2016-10-31-LEC-28-slides.mp4": " and that didn't get around to it. Remain to them directors of Professor or something like that. So we're going to finish up instruction formats and then start talking about instruction processing. So how the LC3 actually executes instructions, processes them one by one. I'll walk through a detailed example of instruction execution, realize a trend might go way up. And then we will, I think probably on Wednesday, go through the entire ISA and look at most of the instructions. Most meaning, I'll leave a couple for 220. But for the most part, we'll look at the instructions you'll need in our class. So I wanted to put this up briefly again. And then I'll turn the volume down a little bit. So I just want some feedback. So yeah, again, please do think about nominating your TA for the Olsen Award. It's a nice thing. These are for 225. So unless you really enter getting ahead. All right. So last time we saw that in order to simplify logic, we can actually break representations such as instruction encodings into fields. So we looked at that. We looked at a couple instructions and we saw that there's an up code, which tells us, well, what is this instruction supposed to do? What kind of instruction is it? And then the other fields will actually specify the operands for that particular up code. So we looked at a few LC3 instructions. Sorry, I didn't remove the animation from these, I see now. One of those was LDR. So LDR then had three operands, a destination register, a base register, and a six bit offset. And we saw that, OK, here's how that particular instruction works in RTL. We'll go through all of these in detail again. So primarily, what I want you to see here is this structure in the instruction encoding. So you've got the up code, which is always the four high bits in LC3. And then you have the rest of the bits, the other 12 broken up into fields. So there's no overlap here. You don't have to do any complicated math or anything. We're three bit register fields, or multi-bit, two complement numbers. For the add instruction, similarly, we looked at one variant of it. You'll see another one later. And this variant had three registers. So you take source register one, add it to source register two, and write the sum back into the destination register, again, in fields, four bit, up code, and then three three bit register fields. We had some left over. And so we set those all to zero. Rather patent Patel set those all to zero. So there was one more I wanted to show you before we started talking about how the LC3 processes these instructions. So this is the STR instruction. So if you look at this opcode, and you go look it up in the table, I don't expect you to memorize opcodes, but we'll give you a table for that. If you learn it a little, then you might go faster translating code and things like that. So it might be worthwhile. But I would recommend just getting it by practice, and I'm bothering to try to memorize them or anything like that. So it has a source register. So this is a store. So this will have actually the same fields as the LDR instruction, except that the direction will now be from a register, takes some bits from a register, and put those in the memory. So remember the LDR was take some bits from memory, copy them into an instruction. So in this case, you can see the address generation is the same. So we take this base register, we read 16 bits out of it. It's 0 to 7. So any of the registers in the register file, read those 16 bits out. Take these six bits from the instruction, sign extend them out to 16 bits. This is a six bit, two's complement number. So you just copy this sign bit 10 more times. Add those two together, and then go to that memory location and store the bits in the source register named by these three bits of the instruction into that memory location. So that's an STR instruction. And then in words, of course, that's much longer than the RTL. It's one reason we like to write RTL. So that's what it does. So I wanted to kind of go over briefly, well, what is it you need to know about this stuff? So one thing is what we saw at the end of the week last week, which is, well, why do we do it this way? Why do we break things up in the bits? You'll see there's already a question on the homework that kind of gets at that in an upcoming homework. I guess maybe it's not sure if it's the one that's out now or the one that's coming next week. But you'll get a question about this kind of on a homework at some point. Know the terminology, so things like opcode and fields of instructions. And eventually, in the next today and Wednesday, I'll show you how the different kinds of operations work. And you should have some idea of how they work and the kinds of things you can do with instructions, because you will start to have to program in a class, at the end of the class, in the last three labs. And so you need to know what you're targeting when you're breaking down the tasks down to the instruction level. So the better you understand, well, what can you actually do in an instruction, easier that process will be. And then finally, how those operations can be executed on the data path. So I'll show you that as we go through it. So we're not even going to look at return from interrupt. We won't look at interrupts in our class. But if the question is, do you know how to take a finite state machine state in the LC3 and map that to control signals? Yeah, for the data path in the book. That is one of the things we'd like you to be able to do. You've already seen that on the previous example in terms of a very simple data path with six control signals and a finite state machine. The LC3 is a bit more complicated. There are a couple examples you can look ahead to and set you to 401. All right. I can set it. Come on. I did five. Sure. I'll be now out here back. Thank you. Thank you. Thank you. OK. So I hear two questions. One was, do you need to know where the fields are for each of the up codes? No, but you need to be able to read the table, which means you need to be able to translate all the things in the table. So if we give you instructions, you need to know how they work. You don't need to memorize that. And then the first question was, well, why are they designed and LC3 are the way they're designed? No, we're not going to go much into that. But other than to say that they're splitting the fields to make the logic much simpler. So when you look at the data path, you probably notice that things are pretty simple. There isn't much extra logic, besides from a few moxies, sign extension, things like that. Because they took the time to do a very careful job designing the ISA with that goal in mind. If you're interested in more general ISA design trade-offs, you can read section 4.3 of the notes, which is a start section. But it'll talk about instructions that architectures design. But beyond our class, OK. So that's just for this. This is one field for STR and LDR. And it's an offset because it's being added to the value in the space register. So your memory address is taken by adding these two numbers together. So this is an offset relative to the value stored in the base register. It makes sense. Yeah, the particular fields will be on a per op code basis. Each op code will have a different set of fields for its operands. Muhammad. Sorry. Yeah. The source register are the bits being stored to the memory address. So the base register in the offset are used to create the address, to calculate an address. And that address in memory is where we're storing the bits of S on. We're talking about add immediate. We haven't even gotten there yet. Let me come back there. Let me get there first. OK. So all right. So what don't you need to know? We don't care if you learn the LC3 encoding as long as you can use it. So don't bother trying to memorize it or anything like that. In particular, if you want to know what will give you on the exam, under the Wiki, under resources, LC3 handout, there's I think four pages that will attach both to midterm 3 and to the final exam. So you won't need all of it on midterm 3, but it'll all be there if you really want to look at it. It has things like the LC3 instruction encoding with RTL for every instruction. It has the LC3 finite state machine state diagram. It has explanations of the control signals. So that handout will be attached to both of the exams. OK. So let's then think about, well, how does the LC3 actually process these instructions? So you've seen some examples. The LC3 is going to execute those instructions using the data path. But the data path can only do so much. So for example, think about the memory. The memory, the way we designed it, you can either read, actually, it takes more than a cycle. I think it says a cycle on the slide. But you can read or you can write. You can't do both. And you can't do two. You can't say, hey, I want to do two reads or four reads. So and it might take many cycles just for one. The tell design, there was an R signal. And until the memory says it's ready for something else, you can't go ahead and do something else. But to do an instruction, well, the instructions are sitting in memory. So how do we know what the instruction is until we do a read? So to get the instruction, that I read it for memory. But then what if it's a load? We have to read again. So what should we do? Don't panic. There's nothing new. So all we're doing is breaking things down. So first day of class, I said, how do you make a peanut better sandwich? And you helped me break things down step by step to try to help me keep less hungry. When we designed the keyless entry system, if you want to open all the doors in your car, you have to push the button twice. You push it once, your driver's door in launch, you push it again for the other doors. So we just need to break instruction processing down into steps. And each step then has to execute on the data path that the LC3 has. So we have to simplify to the point that our states, our finite state machine states, can execute on the LC3 data path. So what kind of things do we need to do? So first thing is, well, we need to get the instruction. Computers just going to execute instructions. Structions are sitting in memory. Computer doesn't know, oh, that instruction does such and such until it actually goes to get the bits. So that's to fetch the instruction out of memory. Then it has to take a look at it, meaning there's going to be some finite state machine state that looks at the bits of the off code. So well, what are they? Is it an add? Is it a store? Is it a load? What is it? So that's called decode. Those always have to happen. So those two, every instruction, go get the instruction, look at it to see what it is. It has to happen. Otherwise, you don't even know what it is. For some instructions, then we need to evaluate an address. If you're going to do a load or a store, well, load or store to what memory address. So there might be some computation as there was an LDR and SDR to add things together, whatever, calculate the address for memory access. Fetch operands from the register file. If you're going to do an add, we need to take the bits out of two registers. You can put them in the ALU to add them. So fetching operands, another kind of thing we need to do. Execute. So when we do an add, we have to use the ALU to add things together. So we've got to do execution. And then store the result back to the register file or back to memory. Once we get bits out of the memory, we want to put it in a register, where we do a sum, we need to put it back in a register. So these are the kinds of things we need to do with instruction processing. Not every instruction needs all of them. So sometimes we'll do some of them, sometimes we won't. We'll always do fetch and we'll always do decode. The rest of this stuff is just sort of general categories to help you think about the kinds of things you need to do when processing instructions. So don't worry too much about them. The book will mention them. The book will give you definitions. The definitions there are a little fuzzy too. What matters do you understand? You have to take the LC3 instruction, the RTL for that, and break that down into steps that are simple enough to execute on the data path. And you always have fetch and you always have decode, and then you'll have some more steps. As you'll see, it'll be one to five more steps for each of the instructions in LC3. So let's focus on these two parts that we need to do all the time, fetch and decode. So we'll start with fetch. So here's our data path. Hopefully this is visible. I thought about giving you a handout. Can people read this in the back? Are you getting a little fuzzy? If you've got your LC3 or your patent to tell book, it's just taken from that, from FigureC3 in the back. So where are the bits of the instruction? Before I go get them. They're in memory, right? So they're down here in memory. Good. And where do we want them to be? Well, remember there's a special register as part of the control unit in the bunnoiming model that's supposed to hold the instruction bits? Register files part of processing unit. So control units over here. Yeah, instruction register, right? So in order to execute the instruction, we want to copy the bits out of memory into the instruction register. Then the finite state machine here can look at those instruction bits and do whatever it says. So we need to somehow get these bits out of memory over to the IR. So how are we going to do that? So the last step then is somehow copying bits into the IR. You can see that it copies off the bus. So memory, though, can't write to the bus directly, right? And memory's down here, and it can go to the MDR. OK, so maybe that's what we need to do. Memory can write into the MDR, and then that memory from the MDR, those bits can go over to the IR. And so those will be our last steps. So let's put those in context. So the last step is take MDR, copy it across the bus into IR, and then whatever we do right before this step, we're going to have to fill MDR. So in other words, we do a read operation. But when we do a read, whenever we do a read, remember there's also this MDR, memory address register. Whenever we read from the memory reads from the MDR. So that'll copy memory at MDR into MDR. So here's our last two steps. We don't know how many states the whole fetch will take right now. So it's called at state N, copy memory at MDR into MDR, and then the last one, copy from MDR across the bus into IR. So how do we set MDR? Let's go back and take a look at the data path. So where's the next instruction? In other words, what's the address of the next instruction? Then the program counter, right? Good. So it's up here in the program counter. So I need somehow to copy PC down to MDR. So how can I do that? Yeah, I just copy. And see, there's this gate PC here. So I'll just turn on the gate PC. PC will be copied onto these 16 wires. They'll go everywhere around the stick black line, the bus. And then in MDR, you can see that it loads from the bus. So I'll just turn on LDMAR, and that will give me PC copied into the MDR. So in the same cycle then, sorry, hopefully that was clear. So we'll set gate PC and we'll set load MDR. As part of our control signals. In the same cycle then, I want to set PC to PC plus 1. Then we'll be ready for the next instruction. So the PC, after the first fetch cycle, will point to the instruction, the new next instruction. So instructions, we're going to execute just in order in memory. So we'll be at some address, say, 5,000 texts. And then we'll go to 5,001 and 5,002 and so forth. So in the fetch, we're just going to, in the first cycle, copy PC into MDR, but we're also going to copy PC plus 1 back into PC. And notice this doesn't use the bus. The wires are all in this circle. And that's important because the PC is carrot, I'm sorry, the bus is carrying the PC. So the bus can't also carry PC plus 1. It's a different number. OK, so here's our full fetch sequence. So in three states, first one we do two things. Remember these are parallel. So MDR gets PC and PC gets PC plus 1. Second state, memory access does a read. So memory at MDR, the bits come out. They get put in the MDR. And in the third state, we copy the bits from MDR over to IR. So there's something I want you to notice here, which is if I execute an address, I'm sorry, if I execute a PC in instruction at some address, what's the value of PC when the instruction executes after the fetch? PC doesn't no longer points to the instruction that we're executing. PC now points to the address of the next instruction. So it's the address of the current instruction plus 1. That'll be important because in LC3, we have a lot of instructions that make use of the value of the PC. So you need to remember that it's not the address of the current instruction. It's that address plus 1 in all cases. No, it is always true. It doesn't use PC. Whenever you use PC, PC is the address of the current instruction plus 1. Sasha. Yeah. Right. 5, 2, 3, 4, 5, 5, 6, 6. That's this one up here. Yeah. Yeah. Thank you, Gerard. Thank you. No, this is all happening in one clock cycle. So this is a clock synchronous sequential circuit. So you can see there's a separate set of wires that come over here from the PC. And then they go through this plus 1, which is just some logic to add 1 to a 2's complement number, or an unsigned number, either 1. That then comes to this MUX. And we're going to select this input. And then we're going to set load PC. So on the rising edge of the clock, PC will become PC plus 1. On the same rising edge, MAR will copy the old value of the PC off the bus. So it's just two separate registers that load new values in the same clock cycle. No, because remember that if the rising edge comes, these things happen simultaneously on the rising edge. It's just two separate registers. So it's no different. I mean, it's a good question, but there's no difference from our previous data path where we had multiple registers being loaded at the same time. And this is an important difference between hardware and software. So whenever you see RTL, these things will happen simultaneously if they're put in the same clock cycle. And so all the right sides have the old values, and all the left sides will be the new values. Yeah. OK. Anything else on this one? OK. So let's go forward and see how these three states can be accomplished. So look at them in a little more detail. So here's the first state of fetch. So PC Mox is set to take this PC plus 1 input. So this is what I was just describing. So we'll go through them a little more detail. Load PC is set to copy the output of the Mox, which is PC plus 1 back into PC. Gate PC is turned on to put PC out on the bus. Now that'll be the old value, not the new value. And then LDMAR is also set so that the value put onto the bus by gate PC, which is the old value of the PC, is copied into the MAR. So again, both of these changes to the registers happen on the rising clock edge. These are just normal flip clock based registers. So when the rising clock edge comes, MAR, we'll have now a copy of the old value PC and PC will now store PC plus 1, the old value PC plus 1. So why is this the bus? Kind of a normal, free, possible memory study. So you need to tell the memory what address to read from. And that address is stored in the PC. So in order, the memory only looks at MAR when it does a read. So in order to get it to read from the address stored in PC, you have to copy the bits out of PC in the MAR. That's okay. Sure. Well, how many? Five seconds. Yes. So in the second state of fetch, which we'll look at in a second, we'll tell memory to go do a read. And it will read from this address that we've just stored in MAR. Yeah, that's the third and I'll illustrate that too. Okay. So here's the second state of fetch. So memory, we're going to enable by setting this input to one. I've kind of masked out the IO logic. This is the one the figure I put in the notes, but the IO logic we're not going to use in our class. So you sent memory enable to one. Notice that this mux is also controlled by memory IO enable. So that will take the output from memory, which goes through this IO logic again. But it will take the bits coming back from memory and store them into the MDR through this mox. The read write signals put here. So we're going to tell it to do a read when we're doing fetch. And then the LVMDR signal is also set high so that MDR when memory comes back with bits will store the bits for of the instruction at the address MAR. So this is the, here's some control signals for the second state. So we're just copying again. The memory at this address MAR into MDR. So we're just doing a read. This is how the read works on the memory. All right. Then the last state is just a copy from MDR across the bus into into IR. So that's relatively easy compared to the last two. So we set gate MDR to one that allows MDR to be copied out onto the bus. And LDIR is also set. So it takes the value of MDR, which is now on the bus. And it copies it stores it into IR in the in the third state. It's sense? We're good. All right. Okay. So fetch is done. So each of each type of instruction then is going to use a distinct sequence of finite state machine states to execute. Okay. So we'll have one set of states for add a different set of states for LDR, a different set of states for FTR. And in order to get to that sequence, well, we need to say, well, what is the op code? Right. Now the finite state machine can't look at the op code. Can't use those bits until they're in the IR. Remember, in fetch state three, we're copying them into the IR, but they're not there until the rising clock edge. So we can look at them in cycle four, state four. Okay. So state four, that's all it does is it looks at them. And then it jumps to a new finite state machine state, one of 16 based on the op code. That's all it does. So we call it a decode state. I should do something else until you later, but for now, the important part is switched to one of the 16 sequences for that particular op code. Whatever the op code is, the op code is stored in IR 15 to 12, the first four bits, the high bits of the instruction register. All right. So here's what we've got. So instruction processing is going to look like this. These first three are fetch. Right. So MAR gets PC PC gets PC plus one. That's in state one state to read memory and MAR copied into MDR state three copy NDR into IR state four decode and then some variable number of executing the instruction. That's how we process instructions for the LC three. In general, every process is going to have fetch decode in some set of execution states. It's always going to take some number of cycles to fetch some number of cycles to decode some number of cycles to execute. So what's the relationship between states and cycles? Well, each of those states is going to require at least one cycle, but some might require a lot. So many remember is fairly slow compared to the processor. Real DRAM memory would be even order 100 cycles compared to a modern processor. So quite slow. Memory access states such as the second fetch state can thus require more than one cycle. So those states will actually have self loops or they'll sit in that second state of fetch until memory says, OK, the bits are now in the MDR. So the sequence cycle might take 100 cycles. Doesn't matter the finite state machine has to be designed to wait for the memory to finish. All right, so here's the state diagram. So let me highlight some things for you. So here's fetch up here. You can maybe can read the RTL. That's just the RTL we've been looking at. Here's decode. And you can see it branches out into a bunch of different chains of instructions. Right. And there's just one sequence for op code. So if you go through and look carefully. The shortest is one. Because this is add over here. So the shortest is just one state to execute an instruction and the longest is about five. So some of these some of these for the different loads and stores actually overlap in states. So they share some of their some sequences. But generally speaking, you do fetch, you do decode, you figure out what it is in decode, you go execute for a few for a few states. And then you go back up and find a new instruction. So after you finish, you go back to the first fetch state. So finance and machine fetches and instruction decodes instruction executes the instruction starts over. And that's it. It's computer. So now you know how to build it from transistors. So, so here's a little thought problem for you. And I mean, you can be honest or not. I won't really even ask you an answer. But think about it. So if at the start of the class, I couldn't have even asked you this question. Right. What I really wanted to ask you is, well, how many bits do you need for the finance state machine? So for this high level state machine, I just showed you how many bits do you need to build a computer? I don't know what you would have guessed. And he wouldn't know at that point. But I don't know what you would have guessed. I kind of feel like I would guess I don't know a million or something something big. 42. That's probably a better answer. But patent pretails answer is six. Right. There are fewer than 64 states in that state diagram. So with a six bit finance state machine. And yeah, there's the IR. There's the PC right. We're playing the same games we did with our abstraction before. So the high level state diagram only needs six bits. So I find that pretty amazing. Right. You can build a computer with a six bit finance state machine. So I think that's kind of cool. Right. Any questions on this? How much you actually this is an actual computer. So it depends on the design. So if you look at something like x86, right. It's been building up a lot of complexity because it's been growing gradually over about 40 years. And so it's a very, very complicated design. I really, I'm not even sure I can make an estimate. And things like the external instructions are actually translated internally and a lot of the implementations into simpler instructions for speed reasons. And so, you know, there's a lot of state on the chip that logically is part of the FSM. In terms of executing the micro instructions. It's probably actually kind of comparable. But there's a lot of other things going on in a high performance design. So for example, they've mentioned this in Pat Betel, but when you fetch one instruction and then you're going to decode it, well, you could usually fetch the next one at the same time. And then why you're executing the first one and decoding the second one, you could fetch the third one and executes more than one stage. So maybe you can overlap those two. Right. And so that's called pipelining. And so most modern hype, pipe speed process, there's all the pipelining. There's also things like simple scalar execution, sorry, super scalar execution where instead of fetching one instruction decoding one instruction will why not fetch two or four or eight. So those kind of things, if you take 411, there's a design competition and some of our students have tried to build those in their in their designs. So I mean, it's in the scope of what you can do. That's pretty aggressive. I mean, just to give you a number, some of my staff for 391, they had a team where they did actually one of the first super scalar out of order process or designs in 411. And they told me they spent a thousand hours between the three of them on that design. So, so that's sort of the high end of of ECE design competitions, but 391 is more fun. But that's because it's the my class. Anyway, so let's see. So the simpler architecture is like arm or alpha. I think again, they have all of the things I mentioned pipelining super scalar fetch and decode an issue. But the core is also probably pretty similar into complexity to LC3. Yeah, and there there's not the complexity of the translation process either. So we'll come we'll come back to that. Yeah, PC has to start somewhere. Yes. And so we'll talk about that later, how we make PC point to a certain point and things like that. I mean, a real computer bootstrapping process PC will be initialized to something and there will be some code that goes and looks looks on a disk usually for for a small chunk of memory, which is the core of the OS and will load that into memory and then start from there. We'll go go to a particular place and read only memory and use that to do some of that bootstrapping process. So that kind of thing you can learn and you can learn at least the fundamentals of it in 391. But we won't we won't do much in our class. Yeah, yeah, in most in most laptops and desktops, there's a bias like that that'll be in read only memory and that'll tell the computer where to go look for for the first chunk of the OS. So there's a bootstrapping process to bring the OS up. Okay, so let's let's actually some of these questions that you were just asking Sasha. So, you know, we just looked at some instructions and said, okay, there'll be a PC and so how does those instructions get there, but you can ask the same sort of questions, right? So when I made a peanut butter sandwich, why was the bad closed? Why didn't they come open when I wanted my bread? Where did the bread come from? Right? Or you know, why was it whole wheat? These are perfectly valid questions, right? So in our model of programming, we'll put bits into memory and then tell the LC3 to interpret our bits. We can also put data bits and memory and, you know, the LC3 can't tell the difference. So if you tell the LC3, execute my data, it will just execute your data for you. And all the stuff that we're just talking about about bootstrapping and things like that, you'll learn in later classes, you can kind of see how it's done in the simulator here, but, but in order to really understand it, I think, wait until three and I do one or talk to me in office hours, I can tell you more. So let's take a look at LC3 instruction processing, what we just did and actually illustrated. So a few piece of the data path. So put memory, register file, PC and I are, MAR and MDR, so it'll look like this. So here's memory over on the right side, I've got 65,000 addresses, except I left a few of them out. Here's register file on the left side, I could all eight of them there. Here's PC, IR, MAR, MDR, and there's some blanks. What's in those blanks? Oh, you're good at this. Okay, there's no such thing as a blank, right, there are bits, there are never blanks, there are always bits, we don't know what the bits are. Why are some values and hex? Yeah, so that's slightly different question, right? I mean, normally in LC3 by convention, we'll put our program at 3000, which is why we're 3000 here. But what I was trying to ask is, well, how come there are hex numbers on here? Because the computer doesn't understand hacks, right? It only understands bits. So that's just for humans. So, so the hex here is just for us, right? All these, all these you should read is bits, right? If I put bits here, it'd be pretty big. So I got tired of writing bits. But the computer is all bits. Okay, so 3000 is 0011 and 12 more zeros. So they got tired of even trying to read it. But yeah, as Eric pointed out, the 3000 is where we'll usually store LC3 program. So when you get in the lab and write your code, you should write it address 3000 by convention. All right, so, so let's get started. So let's say that we tell the LC3 to go ahead and execute. And so the first fetch step is, well, MAR is going to get the PC PC is going to get PC plus one. So what will PC become? 2001, right? It'll get this value plus one. What about MAR? What will it become? 3000 and then it'll happen at the same time as you can tell by animation. So, all right, so to get those new, those new values. So let's put those in there. So fetch stage two, we're going to then go to memory at MAR and copy the bits there into MDR. So first we'll go to memory at MAR, which is 3000. Here's address 3000. You can see the bits here, which for us humans, we can call 67 0 a and we'll copy those into MDR. All right, third stage of fetch copy MDR into IR here's MDR 67 OA. So we'll overwrite whatever bits are an IR will 67 0 a. Those are the three fetch stages. Now we have this instruction over here, 67 0 a and we can execute that. So these are the bits now sitting in the IR that we need to decode and execute. Now, there's three separate states of the finite state machine. So they went in the order that I showed on the slides. Yeah, so you go through the finite state machine one state at a time and then decode you would then start looking at this and decoded and execute it. It's only in the first state of fetch that you add one to PC. Yeah, you know way to start processing the next instruction to increment again. So you will we will get there. Yeah, we have to wait till we finish processing this one. Okay, all right, so 670 a let's put that out in bits. So there it is in bits. So what does that mean? Can you remember what this one is? It's a LDR. Okay, and this one is the destination register. So that's what. R3. Okay, this one is the base register. So it's R4 good. And this is the offset, which is what in hex. So it's complement and so it's zero a and hex, right? So the zero and then a is there. Okay, so in RTL that means okay, take R4 add a extended out to 16 bits. So just put the leading zeros on there. That'll be a memory address. So go there in memory, read that out and store it in R3, the destination register. So let's go back and look at our data path pieces. So the memory address is R4, right? Here's R4. So R4 is 123 zero. And then we'll add the 0, 0, 0 a to R4. So what do we get? 123 a. Okay, so what store to memory address 123 a. So go back to our thing over here. And it's there, right? So 0, 0, F, 0, F. So we'll take those bits and copy those to R3. So 0, 0, so we're going to copy 0, 0, F into R3. So there's R3 over there and it has a bits in it. We'll just write over those and put 0, 0, F, 0, F. And that's our instruction. That was the first instruction. So all that work for one instruction. So what's next? That's good. Start over. Okay. First that state. So MAR gets PC and PC gets PC plus one. So what does PC become? Good. And what's MAR become? Good. Okay. Second state. So MDR gets memory at MAR MAR 3001. That was one of the ones I left out. So let's just say it's filled with 163. So then we'll copy 163. Oops, sorry. Into into MDR. Okay. And then in the third batch state will copy MDR over to IR. So IR will now also have 163 at the end of fetch. So next is decode. So this is just walking through the finite state machine states as we saw before. So we're going to decode the instruction in IR, which is 163. So let's write that out in bits as we did before. And do you remember what that output is? As an ad. Okay. And then this is our destination register, which is R3 source register. R3. Other source register. So it says take R3 added to itself, put it back into R3. So let's go do that. So we take R3 and change it from 0F, 0F to 1E1E, and multiply by 2. And we add it to itself and store it back. That's it for that instruction. So what's next? Okay. Yeah, you can stop. You know, you get to stop in a few minutes. Imagine if you leave the simulator running in the lab. All right. So batch state number one. What are we going to do? What's PC become? 2003. What's MAR become? Good. Okay. So again, I didn't write this one. All right. So let's say it's 770a. That's the memory at address 3,0002. We'll copy that into MBR. So 770a. And then in the third state, we'll copy from MDR over to IR. So IR will have 770a. Going to decode. Take those instruction bits. Okay. So 770a looks like this. The opcode there is. You remember? And then this one is the source register, which is our three. This one's a base register. Or four. This one's the offset. 0a again, right? Good. Okay. So memory at r4 plus 0,000a gets r3. So what's the memory address? Same calculation as before, right? Since r4 didn't change. So r4 is here. It's 1, 2, 3, 0. We add 0, 0a. And what do we get again? 1, 2, 3a. Good. So we're going to store the bits in r3 into memory address 1, 2, 3a this time. So the bits in r3 are 1e, 1e. And we're going to store those bits into 1, 1, 2, 3a. So we not changed 1, 2, 3a to 1e, 1e. All right. What's next? Yeah. For the LC3 back to work for us. Yeah. So that's the end of our instruction sequence. So what is that? That's three instructions. And all we did is we went to memory. We read the value out. We multiplied it by two. We put it back. Right. What if r3 had something important? What if it had the only copy of your secret key? Your encryption key? Too bad for you. All right. It's gone. Don't do that. You're the programmer. The programmer controls a computer. A computer just does what it's told. If you have something important and you overwrite the bits, those bits are gone. Right. So be careful. The computer will do exactly what you tell it to do. And if you had something important and you lose it because you told the computer to overwrite it with something else, your bits don't just magically come back. The computer doesn't stop and say, you know, I think you care about this. It just throws them away for you. All right. Yeah. Not that. So we'll get to that with part of the ISA. But let me just answer you briefly. So halt. What it does in the in the virtual world of Pat Patel is it turns the computer off. What it does in the simulator just makes the simulator stop running. And now it might change register values. So if you're trying to inspect things, tell the debugger or the simulator rather to do a break point and stop at the break point. But if you execute halt, you should always end your program with a halt. And that'll stop simulating. That'll stop the simulated processor. Continue and do. Anything else before we go on? Yeah. What does it do for you? So pretty much any computer you use for any purpose is executing instructions. So at some level, you know, your phone, even your watch these days, the software that's written on them has to be mapped down to this level in order to execute. So what it does is everything computers do. This is the only way in which you can make computers do things is to execute at this level. Now we built things on top of it to make it easier. So the one that will get through in this class is an assembler so that we can write. Things. I'm going to go back a couple more things that look like this line. Instead of things that look like this line. So in next week, you'll be writing this kind of line with zeros and ones. In a few weeks, you'll be writing this kind of line with with, you know, our one nice human friendly terms. Next semester, you can actually write C and compile that down on x86 and run that. But, but you know, at the end, at the end of every execution process, the only thing the computer knows how to do is these bits. I mean, it'll be a different encoding for x86 or for ARM, but it's still not much more powerful in terms of what it can do. Good question. Yeah. Okay. We knew. But you're changing the piece that you're not reading it. Sorry, but, but PC, I mean, the old value of the PC is not relevant if you're changing the PC. You did add, you added one before you executed. You always add one in fetch. Yeah. Yes. Yeah. The addition, the increment of the PC happens in fetch. So anytime you use PC in the RTL of an instruction, the value of the PC for the execution is the address of the instruction plus one. Yeah. When you're writing to the PC, the old value doesn't matter. All right. All right. So let's see. So we can talk a little bit about this and then we'll pick it up on Wednesday in a couple of minutes. So we'll talk about a little bit. So in the, in the ISA, we'll have three different kinds of offcodes. You've actually seen examples of a couple of them. So one is operations. Right. So those are the things we'll do with the ALU. The second kind is data movement. So we have register bits moving to memory, memory bits moving to register. So two in front memory, we call those data movement instructions. And then the third kind is control flow where we want to conditionally change the program counter. So let's take a look at each of the three kinds. So when we talked about LC3, we mentioned that the ALU only does three different operations. Right. So there's add and not. Each of those operations has at least one source register and one destination register. And then for, for add and end, we're going to have a second input operand. So where does that come from? We have a couple of choices. So one choice is, well, we can use another register. That's the one I've shown you already. The other choice is to store some bits in the instruction itself. That's called an immediate operand. And you have the choice of addressing mode for your second input operand. So you can have a register or you can have immediate value. So let me show you how that looks in terms of encoding. So first of all. Two op codes for the for the two input operands, the binary operators. So add is zero, zero, zero, one. And is zero, one, zero, one. The mode bit here, I are five is what decides which of the sec, which is the addressing mode of the second operand. So one choice is that mode bit is a zero. And that says, well, the second operand is also a register. So in that case, these two bits have to also be zero. And then you get SR2 here. Now, that's the one you've seen. Right? So when we didn't add before, we had two input registers. We added them together. We stored it to the destination. The other choice, though, is to put a one for the mode bit in which you, in which case, you get a five bit two's complement number. So that means the second operand where you add your end will be the five bit two's complement number sign extended out to 16 bits. So what can you do with the media mode? And why bother to have it? So one thing is you can add small numbers. So for example, it's pretty common to want to increment or decrement. If you're going to run a loop, you want to do an increment, you do an increment decrement. You can go up to or down to negative 16 with five bits up to plus 15. You can also mask out your high bits. So if you want to just look at the low bits of a number, you can end it with immediate one or low two bits. You can end it with immediate three. That'll throw away all the other bits in the register. And all the other bits will be zeroed out. You can also mask out low bits. So if you want to zero the low bit here, you can end with minus two. And that'll give you a FFF is minus two. So the low bit will be set to zero. Or if you want the last two bits set to zero, you can end with minus four. And then probably one of the most important things you can do is put zero in a register. So if you want to count from zero to nine, well, how do you get a zero in LC3? So one way to do it is to use and. That's a common way to initialize a registered zero. So just some uses for the immediate mode. Yeah, let me show you this one. And then we'll stop for today. I'll show you how it works in the data path on Wednesday. So this is the not. So you only have one operand. So in this case, I or five to zero have to be one. So the not the not operand is one zero zero one. So that takes S R one calculates one's complement of S R one and puts it back into DR. So let me stop there and I'll see you on Wednesday. Enjoy your Halloween. Thanks. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you."
    },
    {
        "ECE120-2016-09-26-LEC-14-slides.mp4": " The comparator design, and then we'll go through that design and analyze it in terms of area and delay. And think about optimizing it. We'll do a little bit of algebra come up with a better design. Then I want to take that design and think about what we can do. So the design we're working on is an unsigned comparator. So we put in two unsigned numbers, and it tells us A and B tells us whether A is less than B equal to B or greater than B. So then I want to think about, well, how would we build a two-s complement comparator? And so the answer we don't want is we'll start over to a bunch more K-maps. So we'll see what we can do. That's probably about as far as we'll get today, hopefully. But one thing the midterm grades are posted. So we finished grading them on Saturday. The standard plan, by the way, is the Saturday after the midterm, we're going to all sit down in grade. So it's kind of a standard process so you can expect your midterm grades to be done by that Saturday and up usually by the afternoon and it's not by the evening. So those have been up a couple of days now. I will send a few emails related to that. I mean, generally people did well. I want to maybe talk with a few people, make sure people feel like they're on track for getting a grade they're happy with in the class. But and feel free to talk to me about the same during office hours tomorrow, one to three. It may extend them a little bit, but I'm not quite sure which direction yet. I think my next meeting is at four. So maybe at least I'll stick around a little longer if people have questions tomorrow afternoon and over in daily bite. All right. So I wanted to review, since we had the whole weekend to do other things. So I wanted to review the design we were working on. So remember, when we compare as humans, we write the numbers down, line them up, and then start on the left because the left side's a bigger side. And so as soon as we find a difference, we're done. But of course, when we're designing a digital system, it's not so easy to just have the wires suddenly give us an answer. So the information will flow all the way to the end. And then we'll look at the wires at the end. And that'll tell us the answer with what's a related to b. So it doesn't matter for the digital system, which way we go, right? Because the amount of time it takes, the logic is going to be the same. So I thought, well, let's just design the other direction. Our choice will actually affect our logic. So you can do different approaches, and sometimes that'll affect your logic, something might be easier other times it might be harder. But our comparator here in class will go from least significant to most significant bit. So this was our bit slice abstract model. So we have two bits coming in. Remember, there are two bits because there are three possible answers. So for all of the less significant bits, we can say, well, a was less than b is equal to b, or a is greater than b. So in order to encode three different answers, we need at least two bits. So we've got two bits coming in. Similarly, our answer of whether with this extra bit in the front, a is less than equal or greater, we need two bits to encode that answer, pass those usually to the next bit slice. But at the end, we'll have our answer. And then we get one bit of a and one bit of b into this bit slice for bit number m. And then we talked about, well, how do we actually choose the representation? There is no natural representation. If I said, OK, everyone pick their favorite, or pick what you think is best. And then we looked at them all. There are 24 different ways to assign these three different messages to these four different bitcoding. And I'm sure that none of them would have a bigger distribution, or a bigger number of students than other ones. Well, maybe you pick this one because you've seen it already. But other than that, there's no real reason to choose one over the other inherently, except a little bit. So if you look at this, there is some symmetry here. So the equals case, I chose a pattern where the bits are equal, the less than and greater than case, I chose a pattern where the bits are different. So there is actually a little bit better advantage. If you look at symmetries, then try to reflect those symmetries of the answer in the bits, often your logic will end up being a little simpler. Because we did this, you'll see that the one bit solution that we calculated initially will also show up in the full solution. So I'll call that out for you as we look at the designs. But you'll see the one bit solution, the circuit, where that one bit solution appearing in the general solution, as we solve the problem more generally. All right, so this was our single bit solution. So I said, well, for the end bit, we don't have any extra bits to look at. And so those are implicitly equal. So let's start with this easy problem, or easier problem, of saying, well, what happens when we have one bit of A and one bit of B? What is the meaning of the answer for that? Of course, if we have 0 and 0, those are equal, or 1 and 1, A is equal to B still. Here, A is 0, B is 1, these are unsigned again, so A is less than B. And then 1, 0, A is greater than B. We code that with our representation, and those are the bits that get passed out for the first bit slice. Now, of course, the real bit slice we're going to build for the first bit slice will look like this, and so we'll feed in zeros to that bit slice in the real design. But we just wanted to calculate this answer. And that gave us this circuit diagram, where the min terms here, these are, sorry, let me go back to that. Each of these functions, remember, Z1 and Z0 is a min term, meaning that it has 1, 1 in its full truth table, 1 output of 1. And the min terms are A0B for Z1, and A prime B for Z0, sorry, I should say that is AB prime for this one, and A prime B for that one. Now, again, those two are the ones that say that A and B are not equal. Those are the min terms that say A and B are not equal. So for example, if you wanted to build a simpler comparator that simply told you whether the two values are equal or not, then you could or these two together, and it turns out that would just be an XOR gate. And so an XOR also tells you whether the two input bits equal or not. Not equal, you're going to want equal, you get a 0. OK, so now we're ready, hopefully, to solve the more general problem. I won't flip back to the representation because it's actually here for you. OK, so we've got the, on the left side, our inputs, we have A and B, one bit of the current number, remember this is the most significant bit. So we're getting input from the less significant bit. So A and B are the most important bits to look at at this point in the number. C1 and C0 encode the answer for all of the lower bits. And so when I say the representations we've produced here, 0, 0 means A equals B for the less significant bits. 0, 1 means A less than B, 1, 0 means A greater than B, and 1, 1 should never happen. All right, so let's go through these. So this is one quarter of the truth table we have to write out in order to understand the design. So I want you to kind of get a feeling for what's going on here. So in order to find the answers, we have to look at the meaning. So we have to use the representation that we chose to decode C1 and C0 into a human meaning. We have to then calculate the right meaning for the output. So given this meaning and these bits A and B, what should we tell the next bit slice, A relative to B, and then we have to use the representation a second time to encode the answer. And so when you're picking a representation, the relationship between that representation and the resulting truth table in KMAPs is not going to just be trivial. You're not going to be able to say, oh, well, if I change it a little bit, that'll make my KMAP easier to solve. It's not unfortunately quite that easy, right? You have to go through it twice in order to get the truth table and then you have to take the truth table, put it into the KMAP. It's often not easy to see. So that's why with something like 24 different choices, often it's better to say, hey, computer, go look at all the answers and find the best one for me. So for something this small, 24 is a tiny number, right? Even thousands or millions are usually pretty tiny for a computer. So they can solve those kind of problems. If you get a much bigger design, something like you'll see with the LC3 micro architecture, we have many, many bits, a computer can't solve it, right? And that's where you really need human intuition about symmetries, different kinds of information that don't have to be related. Where as a human, you break those into pieces, you give the pieces to the computer to solve the small problems and the computer can do a good job with the small problems. But you can imagine if you had instead of four rows of your truth table, if you had 32, sorry, not on this one, but on the representation, if instead you had 32, well, then you have 32 factorial different ways to assign your representation. Even a computer is not going to explore 32 factorial ways for you, right? Not in your lifetime. So, so the human intuition helps you in real designs, right? In this kind of design, we could just hand it to the computer. I think that, but I want you to understand how it's done. Yeah. So remember, inner bit slice, we have four inputs. We have to look at one bit of A and one bit of B. And we also have input from all of the rest of the lower less significant bits, telling us the relationship of A and B for those bits. Now, anytime you have input bits, you have to consider all possible patterns. So with our truth table, all I've done here, sorry, wrong way, all I've done here with our truth table is say, well, I can only fit a quarter bit on a slide. So the quarter I'm going to fit is the quarter where A and B are both zero. And we'll have three other slides. I don't want to show you the answers. We'll have three other slides where A and B are zero, one, one, zero, and one, one. And then we'll go through all possible values of C1 and C0. Yeah. Yes. Yes. That's right. So remember the information flow. I don't think I have the big picture in front, but we'll look at it later. There will be N copies of this bit slice. So all of the copies down here for at least less significant bits will do all of their computation, will decide whether for all of those less significant bits, A is less than equal or greater to B, and we'll tell this bit slice through these two wires. Yeah. Yes. Right. And that's part of filling in the truth circles. So hold on to that thought. Any other questions? Okay. All right. So, Mahalini points out that C1 and C0, we probably only care about when A and B are equal. Right. Because A and B are the most significant bits in our design. Right. So since we're passing from at least significant to most significant, the only time we should care about the inputs are when A and B are equal. I'm sorry, the input C1 and C0 when A and B are equal. Yes. There's one caveat to that which let me get to the non equal slide before we look at what it is. All right. So help me out here. So if I get A and B are zero and C1, C0 tell me A equals B to the right of me. What message should I pass? 0 0. So actually I just want you to tell me meaning first and then we'll encode it. But yeah, A equals B, which is going to be 0 0. So what if I get 0 0 for A and B. And I have A less than B for the less significant bits. What message should I pass? Okay. A less than B. Good. How about this next line? A greater than B. And so you see basically what A and B are since they're equal, I have to rely on what's what the less significant, the relationship between the less significant bits, which is encoded in C1 and C0 for me. So I'm going to pass the same meaning then because my bits and B were equal didn't change the answer. So I'm going to pass the same meaning. How about this last one? It never happened. This is not a human pushing buttons for us. This is not our hand, handheld computer or hand controlled computer. Some switches. This is a bit slice. It never produces one one. So we don't have to worry about this case. So we don't care. So then we can code it over here. We already have the encodings, right? So this one A equals B is going to be one. Zero zero. Right? Good. What about this one? Zero one. One zero. XX. Good. All right. So this is a quarter of our truth table. We've got three more slides to go. So this is the A equals zero B equals zero case. So let's then do the A equals one B equals one case. Is there any difference? There's not right. A and B are the same. So we have to take the answer that our less significant bits gave us as encoded in the C1 and C0 inputs. And just pass that along to Z1 and Z0 using the same representation. And so we just forward those bits. So A equals B equals B. A less than B. A less than B. Good. And then the bits are the same. So it looks exactly the same. Right? Outputs are exactly the same as the last case. All right. So now what about this case? A equals zero and B equals one. So when A equals zero and B equals one. And the less significant bits are all equal. What relationship do these have? A less than B. Right? Because this is the most significant bit. He starts with a one and sign number. He starts with a one. Be bigger. Doesn't matter what the rest of the bits are. Be bigger. And that's where you'd stop comparing as a human. So A less than B. So if it doesn't matter what the rest of the bits are, will A less than B also send. A less than B. Right? Not because of this, but because B is one. And A is zero. And even though these bits A is greater than B, well, this is the leading bit. So A less than B. It's about down here. Don't care. We couldn't say A less than B, but we don't need to. Right? If we put out a different answer here, it doesn't matter because this case won't happen. So somehow this, this answer enables us to get a simpler logic. Let's take advantage of it. So this is the, this is the caveat that I mentioned in answering. Question of the Harvard that, you know, even though we know the most important bit tells us A less than B, we also know that this should never have happened. So I don't care what answer I put out. And so this is the one that overrides because. It doesn't matter in this case. It should never happen. So I can take advantage of the flexibility. Now, I don't actually even know if putting X this year gave me a better function. But I want to make sure if it can. Yeah, I mean, we could put zero one here, but that just means there are three functions. Well, three times three is nine functions that were not considered. Okay. So always out food A less than B for valid inputs. And so the valid inputs is the caveat. All right, good. And what about equals one B equals zero? A greater than B. So A greater than B. A greater than B. A greater than B. A greater than B. Don't care. And those are all coded the same. All right. So now we have our truth table. I'm not going to walk through copying the K maps. I'm just going to pop up the K maps with all the values. Okay. Is that okay? All right. I mean, we can go through and copy it, but this is what you should get. So what I've done here is I put A and B on the top. I put C1 and C0 on the side. And so these are essentially the same as our truth tables except that the bottom two rows, of course, are flipped. And then the order we did the truth tables was 0011, 01, 1, 0 on the slides. Where the loops. Right side. That's what I picked first two. What is that one? A, B, not. It would be prime. Okay. So A, B, prime. What else? Bottom right corner. Hey, look. That's what I picked you. Okay. What is that one? I'm hearing different answers. So, okay, right side is A, right? And then bottom is C1. So AC1. Okay. Good. And then what else? The bottom left two except. You can go this way to wrap around. Okay. So we're going to wrap around. Okay. Good. Little messy looking. I guess I'll run my hand. Tell our, tell our students that Microsoft that we need wrapping, wrapping defaults, arc things. All right. So what is that one? B not C1. Good. So. This is sort of a majority function. I hesitated to call it this, but it's a majority function. So, the value of B prime is valid input, right? So if two of these three are equal to one, then Z1 is also equal to one. So if we write that out, AB prime plus AC1 plus B prime C1. If any two of those are one, then Z1 is one. Yeah. Yeah. So the question that Muhammad is asking is, should you make the loops as big as possible? Because you need to change the original rules for finding prime implicants. You do need to find prime implicants, right? So you need to make them as big as you can. Circling X is okay. Circling zero is still not okay. Right? So make them as big as you can. Choose as few as you can. And always cover all of the ones. You do not have to cover X's. Okay. So the change is, I put them on a previous slide when we, when we introduce X's. But make the loops as big as you can. Cover all the ones. And don't need to cover X's. So that's the rules we've applied here. And that gives us this minimal SOP form. Yeah. Is this one unique? Okay. So that's a good question. Did I make any choices? So when I went up here, right? I could go. I could not go left. Left. I could not go right. I could go down. I could go up. And I did go in both directions. So I didn't make a choice. For this one year, I could not go left. I could not go down. I could go these two directions. I went and both. So I did not make a choice. And then I had this one left. I could go, could not go this way. Could not go that way. I could go this way. And that way I went in both. So I made no choice. So since I made no choice in any of these. And I'm done. Yes, it's unique. Any other question? Yeah. It's not that there are unknowns. It's that we don't care. And so we're allowed to leave them as zero. So in particular, we do not need to circle this x. Right? And so in this case, we have a good answer without circling that x. Circling the x would not have bought us anything. And adding this row here of four x's would not have gotten us anything because we wouldn't include any ones. Right? So including the ones is the important part. You're allowed to include x's, but you don't need to. Anything else? All right. Good. So we got another function to do. These are zero. So what are the loops? Vertical one. Okay. Good. What is that? A not B. And what else? Two squares, which one did I pick first? There's one. What is that? A not C zero. Okay. And then the other squares were in the middle. That's B C zero, people are saying. Okay. So same kind of thing, right? Three values, one of which is a prime, but if two of those three values are one, then Z zero is one. So you notice these are symmetric, hopefully. Let me put them side by side. So there's a symmetry both in the circuit diagram, but also in the algebra. That symmetry is there partially from the problem, right? That A and B were just comparing them. So there's no reason to think that A isn't a different than B. If I swapped them, I'd still get an answer. It would be the opposite sense. But also because of the way we chose our representation. If you chose an asymmetric representation, the symmetry would be broken and you wouldn't see it in your design. But here we chose a symmetric representation, where when the two are equal, we have the zero, zero pattern. And when they're not equal, if A is bigger than B, we have one of the non equal bit patterns. And when A is less than B, we have the other non equal bit pattern. So the symmetry shows up in our answer. So that's a nice design. A lot of gates, but. So this is what we get out of our computation. We could stop here. If we were to give you something like this on a homework or exam, this would be a fine answer. I'm going to take it further and do some analysis, because I want you to understand how you do trade-offs and how you think about these things. But this would be a fine answer. And you can go implement it this way, and this would work just fine. Any questions on this? Okay. So hopefully people feel like they followed along and could do this themselves. So, oh, yeah, yeah. So I did want to call this piece out for you. Notice this thing in the middle. Because we're doing information flow from less significant to most significant bits, the most significant bit, of course, is the most important. As we talked about when we did the truth tables. So if you look at this, this is the same functionality that I got when I did one bit, without considering what was happening with the, you know, when there were no lower bits. And so this is my circuit diagram for one bit. And it produces the same answers. And those answers, if this and gate produces a one, z1 is one. If this and gate produces a one, z1, I'm sorry, z0 is one. And so that single bit core is still there. It's just that in order to handle the other cases, when we have less significant bits giving us information, we need this extra logic. But the single bit core of just comparing A and B is still there. One did a V and B and B. Yeah. How would I represent? Dimitri. So the symmetry will actually come out in the form. So you can see that that here, the A's and B's have opposite complement, complementation. So if you look at this term, A and B prime, and then the C1 and C0 are also symmetric in the sense. This one has C1s and this one has C0s. So the symmetry comes out in the algebra is that. But just like we talked about duality, where you replace it, you replace and in order, you replace 0 and 1 with each other. Here, you replace, if you replace A and B with one another, and you replace C1 and C0 with one another, then you get the other expression. So that's where it comes out algebraically. So that's where it comes out algebraically. Yeah. That's a good question. So the question is that Dan was asking, is it possible that an asymmetric group presentation give you a more efficient design, whether better area or better delay? It's certainly possible. I think if you have to pick and you don't want to explore both, I would tend to favor the symmetry. I think it's reasonably good intuition. I think the, it's possible, but I think of just sort of geometric arguments. Like if you have a fixed perimeter and you want to make optimal size area, you end up with a square. So making things asymmetric usually ends up making half of it more complicated and not simplifying the other half as much. So the balance tends to be not as good. But it's certainly worth exploring. Certainly in simple designs like this, where it takes you a few minutes to go do it. Yeah. So I just wanted to call it out so that you see that once we've gotten, once we've decided on the symmetric representation or the use of the mat, of the least significant bits passing information to the most significant bits, that this logic for calculating the single bit solution is still part of our answer. That it's, it's sitting there because the single bit solution is the thing that dominates the answer. So when we fill in the truth table, we said, well, you know, if a is one and b is zero, then the rest of the bits just don't matter, right? Because clearly if the leading bit of a is one, the answer is a is bigger than b. If, if the assume. So that single bit, that single bit answer here is also logically dominating this, this bigger system in the sense that if this outputs a one, z1 is one, regardless of what these gates do, and because it's an or gate. And if this one down here says b is bigger than a is less than b, z0 is one because this is an or gate. So that's how that, that human meaning gets interpreted in the logic. Yeah. Um, easier in the, in the area delay power sense or easier in the human. Yeah, so, so I think you get benefits both directions, right? Yeah, you can't stop. Yeah, that's right. Yeah, so there's no, you can't look at one bit and then suddenly give the answer out of two different wires, right? Someone has to know which wire still look at. So you have to floor the information to the end. So you'll have to carry it forward. So the truth table calculations will be different ones, but more or less, more or less the same. Okay. So what we've got, so let's go through and use our heuristics analyze area and delay. So how many literals do I have here? All right, so remember literals. So it's a little tricky because when, when we talked about literals before we only had one output. So the way I want to count literals is just to look at this diagram and say, well, whatever is going into the first level of gates is a literal. So here's a copy of a, here's a copy of c1. And so forth. So how many inputs do I have on my first level of gates? I have six gates, but how many inputs total? 12, right? Two, two input gates everywhere. So 12 inputs, so 12 literals. And if you look at the equations here, it's going to match, but later it won't quite match. Let me flip back to the equations. So if I ask you to count literals here, you'd also get 12, right? It's okay. Count literals. A, one, two, three, four, five, six, seven, eight, nine, ten, one, twelve. Right? Later we're going to reuse some of our expressions. So it won't be quite as, quite the same. But here, 12 inputs to our, to our gates from the inputs, directly from the inputs. So those are the literals. How many, how many gates do we have? Not counting these inverters. Eight, right? So eight operations. And so that gives us an area of 20 from our heuristic. So keep that in mind. Every bit slice costs us 20 area. Because later we're going to do a different design. We're going to want to compare. Add 12 to eight. Remember our area heuristic was literals plus operators. And when we do that graphically, it's number of connections from the, from the inputs, possibly through inverters to the first level gates plus the total number of gates. All right. Yeah, Eric? Yeah. So the question is, if we were able to find things like exorers, would that decrease speed or, or area? And possibly mean decreased delay and increased speed or something. So it may, in some cases. And so the thing is you have to go through the different representations and work it out. And figure out the balance, right? Figure out which answer looks best. And that's why I said for 21st solutions, just have a computer calculate them all and find the best one for you. I actually did this all on paper after I picked my representation based on symmetry the first time. So I think the representation I gave you is, is one of the optimal ones in that sense. Right. But, but in general, it's worth exploring a few different options that you think might be promising if you're doing it by hand. That's a good question. All right. So let's analyze delay. So to do this, I want to start with z1. And then maybe I'll tell you now I'm going to remind you this is symmetric. So if we do for z1, we're going to get the same answers for z0. Right. So what's the number of gate delays again, we decided not to count inverters. So we're just going to go from a to z1. Two. Right. So there's a path that takes two. And I think probably all the paths take two, so two gate delays are made as a one. What about c c1 to z1? Also two. Right. There's another. There's a pattern c1 to z1 with two. Good. What about c0 to z1? Yeah, zero would actually be a little misleading. It doesn't it doesn't matter. Right. It doesn't have any impact on z1. So let's just say it's not relevant. Zero, we could get confused later. We could think that until I have c0, I can't calculate z1, which is not true. So in this case, it wouldn't have any effect, but you don't want to have that constraint when later you're trying to glue pieces together and figure out the layers. So it's not relevant. What about b up to z1? Two also. Right. So this one does go through an inverter. So if we're going to count that, it might be a little slower, but, but we'll count it as two. We're going to ignore the ignore the inverter. Same way we talked about when we introduced the ideas. All right. And again, the delays to z0 are symmetric. So if you went and did the same exercise, you would get a to z0 is two ignoring the inverter c1 not relevant c0 to and b2. So here, this is what the comparator is going to look like when we glue it together at the low end. So we're putting zero and zero to say that these are equal initially and be equal. And we're going to say a and b are available at time zero. So if I at time zero zero gate delays, I put a and b on my inputs, then when can I expect to see my outputs? So here's the calculations we just made to figure out for the bigger system when the answer will become available. So a and b are available at time zero. I'll just mark those. Zero. So those mean available at time zero. What about these zeros on the right? What time are those available? So these are just constants. So those are just wired to ground. Yeah, negative infinity effectively. Right. So these are always available from from the point of view of the system. These are available when I turn the power on. Right. So we'll just call it negative infinity. So forever. So that's what we have so far. Now what we need to do is use the use the timings we just calculated to let this information flow through the system and figure out when are these intermediate value is going to become available. Yeah. This one. Why is what to? Why is C zero to Z one? So C zero. Let's look at where it goes. So it goes into this gate. Let me delete that. It goes into this gate and into this gate. These gates go both into this gate and that gate changes Z zero. None of that information affects Z one. I'm sorry. I'm sorry. I still can. Yes. Yes. None of the. None of the changes affected by C zero make their way up to Z one. The other way to do this is to go backwards from Z one and to look at the gates that affect it. So. So the gate, the or gate that produces Z one is only affected by the top three and gates. And those top three and gates are fed by AC one B. And I think that's it. So those three variables are the ones that affect it. Yeah. In fact, most tools would define what's called a cone of logic. So they started the output and they go backwards and they figure out what variables affect that that output. And that backwards cone is called a cone of logic. You don't need to know that. All right. Let's roll forward. All right. So we need to use those delays. We found for one bit slice to calculate the times for these intermediate C values between the slices. So remember that all the A and B bits are available at time zero. So what matters most in that input to output analysis is going to be C getting to Z. And all of the A's and B's are available at time zero, even if it's bit number n minus one those come in at time zero. So the thing that's going to be slowest and we care about the slowest thing is C to Z. So we found just to remind you, I would just looked at it, but C one to Z one was two gate delays C zero to Z zero to gate delays. So when is this first set available? So this is bits like zero. Now these are available negative infinity. So that's, you know, probably not the thing we care about for this first bits. So when will these be available? I'm sorry, these are not input values. These are timings now. So these are available at zero gate delays at time zero. Yeah. So how that's the question is how long does it take for this comparative bits slice logic to process A and B starting at time zero and these arbitrarily far back in time. So if you remember the A input going to C one and also A to C zero B to C one B to C zero, those are all two. And so both of these outputs will be available after two gate delays. So I'm going to draw an arrow saying, well, the information is flowing from here. That's one of the longest paths and that'll take two gate delays. So what about the next one? What about these variables on the left coming out of bits slice one? When do those become available? For why? Yeah. So even though A and B are available times zero. So if we think about the past from A and B over the year, that only takes two gate delays. That would make these available to. From here, these answers are not here until time two. So these answers are two plus two is four. Okay. So let's generalize that. So this the C upper script zeros out of bits slice zero available time to which means two gate delays. So C ones are available time for. So what do you think about C and minus one? So our whole system takes two end gate delays. If you build a 32 bit comparator, it'll take 64 gate delays. Can we do better? Probably. But you should ask that. So we have two metrics, right? So can we do better in area? Can we do better into that? And maybe we can do better in both. Can we reduce delay? Actually, without without not using a bit. We can go to bigger bits slices, right? Do two to two bits at a time from A and B or more. That could make things faster. But if we keep a bit slice design, it's actually pretty hard. Bit slice with one bit is actually what I mean. Why is that? Because if you want to reduce from two gate delays to something less than two, how do you implement a function with fewer than two? You got to implement the function with one gate. So unless you get really lucky in your representation, let you implement both of your functions with one gate. Then you're not going to one gate delay per bit slice. You're going to have two, two level logic. So it's actually pretty hard to beat to again. If you do two bits at a time, you might be able to do that with two level logic and that really means you're going to get down to end, right? Because you've only got half as many bits slices as you do bits. So you can do two for each and then you've got overall end delays and gate delays. But using the bit slice approach, dealing with one bit at a time, which is much simpler. It's difficult to beat those away. So let's do some algebra. Algebra is fun. I know I know you all love it. So here's what I want you to do. Here are equations from before. So all I did is copy these. I'm sorry, copy this one. So the first I want to pull out C1 using distributivity. So I've got the AC1, B prime C1. So instead I'm going to write A or B prime time C1. So that's our first step. So I want to say, well, you know, this A plus B prime factor, I could use a nan gate for that. In particular, I could write A prime B complemented. So all I've done is I applied the Morgan's law. So I said, I want to complement this thing. So complement the A, get A prime, complement the B prime, get B, and then complement that and. So now I have Z1 is A B prime plus A prime B quantity prime ended with C1. And then I gave you the same equation, same manipulations for Z zero right down here. So why did I do that? So here you see A B prime here you see A B prime. If I calculate A B prime with the gate, I can now reuse that gate output in two different in two different equations. Similarly, here I have a prime B, here I have a prime B. If I calculate that that expression with the gate, I can then use that gates output in two different places. If I can reuse my gates to calculate these two output variables by by manipulating the algebra a little bit. So maybe I can reduce the number of gates I made. So I have a very good question. So I have to do Morgan generalize to Morgan's and applying duality and then swapping on the compliments of the same thing. This is just one application of the Morgan's loss. This is just applying it once. So you don't need the full power of duality. Any questions. All right. Here's what that looks like. Except I made it into nans. So I turned it all into nans. Why did I do that? Because if you use and or you actually get extra inverters that are not really there. And so I didn't want you to count the wrong sort of diagram that had gates that didn't exist in the real implementation. So this is how you would implement those equations using nand and nor, which is what we have to do and see most. Now, probably you look at this and you say, I don't know that this represents those equations. I certainly do. In fact, every time I come back to it, I confuse myself before I get it right. So I wrote it up for you. So first of all, I wanted to point out though, here's your single bit core again. Right. So those two those two factors we pulled out, those are actually the two min terms we produced for a single bit. So all we need to do is produce those two answers is a bigger than B or is B bigger than a from that one bit. If so, that's going to basically drive out drive all over answers, just like in our last solution. I did a funny thing, which I clipped it before the inverter on the nan gate. So the single big core had and gates in it. These are nan gates. So we're actually inverting our terms before we use them in the rest of the surface. That's not a big. So here, let me try to convince you. So this thing down here now forms a prime B. Right. So a comes through this inverter goes in there, B is here. So a prime B and then it's the nan gate. So a prime B inverter. We're going to take that and put that in this nan gate up here. That's also going to have C1 coming in. So out of that nan gate, we're going to have a prime B prime ended with C1 and then prime again. Happy. This one on the middle left. This is producing a with the prime and it's a man gate. So we'll complement it after that comes out after it's ended. We're going to feed that one into this man gate along with this expression. What we'll get is this thing ended with that thing and then complement it yet again. Which looks like that. So there's our A B prime prime there ended with this thing there and then the whole thing compliment. Now apply to Morgan's one time. So I'll take this prime here and I'll change this and into an or and then I'll compliment this one, which will just take that prime away and compliment this one, which will take that prime away. But that's what we wanted to implement, right. So fortunately, this diagram is symmetric. So I don't have to show you that nasty elderberg again. So you should convince yourself that you think this is right because obviously if you get the circuit wrong, it doesn't really work. It's just some random circuit. So it works on the other hand, it has fewer gates than the other ones, so maybe areas better. So let's think about it. So how many literals. So here I want to be careful on the literals again anywhere where one of these or its compliment goes directly into a gate. I want to count as a literal. So how many literals do I have six. Good. There they are. So this one, this man gate has one literal coming in. This one has one literal and these have two each. So six literals total. How many operators? Also six all man gates. So my area is 12. So smaller area last time was 20. How about delay? A to A to Z1. What about that path? So let me make a comment here. So be sure on A, be sure that you're looking at the longest path. What matters is the slowest path. So there are paths that are only two. If I go this way, it's only two. But what matters is going to be the longest one. So I'm drawing you examples, but the examples are always one of the longest paths. I'm not just picking a path randomly and measuring it. So I'm going to do for C1. Good. And what about B? Is it three? Did I mess it up? I think it's two. Oh, three. Sorry. Yeah, it's three. Okay. I messed up my memory. All right. So three also. There's no, there's no inverter on that path. The reason I keep pointing out the inverters, if you go and read the notes, the notes, count the inverters. So I'm going to go off by one relative to the slides in class. All right. So you might think, well, G is that 50% slower? Three instead of two. So let's go here again. So actually, let me go here and make sure. So A to Z1 is three. B to Z1 is three. C1 to Z1, only two. Okay. And it's symmetric. So the C's disease are two. The A's and B's to the C's are three. So what about this first set of outputs? When is this come available? So same path from zero, add three, we get three. What about this set? A's and B's are done here at zero. So you add zero to three, you get three. So certainly no earlier than three. These are available three. The delay is not three to get to here. The delay is two, three plus two is five. So you take the bigger of three and five, you get five. These are there five. Same slide with numbers change slightly three, five. So when will these become available? Two in plus one. Right. So all we did for the overall design, even though to A to B paths, I'm sorry, A and B to Z paths got 50% longer. The C to Z paths stay the same. And those are the ones that add up as we go through. It's sliced a bit so those are the ones that add up to this two number here. Is the C to Z paths. The extra one three minus two is here. So if the eight, if we did a different design or eight is a Z's became 10, this would just become plus eight. And as long as the C to Z paths are fast. So the full calculation is for every input that matters, you add the delay. So A to C one is plus three. So zero plus three is three. Zero plus three is three. And three plus two is five. And then you take the biggest. So three, three and five, the biggest is five. We're actually at the end of the hour. So I don't want to keep people over time. We'll look at this briefly again and then finish up the discussion on Wednesday. But we can talk more offline if you want to be satisfied today. Thanks. Thank you. You You You You You You You You You"
    },
    {
        "ECE120-2016-10-03-LEC-17-slides-broken-video.mp4": " pushed back, so two to four instead of one to three. I think you got your midterm specs if you want to chat with me, feel free to come by. We're going to start sequential logic today, talking about how we store a bit. So we'll look at a gated D latch and then we'll look at flip-flops going into talking about digital time and the clock abstraction in all of the sequential systems that we'll look at, including the computer. I'll tell you more about that when we get there. We'll spend a little time talking about timing issues in particular, take a look at static hazards and how we can fix them in two-level logic. That's all beyond the scope of the class. So that whole section is just so you understand a little more about timing. In our class, we're going to just sweep timing under the rug and go on at the worry about it too much. But it's good to know for later in 3D5 you'll have to learn a little bit about it. And if you go into hardware design, you'll have to understand a little more deeply. A lot of what people do these days is one common clock and let the circuits people to worry about clock skew. So we'll see that and write it off and move on to the easy stuff about a class. And then we'll talk about registers. So these four topics are supposed to carry us all the way through the end of the day on Wednesday. So we may or may not start serialization on Wednesday and move into part three of the class. This will be it for the second midterm. So basically this stuff will define the second midterm, which I think is still two weeks out. That's right. Two weeks from tomorrow, maybe. Sounds about right. So that's a plan. So so far we talked just about what we call combinational logic. So the idea is that we have the following type of problem. So give you some bits, a, b, whatever. And we want to combine them using rolling expressions to produce some other bits. And so we have some input bits, some output bits. And we've learned, well, how do you make circuits or do that? And we've learned a bunch of ways when you go down to K maps, build them out of man, nor gates, and or not. We can build them out of components like adders, comparators. But where do those bits actually come from? And so that we haven't talked about it all yet. And so where are these bits coming from? They've just been magically appearing as inputs to our circuits. So now we're going to say, well, how can we actually store a bit? When you have stored bits instead of combinational logic, you have something called sequential logic, which is actually much, much more complicated to test and debug. Sequential logic stores bits of state. And so there are going to be bits now somewhere in our system. We'll show you today how you store them using transistors again, of course. But sequential logic stores bits of state and its behavior actually depends on those bits. So what a sequential circuit does depends on what the state of the bits is. And that's what makes it so hard. Because you can imagine today's modern processors might have hundreds of thousands of flip-flops. So the state of that chip is two to the 100,000. That's a big number. So you're never going to run through all the states. That's bigger than the number of electrons in the universe, et cetera. You're never going to test it fully. Actually another good example that has steel from Johnic Patel. If you think about a 64-bit adder, you think, well, surely they test the adder before they give it to me in the processor. Well, if you have two 64-bit values, that's two to the 128 different patterns. So they don't test all patterns for your adder. They can't. So they have to think of better ways to test things. For an adder, it's actually not that hard to come up with a good set of what we call test vectors. But the sequential circuits are actually pretty difficult to test. So we'll start thinking about these. But just like a C program can depend on the state of its variables, the sequential circuits behavior will depend on the state of the state of the forever. Well, depend on the state, which is the values of the stored bits. So what's the one input and then gate? And well, you can smell this stuff. Okay, there's a circuit. What to do? The door is a bit. Yeah. But it doesn't have any input. So I mean, can you prove that it stores a bit? What would you do? Go ahead. You test it. Yeah, unfortunately, there's just some squiggles on a powerpoint slide. So how are we going to test it? When in doubt? The truth table. Good. All right. So here's a truth table that has no inputs, right? There's no inputs to the circuit. So to fill in our truth table, we'll just make a guess. We'll just say, okay, how about a few equals zero? So pick a value. So few equals zero. Put it in the table. So what does that mean about P? P is zero. P is one, right? Because it goes through an inverter, it comes out at the one. Good. And if P is one, what does that imply about Q? P is zero. It's important that you go through all the way and check that. Because there are plenty of circuits where some states may not be stable. This is called a stable state. But some states might not be stable. And some circuits might have no stable states. So for example, if I were to put three inverters in a loop, it would have no stable states. That's a design called a ring oscillator. It's used to produce oscillating, oscillating signals on chips. And people actually use it, but it's an analog system. Basically, it's beyond the scope of what we'll look at in our class. But if I draw that for you and I say, well, what are the stable states? We should say, well, there are no stable states. It's an oscillator. It just oscillates. So here's the stable state, zero and one. But we picked Q equals zero, right? So what happens if Q equals one? Yeah, P equals zero. So fill that in. And then of course, we should check again. What does P imply for Q? Q equals one again. So that's a second stable state. So this two inverter loop has two stable states. So we call it a by-stable element because there are two stable states and by, you probably remember, that prefix means two. So all of the bits on your chip are typically stored using this kind of dual inverter loop. So if you have 100,000 bits on your chip, there are at least 100,000 of these dual inverter loops sitting somewhere in the chip, storing those bits. Well, okay. So that's cool. But how do we set it? I want to put a zero. What do I do? India. That's an input. Okay. Here's an input. S bar. So what happens when S bar is one? Really? So remember, that's an AND gate followed by a knot. So if you put a one into an AND, what does it do? It depends what the other one is, right? One AND something is something. So in other words, if S bar equals one, it's just like we didn't add anything, right? As the same behavior as before. So we can draw a truth table and say, well, if S bar equals one, we've got the same truth table as we did before. Two different rows by stable states. So again, if this S bar equals one, one AND did what something is just this something. And so this happens to be a man instead of an AND, but the property of this part of the gate is the same, right? So now we've just got our dual inverter loop. The green part is our old truth table from the previous slide. And when S bar equals one, S bar does nothing. What about S bar equals zero? Yeah. So that will force q equal to one, right? Because zero going into an AND gives me zero, not with meal one. And P equals zero then, right? So in other words, S sets the bit q to one. So the name S stands for set. And so you want to set your bit to one, then you put S bar to zero. Why is it called S bar? So we call it S bar because the action, meaning set the bit, q, happens when S bar is zero. So it's called an active low input. So you've probably already seen this on some of the components in the lab. Anytime, anytime the inputs activity, whether it's setting the bit, resetting the bit, doing something else is, is happens when you set the input to zero. We set an active low input. And usually we label them with bars or primes in order to tell the human, you know, if you want to do this thing, that the input's supposed to do for you, put a zero in. You don't want that to happen put a one. You can also of course have active high inputs. But so I think in lecture notes on the wiki, you'll see the opposite design using nor gates. So this one uses man gates. If you use nor gates, you'll have active high inputs. So you can do it both ways. We'll look at the active low inputs. All right, so we can set q equal to one. What if we want q equal to zero? Let's turn it on and off. Eventually it'll be zero maybe. What should we do? Yeah, put another input. Maybe we'll call it a different name. We call it R bar for reset. So what happens when R bar is one? Yeah, same thing, right? It's an AND gate. If you put a one into it, whatever was there before is still there. All right, so one has no effect. So if you put R bar equals one in this truth table, the rest of your truth table looks just like it did on the last slide, including all the S box. So we're just baking our truth table bigger, but we still have exactly the same behavior as we did before. And I didn't highlight it, but this part down here, the lower right four boxes, that's just the original dual inverter loop. All right, both R bar and S bar equal to one. So what if R bar is zero and S bar is one? So S bar is one, so we can ignore that input. R bar is zero. What does that imply? P is one, right? And then Q is zero, right? Because we put one here. S bar is one. One and one is one. Inverted. Q is zero. Good. Okay, so S. I'm sorry. The R bar input resets a bit. That's where the name comes from. It's the reset input. Yeah, I think. 5. 5. No, it means when you put a zero at resets, when you put a zero, it sets. It's active low inputs. Yeah. So one of these, the reason they're named this way is actually because of the sense of the input. So there's no inverter. I mean, it's the circuit you see here. And when it's a zero, it performs the activity either set or reset the stored bit, which is considered to be here. Yeah. Good question. Wait one slide. S and R at the same time. Yeah, so if you would use nor gates, then a zero would have no effect on the or. Right. And so the low input would have no effect. And the one input would have would cause something to happen. It would cause the inversion and force the output of q to be zero. In this case. So if you used a nor here, then this would be the reset input. And this would be the set input to go the other way. And I think there's a picture of that in the notes connected from the. Almost. Yeah. So we're so the question is, is this why we're assuming it? Why we've assumed in the past an inverted inputs are free and answers. Yes. And since we're always storing bits using dual inverter loops. And eventually Q and P will always be compliments of each other. Then if you want the compliment of Q, we'll just pull it off of this one. It will be in a second right now. It's because they're actually not always the not always compliments as you'll see on the next slide. So yeah. That's why I kept it this piece. Good question. Okay, ready to go to the next slide answer. I'm going to ask. All right. So actually one more slide. I'm sorry to slide. So this circuit has a name. It's an R bar S bar latch. S R latches with the Norgates. This is R bar S bar latch. So we'll store a one bit by lowering S to zero store zero bit by lowering R to zero R bar to zero. And so here's Muhammad's question. So what if we set both S bar and R bar to zero at the same time? So what happens? So S bar is zero R bar is zero. What's Q? One right? Because S bar zero forces Q to one. What's P? One, one, one. So that's why I left this piece. Because they're not actually forced to be opposites in the R bar S bar latch. So you can do that. It's not going to hurt anything as is. The problem is now depending which of those two inputs S bar R bar you let go up first. You'll get one or the other bits. Unfortunately, if you let them go up back to high voltage close enough in time, your loop may settle into what we call a meta stable state where it's not actually any more digital voltage. So it's hovering somewhere around the BDD over two mark on both of the on both of the outputs. And so it's it's meaningless digitally. It's still an analog circuit. It'll still, you know, electrons will move around. But what behavior it has is no longer, you know, something you can easily analyze. So don't lower both at once. You've probably heard the joke, right? It's a patient goes to the doctor doctor. You know, my head hurts when I push on it. Don't push on it. So seriously, I mean, when you use S bar R bar, R bar, R bar latches, R bar, R bar latches, then you just don't do this, right? You control it in a way that you simply don't do this. So on the other hand, we can also add some more NAND gates to keep ourselves from doing it. So here's a couple NAND gates and a D input. So what does this, what effect does this have? So if I put, let's see, let's check the true table. So if I put a D equals zero, then what is R bar? So zero, one here, zero here, right? Okay, so D equals zero means R bar equals zero. What about S bar? One, so zero one. So if I put R bar zero and S bar one, what are Q and P? So I think I had zero here, you said, right? So zero and R bar, so that resets Q to zero. And then P should be one. Oh, I did it one other time. Okay. So let's make sure we understand this. So R bar is zero, S bar is one. So when R bar is zero, that force is P to one. And P is one, so that force is Q to zero. Because S bar is also one. Makes sense? The same true table is before. Oops, I went one too far. Okay, so when D is one, again, two inverters here. So R bar is one, S bar is one. Zero. So what is Q? One, because it's being forced to be set. And then P is one. Zero. Okay. All right, so now we can avoid the state we wanted to not have the one, zero, zero state on R bar S bar. Well, you can see D gets copy to Q, right? D copy to Q. Yeah. Yeah. Oh, it's a word of the D come from. Well, but this lets us store D, right? D gets stored in our dual inverter loop. So you're saying we could simplify this? Okay, let's try to simplify this. You're right. It does the same thing. Good call. It's a good call. We say there are some gates. Yeah, maybe it's not quite doing what we want. We're saying D to Q, right? If we go look back at this, it always copies D to Q. This is a complete truth table, right? We didn't leave anything out of D is zero, few is zero. Yeah. Yeah, I evenly plan to add inputs there. That's a good question. So in order to prevent that nice wire like behavior instead, let's add some inputs. Okay, so there's some more inputs. So now it's not a wire anymore. It is a wire sometimes. So when right and able, this thing down here, W, right and able is equal to one, it's still a wire. So when right and able is one, it copies from D to Q. Sorry. Copies from D to Q when right and able is one. What happens when right and able is zero? So right and able zero here, what's S bar? One, zero here, one. So R bar and S bar are both one. So in that case, so here I've used, hopefully remember, but I'll remind you, here, I don't care what D is when right and able is zero. So these are actually, each of these lines is like two lines in the truth table. So it doesn't matter what D is, when right and able is zero, R bar and S bar are both one, and I can either store a zero or I can store a one. Whatever the last value of D is, when right and able goes down to zero, it keeps that value. Yes, right? Yes. So when you lower right and able, then this holds a bit as long as you keep right and able to. Yes. So this will store a bit as long as you want until you set right and able high, which point of copies again. Yes. Yes. Yes. And as you'll see, we're going to use a clock signal to drive this. Yes. Yes. Yeah. So the point that matters in time, and again, we're not going to do much with timing in our class, but the point that matters is what's the value of D when you switch right and able from one to zero. That's the value that will continue to be stored. Yes. The question is, can you store one only one bit? Yeah, there's, you can only have zero one or one zero. Yeah. Yeah. Yeah. This thing, if you're not careful, can be metastable in most modern processes. So you do want to keep it away from that. So most of the time, in fact, these will be initialized to keep them from being initialized into metastable states. When I mentioned flipping the power on and off in most modern processes, you, you won't necessarily land in zero one. You might land in a metastable state. So typically flip-flops will be forcibly initialized to zero one. Okay. So. So remember if I give you the picture again, yeah, there it is. So here's the gated D latch inside. And then what that looks like, it's actually a little simpler in practice. This is how they used to be built, but you can do it with fewer transistors if you're willing to design at the transistor level. So this, this design is maybe actually roughly two X is big is the real one. But you can think of it this way, it's how it works. And symbolically, we draw it this way. And so it's just a box with a D input for the, for the D, a right and able input and then Q and Q bar. So now we're labeling them as Q and Q bar, because there are always opposites. So this is, in fact, where the, I think I mentioned on the later slide, but then flush already asked about it. This is why when we talked about evaluating the cost of combinational logic for delay in area, we said, well, it's just not counts in burgers on the literals. Right, because if your bits are coming from, from latches or from the flip flops that we'll design in a minute, then if you want the complemented literal, you just take a different wire. You don't need an inverter physically. You just take the other wire coming from the other part of the double it to inverter loop. So that's why we said they were free. Okay, so any more questions on latches before we. Yeah. Yeah, so I mean, the same way you're doing in the lab now, you know, on paper, we just draw the wire to the correct output of the, of the latch or the flip flops, right? So you draw it either to Q or to Q bar. In the tool, you would do the same thing and that would become a physical wire in your circuit. It would be a piece of copper sitting on your chip or some other metal made. These are active logic. So the question is, how long will these store bits as long as you keep the power on those store the same bit. Cosmic race strikes can flip the bit because they can move electrons around. But for the most part, active logic is pretty robust because if you think back to what's what's going on inside these gates, we're actually connecting the high voltage in ground. There's a constant constant influx. If there's any variation in the, in the output voltage, this is connected. If this is starting a one, for example, this is connected directly to high voltage through and transistor that's turned on. And the transistor is turned on because this one is at low. So to flip them, you actually have to, you have to do a little bit of work. And that's one reason that the real design, the real design provides electrical isolation also uses your transistors because otherwise you have to actually this design is good enough. But the feedback here. When we look at real memory cells, then there's some analog issues for overriding the paths inside the transistors and avoiding creating shorts from high voltage to ground when you're switching bits. But in here, these are actively connected through the transistors. When it's storing a one, it's actively connected to high voltage. One is storing zeros, actively connected to ground. So it's rather difficult to make them accidental. Okay, so the question is, why does D not matter when right and able is zero? So look at right and able to very name is zero, you've got a zero going into an advocate. So zero and whatever is zero, man is one. Right. So right and able are bars one, if right, maybe was zero. Similarly, as far as one whenever I am able to zero. I think we have that on the. Okay. Let me skip out of this. Here's our. Here's our full truth table for this one. Right and able is zero are bar and S bar of both one. And in that case, you can store it using the bite stable nature of the dual inverter. So in that case, he doesn't, he doesn't matter. It doesn't have any impact because right and able zero forces both are bar and S bar to one all by itself. So while writing able is one, you put whatever value you want to store on D and then it's copied to queue. It acts like a wire. Right. So you copy from D to Q while right and able is one. And then before you change D, you turn right and able from one down to zero, now stores whatever bit you put there. Yes. Yeah. And once right and able is zero, it won't you and P will not change again until you change right and able back to one. Any other questions on the lat before we move on. So permanent storage is probably outside of the scope of what I want to talk about now. I can talk about it after classes during office. Yeah. Yeah, they usually make net a quantum quantum wild based. Or for glass and isotropic glass or CDs and DVDs. All right. So a lot of high speed designs will actually use latches like this directly. So what do they do? You'll have latches that'll store some of your bits. And then you'll use those latches as inputs to a combinational logic from your combination logic, your produced outputs. Those will get stored in some other latches. And so for an eventually those will come back and make a loop. And so between sets of latches, you'll have combinational logic. And as you'll see, we'll flip the sense of the right and able on the two latches. So this is where I was going to explain what I've already mentioned, which is this is why complemented literals are free. You can see into the into the combinational logic, you have both the queue and the q bar from all of your latches. So you don't need inverters to get the keyboards. Let me just connect to the right place. All right. So clock signal then is idealized as a square wave. So we're going to use that square wave to drive the right and able of our latches. So that what is a square wave. So it's basically. If you have a forgator Hertz clock that means your period is a quarter of an antisecond. So you've got one eighth of an antisecond at zero voltage in eighth of an antisecond at BDD. And then that repeats when we show you what that looks like. It's something like this. It's a little faster at forging. All right. So you have this kind of signal. And this is what we're feeding into our right and able. So here we alternate the clock signal to have the low and high phases of the clock drive alternating sets of latches. So for example, we might put the when the clock is low. So the clock is high. So this copy is from D to Q when clock is zero. And this set of latches over here will copy from D to Q when clock is one. And the first half of the clock cycle. Whatever logic came before this is actually outputting its values and getting copied into this set of latches. But this set of latches while the clock is low is ignoring this combination of logic. Then when the clock changes from low to high. And the lower values were here are copied into these latches in the meantime, these latches are now ignoring their influence while the clock is high. So they basically just shift back and forth with the clock. So in the low cycle. Half of your logic is working in the in the high part of the clock, the other half is working. So the clock frequency is then limited by this logic delay. So before we said, well, how many gate delays is something. Well, if it's five gate delays, then you can have a faster clock cycle than if it's 10 or 20 or 100 gate delays. So if you want to have a very fast clock, like a few gigahertz clock, you have to be careful about how many how many gate delays you have in your combination of logic. And where your clock speed limit comes from is this notion of delay in your logic and being able to take the latch values here, calculate whatever Boolean expressions you want and latch them into these latches here. So these days, a lot of the a lot of the chips will start to have different what we call clock demands, which means just different different clock speeds. Historically, though, and still for almost all embedded systems, and even a lot of processors, there's just one clock demand for the whole chip. So if you want to have a lot of module, it may be some IO to the outside world. Yeah, a lot of systems are just one clock domain for our class, certainly, you're just to see one common call. So the question is, how do you pick your clock speed, I think. So this is kind of a complicated answer. If you're doing something like an FPGA design, the tool will tell you what it thinks can work, but really until you test it, you're not sure if it works often, it will sort of overestimate and then you have to make it run more slowly. So practice also, so you probably know that if you go out and buy a processor, you can get the 4.2 gigahertz, you can get the 4 gigahertz, you can get the 3.8 gigahertz, et cetera, those are actually the same chip. So what what companies like Intel do is they build the same chip and then there's process variation. So the chip might be okay at 4.2 gigahertz. Another chip, if you run it over 3.5, it'll just break at some point, some point soon after 3.5. And so they do what's called speed bending and they take all their chips and they go see how fast they can run each one of them. And then if it's faster, they charge you more money. And that's why I have it, has anyone overclocked your processor? Okay, so that's why it works, right, because the bins, you know, they have like 4, 6 or 8 bins maybe, but of course the answer is continuous, right. So given any bin, probably you can afford to go a little bit faster. You probably can't go to the next bin speed without running into problems, but you can go a little bit faster and overclock the processor and make it make it a little bit better. It can be, yeah, it's at some point, there is a, there is basically an oscillator on the chip for several oscillators on the chip that are generating or from off chip that are generating clock signals. And there's also you have to distribute the clock. We won't spend much time at all here, but the reason I'm willing to kind of talk about a little bit is because you should be aware that distributing the clock is a hard problem, right. And we make the circuits people deal with it so that we can have an easy abstraction, not only in our class, but also people who are designing chips. I don't think so anymore, but I'm not sure. I have to look at specific design. Yeah, so this right so once these values have been set, you have, you have basically half of a clock cycle from when this value becomes visible until this one is going to copy because the clock changed. So you have to split your logic up so that it finishes within the part of the clock cycle that's allocated to you. It's actually a, it's actually a much more complicated game than that because really through two sets of latches that has to complete in one clock cycle. So you can have, you can have it be two thirds and one third for example. So the people who play games like that. But it's trying to be on the scope for class. You think of it as you need to finish this logic has to finish in time for the next half of the clock cycle because as soon as the clock changes, this latch will start topping from the output. And so if you make this delay too long, the answer won't be the same. So it takes 10 gate delays and your clock is such that it changes after eight gate delays for some of the input output paths. You simply won't have the right answer. Yeah, yeah. So if it's fast enough extra delay doesn't matter. The problem is when it's too slow. And so that's why when you overclock at some point, the clock is too fast for the logic. I mean, well, or you'll get you'll get mistakes in what's going on in process, which sometimes you might be able to stand a few of those, but usually things will crash. So, yeah, that's a good question, although it's getting into some things you'll start to see in one 10, I think, and you'll definitely see in two 10 and later circus classes. The higher the voltage, the faster the electrons are going to move, right? And in selector field. So you need a certain number of electrons to fill the wire to bring the other voltage up. And so the faster they move, the sooner that happens, the higher your voltages are, the sooner your outputs will change. And so if you raise the voltage, it'll go faster, but there's limits to that too. Because then the next one, if it's at a higher voltage, it takes more electrons to bring it that down. Right? So sometimes it works. And then if you go too far, it doesn't work anymore. It's a fairly complicated set of equations, it's way beyond their class. So, it's actually after class. And at the point, you will use flip-flops, implement a finite state machine in your lab to control our coin machine. Yeah, and that's your building towards that already in the lab. Yeah, usually they'll ramp it up until it until it fails and then they'll sell it at whatever the highest one and what it worked was. So the latch is what I've shown you in a flip flop. I hasn't shown you yet. So let's go do that. Okay, so, yeah, so this is just some comments on reality. So the clock is not really a square wave because square waves don't exist. Things never happen instantaneously. So the sharp edges just don't happen. Getting it to all the latches at the same time. Also, same time is not even meaningful. So we'll use a simpler abstraction than then dealing with latches and combination larger between them. So the problem of clocks you getting the timing of all the clock edges to the latches or flip-flops at the same time, it's a hard problem. We're going to leave it to the circuit designers. So what we will use is what's called a flip flop, which is this design here. So you can see I've built it out of two latches. So we're not going to allow any logic in the middle here. So we're only going to have logic between flip-flops. So we'll have pairs of levels of latches where each pair, each other pair has no logic in between. So it's just back to back latches and we'll have the clock signal inverted here so that just like I showed you in the previous diagram, this latch copies from d to q when the clock is zero. So this is a flip flop. This is in particular what we call a master slave implementation of a positive edge triggered deep flip flop. So where's the name come from the master slave part is because we have two gated D latches. So one is the master one is a slave. The positive, oh, and also I wanted you to notice this. So on the flip flop, the difference is instead of right and able, we put this little triangle, which means clock. So you put the clock input there. So where does the name come from flip flop stores a bit and changes once each clock cycle. Okay, so every clock cycle the flip flop will take one new value. And that's it. It doesn't it doesn't bounce around it just changes once each clock cycle. A deep flip flop accepts the bit to store using a data input. There are other types of flip flops. We're only going to use deep flip blocks in our class. So you put you tell it here's the bit I want to store once per clock cycle. It'll copy from its D input to its stored bit and it'll then put the stored bit out for a full clock cycle. So positive edge triggered means that the flip flop value actually changes on the rising edge of the clock. So when the clock goes from zero to one, that's the moment that the flip flop copies from data queue. That's that's the meaning of this flip flop and the design is what I showed you. So use of flip flops and ignoring clocks to apply. It's discrete time. So for the purpose of our class time is not a continuous number for our system. It's clock cycle one clock cycles. So each clock cycles one unit of time and time is an integer. So flip flops copy their D inputs to their queue outputs on the rising edge of the clock and then between integer values of time we just assume nothing changes. So for all the designs we're going to look at nothing happens between clock cycle the clock cycle. Everything happens on the rising edge of the clock. So time is discrete. It's a lot easier model to deal with the circuits people still have to deal with timing and clock. So we don't. That depends really strongly on what you're trying to build and what technology you're using. Right. So I mean, get to hurts clocks have been around in different technologies for 35 or more years. You know, the first craze to use bigger hurts clocks. I think we're 80s mid 80s to late 80s. The alpha processors that came out in the early 90s were bigger hurts clocks. The X86 designs. So we started hitting gigahertz rates maybe around mid 90s to late 90s. And then we started hitting power started to be the limiting resource in the early 2000s. Right. So even though we could build faster clocks. The clock speed has actually gone down a little bit in the last 10 years or so. Mostly because of power issues. People want to use less energy. Now, so that's gigahertz speeds on your typical, you know, your phone is probably gigahertz processor, your laptop desktop or gigahertz processors. In contrast, if you look at it at a small embedded system, you might want to use very, very low power in which case you might have a 250 megahertz clock or something like that. You can get even slower clocks and they'll use much less power. So it really depends on the context in which we're asking the question. Yeah, in the lab, they're going to be pretty slow to. Yeah. Yeah. So, so the flip flop is basically a simplification from the latches. Right. So it's it's the same thing. It's going to store bits for us. And it's only going to change once per cycle. So it's going to give us this discrete time of stratch it. At this point X. So remember in the previous diagrams, I said, okay, we're going to have latch, combinational logic latch, combinational logic latch and so forth. In the flip flop, every other level of combinational logic coming to reduce to zero. Between the between the zero right naval latches and the one right naval latches, I'll just cross out this combinational logic and all of my combinational logic will be an alternating levels. Makes sense? Okay. So, so this one was copying on zeros on clock zero. This was on one. This was on zero. So instead of having every pair of every alternating set of latches, potentially combinational logic, I'm simply putting these things in a box and putting all my logic between this kind and the next time. So this is then a flip flop. Now, now things only change once per cycle. Instead of worrying about, well, which of the latches are changing when clock is high, which are changing when clock is low and having different types of latches in my system and worrying about that. I simply make all of my all of my logic go between the. So, that's the path that I'm going to have to happen on the rising edge of the clock. Everything changes on the rising edge of the clock. And I don't have to think about latches. There are gate delays between, I mean, it takes time for, it takes time for the flip flop to see the value on the input and it takes time to get it to the output. So we'll look at that one way, start to use them. We'll think about that. Ideally, ideally, no, right? You idealize it as every, you know, clock is a square wave, flip flops are instantaneous, but. And they're designed to have some, some reasonable flexibility, but. But in terms of the, in terms of analyzing the gate delays, you have to have a few gate delays for your flip flops to act as well. Yeah, it's relatively fast. It's just a couple gate delays, but it adds, you know, if you're, if you're trying to drive your clock to say five gate delays and your flip flops take two of them or four of them. It's not so short, right? You only get what's left for your combination of logic. Yeah, depends how fast you're trying to drive your clock. Yes, but with the flip flop again, all of the flip flops will use will will change their value simultaneously, because we assume common clock and read nor clocks, you on the rising edge of the clock. So once per cycle, everything will change. So it's discrete time. So it's a little simpler to. No, these latches change when clock is zero. These latches change when clock is one. Yeah, these change would zero. Yeah, so then you have to know which kind of latch is changing when so it's more complicated to reason about. Not inside the flip flop. Yeah, yeah, so that's the that's what I crossed out here. And that's what I highlighted on the flip flop diagram here. So before these two latches, we'd say, oh, no, I want to put some logic here, but we're not going to do that. Yeah, so there will be combination logic here and combination logic there and this combination logic has to settle before the rising clock edge and whatever we put here has to settle before the next right clock edge for the next flip flop. All right. So. Three time simplifying. All right. So here's a timing diagram. I wanted to just show you kind of how it works inside. So and also show you what it kind of behavior ignores. So here initially the data input is high. And the internal input is high because the clock is low. So do you is being copied to X by the first latch and the output. So the second latch is also just happens to start low at the rising clock edge. X will get copied to Q. And so Q will go high at that point. But also at the rising clock edge, the first latch will stop copying. D to. So there's not much of a margin here. Sorry for that. But you can see D goes down here. But because the clock is high, the first latch ignores D. It doesn't copy to X immediately. So until the clock goes low does D actually get copied to X again. So when the clock calls D is copied to X and X goes down as well. But when the clock calls the second latch, which copies X to Q stops copying. And so when the clock calls, even though X goes low, few stays high for the full cycle. So until the next rise and clock edge, Q doesn't change at all. When the rising clock edge comes look at the value of X, which is the value of D because it's being copied. And then that gets copied to Q. So X is copied to Q when the clock is high. I D is copied X when the clock is low. Now you'll notice inside this clock cycle, D actually went up and then went back down, but it got ignored completely. Right? Because, well, not completely. It got copied to X for part of the time. But because it went down before the rising clock edge, X was already low. And so here at the rising clock edge, we look at X and copy it to zero, copy it down here. So X is zero, Q is also zero. So even though D went high in the middle, then never showed up on the output of the flip flop. There are flip flops that do things that are called things like ones catching. Right? So the output, if the input ever goes high during that clock cycle, the next output will be a one. And even if it's just for very short pulse. But the flip flops will use are these positive edge trigger D flip flops. So this kind of behavior will never show up on the output. So, and this kind of behavior makes no sense in discrete time. Right? If I think about this as a discrete time system, only at these dotted lines do I look at what's going on. So these dotted lines, they say, well, what's D? Oh, it's one copy it there. One. Here it's zero, zero, here it's zero, zero. That's it. And so that's the simplifying assumption. The only time we ever look at the system is we look at the input to the flip flop at the at the discrete time, the copy to the output. It stays at the output for a full clock cycle. So look again, copy it again, stay for a full clock cycle, look again. So makes makes analysis and developing designing the systems much easier. And it actually works along as a circuit designer, speed the clock skew tool. Makes things easier. So all of your designs will be what we call clock synchronous sequential circuits. So these assume the use of flip flops and then a common synchronous clock signal. That's what makes them synchronous is they have a common clock. Latches and flip flops are what we call sequential feedback circuits. So you should understand how they work, the analysis we did of, okay, draw the truth table, put a value in, see what happens, see what it what it means for the rest of the values. So you should be able to analyze them, but we want to expect you to design any. Actually, not too many people design them anymore usually people who are building building circuits will actually use what are called standard gate libraries. So there will be people responsible for developing latches and flip flops for a given process, but there'll be relatively few people and then everyone will simply use their designs. And say, okay, I want to latch a lot of flip flop. So it's getting to us into the hour. All right, so instead of going to static hazards, let's just stop there. It's good time to stop. And we'll talk about hazards and registers on Wednesday. Thanks. you you you you you you you you you you you you you"
    },
    {
        "ECE120-2016-09-28-LEC-15-slides.mp4": " logic. So, and now it's three o'clock. So, oops, I need my magic device out. So, what we're going to do today is wrap up the new comparator design and then do a two-se complement comparator and then do another bit-slice design to do power to check whether a number is a power of two and an unsigned number is a power of two. And we'll do two bits at a time with that one. We may or may not get into talking about building with abstraction. So, the first thing there will be a subtractor and then doing something to check whether an ASCII character is an uppercase letter and then looking at multiplexers. So, that'll carry us basically through the end of the day on Friday and then next week we'll start doing sequential logic. All of this is what's called combinatoric logic combinatoric design. So, so far through the end of this week we haven't talked about how you store bits. So, next week we'll talk about how you actually store bits on the chip. All right. So, on Monday we looked at this and there were a few people that asked me afterwards. So, I wanted to just make sure everyone understood what we were doing. So, we did path-to-path input to output for each of the inputs here that matters. So, remember C0 doesn't affect Z1. But for each of the inputs that affect Z1 we calculate the gate delays from input to output and then we went to this diagram and I just sort of showed you the answers. So, let me also show you a table. So, what we're really doing at each of the steps in this slide is this whole table. So, the inputs for bits like 0, the one on the right are available at time 0 for A and B and a time negative infinity for C1 and C0, to calculate when we get Z1 we then have to go through each of the inputs add the delay from input A to Z1 which is plus 3 for A plus 3 for B plus 2 for C1 and not relevant for C0. Add those to the time AB and C1 become available to get the minimum time that Z1 will be available. So, then we take the max over these three and that tells us when we'll get Z1 out of bits like 0. Similarly, for Z0 we add the delay from A to Z0, B to Z0, each of those is also 3. We get 3 and 3. C1 is not relevant to Z0, C0 is plus 2 but negative infinity plus 2 is negative infinity. So, the maximum here also 3 and so that's where we got these numbers, the 3 and the 3 for the first bits slice and then similarly there's another table for bits slice 1 where you say well A and B are both still available at time 0, C1 and C0 now available at time 3 for bits slice 1 so 0 plus 3 is 3, 0 plus 3 is 3, 3 plus 2 is 5. So now that's where we get Z1 coming out of bits slice 1 at time 5 same reasoning for bits slice 1 Z0. So that's where these numbers in the blue circles came from. So, I know at least a couple of people were confused about that so I wanted to go through the detailed process and make sure you understand kind of how we get those. We do have to think about all the paths and take the longest one across all of the possible paths. Make sense? Okay. All right so that's just a little bit of review and a couple of new slides. I put those back into the ones I posted too so I think those are out if you look on the video lecture now in today's lecture but also in the slides you can grab online. So overall we found that compared to the original design we reduced our area by about 40% right each of the bit slices was area 12 as opposed to area 20 and we increased delay overall by one gate delay so it took us 2n plus 1 instead of 2n. So pretty good trade off but you might wonder well can we do better than that right so you know we played with algebra for a couple minutes we got a better design by 40% area about the same delay. It's not quite as easy so for example you can compare or you can design a slice that that looks at two bits at a time of A and B so I actually did that in the notes for you so if you want to look at that you can go look at section 246 that'll give you better delay right because generally you can reduce things to two-level logic. Now at some point you'll have too many inputs and you'll have to go beyond two-level logic too many inputs to a gate I mean but you can do two and so you can get basically delay two for two bits instead of delay two for one bit right so overall you'll cut your delay in half for the whole design and it doesn't get too much bigger so and you're handling two bits so you'll end up in half as many bits slices but of course it's a much more complicated problem right so then you can go all the way to the extreme if you want and say well I want to do a 32-bit comparator let me just write down the bull-aid expressions and I got 64 bits of input I'll go solve a 64 input K-map well maybe not you'll do a lot of algebra right and then you'll and then you get answers those answers will give you a better design right it'll be it'll probably be smaller and faster but it'll be a heck of a lot of work so there's a trade-off between human work and complexity of the design which you're probably going to make some mistakes if you really try to do that for 32 bits and then you'll have to go figure out where you made mistakes versus better area and delay right so those are the trade-offs okay so let's do a two-s complement comparator so is this the same as unsigned so for unsigned for example we have this four-bit unsigned number one zero zero one is greater than this four-bit unsigned number zero one zero one right does the same truth it's two complement no why all right so one zero zero one is negative right this is non-negative so this one has to be less good okay so should we just start over just throw it out start over like doing k-maps anyway it'll be more k-map fun no okay let's try a little harder um so what if the two two-s complement numbers we compare are non-negative can I just stick them in an unsigned comparator and get the right answer I can right because they both have a leading zero that'll get you know equal and then the rest is just like the unsigned representations so maybe we can just look at the sign bits and figure something out so let's make a table of sign bits okay so here's the four possible combinations I put a sub s for a sign bit b sub s for b sign bit I interpreted those meanings for you here and then I put in the solution you already found which is well if they're both non-negative just put it into the unsigned comparator you're done all right so how about this line so if a sign is zero b sign is one which one's bigger okay all right good and if a sign is one b sign is zero which one's bigger and if both of them have sign one which one's bigger really I don't know it's too hard for me to figure out my head all right so maybe you guys figured this out in your head already but for for people like me they're a little slower I've got some more slides so so to me maybe that works but are the rest of the bits you can just compare let's let's make sure so so remember a simple rule for for translating two's complement numbers into decimal we said well the value of a negative two's complement number actually this works for all two's complement numbers is this place value here for the leading bit is negative right so negative first bit times to the n minus one so if a is negative then a n minus one equals one and if we interpret those same numbers as unsigned they're same digit I'm sorry same bits as unsigned what we'll get is the is the two's complement value plus two to the end right so for an unsigned number this is plus a n minus one so we'll have two times this difference between the choose complement value v sub a and the unsigned value v sub a plus two to the end right that's actually by definition of two's complement so either way you want to remember that so if we do what people suggested and we just feed those two negative numbers in well what happens so we end up comparing v a plus two to the n with v b plus two to the n and we get an answer so let's say that answer for example is less than right well we can just subtract two to the n for both sides here so if this is true so is that right and it didn't matter whether the operator in the middle was equal or greater than or less than same operator we can subtract two to the n for both sides right so whatever unsigned comparator says that's actually the right answer also for the two's complement so some people already saw that but you know I wanted to work through it to make sure make sure it was clear so we have the right answer for choose complement and the same result holds for for equal and greater than we'll fill that into our table so we done can we just put these two unsigned I'm sorry two two's complement numbers into the table yeah yeah so these middle ones are these right for for unsigned is this what we get out no if I put these unsigned leading bits what do I get a greater than b I get a less than b right but it's for unsigned this is a leading one they're leading zero well that one's bigger b's bigger for two's complement a is bigger so it's the wrong answer so how about we just flip those two bits what we just cross the wires so on the sign bits just flip them I get to work so if we do that for these middle cases for a is zero and b is one the sign bits we feed in one for a and minus one and zero for b so we just cross the wires and our unsigned comparator of course is going to produce a greater than b look back here so well that's what I wanted right and for this case a is one and b is zero we flip the wires so we get a is zero b is one and that'll give us for unsigned comparison well b is bigger right so a less than b and that's what we wanted right so what about the other two cases yeah so when you design it if you want to build the two's comp to his complement comparator you simply put the a bit into the b input and the b bit into the a input it's just wires right so I mean just like you want on your proto board you just say okay swap them no for just for the sign bit only for the sign bit yeah the rest we're going to compare as is what about a equals a s equals b s do we just break those why not they're the same right either they're both zero and you put this zero in over here and this zero in over here they're both still zero or they're both one you put a one this one over here this one over there they're both still one right so it doesn't make any difference so that's it but in other words if you want to choose complement comparator instead of an unsigned comparator you take the unsigned comparator design and you put the b sign bit into the into the first bit slice the highest most significant bit size in the a input and vice versa and that's it that's now a two-se complement comparator yeah Nathan yeah so you can so probably it would be implemented in the library that if you did a actually you would write a comparison operator in a in system verilog which is somewhat like C and so the comparator they've got instantiated would be the unsigned one if the things you were comparing were unsigned and just complement it though which is complement and so the difference would simply be those two wires would be swapped in the two's complement yeah so in terms of our original diagrams that would be it depends whether it's visible to someone doing programming right so if you had a compare instruction for example and you had two different compare instructions you could implement that with two different comparators you would probably do something more like what's on this slide which I haven't described yet so what about just using one comparator to do both kinds right what do we actually have to do in order to make that work well so in order to tell the comparator what kind we want we need some kind of signal so let's make up a signal we'll call it s and that'll let us select between two's complement which will be s equals one and unsigned which would be s equals zero comparison so in that case I claim that all you need to do is x or s with the most significant bits the sign bits of a and b and that'll give you the right answer so if you tell it okay I want unsigned comparison and the sign bit you x or with s well s is zero so then it will go unchanged right so clearly that one works and then I claim if you x or for two's complement comparison you you x or both of the sign bits with one you also get the right answer so let me figure out why it leverages the flexibility in the design so if you if you solve this with the truth table and you don't put any don't cares which you kind of have to do because you actually do care about every answer then you'll get a more complicated design than this so you might want to just work through it and see why it works and what we're taking advantage of all right so power of two so I wanted to do one more bit slice design for you so let's think about how we do a power of two checker so how can we check whether an unsigned number is a power of two what is a power of two yeah mom okay what does it look like yeah yeah only one bit is on right power of two two to the end then that's a place value in binary right in base two so one of our bits will be a one right so here for example for five but unsigned these are the five powers of two you can write in five but unsigned so you can see there's one two four eight and sixteen and all of them have one one bit man which is two to the end for some end so in order to check whether whether um unsigned bit pattern is a power two we need to know well is there is there one one bit in that number okay so I claim we can do this as a bit slice design so if I ask this question so is A which is all these bits of power of two how many answers can you give two right in the yes or no all right so here's a trick question how many bits do you need to pass between slices I'm hearing ones and twos two is right why answer only takes one right is the power two you can't say well maybe it's a yes or no so the question you you need to ask though is if you look at the rest of the bits right so if I have a number that has n bits in it so this is n minus one bits here so if for example these bits are a power of two can the whole number be a power of two actually put the wrong answer it says no it could be a power of two this would have to be a zero right so this were a zero and this is a power of two the answers yes so sorry miss slides wrong but you could tell right so if I told you this is a power of two then by looking at this bit you could say yes or no right if it's another one the answers know because that'll mean there's a one here and the one somewhere in here and you know that's not a power of two or as if you get a if you get a zero here and this is a power of two the answers yes so you know the answer so what about this case so if I tell you these lower bits are not a power of two and you tell me whether with the extra bit it is a power of two or not you can't right because you don't know what these bits are you just know they're not a power of two so it's impossible for you to answer that question so you need more information so let's let's figure out what else do we need to know so imagine we just finished n minus one bits right so answers coming out of a bit a bit slice so under what conditions can our number a be a power of two so I claim there two cases so one case is the bit for our bit slices of one and in that case what do we need for the rest of the bits they need to be zeros right because a power of two has one one so if we've got the one everything else had to be zero okay and if we've got a zero the rest has to be a power of two right so we need answers to both of those questions in order to be able to pass the next answer out of our bit slice right so we need to know whether the rest of the bits form a power of two this question but we also need to know so that was our original answer right but we also need to know the answer to this question down here for number one is the rest all zeros or not if I tell you the answers to both of those questions right then you can tell me for the one bit you get in the bit slice one or zero whether the answer is a power two or not yeah so remember we're trying to build a bit slice design so we have to make a decision based on one bit and the rest right so we want to we want to ask how do we actually prove an inductive step and so remember when we do bit slice designs this is proof by induction so we need to be able to look at one bit and then the rest and so the question is well what answers what possible answers do we need summarized out of the rest in order to make our decision and do that inductive step and so there are two possible cases for one bit and for this case we need the answer to this question is the are the rest of the bits all equal to zero and for this case we need the answer to this question are all of the rest of the bits of power two so if you tell me both of those answers then I can design the bit slice that answers the question yeah it is and that's our and that's our inductive step if we assume that that we can answer this question then we can answer this question so yes and I will not fall into the trap of going down to n minus one and proving it but we'll assume it works yeah yes the remaining bits form a power of two which means there's exactly one one okay any other questions before okay so the yes cases actually don't overlap right so the yes cases are everything zero and everything else is a power of two there's no overlap there right everything being a power of two means there's one one and all zero means zero ones so those two don't overlap the no cases we actually don't have to do anything else to further separate them so all zeroes again means no one bits power of two means one one bit and the other possible cases there's more than one one which means no to both of those questions right if there's more than one one in the rest of the bits it's not a power of two and then not all zero so we're done so those are the three cases we need we need to convey one of these three answers in all of my bits there's zero one bits one one bit or more than one one bit and if I convey that information to as input to my bit slice my bit slice then can convey the same information to the next bit slice so three possible answers or messages so we need two bits make sense all right so here's a representation is this the best one I'm not really sure I didn't compare them all by hand so others may be better it's a pretty good one so so what is it so no one bits we're going to call zero zero one one bit we're going to call zero one more than one one bit we're going to call one one and then I'm not going to use this one zero pattern yeah I mean that if you pick a different way of putting these messages into these four bit patterns you might get a better smaller faster design probably not faster but maybe smaller yeah all right so let's think about let's think about the bit slice that we're going to build so we're going to actually look at two bits at a time so let's call those a and b there's bits bits of our number a but I'll just call them a and b inside the bit slice the inputs from the previous bit slice we're going to call c1 and c0 just like we did in the comparator and then just like we did in the comparator we call the output z1 and z0 just to distinguish the inputs from the outputs both will use the same representation okay so the input meaning and the output meaning we'll use the same representation the direction for this doesn't actually matter right we just need to know is there a one bit one one bit somewhere in there so it doesn't matter whether we start at the big end or the little end and go either direction it's okay so let's fill in a truth table so we'll start with a case of the two bits from the from the number being zero and we've got four possible cases so if we see c1 c0 is zero zero that means there are no ones in the rest zero one means there's one one one one means there's greater than one one and one zero should never happen so in the case of a b equals zero zero and no ones what message should I pass no ones right because there are no ones that I see and before me there were no ones so there's still no ones what about if there was one one in the rest also one one right the zero zero adds no new ones so we just copy the message over what about this one also more than one one oh sorry wrong order more than one one and this of course is don't care right we should never see those that input pattern so we don't care about the outputs in that case all right so we can then fill those those back in and of course we're just copying the bits since the meanings are the same from c1 c0 to z1 z0 except for here where we don't care what the outputs are so we'll get a little bit of flexibility in designing our bits slice all right so then the next quarter of the truth table so if we've got a zero on a and a one on b and the meaning is no ones what message should I pass one one I've now seen one one what if I saw one one before and I got one one a new one in b more than one one good I don't hopefully I get the right order but I feel like I didn't okay sorry what about this last one still more than one one right no matter how many ones we see there's just more than one that's all we care about right so we don't we don't keep track of whether it's two or five or a hundred one bits it's not a power of two it never will be so more than one one so we can fill in the bits so zero one for one one one one for that xx1 one okay is this case any different than the last one it's not right a and b are just two two bits out of the number it doesn't matter which one is a one so if I flip through these I've got exactly the same truth table as I did for the previous slide exactly the same messages out what if I see a and b both equal to one they're all greater than one one all this message out separate don't care all right so that's the design we can copy that into K maps so here's the first one I liked POS for this so let's do a POS solution so where are the loops yeah we're going to do the zeros right for POS so let's see so here's how about this one where should I just opt right I can't go down can't go right can't go left so I'll just go up I can do a square oh the next one you want to do a square yeah okay so let what is this what is this factor here first okay so remember when you read POS factors you want to complement right so this would have been c1 prime in an implicant but in a in a POS factor it's going to be c1 and then that would have been a prime b prime but here it's going to be plus a plus b and because we're going to complement the literals in the POS factor so c1 plus a plus b okay what about this one I guess I should have let you say what that was but someone already said it in front so there's a there's another POS factor right we want it need to cover this zero and so we can go left and we can go up so we'll go both directions at once and get this purple square that wraps around okay so I hear a few people saying c0 plus a okay and what other four corners let's see so I got one more zero to cover and go right and wrap around I can go up get this x you can actually do both at the same time right so good four corners what is that one okay so I'm hearing some c0 or b's right good all right so we got those three POS factors so there's z1 so those three POS factors yeah so I wanted to mention I didn't mention this before I didn't put it in the slides but when we're solving POS you can also think of this as as Kyle somewhere probably there he is as Kyle reminded me in office hours you can think of this if you if it makes it easier for you think of this as as F complement what is this one sorry z1 complement so imagine replacing all the zeros with ones and all the ones with zeros and then solving that as SOP if you do it that way you get the you get z1 complement which you can then apply generalized demorgans and get the POS form so that's actually fully mathematically equivalent so if it makes more sense to you by all means do it that way okay so in other words replace zeros and ones then these zeros become ones circle the ones with the same rules and then just apply generalized demorgans to complement what you get yes except if you circle zeros do remember to to change it into this form the generalized demorgans will change it into this form so you can either do it by hand after circling zeros or you can solve the complement function and then do it with generalized demorgans that's why I say it's mathematically equivalent but I think sometimes it might make more sense one way than the other to some people so so I think it's it's equally valid to understand it either way so equivalent that's why I wanted to mention it all right here is z0 came up so this one looks remarkably attractive for POS right but we'll do SOP so what are the loops for SOP yeah so we got that eight in the middle good what else yeah another the other middle right sorry that was c0 oh I didn't do them in the right order sorry okay we got that one what is that one okay and what is this one be good actually if you solve if you solve this min term and extend it up to here you'll get exactly the same form from POS right so in this case you'll get the same answer regardless of whether you solve POS or SOP so so this is easy or O C 0 plus A plus B and notice that if you write those down side by side this thing here you can actually get by adding these two factors together and so you can say well Z0 is C0 plus A or C0 plus B so we can reuse those gates that's kind of nice a little simpler so here's the here's the design it has something new so the new part is not nor nor you should hopefully remember that when I have a POS I can just write this as nor nor right so that's all these nor gates are up here is a nor nor design for Z1 but this and this nand gate down here if you think about well what is that these are the two factors I called out if you do de morgens on this one you push the inverter through you get an or gate and that then cancels these two inverters here so you've got ore followed by ore but that was what we wanted right so if you do nor followed by nand it's just like an or gate okay so all right so let's let's analyze this so how many uh how many literals do we have seven right coming in there okay and then how many gates five so good so then we've got total area of 12 and so remember though we're handling two bits of the number right so since we're handling two bits of the number for an n-bit number we only need n over two bits slices so the total area is going to be just half of 12 times n so 6n what about delay yeah so two gate delays on all paths right so the total delay through our system again we only have n over two bit slices for n bits so the total delay is what is just n right so up here in the title and put the overall yeah exactly we're handling two bits per slice so we only need n over two slices yeah where to so you mean this sorry let me go back you need this part down here okay so if you look at this structure so just ignore the upper two gates if you just look at these three gates down here um this nand gate by de morgan's is equivalent to an or gate with complemented inputs right so imagine you replace it you've got an or here and you have inverters here and here slide those inverters down they cancel the inverters there and there so now you have or gate followed by or gate it's just an or gate right so now you have c c 0 or a ord with c 0 or b which was this expression here which then is equivalent to what we wanted anything else on this yeah why I can split the bits apart um I'm don't understand what you mean by split the bits apart sorry ah so remember when we did our design don't remember how far back I said that I would take two bits out of the number so I'm building a bit slice that handles two bits and so that's why if I have n bits I only need n over two bits slices to handle all n of them because each of the slices handles two yeah um it's algebraic so you look at the design and you try to spot common factors so that's all I did yeah yeah I mean I didn't really even have to manipulate it right when we saw the K-maps that way it's it's almost obvious yes yeah I mean you can you can start by drawing this design in just and an or and then when you change it to n and an or I just cut to the chase and show the two yeah yes um sort of okay so the question is well what if n is odd then you need n plus 1 over two slices right so if you had 5 n equals 5 you would need three slices okay but what can you do with the extra slice so you can simply knowing how this works you can set one of the bits to zero right and that will give you the right answers yeah good question yeah yes yes so again both area and delay we only have n over two slices because we have n bits each one handles two yes yeah that's right so you would take your n bits you would feed two into the first bit slice feed two into the second bit slice yeah yeah so so remember that if I if I just pick one of these a and b inputs and I put a zero in that doesn't affect my answer right yeah so I just take the bit slice where I don't have another bit of n to feed it and I put a zero then I still get the right answer yeah that's very much dependent on what we're trying to do right so if you had a if you had something a design that didn't allow you that kind of simple answer you would have to also design a something to handle one bit and you'd have to use that one to handle the odd and yes typically typically but usually it's not a big deal to try to handle two bits at a time I'm trying to do three is a little weird right because then you probably also have to do another design in most applications okay all right so we don't get an answer right we said are you going to build a power of two checker outcomes this two bit thing it has some representation and we say we'll wait a minute we wonder to know is it a power two or not right we don't want to know are there zeroes or there more zeroes are there ones right when I know is it a power of two or not so we just produce this count right it's zero one or many we want yes so I'm going to call that p equals one or no p equals zero power of two so if you look at the representation which I guess it didn't copy up here for you but if you look at the representation from that representation the two bits coming out of the last bit slice you can simply connect to z1 and z0 with an x or gate and that'll be p right so if z1 x or z0 is equal to one that means it's a power of two and if it's not zero that means it's not a power of two where's my last representation maybe here all right there so zero zero right look on the input side it gives a full representation zero zero x or together is zero that means no ones right that's not a power of two zero x or one that gives one that's because there's one one that is a power of two and one one x or together it gives zero also not a power of two we never see this one this one would also say power of two but it's never generated okay so let me skip ahead to slide sorry pull that up before all right so that adds one extra gate to lay so the real design including getting the answer out at the end is n plus one gate delays all right so let's let's think a little bit about building using some of the components we've already designed so you can always go down to the down to the expression level down to the k map level maybe you can't always use k maps if you have a lot of variables but you know what you know the underlying algebra so if you have to you can do that you can get your computer to do that but it takes a lot of time and it's not very robust right so if you make a change to what you want to do then you have to redesign the whole thing and do all that work again as opposed to making some some high level change and maybe it's a little easier so you don't have to do that process but you rarely actually need to do that level to get a satisfactory solution right so a lot of the time you know the things we're working on you don't need to get the optimal answer you just need to get an answer that works because other parts of the system are going to be slower or going to take more most of the area anyway and so you just need an answer that works you did very simple get it correct get it designed and put it in right so instead we can take an approach where we say well let's use abstraction right we know how to build things like adders comparators let's just put some things down and get the answer out and then if our part is the thing that needs to be optimized we can go back and optimize right so we can use extra level of logic to describe our functions intuitively also um there are also CAD tools right so the tools you'll use once you get into 385 to some extent the ones you're already using the mentor graphics tools can also help you with your designs right so they can they can do low level optimizations for you often they can do a better than you can not because you know they're smarter than you it was just some engineer probably not even a Illinois engineer right so probably you could do a better job but it'll take you a lot of time right whereas a computer can go look at a whole bunch of stuff really really quickly and find the best answer out of all the things it looks at so it might take you know less than a second whereas you could spend a month looking at all the possible ways to do it and you find a better answer but it still took you a month it took the computer a few seconds right so it's probably not worth your time in most cases so context is important so if you go talk to your mechanical engineering friends and they say oh I just got a 0.5% boost in you know internal combustion engine efficiency they're probably going to win some major awards for that right that means that everyone in the room's gas consumption just went down by 0.5% right that's that's actually a big deal right because that's a fairly established field and that's a big number for them right they don't get that every year right they don't get that every decade so in our field engineer spend a lot of time doing things like improving the designs of arithmetic units and memory because those are the things we use a lot of and we use them very fast right and so if you can improve those designs a little bit it'll matter or doing things like improving CAD tools ability to optimize right so now all engineers who use the CAD tools get that benefit right so it depends on context oh sorry there's a famous computer scientist Tony Hurray or a horror I guess I'm not quite sure actually never met him but he said premature optimizations are root of all evil so sometimes this gets overinterpreted so the interpretation that you'll see a lot is don't spend optimizing something that's likely to change right so if you're doing a prototype don't go optimize as much as you can because then well gee we need something slightly different well throw away all your work and start over right so don't spend time on that or something that really doesn't contribute much to the overall system goodness and so if you if you optimize something that contributes one percent of the time no matter even if you make it go infinitely fast you still have 99% of the time right so so be careful about spending your time on stuff that just doesn't matter overall right the flip side of this is um don't ignore scaling issues when you're choosing algorithms so for example let's say I decided hey I want to return your midterms to you so one algorithm I could use as well I've got 95 people in the room so I'll go I'll start over here and I'll say here's test number one is this your test no okay sorry is this your test no is this your test no and if I do that then I've got roughly 95 squared questions to ask and instead I could alphabetize them and have you line up an alphabetical order right and that's actually easier than it sounds because you can compare it locally um so they're better algorithms right so don't ignore scaling issues and then also don't design in a way that that prohibits or inhibits optimization right so usually what that means is you think of things and you build abstraction boundaries right what I'm building is an adder or comparator how I then implement it it doesn't matter right if I need my adder to go faster instead of a ripple carry adder I can go do a tree based adder right so if you define clean abstraction boundaries then that enables later optimization if you if you mix everything together it makes it very hard to go figure out how to optimize it later all right so let's do a little example so let's start with a subtractor so how do we subtract as humans so let's say I asked you to do this subtraction what would you do so you take the tens complement right the 9's complement add 1 so the 9's complement would be 8 8 2 1 9 9 that one plus 1 8 plus 1 okay help me out here let's add it up 5 plus 9 is what 4 carry the 1 1 plus 4 plus 2 7 3 plus 1 4 2 plus 9 1 carry the 1 1 plus 1 plus 9 1 carry the 1 we don't have room for that did you right that's the right answer yeah okay I don't know maybe your elementary school didn't teach you that way it's not my fault but you probably did that in your homework right you probably said oh I got to subtract you can use that from now on for your decimal subtraction if you want to actually one one day and maybe maybe some of you have children now but one day when you have children I actually suggest you not teach them that way because they're going to confuse a lot of people all right so you probably did that approach in your in your homework right where you said okay well I'm gonna I'm gonna take the ones complement of that number I'm supposed to subtract add one to it I'll add that together and that'll give me the a minus b that I want to look for because somehow taking the subtraction process we did learn an elementary school and mapping that to base two is just kind of a pain and this is easy so so instead of mimicking human subtraction let's use an adder right we have an adder we know how to build it let's just use one so here's an adder and I made some changes and I think we still have time to finish this in a few minutes so here's our design so we have our adder in the middle that's the core and we want to calculate a minus b so we want our adder to produce a minus b so we're going to modify the inputs to perform the subtraction okay so let's take a look at how we modified them so first one is a so a is not changed at all a just comes straight into the adder on b goes through this box I've called one's complement here so what is that it's a bunch of inverters right good so as there's n inverters in there for each bit so remember this is n wires right so for each wire I put it through an inverter and then I put it into b yeah so that's a third change so the third change is cn you may notice here is a one when I change the carry into a one all that does is add one overall and so now what is this adder computing will a added to the one's complement so not be bitwise right plus one which is a minus b yeah what happens if the user does a minus a negative number in two's complement remember that negating in two's complement works for both positive and negative numbers so not b plus one is negative b in two's complement regardless regardless of whether b was negative or positive or zero good question what about the carry out let's think about this for for unsigned so remember that are our ones complement you can think of the value as two to the n minus one minus b right remember when we when we first talked about negation I said well when you want to negate something you can you can think of this one's complement as two to the n minus one and then subtracting b so we obtain d this thing down here you can say well what I did was I added a to the to the one's complement which is two to the n minus one minus b plus one so minus one there and the plus one there cancel so d comes out as a minus b plus two to the n but what is the carry out the carry out is the two to the n right so if I see a two to the n coming out that means that this number a minus b plus two to the n was at least as big as two to the n right so in other words if I get the carry out c out equals one then that means this number here a minus b was at least zero so in other words a was at least b a is greater equal to b whereas if I don't see the carry out so c out equals zero that means this number d is less than two to the n which means that a minus b is less than zero or a is less than b but in other words if these are unsigned if I subtract b from a and b is bigger than a then I get some unref presentable number right it's a negative number so I can't represent it with an unsigned bit pattern so this is an overflow down here and this one if I subtract unsigned b which is less than a then I get some non-negative number which I can represent because I it can't be bigger than the numbers I can represent since I did a subtraction right so this means no overflow so in other words the the carry out here is an overflow indicator in the opposite sense for subtraction as it is for addition remember for addition if we got a carry out for unsigned addition that meant overflow now if we get zero carry out for subtraction that means overflow carry out of one means no overflow yeah yeah there's a similar sort of equations you can use and in some sense it's opposite it's in the notes explicitly but I didn't do it in the slides so you can flip flip to this section of the notes and it's there for you and the derivation is there yeah good question yeah for two's complement you know just like unsigned was relatively easy we just look at the carry out here we also just look at the carry out two's complement you have to do more work so we looked at the sign bits it's the same sort of thing good question all right I think that's it for our first well okay I wanted to also give you the control signal thing so if we want to build one that does both right then we need to choose have some way to choose do you want to add or do you want to subtract so we can again add this control signal s maybe s is zero for addition one for subtraction so then we need to modify our adder inputs with s what should I do for a just a right don't need to do don't need to do anything for a what about b so remember I want to do one's complement for subtraction but not for addition if I do complement then I'll be adding when I when I say add I'll get a plus b prime so I don't want to do not quite that simple that's to depend on s x or so if I x or all of the bits of b with s when I do addition I'll get b unmodified when I do subtraction get not b good what about cn just s when s is zero I get a plus this one is just b plus zero a plus b when I do s equals one I get a plus not b plus one a minus b good okay that's it thank you see you Friday you you you you you you you you you you you"
    },
    {
        "ECE120-2016-11-28-LEC-36-slides.mp4": " So we're going to spend all day talking about control signals. I know you're probably just dying to talk about control signals or a break. I don't want to talk about control signals with, but yeah, all day. So we'll start by just going through the control signals in the LC3 data path, looking particularly at those that are not involved in interrupt and privilege, neither of which we talked about in our class. So you'll be the subset of those that you need to know about and understand. And then we'll look through fetch and decode states and map each of those states to the control signals that need to be generated to execute those on the LC3 data path. And then we'll walk through LDI execution. LDI is one of the longest instructions. So I just figured that's the biggest example. There's another couple examples worked out in the notes. I think add and maybe one state of branch or something. On Wednesday we'll do control unit design that may go through some of Friday. And then on Friday we'll start if not finish redundancy and coding, air correction, coding, air control coding. So before we get started, if anything happened over break. Go figure. Yeah. All right, so let's go. All right, so that really happened. That was not a fake picture. I don't know why. All right, so remember that the control unit finite state machine in a processor takes as inputs the signals coming out of the data paths. So remember we developed our own little, our own little finite state machine with a data path and a control unit for that to do finding a minimum in an array. Right? And so the LC3 is no different. There are signals coming out of the data path that the control unit uses to decide what state to go into next. And then there are also the control signals from the finite state machine or its outputs that go to the data path to execute the RTL using the data path. So let's take a look at these control signals. The LC3 data path, it's in the notes, it's in the back of the book. You can actually get it online pretty easily as well. And we will also of course give you a figure in the test, which you've seen before. And you can go get it off the wiki if you want to have a copy. We're going to ignore any control signals that are associated with interrupt and privilege. So if you read through the appendix of the book, it will talk about all of the control signals. Many of those you don't need to care about because they're only used for implementing interrupt or interrupts or implementing privilege in the LC3 processor. If you take 391, so these are probably going to be left out for the most part of even 220. If you take 391 though, you'll make use of both of those ideas in the context of the X86 ISA. You'll see how they're really implemented and used. So let's start by breaking up the control signals in the LC3 into five groups. So one group will be the register loads. So a bunch of registers that can be loaded in any given cycle. So each of those will have a load signal. And those will be our register load control signals. So we'll go through those first. Then they're buscating signals. Remember that in the LC3 data path, each of the outputs that can go onto the bus are gated by a set of tri-state buffers. So there's 16 wires on the bus. There'll be 16 wires coming out of some given output. 16 tri-state buffers, all controlled by one input, to decide do those 16 bits go onto the bus or not. And there are actually four sets of those. So we'll have four buscating control signals. The third set then is Mux selection. So if you remember the data path, so I could have popped up a picture here, but there are lots of Muxes. And those are mostly for making decisions about whether to pick a five bit, two complement offset, or an eight bit, or a nine bit, or an 11 bit. So all of those Muxes will be need configuration when we want to implement some RTL, often meaning configuration, maybe sometimes a new configuration. So those Mux selection bits are also control signals. That's our third group. The ALU of course, implements add and not. And then there's also a pass mode that some of the RTL needs to just get something out of the register file, put it directly onto the bus. It passes through the ALU using the pass mode. So there are ALU function selection control signals. So that's our fourth group. And then finally, control signals to operate the memory. And so when RTL needs to make use of the memory, we need to tell it to you on a read or write. You need to tell it, okay, enable the memory in the cycle so there are a couple of control signals for that. So we'll break them into those five groups. So first group then is register loads. So again, each of the register load signals controls one or more registers. So I say sometimes more, it'll make sense the grouping. So for example, the grouping I had in mind here was the condition codes. NZPL have one control signal to load them. They all either load or they don't load. So each of those signals is set, meaning it's one, if and only if the RTL for the current finite state machine state changes that register's value. So you look at the RTL and if it changes that value, set it to one. Otherwise you set it to zero because you don't want that register to change unless that was part of what you're trying to implement. So let me give you some examples or just actually walk you through each of these. So load signals include the MAR load signal. Do you want to reload the memory address registers down here? This next to the MAR of course. The MDR right there. The IR instruction register over here in the control unit side. So the two memory registers instruction register. This one you haven't seen before doesn't actually show up in the main data path diagram. Be stands for branch enable. So we'll walk through this in detail because we're going to see how the decode state is implemented. But basically in the decode state, the LC3 processor uses these NZPL registers to calculate a branch enable using the IR bits for the little NZPL and then the big NZPL control condition codes here. And it calculates a branch enable bit. Should the branch be taken or not? It does that in decode so that in the first state of branch execution, it can use that to decide whether or not to change a PC. Yeah. Yes. Yeah, the state diagram. Yes. Yes. So I'll show it in a minute. But remember that the LC3 has three fetch states and then a fourth one is the decode that then branches out into 16 different states, one for each opcode. So decode is basically looking at the four bits of the opcode and transitioning into one state for each different opcode to execute that particular type of instruction. And I'll show you again, I'll show you that diagram as we walk through things, pieces of that diagram. Okay, so that's four of them. There are actually three more. So zoom into another part of the data path. So there's LDREG, which is the register file. So only one of the eight registers will change. So which register depends on what input you give on the DR, the destination register input. But if you want any of the registers to change, you need to set LDREG. So there's a load for the register file. There's a load for the condition codes. Typically, this thing will be set whenever you're writing doing an ALU op or a load. Remember that the condition codes are set for the loads and the ALU ops. Right? So here's a load control signal for the condition codes. You'll notice that that's just calculated by whatever values on the bus goes in through this logic and then into the condition codes and is latched there. And then the last is the load PC signal up here on the PC. So there's seven of these different register load control signals. So we're going to wonder, well, what are these things right? All right, so you can look at the data path for each of the registers and see what they're right. NDR's new value either comes from the bus or from memory. A lot of them come directly from the bus. So MAR, IR, the register file and the condition codes. All of their values just come directly from the bus. So whatever's on the bus will get copied into the register. You don't have any choice. If you want to write something into those, you have to put it on the bus first. PC is new value comes from a MUX, PC MUX in particular with one MUX input from the bus. So that's this one here. So we're going to have to control that to decide what the PC writes when we tell it to write. And then finally, branch enable is just loaded based on CC and IR. Again, it's not in the data path picture. Sorry, I won't show you. But it's basically just loaded directly from CC and IR. And so there's nothing to configure. If we tell it to load, it'll look at the current values of the condition codes and the current value of the instruction register. All right. So the second group then is the bus gating signals. So again, you'll see again when I pop up the data paths, but each of the, a bunch of the outputs are gated to go on to the bus. And so we need to make sure that we only send one one to each of those sets of tri-state buffers. So the tri-state buffer is keep those outputs from being written onto the bus. But if we send the one enable signal to a particular set of tri-state buffers, that will put those 16 bits onto the bus. So we need to make sure only one set of 16 bits goes onto the bus. So the register loads, we only set to one, the ones that we want to change, the bus gating, we only set to, we only set at most one of them to one. If we set more than one to one, we're in trouble. So let's see what they are. So you can just look at the tri-state buffers to see where they're going to be. So they're four sets there. So the first one is the PC. So we can take the PC register and write its contents onto the bus. So that's gate PC. The MDR, so we can take the memory data register and write its contents onto the bus. So that's down here. The result of the ALU, so if we do an add or an and or if we pass something from the register file out onto the bus, we turn on gate ALU to do that. And then the last one is gate Marmux, which is this, this mux up here and its output is gated onto the bus. This is the thing that we use for address generation, for memory operations, loads and stores mostly. But sometimes PC relative addressing too, we might make use of Marmux. All right. So the third group of control signals then is our mux select signals. So we've got the register loads, the bus gating and now mux selection. So we've got a bunch of muxes, actually six muxes. So the muxes are going to be used to control well, what value do we put in the PC, what's the destination register in the register file, what source register one in the register file, and then what's the memory address that we want to use. There are actually three different muxes for memory address generation. One controls the source register, one controls the offset size, and then one controls whether we want directly from the IR or want something out of the address. Out of the memory address adder. So, oh, so the other difference between these and the previous control signals is if muxes are not used, if the output of the mux is not used, the input can be don't care. So not the case for bus gating. You can't leave it floating because then if you end up with more than one one, you're going to get shorts. And registers same thing. You don't want to register to change, so you're not going to leave a register load control signals that don't care. The muxes on the other hand, if the outputs are just discarded, who cares what the outputs are, so we can pick anything. So we can leave their select inputs as don't cares for these mux controls. All right, Eric. So, I mean, the muxes aren't always even connected to the bus, right? This one just goes into the PC, but this muxes output never goes anywhere except into the PC. So if you're not changing the PC in a given cycle, this output is ignored. So who cares what it is? Makes sense? Yeah. So basically, anytime you have an output that's being ignored, you don't care what the setting on the muxes because it just pulls some random bits and then it throws whatever the random bits are away. So it's okay. Yeah, and I'll give you details of how you can check to see whether it's used. And this is the example for the PC mux. The only use is to change the PC. So if you're not changing the PC, if load PC is zero, then PC muxes setting can be a don't care. And if you are changing the PC, you need to set PC mux correctly to get the right value. So what can you use for PC mux? Well, there are only three choices. You can see them there in the diagram. The encoding we're going to give you, right? So don't worry about memorizing it or anything. If you happen to have your sheet later when we figure out bits, then you can look it up. But if we want PC plus one, this path over here is for fetch, for example, the encoding is zero, zero. If you want to take from the bus, you can see the bus comes down here. You can write that into the PC. That would be zero one. And then this line here is coming out of the address generation to adder here for branch and jump. That's this path. And that's the one zero input. One one is not used. Because we only have three things we need. Okay, so second mux, the destination register is also muxed. So there are three choices here as well. Now if we're not writing to the register file, it doesn't matter what destination register we pick, right? So if we're not writing to the register file, LD reg is not one, then DR mux input can be don't cares. If we are writing to the register file to get the high bits of IR, the high bits after the opcode, I should say, then we put in zero zero. If we want our seven or our six, we can put in one zero one or one zero respectively. These are actually used for things that we didn't really cover in our class. So the only things that we're going to talk about in our class would use the zero zero input for DR mux. But those, that mux is there, so just to explain it. One can also pick different values for source register one. So source register one is the, remember there are two registers you can read from the register file in any given cycle. So this is the left side in the diagram. So source register one is then used by both the ALU and the address one mux. So if you are doing an ALU op, right, and then writing that onto the bus, then you need to make sure that this SR mux setting is valid. Or if you are doing using the address generation with this as the input, then you need to make sure it's valid. Otherwise, it's can be don't cares. So you need to kind of back propagate. If you're using it in any way, then you don't want to leave it as don't care. If you know you're not using it, you can leave it as a don't care. So the choices here, zero zero zero give you IR 11 through 9. If you look at the instruction encoding, those are the source register bits for stores. And so this is how you would set up for a store is to pull those bits out as your source register to write those to memory, write that register to memory. For ALU ops, jump LDR and STR's base register IR 8 to 6, you set zero one and then I'll give you that register. And then finally, the one zero setting will give you R6, which is again, nothing that we've seen, it's actually the changing privilege implementation on the LC3. So you don't need to worry about it, but it's there. Yeah, those like load. Yeah, so these are all clocked. I mean, the entire LC3 data path is on a single common clock, just like all of the other designs in our class. Yeah. Yeah, this is still clock synchronous state machine with a common clock. And then we'll find that state machine. All right. I mean, the thing to remember, when we talked about the, when we did the example of mapping the code into a finite state machine and I introduced the idea of RTL, is that we define the RTL for the state, but the RTL actually happens on the rising clock edge. Right? So the control unit exerts all of these control signals and then the changes happen on the rising clock edge. So they'll be true in the next cycle. So that's why, for example, is IR somewhere, IR is here. So in the third fetch state, we're writing into IR, but we have to wait until the fourth fetch state to look at the bits in the opcode in the IR, read the 15 to 12 bits for the opcode, because until the fourth cycle, they're not there. Right? And in the third cycle, we copy them from MDR into IR, but then only in the fourth cycle are they present in the IR to use them. All right. So let's go back. So in the next mocks, this is actually two of the mocks is two of the three for address generation. The third is the marmux, I'll show you in the next slide up there. So the first one here is choosing a source register. So this line comes from SR1. This line comes down from the PC and address one mocks just chooses between them. So if you configure it to zero, you get PC. If you configure it to one, you get SR1. Now obviously, if you're not using the output of this adder to write back into the PC or to write onto the bus through the marmux, then you don't care what this address generates. Right? So you can set it to don't care in those cases. This second one, you can see several sign extended offsets. So there's a six bit. That's for base plus offset mode for LDRSTR. There's a nine bit that's used for branches. Yeah, branches. And there's an 11 bit that's used for JSR, which you haven't seen. But those three different sign extended chunks of the IR or a zero. And so you can see the four choices and the encodings for address two mocks down over there. Once you've decided those two values, those go into this adder, get added together and go into marmux. Your other choices over here from marmux. Yes, that should be 10 to zero. Thank you. That's a typo. This one is right. Yeah, thanks. Okay. So on the left here is something. We didn't talk about how traps are implemented. If you're interested, it's using is using this approach to go to this memory address, basically. So you take your eight bit trap vector zero, extend that to 16 bits and that's your memory address. So that zero mode of this marmux is used to execute a trap instruction. All of the things that we know about, we didn't talk about trap implementation. So everything we know about will go through this address adder here and go out through the marmux. So that would be setting one in the marmux. And that's it for the mux settings. So those six mocks. All right. So notice that these two mocks are used by both the PC mux. So the output here of the adder gets used by the PC mux in the marmux. It kind of said this already, but if either one of them is used and marmux is only used if gate marmux is one, PC mux is only used if load PC is one. So if either of those is turned on, then you have to set these three address generation mux. If they're not, you just don't care. You can set them to don't cares. Makes sense? Okay. All right. So ALU selection bits, so we have four functions. You know three of them. Of course, add and not. We put in as part of the ISA. The fourth one is necessary again so that we can pass values from the register file out onto the bus to go places like the ma or the PC for control flow or other operations. So the ALU output is only put on the bus when gate ALU is one. If gate ALU is zero, it's just thrown away. So we can just set the ALU function to don't cares. And then finally, the memory operation. So memory only needs two bits to control it. So it needs to know, well, do you want it to operate? And so there's an MIO enable for enable the memory, it's actually memory and IO, which we didn't look at the memory mapped IO implementation, but this is the control signal name. So when that's equal to one, memory does something when it's equal to zero, memory does nothing. So the read write bit only matters when memory enable is one. When memory enable zero, read writes don't care. When it's a one, it's defined as follows. One is a write read write, I'm sorry, r.w is, those one means a write, r.w is zero means a read. So that's it for the control signals. So this is just a summary of all the control signals. So it's seven different register loads with four different buscating signals. The mux is there are four two bit signals and two one bit signals. So that gives us a total of 10 bits. So this is number of bits. ALU function selection, we needed two bits in memory, we had two one bit signals. So if you add them all up, you get 25. So every FSM state in the LC3 have to specify 25 bits to say, well, how do you implement that particular state? Any questions on this before we start looking at examples? Well, you can set them to don't care, but if you're calculating logic to build a finite state machine, you've got to put bits. So just like in any other logic design, it's going to output real bits, however you build it. So in your design, you can put don't cares. The thing you build will make zeroes and wants. I don't think so. I compared them before. Yeah, I compared those sheets with my notes and with this. Yeah, so again, there are six boxes. Four of them are two bits and two of them are one bit. So four times two plus two times one is 10. Okay. Okay, so let's see. So let's do fetch and decode. So this was the top of the finite state machine diagram. It's figure C2 in the back appendix and Patel. But this is the fetch part up here. These three states and then this is decode down here. And then after that, you go into instruction execution. So let's go through these one by one and work out the control signals that we need for each of the fetch states and for the decode state down here. And so hopefully you remember, you will need to know this on the final. I mean, you'll have the diagram, but you needed to know it on the midterm too. So MAR gets PC, PC gets PC plus one. That's the first fetch state. So let's go think about, well, what do we need to do for the control signals to make that happen? So let's start with the registers. So which of the registers need to change? Which of these values should be one? Yeah, so LDMAR, right? Because we want MAR to change. So make that a one. What else? The PC, right? Good. Okay. What about the rest of them? Zero? Not don't care? Yeah. Zero. Right? We don't want the registers to just load random bits, right? So they better all be zeroes. Okay. All right. Let's take a look at how we would implement this thing. So we want, let's see, MAR gets PC. So PC is up here. So we've got to send it across the bus down here and then put it in the MAR. So it's going to have to go across the bus and go down into MAR. And then the other part was PC gets PC plus one. So if here's PC, it goes through this little plus one thing here. We've got to take it through the PC mux and then put it back into PC and do both the blue arrow and the green arrow and the same cycle. So it's worth when you're trying to figure out how to set things up. Just looking at the data path and maybe sketching out, well, where's the, how are the bits going to move from place to place? Because anytime you go through a mux, you're going to make sure the mux is configured properly, for example. Right? Okay. So we've got these two bits. So what do we put on the bus? PC. Right? So you can look back at the picture. Right? Does gate PC got to get the blue line to go through there onto the bus? Oops. Right? So what are the rest need to be? Zero. Okay. So those are the bus gating signals. So which mux is matter? Yeah. PC mux. What about Marmux? No. What about this one or this one? No. DR mux and SR mux. In there. They matter? You're not writing into register file. You're not using the output, right? So they don't matter. So only the PC mux. So what should PC mux be? The PC plus a one, right? Which was zero, zero. So okay. What about the rest? They're all don't cares. Right? Because none of them are used. So we can just spell them all up with don't cares. Right? All right. So what about the ALU and memory? So here's the ALU. Gate ALU is off. Right? So it's not used. Memory is down here. We're not doing anything with memory. So it should be turned off. So what should the values be for ALUK, MIO, enable, and read right? So let me take them one at a time. ALUK, what should it be? I'm hearing zeros and don't cares. So remember, the value of ALU is being thrown away. So an in gate ALU is off. Right? So if it just bits out some random bits, so what? They're just discarded. So it's don't cares. What about MIO and enable? It better be zero. Because otherwise, we might end up doing a right. And especially if we leave read right as a don't care. If it's a read, maybe that doesn't matter so much. But then memory won't be ready when we need it. It'll be busy finishing a read we didn't need. So let's just set that one to zero. What about our W? That's a don't care, right? Because memory enabled to zero. So memory's turned off. Yeah, such. No, actually, no. So this is a clock synchronous sequential design. And the clock timing has to be such that the longest combinational logic in the system is slower than the clock speed than the clock period. And that's the limiting factor, actually, in a lot of high speed processor designs. So in a lot of your desktop or laptop, what sets the clock speed is something like the adder time or the time to do simple arithmetic operations, that's what limits it. So that's, if we have time, I'll show you a tree adder, which is a faster version and has shorter paths. And those are what people actually use in real processors. Because the ones we looked at, things like the ripple carry, they're too slow, right? And they're what set the clock speed. But in most of these designs, you find your slowest combinational logic and they don't take more than one clock cycle. If they do, you have to set it up so that it's managed across multiple clock cycles. So for example, a floating point unit in a typical modern design might take four or eight, depending on whether you're just adding or multiplying four or eight cycles to complete one operation. But they are usually designed in the high performance systems to accept new operands every cycle. So you can start a new addition or a new multiplication every cycle, but you still have to wait that long to get your answer back. OK, so we've finished this one, right? So we've done fetch one. I just want to make sure people notice this is not a doubt care. So don't get confused by that. So now we can go on to fetch stage two, fetch state two, which is this one, right? So now we have the PC and the MAR. We can go get the instruction out of memory, take its bits, put them in the MDR. So this is MDR gets M at MAR, memory at MAR. So which registers are going to change? Just MDR, right? Anything else? That's it. So all zeroes, right? So those are our register load signals. So let's see. So we have MDR gets MAR. So data comes out of the memory and goes through this MUX, which is controlled by MIO enable anyways. We don't need to do anything there. Goes into the MDR. Now you might actually notice there's this funny path through this other MUX over here. This is part of the memory map dio system, and we didn't talk about it. So just ignore that part. There's actually simpler diagrams of the data path that this is the one I had. So I just kept this one. This MUX will be configured to forward this output back. So the path is OK. So what should be put on the bus? Nothing, right? Well, we could technically probably leave one as a don't care, but let's not do that kind of thing. Because then we have to worry about, well, so what bits go where? So we'll just set them all to zero. So nothing's on the bus. It's just floating. So what MUX's matter? Yeah, this one is set, though, right? This is not in our control. This one does matter, but MIO enable. We're going to have to make sure it's turned on to get the memory output into the MDR. This path is actually what we use for stores. We set up the MDR before we write the bits into memory. But when we're fetching, we need to read memory. So that's coming through here. And it's already going to be controlled by MIO enable signal. So do any of the six months as we talked about, PC Mox or address of one or two Mox or SR1 Mox? Do any of those matter? No, there's nothing going on in that part of the data path, that's all just nothing. It's all turned off, not turned off, but there's nothing going on. So none of them matter. So what should I do? Just set them all to don't care. Put all don't cares there. Good. What about ALU? ALU's not used, right? But memory has to do a read. So what should I put here? So what about ALU? Don't cares. What about memory? IONable. A 1. What about read or write? 0 for read. All right. Oh, I didn't want it at the time. Thanks. OK. So these are then the settings for memory. We want to turn memory on and tell it to do a read. ALU, we don't care. It's being thrown away anyway. So that's it for the second fetch state. So what about the third fetch state? So we finished this one. We finished this one. So now we have to write RTL, well, great. Control signal is to implement this RTL. So we take MDR, copy it to IR. So let's take a look. So what registers are going to change? Just IR, right? Anything else? Let's just add it. So bunch of zeros. So here's data path. So MDR is going to come out across the bus, go into the IR. There we go. So what should be, which gate busgating signal do we need to set MDR, right? Anything else? Better make sure the rest are zero. I can never have more than one busgating signal turn off. OK. So which mocks this matter? None of them. I'm going to set it. Because all the mocks are up here in this part that I did in this show. So all don't care. Just like the second state. OK. What about the ALU in memory? Not used, right? Memory is down here. ALU is over here. So what should these be? Don't care is here. Zero. And don't care. Same is up here, right? We're using ALU in memory. All right. So that's it for fetch. That's just done. And then we have one more state to do, which is decode. So in the decode state, we're calculating branch enable. And branch enable, you might remember, the little n bit is IR 11. The little z bit is IR 10. And the little p bit is IR 9. So I just took the same terminology rather than the same RTL out of the FSM diagram out of patent Intel. But when we've written it, it's been little n and it was big n, little z, and it was big z, little p, and it was big p. That's our branch condition. So that is calculated by some logic that's not shown in the data path. And then copied into branch enable in the decode state. So which registers are going to change? Just branch enable, right? So what do we do for rest? Zeroes. OK. How about, let's see. So I can't show you in the data path because there's nothing there. It doesn't show up. So just calculate directly from the condition codes in the IR. So what should I do with the bus? Just zeros, right? There we go. Zeroes. Yeah, there's nothing flowing across the bus. There's some special combinational logic. Takes a bit out of NZIP registers, looks at IR, does some combinational logic, and writes into branch enable. So there's nothing that's going on the bus. What about my selection? Do we care about any of them? There's nothing being used, right? So we don't need any of them. So just don't care about any of the selection bits. What about these? Yeah, such. All right. So remember in the branch instruction, so let me get that back up. There it is. In the branch instruction, we've got encoded in the instruction the selectors for which of the condition codes we want to consider. And we write them as little N, little Z, and little P. And so IR 11 is little N. IR 10 is little Z, and IR 9 is little P. Yeah. That's part of the instruction. The IR is the instruction. Yes. So no, I take it back. Branch enable, one reason for writing it in decode is it's ready to go when you execute when you get into the branch execution. If it's not a branch, you don't need to look at it. So it's just like the mux selection bits. So if you can calculate it, then you just ignore it. It doesn't matter. So you're actually, the LC3 is in fact calculating the branch enable for all instructions, but only using it for branch. And it'll just be garbage for the rest of the room. It doesn't matter. Yeah. Were that watching the reference for the first? Yeah, it's in the control block. It doesn't appear in the data path. That's why I didn't highlight it for you. It's not there. I think there might be a separate figure in the back of Pat and Patel, but I didn't pull it out. Yeah. That's the IR. That's the IR. IR is the instruction register at 16 bits. IR is not signing. It's a long way back to a full data path. The sign extension is for the two's complement offsets that are fields of certain instructions. The instruction register itself is 16 bits, and it takes all 16 bits to represent the instruction. It's pulled out of memory. Remember, it's pulled directly out of memory through the MDR from MDR directly into IR. It's never sign extended in the fetch path. Yeah. OK. There's no problem. OK. So where were we? I think we've done the use, right? We've done the use. All right. So what about these? So all we're doing is calculating branch enable and decode. The whole reason for decode is so we can look at the opcode and get to the start of the execution state for the correct opcode. So do we need to do anything with ALU or memory? No. So what should I set these to? XX0X. I don't know. There I'm doing anything from that state. OK. Yeah. Yes. Yeah. So that was the question Sasha asked earlier. Yeah. So branch enable is calculated before you've decoded. During the decode state. So you don't know what kind of instruction it is. You don't even know if it's a legal instruction, right? Because not a lot goes to legal instructions. So you're going to calculate it every time. But it's a garbage bit. It's a garbage bit. You only use it if it's a branch. You're always going to calculate it and then just ignore it unless it's a branch instruction. Any other questions on this? OK. So I think that's it. That's our four. So these are the whole table with all four fetch state and decode state and all of the signals. So that one's in the slides for you. It's not really something we need to dwell on here. Any more questions before we look at LDI execution? OK. So let's do LDI execution. All right. So here's execution of LDI. It starts up here. These are other loads. So just ignore these two states. LDI comes down here and then goes all the way down to this, which is 1, 2, 3, 4, 5 states. So it takes five states to execute an LDI. So let's work out all the control signals for those five. So we'll start up here in the first execution state. We'll call that LDI1. And what we have to do there is take the 9-bit offset. I'm just using the RTL from the FSM diagram. This is sine extended from 9 bits in the IR. Then add it to the PC and then store it in the MAR. So what registers change? Just MAR. Then so the rest should be what? It's zeros. So let's look at what happens. So let's see. We have MAR gets PC plus offset 9. So offset 9 needs to come out of the IR. I don't know if you can read it. But there's a sine extension of the 8-0 bits here that will go up into address 2 mocks. So we're going to have to pick that sine extended version out of address 2 mocks. And that'll go into the address adder. So that's step one. For PC, it's going to have to come down this way and go through address 1 mocks. So that's this direction. So then those two get added together. PC is green. Offset 9 sine extended to 16 bits is blue. Those get added together. That has to then go through the MAR mocks across the bus and then down into the MAR. So that's purple. So we need those three parts. So we have to configure all of those parts so that this data flow works through the data path. All right. So what do we need gating? The marmox, right? So up here, this thing needs to go out on the bus. So marmox needs to be a 1. What about the rest? Zeroes, right? Again, only one gate signal should be on. If you write on the final multiple gate signals, turn 9. I'm going to cross it out. So don't do that. All right. So what about the mocks? Which ones do we care about? Yeah, the address mocks is these. We better set up. This one we better set up. What about PC mocks? Not used, right? PC is not changing. And that's only used if we're going to change PC. What about DR and SR1? They're not used. So we can ignore those mocks as two. So those three we need to set. And then the other three we don't care about. So let's just fill in the don't cares. So those three we don't care. What should address 1D? Does anyone remember have the encoding? I don't even remember it. OK. Zero. What about address two mocks? 1, 0. OK. And then marmox. Appreciate this one's a 1. OK. But again, the right thing to do here would be to look at the table, which would be in the back. So you should always keep the table with you. Don't try to memorize this stuff. OK. So those are mocks selection signals. And that will implement these three lines here to move the data out. The ALU and the memory are both unused. So what should these values be again? XX, 0, and X. Good. OK. The second LDI state is this one here. Take memory at MAR. Copy the bits from memory into MDR. Does that remind you of anything? Second fetch state, right? Good. OK. So we don't really need to do the RTL again. We did it already. So we know how to do that RTL. We'll just take the bits we already wrote, copy them into this one for the same control signals. OK. So the control signals here were MDR changes. So we'll just fill that in. The control signals here, let's see. I think nothing, right? Yeah. For this one, we weren't using any of the mocks. So they were all don't cares. And then for this one, we have to do a read. So that's a one. Read right is a 0 for a read. And then ALU is not being used. So all they did was copy the bits out of the fetch two state. Same RTL, same control signals. OK. So then we're in the third LDI state, which is 1, 2, 3, this one here. So we're going to take MDR and copy it back to MAR. Remember LDI is the one that says, oh, I got 16 bits out of memory. Oh, that's like an address. Let me go read from that address. So we're going to copy MDR over into MAR and then do another read. So let's go figure out how to do that. So MDR goes to MAR. So which registers are we going to change? Just MAR, right? Good. So the rest 0s. OK. So here's the data path that would happen. So we're going to take MDR, copy it across the bus into MAR, like that. So what needs to be gated onto the bus, the MDR? That has to go into the bus so we can copy it into MAR. So the rest are 0s, which muxes matter. None, all the muxes are up in the data path above this little part here. And we're not using any of them. So what should these signals be? All don't cares. ALU and memory are not used. So here xx0x. All right. Well, we're 3 fifths done. So now we have state 4, so 1, 2, 3, 4. So we're down here. This happens to be used by the other loads. So let's see. This one is LDR. This one is LD. So this is used by all three types of loads. But it's going to take memory at MAR, copying an MDR. We did that one already, right? Same RTL. OK. So why do we need more than one state? Yeah. Yeah. Yeah. Yeah. So it actually, you can come from different places and go to the same state, just like these do. But what matters is actually the output path. It's remember when we talked about merging states, we said, well, if there's the same outputs and the same next states. So these have the same outputs. The outputs remember the RTL. So RTL is identical. But the next states are not. And that has to do with what you were saying here. It's about setting things up for the addressing, for the different modes. But unless the next states are also the same, we can't merge the states. All right. So we have to go implement this RTL again. Or rather, we need to copy the control signal bits, because it's the same. So let's just do that. So all we're going to do is copy from LDI2 down to LDI4. So there, that's done. Done again. Done again. Done again. All four are done. All right. So now we have one last LDI state. It's this one here. So copy MDR into the DR. So we finally have the value we've loaded for memory sitting in MDR 16 bits. We want to copy it into the register file, stored into some destination register, specified by the instruction, and set the condition codes based on that value. So what registers are going to change? So the register file, right? So I better put a one there. And what else? The condition codes, right? So I better put a one there. What about the rest? Just all zeros. OK. All right. So then let's look at the data path. So how do these things work? So we've got a copy from MDR across the bus and store that into the register file. The only way we can run into the register file from the bus, so along that blue path. And then the other half is set CC. So remember, the condition codes are always set by what's written on the bus. So this green arrow is just coming off what we've already written onto the bus, going through this little block of logic here and then being stored in the condition codes. Whatever value was being stored, it would be calculated negative 0 positive and latched into the condition code registers. All right. So what do we need to gate onto the bus? MDR? And then the rest better be zeros. OK. So which of the muxes matter? Yeah. So DR is going to matter because we're writing into the register file. PC mux will not matter. The address generation muxes won't matter. They're all being thrown away. And what about SR1? Are we using it for anything? No. So that's not going to matter either. So only DR mux is going to matter. So DR mux needs to be set to take the input from I think 11 to 9 bits for the source register in the store. So that'll come with 0 0 setting and DR mux. And then the rest of them are don't cares. So you notice we almost never use too many of the muxes in a lot of these things. Occasionally we'll have to set some muxes up for address generation or things like that. But often they're all don't cares. All right. ALU in memory are both unused. So same as before, xx 0x. So that's it. So there's our whole table. So yeah, in order to implement an LC3 processor, you have to go through the whole state diagram and do this. But as you can see, a lot of it's pretty easy. So on Wednesday, what we'll talk about is then taking all of these tables with all of the RTL and thinking about, well, what are the different ways we can take those bits, we won't do them all. But what are the different ways we could take those bits and then actually build the control unit? So we'll look at a few different ways to do that. Any closing questions before I end? OK, thanks."
    },
    {
        "ECE120-2016-09-09-LEC-08-slides-no-sound.mp4": " you Okay, all right. Well, hopefully this Michael continue to work. It's a little low on battery. So what are we going to do today? Please grab a copy of the code if you don't have one. I guess you could try to share with a neighbor too. We're going to spend today going through some programs that I put up for you to look at. Feel free to grab them during the lecture if you have a computer with you if you want to try to compile them or anything. But otherwise, they're hand out. You can look at them and follow through. I'm probably going to switch over to notepad as we walk through a couple of them and write off lists. So you will need to be able to at least look at the code. So I want to briefly review while loops that we we went over kind of quickly at the end on Wednesday. And then I will go through example programs. So look at understanding loops, a couple of codes there. Reading C programs. There's one program there testing your code and may or may not get to bit manipulation. Actually, I'm not sure how far we'll get through this. So all the slides as always will be posted for you. These are all up. Someone asked me about watching the lectures, the videos in Chrome. I tried that in my office and it seemed to be fine. So do contact engineering IT. I usually I think just have IE or something. I think I've done it in Firefox. I don't have any Apple products right now. So I haven't tried so far your opera. But but at least Chrome worked for me too. So let's start just looking again briefly at the for loop. So the for loop has has four pieces. There's an initialization expression, a test expression and update expression and then a loop body. And the way it works is it evaluates the unit expression first and then it evaluates the test expression. And if it's false, it stops. Then it executes the loop body compound statement. And then it goes and evaluates update and goes back up to step two and checks the test again. And so just remember first unit and then test loop body update repeat the last three until the test is false. Now it might be that it never goes to the loop body test could be false the first time. So while loop. This we're going to show you but we're not we're trying our best not to use it so that you only have to know how for loops work. It's actually quite simple. So the while loop just has a test and a loop body in it and the update are missing. And it's completely equivalent to a for loop where you've just left the unit and the update empty. So there's really very easy just imagine that you don't have those two expressions. So there's nothing to do for those parts. So in particular if we take our our step by step process while we'll skip that step. There's no in it. First will evaluate test if it's false, it'll stop. Otherwise it'll execute the loop body. There's no update. So skip that part and go back to step two. That's all. So while loops are pretty simple. We teach you the more general loop because we want you to be able to use the more general loop. This one you can pick up into 20. It's syntactically convenient when you don't have an iter test but you don't really meet it. So here's where I want to do for most of the day. So I want to go through some code examples with you and just make sure that you're following and that you feel like you understand and you can you can understand how the how the code works. You will need to learn how to compile you've already done that I think once in your in your labs. So you will learn that in the lab. There's some style guidelines on the wiki that you should take a look at at some point. So look at the code samples I've given you to try to pick up well how should I how should I be indenting my programs or whatever picking variable names I'll comment on a couple of those two spaces tight in the slides of call out things that are that are just wrong because I had to fit it into a slide but and you'll see it the right way in the code. The ones that I just handed you those will compile and the programs are available for you to compile so you don't have to like cut and paste them or something. So this was the Fibonacci loop that I showed you at the end of the day last time. So our first program is going to just walk through this and make sure we understand how the for loop works. So it might be worthwhile getting out of sheet of paper I'm going to switch over to notepad and then you know this is the first program on that handout I think it's the left top of the front part. So this is what will keep track of as we go through so we're going to execute one piece at a time and I'll put a comment explaining what it is we're doing and then we'll just update whatever variables change or if there's a printout that it makes them output will put in that column what the output is. So in the slides if you look at them later you'll see that there's a bunch of stuff there we're going to develop this ourselves so if you go back and look at the slides you can see all of that development but we'll do it in class instead of just flipping through slides. So let's go ahead and switch over. you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you"
    },
    {
        "ECE120-2016-09-02-LEC-06-slides.mp4": " It'll go till the end of next week because we have Monday off for Labor Day. So we'll start talking about the C programming language. I'll tell you why in a few slides, but give you an introduction today. Maybe start talking about expressions and operators. We might get through all of that or we might not. If we don't, we'll pick it up on Wednesday. After that, we're going to start looking at C programs in class. So I have a bunch of those. I have already actually put them up on the links page for you. So let me just flip over there briefly for you so you can see it. So if you go down to the bottom, so this is the one linked off my homepage. If you go down to the bottom, sorry. PowerPoint likes to take control of my laptop and forbid me from letting you see anything else. So these links, way down at the bottom are links to programs. You can also get a handout, which I plan to give you copies on next Wednesday. Once I think we're going to actually start doing them in class. So this is a PDF handout with all the codes printed out. So if you want to look at them, you can use that. If you want to compile them, you can use the links directly to the programs and download them and compile them wherever you'd like. This should be reasonably portable, C code. So I meant to ask this question last time. So this will apply before we have another lecture, because my office hours remember two stays one to three. So historically, I've held them in Zaws. Now that we have the new building, we could have them closer. So here are some photos that I got off the web. So this one by Bill Sanders is the daily byte. So that one, I think, maybe it's okay for me to use. There was one from Pinterest of Zaws. So this is the place I've been going for a long time. It's a cafe down on Wright Street. Just West, I'm sorry, it's on Green Street, just west of Wright. This is a care booth coffee at fourth and Springfield. And I used to hold them there until easy students said, why are you so far away when you go back to Zaws because it used to be in your department building. So I moved back to Zaws. And this is not the lab in the basement of DCL, but it looks a lot like it. It is one of our labs somewhere, so it's cold and lonely. And if you want, you can sentence me there. Someone seriously, your labs are due the next day. So if you want me to be in the lab, I can be. But so let's just go through them. How many people would prefer Zaws? Oh, but now let me tell you something before you vote. So Zaws and daily byte, I never asked care a boo, but I think they'd be okay with it. Certainly these two have asked them. And you don't need to feel obliged to eat there or drink there or do anything. I mean, if you want something great, but I asked daily byte the other day, and the owner of Zaws is told me in the past, he doesn't care if people don't buy anything. So don't feel obliged to buy anything if you come. Okay, so sorry, Zaws. Okay, so maybe 10 to 12. How about daily byte? Okay, it might be hard to find seating there, but it's looking like 20. Okay, how about the basement? Okay, it's looking smaller than daily byte. Okay, and care a boo coffee. Okay, all right, that's the smallest. So I think we're going for daily byte. So we'll see how it goes, because quite honestly, I mean, anytime you put any flat surface out there, there's an EC student on it within a matter of seconds. So if we're too crowded, then I think we might have to not do it there, but we'll see how it goes. I will go there next week and try to keep them there. So change it on the wiki. All right, so so far you learned to represent information with bits, right? For the last couple of weeks, we've been talking about different ways to represent information and manipulate some of that information, arithmetic, things like that. Now our class as a whole is going to teach you how to design a computer. Okay, so we're going to teach you everything you need to know to build a computer, design a computer, fairly simple one, but a computer, right? So computer instructions are pretty simple. So once we get there, you'll see computer instructions can do things like add to numbers together, copy some bits from one place on the chip to another. Not many programmers are writing those kind of instructions, right? So if you look at all the people writing programs, or a few of them these days, according to my colleagues, still DSP people, but signal processing people that is are writing instructions. But for the most part, not very many people are writing instructions. Most people are writing high-level languages. So since about 1954, when scientists came up with this idea of a formula translator, people have been trying to bridge this semantic gap between human problems, like how to make a peanut butter sandwich and instructions at our detectors. So how do you get a computer to do something that you sort of think you know how to do as a human? And how do you make that an easy process? So as a result, there are now thousands of computer languages. And most of the programs in the world, of course, are written most of the programs that run, most of the programs written, I think whatever metric you choose, most programs are written in these languages. And meaning that the people writing the programs are not using instructions, they're writing in some higher-level language, like C, or like Java, or C++. So before we move on and start talking about how to go from bits and transistors up into gates, we're going to take a week and talk about the language C. So what's the point of that? Why go all the way up there and then come back down? So I mentioned at the start of class, in the predecessor classes, we found that a lot of the students, about 20%, it was going too fast, right? So students especially felt, and honestly, I measured it many times and it wasn't quite true, but students really felt that there were a big disadvantage if they hadn't programmed before. So it took them time to get used to programming, and people would feel like, well, this is not fair, I need to quit and start over because I don't like where I'm going with this grade in this class. And so we had about 20% of the people who would drop out of the class and take it again later. So that was not a very satisfying feeling. So we thought, well, let's switch the material around. So the class you're in now, we're doing mostly digital design, but we wanted to give people more time to absorb programming, more time to absorb just the mechanics of programming languages. So honestly, this part of the class, I think I did mention earlier, is not as integrated into the point system as maybe it should be. So you might notice, well, OK, we've got some stuff on the first midterm. After that, we'll have a homework problem a week using C, and you think, well, one part of one homework problem every week, homework's only worth 15%. You might feel like, I don't need to do that. I can safely skip that part. We discourage you from doing that because the whole point was to help people that haven't programmed before just kind of absorb this idea slowly. So if you haven't programmed before, please make sure you do all of these, even though it might seem like work per point is not quite as much as it could be, because there's a lot of other material that is also important. So that's why it's in there. So what are we going to do? Start simple. So we'll have you making some small modifications to programs, and we will have you reading examples of programs. So you can see what programs look like, get a feeling for how they're written before you go and write anything bigger, which you'll do in 220. We'll actually do some programming at the end of this class. So to be clear, in this coming week, today, in the next two lectures, we're not going to teach you how to program. So programming means taking some human task and expressing it in something like assembly code or computer language, like C, or something like that. And we're not teaching you that yet, later. So what are we teaching you? So right now, we're trying to teach you how to express certain types of tasks, usually things like mathematical formulas, some of the digital design ideas we'll talk about in the lecture, formally enough, that you can get a computer to do them. So we won't show you how to teach a computer to make a peanut butter sandwich. I'm not sure they know how to do that yet. But we will teach you how to do things like printed truth table and some other concepts that will become more familiar in the next couple of months. So we'll also teach you how to read and interpret simple formal expressions of computation and C. So to look at simple programs and understand what they're doing. And also how to use a compiler. So we'll commend these skills to the material that we're learning. And also, we think that this will help you learn the skills because you'll have to learn how to express them formally enough that a computer can do them, which is pretty formal. Pretty rigid. Computers are not smart. And also to just help you realize that computers can help you. So in most of your careers, you're going to be using computers on a daily basis. Most E-careers, as well as almost all computer engineering careers, you're going to be using computers on a daily basis. And you, as an Illinois graduate, will have the skill to get the computer to help you. So you'll know how to say, well, this thing I'm doing is really systematic. Let me get my computer to do it for me. And that's what programming is basically. All right. So computers don't know how to program. You'll start learning that skill in part four of the class. I didn't want to mention, by the way, in the old class, and ideally in 220, this compiler idea, the idea of translating something in a language like C into instructions is easy enough that in fact, in our old class, 190, the students wrote most of a compiler as part of that class, or they could. There was one machine problem one time where they ended up writing a compiler. They had also written an assembler that semester so they could take a subset of C and go all the way to binary instructions and run those in the simulator for the LC3 processor. So it's easy enough that students could do it in one semester. So they're not very hard things. Of course, that's not to say they were outwriting, say, a visual studio or something. It was a fairly simple form of a compiler. But we'd like you to learn that. And be that level in a year. That's after 220. So let's talk a little bit about C. So the C's programming language was invented by Dennis Richey when he was at Bell Labs in 1972 to simplify the task of writing the Unix operating system. How many of you use Unix? So you know you're using Unix. So for those of you who didn't raise your hands, how many of you use Windows? Windows is based on Unix. How many of you use Mac OS? Mac OS is based on Unix. How many of you use? What's the other popular? How many of you have a phone with Android? Yeah, Unix. How about iOS? Unix. Linux. Unix. OK. If you don't have any of those five, maybe you don't use Unix. All of those are based on Unix originally. So they're all derivations of Unix. The original Windows was not. But as of Windows NT, everything after that is based on a variant of Unix originally. All right. So that's how important Unix is. But when he was writing this language, the whole idea was he wanted to write something that would allow him to take advantage of the hardware. So C is a fairly transparent mapping from the C language down to typical ISA. So easy enough, as I said, that 220 students, at least in the former class, could write a compiler for it. So the C compiler converts a C program into instructions. And this was around for 17 years before it was standardized. So there are lots of different variations. It became standard. As you'll see, there's still some machine-dependent parts of the C language. So we'll talk about those as we go through. OK. So here's a program. Let's take a look at a little program. So first thing I want you to notice, up here, we have a definition for a function main. The int means it returns an integer to his complement number. So when your program runs, what it does is it just executes this one little piece of code called main. Now you can write other things. We're not going to tell you much more than main. All the programs here in 120, you'll just write main. So your program will execute main. And when it's done, it'll terminate by returning a number in the integer. So that's the first thing to notice. So the next thing I want you to notice is you can break this main into two parts. The first part are called variable declarations. So when you want to use bits for something, you say, hey, I need to have a set of bits. And it's going to have this type integer. It'll go over this in more detail after the rest of the lecture. But it'll have a type that's a two-seater complement number. And I want to name it answer. And I want to set it equal to 42. So you'll have some variable declarations. And then down here, you'll have a sequence of statements. So all the program does when you start it, and you start it by typing a command like you did in the lab, or you're on a GUI like Windows or Mac OS, you double-click something that starts a program. If you're on Android or iOS, you click something that starts a program. So whenever you start the program, it runs through main execute statements in order. And then that's it. Start. So pretty simple. If you program before, maybe this is really dull. Sorry for that. But if not, maybe it's too fast. There you go. All right. So what does the program do? Again, it executes these statements in order. So let's take a look at the two here. So the first one is going to send to the monitor this string. We'll talk about how it gets that string later. But it'll basically say the answer is 42, followed by an asking new line character, such that later printing, if there were, any would occur on a new line. And then that's it. The second statement terminates the program. So there are two statements. You do them in order if that they appear in the program. Bigger programs will have many statements, again, just execute them one at a time until you get to the end. Good programs also have a lot of comments. Even though people try to make computer languages expressive and easy to read and understand, it's very easy to write programs that are not very easy to read and understand. So we strongly encourage you to put lots and lots of comments. So what's a comment and see? It starts with a slash followed by a star, master's, and it ends with a star followed by a slash. Yeah, question? Yes. Yeah, so the question is does percent d stand for decimal? The answer is yes, d stands for decimal. There's also i for integer. I don't think I mentioned that in my slides. We will go through this in much more detail. And it's going to be probably a later lecture. But we will go through print f and scan f in 11 detail. Good question. OK. Any other questions? Yeah. There is. And we're trying to minimize the amount of syntax we make you learn in 120. So there are single line comments. They're adopted from C++ and the currency standards and they're slash slash. So we'll try not to give you those because we don't want you to have to learn everything all at once. But I think it should be OK to use them, although sometimes we're asking you to compile with older standards. So I'm not positive about that. I think it's OK. So if you know some of these things, it's OK. Sometimes we'll ask you to use specific set of operators for certain programs because we want you to learn how to use them. So it'll be, hopefully it'll be clear in the assignment what you're allowed to do or not do. OK. So comments can span more than one line. So you can write as many lines of comments as you want with this style of comment. The other style that someone just asked about, what's your name? I should start learning. Sasha, the style Sasha just asked about, if you do learn it, those are single line comments. They end at the end of the line. But the C comments I'm introducing here, these continue until the compiler sees a star followed by a slash. So you can put as many lines as you want. So so far, just looking at that little program, we looked at four different elements of C syntax. So we saw the main function, which is the function that executes when your program starts. We saw the variable declarations, which specify symbolic names and data types. We looked at statements, which tell the computer what to do. And then we looked at comments, which just help us humans understand the program. So let's go through those and think about some of the things that tend to confuse people. So first of all, I'm calling main a function, but that doesn't mean it's a function in the mathematical sense. So you learned about mathematical functions probably in junior high or high school. And they said, OK, well, at every point, the function will have one value. And that value, it doesn't change. If you evaluate the function at the same point twice, you get the same answer. That's not necessarily true for a C function. A C function is only a function in this syntactic sense of the C language. So it's a set of variable declarations in a sequence of statements, ending in a return statement, doesn't necessarily mean it's a math function. So for example, we can write a program that returns a random number between 0 and 255. So that program does not return a unique answer. And that program does not even return a reproducible answer. So if I run it twice, I get two different random numbers. So it's not a mathematical function. Both of those properties would be needed to make it a mathematical function. So when we say function, don't try to infer things from math because these are not math functions. They're also not algorithms. So on first day, I think we talked about algorithms. Algorithm cannot run forever. They have to be finite. A program can run forever. Very simple. Very easy to make a program that just runs forever. It doesn't do anything. That would be a very simple program that's not an algorithm. OK, let's look at variable declarations in a little more detail. So variable declaration lets you name sets of bits. So we've been talking about sets of bits. We've been using variable names as if they were algebraic variable names. They're going to be different in a programming language. So that's going to be one thing we talk about carefully in a minute. This declaration from the sample program I showed you, int answer equals 42. So it's OK. I want the compiler to make space on the chip in memory for a 32-bit, two-s complement number. The shorthand for that in C is int. And I want to initialize the bits of those 32 bits to the bit pattern for 42 using 32-bit, two-s complement as the data type. And I want to make use of those bits any time one of my statements in my program uses the symbolic name answer. So any time I use the name answer, I want the computer to go get those bits and use them for that number, whatever I've stored. Yeah, Eric. How do you know that number for the one of the three? So the question is, how do I know it's 32 bits? The answer is that I don't give in that it's a C variable. But the lab machines are, I'll come back to this. I should have a slide on it. The lab machines int is 32 bits. Some older machines that might be 16 bits. So unfortunately, see types due to pandas. We'll talk about later. I have some on that question. Do we have to do that in our architecture as long as that? So the question is, should you make assumptions? In this class, it's probably not going to hurt you if you're making assumptions. There might be cases where you need to know occasionally. But generally, as I'll show you in a later slide, I would recommend that you be specific in your code. Yeah. Yeah. OK, so variables in C are not algebra variables. So if I tell you in algebra, well, A equals 42, then you would say, well, OK, A is 42. Five minutes from now, A will still be 42. As long as we talk about the same problem, A is 42. A doesn't suddenly become 25. That's not true in C. Every statement in C can change the value of really any number of variables. So your variables just represent sets of bits. Those bits can be changed by the statements. So you should not think of them as something that, like a variable in algebra, continues to hold its value forever. Yeah. That should be clear in constant. Can you declare constant variables? Yes, you can. And in that case, if you declare it constant, the compiler will try to keep you from changing the values. Now, in C, the C language allows the programmer to do pretty much whatever they want. So even if it's constant, sometimes the programmer can change it. Obviously, programmer should not change it. But so you can declare constants. And there are other things you can do to try to have something that people can know is not changeable. So yes, you can do that. But in general, most of your variables will not be constants. They're also just on that topic. There are high-level languages that use what are called immutable types. And in that case, your variables don't change value. They're assigned once, and then they hold their value. The cost of using those languages performance-wise is often a factor of 1,000 to 10,000 times in speed. So if you can afford it, if your program doesn't need to do much, they deal. Go use one of those. Maybe it's easier to understand. If you need that 1,000-fold performance, then you need to use something that's closer to the hardware. OK, so variables and C are sets of bits. So they're not algebraic variables. I think that's a source of confusion for people when they first learned how to program a potential source of confusion. So your bits are always going to be 0s and 1s. But you can't necessarily make other assumptions about them unless you look at the code. So by looking at the code, it might be true that, for example, something is constant. If you look back at the little example program, the variable answer is always 42. None of the statements change answer. So it is, in fact, constant. But you can't make that assumption without looking at what the code does. Now, the other thing about variables and C, in addition to just being a set of bits, is you tell the compiler what is the data type. So C requires that you say a specific data type for each variable. A not all programming languages require that. But C does. So you need to specify a data type. And then the compiler will use that data type to interpret the statements that use that variable. So for example, if you say that you want to add answer plus some other thing, maybe you want to take two times answer. So you say answer plus answer. What instructions should the compiler generate? Well, it depends on the data type of answer. If answer were unsigned, then it would generate instructions to do an unsigned add. If it were a two's complement, it would generate instructions to do a two's complement addition. If it's floating point, it will generate instructions to do floating point addition. How does the compiler know what to do? It looks at the data type that you've assigned by writing the variable declaration with the type int. So given the int, it will choose two's complement. Now, there are a few data types that are always available in C. They're part of the C language. So they correspond to the representations that we've been talking about for the last couple of weeks. So you've got unsigned representations. You've got two's complement representations. And you've got IEEE floating point representations. So the same ones you just learned, those are available to you in actually most high-level languages, but certainly in C. There are also a bit primitive data types that can be used to store ASCII characters. Technically, there are also two's complement, but you can store ASCII characters in them. Now, here's the question that Eric and Rowe were asking earlier. So unfortunately, C was designed to be fast. And so C is still the case in C that if you use the primitive data types, those are tuned to your system. And so the number of bits in an int depends on your system. The number of bits in a long int depends on your system. So when you write those types, you want to be a little careful about what you assume. You probably should assume the smallest one so that if overflows going to happen on a different system, you handle it properly. But for example, a long int could be 32-bit, 2's complement, or it could be 64. And which one you get depends on what compiler you use, what system you're running on. So to be specific, there's a more modern little library where you use int 32 and 64 underscore t, the t stands for type. So if you look in the notes, there's a more complete list. But the ones that we'll use in class for example codes are a small subset. So I just wanted to show you those and tell you what they mean on the lab machines. So we have character which holds an ASCII character, or it's interpreted also as an 8-bit 2's complement number. We'll call it character right at CHAR. There's int, which on the lab machines are 32-bit 2's complement numbers. I won't use long int. I think on the lab machines, those are 64-bit. But on other machines, it'd be 32 also. There's float, which is the IEEE 754 single precision format that you learned in class. And then there's also double, which is the double precision format, which is 64 bits, which I think I saw the other days 11-bit of Mantici and 53-bit. I'm sorry, 11-bit of exponent and 53-bit Mantici. But you don't need to know that. It's just a bigger representation. So you have more significant figures of accuracy. Yeah. There is. And you know what? In fact, I don't think I use it in the examples in the slide, but we do use it in some of the assignments. Basically, if you put the word unsigned in front of character or integer, you will get unsigned instead of choose complement. Yeah. And that is in the notes. So take a look at the notes. And it will show you much more, a much more complete set of types, including these types down here in 32 and 64, you end for unsigned. Yeah. Yeah. Good question. Anything else? Yeah. We're not going to, we will not require pointers in 120. You'll learn those in 220. Yeah. Sorry. Let's skip that for now. Yeah. Thanks a lot. OK. So the answer is yes. So each variable also has a name, which we call an identifier. So what is an identifier? So it's a set of letters and numbers. Can I actually use underscore two, but in, put it in the slide? It starts with a letter. So you can't start with a number. Any length, some compilers may limit you, so don't make it 100 characters or something like that. But it's supposed to be any length. Use words. You can have any length. And so don't put one letter variable names if you can avoid it, because then people will not know what you mean. If you can describe what you want in the variable name, then whenever people use it, they know what it's supposed to represent. Variables are case sensitive. So all four of these are at could be different variables. You could have four different variables named in this way. And the C compiler would not complain. But your professors may be upset. So please don't do that. It'll make your colleagues looking at your code crazy too. That can do that because the difference. Mm-hm. A lot of different variables. Yeah, so the compiler can tell the difference because the ASCII characters are different. And the rule in C is that they are case sensitive identifiers. So that means if there's any difference in case, those are separate identifiers. Yes. So what are the other stuff? That's an interesting question. You mean as opposed to unit code? I am not sure what the latest C standard says. I'll try to look that up. That's a good question. Certainly for many years, they were only ASCII. But if you want to write international identifiers, I'm not sure if you're allowed to. I'm not sure. Is another question? Yeah. Only by name. So you can't use reserved keywords. So you can't name a variable int. I think of that's true. There's certain contextual identifiers that can help. But for the most part, you shouldn't name variables keywords. But other than that, variables are identified just by the symbolic name you choose for them. Yeah. Yeah. Sort of variable name. Yeah, I think I said that. Start with a letter. Oh. Yeah. Sorry. Okay. So what do these look like? So let's put these together. Variable declaration is a data type. So when I put these brackets, you would replace that thing with an instance of a particular data type. And you wouldn't write the brackets. So you could put int or care or flow or double. Then you put your identifier. Then you can assign an initial value to the variable by saying equals some value. So for example, there are a few examples down here. I can have an integer and choose complement. That'll have data type int. And I'll assign the value 42. For example, I can have an unsigned integer. So this kind of answers your question, even though I guess I didn't put that in my list. But I'm an unsigned integer. So this up here is a two complement representation. This one down here is an unsigned representation. Here I have assigned the value of 100 to that. I can have a floating point number, name it IEEE 754. So the underscores in there is cool. And assign it the value of the Godrush number. Because I can do that with a float. Yeah. If you have any other signs. Mm-hmm. Like, if they want data. Yes. So together, these two on the lab machines would be a 32-bit unsigned. Yeah. Yeah. Does this need to be capital? I think it can also be lowercase. Yeah. Don't need to be capital. Yeah. Special characters. You mean the underscores? No, you can use underscore. That's the only one. Yeah. Except maybe the new standards might allow you in a code in which case. I'll look it up. I'll find out. Yeah. Yes. Mm-hmm. You cannot use space and identifiers. No. Yeah. You certainly cannot use space. Anything else? Yeah. Other than letters, numbers, and underscores. At least the older standards will not allow anything. I'm not in C. Yeah. There are a lot of programming languages where dollar sign means evaluate or variable. And evaluate variable. But C, no. You can't use it as part of an identifier. Yeah. Unfortunately, no. I don't know. So even if you want to type in billions or something, usually when we type such numbers, it would be either a real number in scientific notation or it would be something that maybe we could put in hex. It's kind of rare that you would type or something with a lot of zeros. I haven't seen too many numbers like three billion eight hundred and seventy nine million where. Yeah. Yeah. So the question is, can you add different types together? The answer is yes, but that's a little bit beyond the scope of what I want to talk about in the lectures. There's a start section in the notes that talks about that. So take a look at that. And if you have more questions about it, come talk to me in office hours. It's a good question. But we're trying to contain kind of the things everyone has to think about here. Okay. So the initialization is actually optimal optional. So the following is acceptable. Just data type identifier, for example, int i. So if I write that code, what what's an i? I just set a bits. What's there? It's just bits, right? Good. Okay. I'll ask you lots of questions where the answer is bits. They may be zero bits, but don't count on it. And unfortunately, if you just write a little program and you look at those bits, often they will be zero bits. But again, don't count on it. Okay. It's because of the way the operating systems work. Yeah. Sometimes. So the question is, will a compiler complain if you declare something without initializing it to a specific bit pattern? And then try to make use of that unknown bit pattern. And unfortunately, the answer is sometimes. So maybe even most of the time, but not always. So if the compiler can figure it out and you tell the compiler as you always should, that if the compiler thinks there's anything wrong, it should tell you, then it will tell you. But there's some corner cases where compilers won't figure it out. And the default with a lot of compilers is that they don't warn you about everything anyway. So as a programmer, you should just always turn on all warnings and hopefully the compiler will help you whenever it can. All right. So statements tell the computer what to do. So in C, a statement specifies a complete operation. So it tells a computer to do something. And the function main again is a sequence of statements. So we have a bunch of different metaphors for executing, running, starting the program. So I might use those words interchangeably. When that happens, your computer executes the statements in main in the order that they appear. All right. So that's the intro. Any more questions before we start talking? I guess not. Yeah. Yeah. So there is a way to do it. And I deliberately didn't show you because I want you to put a comment on every variable. So the question is, can you put more, can you declare more than one variable in a single line? And you might see it so you can, you separate them with commas. The other reason I don't tell you is because in C, when you learn new types like pointers, the declaration is a little bit strange. And so until you get used to it, it's kind of air prone. Whereas if you declare only one variable per line, you kind of make it easier to understand. So I'm trying to encourage you not to do that, but you can do that and it'll be fine. Yes. So the question is, does the compiler read, read languages line by line? To some extent, yes. I mean, there has to be a way to get through the program, but C does not have the constraints of some other programming languages where, for example, a function, we're not going to talk about functions, but there are languages where you can't make use of things. That's not making use of things that weren't above that thing you're trying to use in the file. That's not true in C. Variable declarations still do have to be above, but I would like to have you put all of those at the top of your blocks of code, even though now modern standards allow you to express them. Anything else before we go on? How would null be represented by bits? That's kind of beyond, did I say null? No is a pointer value. It's all zeros. It's the L0 bits. And there's a reason for that, historically, but it's beyond the scope of the class. So ask me after class, I'll tell you. Yeah, we'll look at statements in more detail later, but essentially, after every statement, every simple statement you would put a semicolon. So a simple statement is a type of statement. Oh, absolutely. If you leave out semicolon, the compiler will complain. Yeah, it's not optional. The compiler will not let you compile your code. Or worse, it will let you compile your code or not have a completely different meaning. So you want to be careful. All right. Let's talk now before we get into statements again and look through those in more detail. I want to spend some time talking about another syntax concept and see which is the expression. So an expression is a calculation consisting of variables and operators. So let me give you some examples. They say a plus 42. A is a variable. 42 is a number. I add them together. That's an expression. I can say a divided by b. You can say deposits minus withdrawals. So all of these are fine. Good expressions. The C language has a lot of operators. So we're going to focus on four types, four types of operators that you need to learn for 120. And then there's another type called logical operators that will introduce, but we're going to not have you. You're not required to learn them. We're not going to introduce the subtleties of logical operators. We'll leave those for 220. So we're going to look at arithmetic operators, bitwise Boolean operators, like we talked about when we introduced Boolean expressions, relational and comparison operators, and then the assignment operator. So first arithmetic, we've got addition, which is a plus subtraction minus multiplication is an asterisk. So you need to use an asterisk for multiplication. I divide as a slash modulus, which only works for integers is a percent sign. There are lots of other functions in the C library. So lots of other mathematical functions, sign, cosine, et cetera, square root, those are going to leave for 220. So you shouldn't have to use those here. If we have one occasionally, we will tell you how to use it and what it is and what it means and things like that. But for the most part, you won't need to use any of those. So let's take a look at this. So let's say I declare two variables, a and b, both in, and I set a to 120 and I set b to 42. Now when I say evaluates to the C compiler, the C compiler is going to write a set of instructions that takes the variables a and b and adds them together. And so evaluates to means, well, what's the answer? What's the value of this expression after it's been computed? So what's a plus b? Yeah, 162. Good. A minus b. 78. Good. A times b. A big number. Very good. A mod b. 36. 36. Good. I think that's right. So we've got A mod b. So there's two b's make 84 and I got 36 left. What about A divided by b? Oh, I'm hearing lots of twos. So a lot of people have played with this stuff before. Why two? Why not two point 36 over 42 is seven something. Yeah, it's an int, right? So it's going to return us an int. So some of the pitfalls of division, actually, let me start at the bottom. It dividing by an int, dividing one int by another returns an integer. Okay. So if you take 120 divided by 42, you get two. If you take 100 divided by eight, you get some integer. It's going to be either 12 or 13. You multiply 12 or 13 by eight. You don't get 100. Right. So when you do integer arithmetic, don't expect basic mathematical equivalence is like this to work because this one is going to give you 12 or 13. That's going around. If you divide by zero, if you divide by zero, your program will crash. If you do an integer divide by zero, your program will crash. If you do that with floating point, you'll get an infinity. Yeah. I get a divided by adding a long, by adding a one to five. A long, um, adding a long, without the forward, you get a little bit. Ah, so can you, can you change the type and, uh, yes, so there are type inversions. And again, that's in the start part of the note. So, um, so take a look at that. If, if you want to know how to do it, um, but we won't do it in this class. So you don't need to, you don't need to understand it yet for 220, you'll need to understand it. Um, the other thing is there are no checks for overflow and C. So if you tell, if you tell the C compiler, hey, I want to set my unsigned hint to zero minus one. It will do that for you. It's a very big number. Zero minus one unsigned will, will overflow. Right. So you'll get for 32 bits, you know, four billion, whatever minus one, two to the 32 minus one. And if it's, if it's, if you did a long unsigned long end, you'd get a two to the 64 minus one. Um, unfortunately, C behavior with arithmetic also sometimes depends on the processor. So in particular, um, the rounding direction for integers depends on the processor. Whatever the processor says, most modern processors round toward zero. So it's not really as bad as it sounds because you'll, you'll be hard pressed to find a processor that doesn't round toward zero these days. So what does round toward zero mean? If you take 11 divided by three, you should get what three and two thirds instead you get three. So it goes downwards towards zero. If you take negative 11 and divide it by three, you should get negative three and two thirds. It doesn't go downwards. It goes towards zero. So negative three. So it's not rounding off. Right. In both of those cases, if you round it off, you would get four and negative four. Right. Round towards the closest integer. Yeah. Yes. So floating point will produce a floating point number. And so there is rounding, right, because it's a finite, a finite mantissa, right. And so sometimes actually in your homework, you'll need to think about that. Right. But, but you will need around, uh, IEEE floating point has four rounding modes, uh, down up, um, towards zero and it is the last one. Um, oh, around to nearest. Yeah. So those are the four modes. So the default mode is round to nearest, but you can change the mode. Oh, no, it will not. It will return a floating point number that's most accurate representation it can modular rounding. Right. At the two to the minus 23rd level for the exponent. Yeah. Uh, the percent sign is modulus. So it's similar to, um, it's similar to remainder, but not quite the same. I mean, when, when you learned remainder, it's probably elementary school. And so you probably didn't, I think we teach it in the US at least before you learn negative numbers. And so no one talked about, well, what is a negative, what is remainder when you work with negative numbers in division. But modulus does is defined, um, but it's not quite defined the way it is mathematically. So this is not mathematical modulus. So it's defined in this way and see. So it's defined such that this expression is equal to a. So in particular, if, for example, you said, well, what's 11 mod, what's negative 11 mod three? Right. Then negative 11 divided by three gives you minus three, multiply that by three minus nine. And to get negative 11 back, the mod has to be minus two. So this expression defines modulus and C. So in practice, what this means is don't use negative modulus. You'll have plenty of, plenty of codes where for, um, building things like cyclic buffers, you want, you want to use modulus. But if you ever need to go in the negative direction, then you want to add the, you want to add, um, E plus one, if your, if your number is negative because this negative modulus will screw your code up. But this is how it's defined. So if you want to work with the definition, that's the definition. And again, it's machine dependent, right? Because the divide part depends on the machine depends on the processor. So that's another aspect of modulus is it's not even well defined in the language. Okay. So here are, so that was it for arithmetic, those five operators. Um, they're no for finish these, but let me introduce the, the bitwise operators. So we have six of them. And four of them, you know, um, or at least you know the, the bull, the bullying operators. So and or not next or, and then we have left shift and right shift. So in some languages, some of you may know languages where the carrot sign means exponentiation, not in C. It means bitwise X or. Okay. So if you, if you write it, the compiler will not complain. It will also not exponentiate. It will do a bitwise X or. So they treat numbers as bits. So here I've defined a couple of hacks values. You'll notice that in C, when we write hacks numbers, we put a zero in front of the X. So this is hex notation for a 32 bit, a 32 bit value. Uh, these are the, the two 32 bit values, otherwise the same numbers. So if I take a bitwise ended with B, then what should that give me? This is why I said hex is maybe not as easy with bitwise. Like well. So you have to translate in your head to bits. Okay. Let me just tell you. Um, so the seven is zero one one one. The two is zero zero zero one zero. So if you end those together, you just get the two back. And so you get the two. And then the eight is one zero zero zero. And the a is one zero one zero. So you just get the eight back with bitwise and. Okay. And you can, you can maybe write these out in bits. It'll be a little easier. If you or them together, you get this pattern. The hex will be much easier to calculate. So usually we, if we are doing bitwise operators, it's because we care about bits. And so thinking of it, and it hex is maybe the natural thing. If you get this one, maybe we can figure out easily. So not a bitwise. Well, remember, how do we negate and choose compliment? Not a plus one, right? So if I just take not a, it should be negative a minus one. So negative one, 21. Notice that the bit pattern. It is a bitwise not on all of the bits. So all the high bits became apps or what ones which in hex or apps. And then if I X or them together, I get, I get 52. So let me stop there. And then on Wednesday, we will cover shifts. Thanks. Thank you. You You You You You You You You You You You You You You"
    },
    {
        "ECE120-2016-11-14-MT3-review-slides.mp4": " It's midterm review. Everyone ready for the midterm? Go. OK. Can we just go home now? All right. So what do you want to review? Oh my gosh. We'll start and go back. More versus merely. OK. And mom, have you heard your hand up first? Oh, it's up there already. OK. I'll see if we data path. Yeah. So I'm trying to remember the exact boundary. So you need to know control signals. You need to know how fetch works. But you don't need to do things yet, like translate RTL into control signals. We'll see through a data path. And look. Thank you. The public is the development, like, managing the hard-to-finantic funds. This one, the ISA, where you have the R and the MBR. And your instruction is just like knowing how to increment those and change those. OK. So instruction processing, basically. OK. How to make an FSM smaller? OK. So just basically FSM design, or we didn't talk about statement minimization. But now, I mean, I did it once, but we didn't talk about it as a subject, right? When we did the lab machine, I reduced states. But that was not. It's something you can do, but we didn't formally cover it. So yeah. So we're not going to worry too much about that. Yeah. I'm sorry? FSM design. OK. OK. Anything else? Not on there? Yeah. I'm sorry. OK. OK. OK. Yeah. I'm sorry. LC3, what operands? OK. Do you mean in the sense of like the different addressing modes or OK. OK. All right. Anyone else want to put something up here before we go down and vote? All right. So more versus melee. How many people want to see something? OK. What's that about? 35 to 40? Memory and building larger memories from smaller memories. OK. That's more like 50 to 60. LC3 data path. So all popular topics. I'm going to get to make 30-ish. By no, I mean, I'm going to be about 25 to 30. Our instruction processing. That's only about 5 to 10. Final shape machine design. About 20% serialization and trade-offs. OK. Maybe in the 15. All right. LC3 operands. OK. One. No one else? OK. Yeah. Can ask me an officer. All right. OK. So what's the popular topic? So let's start with memories. There are a couple of examples in the notes if you hadn't seen those already. So do take a look at those. But remember a memory model. I don't remember which ones we use where. But generally speaking, there's data input. There's data output. There's some kind of chip select. Sometimes inverted. Sometimes not. There's some kind of write-navel. Sometimes we might write read or write bar. Sometimes we might write write-navel. I think the book actually just writes RW. And it just assumes you'll put one bit for one of them and one bit for the other. And then of course, there's address. So remind me. So let's see. So two to those. Give these names. So what's the size of the address space for this generic thing here? Two to the n, right? So the address space is this part. And how many bits do we need for address? N bits. OK. Good. So this over here will be N bits wide. So this thing implies N bit addresses. And what's the addressability? M, right? So M is the addressability. And so what does that M imply about our box over here? So what does it affect chip select? Data in and data out, which are how many bits wide? M. Good. OK. So this is our generic design. So this is a two to the n by m bit memory. And so let's say you wanted to build something with, so I'm going to pursue that a little bit to be able to fit something else. Let's say you wanted to build something twice as wide wider addressability. So say two to the m bit. I'm sorry, two m bits. So you get say two chips. You could also do four chips. And we'll just do four. So this will be four m wide. So if I want to build the same size address space, but four times is wide, how many of these chips will operate at one time? Four or if the other possibility is what? If we're not doing anything, how many chips will be chip selected? Zero, right? So all zero or four. So how should I wire up the chips away? Same chips away, right? So let's see. Let me call this external CS. And so that would go to all of their chips away. I can spell chips away. All of their chips away. What about reading right? Right, enable will call it. It's all the same, right? So if I'm going to do a read, I'll read from all four. If I do a write, I'll write to all four. In all of the designs we've looked at, but if you look at some of the test problems, it doesn't necessarily have to be identical signal. Usually you wouldn't have some of them reading and some of them writing. That would be strange, right? OK. I'll just label these separately to keep the diagram from getting too messy. What about address? Yeah, I probably could just take the external address. I didn't make the address space any different. But if I just take the external address and put it in, that's fine. So external address to all four also. So it's pretty easy to do the wider one, right? What about data and data out? Yeah, so I'm going to have four m bits coming in, right? So if you make each one m wide, really, it's a total of four m. So I'm breaking these out of something much wider. And then each of those m groups can go into one ship. Does it matter which m I put into which chip? Yeah, as long as they come out the same way, it doesn't matter. You can do whatever you want. When you get into later classes, I think I mentioned this, there are some tricks you might want to play that'll affect performance. But correctness wise, it doesn't matter at all. So as long as the input and the output have the same pattern of splitting the bits up and bringing them back together, it's fine. I'll ask you something else when we look at the other way for address, too. So let's do the same gathering in our outputs then. Normally, we'd have to label this somehow. The best way would just be to not gather them and put them side by side like this. So those are the data outs coming out of the bottom. I won't go at all the labels. So it's pretty straightforward to make wider addressability. What about more addresses? What if we want to do more addresses? Let's see. Do you want to do four? I fit four. Yeah, there we go. OK. How many chips are going to be active? So now I'm going to have four times as many addresses the same addressability. How many chips will be active at once? One or four or zero? So how do I set chips select? Yeah, so I need to decoder. So they're four of these. So how big a decoder? I mean, how many bits in? Two. Good. And where should those come from? Two address bits. OK, good. So two address bits. So let's say these are m plus 1 and m. So now I still have m minus 1 down to 0, which is m bits. So those I could put into here and here and here. Sorry, I think I scrambled my order a little bit. And each of these is m bits wide. Oh, but what if I don't want to do anything? What if I don't want to do an operation? This decoder, as I've drawn, is always going to output a 1. I should use a enable. What should I use to drive enable? CS, OK. So external chips select is going to drive this decoder. Does it matter which of these outputs I hook to the chip? What if I cross my wire? Does it matter? Yeah, they're identical chips, right? So if I call the name of the chip that gets associated with whatever the output of the decoder is, but if I just flip the chips, they're the same chips, it doesn't matter. So that's fine. What about right enable? Yeah, whatever the external one is, only one of these chips is going to be active. So it's the only one that'll be looking at right enable externally. So we'll drive all four of the right enables from the same signal. And that's OK. Let's see. So then we only have one data in of m bits. So where should it go? All four, really? Oh, yeah, only one chip's going to be active. So if we're actually doing a right, whatever chip that is, we'll look at the data we put in, the other ones will ignore it. OK, so here's the tricky part. What about data out? Where's it come from? Ah, do I need a mux? So remember, when we talked about the data chip, we're going to assume these chips are going to be try state buffered on the outputs. So if the chip is not chip selected, and I look at its outputs, what logic values do they have? Yeah, high Z, right? It's not even bits. It's disconnected. So if I have only one chip out of the four, or even zero chips out of the four, connected to the same set of wires, a bus, basically, only one of those is active. Only one of those is going to put zeroes and ones onto that output, onto those output wires. So that's safe. As long as only have one chip chip selected, which is always true because it might be colder, most one of them is chip selected, I can take these four and just wire them together, and it will be safe. Sorry, sorry to see this. And that'll be M bits of data out. So whichever chip I say I want to read from, whichever chip I say I want to read from will produce my output data on the same M wires. And that'll be fine. What happens if I scrambled my wires? I mean, it's kind of complicated. If I was building this on a protoboard, I scrambled my wires. Wouldn't matter? Doesn't matter, right? As long as they're self-consistent. What if I put by accident address M plus 1 into one of these bits? Would that matter? So well, so be careful. So if I use these two bits for my decoder, and then I reuse one of the bits for one of the addresses, maybe on all four chips. Does that matter? It does, right? So let me give you a concrete example. Let's make it easy. We'll say that there's only a one bit address going into the chip. So if I use, so I'll have three bits of address in total. If I use address 2 and 1 here, and address 1 going into the chips. So if I've done it this way by accident, how many addresses can I access? Total. How many bits am I using? Can I get 2 there, right? But that's not an extra one now. So total number of bits is only 2. So I can only access 4 addresses. So if I make that mistake, I'm going to miss half of my cells in my memory. So it's not going to let me access everything. Does it matter, which ones I choose, as long as the other m are over here? I can reply to my problem. I can't do it. Yeah, I can't do it. So why did I pick the high 2 bits? I just like the high 2 bits. It really doesn't matter. Any 2 bits is fine. Any 2 bits is fine. You could pick the low 2 bits. It would work fine. So any 2 bits to run the decoder, but don't reuse those bits as the address for the chips. Yeah. No. If your chips don't have it, then you need it. If your chips don't have the tricycle buffer, and you would need it, yes. If the chips have it, it's just a waste, and it will slow things down. So it's extra gait, extra chips, and it will slow things down. So if your chips have it, you wouldn't do it. You don't. And that was the question. I was asking, do we want to put a Mox just in case? And I said, no. If you know you have tricycle buffer, which is our design, you do not need the Mox, and you shouldn't put it in. Is that answer? Yes. Yes. So if you don't have tricycle buffers on the chips, then these chips are driving active zeros and ones. In other words, they're connecting the output wires to your BDD or to ground. So if you connect those two output wires together, you have a good chance of creating a short. So if you, in order to avoid that, you would need a Mox. The question is either, or sorry. Yeah. OK. Yeah. The tricycle buffers are inside these chips. So in our abstract model, all of the memory chips would give you will be tricycle buffered. Internally, yeah, it would be driven by chips away. And in fact, it would be driven. There's a diagram in my PowerPoint slides also in the notes. But it's driven by a combination of chips select and write and enable. So you only get data output when you are reading Andrew chips selected. OK. OK. So that's an interesting question. So if I send chips select zero, are my outputs zeros and ones or are they high impedance? Yeah. So I don't need any more tricycle buffers. This design is already tricycle buffered by virtue of having all of the chips be tricycle buffered. And having the chips selects all these zero if I didn't select this bigger system. Yeah. The good question. Yeah. So you need to know what it is. And you need to know why it's useful. So yeah. So how to implement it. The only useful way, like there was a homework problem that just made you replicate the logic of the decoder. So that was not a useful way. The useful way is to use the fact that you've got bit lines and you've got select lines in each of those can be driven by a separate decoder. So yeah. So you have to label the data output with that one. That's the one that's drawn to that. That's like zero. Higher than zero. And then they have to connect to the bigger abstraction. So you have M plus 2 bits of address coming into the bigger system. So giving them new names is fine. So long as you still connect them to the address bits. Yeah. That's the only way you can name two times M plus 2 address. Two to the M plus 2 power address. Yeah. This is four times as many addresses as you can. You can go to this. OK. All right. Should we move on then? OK. All right. So back to topics briefly. Sure. No. We were on the line. No. You mean things like SRAM cells? No. No. OK. So let's see. So this one we finished. Thinking more versus melee. So you don't really need to know much about more versus melee. And really, honestly, the names. So the only thing in our class, we always do these. So these are a limited version of more machines in which inputs do not affect outputs directly. In other words, state is a function of state moment. And melee is the more general model in which outputs and depend directly on inputs. And this is the one that's always used in practice is the melee machine. They're not met with names. It's just that if you want a more machine, you simply don't make your outputs depend directly on your inputs. So if you designed one and the timing doesn't work, you can throw down a flip-flop. Yeah. Yes, the next state logic can always depend on the input of the output on the states. That's right. That's right. Yeah. So the constraint is a no more machine. The output is purely a function of the state, not also of the input. So that's the extra constraint. It does mean the slight difference in the transition diagrams and the way we draw them, also next state tables. So this is how Moore looks. So because the outputs are only a function of the state, we can label the outputs in each state. There's no input dependence. So we don't need to know what the inputs are. We can just put the output bits here. And then the input arcs, we have to have one arc per bit combination of inputs. With merely, however, the outputs depend on the or can depend on the inputs as well. So what we have to do is label them this way. So every state, remember, if there are say three inputs, we have two to the three or eight different possible arcs. And each of those arcs will have a different combination of outputs, potentially, because the outputs can depend on the inputs. So in the melee design, the transition diagrams, you've got to move the outputs to the transition arcs. OK, yeah. There's a synchronous counter. An example, a synchronous counter can be either. That's an orthogonal decision. The synchronous counter just means that all of your flip-flops, so synchronous means they all share a common clock. And the counter means that it's mostly, it doesn't have inputs. It's just a loop of a circle of states. So you can still do these either way. I guess, technically, if we say strictly that a counter has no inputs, then they're the same. So if you do things like reset, you could have a reset that forced the output immediately into whatever state would be, you'd be resetting the counter into, for example. And that would be a melee counter versus a more counter that waited until the rise in clock edge before accepting that reset signal. But it's largely orthogonal to. OK. Anything else on this topic? All right. Let's move on. I think maybe LC3 data path, wow. Let's see. What kind of looks like this? There's a big bus. Oh, all right. So LC3 data path. So there are a lot of control signals, but you don't need to know how to use them until the final. The thing is you need to know or this instruction processing, which no one wanted to hear about, fact to 10 people. Who asked this question, clarify what you wanted to know? And everyone liked it. So anyone can chime in, yeah. OK. So all right. So first of all, there's the state machine. So the state machine looks roughly like this, and you need to know a tiny bit about it. So this is kind of what you need to know. Yeah, just a second. Let me finish it. I'm going to zoom out a little. OK. So this is the rough structure of the state machine. So you've got three fetch states. And you should know the RTL for those. You've got a decode state, and I'll explain why that needs to be separate again in a second. And then you've got instruction execution. I've drawn three. Of course, there are 16, right? Because we have four bit off codes. So there's 16 different sequences, each of which is executing one of the different off codes. So the way they LC3 works is first you do your fetch. And then we'll talk about what RTL goes into those boxes in a second. Then you do your decode. Then you do the instruction execution for whatever that off code is. So you do need to know at this point, roughly how these instructions are processed, what fetch does, what decode does on the LC3 data path. You don't need to know which control signals does that mean. I showed you. But we're not going to ask you to write control signals until the final. I did say until. So you do need to know that eventually. They're not tomorrow. Yeah, then. Yeah, so this one, the sheet I gave you is what you'll get, which has this with all the RTL filled in. So you will have that also. You probably want to remember the thing that I've told you 25 times in our class, which is PC gets incremented in the first stage. So when your instruction executes, as long as you remember that, you'll be good. But you should know kind of what the RTL is here. You can always look it up in the diagram. If you lost that page, it's under resources LC3 handout or something like that on the wiki. So if you want to look it up, it's also attached to most of the sample exams. And it will be attached to your exam tomorrow night. So you'll have the LC3 encoding with all the fields in the RTL. You have this one. You'll have the data path picture. A lot of this you won't need much of this exam, but you'll have them. You'll need it more on the final. OK, let's just fill these in. So do you remember what's here? RTL-wise? So M-A-R, M-A-R. OK. So the other thing to remember about RTL is these things happen simultaneously. So whichever order I write them doesn't matter. On the right side is the current value of the PC and the cycle. And on the left side is what the values will be in the next cycle. So at the rising clock edge, M-A-R will have the value currently in the PC and this cycle. PC will get incremented by 1. So then whenever our instruction gets executed, the address in the PC will be the instruction address whatever one we're executing plus 1. So what's next? Yeah, so then we read memory. So memory, remember, the way the von Neumann machine is designed, the memory only reads from the M-A-R. So we just tell the memory, well, go to a read. And we wait until the bits are then in the M-D-R. So that's the second stage. If you look at the diagram, we've talked a couple times about memory having a ready signal. So that just stays there as long as memory's not ready. So once memory finishes getting the bits, we move on down to here. What happens there? Yeah, so we copy across the bus from M-D-R to IR. And that's the point at which we can decode. This actually sets branch enable here, but we didn't even talk about that. It's not that important right now. So the reason we need a decode stage is because the decode is going to make use of the IR. But remember, we can't make use of the IR until the instruction bits are in the IR and the instruction bits are not in the IR until the rising edge after that third state. So in the fourth state, the bits are there for us to look at and to branch off into these different subsequences for each of the instructions. But before that fourth stage, we don't have the IR sitting in the, I'm sorry, we don't have the bits of the instruction in the IR yet. So we can't branch until that fourth cycle. Yeah. Red or written? Yeah, so for a right, you fill M-D-R and then fill M-A-R and say go to a right. And then for read, you fill M-A-R and say go to a read and then you pull the bits out of M-D-R after the memory says they're there. OK, anything else? No, no, you don't think so. OK. I know you cannot set memory decision. Sorry, I can answer afterwards. OK, anything else? Yeah. So whenever we can have that memory says, as we go along to this, like, moving where the memory is, I'm going to try on your turn. And that's when you take the key, when you're going to fill in all that stuff and that's when you're going to fill out the output. Yes. Yeah. So yeah, so I won't go through and do a detailed example now, but there are some detailed examples in the PowerPoint notes and in the recorded lectures, right? That'll remind you of exactly what values the PC-ER M-A-R-M-D-R-T-A-C as you go through and fetch and execute instructions, including loads and stores. Yeah. It's important to first turn it on the DR and the DR and the DR and the DR. When you start executing an instruction, yes. After that point, for a loader store, you're going to change M-D-R for a loader store. Right? So are they always the same now? And have to be ordered for R-D-1-C. How are these different high-Rs? They're in execution. You may need to use M-D-R. So you asked whether I or an M-D-R are always the same. No, they're not. Yeah, that's it. Even in my slides. Oh, yeah. Unfortunately, I'm not sure that I can remember exactly what it looks like in the discussion. Yeah, except that I don't know what the discussion sheet looks like. I'd look at it briefly. And then, yeah, if you have it, it can show it to me, even I'll explain it. But I mean, we tend to ask you things like the sequences so that you fill them in as they change. So you do need to be able to walk through this and understand when a particular register changes and then put them in order, that kind of stuff. But I don't remember how that discussion sheet was organized up to a couple of minutes. No. I mean, T-Flip Flop is not terribly complicated, but it's outside the scope of the class. People don't really use it anyway. I know. I know, yeah. It was not supposed to. OK, anything else? OK. All right. So which one is that? OK. So Van Neumann architecture. All right. So Van Neumann, there are five pieces, right? What are they again? Memory. Good. As you name them, I can draw them. Control unit. You've got to remember my Tolkien joke. I'm sorry? Input and output. And processing unit, right? OK. And then there are a couple of registers here and there. Right? So what are the pieces, let's say, will start with the order. Oh, I put them in the same places as before I did. So what do we have associated with the memory again? M-A-R and M-D-R. So remember, remember, always going to have an address. And we're going to use a register to hold that address when the load or store stuff from the memory. And then M-D-R, we use as a register to move the bits in and out since the memory is asynchronous with respect to the processor. Memory is not clocked, remember. In the processing unit, we also had a couple of things. What were they? Again, ALU, right? So arithmetic logic unit is what that stands for. Whatever set of arithmetic logic, shift, whatever operations we want to do, we have some function unit that can do them for us. So for the LC3 is relatively simple. Generally, it could be any set we want to implement. What was the other thing in the processing unit? A register file. So these are actually registers. So they are synchronous with respect to the processor and substantially faster than the memory. And they allow us to manipulate values quickly by just having a few of them in the processing unit. So tends to be small and much faster than memory. Input and output, those are just devices. We talked in detail about the LC3, but you don't need to know those details until 220. And then what's in the control unit? PC and IR. So program counter, which is what again? The address of the next instruction, right? And what's the IR? Instruction register. And what does it hold? The bits of the current instruction. Anyone want to ask anything else about that? Wow, it captured my pen. I don't know how it grows. I can figure out how to unfreeze it before we run out of time. Anything else you want to know? No, you don't need to memorize those. You can always just look them up if you need to use them. I don't think we hand you anything that has them, but you don't need to know them. OK, so nothing else on the noirman? All right. Finite state machine design. That's just kind of general, huh? So let's see. I mean, those are, let's see. So let's try to think of another one we could do quickly. Yeah, we could do a counter quickly. That's a good idea. Or a sequence recognizing. Why don't we do one of both? So just someone make up some bits, say three bits. 1, 1, 0, next. 0, 1, 0, next. Next. 1, 0, 0. OK, there's a counter. That was tough. All right. So then, I mean, seriously, what we would do is write. So those will call us s2s1s0. And we could write those out like this. So 0, 0, 0, 0. We could say, well, I don't care. 0, 0, 1, you didn't do me either. Shout out to your, 0, 1, 0, 1, 1, 1, 0, 1, 1, where's that going? xxx. It's a pretty easy counter so far. 1, 1, 0. Oh, he does words. We'll see. OK. OK. OK, so we can draw k-maps. So let's see. So we've got xx1x. OK. And then 1x0, 1. All right. So an x0? x0, huh? What we could do this? We need that one. Yeah. We have just this one here, right? We'll write that. So I look OK. Simple enough. Could be simpler, I don't know. Maybe I wouldn't get full points in this problem. All right. So xx1x again, 1x1o. That look right? That looks there. Yeah, that one looks easy, huh? OK. So s1 plus is what is that? s1 bar. OK. Good. So xx1x and 0x0. Is this one? That's good. Is that right? Oh, sorry. Now this doesn't look right, does it? I think I screwed something up. This doesn't look right. OK. On top of the. I know I just don't know where you're going. I know I just don't know where you're looking. Sorry. All right. So 0 is a transfer of care about 1, 1, 0. Oh. How did I screw this one up? Oh shoot, I copied it wrong. Give me. Why didn't you guys tell me? Which way did I copy it wrong? So in that way. So s2 should be on the left. Thank you. OK. That's what you're saying. On the left of all the K-mats. OK. So then these are all wrong. So this one should be s0 bar. Is that right? That looks right. This one should be s2 bar. And this one should be s2 bar s1 bar s0. OK. Does that look better? OK. Thank you. So three flip-flops. And this one will be s2 bar. And this one will be a 0 bar. And this one will be s2 bar s1 bar s0. And I think that's it. So if you wanted to, you could then ask, well, what happens if it starts in one of these four unknown states and then figure out whether we need to initialize it or we can just dump it into some random state and expect it to fall into our cycle of four? Oh, now you can always write it like this. Yeah. Yeah. Yeah, we're not, I don't think we're checking anymore whether you can draw. We used to, right? That's not anymore. I think it's OK. All right. Used for a long time ago. All right. So let's do a little sequence recognize you then, someone pick a sequence. 1, 1, 1. OK. So how many bits do we need to recognize that? Three. OK. So have a start state. So usually sequence recognizers, we just start by drawing what we want to recognize. So start with output of 0. This would output of 0. This would output of 0. This thing would output of 1. And then we can fill in the other arcs. So one question since that can overlap with itself, what does that mean? So these three, if this were input sequence, these three should output of 1 in that cycle. But if our input sequence is 1, 1, 1, 1, well, that's going to output of 1 here. But then the question is what about this one? All right. So if we say, well, it's OK to overlap, then that question mark should be a 1. Sorry, the input is the top, the output is the bottom, and they're lined up cycle by cycle. So it takes an extra cycle of delay, in order to get the output with the moment she. So the question is, should that question mark be a 0 or 1? So that output did. If we allow the overlap, then it should be a 1. If we say no, they need to be separate sequences of 1, 1, 1. Then it should be a 0. If we say that have to be separate, we can only get 1, 1 every three cycles at most. Yeah. So if we want to have 10 last days, 1 output, what case would we have back with itself? So the last thing don't do that first day, that's the start? Yeah, so if you allow overlap, then you put this back to itself, because I'd be continuing your sequence of 1s. And if you didn't allow overlap, you should be going up to that one, because that's the new one for the next sequence. So anyone ever preference? You want overlap or no overlap? Do you do a question? Yeah, so let me draw this more carefully. So this is input. This is output. And so the recognition will always be in the cycle after the sequence. So you won't recognize it until the rising clock edge. You're able to change the output to say, well, yeah, I saw the sequence. And so in terms of cycles, if you count this one on the left as a cycle 1, that'll be in cycle 4, 3 cycles later that you see the output is equal to 1, the sequence recognition. And remember, then, in more machine, the output is independent of the input. So even though that question mark I just added may affect our state transition, it can't affect the fact that we saw the sequence. OK, so what did we want to do? Overlapped or no overlap? Overlapped. OK, so if we're going to allow overlap, let's see, we don't have a 0R here, where should I go? To itself? How about a 0R here? Back to start. This one's relatively easy. What about a 0R here? Back to start. All right, what about a 0R here? Start. What about a 1R here? OK. But it would done. Can we finish? OK. Here's our sequence recognizer. Yeah, you have to complete it. So remember when we talked about designing finite state machines, you have to make sure that every state has a 0 and a 1R. There's one bit of input. You have two bits of input. You need to make sure it has all four arcs. And you can give these names if you wanted to or say, well, let's recognize one bit, two bits, three bits. All right. We have two minutes. So serialization and trade-offs. So generally speaking, let's just do it quickly generally. The serial design, if you're talking about a big bit slice design, it can take lots of gates, right? So when you do the serial design, you do have to put a few flip-flops down. But those flip-flops will balance against you a few bit slices. And so if you're doing a many bit slice design, the serial one will be smaller. It will take fewer, fewer gates. It will also be slower. So you're doing a slower design, but a smaller design. Why is it going to be slower? There are several reasons. But basically, you're doing one bit per clock cycle. And so instead of being limited by the gate delays in your system, you're limited by the clock cycle. And you're doing one bit per clock cycle. This serial design may not be the limiting factor in your system. So the clock cycle may even be longer than the single flip-flop plus one bit slice delay. So that adds up pretty quickly. I mean, numbers wise, it was something like an order of magnitude slower in the designs we looked at in class. Those are two extrema. So you can say, well, instead of having one bit slice for my serial design, let me do two, or four, five, or eight, or whatever. And so you can operate in between those two. You can also optimize. So instead of doing a bit slice design, you can optimize across a couple of bits. So there's one example of that in the notes where we did the comparator that we did in class. And then it's not something we're going to ask you to do. But if you're interested, I did a two-bit design for the comparator where you can handle two bits at a time and optimize the logic for that, just so you can see how you get smaller logic when you look at the more general function and optimize it with KMAPs. So those are some of the trade-offs to think about. Yeah, so let me stop there. If there are any real burning questions, you can ask me now that I'm going to turn off the mic. Thanks."
    }
]